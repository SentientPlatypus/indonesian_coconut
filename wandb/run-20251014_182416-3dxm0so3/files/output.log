Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.08395
Policy Entropy: 1.36156
Value Function Loss: 313.40268

Mean KL Divergence: -0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12045
Value Function Update Magnitude: 0.04398

Collected Steps per Second: 8,125.12517
Overall Steps per Second: 6,563.76637

Timestep Collection Time: 6.15744
Timestep Consumption Time: 1.46470
PPO Batch Consumption Time: 0.64305
Total Iteration Time: 7.62215

Cumulative Model Updates: 892
Cumulative Timesteps: 14,955,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.40129
Policy Entropy: 1.25956
Value Function Loss: 178.82690

Mean KL Divergence: 0.18085
SB3 Clip Fraction: 0.59484
Policy Update Magnitude: 0.25160
Value Function Update Magnitude: 0.11005

Collected Steps per Second: 9,574.88033
Overall Steps per Second: 8,301.18426

Timestep Collection Time: 5.22283
Timestep Consumption Time: 0.80137
PPO Batch Consumption Time: 0.04787
Total Iteration Time: 6.02420

Cumulative Model Updates: 894
Cumulative Timesteps: 15,005,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 15005292...
Checkpoint 15005292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.84631
Policy Entropy: 1.21261
Value Function Loss: 127.96316

Mean KL Divergence: 0.21259
SB3 Clip Fraction: 0.56802
Policy Update Magnitude: 0.21880
Value Function Update Magnitude: 0.14884

Collected Steps per Second: 10,454.61919
Overall Steps per Second: 8,924.33966

Timestep Collection Time: 4.78487
Timestep Consumption Time: 0.82047
PPO Batch Consumption Time: 0.04796
Total Iteration Time: 5.60534

Cumulative Model Updates: 896
Cumulative Timesteps: 15,055,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.05793
Policy Entropy: 1.17569
Value Function Loss: 33.30959

Mean KL Divergence: 0.11987
SB3 Clip Fraction: 0.59357
Policy Update Magnitude: 0.25629
Value Function Update Magnitude: 0.29326

Collected Steps per Second: 10,344.35895
Overall Steps per Second: 8,785.01132

Timestep Collection Time: 4.83355
Timestep Consumption Time: 0.85796
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 5.69151

Cumulative Model Updates: 899
Cumulative Timesteps: 15,105,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 15105316...
Checkpoint 15105316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.97285
Policy Entropy: 1.14584
Value Function Loss: 29.38533

Mean KL Divergence: 0.04519
SB3 Clip Fraction: 0.45293
Policy Update Magnitude: 0.22724
Value Function Update Magnitude: 0.27802

Collected Steps per Second: 10,233.31730
Overall Steps per Second: 8,788.16791

Timestep Collection Time: 4.88776
Timestep Consumption Time: 0.80376
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 5.69152

Cumulative Model Updates: 902
Cumulative Timesteps: 15,155,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.27592
Policy Entropy: 1.13605
Value Function Loss: 31.31931

Mean KL Divergence: 0.03673
SB3 Clip Fraction: 0.31115
Policy Update Magnitude: 0.25686
Value Function Update Magnitude: 0.22601

Collected Steps per Second: 10,129.83325
Overall Steps per Second: 8,512.70097

Timestep Collection Time: 4.93749
Timestep Consumption Time: 0.93796
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 5.87546

Cumulative Model Updates: 905
Cumulative Timesteps: 15,205,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 15205350...
Checkpoint 15205350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.86619
Policy Entropy: 1.12885
Value Function Loss: 27.54296

Mean KL Divergence: 0.02402
SB3 Clip Fraction: 0.28908
Policy Update Magnitude: 0.22184
Value Function Update Magnitude: 0.24231

Collected Steps per Second: 9,420.43011
Overall Steps per Second: 8,196.54732

Timestep Collection Time: 5.30825
Timestep Consumption Time: 0.79261
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 6.10086

Cumulative Model Updates: 908
Cumulative Timesteps: 15,255,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.40504
Policy Entropy: 1.15865
Value Function Loss: 23.90204

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.24782
Policy Update Magnitude: 0.19728
Value Function Update Magnitude: 0.27758

Collected Steps per Second: 10,673.31379
Overall Steps per Second: 9,079.71088

Timestep Collection Time: 4.68702
Timestep Consumption Time: 0.82263
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.50965

Cumulative Model Updates: 911
Cumulative Timesteps: 15,305,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 15305382...
Checkpoint 15305382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.05932
Policy Entropy: 1.17232
Value Function Loss: 23.89521

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.32946
Policy Update Magnitude: 0.19352
Value Function Update Magnitude: 0.28270

Collected Steps per Second: 10,332.56671
Overall Steps per Second: 8,807.61004

Timestep Collection Time: 4.84004
Timestep Consumption Time: 0.83801
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 5.67804

Cumulative Model Updates: 914
Cumulative Timesteps: 15,355,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.86590
Policy Entropy: 1.16629
Value Function Loss: 22.38929

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.29077
Policy Update Magnitude: 0.24432
Value Function Update Magnitude: 0.26877

Collected Steps per Second: 10,116.11884
Overall Steps per Second: 8,699.50456

Timestep Collection Time: 4.94636
Timestep Consumption Time: 0.80546
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 5.75182

Cumulative Model Updates: 917
Cumulative Timesteps: 15,405,430

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 15405430...
Checkpoint 15405430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.92854
Policy Entropy: 1.15714
Value Function Loss: 21.40395

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.31975
Policy Update Magnitude: 0.21290
Value Function Update Magnitude: 0.26222

Collected Steps per Second: 9,669.43258
Overall Steps per Second: 8,182.29795

Timestep Collection Time: 5.17238
Timestep Consumption Time: 0.94008
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.11246

Cumulative Model Updates: 920
Cumulative Timesteps: 15,455,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.97025
Policy Entropy: 1.21427
Value Function Loss: 20.92125

Mean KL Divergence: 0.05357
SB3 Clip Fraction: 0.47910
Policy Update Magnitude: 0.22163
Value Function Update Magnitude: 0.26314

Collected Steps per Second: 8,737.09090
Overall Steps per Second: 7,559.12887

Timestep Collection Time: 5.72273
Timestep Consumption Time: 0.89179
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 6.61452

Cumulative Model Updates: 923
Cumulative Timesteps: 15,505,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 15505444...
Checkpoint 15505444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.10463
Policy Entropy: 1.19750
Value Function Loss: 20.08027

Mean KL Divergence: 0.02759
SB3 Clip Fraction: 0.31425
Policy Update Magnitude: 0.17684
Value Function Update Magnitude: 0.25890

Collected Steps per Second: 9,532.83360
Overall Steps per Second: 8,035.32988

Timestep Collection Time: 5.24734
Timestep Consumption Time: 0.97792
PPO Batch Consumption Time: 0.05074
Total Iteration Time: 6.22526

Cumulative Model Updates: 926
Cumulative Timesteps: 15,555,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.01026
Policy Entropy: 1.23040
Value Function Loss: 20.02903

Mean KL Divergence: 0.03658
SB3 Clip Fraction: 0.32669
Policy Update Magnitude: 0.17153
Value Function Update Magnitude: 0.25457

Collected Steps per Second: 9,361.72798
Overall Steps per Second: 7,991.31327

Timestep Collection Time: 5.34303
Timestep Consumption Time: 0.91627
PPO Batch Consumption Time: 0.03982
Total Iteration Time: 6.25930

Cumulative Model Updates: 929
Cumulative Timesteps: 15,605,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 15605486...
Checkpoint 15605486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.74579
Policy Entropy: 1.20688
Value Function Loss: 18.94020

Mean KL Divergence: 0.02255
SB3 Clip Fraction: 0.19852
Policy Update Magnitude: 0.16452
Value Function Update Magnitude: 0.25929

Collected Steps per Second: 9,606.06489
Overall Steps per Second: 8,307.93814

Timestep Collection Time: 5.20546
Timestep Consumption Time: 0.81336
PPO Batch Consumption Time: 0.04340
Total Iteration Time: 6.01882

Cumulative Model Updates: 932
Cumulative Timesteps: 15,655,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.27957
Policy Entropy: 1.23249
Value Function Loss: 19.10993

Mean KL Divergence: 0.03080
SB3 Clip Fraction: 0.28510
Policy Update Magnitude: 0.15828
Value Function Update Magnitude: 0.22707

Collected Steps per Second: 9,713.91008
Overall Steps per Second: 8,259.89243

Timestep Collection Time: 5.14849
Timestep Consumption Time: 0.90631
PPO Batch Consumption Time: 0.04477
Total Iteration Time: 6.05480

Cumulative Model Updates: 935
Cumulative Timesteps: 15,705,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 15705502...
Checkpoint 15705502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.23054
Policy Entropy: 1.20893
Value Function Loss: 18.54696

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.20109
Policy Update Magnitude: 0.16252
Value Function Update Magnitude: 0.21143

Collected Steps per Second: 9,151.75252
Overall Steps per Second: 7,802.61177

Timestep Collection Time: 5.46606
Timestep Consumption Time: 0.94513
PPO Batch Consumption Time: 0.04592
Total Iteration Time: 6.41119

Cumulative Model Updates: 938
Cumulative Timesteps: 15,755,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.15555
Policy Entropy: 1.23821
Value Function Loss: 17.90017

Mean KL Divergence: 0.03162
SB3 Clip Fraction: 0.26035
Policy Update Magnitude: 0.15739
Value Function Update Magnitude: 0.20042

Collected Steps per Second: 9,897.13621
Overall Steps per Second: 8,365.41086

Timestep Collection Time: 5.05237
Timestep Consumption Time: 0.92510
PPO Batch Consumption Time: 0.04464
Total Iteration Time: 5.97747

Cumulative Model Updates: 941
Cumulative Timesteps: 15,805,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 15805530...
Checkpoint 15805530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.61451
Policy Entropy: 1.21166
Value Function Loss: 17.42313

Mean KL Divergence: 0.02393
SB3 Clip Fraction: 0.19460
Policy Update Magnitude: 0.16449
Value Function Update Magnitude: 0.20970

Collected Steps per Second: 8,977.36078
Overall Steps per Second: 7,712.85932

Timestep Collection Time: 5.57113
Timestep Consumption Time: 0.91337
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 6.48450

Cumulative Model Updates: 944
Cumulative Timesteps: 15,855,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.42974
Policy Entropy: 1.24281
Value Function Loss: 16.42443

Mean KL Divergence: 0.03895
SB3 Clip Fraction: 0.28851
Policy Update Magnitude: 0.15485
Value Function Update Magnitude: 0.17752

Collected Steps per Second: 9,012.26342
Overall Steps per Second: 7,655.71097

Timestep Collection Time: 5.54977
Timestep Consumption Time: 0.98339
PPO Batch Consumption Time: 0.04748
Total Iteration Time: 6.53316

Cumulative Model Updates: 947
Cumulative Timesteps: 15,905,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 15905560...
Checkpoint 15905560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.13570
Policy Entropy: 1.22362
Value Function Loss: 16.57271

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.18899
Policy Update Magnitude: 0.13052
Value Function Update Magnitude: 0.15350

Collected Steps per Second: 8,871.57928
Overall Steps per Second: 7,574.47077

Timestep Collection Time: 5.63823
Timestep Consumption Time: 0.96553
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 6.60376

Cumulative Model Updates: 950
Cumulative Timesteps: 15,955,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.03681
Policy Entropy: 1.25820
Value Function Loss: 16.29777

Mean KL Divergence: 0.03504
SB3 Clip Fraction: 0.24267
Policy Update Magnitude: 0.13456
Value Function Update Magnitude: 0.12951

Collected Steps per Second: 9,170.23022
Overall Steps per Second: 7,869.32539

Timestep Collection Time: 5.45373
Timestep Consumption Time: 0.90158
PPO Batch Consumption Time: 0.04600
Total Iteration Time: 6.35531

Cumulative Model Updates: 953
Cumulative Timesteps: 16,005,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 16005592...
Checkpoint 16005592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.24025
Policy Entropy: 1.23346
Value Function Loss: 16.33062

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.17519
Policy Update Magnitude: 0.12061
Value Function Update Magnitude: 0.12315

Collected Steps per Second: 10,062.82790
Overall Steps per Second: 8,608.91470

Timestep Collection Time: 4.97077
Timestep Consumption Time: 0.83949
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.81026

Cumulative Model Updates: 956
Cumulative Timesteps: 16,055,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.41205
Policy Entropy: 1.25804
Value Function Loss: 15.19846

Mean KL Divergence: 0.03000
SB3 Clip Fraction: 0.22248
Policy Update Magnitude: 0.12420
Value Function Update Magnitude: 0.10447

Collected Steps per Second: 9,909.87095
Overall Steps per Second: 8,482.07355

Timestep Collection Time: 5.04568
Timestep Consumption Time: 0.84934
PPO Batch Consumption Time: 0.04901
Total Iteration Time: 5.89502

Cumulative Model Updates: 959
Cumulative Timesteps: 16,105,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 16105614...
Checkpoint 16105614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.41359
Policy Entropy: 1.23366
Value Function Loss: 15.41602

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.17892
Policy Update Magnitude: 0.12507
Value Function Update Magnitude: 0.10343

Collected Steps per Second: 9,938.51002
Overall Steps per Second: 8,614.53906

Timestep Collection Time: 5.03194
Timestep Consumption Time: 0.77336
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 5.80530

Cumulative Model Updates: 962
Cumulative Timesteps: 16,155,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.17225
Policy Entropy: 1.26303
Value Function Loss: 14.82688

Mean KL Divergence: 0.02850
SB3 Clip Fraction: 0.20617
Policy Update Magnitude: 0.13639
Value Function Update Magnitude: 0.09199

Collected Steps per Second: 9,632.39159
Overall Steps per Second: 8,102.16237

Timestep Collection Time: 5.19103
Timestep Consumption Time: 0.98041
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 6.17144

Cumulative Model Updates: 965
Cumulative Timesteps: 16,205,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 16205626...
Checkpoint 16205626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.12352
Policy Entropy: 1.23643
Value Function Loss: 14.89729

Mean KL Divergence: 0.02558
SB3 Clip Fraction: 0.19100
Policy Update Magnitude: 0.12747
Value Function Update Magnitude: 0.08627

Collected Steps per Second: 9,882.80155
Overall Steps per Second: 8,419.60567

Timestep Collection Time: 5.06031
Timestep Consumption Time: 0.87940
PPO Batch Consumption Time: 0.03917
Total Iteration Time: 5.93971

Cumulative Model Updates: 968
Cumulative Timesteps: 16,255,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.98974
Policy Entropy: 1.26115
Value Function Loss: 14.43076

Mean KL Divergence: 0.02783
SB3 Clip Fraction: 0.20015
Policy Update Magnitude: 0.12103
Value Function Update Magnitude: 0.07300

Collected Steps per Second: 10,337.42837
Overall Steps per Second: 8,768.44394

Timestep Collection Time: 4.83737
Timestep Consumption Time: 0.86558
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 5.70295

Cumulative Model Updates: 971
Cumulative Timesteps: 16,305,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 16305642...
Checkpoint 16305642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.54786
Policy Entropy: 1.23656
Value Function Loss: 14.58324

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.19077
Policy Update Magnitude: 0.12238
Value Function Update Magnitude: 0.07492

Collected Steps per Second: 10,016.26170
Overall Steps per Second: 8,506.74900

Timestep Collection Time: 4.99308
Timestep Consumption Time: 0.88602
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 5.87910

Cumulative Model Updates: 974
Cumulative Timesteps: 16,355,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.44731
Policy Entropy: 1.26312
Value Function Loss: 14.32364

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.19697
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.06837

Collected Steps per Second: 10,288.74456
Overall Steps per Second: 8,765.23533

Timestep Collection Time: 4.86123
Timestep Consumption Time: 0.84494
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 5.70618

Cumulative Model Updates: 977
Cumulative Timesteps: 16,405,670

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 16405670...
Checkpoint 16405670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.66796
Policy Entropy: 1.23874
Value Function Loss: 13.78573

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.18052
Policy Update Magnitude: 0.12716
Value Function Update Magnitude: 0.07059

Collected Steps per Second: 11,007.16701
Overall Steps per Second: 9,244.64536

Timestep Collection Time: 4.54249
Timestep Consumption Time: 0.86604
PPO Batch Consumption Time: 0.04720
Total Iteration Time: 5.40854

Cumulative Model Updates: 980
Cumulative Timesteps: 16,455,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.17924
Policy Entropy: 1.26445
Value Function Loss: 13.75705

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.20468
Policy Update Magnitude: 0.12864
Value Function Update Magnitude: 0.06400

Collected Steps per Second: 10,391.40336
Overall Steps per Second: 8,980.99150

Timestep Collection Time: 4.81244
Timestep Consumption Time: 0.75577
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 5.56820

Cumulative Model Updates: 983
Cumulative Timesteps: 16,505,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 16505678...
Checkpoint 16505678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.46640
Policy Entropy: 1.24261
Value Function Loss: 13.63479

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.17672
Policy Update Magnitude: 0.12600
Value Function Update Magnitude: 0.07191

Collected Steps per Second: 10,701.98733
Overall Steps per Second: 9,018.22057

Timestep Collection Time: 4.67352
Timestep Consumption Time: 0.87258
PPO Batch Consumption Time: 0.04821
Total Iteration Time: 5.54611

Cumulative Model Updates: 986
Cumulative Timesteps: 16,555,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.15152
Policy Entropy: 1.26639
Value Function Loss: 13.34740

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.18383
Policy Update Magnitude: 0.12805
Value Function Update Magnitude: 0.07859

Collected Steps per Second: 10,704.69547
Overall Steps per Second: 9,019.36580

Timestep Collection Time: 4.67365
Timestep Consumption Time: 0.87330
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 5.54695

Cumulative Model Updates: 989
Cumulative Timesteps: 16,605,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 16605724...
Checkpoint 16605724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.12796
Policy Entropy: 1.24081
Value Function Loss: 13.42335

Mean KL Divergence: 0.02646
SB3 Clip Fraction: 0.19202
Policy Update Magnitude: 0.12299
Value Function Update Magnitude: 0.09928

Collected Steps per Second: 11,247.68609
Overall Steps per Second: 9,379.92450

Timestep Collection Time: 4.44696
Timestep Consumption Time: 0.88549
PPO Batch Consumption Time: 0.04711
Total Iteration Time: 5.33245

Cumulative Model Updates: 992
Cumulative Timesteps: 16,655,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.55662
Policy Entropy: 1.26472
Value Function Loss: 13.35711

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.17192
Policy Update Magnitude: 0.12481
Value Function Update Magnitude: 0.07580

Collected Steps per Second: 10,863.32756
Overall Steps per Second: 9,146.13055

Timestep Collection Time: 4.60283
Timestep Consumption Time: 0.86419
PPO Batch Consumption Time: 0.04144
Total Iteration Time: 5.46701

Cumulative Model Updates: 995
Cumulative Timesteps: 16,705,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 16705744...
Checkpoint 16705744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.88097
Policy Entropy: 1.24044
Value Function Loss: 13.14693

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.18705
Policy Update Magnitude: 0.12839
Value Function Update Magnitude: 0.08646

Collected Steps per Second: 10,150.96516
Overall Steps per Second: 8,755.61841

Timestep Collection Time: 4.92643
Timestep Consumption Time: 0.78510
PPO Batch Consumption Time: 0.04561
Total Iteration Time: 5.71153

Cumulative Model Updates: 998
Cumulative Timesteps: 16,755,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.02047
Policy Entropy: 1.26424
Value Function Loss: 12.77322

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.17323
Policy Update Magnitude: 0.12133
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 10,281.54009
Overall Steps per Second: 8,760.58998

Timestep Collection Time: 4.86581
Timestep Consumption Time: 0.84477
PPO Batch Consumption Time: 0.03974
Total Iteration Time: 5.71057

Cumulative Model Updates: 1,001
Cumulative Timesteps: 16,805,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 16805780...
Checkpoint 16805780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.70458
Policy Entropy: 1.24174
Value Function Loss: 12.87682

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.18003
Policy Update Magnitude: 0.12382
Value Function Update Magnitude: 0.08777

Collected Steps per Second: 10,556.87940
Overall Steps per Second: 9,092.93237

Timestep Collection Time: 4.73814
Timestep Consumption Time: 0.76283
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 5.50098

Cumulative Model Updates: 1,004
Cumulative Timesteps: 16,855,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.21005
Policy Entropy: 1.26027
Value Function Loss: 12.76394

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.17475
Policy Update Magnitude: 0.11196
Value Function Update Magnitude: 0.08365

Collected Steps per Second: 10,859.32299
Overall Steps per Second: 9,219.86813

Timestep Collection Time: 4.60710
Timestep Consumption Time: 0.81922
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 5.42632

Cumulative Model Updates: 1,007
Cumulative Timesteps: 16,905,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 16905830...
Checkpoint 16905830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.43211
Policy Entropy: 1.23581
Value Function Loss: 12.52204

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.18261
Policy Update Magnitude: 0.11024
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 10,539.57784
Overall Steps per Second: 9,015.89770

Timestep Collection Time: 4.74611
Timestep Consumption Time: 0.80209
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 5.54820

Cumulative Model Updates: 1,010
Cumulative Timesteps: 16,955,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.74383
Policy Entropy: 1.25671
Value Function Loss: 12.30936

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.16311
Policy Update Magnitude: 0.11053
Value Function Update Magnitude: 0.06989

Collected Steps per Second: 10,943.43075
Overall Steps per Second: 9,217.80688

Timestep Collection Time: 4.57114
Timestep Consumption Time: 0.85574
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.42689

Cumulative Model Updates: 1,013
Cumulative Timesteps: 17,005,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 17005876...
Checkpoint 17005876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.76495
Policy Entropy: 1.23774
Value Function Loss: 12.81493

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.15999
Policy Update Magnitude: 0.13050
Value Function Update Magnitude: 0.06841

Collected Steps per Second: 10,470.39629
Overall Steps per Second: 8,935.79838

Timestep Collection Time: 4.77613
Timestep Consumption Time: 0.82023
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 5.59637

Cumulative Model Updates: 1,016
Cumulative Timesteps: 17,055,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.26401
Policy Entropy: 1.25882
Value Function Loss: 12.59830

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.11867
Value Function Update Magnitude: 0.07319

Collected Steps per Second: 10,795.16006
Overall Steps per Second: 8,973.59778

Timestep Collection Time: 4.63226
Timestep Consumption Time: 0.94031
PPO Batch Consumption Time: 0.04936
Total Iteration Time: 5.57257

Cumulative Model Updates: 1,019
Cumulative Timesteps: 17,105,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 17105890...
Checkpoint 17105890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.21952
Policy Entropy: 1.23769
Value Function Loss: 12.70267

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.15702
Policy Update Magnitude: 0.13659
Value Function Update Magnitude: 0.08188

Collected Steps per Second: 10,338.48067
Overall Steps per Second: 8,756.60728

Timestep Collection Time: 4.83862
Timestep Consumption Time: 0.87409
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 5.71271

Cumulative Model Updates: 1,022
Cumulative Timesteps: 17,155,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.86944
Policy Entropy: 1.25563
Value Function Loss: 12.20157

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.16262
Policy Update Magnitude: 0.12008
Value Function Update Magnitude: 0.08487

Collected Steps per Second: 10,617.83296
Overall Steps per Second: 9,174.76685

Timestep Collection Time: 4.71019
Timestep Consumption Time: 0.74085
PPO Batch Consumption Time: 0.03953
Total Iteration Time: 5.45104

Cumulative Model Updates: 1,025
Cumulative Timesteps: 17,205,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 17205926...
Checkpoint 17205926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.79543
Policy Entropy: 1.23654
Value Function Loss: 12.40164

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.12931
Value Function Update Magnitude: 0.09135

Collected Steps per Second: 10,507.37132
Overall Steps per Second: 8,912.33302

Timestep Collection Time: 4.76123
Timestep Consumption Time: 0.85212
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 5.61335

Cumulative Model Updates: 1,028
Cumulative Timesteps: 17,255,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.39838
Policy Entropy: 1.25474
Value Function Loss: 12.02696

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.15564
Policy Update Magnitude: 0.11402
Value Function Update Magnitude: 0.07627

Collected Steps per Second: 10,013.92677
Overall Steps per Second: 8,478.79037

Timestep Collection Time: 4.99305
Timestep Consumption Time: 0.90402
PPO Batch Consumption Time: 0.04406
Total Iteration Time: 5.89707

Cumulative Model Updates: 1,031
Cumulative Timesteps: 17,305,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17305954...
Checkpoint 17305954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.44329
Policy Entropy: 1.23931
Value Function Loss: 12.09737

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14603
Policy Update Magnitude: 0.12101
Value Function Update Magnitude: 0.06388

Collected Steps per Second: 10,991.88309
Overall Steps per Second: 9,240.55908

Timestep Collection Time: 4.55118
Timestep Consumption Time: 0.86257
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 5.41374

Cumulative Model Updates: 1,034
Cumulative Timesteps: 17,355,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.32741
Policy Entropy: 1.25968
Value Function Loss: 11.95470

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.11626
Value Function Update Magnitude: 0.06331

Collected Steps per Second: 10,539.97023
Overall Steps per Second: 8,954.63763

Timestep Collection Time: 4.74555
Timestep Consumption Time: 0.84015
PPO Batch Consumption Time: 0.04609
Total Iteration Time: 5.58571

Cumulative Model Updates: 1,037
Cumulative Timesteps: 17,405,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 17405998...
Checkpoint 17405998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171.04169
Policy Entropy: 1.24013
Value Function Loss: 12.46454

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.11859
Value Function Update Magnitude: 0.06367

Collected Steps per Second: 10,614.72701
Overall Steps per Second: 9,163.53129

Timestep Collection Time: 4.71119
Timestep Consumption Time: 0.74609
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.45728

Cumulative Model Updates: 1,040
Cumulative Timesteps: 17,456,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.72368
Policy Entropy: 1.25832
Value Function Loss: 12.41612

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.11893
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 10,392.76952
Overall Steps per Second: 8,812.59070

Timestep Collection Time: 4.81277
Timestep Consumption Time: 0.86297
PPO Batch Consumption Time: 0.04465
Total Iteration Time: 5.67574

Cumulative Model Updates: 1,043
Cumulative Timesteps: 17,506,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 17506024...
Checkpoint 17506024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148.95539
Policy Entropy: 1.24120
Value Function Loss: 12.21186

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.11616
Value Function Update Magnitude: 0.09774

Collected Steps per Second: 10,356.36106
Overall Steps per Second: 8,945.20128

Timestep Collection Time: 4.82969
Timestep Consumption Time: 0.76191
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.59160

Cumulative Model Updates: 1,046
Cumulative Timesteps: 17,556,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.00514
Policy Entropy: 1.25924
Value Function Loss: 11.50846

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.12073
Value Function Update Magnitude: 0.08159

Collected Steps per Second: 10,641.67197
Overall Steps per Second: 9,045.71880

Timestep Collection Time: 4.70039
Timestep Consumption Time: 0.82930
PPO Batch Consumption Time: 0.04501
Total Iteration Time: 5.52969

Cumulative Model Updates: 1,049
Cumulative Timesteps: 17,606,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 17606062...
Checkpoint 17606062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.34633
Policy Entropy: 1.24307
Value Function Loss: 11.37827

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.12599
Value Function Update Magnitude: 0.07633

Collected Steps per Second: 10,743.72359
Overall Steps per Second: 9,165.93577

Timestep Collection Time: 4.65500
Timestep Consumption Time: 0.80129
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 5.45629

Cumulative Model Updates: 1,052
Cumulative Timesteps: 17,656,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.14667
Policy Entropy: 1.25752
Value Function Loss: 11.37427

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.15199
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.08124

Collected Steps per Second: 10,875.84896
Overall Steps per Second: 9,207.49664

Timestep Collection Time: 4.59900
Timestep Consumption Time: 0.83332
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.43231

Cumulative Model Updates: 1,055
Cumulative Timesteps: 17,706,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 17706092...
Checkpoint 17706092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.01551
Policy Entropy: 1.24082
Value Function Loss: 11.49115

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.12973
Value Function Update Magnitude: 0.07459

Collected Steps per Second: 10,679.55896
Overall Steps per Second: 9,054.02216

Timestep Collection Time: 4.68240
Timestep Consumption Time: 0.84067
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 5.52307

Cumulative Model Updates: 1,058
Cumulative Timesteps: 17,756,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.43755
Policy Entropy: 1.25829
Value Function Loss: 11.00722

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.12546
Value Function Update Magnitude: 0.08646

Collected Steps per Second: 10,855.38955
Overall Steps per Second: 9,217.70096

Timestep Collection Time: 4.60932
Timestep Consumption Time: 0.81893
PPO Batch Consumption Time: 0.05042
Total Iteration Time: 5.42825

Cumulative Model Updates: 1,061
Cumulative Timesteps: 17,806,134

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 17806134...
Checkpoint 17806134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.13476
Policy Entropy: 1.24062
Value Function Loss: 11.25663

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.13098
Value Function Update Magnitude: 0.08074

Collected Steps per Second: 9,573.04202
Overall Steps per Second: 8,186.35419

Timestep Collection Time: 5.22342
Timestep Consumption Time: 0.88480
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 6.10821

Cumulative Model Updates: 1,064
Cumulative Timesteps: 17,856,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.21504
Policy Entropy: 1.25708
Value Function Loss: 11.02892

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.11717
Value Function Update Magnitude: 0.09724

Collected Steps per Second: 10,628.42942
Overall Steps per Second: 9,133.95371

Timestep Collection Time: 4.70606
Timestep Consumption Time: 0.76999
PPO Batch Consumption Time: 0.03949
Total Iteration Time: 5.47605

Cumulative Model Updates: 1,067
Cumulative Timesteps: 17,906,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 17906156...
Checkpoint 17906156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.84332
Policy Entropy: 1.23808
Value Function Loss: 11.19541

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.11131
Value Function Update Magnitude: 0.10574

Collected Steps per Second: 10,556.82937
Overall Steps per Second: 8,983.36316

Timestep Collection Time: 4.73722
Timestep Consumption Time: 0.82974
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 5.56696

Cumulative Model Updates: 1,070
Cumulative Timesteps: 17,956,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.57970
Policy Entropy: 1.25764
Value Function Loss: 10.48125

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.11520
Value Function Update Magnitude: 0.08734

Collected Steps per Second: 10,621.96914
Overall Steps per Second: 9,048.72059

Timestep Collection Time: 4.70760
Timestep Consumption Time: 0.81848
PPO Batch Consumption Time: 0.04145
Total Iteration Time: 5.52609

Cumulative Model Updates: 1,073
Cumulative Timesteps: 18,006,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18006170...
Checkpoint 18006170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.03579
Policy Entropy: 1.24209
Value Function Loss: 10.32634

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.10869
Value Function Update Magnitude: 0.15258

Collected Steps per Second: 10,580.65232
Overall Steps per Second: 9,010.83808

Timestep Collection Time: 4.72825
Timestep Consumption Time: 0.82373
PPO Batch Consumption Time: 0.04572
Total Iteration Time: 5.55198

Cumulative Model Updates: 1,076
Cumulative Timesteps: 18,056,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.21810
Policy Entropy: 1.25846
Value Function Loss: 10.40582

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.10950
Value Function Update Magnitude: 0.18035

Collected Steps per Second: 9,090.62486
Overall Steps per Second: 7,703.44453

Timestep Collection Time: 5.50127
Timestep Consumption Time: 0.99063
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 6.49190

Cumulative Model Updates: 1,079
Cumulative Timesteps: 18,106,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 18106208...
Checkpoint 18106208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.90552
Policy Entropy: 1.23912
Value Function Loss: 10.82404

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.10680
Value Function Update Magnitude: 0.16678

Collected Steps per Second: 9,068.30056
Overall Steps per Second: 7,799.95631

Timestep Collection Time: 5.51526
Timestep Consumption Time: 0.89683
PPO Batch Consumption Time: 0.03886
Total Iteration Time: 6.41209

Cumulative Model Updates: 1,082
Cumulative Timesteps: 18,156,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.48803
Policy Entropy: 1.25794
Value Function Loss: 10.60200

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.09842
Value Function Update Magnitude: 0.14459

Collected Steps per Second: 10,127.20248
Overall Steps per Second: 8,634.24625

Timestep Collection Time: 4.93917
Timestep Consumption Time: 0.85404
PPO Batch Consumption Time: 0.03923
Total Iteration Time: 5.79321

Cumulative Model Updates: 1,085
Cumulative Timesteps: 18,206,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 18206242...
Checkpoint 18206242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.05070
Policy Entropy: 1.24165
Value Function Loss: 10.11366

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.11679
Value Function Update Magnitude: 0.13577

Collected Steps per Second: 10,582.86104
Overall Steps per Second: 9,141.18785

Timestep Collection Time: 4.72575
Timestep Consumption Time: 0.74531
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 5.47106

Cumulative Model Updates: 1,088
Cumulative Timesteps: 18,256,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.21792
Policy Entropy: 1.25716
Value Function Loss: 9.72549

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.10673
Value Function Update Magnitude: 0.13923

Collected Steps per Second: 10,630.06997
Overall Steps per Second: 8,991.16503

Timestep Collection Time: 4.70364
Timestep Consumption Time: 0.85738
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 5.56101

Cumulative Model Updates: 1,091
Cumulative Timesteps: 18,306,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 18306254...
Checkpoint 18306254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.91481
Policy Entropy: 1.23945
Value Function Loss: 9.80740

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.10222
Value Function Update Magnitude: 0.13162

Collected Steps per Second: 9,692.52116
Overall Steps per Second: 8,281.59311

Timestep Collection Time: 5.16027
Timestep Consumption Time: 0.87915
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 6.03942

Cumulative Model Updates: 1,094
Cumulative Timesteps: 18,356,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.86982
Policy Entropy: 1.25704
Value Function Loss: 10.03113

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.10862
Value Function Update Magnitude: 0.11166

Collected Steps per Second: 10,650.92166
Overall Steps per Second: 8,985.03078

Timestep Collection Time: 4.69462
Timestep Consumption Time: 0.87042
PPO Batch Consumption Time: 0.04720
Total Iteration Time: 5.56503

Cumulative Model Updates: 1,097
Cumulative Timesteps: 18,406,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 18406272...
Checkpoint 18406272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.04316
Policy Entropy: 1.24275
Value Function Loss: 10.34101

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.10597
Value Function Update Magnitude: 0.11467

Collected Steps per Second: 10,444.22548
Overall Steps per Second: 8,776.18379

Timestep Collection Time: 4.78753
Timestep Consumption Time: 0.90994
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 5.69746

Cumulative Model Updates: 1,100
Cumulative Timesteps: 18,456,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.52995
Policy Entropy: 1.25804
Value Function Loss: 10.40154

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.10788
Value Function Update Magnitude: 0.10786

Collected Steps per Second: 10,480.98048
Overall Steps per Second: 9,026.08679

Timestep Collection Time: 4.77188
Timestep Consumption Time: 0.76917
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 5.54105

Cumulative Model Updates: 1,103
Cumulative Timesteps: 18,506,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 18506288...
Checkpoint 18506288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.56888
Policy Entropy: 1.24113
Value Function Loss: 10.47636

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.10886
Value Function Update Magnitude: 0.10044

Collected Steps per Second: 10,791.11568
Overall Steps per Second: 9,116.53584

Timestep Collection Time: 4.63344
Timestep Consumption Time: 0.85110
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.48454

Cumulative Model Updates: 1,106
Cumulative Timesteps: 18,556,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.35582
Policy Entropy: 1.25432
Value Function Loss: 10.18660

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.09904
Value Function Update Magnitude: 0.09655

Collected Steps per Second: 10,563.96631
Overall Steps per Second: 9,083.35004

Timestep Collection Time: 4.73345
Timestep Consumption Time: 0.77157
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.50502

Cumulative Model Updates: 1,109
Cumulative Timesteps: 18,606,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18606292...
Checkpoint 18606292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.03403
Policy Entropy: 1.23847
Value Function Loss: 10.22074

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.11907
Value Function Update Magnitude: 0.11198

Collected Steps per Second: 10,493.57196
Overall Steps per Second: 8,892.68687

Timestep Collection Time: 4.76901
Timestep Consumption Time: 0.85853
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 5.62755

Cumulative Model Updates: 1,112
Cumulative Timesteps: 18,656,336

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.61263
Policy Entropy: 1.25892
Value Function Loss: 10.24599

Mean KL Divergence: 0.02517
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.10656
Value Function Update Magnitude: 0.10209

Collected Steps per Second: 10,660.25858
Overall Steps per Second: 8,986.10043

Timestep Collection Time: 4.69257
Timestep Consumption Time: 0.87425
PPO Batch Consumption Time: 0.04612
Total Iteration Time: 5.56682

Cumulative Model Updates: 1,115
Cumulative Timesteps: 18,706,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 18706360...
Checkpoint 18706360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.82725
Policy Entropy: 1.23995
Value Function Loss: 10.34832

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.10691
Value Function Update Magnitude: 0.08285

Collected Steps per Second: 10,918.82730
Overall Steps per Second: 9,187.61664

Timestep Collection Time: 4.58254
Timestep Consumption Time: 0.86348
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 5.44603

Cumulative Model Updates: 1,118
Cumulative Timesteps: 18,756,396

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.31566
Policy Entropy: 1.26105
Value Function Loss: 10.40009

Mean KL Divergence: 0.02388
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.11089
Value Function Update Magnitude: 0.07414

Collected Steps per Second: 10,814.83022
Overall Steps per Second: 9,141.85154

Timestep Collection Time: 4.62513
Timestep Consumption Time: 0.84641
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 5.47154

Cumulative Model Updates: 1,121
Cumulative Timesteps: 18,806,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 18806416...
Checkpoint 18806416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.83621
Policy Entropy: 1.24640
Value Function Loss: 10.06996

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.15554
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 10,610.56183
Overall Steps per Second: 9,113.94797

Timestep Collection Time: 4.71266
Timestep Consumption Time: 0.77387
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 5.48654

Cumulative Model Updates: 1,124
Cumulative Timesteps: 18,856,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.03029
Policy Entropy: 1.27161
Value Function Loss: 9.39519

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.16607
Policy Update Magnitude: 0.12940
Value Function Update Magnitude: 0.06122

Collected Steps per Second: 9,408.03445
Overall Steps per Second: 8,141.45468

Timestep Collection Time: 5.31716
Timestep Consumption Time: 0.82720
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 6.14436

Cumulative Model Updates: 1,127
Cumulative Timesteps: 18,906,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 18906444...
Checkpoint 18906444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.91739
Policy Entropy: 1.25809
Value Function Loss: 8.98309

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.12590
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 9,635.54245
Overall Steps per Second: 8,392.31907

Timestep Collection Time: 5.19120
Timestep Consumption Time: 0.76901
PPO Batch Consumption Time: 0.04413
Total Iteration Time: 5.96021

Cumulative Model Updates: 1,130
Cumulative Timesteps: 18,956,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.21161
Policy Entropy: 1.27841
Value Function Loss: 8.80498

Mean KL Divergence: 0.03595
SB3 Clip Fraction: 0.17396
Policy Update Magnitude: 0.11442
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 10,000.67761
Overall Steps per Second: 8,524.36063

Timestep Collection Time: 5.00286
Timestep Consumption Time: 0.86644
PPO Batch Consumption Time: 0.04747
Total Iteration Time: 5.86930

Cumulative Model Updates: 1,133
Cumulative Timesteps: 19,006,496

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 19006496...
Checkpoint 19006496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.43831
Policy Entropy: 1.26238
Value Function Loss: 9.02996

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.10557
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 10,427.55673
Overall Steps per Second: 8,963.86478

Timestep Collection Time: 4.79537
Timestep Consumption Time: 0.78303
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 5.57840

Cumulative Model Updates: 1,136
Cumulative Timesteps: 19,056,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.25852
Policy Entropy: 1.28552
Value Function Loss: 8.71239

Mean KL Divergence: 0.03190
SB3 Clip Fraction: 0.17219
Policy Update Magnitude: 0.10569
Value Function Update Magnitude: 0.07211

Collected Steps per Second: 10,664.95841
Overall Steps per Second: 9,111.39637

Timestep Collection Time: 4.68938
Timestep Consumption Time: 0.79957
PPO Batch Consumption Time: 0.03838
Total Iteration Time: 5.48895

Cumulative Model Updates: 1,139
Cumulative Timesteps: 19,106,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 19106512...
Checkpoint 19106512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.84466
Policy Entropy: 1.27008
Value Function Loss: 9.04869

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.09159
Value Function Update Magnitude: 0.10592

Collected Steps per Second: 10,409.44966
Overall Steps per Second: 8,802.36120

Timestep Collection Time: 4.80563
Timestep Consumption Time: 0.87739
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 5.68302

Cumulative Model Updates: 1,142
Cumulative Timesteps: 19,156,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.48385
Policy Entropy: 1.29277
Value Function Loss: 8.74624

Mean KL Divergence: 0.02772
SB3 Clip Fraction: 0.15809
Policy Update Magnitude: 0.09707
Value Function Update Magnitude: 0.10774

Collected Steps per Second: 11,007.73620
Overall Steps per Second: 9,370.80682

Timestep Collection Time: 4.54444
Timestep Consumption Time: 0.79384
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.33828

Cumulative Model Updates: 1,145
Cumulative Timesteps: 19,206,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 19206560...
Checkpoint 19206560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.47421
Policy Entropy: 1.27525
Value Function Loss: 8.89418

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.15208
Policy Update Magnitude: 0.08674
Value Function Update Magnitude: 0.09502

Collected Steps per Second: 10,648.50580
Overall Steps per Second: 8,976.78767

Timestep Collection Time: 4.69587
Timestep Consumption Time: 0.87450
PPO Batch Consumption Time: 0.04601
Total Iteration Time: 5.57037

Cumulative Model Updates: 1,148
Cumulative Timesteps: 19,256,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.50406
Policy Entropy: 1.29448
Value Function Loss: 8.44899

Mean KL Divergence: 0.02540
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.08846
Value Function Update Magnitude: 0.08730

Collected Steps per Second: 10,481.83226
Overall Steps per Second: 9,059.33041

Timestep Collection Time: 4.77073
Timestep Consumption Time: 0.74910
PPO Batch Consumption Time: 0.04728
Total Iteration Time: 5.51983

Cumulative Model Updates: 1,151
Cumulative Timesteps: 19,306,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 19306570...
Checkpoint 19306570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.55706
Policy Entropy: 1.27429
Value Function Loss: 8.47823

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.15313
Policy Update Magnitude: 0.08602
Value Function Update Magnitude: 0.09221

Collected Steps per Second: 10,697.96589
Overall Steps per Second: 8,986.40391

Timestep Collection Time: 4.67379
Timestep Consumption Time: 0.89018
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 5.56396

Cumulative Model Updates: 1,154
Cumulative Timesteps: 19,356,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.82966
Policy Entropy: 1.29446
Value Function Loss: 8.59130

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.08837
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 10,345.34295
Overall Steps per Second: 8,768.40070

Timestep Collection Time: 4.83425
Timestep Consumption Time: 0.86941
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 5.70366

Cumulative Model Updates: 1,157
Cumulative Timesteps: 19,406,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 19406582...
Checkpoint 19406582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127.32376
Policy Entropy: 1.27975
Value Function Loss: 8.59275

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.08115
Value Function Update Magnitude: 0.08052

Collected Steps per Second: 10,629.58725
Overall Steps per Second: 9,000.68809

Timestep Collection Time: 4.70592
Timestep Consumption Time: 0.85165
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 5.55758

Cumulative Model Updates: 1,160
Cumulative Timesteps: 19,456,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.57199
Policy Entropy: 1.30183
Value Function Loss: 8.74078

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.09318
Value Function Update Magnitude: 0.10859

Collected Steps per Second: 10,666.63595
Overall Steps per Second: 8,994.99100

Timestep Collection Time: 4.68770
Timestep Consumption Time: 0.87117
PPO Batch Consumption Time: 0.04588
Total Iteration Time: 5.55887

Cumulative Model Updates: 1,163
Cumulative Timesteps: 19,506,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 19506606...
Checkpoint 19506606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.91872
Policy Entropy: 1.28187
Value Function Loss: 8.42240

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.08689
Value Function Update Magnitude: 0.13661

Collected Steps per Second: 10,742.57964
Overall Steps per Second: 9,153.14902

Timestep Collection Time: 4.65475
Timestep Consumption Time: 0.80829
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 5.46304

Cumulative Model Updates: 1,166
Cumulative Timesteps: 19,556,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.40294
Policy Entropy: 1.30068
Value Function Loss: 8.19004

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.08841
Value Function Update Magnitude: 0.16211

Collected Steps per Second: 10,751.13735
Overall Steps per Second: 9,152.43571

Timestep Collection Time: 4.65309
Timestep Consumption Time: 0.81278
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 5.46587

Cumulative Model Updates: 1,169
Cumulative Timesteps: 19,606,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 19606636...
Checkpoint 19606636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.08692
Policy Entropy: 1.27704
Value Function Loss: 8.05367

Mean KL Divergence: 0.02347
SB3 Clip Fraction: 0.15543
Policy Update Magnitude: 0.08721
Value Function Update Magnitude: 0.17270

Collected Steps per Second: 10,326.07203
Overall Steps per Second: 8,870.32961

Timestep Collection Time: 4.84289
Timestep Consumption Time: 0.79478
PPO Batch Consumption Time: 0.04581
Total Iteration Time: 5.63767

Cumulative Model Updates: 1,172
Cumulative Timesteps: 19,656,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.77737
Policy Entropy: 1.29556
Value Function Loss: 8.09859

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.08458
Value Function Update Magnitude: 0.16294

Collected Steps per Second: 10,370.36567
Overall Steps per Second: 8,776.60848

Timestep Collection Time: 4.82259
Timestep Consumption Time: 0.87574
PPO Batch Consumption Time: 0.04635
Total Iteration Time: 5.69833

Cumulative Model Updates: 1,175
Cumulative Timesteps: 19,706,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 19706656...
Checkpoint 19706656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.74314
Policy Entropy: 1.27195
Value Function Loss: 7.96535

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.15516
Policy Update Magnitude: 0.08501
Value Function Update Magnitude: 0.16754

Collected Steps per Second: 10,849.15889
Overall Steps per Second: 9,182.48295

Timestep Collection Time: 4.61105
Timestep Consumption Time: 0.83693
PPO Batch Consumption Time: 0.04602
Total Iteration Time: 5.44798

Cumulative Model Updates: 1,178
Cumulative Timesteps: 19,756,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.54157
Policy Entropy: 1.29511
Value Function Loss: 7.80305

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.08920
Value Function Update Magnitude: 0.16565

Collected Steps per Second: 10,790.38642
Overall Steps per Second: 9,145.76151

Timestep Collection Time: 4.63394
Timestep Consumption Time: 0.83329
PPO Batch Consumption Time: 0.04135
Total Iteration Time: 5.46723

Cumulative Model Updates: 1,181
Cumulative Timesteps: 19,806,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 19806684...
Checkpoint 19806684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.65789
Policy Entropy: 1.27459
Value Function Loss: 7.72942

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.15408
Policy Update Magnitude: 0.08182
Value Function Update Magnitude: 0.16439

Collected Steps per Second: 10,691.42452
Overall Steps per Second: 9,102.16100

Timestep Collection Time: 4.67926
Timestep Consumption Time: 0.81701
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 5.49628

Cumulative Model Updates: 1,184
Cumulative Timesteps: 19,856,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.30039
Policy Entropy: 1.29336
Value Function Loss: 7.87607

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.08278
Value Function Update Magnitude: 0.15774

Collected Steps per Second: 10,676.13152
Overall Steps per Second: 9,157.81764

Timestep Collection Time: 4.68540
Timestep Consumption Time: 0.77681
PPO Batch Consumption Time: 0.04683
Total Iteration Time: 5.46222

Cumulative Model Updates: 1,187
Cumulative Timesteps: 19,906,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 19906734...
Checkpoint 19906734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.88151
Policy Entropy: 1.27343
Value Function Loss: 7.95613

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.15382
Policy Update Magnitude: 0.08199
Value Function Update Magnitude: 0.14195

Collected Steps per Second: 10,165.79331
Overall Steps per Second: 8,648.16487

Timestep Collection Time: 4.91846
Timestep Consumption Time: 0.86312
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 5.78157

Cumulative Model Updates: 1,190
Cumulative Timesteps: 19,956,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.83153
Policy Entropy: 1.29095
Value Function Loss: 7.85158

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.08479
Value Function Update Magnitude: 0.13025

Collected Steps per Second: 10,558.57037
Overall Steps per Second: 9,077.27170

Timestep Collection Time: 4.73663
Timestep Consumption Time: 0.77296
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 5.50959

Cumulative Model Updates: 1,193
Cumulative Timesteps: 20,006,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 20006746...
Checkpoint 20006746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.66972
Policy Entropy: 1.27010
Value Function Loss: 7.48175

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.15907
Policy Update Magnitude: 0.08474
Value Function Update Magnitude: 0.12695

Collected Steps per Second: 10,830.73040
Overall Steps per Second: 9,088.86120

Timestep Collection Time: 4.61889
Timestep Consumption Time: 0.88521
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 5.50410

Cumulative Model Updates: 1,196
Cumulative Timesteps: 20,056,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.50569
Policy Entropy: 1.28388
Value Function Loss: 7.29521

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.08126
Value Function Update Magnitude: 0.10141

Collected Steps per Second: 10,469.41689
Overall Steps per Second: 8,947.37086

Timestep Collection Time: 4.77601
Timestep Consumption Time: 0.81245
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.58846

Cumulative Model Updates: 1,199
Cumulative Timesteps: 20,106,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 20106774...
Checkpoint 20106774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.65127
Policy Entropy: 1.26085
Value Function Loss: 7.18548

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.15767
Policy Update Magnitude: 0.08151
Value Function Update Magnitude: 0.08504

Collected Steps per Second: 10,341.45969
Overall Steps per Second: 8,837.89931

Timestep Collection Time: 4.83510
Timestep Consumption Time: 0.82258
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 5.65768

Cumulative Model Updates: 1,202
Cumulative Timesteps: 20,156,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.08697
Policy Entropy: 1.28190
Value Function Loss: 7.28333

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.15014
Policy Update Magnitude: 0.08312
Value Function Update Magnitude: 0.07263

Collected Steps per Second: 10,518.40446
Overall Steps per Second: 8,841.76112

Timestep Collection Time: 4.75414
Timestep Consumption Time: 0.90152
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 5.65566

Cumulative Model Updates: 1,205
Cumulative Timesteps: 20,206,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 20206782...
Checkpoint 20206782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.00606
Policy Entropy: 1.26483
Value Function Loss: 7.40983

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.08186
Value Function Update Magnitude: 0.06803

Collected Steps per Second: 10,557.11430
Overall Steps per Second: 9,116.00432

Timestep Collection Time: 4.73898
Timestep Consumption Time: 0.74917
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.48815

Cumulative Model Updates: 1,208
Cumulative Timesteps: 20,256,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.63322
Policy Entropy: 1.28321
Value Function Loss: 7.38423

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.08374
Value Function Update Magnitude: 0.05826

Collected Steps per Second: 10,578.94100
Overall Steps per Second: 8,893.65781

Timestep Collection Time: 4.72807
Timestep Consumption Time: 0.89594
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 5.62401

Cumulative Model Updates: 1,211
Cumulative Timesteps: 20,306,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 20306830...
Checkpoint 20306830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.54263
Policy Entropy: 1.26378
Value Function Loss: 7.58458

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.16265
Policy Update Magnitude: 0.08111
Value Function Update Magnitude: 0.07266

Collected Steps per Second: 10,347.26212
Overall Steps per Second: 8,815.31087

Timestep Collection Time: 4.83587
Timestep Consumption Time: 0.84039
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 5.67626

Cumulative Model Updates: 1,214
Cumulative Timesteps: 20,356,868

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.64095
Policy Entropy: 1.27527
Value Function Loss: 7.71990

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.08048
Value Function Update Magnitude: 0.06273

Collected Steps per Second: 10,835.05185
Overall Steps per Second: 9,089.36179

Timestep Collection Time: 4.61576
Timestep Consumption Time: 0.88650
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 5.50226

Cumulative Model Updates: 1,217
Cumulative Timesteps: 20,406,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 20406880...
Checkpoint 20406880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.79848
Policy Entropy: 1.26196
Value Function Loss: 7.82032

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.15335
Policy Update Magnitude: 0.08049
Value Function Update Magnitude: 0.05556

Collected Steps per Second: 10,530.92324
Overall Steps per Second: 8,813.11181

Timestep Collection Time: 4.74906
Timestep Consumption Time: 0.92567
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 5.67473

Cumulative Model Updates: 1,220
Cumulative Timesteps: 20,456,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.43031
Policy Entropy: 1.27990
Value Function Loss: 7.61684

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.07228
Value Function Update Magnitude: 0.05941

Collected Steps per Second: 9,892.92806
Overall Steps per Second: 8,425.23616

Timestep Collection Time: 5.05695
Timestep Consumption Time: 0.88093
PPO Batch Consumption Time: 0.04631
Total Iteration Time: 5.93788

Cumulative Model Updates: 1,223
Cumulative Timesteps: 20,506,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 20506920...
Checkpoint 20506920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.30123
Policy Entropy: 1.26644
Value Function Loss: 7.46592

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.08070
Value Function Update Magnitude: 0.05222

Collected Steps per Second: 10,516.30648
Overall Steps per Second: 8,860.37738

Timestep Collection Time: 4.75452
Timestep Consumption Time: 0.88858
PPO Batch Consumption Time: 0.03915
Total Iteration Time: 5.64310

Cumulative Model Updates: 1,226
Cumulative Timesteps: 20,556,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.54844
Policy Entropy: 1.28079
Value Function Loss: 7.45270

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.14599
Policy Update Magnitude: 0.07968
Value Function Update Magnitude: 0.05529

Collected Steps per Second: 10,392.07993
Overall Steps per Second: 8,947.37766

Timestep Collection Time: 4.81251
Timestep Consumption Time: 0.77706
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 5.58957

Cumulative Model Updates: 1,229
Cumulative Timesteps: 20,606,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 20606932...
Checkpoint 20606932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.14355
Policy Entropy: 1.25620
Value Function Loss: 7.66008

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.07731
Value Function Update Magnitude: 0.05221

Collected Steps per Second: 10,505.60051
Overall Steps per Second: 8,906.42898

Timestep Collection Time: 4.76013
Timestep Consumption Time: 0.85469
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 5.61482

Cumulative Model Updates: 1,232
Cumulative Timesteps: 20,656,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.53808
Policy Entropy: 1.27663
Value Function Loss: 7.50503

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.09538
Value Function Update Magnitude: 0.04782

Collected Steps per Second: 10,595.89627
Overall Steps per Second: 9,001.86203

Timestep Collection Time: 4.71956
Timestep Consumption Time: 0.83573
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 5.55530

Cumulative Model Updates: 1,235
Cumulative Timesteps: 20,706,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 20706948...
Checkpoint 20706948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.21663
Policy Entropy: 1.25957
Value Function Loss: 7.56972

Mean KL Divergence: 0.02375
SB3 Clip Fraction: 0.16070
Policy Update Magnitude: 0.08525
Value Function Update Magnitude: 0.06129

Collected Steps per Second: 10,428.18715
Overall Steps per Second: 8,781.35670

Timestep Collection Time: 4.79508
Timestep Consumption Time: 0.89926
PPO Batch Consumption Time: 0.04617
Total Iteration Time: 5.69434

Cumulative Model Updates: 1,238
Cumulative Timesteps: 20,756,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.13395
Policy Entropy: 1.27642
Value Function Loss: 7.34447

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.08375
Value Function Update Magnitude: 0.06940

Collected Steps per Second: 10,644.42269
Overall Steps per Second: 9,016.03271

Timestep Collection Time: 4.69993
Timestep Consumption Time: 0.84886
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 5.54878

Cumulative Model Updates: 1,241
Cumulative Timesteps: 20,806,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 20806980...
Checkpoint 20806980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.12954
Policy Entropy: 1.25938
Value Function Loss: 7.25881

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.15879
Policy Update Magnitude: 0.08477
Value Function Update Magnitude: 0.06018

Collected Steps per Second: 10,704.87878
Overall Steps per Second: 9,123.10964

Timestep Collection Time: 4.67133
Timestep Consumption Time: 0.80992
PPO Batch Consumption Time: 0.04575
Total Iteration Time: 5.48125

Cumulative Model Updates: 1,244
Cumulative Timesteps: 20,856,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.58317
Policy Entropy: 1.27816
Value Function Loss: 6.93678

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.08159
Value Function Update Magnitude: 0.05639

Collected Steps per Second: 10,697.88302
Overall Steps per Second: 9,081.89585

Timestep Collection Time: 4.67663
Timestep Consumption Time: 0.83214
PPO Batch Consumption Time: 0.04046
Total Iteration Time: 5.50876

Cumulative Model Updates: 1,247
Cumulative Timesteps: 20,907,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 20907016...
Checkpoint 20907016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.88866
Policy Entropy: 1.26655
Value Function Loss: 7.08184

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.08301
Value Function Update Magnitude: 0.05235

Collected Steps per Second: 10,429.31904
Overall Steps per Second: 8,761.87741

Timestep Collection Time: 4.79744
Timestep Consumption Time: 0.91298
PPO Batch Consumption Time: 0.04271
Total Iteration Time: 5.71042

Cumulative Model Updates: 1,250
Cumulative Timesteps: 20,957,050

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.62278
Policy Entropy: 1.28053
Value Function Loss: 6.92134

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.07852
Value Function Update Magnitude: 0.05108

Collected Steps per Second: 10,512.37766
Overall Steps per Second: 8,888.14526

Timestep Collection Time: 4.75915
Timestep Consumption Time: 0.86969
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.62885

Cumulative Model Updates: 1,253
Cumulative Timesteps: 21,007,080

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 21007080...
Checkpoint 21007080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.51517
Policy Entropy: 1.26002
Value Function Loss: 7.00628

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.14805
Policy Update Magnitude: 0.07558
Value Function Update Magnitude: 0.05290

Collected Steps per Second: 10,268.63020
Overall Steps per Second: 8,708.78810

Timestep Collection Time: 4.87115
Timestep Consumption Time: 0.87248
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.74362

Cumulative Model Updates: 1,256
Cumulative Timesteps: 21,057,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.59212
Policy Entropy: 1.27368
Value Function Loss: 6.79584

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.07620
Value Function Update Magnitude: 0.04967

Collected Steps per Second: 10,028.84169
Overall Steps per Second: 8,654.35955

Timestep Collection Time: 4.98781
Timestep Consumption Time: 0.79216
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 5.77998

Cumulative Model Updates: 1,259
Cumulative Timesteps: 21,107,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 21107122...
Checkpoint 21107122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.54532
Policy Entropy: 1.25646
Value Function Loss: 7.18465

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.06759
Value Function Update Magnitude: 0.05199

Collected Steps per Second: 10,589.93578
Overall Steps per Second: 8,904.18601

Timestep Collection Time: 4.72260
Timestep Consumption Time: 0.89409
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 5.61668

Cumulative Model Updates: 1,262
Cumulative Timesteps: 21,157,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.28833
Policy Entropy: 1.27781
Value Function Loss: 7.01984

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.07824
Value Function Update Magnitude: 0.05053

Collected Steps per Second: 10,297.03805
Overall Steps per Second: 8,724.00812

Timestep Collection Time: 4.85771
Timestep Consumption Time: 0.87590
PPO Batch Consumption Time: 0.04473
Total Iteration Time: 5.73360

Cumulative Model Updates: 1,265
Cumulative Timesteps: 21,207,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 21207154...
Checkpoint 21207154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130.60589
Policy Entropy: 1.26470
Value Function Loss: 6.99743

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.06776
Value Function Update Magnitude: 0.05752

Collected Steps per Second: 10,613.57123
Overall Steps per Second: 8,990.14594

Timestep Collection Time: 4.71302
Timestep Consumption Time: 0.85107
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 5.56409

Cumulative Model Updates: 1,268
Cumulative Timesteps: 21,257,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.04167
Policy Entropy: 1.28310
Value Function Loss: 6.49368

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.08037
Value Function Update Magnitude: 0.05402

Collected Steps per Second: 9,970.32806
Overall Steps per Second: 8,595.19814

Timestep Collection Time: 5.01588
Timestep Consumption Time: 0.80248
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 5.81836

Cumulative Model Updates: 1,271
Cumulative Timesteps: 21,307,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 21307186...
Checkpoint 21307186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.05596
Policy Entropy: 1.26563
Value Function Loss: 6.57493

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.08008
Value Function Update Magnitude: 0.05246

Collected Steps per Second: 10,649.99655
Overall Steps per Second: 9,198.44172

Timestep Collection Time: 4.69484
Timestep Consumption Time: 0.74087
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 5.43570

Cumulative Model Updates: 1,274
Cumulative Timesteps: 21,357,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.16022
Policy Entropy: 1.27703
Value Function Loss: 6.65829

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.07743
Value Function Update Magnitude: 0.04816

Collected Steps per Second: 10,228.16662
Overall Steps per Second: 8,673.82199

Timestep Collection Time: 4.88885
Timestep Consumption Time: 0.87608
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 5.76493

Cumulative Model Updates: 1,277
Cumulative Timesteps: 21,407,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 21407190...
Checkpoint 21407190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.47574
Policy Entropy: 1.26513
Value Function Loss: 6.80781

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.06909
Value Function Update Magnitude: 0.04938

Collected Steps per Second: 10,574.49707
Overall Steps per Second: 9,009.40114

Timestep Collection Time: 4.72911
Timestep Consumption Time: 0.82153
PPO Batch Consumption Time: 0.04545
Total Iteration Time: 5.55065

Cumulative Model Updates: 1,280
Cumulative Timesteps: 21,457,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.10980
Policy Entropy: 1.27360
Value Function Loss: 7.02752

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.07854
Value Function Update Magnitude: 0.05142

Collected Steps per Second: 10,871.64138
Overall Steps per Second: 9,155.54147

Timestep Collection Time: 4.59931
Timestep Consumption Time: 0.86209
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 5.46139

Cumulative Model Updates: 1,283
Cumulative Timesteps: 21,507,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21507200...
Checkpoint 21507200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.54834
Policy Entropy: 1.25736
Value Function Loss: 7.16551

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.05377

Collected Steps per Second: 10,162.53246
Overall Steps per Second: 8,512.32386

Timestep Collection Time: 4.92200
Timestep Consumption Time: 0.95418
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 5.87619

Cumulative Model Updates: 1,286
Cumulative Timesteps: 21,557,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.76970
Policy Entropy: 1.26730
Value Function Loss: 7.12645

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.08444
Value Function Update Magnitude: 0.05211

Collected Steps per Second: 10,293.43535
Overall Steps per Second: 8,797.40937

Timestep Collection Time: 4.85921
Timestep Consumption Time: 0.82632
PPO Batch Consumption Time: 0.04683
Total Iteration Time: 5.68554

Cumulative Model Updates: 1,289
Cumulative Timesteps: 21,607,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 21607238...
Checkpoint 21607238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.33689
Policy Entropy: 1.25020
Value Function Loss: 7.14318

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.14927
Policy Update Magnitude: 0.07774
Value Function Update Magnitude: 0.08038

Collected Steps per Second: 10,109.76098
Overall Steps per Second: 8,589.24928

Timestep Collection Time: 4.94888
Timestep Consumption Time: 0.87608
PPO Batch Consumption Time: 0.04742
Total Iteration Time: 5.82496

Cumulative Model Updates: 1,292
Cumulative Timesteps: 21,657,270

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.30495
Policy Entropy: 1.26599
Value Function Loss: 7.11636

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.08960

Collected Steps per Second: 10,593.29167
Overall Steps per Second: 9,014.14814

Timestep Collection Time: 4.72242
Timestep Consumption Time: 0.82730
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 5.54972

Cumulative Model Updates: 1,295
Cumulative Timesteps: 21,707,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 21707296...
Checkpoint 21707296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.88187
Policy Entropy: 1.25356
Value Function Loss: 7.15127

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.16209
Policy Update Magnitude: 0.06675
Value Function Update Magnitude: 0.07773

Collected Steps per Second: 10,788.08161
Overall Steps per Second: 9,144.17127

Timestep Collection Time: 4.63697
Timestep Consumption Time: 0.83362
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 5.47059

Cumulative Model Updates: 1,298
Cumulative Timesteps: 21,757,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.94706
Policy Entropy: 1.27420
Value Function Loss: 7.22139

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 10,404.88420
Overall Steps per Second: 8,874.43237

Timestep Collection Time: 4.80755
Timestep Consumption Time: 0.82909
PPO Batch Consumption Time: 0.04587
Total Iteration Time: 5.63664

Cumulative Model Updates: 1,301
Cumulative Timesteps: 21,807,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 21807342...
Checkpoint 21807342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.87683
Policy Entropy: 1.26767
Value Function Loss: 6.87789

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.06441
Value Function Update Magnitude: 0.07144

Collected Steps per Second: 10,668.43376
Overall Steps per Second: 9,136.20692

Timestep Collection Time: 4.68897
Timestep Consumption Time: 0.78638
PPO Batch Consumption Time: 0.04582
Total Iteration Time: 5.47536

Cumulative Model Updates: 1,304
Cumulative Timesteps: 21,857,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.12807
Policy Entropy: 1.28162
Value Function Loss: 6.84683

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.09790

Collected Steps per Second: 10,820.39469
Overall Steps per Second: 9,090.86050

Timestep Collection Time: 4.62127
Timestep Consumption Time: 0.87920
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 5.50047

Cumulative Model Updates: 1,307
Cumulative Timesteps: 21,907,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 21907370...
Checkpoint 21907370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.40966
Policy Entropy: 1.26737
Value Function Loss: 6.53605

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.14517
Policy Update Magnitude: 0.06879
Value Function Update Magnitude: 0.09232

Collected Steps per Second: 10,340.48270
Overall Steps per Second: 8,805.80055

Timestep Collection Time: 4.83652
Timestep Consumption Time: 0.84291
PPO Batch Consumption Time: 0.04625
Total Iteration Time: 5.67944

Cumulative Model Updates: 1,310
Cumulative Timesteps: 21,957,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.63131
Policy Entropy: 1.27760
Value Function Loss: 6.79308

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.07118
Value Function Update Magnitude: 0.08972

Collected Steps per Second: 10,830.04631
Overall Steps per Second: 9,129.61595

Timestep Collection Time: 4.61697
Timestep Consumption Time: 0.85993
PPO Batch Consumption Time: 0.03963
Total Iteration Time: 5.47690

Cumulative Model Updates: 1,313
Cumulative Timesteps: 22,007,384

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22007384...
Checkpoint 22007384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.15928
Policy Entropy: 1.26121
Value Function Loss: 6.85564

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.08855

Collected Steps per Second: 10,456.69856
Overall Steps per Second: 8,868.21400

Timestep Collection Time: 4.78449
Timestep Consumption Time: 0.85700
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 5.64150

Cumulative Model Updates: 1,316
Cumulative Timesteps: 22,057,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.01376
Policy Entropy: 1.27861
Value Function Loss: 6.96311

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.07446
Value Function Update Magnitude: 0.07918

Collected Steps per Second: 10,046.62605
Overall Steps per Second: 8,588.48214

Timestep Collection Time: 4.97799
Timestep Consumption Time: 0.84516
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 5.82315

Cumulative Model Updates: 1,319
Cumulative Timesteps: 22,107,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 22107426...
Checkpoint 22107426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.00497
Policy Entropy: 1.26271
Value Function Loss: 6.87222

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.07511
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 10,734.81221
Overall Steps per Second: 9,054.77649

Timestep Collection Time: 4.65905
Timestep Consumption Time: 0.86445
PPO Batch Consumption Time: 0.04416
Total Iteration Time: 5.52349

Cumulative Model Updates: 1,322
Cumulative Timesteps: 22,157,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.43107
Policy Entropy: 1.27741
Value Function Loss: 6.82768

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.07486
Value Function Update Magnitude: 0.06289

Collected Steps per Second: 10,763.52123
Overall Steps per Second: 9,123.16835

Timestep Collection Time: 4.64736
Timestep Consumption Time: 0.83560
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.48296

Cumulative Model Updates: 1,325
Cumulative Timesteps: 22,207,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 22207462...
Checkpoint 22207462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.04148
Policy Entropy: 1.25831
Value Function Loss: 6.74864

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.07271
Value Function Update Magnitude: 0.06832

Collected Steps per Second: 10,465.65663
Overall Steps per Second: 8,970.66909

Timestep Collection Time: 4.77810
Timestep Consumption Time: 0.79628
PPO Batch Consumption Time: 0.04504
Total Iteration Time: 5.57439

Cumulative Model Updates: 1,328
Cumulative Timesteps: 22,257,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.74922
Policy Entropy: 1.26875
Value Function Loss: 6.68412

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.08797
Value Function Update Magnitude: 0.07365

Collected Steps per Second: 10,225.40258
Overall Steps per Second: 8,636.90793

Timestep Collection Time: 4.89272
Timestep Consumption Time: 0.89987
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.79258

Cumulative Model Updates: 1,331
Cumulative Timesteps: 22,307,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 22307498...
Checkpoint 22307498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.26687
Policy Entropy: 1.25409
Value Function Loss: 6.50682

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.16263
Policy Update Magnitude: 0.07836
Value Function Update Magnitude: 0.05145

Collected Steps per Second: 10,074.19572
Overall Steps per Second: 8,774.23776

Timestep Collection Time: 4.96417
Timestep Consumption Time: 0.73547
PPO Batch Consumption Time: 0.03800
Total Iteration Time: 5.69964

Cumulative Model Updates: 1,334
Cumulative Timesteps: 22,357,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.76794
Policy Entropy: 1.26956
Value Function Loss: 6.66304

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.06899
Value Function Update Magnitude: 0.05906

Collected Steps per Second: 10,736.06034
Overall Steps per Second: 9,066.58161

Timestep Collection Time: 4.65944
Timestep Consumption Time: 0.85797
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.51740

Cumulative Model Updates: 1,337
Cumulative Timesteps: 22,407,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 22407532...
Checkpoint 22407532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.73159
Policy Entropy: 1.25832
Value Function Loss: 6.87812

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.15429
Policy Update Magnitude: 0.07714
Value Function Update Magnitude: 0.05829

Collected Steps per Second: 10,482.77649
Overall Steps per Second: 8,935.64626

Timestep Collection Time: 4.76992
Timestep Consumption Time: 0.82587
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.59579

Cumulative Model Updates: 1,340
Cumulative Timesteps: 22,457,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.33450
Policy Entropy: 1.27493
Value Function Loss: 6.63480

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.08215
Value Function Update Magnitude: 0.05070

Collected Steps per Second: 10,361.07901
Overall Steps per Second: 8,909.09303

Timestep Collection Time: 4.82884
Timestep Consumption Time: 0.78699
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 5.61584

Cumulative Model Updates: 1,343
Cumulative Timesteps: 22,507,566

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 22507566...
Checkpoint 22507566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.03283
Policy Entropy: 1.25678
Value Function Loss: 6.61099

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.07615
Value Function Update Magnitude: 0.06400

Collected Steps per Second: 10,489.90776
Overall Steps per Second: 8,840.82144

Timestep Collection Time: 4.76763
Timestep Consumption Time: 0.88931
PPO Batch Consumption Time: 0.04595
Total Iteration Time: 5.65694

Cumulative Model Updates: 1,346
Cumulative Timesteps: 22,557,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.03886
Policy Entropy: 1.26529
Value Function Loss: 6.51606

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.07674
Value Function Update Magnitude: 0.08472

Collected Steps per Second: 10,446.31531
Overall Steps per Second: 9,038.21928

Timestep Collection Time: 4.78714
Timestep Consumption Time: 0.74581
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 5.53295

Cumulative Model Updates: 1,349
Cumulative Timesteps: 22,607,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 22607586...
Checkpoint 22607586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.58092
Policy Entropy: 1.24506
Value Function Loss: 6.67587

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.14718
Policy Update Magnitude: 0.07036
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 10,528.52004
Overall Steps per Second: 8,900.02208

Timestep Collection Time: 4.75015
Timestep Consumption Time: 0.86917
PPO Batch Consumption Time: 0.03912
Total Iteration Time: 5.61931

Cumulative Model Updates: 1,352
Cumulative Timesteps: 22,657,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.86871
Policy Entropy: 1.26063
Value Function Loss: 6.59177

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.11729

Collected Steps per Second: 10,605.06506
Overall Steps per Second: 8,964.66443

Timestep Collection Time: 4.71586
Timestep Consumption Time: 0.86293
PPO Batch Consumption Time: 0.04018
Total Iteration Time: 5.57879

Cumulative Model Updates: 1,355
Cumulative Timesteps: 22,707,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 22707610...
Checkpoint 22707610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.65633
Policy Entropy: 1.24570
Value Function Loss: 6.76255

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.06861
Value Function Update Magnitude: 0.10021

Collected Steps per Second: 10,612.17237
Overall Steps per Second: 8,869.41521

Timestep Collection Time: 4.71289
Timestep Consumption Time: 0.92604
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 5.63893

Cumulative Model Updates: 1,358
Cumulative Timesteps: 22,757,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.72952
Policy Entropy: 1.26339
Value Function Loss: 6.62328

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.07093
Value Function Update Magnitude: 0.09107

Collected Steps per Second: 10,992.26730
Overall Steps per Second: 9,228.44212

Timestep Collection Time: 4.54974
Timestep Consumption Time: 0.86959
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 5.41933

Cumulative Model Updates: 1,361
Cumulative Timesteps: 22,807,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 22807636...
Checkpoint 22807636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.00462
Policy Entropy: 1.25137
Value Function Loss: 6.73811

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.06757
Value Function Update Magnitude: 0.08170

Collected Steps per Second: 10,924.00781
Overall Steps per Second: 9,325.97449

Timestep Collection Time: 4.57836
Timestep Consumption Time: 0.78451
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.36287

Cumulative Model Updates: 1,364
Cumulative Timesteps: 22,857,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.79203
Policy Entropy: 1.26509
Value Function Loss: 6.73859

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.07115
Value Function Update Magnitude: 0.07315

Collected Steps per Second: 10,433.90217
Overall Steps per Second: 8,885.07549

Timestep Collection Time: 4.79207
Timestep Consumption Time: 0.83534
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 5.62741

Cumulative Model Updates: 1,367
Cumulative Timesteps: 22,907,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 22907650...
Checkpoint 22907650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.78564
Policy Entropy: 1.25061
Value Function Loss: 6.82147

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.07225
Value Function Update Magnitude: 0.05756

Collected Steps per Second: 10,880.82379
Overall Steps per Second: 9,227.29315

Timestep Collection Time: 4.59708
Timestep Consumption Time: 0.82380
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 5.42087

Cumulative Model Updates: 1,370
Cumulative Timesteps: 22,957,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.51062
Policy Entropy: 1.25906
Value Function Loss: 6.70276

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.11672
Policy Update Magnitude: 0.07782
Value Function Update Magnitude: 0.05040

Collected Steps per Second: 11,008.21567
Overall Steps per Second: 9,088.36421

Timestep Collection Time: 4.54388
Timestep Consumption Time: 0.95986
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 5.50374

Cumulative Model Updates: 1,373
Cumulative Timesteps: 23,007,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 23007690...
Checkpoint 23007690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.28204
Policy Entropy: 1.24805
Value Function Loss: 6.70713

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.15354
Policy Update Magnitude: 0.07690
Value Function Update Magnitude: 0.05322

Collected Steps per Second: 10,925.32400
Overall Steps per Second: 9,195.95870

Timestep Collection Time: 4.57799
Timestep Consumption Time: 0.86092
PPO Batch Consumption Time: 0.04357
Total Iteration Time: 5.43891

Cumulative Model Updates: 1,376
Cumulative Timesteps: 23,057,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.01264
Policy Entropy: 1.26133
Value Function Loss: 6.53809

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.07437
Value Function Update Magnitude: 0.04923

Collected Steps per Second: 10,433.07131
Overall Steps per Second: 9,018.26030

Timestep Collection Time: 4.79514
Timestep Consumption Time: 0.75228
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 5.54741

Cumulative Model Updates: 1,379
Cumulative Timesteps: 23,107,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 23107734...
Checkpoint 23107734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.61176
Policy Entropy: 1.24941
Value Function Loss: 6.63083

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.06679
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 9,965.18877
Overall Steps per Second: 8,411.26683

Timestep Collection Time: 5.01987
Timestep Consumption Time: 0.92739
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 5.94726

Cumulative Model Updates: 1,382
Cumulative Timesteps: 23,157,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.36882
Policy Entropy: 1.25546
Value Function Loss: 6.68540

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.07034
Value Function Update Magnitude: 0.04734

Collected Steps per Second: 10,354.04065
Overall Steps per Second: 8,784.42671

Timestep Collection Time: 4.82961
Timestep Consumption Time: 0.86296
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 5.69257

Cumulative Model Updates: 1,385
Cumulative Timesteps: 23,207,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 23207764...
Checkpoint 23207764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.76649
Policy Entropy: 1.23545
Value Function Loss: 6.91799

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.06629
Value Function Update Magnitude: 0.04470

Collected Steps per Second: 11,093.60686
Overall Steps per Second: 9,360.17482

Timestep Collection Time: 4.50944
Timestep Consumption Time: 0.83511
PPO Batch Consumption Time: 0.04028
Total Iteration Time: 5.34456

Cumulative Model Updates: 1,388
Cumulative Timesteps: 23,257,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.74302
Policy Entropy: 1.24839
Value Function Loss: 7.02127

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.07529
Value Function Update Magnitude: 0.04291

Collected Steps per Second: 10,411.16289
Overall Steps per Second: 8,916.37951

Timestep Collection Time: 4.80484
Timestep Consumption Time: 0.80551
PPO Batch Consumption Time: 0.04027
Total Iteration Time: 5.61035

Cumulative Model Updates: 1,391
Cumulative Timesteps: 23,307,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 23307814...
Checkpoint 23307814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.60978
Policy Entropy: 1.23864
Value Function Loss: 7.01924

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.15726
Policy Update Magnitude: 0.07247
Value Function Update Magnitude: 0.04173

Collected Steps per Second: 10,516.13300
Overall Steps per Second: 9,079.54390

Timestep Collection Time: 4.75498
Timestep Consumption Time: 0.75235
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 5.50733

Cumulative Model Updates: 1,394
Cumulative Timesteps: 23,357,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.80354
Policy Entropy: 1.26127
Value Function Loss: 6.81859

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.04382

Collected Steps per Second: 10,430.11873
Overall Steps per Second: 8,720.50769

Timestep Collection Time: 4.79496
Timestep Consumption Time: 0.94003
PPO Batch Consumption Time: 0.04085
Total Iteration Time: 5.73499

Cumulative Model Updates: 1,397
Cumulative Timesteps: 23,407,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 23407830...
Checkpoint 23407830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.98568
Policy Entropy: 1.25088
Value Function Loss: 6.64385

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.07237
Value Function Update Magnitude: 0.04139

Collected Steps per Second: 10,301.91702
Overall Steps per Second: 8,721.06003

Timestep Collection Time: 4.85541
Timestep Consumption Time: 0.88013
PPO Batch Consumption Time: 0.04677
Total Iteration Time: 5.73554

Cumulative Model Updates: 1,400
Cumulative Timesteps: 23,457,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.53967
Policy Entropy: 1.26194
Value Function Loss: 6.61509

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.07349
Value Function Update Magnitude: 0.03668

Collected Steps per Second: 10,619.37708
Overall Steps per Second: 9,063.87337

Timestep Collection Time: 4.70837
Timestep Consumption Time: 0.80803
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 5.51641

Cumulative Model Updates: 1,403
Cumulative Timesteps: 23,507,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 23507850...
Checkpoint 23507850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.48678
Policy Entropy: 1.24615
Value Function Loss: 6.69064

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.04042

Collected Steps per Second: 10,251.60639
Overall Steps per Second: 8,737.48573

Timestep Collection Time: 4.87748
Timestep Consumption Time: 0.84522
PPO Batch Consumption Time: 0.04873
Total Iteration Time: 5.72270

Cumulative Model Updates: 1,406
Cumulative Timesteps: 23,557,852

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.95116
Policy Entropy: 1.26022
Value Function Loss: 6.81387

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.07867
Value Function Update Magnitude: 0.04021

Collected Steps per Second: 10,689.75600
Overall Steps per Second: 9,195.53671

Timestep Collection Time: 4.67868
Timestep Consumption Time: 0.76026
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.43894

Cumulative Model Updates: 1,409
Cumulative Timesteps: 23,607,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 23607866...
Checkpoint 23607866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.22109
Policy Entropy: 1.24574
Value Function Loss: 6.92248

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.06814
Value Function Update Magnitude: 0.03761

Collected Steps per Second: 10,531.15530
Overall Steps per Second: 8,902.37237

Timestep Collection Time: 4.74972
Timestep Consumption Time: 0.86901
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 5.61873

Cumulative Model Updates: 1,412
Cumulative Timesteps: 23,657,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.60996
Policy Entropy: 1.26295
Value Function Loss: 6.96825

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.06767
Value Function Update Magnitude: 0.03907

Collected Steps per Second: 10,216.52704
Overall Steps per Second: 8,713.62987

Timestep Collection Time: 4.89501
Timestep Consumption Time: 0.84427
PPO Batch Consumption Time: 0.04617
Total Iteration Time: 5.73928

Cumulative Model Updates: 1,415
Cumulative Timesteps: 23,707,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 23707896...
Checkpoint 23707896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.56683
Policy Entropy: 1.24800
Value Function Loss: 6.95428

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.16277
Policy Update Magnitude: 0.06541
Value Function Update Magnitude: 0.03744

Collected Steps per Second: 10,571.24952
Overall Steps per Second: 8,921.70548

Timestep Collection Time: 4.73076
Timestep Consumption Time: 0.87467
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.60543

Cumulative Model Updates: 1,418
Cumulative Timesteps: 23,757,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.46254
Policy Entropy: 1.26304
Value Function Loss: 6.68700

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.11815
Policy Update Magnitude: 0.07222
Value Function Update Magnitude: 0.03773

Collected Steps per Second: 10,686.60520
Overall Steps per Second: 9,011.22843

Timestep Collection Time: 4.68137
Timestep Consumption Time: 0.87037
PPO Batch Consumption Time: 0.04543
Total Iteration Time: 5.55174

Cumulative Model Updates: 1,421
Cumulative Timesteps: 23,807,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 23807934...
Checkpoint 23807934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127.78559
Policy Entropy: 1.24235
Value Function Loss: 6.72809

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.16149
Policy Update Magnitude: 0.06706
Value Function Update Magnitude: 0.05439

Collected Steps per Second: 10,716.31230
Overall Steps per Second: 9,194.71049

Timestep Collection Time: 4.66672
Timestep Consumption Time: 0.77228
PPO Batch Consumption Time: 0.04493
Total Iteration Time: 5.43900

Cumulative Model Updates: 1,424
Cumulative Timesteps: 23,857,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.73374
Policy Entropy: 1.25947
Value Function Loss: 6.64038

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.06808
Value Function Update Magnitude: 0.04551

Collected Steps per Second: 10,636.25040
Overall Steps per Second: 9,034.06819

Timestep Collection Time: 4.70222
Timestep Consumption Time: 0.83393
PPO Batch Consumption Time: 0.04641
Total Iteration Time: 5.53615

Cumulative Model Updates: 1,427
Cumulative Timesteps: 23,907,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 23907958...
Checkpoint 23907958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.44331
Policy Entropy: 1.24288
Value Function Loss: 6.78553

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.04024

Collected Steps per Second: 9,925.46910
Overall Steps per Second: 8,515.81604

Timestep Collection Time: 5.03996
Timestep Consumption Time: 0.83428
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 5.87425

Cumulative Model Updates: 1,430
Cumulative Timesteps: 23,957,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.10801
Policy Entropy: 1.25092
Value Function Loss: 7.08205

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.08369
Value Function Update Magnitude: 0.04403

Collected Steps per Second: 10,828.86399
Overall Steps per Second: 9,082.10341

Timestep Collection Time: 4.61729
Timestep Consumption Time: 0.88804
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 5.50533

Cumulative Model Updates: 1,433
Cumulative Timesteps: 24,007,982

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 24007982...
Checkpoint 24007982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.98858
Policy Entropy: 1.23095
Value Function Loss: 7.17354

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.16407
Policy Update Magnitude: 0.07890
Value Function Update Magnitude: 0.04338

Collected Steps per Second: 10,760.90366
Overall Steps per Second: 9,168.80760

Timestep Collection Time: 4.64701
Timestep Consumption Time: 0.80692
PPO Batch Consumption Time: 0.03829
Total Iteration Time: 5.45393

Cumulative Model Updates: 1,436
Cumulative Timesteps: 24,057,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.29897
Policy Entropy: 1.24579
Value Function Loss: 7.28617

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.08566
Value Function Update Magnitude: 0.04075

Collected Steps per Second: 10,452.12230
Overall Steps per Second: 9,032.02974

Timestep Collection Time: 4.78582
Timestep Consumption Time: 0.75247
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 5.53829

Cumulative Model Updates: 1,439
Cumulative Timesteps: 24,108,010

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 24108010...
Checkpoint 24108010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.61819
Policy Entropy: 1.23128
Value Function Loss: 7.23176

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.16443
Policy Update Magnitude: 0.07583
Value Function Update Magnitude: 0.04978

Collected Steps per Second: 10,813.93186
Overall Steps per Second: 9,110.07614

Timestep Collection Time: 4.62699
Timestep Consumption Time: 0.86539
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.49238

Cumulative Model Updates: 1,442
Cumulative Timesteps: 24,158,046

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.13211
Policy Entropy: 1.23794
Value Function Loss: 7.38337

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.07182
Value Function Update Magnitude: 0.04625

Collected Steps per Second: 10,517.74730
Overall Steps per Second: 8,839.48869

Timestep Collection Time: 4.75463
Timestep Consumption Time: 0.90271
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 5.65734

Cumulative Model Updates: 1,445
Cumulative Timesteps: 24,208,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 24208054...
Checkpoint 24208054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.23487
Policy Entropy: 1.22058
Value Function Loss: 7.29785

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.16291
Policy Update Magnitude: 0.06759
Value Function Update Magnitude: 0.04310

Collected Steps per Second: 10,112.43262
Overall Steps per Second: 8,512.28435

Timestep Collection Time: 4.94540
Timestep Consumption Time: 0.92964
PPO Batch Consumption Time: 0.04601
Total Iteration Time: 5.87504

Cumulative Model Updates: 1,448
Cumulative Timesteps: 24,258,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.06933
Policy Entropy: 1.23401
Value Function Loss: 7.18784

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.06993
Value Function Update Magnitude: 0.04522

Collected Steps per Second: 10,490.16020
Overall Steps per Second: 8,863.09587

Timestep Collection Time: 4.76866
Timestep Consumption Time: 0.87542
PPO Batch Consumption Time: 0.04263
Total Iteration Time: 5.64408

Cumulative Model Updates: 1,451
Cumulative Timesteps: 24,308,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 24308088...
Checkpoint 24308088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130.25714
Policy Entropy: 1.22267
Value Function Loss: 7.31320

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.17021
Policy Update Magnitude: 0.06553
Value Function Update Magnitude: 0.05339

Collected Steps per Second: 10,582.47112
Overall Steps per Second: 9,104.18964

Timestep Collection Time: 4.72650
Timestep Consumption Time: 0.76746
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 5.49395

Cumulative Model Updates: 1,454
Cumulative Timesteps: 24,358,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.23401
Policy Entropy: 1.24298
Value Function Loss: 7.20885

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.06406
Value Function Update Magnitude: 0.04744

Collected Steps per Second: 10,753.29536
Overall Steps per Second: 9,116.36233

Timestep Collection Time: 4.65216
Timestep Consumption Time: 0.83534
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.48750

Cumulative Model Updates: 1,457
Cumulative Timesteps: 24,408,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 24408132...
Checkpoint 24408132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.39499
Policy Entropy: 1.22909
Value Function Loss: 7.13434

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.16272
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.04519

Collected Steps per Second: 10,513.32408
Overall Steps per Second: 8,915.03411

Timestep Collection Time: 4.75777
Timestep Consumption Time: 0.85297
PPO Batch Consumption Time: 0.04473
Total Iteration Time: 5.61075

Cumulative Model Updates: 1,460
Cumulative Timesteps: 24,458,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.23596
Policy Entropy: 1.24450
Value Function Loss: 6.83438

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.04773

Collected Steps per Second: 10,446.83666
Overall Steps per Second: 8,862.52988

Timestep Collection Time: 4.78690
Timestep Consumption Time: 0.85573
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 5.64263

Cumulative Model Updates: 1,463
Cumulative Timesteps: 24,508,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 24508160...
Checkpoint 24508160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.56378
Policy Entropy: 1.23155
Value Function Loss: 6.79095

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.16363
Policy Update Magnitude: 0.06294
Value Function Update Magnitude: 0.04276

Collected Steps per Second: 10,834.24252
Overall Steps per Second: 9,105.76511

Timestep Collection Time: 4.61647
Timestep Consumption Time: 0.87631
PPO Batch Consumption Time: 0.04042
Total Iteration Time: 5.49278

Cumulative Model Updates: 1,466
Cumulative Timesteps: 24,558,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.78781
Policy Entropy: 1.24643
Value Function Loss: 6.82168

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.03786

Collected Steps per Second: 10,638.25217
Overall Steps per Second: 9,173.66060

Timestep Collection Time: 4.70190
Timestep Consumption Time: 0.75067
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.45257

Cumulative Model Updates: 1,469
Cumulative Timesteps: 24,608,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 24608196...
Checkpoint 24608196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.43508
Policy Entropy: 1.23405
Value Function Loss: 6.93411

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.15069
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.04276

Collected Steps per Second: 10,253.69847
Overall Steps per Second: 8,700.54622

Timestep Collection Time: 4.87785
Timestep Consumption Time: 0.87075
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 5.74860

Cumulative Model Updates: 1,472
Cumulative Timesteps: 24,658,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.16519
Policy Entropy: 1.23995
Value Function Loss: 7.08327

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.08490
Value Function Update Magnitude: 0.04152

Collected Steps per Second: 10,464.88726
Overall Steps per Second: 8,999.94338

Timestep Collection Time: 4.77865
Timestep Consumption Time: 0.77783
PPO Batch Consumption Time: 0.04160
Total Iteration Time: 5.55648

Cumulative Model Updates: 1,475
Cumulative Timesteps: 24,708,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 24708220...
Checkpoint 24708220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.00207
Policy Entropy: 1.22818
Value Function Loss: 7.09383

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.15606
Policy Update Magnitude: 0.06991
Value Function Update Magnitude: 0.04096

Collected Steps per Second: 10,247.83829
Overall Steps per Second: 8,734.87552

Timestep Collection Time: 4.88103
Timestep Consumption Time: 0.84544
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.72647

Cumulative Model Updates: 1,478
Cumulative Timesteps: 24,758,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.68267
Policy Entropy: 1.24399
Value Function Loss: 7.06180

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.07588
Value Function Update Magnitude: 0.04266

Collected Steps per Second: 10,222.58999
Overall Steps per Second: 8,759.26481

Timestep Collection Time: 4.89426
Timestep Consumption Time: 0.81764
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.71189

Cumulative Model Updates: 1,481
Cumulative Timesteps: 24,808,272

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 24808272...
Checkpoint 24808272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148.86584
Policy Entropy: 1.23433
Value Function Loss: 6.95572

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.16074
Policy Update Magnitude: 0.07086
Value Function Update Magnitude: 0.04384

Collected Steps per Second: 10,839.00189
Overall Steps per Second: 9,111.61250

Timestep Collection Time: 4.61519
Timestep Consumption Time: 0.87495
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 5.49014

Cumulative Model Updates: 1,484
Cumulative Timesteps: 24,858,296

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.75025
Policy Entropy: 1.24798
Value Function Loss: 6.95974

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.06268
Value Function Update Magnitude: 0.04288

Collected Steps per Second: 10,305.15591
Overall Steps per Second: 8,687.93387

Timestep Collection Time: 4.85349
Timestep Consumption Time: 0.90346
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 5.75695

Cumulative Model Updates: 1,487
Cumulative Timesteps: 24,908,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 24908312...
Checkpoint 24908312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.46115
Policy Entropy: 1.22917
Value Function Loss: 7.05358

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.16644
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.03812

Collected Steps per Second: 10,929.61209
Overall Steps per Second: 9,271.74274

Timestep Collection Time: 4.57601
Timestep Consumption Time: 0.81823
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 5.39424

Cumulative Model Updates: 1,490
Cumulative Timesteps: 24,958,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.94693
Policy Entropy: 1.23528
Value Function Loss: 7.30716

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.06482
Value Function Update Magnitude: 0.04028

Collected Steps per Second: 10,838.62255
Overall Steps per Second: 9,039.88463

Timestep Collection Time: 4.61516
Timestep Consumption Time: 0.91832
PPO Batch Consumption Time: 0.04752
Total Iteration Time: 5.53348

Cumulative Model Updates: 1,493
Cumulative Timesteps: 25,008,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 25008348...
Checkpoint 25008348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.07541
Policy Entropy: 1.21336
Value Function Loss: 7.29882

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.16721
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.04365

Collected Steps per Second: 10,655.82350
Overall Steps per Second: 9,030.89753

Timestep Collection Time: 4.69452
Timestep Consumption Time: 0.84468
PPO Batch Consumption Time: 0.04050
Total Iteration Time: 5.53921

Cumulative Model Updates: 1,496
Cumulative Timesteps: 25,058,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.03781
Policy Entropy: 1.22528
Value Function Loss: 7.42612

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.06172
Value Function Update Magnitude: 0.04732

Collected Steps per Second: 10,960.99332
Overall Steps per Second: 9,176.45046

Timestep Collection Time: 4.56200
Timestep Consumption Time: 0.88717
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 5.44917

Cumulative Model Updates: 1,499
Cumulative Timesteps: 25,108,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 25108376...
Checkpoint 25108376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127.99511
Policy Entropy: 1.20867
Value Function Loss: 7.39508

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.15195
Policy Update Magnitude: 0.06124
Value Function Update Magnitude: 0.04120

Collected Steps per Second: 10,863.82387
Overall Steps per Second: 9,076.32447

Timestep Collection Time: 4.60390
Timestep Consumption Time: 0.90670
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 5.51060

Cumulative Model Updates: 1,502
Cumulative Timesteps: 25,158,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.15698
Policy Entropy: 1.22923
Value Function Loss: 7.72817

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.06823
Value Function Update Magnitude: 0.05213

Collected Steps per Second: 10,905.71291
Overall Steps per Second: 9,343.95110

Timestep Collection Time: 4.58475
Timestep Consumption Time: 0.76630
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 5.35106

Cumulative Model Updates: 1,505
Cumulative Timesteps: 25,208,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 25208392...
Checkpoint 25208392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.77687
Policy Entropy: 1.21821
Value Function Loss: 7.66035

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.15422
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.05709

Collected Steps per Second: 10,659.35558
Overall Steps per Second: 8,998.84365

Timestep Collection Time: 4.69278
Timestep Consumption Time: 0.86594
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 5.55871

Cumulative Model Updates: 1,508
Cumulative Timesteps: 25,258,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.69766
Policy Entropy: 1.24148
Value Function Loss: 7.49140

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.07069
Value Function Update Magnitude: 0.06018

Collected Steps per Second: 10,132.51346
Overall Steps per Second: 8,661.18079

Timestep Collection Time: 4.93560
Timestep Consumption Time: 0.83844
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 5.77404

Cumulative Model Updates: 1,511
Cumulative Timesteps: 25,308,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 25308424...
Checkpoint 25308424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.85670
Policy Entropy: 1.22109
Value Function Loss: 7.22660

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.16945
Policy Update Magnitude: 0.08297
Value Function Update Magnitude: 0.05485

Collected Steps per Second: 10,384.41651
Overall Steps per Second: 8,907.18411

Timestep Collection Time: 4.81626
Timestep Consumption Time: 0.79876
PPO Batch Consumption Time: 0.04481
Total Iteration Time: 5.61502

Cumulative Model Updates: 1,514
Cumulative Timesteps: 25,358,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.32158
Policy Entropy: 1.23883
Value Function Loss: 7.21015

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.07099
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 10,686.48747
Overall Steps per Second: 9,038.91985

Timestep Collection Time: 4.67937
Timestep Consumption Time: 0.85293
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.53230

Cumulative Model Updates: 1,517
Cumulative Timesteps: 25,408,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 25408444...
Checkpoint 25408444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148.39893
Policy Entropy: 1.22540
Value Function Loss: 7.28498

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.16109
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.04736

Collected Steps per Second: 10,535.63767
Overall Steps per Second: 9,141.65121

Timestep Collection Time: 4.74864
Timestep Consumption Time: 0.72411
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 5.47275

Cumulative Model Updates: 1,520
Cumulative Timesteps: 25,458,474

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.57424
Policy Entropy: 1.24327
Value Function Loss: 7.17415

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.06552
Value Function Update Magnitude: 0.04830

Collected Steps per Second: 10,905.78618
Overall Steps per Second: 9,185.21026

Timestep Collection Time: 4.58637
Timestep Consumption Time: 0.85912
PPO Batch Consumption Time: 0.03943
Total Iteration Time: 5.44549

Cumulative Model Updates: 1,523
Cumulative Timesteps: 25,508,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 25508492...
Checkpoint 25508492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148.52839
Policy Entropy: 1.22349
Value Function Loss: 7.21139

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15361
Policy Update Magnitude: 0.06303
Value Function Update Magnitude: 0.05643

Collected Steps per Second: 10,295.18418
Overall Steps per Second: 8,705.57580

Timestep Collection Time: 4.85878
Timestep Consumption Time: 0.88720
PPO Batch Consumption Time: 0.04644
Total Iteration Time: 5.74597

Cumulative Model Updates: 1,526
Cumulative Timesteps: 25,558,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.43795
Policy Entropy: 1.23592
Value Function Loss: 7.31202

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13950
Policy Update Magnitude: 0.07912
Value Function Update Magnitude: 0.05185

Collected Steps per Second: 10,698.63096
Overall Steps per Second: 8,994.90669

Timestep Collection Time: 4.67368
Timestep Consumption Time: 0.88524
PPO Batch Consumption Time: 0.04751
Total Iteration Time: 5.55892

Cumulative Model Updates: 1,529
Cumulative Timesteps: 25,608,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 25608516...
Checkpoint 25608516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.14707
Policy Entropy: 1.21439
Value Function Loss: 7.31537

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.19407
Policy Update Magnitude: 0.07202
Value Function Update Magnitude: 0.05755

Collected Steps per Second: 10,706.29423
Overall Steps per Second: 9,073.74058

Timestep Collection Time: 4.67015
Timestep Consumption Time: 0.84026
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.51041

Cumulative Model Updates: 1,532
Cumulative Timesteps: 25,658,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.91066
Policy Entropy: 1.22674
Value Function Loss: 7.15160

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.05343

Collected Steps per Second: 10,348.46001
Overall Steps per Second: 8,787.98952

Timestep Collection Time: 4.83376
Timestep Consumption Time: 0.85832
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 5.69209

Cumulative Model Updates: 1,535
Cumulative Timesteps: 25,708,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 25708538...
Checkpoint 25708538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.14454
Policy Entropy: 1.19346
Value Function Loss: 7.54417

Mean KL Divergence: 0.02723
SB3 Clip Fraction: 0.19870
Policy Update Magnitude: 0.06278
Value Function Update Magnitude: 0.05832

Collected Steps per Second: 10,481.67335
Overall Steps per Second: 8,903.59607

Timestep Collection Time: 4.77233
Timestep Consumption Time: 0.84585
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 5.61818

Cumulative Model Updates: 1,538
Cumulative Timesteps: 25,758,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.31153
Policy Entropy: 1.20628
Value Function Loss: 7.71842

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.06809
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 10,828.85967
Overall Steps per Second: 9,342.95156

Timestep Collection Time: 4.61821
Timestep Consumption Time: 0.73448
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.35270

Cumulative Model Updates: 1,541
Cumulative Timesteps: 25,808,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 25808570...
Checkpoint 25808570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.35360
Policy Entropy: 1.18583
Value Function Loss: 8.12512

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.19507
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.06036

Collected Steps per Second: 10,208.09327
Overall Steps per Second: 8,718.90461

Timestep Collection Time: 4.90003
Timestep Consumption Time: 0.83693
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 5.73696

Cumulative Model Updates: 1,544
Cumulative Timesteps: 25,858,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.17498
Policy Entropy: 1.21368
Value Function Loss: 8.04866

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.15371
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.06240

Collected Steps per Second: 10,379.76587
Overall Steps per Second: 8,837.08618

Timestep Collection Time: 4.81745
Timestep Consumption Time: 0.84098
PPO Batch Consumption Time: 0.04744
Total Iteration Time: 5.65843

Cumulative Model Updates: 1,547
Cumulative Timesteps: 25,908,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 25908594...
Checkpoint 25908594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.44954
Policy Entropy: 1.19660
Value Function Loss: 8.17452

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.17824
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.05618

Collected Steps per Second: 10,817.55588
Overall Steps per Second: 9,059.95178

Timestep Collection Time: 4.62544
Timestep Consumption Time: 0.89732
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 5.52277

Cumulative Model Updates: 1,550
Cumulative Timesteps: 25,958,630

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.56872
Policy Entropy: 1.21779
Value Function Loss: 7.91969

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.16381
Policy Update Magnitude: 0.06135
Value Function Update Magnitude: 0.05894

Collected Steps per Second: 10,640.70018
Overall Steps per Second: 9,050.82627

Timestep Collection Time: 4.69894
Timestep Consumption Time: 0.82542
PPO Batch Consumption Time: 0.03903
Total Iteration Time: 5.52436

Cumulative Model Updates: 1,553
Cumulative Timesteps: 26,008,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 26008630...
Checkpoint 26008630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.05662
Policy Entropy: 1.19815
Value Function Loss: 7.96697

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.16537
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.05067

Collected Steps per Second: 10,236.44494
Overall Steps per Second: 8,866.07904

Timestep Collection Time: 4.88724
Timestep Consumption Time: 0.75539
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 5.64263

Cumulative Model Updates: 1,556
Cumulative Timesteps: 26,058,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.28959
Policy Entropy: 1.21365
Value Function Loss: 7.95970

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.16677
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.04598

Collected Steps per Second: 10,305.67458
Overall Steps per Second: 8,784.71593

Timestep Collection Time: 4.85402
Timestep Consumption Time: 0.84041
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 5.69444

Cumulative Model Updates: 1,559
Cumulative Timesteps: 26,108,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 26108682...
Checkpoint 26108682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.37172
Policy Entropy: 1.19696
Value Function Loss: 8.05739

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.16794
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.05298

Collected Steps per Second: 10,509.72304
Overall Steps per Second: 8,974.53311

Timestep Collection Time: 4.75978
Timestep Consumption Time: 0.81421
PPO Batch Consumption Time: 0.03924
Total Iteration Time: 5.57399

Cumulative Model Updates: 1,562
Cumulative Timesteps: 26,158,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.87419
Policy Entropy: 1.21451
Value Function Loss: 7.86416

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.04727

Collected Steps per Second: 10,129.05172
Overall Steps per Second: 8,540.18864

Timestep Collection Time: 4.93649
Timestep Consumption Time: 0.91841
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 5.85491

Cumulative Model Updates: 1,565
Cumulative Timesteps: 26,208,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 26208708...
Checkpoint 26208708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.12920
Policy Entropy: 1.20439
Value Function Loss: 7.64644

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.18065
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.04926

Collected Steps per Second: 9,823.01888
Overall Steps per Second: 8,368.19734

Timestep Collection Time: 5.09049
Timestep Consumption Time: 0.88499
PPO Batch Consumption Time: 0.04689
Total Iteration Time: 5.97548

Cumulative Model Updates: 1,568
Cumulative Timesteps: 26,258,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.05608
Policy Entropy: 1.21654
Value Function Loss: 7.80402

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.05130

Collected Steps per Second: 10,508.56319
Overall Steps per Second: 9,025.63269

Timestep Collection Time: 4.75898
Timestep Consumption Time: 0.78191
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 5.54089

Cumulative Model Updates: 1,571
Cumulative Timesteps: 26,308,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 26308722...
Checkpoint 26308722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.88563
Policy Entropy: 1.19733
Value Function Loss: 7.80794

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.17205
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.05035

Collected Steps per Second: 10,231.83842
Overall Steps per Second: 8,591.06942

Timestep Collection Time: 4.88886
Timestep Consumption Time: 0.93370
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 5.82256

Cumulative Model Updates: 1,574
Cumulative Timesteps: 26,358,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.71404
Policy Entropy: 1.21297
Value Function Loss: 7.86282

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.15166
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.05267

Collected Steps per Second: 10,298.18706
Overall Steps per Second: 8,751.69704

Timestep Collection Time: 4.85697
Timestep Consumption Time: 0.85826
PPO Batch Consumption Time: 0.04686
Total Iteration Time: 5.71523

Cumulative Model Updates: 1,577
Cumulative Timesteps: 26,408,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 26408762...
Checkpoint 26408762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.84115
Policy Entropy: 1.20008
Value Function Loss: 7.76558

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.17673
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.04922

Collected Steps per Second: 10,708.61868
Overall Steps per Second: 9,055.69710

Timestep Collection Time: 4.67119
Timestep Consumption Time: 0.85262
PPO Batch Consumption Time: 0.04306
Total Iteration Time: 5.52382

Cumulative Model Updates: 1,580
Cumulative Timesteps: 26,458,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.06277
Policy Entropy: 1.22245
Value Function Loss: 8.12900

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.15477
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.05055

Collected Steps per Second: 10,423.08960
Overall Steps per Second: 8,832.87535

Timestep Collection Time: 4.79954
Timestep Consumption Time: 0.86408
PPO Batch Consumption Time: 0.04159
Total Iteration Time: 5.66361

Cumulative Model Updates: 1,583
Cumulative Timesteps: 26,508,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 26508810...
Checkpoint 26508810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.77965
Policy Entropy: 1.19690
Value Function Loss: 8.16944

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.18779
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.05477

Collected Steps per Second: 10,826.72413
Overall Steps per Second: 9,165.85061

Timestep Collection Time: 4.62023
Timestep Consumption Time: 0.83720
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.45743

Cumulative Model Updates: 1,586
Cumulative Timesteps: 26,558,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.45204
Policy Entropy: 1.21126
Value Function Loss: 7.85999

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.15649
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.05317

Collected Steps per Second: 10,358.39478
Overall Steps per Second: 8,708.54205

Timestep Collection Time: 4.82835
Timestep Consumption Time: 0.91474
PPO Batch Consumption Time: 0.04711
Total Iteration Time: 5.74310

Cumulative Model Updates: 1,589
Cumulative Timesteps: 26,608,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26608846...
Checkpoint 26608846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.97225
Policy Entropy: 1.18867
Value Function Loss: 7.56912

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.17779
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.05168

Collected Steps per Second: 10,597.19420
Overall Steps per Second: 8,989.66034

Timestep Collection Time: 4.71993
Timestep Consumption Time: 0.84402
PPO Batch Consumption Time: 0.03877
Total Iteration Time: 5.56395

Cumulative Model Updates: 1,592
Cumulative Timesteps: 26,658,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.18553
Policy Entropy: 1.20590
Value Function Loss: 7.52799

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 10,599.13512
Overall Steps per Second: 8,924.07207

Timestep Collection Time: 4.71850
Timestep Consumption Time: 0.88567
PPO Batch Consumption Time: 0.03843
Total Iteration Time: 5.60417

Cumulative Model Updates: 1,595
Cumulative Timesteps: 26,708,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 26708876...
Checkpoint 26708876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.22992
Policy Entropy: 1.18148
Value Function Loss: 7.85742

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.17402
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.07801

Collected Steps per Second: 10,540.66766
Overall Steps per Second: 8,926.70445

Timestep Collection Time: 4.74429
Timestep Consumption Time: 0.85778
PPO Batch Consumption Time: 0.04584
Total Iteration Time: 5.60207

Cumulative Model Updates: 1,598
Cumulative Timesteps: 26,758,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.68278
Policy Entropy: 1.20023
Value Function Loss: 7.74989

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.09785

Collected Steps per Second: 10,482.13064
Overall Steps per Second: 8,759.14244

Timestep Collection Time: 4.77136
Timestep Consumption Time: 0.93856
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 5.70992

Cumulative Model Updates: 1,601
Cumulative Timesteps: 26,808,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26808898...
Checkpoint 26808898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.51851
Policy Entropy: 1.17970
Value Function Loss: 7.86191

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.16889
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.09312

Collected Steps per Second: 10,811.77974
Overall Steps per Second: 9,071.73284

Timestep Collection Time: 4.62699
Timestep Consumption Time: 0.88750
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.51449

Cumulative Model Updates: 1,604
Cumulative Timesteps: 26,858,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.16785
Policy Entropy: 1.19955
Value Function Loss: 7.93180

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15581
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.10029

Collected Steps per Second: 10,383.55919
Overall Steps per Second: 8,803.12658

Timestep Collection Time: 4.81742
Timestep Consumption Time: 0.86488
PPO Batch Consumption Time: 0.04027
Total Iteration Time: 5.68230

Cumulative Model Updates: 1,607
Cumulative Timesteps: 26,908,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 26908946...
Checkpoint 26908946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.24760
Policy Entropy: 1.18701
Value Function Loss: 8.12246

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.16789
Policy Update Magnitude: 0.06464
Value Function Update Magnitude: 0.08524

Collected Steps per Second: 10,029.96520
Overall Steps per Second: 8,434.03432

Timestep Collection Time: 4.98805
Timestep Consumption Time: 0.94386
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.93192

Cumulative Model Updates: 1,610
Cumulative Timesteps: 26,958,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.10823
Policy Entropy: 1.20598
Value Function Loss: 8.25817

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.07141

Collected Steps per Second: 10,714.26820
Overall Steps per Second: 9,091.56626

Timestep Collection Time: 4.66947
Timestep Consumption Time: 0.83343
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 5.50290

Cumulative Model Updates: 1,613
Cumulative Timesteps: 27,009,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 27009006...
Checkpoint 27009006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.11485
Policy Entropy: 1.18909
Value Function Loss: 7.95750

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.17142
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.07128

Collected Steps per Second: 10,828.31663
Overall Steps per Second: 9,046.50447

Timestep Collection Time: 4.61808
Timestep Consumption Time: 0.90958
PPO Batch Consumption Time: 0.04413
Total Iteration Time: 5.52766

Cumulative Model Updates: 1,616
Cumulative Timesteps: 27,059,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.11406
Policy Entropy: 1.20029
Value Function Loss: 7.81599

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.15627
Policy Update Magnitude: 0.07549
Value Function Update Magnitude: 0.07177

Collected Steps per Second: 10,908.11425
Overall Steps per Second: 9,362.33192

Timestep Collection Time: 4.58448
Timestep Consumption Time: 0.75693
PPO Batch Consumption Time: 0.04797
Total Iteration Time: 5.34140

Cumulative Model Updates: 1,619
Cumulative Timesteps: 27,109,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 27109020...
Checkpoint 27109020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.38799
Policy Entropy: 1.18256
Value Function Loss: 7.88917

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.17443
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.06754

Collected Steps per Second: 10,502.56081
Overall Steps per Second: 8,819.52179

Timestep Collection Time: 4.76151
Timestep Consumption Time: 0.90864
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 5.67015

Cumulative Model Updates: 1,622
Cumulative Timesteps: 27,159,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.00635
Policy Entropy: 1.19699
Value Function Loss: 7.90483

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.06351

Collected Steps per Second: 10,801.52516
Overall Steps per Second: 9,136.26033

Timestep Collection Time: 4.63138
Timestep Consumption Time: 0.84416
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 5.47554

Cumulative Model Updates: 1,625
Cumulative Timesteps: 27,209,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 27209054...
Checkpoint 27209054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.15527
Policy Entropy: 1.18046
Value Function Loss: 7.96606

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.16531
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 11,266.10997
Overall Steps per Second: 9,479.09532

Timestep Collection Time: 4.43951
Timestep Consumption Time: 0.83694
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.27645

Cumulative Model Updates: 1,628
Cumulative Timesteps: 27,259,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.39234
Policy Entropy: 1.19899
Value Function Loss: 7.63594

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.15281
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.06356

Collected Steps per Second: 10,861.93963
Overall Steps per Second: 9,212.26104

Timestep Collection Time: 4.60378
Timestep Consumption Time: 0.82442
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 5.42820

Cumulative Model Updates: 1,631
Cumulative Timesteps: 27,309,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 27309076...
Checkpoint 27309076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.11515
Policy Entropy: 1.18380
Value Function Loss: 7.57040

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.16678
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.07488

Collected Steps per Second: 10,656.87209
Overall Steps per Second: 9,086.54653

Timestep Collection Time: 4.69462
Timestep Consumption Time: 0.81132
PPO Batch Consumption Time: 0.04684
Total Iteration Time: 5.50594

Cumulative Model Updates: 1,634
Cumulative Timesteps: 27,359,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.74483
Policy Entropy: 1.19382
Value Function Loss: 7.86352

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15211
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.08794

Collected Steps per Second: 10,512.42459
Overall Steps per Second: 8,874.85049

Timestep Collection Time: 4.75856
Timestep Consumption Time: 0.87804
PPO Batch Consumption Time: 0.04572
Total Iteration Time: 5.63660

Cumulative Model Updates: 1,637
Cumulative Timesteps: 27,409,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 27409130...
Checkpoint 27409130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.64722
Policy Entropy: 1.17179
Value Function Loss: 7.95787

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.17947
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.12310

Collected Steps per Second: 9,958.15861
Overall Steps per Second: 8,483.55180

Timestep Collection Time: 5.02201
Timestep Consumption Time: 0.87292
PPO Batch Consumption Time: 0.04608
Total Iteration Time: 5.89494

Cumulative Model Updates: 1,640
Cumulative Timesteps: 27,459,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.11930
Policy Entropy: 1.18977
Value Function Loss: 7.92047

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.14435

Collected Steps per Second: 10,706.22803
Overall Steps per Second: 8,980.97264

Timestep Collection Time: 4.67074
Timestep Consumption Time: 0.89725
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 5.56799

Cumulative Model Updates: 1,643
Cumulative Timesteps: 27,509,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 27509146...
Checkpoint 27509146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.89303
Policy Entropy: 1.17290
Value Function Loss: 7.50017

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.17673
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.13104

Collected Steps per Second: 10,587.01571
Overall Steps per Second: 8,909.19058

Timestep Collection Time: 4.72447
Timestep Consumption Time: 0.88974
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 5.61420

Cumulative Model Updates: 1,646
Cumulative Timesteps: 27,559,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.12192
Policy Entropy: 1.19511
Value Function Loss: 7.66970

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.17020
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.12523

Collected Steps per Second: 10,537.54237
Overall Steps per Second: 9,168.91717

Timestep Collection Time: 4.74532
Timestep Consumption Time: 0.70832
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 5.45364

Cumulative Model Updates: 1,649
Cumulative Timesteps: 27,609,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 27609168...
Checkpoint 27609168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.68706
Policy Entropy: 1.17348
Value Function Loss: 7.81266

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.17007
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 10,509.07515
Overall Steps per Second: 8,798.68028

Timestep Collection Time: 4.75779
Timestep Consumption Time: 0.92488
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 5.68267

Cumulative Model Updates: 1,652
Cumulative Timesteps: 27,659,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.44940
Policy Entropy: 1.19747
Value Function Loss: 7.92717

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.16374
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 10,190.28847
Overall Steps per Second: 8,785.89271

Timestep Collection Time: 4.90801
Timestep Consumption Time: 0.78453
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 5.69253

Cumulative Model Updates: 1,655
Cumulative Timesteps: 27,709,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 27709182...
Checkpoint 27709182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148.76467
Policy Entropy: 1.18170
Value Function Loss: 7.68552

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.17997
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.12263

Collected Steps per Second: 10,772.01022
Overall Steps per Second: 9,179.44376

Timestep Collection Time: 4.64370
Timestep Consumption Time: 0.80565
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 5.44935

Cumulative Model Updates: 1,658
Cumulative Timesteps: 27,759,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.54424
Policy Entropy: 1.19927
Value Function Loss: 7.59691

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.16239
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.10211

Collected Steps per Second: 10,732.71042
Overall Steps per Second: 9,110.79285

Timestep Collection Time: 4.66164
Timestep Consumption Time: 0.82987
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 5.49151

Cumulative Model Updates: 1,661
Cumulative Timesteps: 27,809,236

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 27809236...
Checkpoint 27809236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.26236
Policy Entropy: 1.17615
Value Function Loss: 7.77222

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.08263

Collected Steps per Second: 10,529.11752
Overall Steps per Second: 9,055.98778

Timestep Collection Time: 4.75007
Timestep Consumption Time: 0.77269
PPO Batch Consumption Time: 0.04406
Total Iteration Time: 5.52275

Cumulative Model Updates: 1,664
Cumulative Timesteps: 27,859,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.79368
Policy Entropy: 1.19444
Value Function Loss: 7.86018

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.15888
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.07523

Collected Steps per Second: 10,543.25535
Overall Steps per Second: 8,981.87109

Timestep Collection Time: 4.74256
Timestep Consumption Time: 0.82443
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.56699

Cumulative Model Updates: 1,667
Cumulative Timesteps: 27,909,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 27909252...
Checkpoint 27909252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.74124
Policy Entropy: 1.18614
Value Function Loss: 7.84151

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.17274
Policy Update Magnitude: 0.07245
Value Function Update Magnitude: 0.06084

Collected Steps per Second: 10,657.42793
Overall Steps per Second: 8,907.88630

Timestep Collection Time: 4.69213
Timestep Consumption Time: 0.92155
PPO Batch Consumption Time: 0.04836
Total Iteration Time: 5.61368

Cumulative Model Updates: 1,670
Cumulative Timesteps: 27,959,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.91175
Policy Entropy: 1.20633
Value Function Loss: 7.62886

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.06287
Value Function Update Magnitude: 0.05264

Collected Steps per Second: 10,915.11412
Overall Steps per Second: 9,214.64435

Timestep Collection Time: 4.58282
Timestep Consumption Time: 0.84571
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 5.42853

Cumulative Model Updates: 1,673
Cumulative Timesteps: 28,009,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 28009280...
Checkpoint 28009280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.44481
Policy Entropy: 1.17869
Value Function Loss: 7.93844

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.18063
Policy Update Magnitude: 0.06492
Value Function Update Magnitude: 0.05383

Collected Steps per Second: 10,318.32989
Overall Steps per Second: 8,756.24296

Timestep Collection Time: 4.84613
Timestep Consumption Time: 0.86454
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 5.71067

Cumulative Model Updates: 1,676
Cumulative Timesteps: 28,059,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.70508
Policy Entropy: 1.18781
Value Function Loss: 7.63917

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.04660

Collected Steps per Second: 10,655.85432
Overall Steps per Second: 9,227.97664

Timestep Collection Time: 4.69301
Timestep Consumption Time: 0.72617
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.41917

Cumulative Model Updates: 1,679
Cumulative Timesteps: 28,109,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 28109292...
Checkpoint 28109292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.61915
Policy Entropy: 1.16414
Value Function Loss: 7.85180

Mean KL Divergence: 0.02530
SB3 Clip Fraction: 0.18086
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.04286

Collected Steps per Second: 10,688.46226
Overall Steps per Second: 9,013.39342

Timestep Collection Time: 4.68019
Timestep Consumption Time: 0.86978
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 5.54996

Cumulative Model Updates: 1,682
Cumulative Timesteps: 28,159,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.15135
Policy Entropy: 1.18451
Value Function Loss: 7.74338

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.03840

Collected Steps per Second: 10,591.53534
Overall Steps per Second: 9,093.78041

Timestep Collection Time: 4.72075
Timestep Consumption Time: 0.77751
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 5.49826

Cumulative Model Updates: 1,685
Cumulative Timesteps: 28,209,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 28209316...
Checkpoint 28209316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.23579
Policy Entropy: 1.17389
Value Function Loss: 8.34105

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.17279
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.03926

Collected Steps per Second: 10,115.68702
Overall Steps per Second: 8,704.73041

Timestep Collection Time: 4.94420
Timestep Consumption Time: 0.80141
PPO Batch Consumption Time: 0.03972
Total Iteration Time: 5.74561

Cumulative Model Updates: 1,688
Cumulative Timesteps: 28,259,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.05821
Policy Entropy: 1.19511
Value Function Loss: 8.37292

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.16689
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.04000

Collected Steps per Second: 10,689.42473
Overall Steps per Second: 9,154.73769

Timestep Collection Time: 4.67939
Timestep Consumption Time: 0.78445
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 5.46384

Cumulative Model Updates: 1,691
Cumulative Timesteps: 28,309,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 28309350...
Checkpoint 28309350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.57143
Policy Entropy: 1.17839
Value Function Loss: 8.25352

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.16523
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.04740

Collected Steps per Second: 10,921.32707
Overall Steps per Second: 9,139.11272

Timestep Collection Time: 4.57948
Timestep Consumption Time: 0.89304
PPO Batch Consumption Time: 0.03884
Total Iteration Time: 5.47252

Cumulative Model Updates: 1,694
Cumulative Timesteps: 28,359,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.11320
Policy Entropy: 1.20317
Value Function Loss: 7.77792

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.04803

Collected Steps per Second: 10,388.59405
Overall Steps per Second: 8,822.56854

Timestep Collection Time: 4.81586
Timestep Consumption Time: 0.85483
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 5.67068

Cumulative Model Updates: 1,697
Cumulative Timesteps: 28,409,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 28409394...
Checkpoint 28409394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.04411
Policy Entropy: 1.18798
Value Function Loss: 7.60170

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.16326
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.04201

Collected Steps per Second: 10,478.70390
Overall Steps per Second: 9,044.36115

Timestep Collection Time: 4.77254
Timestep Consumption Time: 0.75688
PPO Batch Consumption Time: 0.04603
Total Iteration Time: 5.52941

Cumulative Model Updates: 1,700
Cumulative Timesteps: 28,459,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.99952
Policy Entropy: 1.20495
Value Function Loss: 7.57407

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.15777
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.05083

Collected Steps per Second: 10,194.91415
Overall Steps per Second: 8,666.24086

Timestep Collection Time: 4.90676
Timestep Consumption Time: 0.86552
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 5.77228

Cumulative Model Updates: 1,703
Cumulative Timesteps: 28,509,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 28509428...
Checkpoint 28509428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.84764
Policy Entropy: 1.16984
Value Function Loss: 7.84924

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.18004
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.06755

Collected Steps per Second: 10,519.24089
Overall Steps per Second: 8,975.24122

Timestep Collection Time: 4.75529
Timestep Consumption Time: 0.81805
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 5.57333

Cumulative Model Updates: 1,706
Cumulative Timesteps: 28,559,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.45317
Policy Entropy: 1.18854
Value Function Loss: 8.00538

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.15827
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.07217

Collected Steps per Second: 10,843.43303
Overall Steps per Second: 9,100.55723

Timestep Collection Time: 4.61367
Timestep Consumption Time: 0.88358
PPO Batch Consumption Time: 0.03903
Total Iteration Time: 5.49725

Cumulative Model Updates: 1,709
Cumulative Timesteps: 28,609,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 28609478...
Checkpoint 28609478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.58322
Policy Entropy: 1.17442
Value Function Loss: 7.96647

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.17006
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.07370

Collected Steps per Second: 10,426.50884
Overall Steps per Second: 8,837.19028

Timestep Collection Time: 4.79643
Timestep Consumption Time: 0.86261
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 5.65904

Cumulative Model Updates: 1,712
Cumulative Timesteps: 28,659,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.83809
Policy Entropy: 1.19036
Value Function Loss: 8.13672

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.06876
Value Function Update Magnitude: 0.07860

Collected Steps per Second: 10,531.79547
Overall Steps per Second: 9,024.73969

Timestep Collection Time: 4.75038
Timestep Consumption Time: 0.79327
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.54365

Cumulative Model Updates: 1,715
Cumulative Timesteps: 28,709,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 28709518...
Checkpoint 28709518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.26717
Policy Entropy: 1.17081
Value Function Loss: 8.10883

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.17934
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.06771

Collected Steps per Second: 10,165.04758
Overall Steps per Second: 8,477.63972

Timestep Collection Time: 4.92019
Timestep Consumption Time: 0.97933
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 5.89952

Cumulative Model Updates: 1,718
Cumulative Timesteps: 28,759,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.90884
Policy Entropy: 1.18441
Value Function Loss: 8.43540

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.15042
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.06753

Collected Steps per Second: 10,122.38797
Overall Steps per Second: 8,516.43049

Timestep Collection Time: 4.93955
Timestep Consumption Time: 0.93146
PPO Batch Consumption Time: 0.04852
Total Iteration Time: 5.87100

Cumulative Model Updates: 1,721
Cumulative Timesteps: 28,809,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 28809532...
Checkpoint 28809532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.63706
Policy Entropy: 1.17241
Value Function Loss: 8.24820

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.17302
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 10,287.09413
Overall Steps per Second: 8,717.52385

Timestep Collection Time: 4.86182
Timestep Consumption Time: 0.87536
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 5.73718

Cumulative Model Updates: 1,724
Cumulative Timesteps: 28,859,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.55258
Policy Entropy: 1.19239
Value Function Loss: 8.13845

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.07851

Collected Steps per Second: 9,998.26607
Overall Steps per Second: 8,507.30964

Timestep Collection Time: 5.00367
Timestep Consumption Time: 0.87692
PPO Batch Consumption Time: 0.05068
Total Iteration Time: 5.88059

Cumulative Model Updates: 1,727
Cumulative Timesteps: 28,909,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 28909574...
Checkpoint 28909574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.15001
Policy Entropy: 1.16801
Value Function Loss: 8.17635

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.16622
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.07418

Collected Steps per Second: 10,199.55479
Overall Steps per Second: 8,761.41855

Timestep Collection Time: 4.90453
Timestep Consumption Time: 0.80505
PPO Batch Consumption Time: 0.04794
Total Iteration Time: 5.70958

Cumulative Model Updates: 1,730
Cumulative Timesteps: 28,959,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.22845
Policy Entropy: 1.18695
Value Function Loss: 8.24230

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.15135
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 10,036.61851
Overall Steps per Second: 8,390.69365

Timestep Collection Time: 4.98275
Timestep Consumption Time: 0.97742
PPO Batch Consumption Time: 0.04886
Total Iteration Time: 5.96017

Cumulative Model Updates: 1,733
Cumulative Timesteps: 29,009,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 29009608...
Checkpoint 29009608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.21360
Policy Entropy: 1.17236
Value Function Loss: 8.35454

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.16297
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.07347

Collected Steps per Second: 9,748.75610
Overall Steps per Second: 8,367.05152

Timestep Collection Time: 5.13050
Timestep Consumption Time: 0.84723
PPO Batch Consumption Time: 0.04960
Total Iteration Time: 5.97773

Cumulative Model Updates: 1,736
Cumulative Timesteps: 29,059,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.66196
Policy Entropy: 1.19420
Value Function Loss: 8.05363

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.07655

Collected Steps per Second: 10,264.47354
Overall Steps per Second: 8,675.98321

Timestep Collection Time: 4.87312
Timestep Consumption Time: 0.89222
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 5.76534

Cumulative Model Updates: 1,739
Cumulative Timesteps: 29,109,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 29109644...
Checkpoint 29109644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.35108
Policy Entropy: 1.17377
Value Function Loss: 7.91967

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.16014
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.08405

Collected Steps per Second: 9,488.78380
Overall Steps per Second: 8,110.85699

Timestep Collection Time: 5.26938
Timestep Consumption Time: 0.89520
PPO Batch Consumption Time: 0.04577
Total Iteration Time: 6.16458

Cumulative Model Updates: 1,742
Cumulative Timesteps: 29,159,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.15669
Policy Entropy: 1.18478
Value Function Loss: 8.00093

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.15172
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.07430

Collected Steps per Second: 10,106.25427
Overall Steps per Second: 8,758.11468

Timestep Collection Time: 4.94961
Timestep Consumption Time: 0.76189
PPO Batch Consumption Time: 0.04079
Total Iteration Time: 5.71150

Cumulative Model Updates: 1,745
Cumulative Timesteps: 29,209,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 29209666...
Checkpoint 29209666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.53361
Policy Entropy: 1.16407
Value Function Loss: 8.28087

Mean KL Divergence: 0.02497
SB3 Clip Fraction: 0.16017
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.08248

Collected Steps per Second: 10,170.83070
Overall Steps per Second: 8,614.52299

Timestep Collection Time: 4.91602
Timestep Consumption Time: 0.88813
PPO Batch Consumption Time: 0.04654
Total Iteration Time: 5.80415

Cumulative Model Updates: 1,748
Cumulative Timesteps: 29,259,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.92767
Policy Entropy: 1.18679
Value Function Loss: 8.24474

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.09447

Collected Steps per Second: 10,378.98618
Overall Steps per Second: 8,792.59911

Timestep Collection Time: 4.81781
Timestep Consumption Time: 0.86924
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 5.68706

Cumulative Model Updates: 1,751
Cumulative Timesteps: 29,309,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 29309670...
Checkpoint 29309670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.23412
Policy Entropy: 1.16392
Value Function Loss: 8.21442

Mean KL Divergence: 0.02512
SB3 Clip Fraction: 0.17005
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.10852

Collected Steps per Second: 11,133.68065
Overall Steps per Second: 9,360.80450

Timestep Collection Time: 4.49106
Timestep Consumption Time: 0.85058
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 5.34163

Cumulative Model Updates: 1,754
Cumulative Timesteps: 29,359,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.80040
Policy Entropy: 1.17990
Value Function Loss: 8.11441

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.15408
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.09772

Collected Steps per Second: 11,090.81355
Overall Steps per Second: 9,234.78074

Timestep Collection Time: 4.51094
Timestep Consumption Time: 0.90662
PPO Batch Consumption Time: 0.04871
Total Iteration Time: 5.41756

Cumulative Model Updates: 1,757
Cumulative Timesteps: 29,409,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 29409702...
Checkpoint 29409702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.69715
Policy Entropy: 1.15826
Value Function Loss: 8.22546

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.15877
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.07957

Collected Steps per Second: 10,707.42865
Overall Steps per Second: 9,155.36538

Timestep Collection Time: 4.67115
Timestep Consumption Time: 0.79188
PPO Batch Consumption Time: 0.04856
Total Iteration Time: 5.46303

Cumulative Model Updates: 1,760
Cumulative Timesteps: 29,459,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.29660
Policy Entropy: 1.17547
Value Function Loss: 8.17699

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.06782

Collected Steps per Second: 10,729.66758
Overall Steps per Second: 9,110.52848

Timestep Collection Time: 4.66259
Timestep Consumption Time: 0.82864
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.49123

Cumulative Model Updates: 1,763
Cumulative Timesteps: 29,509,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 29509746...
Checkpoint 29509746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.07533
Policy Entropy: 1.15682
Value Function Loss: 8.00277

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.16661
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.07231

Collected Steps per Second: 9,938.21170
Overall Steps per Second: 8,530.77133

Timestep Collection Time: 5.03189
Timestep Consumption Time: 0.83018
PPO Batch Consumption Time: 0.04800
Total Iteration Time: 5.86207

Cumulative Model Updates: 1,766
Cumulative Timesteps: 29,559,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.25811
Policy Entropy: 1.17528
Value Function Loss: 8.09924

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.16216
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.07918

Collected Steps per Second: 10,268.61057
Overall Steps per Second: 8,669.21605

Timestep Collection Time: 4.86999
Timestep Consumption Time: 0.89847
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 5.76846

Cumulative Model Updates: 1,769
Cumulative Timesteps: 29,609,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 29609762...
Checkpoint 29609762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.27274
Policy Entropy: 1.15766
Value Function Loss: 8.27189

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.16251
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.06154

Collected Steps per Second: 10,521.38088
Overall Steps per Second: 8,815.11564

Timestep Collection Time: 4.75261
Timestep Consumption Time: 0.91992
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 5.67253

Cumulative Model Updates: 1,772
Cumulative Timesteps: 29,659,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.08655
Policy Entropy: 1.17854
Value Function Loss: 8.75379

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.15621
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 10,660.64658
Overall Steps per Second: 9,223.38797

Timestep Collection Time: 4.69202
Timestep Consumption Time: 0.73115
PPO Batch Consumption Time: 0.04504
Total Iteration Time: 5.42317

Cumulative Model Updates: 1,775
Cumulative Timesteps: 29,709,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 29709786...
Checkpoint 29709786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.88071
Policy Entropy: 1.16232
Value Function Loss: 8.71159

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.07148

Collected Steps per Second: 10,710.70770
Overall Steps per Second: 9,141.29888

Timestep Collection Time: 4.67009
Timestep Consumption Time: 0.80178
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.47187

Cumulative Model Updates: 1,778
Cumulative Timesteps: 29,759,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.93394
Policy Entropy: 1.18711
Value Function Loss: 8.58139

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.15135
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.06451

Collected Steps per Second: 10,790.19560
Overall Steps per Second: 9,016.93515

Timestep Collection Time: 4.63421
Timestep Consumption Time: 0.91136
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 5.54557

Cumulative Model Updates: 1,781
Cumulative Timesteps: 29,809,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 29809810...
Checkpoint 29809810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.91598
Policy Entropy: 1.16633
Value Function Loss: 8.17559

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.17311
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.06620

Collected Steps per Second: 10,866.32104
Overall Steps per Second: 9,218.60921

Timestep Collection Time: 4.60156
Timestep Consumption Time: 0.82247
PPO Batch Consumption Time: 0.03965
Total Iteration Time: 5.42403

Cumulative Model Updates: 1,784
Cumulative Timesteps: 29,859,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.91845
Policy Entropy: 1.18098
Value Function Loss: 8.12148

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.06249

Collected Steps per Second: 10,697.71237
Overall Steps per Second: 9,143.81338

Timestep Collection Time: 4.67670
Timestep Consumption Time: 0.79476
PPO Batch Consumption Time: 0.04469
Total Iteration Time: 5.47146

Cumulative Model Updates: 1,787
Cumulative Timesteps: 29,909,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 29909842...
Checkpoint 29909842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.48663
Policy Entropy: 1.16126
Value Function Loss: 8.15626

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.16531
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.07280

Collected Steps per Second: 10,707.80125
Overall Steps per Second: 9,236.81478

Timestep Collection Time: 4.67155
Timestep Consumption Time: 0.74396
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 5.41550

Cumulative Model Updates: 1,790
Cumulative Timesteps: 29,959,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.15092
Policy Entropy: 1.17876
Value Function Loss: 7.95583

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.07170

Collected Steps per Second: 10,703.84293
Overall Steps per Second: 9,104.63500

Timestep Collection Time: 4.67384
Timestep Consumption Time: 0.82095
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 5.49478

Cumulative Model Updates: 1,793
Cumulative Timesteps: 30,009,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 30009892...
Checkpoint 30009892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.95078
Policy Entropy: 1.15123
Value Function Loss: 7.76056

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.17027
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.07017

Collected Steps per Second: 10,422.71579
Overall Steps per Second: 8,921.33920

Timestep Collection Time: 4.79856
Timestep Consumption Time: 0.80755
PPO Batch Consumption Time: 0.04656
Total Iteration Time: 5.60611

Cumulative Model Updates: 1,796
Cumulative Timesteps: 30,059,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.73281
Policy Entropy: 1.17261
Value Function Loss: 7.77401

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.15864
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.04734

Collected Steps per Second: 10,417.47227
Overall Steps per Second: 8,809.24808

Timestep Collection Time: 4.80232
Timestep Consumption Time: 0.87672
PPO Batch Consumption Time: 0.04588
Total Iteration Time: 5.67903

Cumulative Model Updates: 1,799
Cumulative Timesteps: 30,109,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 30109934...
Checkpoint 30109934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.54831
Policy Entropy: 1.15520
Value Function Loss: 7.70152

Mean KL Divergence: 0.02491
SB3 Clip Fraction: 0.17501
Policy Update Magnitude: 0.04212
Value Function Update Magnitude: 0.05115

Collected Steps per Second: 10,700.00027
Overall Steps per Second: 9,070.69671

Timestep Collection Time: 4.67551
Timestep Consumption Time: 0.83983
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 5.51534

Cumulative Model Updates: 1,802
Cumulative Timesteps: 30,159,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.50638
Policy Entropy: 1.18165
Value Function Loss: 7.83928

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.16042
Policy Update Magnitude: 0.04348
Value Function Update Magnitude: 0.07030

Collected Steps per Second: 10,789.14497
Overall Steps per Second: 9,306.02499

Timestep Collection Time: 4.63447
Timestep Consumption Time: 0.73861
PPO Batch Consumption Time: 0.04415
Total Iteration Time: 5.37308

Cumulative Model Updates: 1,805
Cumulative Timesteps: 30,209,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 30209964...
Checkpoint 30209964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.35137
Policy Entropy: 1.15711
Value Function Loss: 7.90540

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.07398

Collected Steps per Second: 10,626.66322
Overall Steps per Second: 9,034.25171

Timestep Collection Time: 4.70778
Timestep Consumption Time: 0.82981
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.53759

Cumulative Model Updates: 1,808
Cumulative Timesteps: 30,259,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.19747
Policy Entropy: 1.17838
Value Function Loss: 8.09367

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.06476

Collected Steps per Second: 10,654.50469
Overall Steps per Second: 9,067.50698

Timestep Collection Time: 4.69529
Timestep Consumption Time: 0.82177
PPO Batch Consumption Time: 0.04559
Total Iteration Time: 5.51706

Cumulative Model Updates: 1,811
Cumulative Timesteps: 30,310,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 30310018...
Checkpoint 30310018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171.42084
Policy Entropy: 1.15642
Value Function Loss: 8.17303

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.16905
Policy Update Magnitude: 0.06355
Value Function Update Magnitude: 0.05384

Collected Steps per Second: 10,474.32154
Overall Steps per Second: 9,038.13714

Timestep Collection Time: 4.77415
Timestep Consumption Time: 0.75863
PPO Batch Consumption Time: 0.04042
Total Iteration Time: 5.53278

Cumulative Model Updates: 1,814
Cumulative Timesteps: 30,360,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.93782
Policy Entropy: 1.17198
Value Function Loss: 8.23930

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.04736

Collected Steps per Second: 10,811.82251
Overall Steps per Second: 9,161.27261

Timestep Collection Time: 4.62586
Timestep Consumption Time: 0.83342
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 5.45929

Cumulative Model Updates: 1,817
Cumulative Timesteps: 30,410,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 30410038...
Checkpoint 30410038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.18580
Policy Entropy: 1.14996
Value Function Loss: 8.00516

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.17338
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 10,903.24347
Overall Steps per Second: 9,411.41748

Timestep Collection Time: 4.58818
Timestep Consumption Time: 0.72728
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.31546

Cumulative Model Updates: 1,820
Cumulative Timesteps: 30,460,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.11633
Policy Entropy: 1.17401
Value Function Loss: 7.84175

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.15097
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.06065

Collected Steps per Second: 10,778.77768
Overall Steps per Second: 9,150.80309

Timestep Collection Time: 4.63874
Timestep Consumption Time: 0.82526
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.46400

Cumulative Model Updates: 1,823
Cumulative Timesteps: 30,510,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 30510064...
Checkpoint 30510064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.68482
Policy Entropy: 1.15646
Value Function Loss: 7.79542

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.16962
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.05509

Collected Steps per Second: 10,772.07380
Overall Steps per Second: 9,174.29493

Timestep Collection Time: 4.64256
Timestep Consumption Time: 0.80854
PPO Batch Consumption Time: 0.03956
Total Iteration Time: 5.45110

Cumulative Model Updates: 1,826
Cumulative Timesteps: 30,560,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.94902
Policy Entropy: 1.17306
Value Function Loss: 7.89511

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14947
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.05362

Collected Steps per Second: 10,549.74615
Overall Steps per Second: 9,052.84804

Timestep Collection Time: 4.74059
Timestep Consumption Time: 0.78386
PPO Batch Consumption Time: 0.03863
Total Iteration Time: 5.52445

Cumulative Model Updates: 1,829
Cumulative Timesteps: 30,610,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 30610086...
Checkpoint 30610086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.88317
Policy Entropy: 1.15878
Value Function Loss: 7.88996

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.06661

Collected Steps per Second: 10,219.97961
Overall Steps per Second: 8,701.23706

Timestep Collection Time: 4.89512
Timestep Consumption Time: 0.85441
PPO Batch Consumption Time: 0.04605
Total Iteration Time: 5.74953

Cumulative Model Updates: 1,832
Cumulative Timesteps: 30,660,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.95750
Policy Entropy: 1.17729
Value Function Loss: 8.19767

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.16345
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.06571

Collected Steps per Second: 10,741.03153
Overall Steps per Second: 9,155.77591

Timestep Collection Time: 4.65635
Timestep Consumption Time: 0.80621
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.46256

Cumulative Model Updates: 1,835
Cumulative Timesteps: 30,710,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 30710128...
Checkpoint 30710128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.03069
Policy Entropy: 1.16268
Value Function Loss: 8.19079

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.15340
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.06177

Collected Steps per Second: 10,762.11054
Overall Steps per Second: 9,132.43927

Timestep Collection Time: 4.64760
Timestep Consumption Time: 0.82936
PPO Batch Consumption Time: 0.04636
Total Iteration Time: 5.47696

Cumulative Model Updates: 1,838
Cumulative Timesteps: 30,760,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.02082
Policy Entropy: 1.17213
Value Function Loss: 8.16551

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.16645
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.05560

Collected Steps per Second: 10,617.91257
Overall Steps per Second: 9,060.26240

Timestep Collection Time: 4.70959
Timestep Consumption Time: 0.80968
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.51927

Cumulative Model Updates: 1,841
Cumulative Timesteps: 30,810,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 30810152...
Checkpoint 30810152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.92076
Policy Entropy: 1.15752
Value Function Loss: 7.65240

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14464
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.06061

Collected Steps per Second: 10,652.15385
Overall Steps per Second: 9,151.51152

Timestep Collection Time: 4.69595
Timestep Consumption Time: 0.77003
PPO Batch Consumption Time: 0.04582
Total Iteration Time: 5.46598

Cumulative Model Updates: 1,844
Cumulative Timesteps: 30,860,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.55682
Policy Entropy: 1.17808
Value Function Loss: 7.66869

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.15333
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.08589

Collected Steps per Second: 10,595.91648
Overall Steps per Second: 9,008.60344

Timestep Collection Time: 4.71955
Timestep Consumption Time: 0.83158
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 5.55114

Cumulative Model Updates: 1,847
Cumulative Timesteps: 30,910,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 30910182...
Checkpoint 30910182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.97796
Policy Entropy: 1.15695
Value Function Loss: 7.88961

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.17549
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.08652

Collected Steps per Second: 10,626.97834
Overall Steps per Second: 8,978.04756

Timestep Collection Time: 4.70651
Timestep Consumption Time: 0.86441
PPO Batch Consumption Time: 0.04770
Total Iteration Time: 5.57092

Cumulative Model Updates: 1,850
Cumulative Timesteps: 30,960,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.12307
Policy Entropy: 1.17917
Value Function Loss: 7.99242

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.08374

Collected Steps per Second: 10,884.65314
Overall Steps per Second: 9,192.14522

Timestep Collection Time: 4.59509
Timestep Consumption Time: 0.84607
PPO Batch Consumption Time: 0.03906
Total Iteration Time: 5.44117

Cumulative Model Updates: 1,853
Cumulative Timesteps: 31,010,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 31010214...
Checkpoint 31010214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.38109
Policy Entropy: 1.15740
Value Function Loss: 7.96924

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.18073
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.08814

Collected Steps per Second: 10,665.39721
Overall Steps per Second: 9,003.15182

Timestep Collection Time: 4.69031
Timestep Consumption Time: 0.86597
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 5.55628

Cumulative Model Updates: 1,856
Cumulative Timesteps: 31,060,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.37707
Policy Entropy: 1.18306
Value Function Loss: 7.86893

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.09101

Collected Steps per Second: 10,719.21440
Overall Steps per Second: 9,191.20637

Timestep Collection Time: 4.66489
Timestep Consumption Time: 0.77552
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 5.44042

Cumulative Model Updates: 1,859
Cumulative Timesteps: 31,110,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 31110242...
Checkpoint 31110242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.00141
Policy Entropy: 1.16127
Value Function Loss: 7.92745

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.16041
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.09663

Collected Steps per Second: 10,658.56300
Overall Steps per Second: 9,008.25912

Timestep Collection Time: 4.69200
Timestep Consumption Time: 0.85957
PPO Batch Consumption Time: 0.04560
Total Iteration Time: 5.55157

Cumulative Model Updates: 1,862
Cumulative Timesteps: 31,160,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.50773
Policy Entropy: 1.17657
Value Function Loss: 7.82547

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.15915
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.11599

Collected Steps per Second: 10,089.32955
Overall Steps per Second: 8,652.81266

Timestep Collection Time: 4.95791
Timestep Consumption Time: 0.82310
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.78101

Cumulative Model Updates: 1,865
Cumulative Timesteps: 31,210,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 31210274...
Checkpoint 31210274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.20823
Policy Entropy: 1.15372
Value Function Loss: 7.59914

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.14829
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 10,765.46237
Overall Steps per Second: 9,113.85726

Timestep Collection Time: 4.64764
Timestep Consumption Time: 0.84224
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.48988

Cumulative Model Updates: 1,868
Cumulative Timesteps: 31,260,308

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.18669
Policy Entropy: 1.16983
Value Function Loss: 7.50746

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.15826
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.09008

Collected Steps per Second: 10,696.46344
Overall Steps per Second: 9,064.94416

Timestep Collection Time: 4.67519
Timestep Consumption Time: 0.84145
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 5.51664

Cumulative Model Updates: 1,871
Cumulative Timesteps: 31,310,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 31310316...
Checkpoint 31310316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.85800
Policy Entropy: 1.14877
Value Function Loss: 7.33421

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.07513

Collected Steps per Second: 10,646.08676
Overall Steps per Second: 9,119.59104

Timestep Collection Time: 4.69900
Timestep Consumption Time: 0.78655
PPO Batch Consumption Time: 0.04691
Total Iteration Time: 5.48555

Cumulative Model Updates: 1,874
Cumulative Timesteps: 31,360,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.27373
Policy Entropy: 1.17786
Value Function Loss: 7.24877

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.07851

Collected Steps per Second: 10,498.60083
Overall Steps per Second: 8,823.87014

Timestep Collection Time: 4.76368
Timestep Consumption Time: 0.90413
PPO Batch Consumption Time: 0.04919
Total Iteration Time: 5.66781

Cumulative Model Updates: 1,877
Cumulative Timesteps: 31,410,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 31410354...
Checkpoint 31410354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.19852
Policy Entropy: 1.15922
Value Function Loss: 7.51253

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.15682
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.07168

Collected Steps per Second: 10,353.60477
Overall Steps per Second: 8,822.07827

Timestep Collection Time: 4.83059
Timestep Consumption Time: 0.83860
PPO Batch Consumption Time: 0.04585
Total Iteration Time: 5.66919

Cumulative Model Updates: 1,880
Cumulative Timesteps: 31,460,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.63519
Policy Entropy: 1.18400
Value Function Loss: 7.43247

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.07112

Collected Steps per Second: 10,764.18574
Overall Steps per Second: 9,104.26384

Timestep Collection Time: 4.64689
Timestep Consumption Time: 0.84724
PPO Batch Consumption Time: 0.03956
Total Iteration Time: 5.49413

Cumulative Model Updates: 1,883
Cumulative Timesteps: 31,510,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 31510388...
Checkpoint 31510388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171.13489
Policy Entropy: 1.15704
Value Function Loss: 7.49054

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.15648
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.06667

Collected Steps per Second: 10,674.06200
Overall Steps per Second: 9,065.82140

Timestep Collection Time: 4.68519
Timestep Consumption Time: 0.83113
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 5.51632

Cumulative Model Updates: 1,886
Cumulative Timesteps: 31,560,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.83881
Policy Entropy: 1.18063
Value Function Loss: 7.14177

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.05921

Collected Steps per Second: 10,933.43472
Overall Steps per Second: 9,364.81792

Timestep Collection Time: 4.57368
Timestep Consumption Time: 0.76610
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 5.33977

Cumulative Model Updates: 1,889
Cumulative Timesteps: 31,610,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 31610404...
Checkpoint 31610404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.08771
Policy Entropy: 1.16659
Value Function Loss: 7.23386

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.06187

Collected Steps per Second: 10,919.15980
Overall Steps per Second: 9,238.69040

Timestep Collection Time: 4.58167
Timestep Consumption Time: 0.83338
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 5.41505

Cumulative Model Updates: 1,892
Cumulative Timesteps: 31,660,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.90161
Policy Entropy: 1.17657
Value Function Loss: 7.57751

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.06038

Collected Steps per Second: 10,695.18122
Overall Steps per Second: 8,921.09756

Timestep Collection Time: 4.67706
Timestep Consumption Time: 0.93010
PPO Batch Consumption Time: 0.04470
Total Iteration Time: 5.60716

Cumulative Model Updates: 1,895
Cumulative Timesteps: 31,710,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 31710454...
Checkpoint 31710454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.70133
Policy Entropy: 1.16107
Value Function Loss: 7.66251

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 10,874.37668
Overall Steps per Second: 9,194.45408

Timestep Collection Time: 4.59907
Timestep Consumption Time: 0.84030
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 5.43937

Cumulative Model Updates: 1,898
Cumulative Timesteps: 31,760,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.21844
Policy Entropy: 1.17651
Value Function Loss: 7.80185

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.06723

Collected Steps per Second: 10,754.05862
Overall Steps per Second: 9,128.20728

Timestep Collection Time: 4.64959
Timestep Consumption Time: 0.82815
PPO Batch Consumption Time: 0.04289
Total Iteration Time: 5.47775

Cumulative Model Updates: 1,901
Cumulative Timesteps: 31,810,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 31810468...
Checkpoint 31810468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.12235
Policy Entropy: 1.16112
Value Function Loss: 7.44846

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.16557
Policy Update Magnitude: 0.06697
Value Function Update Magnitude: 0.06203

Collected Steps per Second: 10,519.83067
Overall Steps per Second: 9,005.82077

Timestep Collection Time: 4.75388
Timestep Consumption Time: 0.79920
PPO Batch Consumption Time: 0.04741
Total Iteration Time: 5.55308

Cumulative Model Updates: 1,904
Cumulative Timesteps: 31,860,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.71636
Policy Entropy: 1.16919
Value Function Loss: 7.60469

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.04859

Collected Steps per Second: 10,613.17385
Overall Steps per Second: 8,985.35709

Timestep Collection Time: 4.71376
Timestep Consumption Time: 0.85396
PPO Batch Consumption Time: 0.04440
Total Iteration Time: 5.56773

Cumulative Model Updates: 1,907
Cumulative Timesteps: 31,910,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 31910506...
Checkpoint 31910506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.27533
Policy Entropy: 1.14847
Value Function Loss: 7.72257

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.15379
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.04283

Collected Steps per Second: 10,569.43346
Overall Steps per Second: 8,949.33123

Timestep Collection Time: 4.73119
Timestep Consumption Time: 0.85649
PPO Batch Consumption Time: 0.04686
Total Iteration Time: 5.58768

Cumulative Model Updates: 1,910
Cumulative Timesteps: 31,960,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.19412
Policy Entropy: 1.16526
Value Function Loss: 8.11259

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.04040

Collected Steps per Second: 10,340.09303
Overall Steps per Second: 8,876.59963

Timestep Collection Time: 4.83787
Timestep Consumption Time: 0.79762
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 5.63549

Cumulative Model Updates: 1,913
Cumulative Timesteps: 32,010,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 32010536...
Checkpoint 32010536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.76827
Policy Entropy: 1.14910
Value Function Loss: 7.75154

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.18479
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.04786

Collected Steps per Second: 10,663.83617
Overall Steps per Second: 9,143.21482

Timestep Collection Time: 4.69024
Timestep Consumption Time: 0.78004
PPO Batch Consumption Time: 0.04004
Total Iteration Time: 5.47029

Cumulative Model Updates: 1,916
Cumulative Timesteps: 32,060,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.60311
Policy Entropy: 1.17007
Value Function Loss: 7.48111

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.15507
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.05530

Collected Steps per Second: 10,615.91986
Overall Steps per Second: 9,128.99324

Timestep Collection Time: 4.71217
Timestep Consumption Time: 0.76752
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.47968

Cumulative Model Updates: 1,919
Cumulative Timesteps: 32,110,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 32110576...
Checkpoint 32110576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.18708
Policy Entropy: 1.16242
Value Function Loss: 7.40567

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 10,610.51589
Overall Steps per Second: 9,067.15865

Timestep Collection Time: 4.71513
Timestep Consumption Time: 0.80258
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.51772

Cumulative Model Updates: 1,922
Cumulative Timesteps: 32,160,606

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.67925
Policy Entropy: 1.17878
Value Function Loss: 7.26374

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.15310
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.04724

Collected Steps per Second: 10,618.07170
Overall Steps per Second: 9,018.33578

Timestep Collection Time: 4.71140
Timestep Consumption Time: 0.83574
PPO Batch Consumption Time: 0.04080
Total Iteration Time: 5.54714

Cumulative Model Updates: 1,925
Cumulative Timesteps: 32,210,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 32210632...
Checkpoint 32210632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.60687
Policy Entropy: 1.15917
Value Function Loss: 7.25174

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.14967
Policy Update Magnitude: 0.06634
Value Function Update Magnitude: 0.03936

Collected Steps per Second: 10,616.71495
Overall Steps per Second: 8,911.85934

Timestep Collection Time: 4.70974
Timestep Consumption Time: 0.90098
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 5.61073

Cumulative Model Updates: 1,928
Cumulative Timesteps: 32,260,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.17869
Policy Entropy: 1.15960
Value Function Loss: 7.33338

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.15251
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.06663

Collected Steps per Second: 10,612.66339
Overall Steps per Second: 8,885.40072

Timestep Collection Time: 4.71493
Timestep Consumption Time: 0.91655
PPO Batch Consumption Time: 0.04475
Total Iteration Time: 5.63148

Cumulative Model Updates: 1,931
Cumulative Timesteps: 32,310,672

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 32310672...
Checkpoint 32310672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.90589
Policy Entropy: 1.14726
Value Function Loss: 7.46263

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.05632

Collected Steps per Second: 10,671.19139
Overall Steps per Second: 9,106.96291

Timestep Collection Time: 4.68607
Timestep Consumption Time: 0.80489
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 5.49096

Cumulative Model Updates: 1,934
Cumulative Timesteps: 32,360,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.07694
Policy Entropy: 1.17013
Value Function Loss: 7.45941

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.05303

Collected Steps per Second: 10,482.10405
Overall Steps per Second: 8,887.61802

Timestep Collection Time: 4.77042
Timestep Consumption Time: 0.85584
PPO Batch Consumption Time: 0.04814
Total Iteration Time: 5.62625

Cumulative Model Updates: 1,937
Cumulative Timesteps: 32,410,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 32410682...
Checkpoint 32410682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.00900
Policy Entropy: 1.16274
Value Function Loss: 7.29337

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.15333
Policy Update Magnitude: 0.07103
Value Function Update Magnitude: 0.05224

Collected Steps per Second: 10,440.76881
Overall Steps per Second: 8,952.36813

Timestep Collection Time: 4.78969
Timestep Consumption Time: 0.79632
PPO Batch Consumption Time: 0.03925
Total Iteration Time: 5.58601

Cumulative Model Updates: 1,940
Cumulative Timesteps: 32,460,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.23499
Policy Entropy: 1.18684
Value Function Loss: 7.31776

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.15594
Policy Update Magnitude: 0.07377
Value Function Update Magnitude: 0.05682

Collected Steps per Second: 10,757.14645
Overall Steps per Second: 9,109.98874

Timestep Collection Time: 4.64956
Timestep Consumption Time: 0.84068
PPO Batch Consumption Time: 0.04293
Total Iteration Time: 5.49024

Cumulative Model Updates: 1,943
Cumulative Timesteps: 32,510,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 32510706...
Checkpoint 32510706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.94465
Policy Entropy: 1.16490
Value Function Loss: 7.28099

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.16173
Policy Update Magnitude: 0.06432
Value Function Update Magnitude: 0.06324

Collected Steps per Second: 10,350.33147
Overall Steps per Second: 8,762.37382

Timestep Collection Time: 4.83289
Timestep Consumption Time: 0.87584
PPO Batch Consumption Time: 0.04178
Total Iteration Time: 5.70873

Cumulative Model Updates: 1,946
Cumulative Timesteps: 32,560,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.26961
Policy Entropy: 1.17034
Value Function Loss: 7.08779

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.06516

Collected Steps per Second: 11,177.88593
Overall Steps per Second: 9,292.53716

Timestep Collection Time: 4.47562
Timestep Consumption Time: 0.90805
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 5.38368

Cumulative Model Updates: 1,949
Cumulative Timesteps: 32,610,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 32610756...
Checkpoint 32610756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.28127
Policy Entropy: 1.14765
Value Function Loss: 7.13933

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.15273
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.06254

Collected Steps per Second: 10,976.45284
Overall Steps per Second: 9,320.90275

Timestep Collection Time: 4.55630
Timestep Consumption Time: 0.80928
PPO Batch Consumption Time: 0.04569
Total Iteration Time: 5.36557

Cumulative Model Updates: 1,952
Cumulative Timesteps: 32,660,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.56939
Policy Entropy: 1.15643
Value Function Loss: 7.17843

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.04964

Collected Steps per Second: 10,817.68097
Overall Steps per Second: 9,287.94788

Timestep Collection Time: 4.62447
Timestep Consumption Time: 0.76165
PPO Batch Consumption Time: 0.04595
Total Iteration Time: 5.38612

Cumulative Model Updates: 1,955
Cumulative Timesteps: 32,710,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 32710794...
Checkpoint 32710794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.47666
Policy Entropy: 1.15593
Value Function Loss: 7.36445

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.16006
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.05392

Collected Steps per Second: 10,543.37249
Overall Steps per Second: 8,943.87877

Timestep Collection Time: 4.74270
Timestep Consumption Time: 0.84817
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 5.59086

Cumulative Model Updates: 1,958
Cumulative Timesteps: 32,760,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.51877
Policy Entropy: 1.17754
Value Function Loss: 7.27266

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.04330

Collected Steps per Second: 10,311.40773
Overall Steps per Second: 8,783.10349

Timestep Collection Time: 4.85113
Timestep Consumption Time: 0.84412
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 5.69525

Cumulative Model Updates: 1,961
Cumulative Timesteps: 32,810,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 32810820...
Checkpoint 32810820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.98305
Policy Entropy: 1.16245
Value Function Loss: 7.29973

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.16875
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.05527

Collected Steps per Second: 10,773.32175
Overall Steps per Second: 9,011.81826

Timestep Collection Time: 4.64109
Timestep Consumption Time: 0.90718
PPO Batch Consumption Time: 0.04777
Total Iteration Time: 5.54827

Cumulative Model Updates: 1,964
Cumulative Timesteps: 32,860,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.35360
Policy Entropy: 1.16726
Value Function Loss: 7.34692

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14301
Policy Update Magnitude: 0.04247
Value Function Update Magnitude: 0.04775

Collected Steps per Second: 10,539.74988
Overall Steps per Second: 8,954.49062

Timestep Collection Time: 4.74527
Timestep Consumption Time: 0.84008
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.58535

Cumulative Model Updates: 1,967
Cumulative Timesteps: 32,910,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 32910834...
Checkpoint 32910834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.23516
Policy Entropy: 1.14805
Value Function Loss: 7.25516

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.14797
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.04373

Collected Steps per Second: 10,754.00514
Overall Steps per Second: 9,170.07519

Timestep Collection Time: 4.64980
Timestep Consumption Time: 0.80315
PPO Batch Consumption Time: 0.04391
Total Iteration Time: 5.45295

Cumulative Model Updates: 1,970
Cumulative Timesteps: 32,960,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.16075
Policy Entropy: 1.16960
Value Function Loss: 7.15835

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.03772

Collected Steps per Second: 10,759.25566
Overall Steps per Second: 9,112.18385

Timestep Collection Time: 4.64883
Timestep Consumption Time: 0.84030
PPO Batch Consumption Time: 0.04432
Total Iteration Time: 5.48913

Cumulative Model Updates: 1,973
Cumulative Timesteps: 33,010,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 33010856...
Checkpoint 33010856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.43449
Policy Entropy: 1.15845
Value Function Loss: 7.16945

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.04073

Collected Steps per Second: 10,838.99021
Overall Steps per Second: 9,055.93351

Timestep Collection Time: 4.61353
Timestep Consumption Time: 0.90838
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 5.52190

Cumulative Model Updates: 1,976
Cumulative Timesteps: 33,060,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.30679
Policy Entropy: 1.17891
Value Function Loss: 7.21897

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.03716

Collected Steps per Second: 10,851.96048
Overall Steps per Second: 9,162.37994

Timestep Collection Time: 4.60894
Timestep Consumption Time: 0.84991
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 5.45884

Cumulative Model Updates: 1,979
Cumulative Timesteps: 33,110,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 33110878...
Checkpoint 33110878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.90704
Policy Entropy: 1.16680
Value Function Loss: 6.94287

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.03367

Collected Steps per Second: 10,782.01092
Overall Steps per Second: 9,135.36864

Timestep Collection Time: 4.63939
Timestep Consumption Time: 0.83625
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.47564

Cumulative Model Updates: 1,982
Cumulative Timesteps: 33,160,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.78420
Policy Entropy: 1.18442
Value Function Loss: 6.86014

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.03325

Collected Steps per Second: 10,623.37478
Overall Steps per Second: 9,139.70412

Timestep Collection Time: 4.71018
Timestep Consumption Time: 0.76462
PPO Batch Consumption Time: 0.03943
Total Iteration Time: 5.47479

Cumulative Model Updates: 1,985
Cumulative Timesteps: 33,210,938

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 33210938...
Checkpoint 33210938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.91820
Policy Entropy: 1.16579
Value Function Loss: 6.60210

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.03047

Collected Steps per Second: 10,721.34676
Overall Steps per Second: 9,074.81199

Timestep Collection Time: 4.66397
Timestep Consumption Time: 0.84623
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.51020

Cumulative Model Updates: 1,988
Cumulative Timesteps: 33,260,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.48546
Policy Entropy: 1.17173
Value Function Loss: 6.85042

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.03383

Collected Steps per Second: 10,594.61728
Overall Steps per Second: 9,022.42055

Timestep Collection Time: 4.72127
Timestep Consumption Time: 0.82270
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.54397

Cumulative Model Updates: 1,991
Cumulative Timesteps: 33,310,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 33310962...
Checkpoint 33310962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.71199
Policy Entropy: 1.15747
Value Function Loss: 6.83046

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.03431

Collected Steps per Second: 10,398.88735
Overall Steps per Second: 8,834.10423

Timestep Collection Time: 4.80878
Timestep Consumption Time: 0.85178
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 5.66056

Cumulative Model Updates: 1,994
Cumulative Timesteps: 33,360,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.88369
Policy Entropy: 1.16447
Value Function Loss: 7.08220

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.03449

Collected Steps per Second: 10,640.88220
Overall Steps per Second: 8,967.00388

Timestep Collection Time: 4.70224
Timestep Consumption Time: 0.87777
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 5.58001

Cumulative Model Updates: 1,997
Cumulative Timesteps: 33,411,004

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 33411004...
Checkpoint 33411004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.59354
Policy Entropy: 1.15433
Value Function Loss: 6.87487

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.03432

Collected Steps per Second: 10,721.47096
Overall Steps per Second: 9,202.31039

Timestep Collection Time: 4.66447
Timestep Consumption Time: 0.77003
PPO Batch Consumption Time: 0.03864
Total Iteration Time: 5.43450

Cumulative Model Updates: 2,000
Cumulative Timesteps: 33,461,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.10061
Policy Entropy: 1.16985
Value Function Loss: 7.05496

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.03511

Collected Steps per Second: 10,550.52305
Overall Steps per Second: 8,933.84410

Timestep Collection Time: 4.73929
Timestep Consumption Time: 0.85763
PPO Batch Consumption Time: 0.04132
Total Iteration Time: 5.59692

Cumulative Model Updates: 2,003
Cumulative Timesteps: 33,511,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 33511016...
Checkpoint 33511016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.03568
Policy Entropy: 1.15930
Value Function Loss: 6.71987

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.15775
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.03552

Collected Steps per Second: 11,265.18002
Overall Steps per Second: 9,479.21670

Timestep Collection Time: 4.44041
Timestep Consumption Time: 0.83661
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 5.27702

Cumulative Model Updates: 2,006
Cumulative Timesteps: 33,561,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.43656
Policy Entropy: 1.16315
Value Function Loss: 7.10492

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.03907

Collected Steps per Second: 11,228.26642
Overall Steps per Second: 9,324.57501

Timestep Collection Time: 4.45412
Timestep Consumption Time: 0.90935
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 5.36346

Cumulative Model Updates: 2,009
Cumulative Timesteps: 33,611,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 33611050...
Checkpoint 33611050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.34850
Policy Entropy: 1.14166
Value Function Loss: 7.16264

Mean KL Divergence: 0.02366
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.03245

Collected Steps per Second: 11,146.77994
Overall Steps per Second: 9,234.29514

Timestep Collection Time: 4.48596
Timestep Consumption Time: 0.92907
PPO Batch Consumption Time: 0.03933
Total Iteration Time: 5.41503

Cumulative Model Updates: 2,012
Cumulative Timesteps: 33,661,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.88129
Policy Entropy: 1.15795
Value Function Loss: 7.56896

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.05097

Collected Steps per Second: 10,975.67493
Overall Steps per Second: 9,380.07770

Timestep Collection Time: 4.55808
Timestep Consumption Time: 0.77535
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.33343

Cumulative Model Updates: 2,015
Cumulative Timesteps: 33,711,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 33711082...
Checkpoint 33711082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.30385
Policy Entropy: 1.14909
Value Function Loss: 7.37873

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.04170

Collected Steps per Second: 11,034.84975
Overall Steps per Second: 9,203.58693

Timestep Collection Time: 4.53110
Timestep Consumption Time: 0.90157
PPO Batch Consumption Time: 0.04871
Total Iteration Time: 5.43266

Cumulative Model Updates: 2,018
Cumulative Timesteps: 33,761,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.34286
Policy Entropy: 1.16780
Value Function Loss: 7.29920

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.03845

Collected Steps per Second: 10,933.84510
Overall Steps per Second: 9,263.64405

Timestep Collection Time: 4.57314
Timestep Consumption Time: 0.82452
PPO Batch Consumption Time: 0.04729
Total Iteration Time: 5.39766

Cumulative Model Updates: 2,021
Cumulative Timesteps: 33,811,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 33811084...
Checkpoint 33811084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.30483
Policy Entropy: 1.15341
Value Function Loss: 7.07724

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.16123
Policy Update Magnitude: 0.06400
Value Function Update Magnitude: 0.04241

Collected Steps per Second: 10,887.13094
Overall Steps per Second: 9,101.00673

Timestep Collection Time: 4.59386
Timestep Consumption Time: 0.90157
PPO Batch Consumption Time: 0.04691
Total Iteration Time: 5.49544

Cumulative Model Updates: 2,024
Cumulative Timesteps: 33,861,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.51129
Policy Entropy: 1.17583
Value Function Loss: 6.94661

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.03849

Collected Steps per Second: 10,275.36766
Overall Steps per Second: 8,798.44130

Timestep Collection Time: 4.86970
Timestep Consumption Time: 0.81744
PPO Batch Consumption Time: 0.04478
Total Iteration Time: 5.68714

Cumulative Model Updates: 2,027
Cumulative Timesteps: 33,911,136

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 33911136...
Checkpoint 33911136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.10262
Policy Entropy: 1.15347
Value Function Loss: 6.89439

Mean KL Divergence: 0.02561
SB3 Clip Fraction: 0.16571
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.04094

Collected Steps per Second: 10,570.04081
Overall Steps per Second: 9,134.77012

Timestep Collection Time: 4.73300
Timestep Consumption Time: 0.74366
PPO Batch Consumption Time: 0.04589
Total Iteration Time: 5.47666

Cumulative Model Updates: 2,030
Cumulative Timesteps: 33,961,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.20075
Policy Entropy: 1.16103
Value Function Loss: 7.04864

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.03767

Collected Steps per Second: 10,613.86969
Overall Steps per Second: 8,992.13983

Timestep Collection Time: 4.71364
Timestep Consumption Time: 0.85010
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 5.56375

Cumulative Model Updates: 2,033
Cumulative Timesteps: 34,011,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 34011194...
Checkpoint 34011194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.32146
Policy Entropy: 1.14114
Value Function Loss: 7.16860

Mean KL Divergence: 0.02562
SB3 Clip Fraction: 0.16069
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.04612

Collected Steps per Second: 10,471.27499
Overall Steps per Second: 8,946.81890

Timestep Collection Time: 4.77707
Timestep Consumption Time: 0.81397
PPO Batch Consumption Time: 0.04606
Total Iteration Time: 5.59104

Cumulative Model Updates: 2,036
Cumulative Timesteps: 34,061,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.67955
Policy Entropy: 1.16825
Value Function Loss: 7.03045

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.14783
Policy Update Magnitude: 0.06567
Value Function Update Magnitude: 0.03509

Collected Steps per Second: 10,941.75423
Overall Steps per Second: 9,192.62284

Timestep Collection Time: 4.57057
Timestep Consumption Time: 0.86967
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 5.44023

Cumulative Model Updates: 2,039
Cumulative Timesteps: 34,111,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 34111226...
Checkpoint 34111226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.65366
Policy Entropy: 1.15973
Value Function Loss: 6.89621

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.04375

Collected Steps per Second: 10,174.57022
Overall Steps per Second: 8,615.73487

Timestep Collection Time: 4.91598
Timestep Consumption Time: 0.88944
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 5.80542

Cumulative Model Updates: 2,042
Cumulative Timesteps: 34,161,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.51728
Policy Entropy: 1.17873
Value Function Loss: 6.75603

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.06273
Value Function Update Magnitude: 0.04211

Collected Steps per Second: 10,449.33979
Overall Steps per Second: 8,924.60874

Timestep Collection Time: 4.78614
Timestep Consumption Time: 0.81769
PPO Batch Consumption Time: 0.04828
Total Iteration Time: 5.60383

Cumulative Model Updates: 2,045
Cumulative Timesteps: 34,211,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 34211256...
Checkpoint 34211256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.78856
Policy Entropy: 1.15639
Value Function Loss: 6.94146

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.03588

Collected Steps per Second: 10,278.55513
Overall Steps per Second: 8,751.26252

Timestep Collection Time: 4.86586
Timestep Consumption Time: 0.84920
PPO Batch Consumption Time: 0.04610
Total Iteration Time: 5.71506

Cumulative Model Updates: 2,048
Cumulative Timesteps: 34,261,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.50631
Policy Entropy: 1.16898
Value Function Loss: 7.20937

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.04016

Collected Steps per Second: 10,783.64743
Overall Steps per Second: 9,198.98391

Timestep Collection Time: 4.63888
Timestep Consumption Time: 0.79912
PPO Batch Consumption Time: 0.03980
Total Iteration Time: 5.43799

Cumulative Model Updates: 2,051
Cumulative Timesteps: 34,311,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 34311294...
Checkpoint 34311294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.19886
Policy Entropy: 1.14725
Value Function Loss: 7.48762

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.15795
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.04432

Collected Steps per Second: 10,869.70833
Overall Steps per Second: 9,137.49753

Timestep Collection Time: 4.60252
Timestep Consumption Time: 0.87251
PPO Batch Consumption Time: 0.04715
Total Iteration Time: 5.47502

Cumulative Model Updates: 2,054
Cumulative Timesteps: 34,361,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.69897
Policy Entropy: 1.16868
Value Function Loss: 7.79211

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.04829

Collected Steps per Second: 10,438.46979
Overall Steps per Second: 8,882.35957

Timestep Collection Time: 4.79093
Timestep Consumption Time: 0.83933
PPO Batch Consumption Time: 0.03899
Total Iteration Time: 5.63026

Cumulative Model Updates: 2,057
Cumulative Timesteps: 34,411,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 34411332...
Checkpoint 34411332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.22737
Policy Entropy: 1.14878
Value Function Loss: 7.55249

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.04271

Collected Steps per Second: 10,131.23960
Overall Steps per Second: 8,736.59391

Timestep Collection Time: 4.93661
Timestep Consumption Time: 0.78804
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 5.72466

Cumulative Model Updates: 2,060
Cumulative Timesteps: 34,461,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.14125
Policy Entropy: 1.16449
Value Function Loss: 7.50369

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.03876

Collected Steps per Second: 10,483.79562
Overall Steps per Second: 8,908.64376

Timestep Collection Time: 4.77022
Timestep Consumption Time: 0.84343
PPO Batch Consumption Time: 0.04452
Total Iteration Time: 5.61365

Cumulative Model Updates: 2,063
Cumulative Timesteps: 34,511,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 34511356...
Checkpoint 34511356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.05804
Policy Entropy: 1.14704
Value Function Loss: 7.23229

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.16270
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.03985

Collected Steps per Second: 10,738.59530
Overall Steps per Second: 9,108.55922

Timestep Collection Time: 4.65796
Timestep Consumption Time: 0.83357
PPO Batch Consumption Time: 0.04018
Total Iteration Time: 5.49154

Cumulative Model Updates: 2,066
Cumulative Timesteps: 34,561,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.41777
Policy Entropy: 1.15710
Value Function Loss: 7.52358

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.04693

Collected Steps per Second: 10,600.08404
Overall Steps per Second: 9,016.52748

Timestep Collection Time: 4.71808
Timestep Consumption Time: 0.82863
PPO Batch Consumption Time: 0.04434
Total Iteration Time: 5.54670

Cumulative Model Updates: 2,069
Cumulative Timesteps: 34,611,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 34611388...
Checkpoint 34611388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.47184
Policy Entropy: 1.14762
Value Function Loss: 7.17757

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.16325
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.05126

Collected Steps per Second: 10,763.34165
Overall Steps per Second: 9,238.06088

Timestep Collection Time: 4.64818
Timestep Consumption Time: 0.76745
PPO Batch Consumption Time: 0.03890
Total Iteration Time: 5.41564

Cumulative Model Updates: 2,072
Cumulative Timesteps: 34,661,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.32371
Policy Entropy: 1.16028
Value Function Loss: 7.29441

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 9,975.68599
Overall Steps per Second: 8,636.23182

Timestep Collection Time: 5.01279
Timestep Consumption Time: 0.77747
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 5.79026

Cumulative Model Updates: 2,075
Cumulative Timesteps: 34,711,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 34711424...
Checkpoint 34711424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.72690
Policy Entropy: 1.15233
Value Function Loss: 6.93761

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.15794
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.03919

Collected Steps per Second: 11,028.41612
Overall Steps per Second: 9,236.32832

Timestep Collection Time: 4.53411
Timestep Consumption Time: 0.87973
PPO Batch Consumption Time: 0.04830
Total Iteration Time: 5.41384

Cumulative Model Updates: 2,078
Cumulative Timesteps: 34,761,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.78136
Policy Entropy: 1.15977
Value Function Loss: 7.47430

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.05226

Collected Steps per Second: 10,721.54975
Overall Steps per Second: 9,068.08759

Timestep Collection Time: 4.66574
Timestep Consumption Time: 0.85075
PPO Batch Consumption Time: 0.04470
Total Iteration Time: 5.51649

Cumulative Model Updates: 2,081
Cumulative Timesteps: 34,811,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 34811452...
Checkpoint 34811452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.38744
Policy Entropy: 1.13993
Value Function Loss: 7.36613

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.16370
Policy Update Magnitude: 0.04522
Value Function Update Magnitude: 0.06945

Collected Steps per Second: 11,050.98344
Overall Steps per Second: 9,328.21988

Timestep Collection Time: 4.52539
Timestep Consumption Time: 0.83576
PPO Batch Consumption Time: 0.04156
Total Iteration Time: 5.36115

Cumulative Model Updates: 2,084
Cumulative Timesteps: 34,861,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.16613
Policy Entropy: 1.14837
Value Function Loss: 7.70348

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.07919
Value Function Update Magnitude: 0.06397

Collected Steps per Second: 10,832.05301
Overall Steps per Second: 9,021.87900

Timestep Collection Time: 4.61870
Timestep Consumption Time: 0.92671
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 5.54541

Cumulative Model Updates: 2,087
Cumulative Timesteps: 34,911,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 34911492...
Checkpoint 34911492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.75536
Policy Entropy: 1.14442
Value Function Loss: 7.90709

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.07406
Value Function Update Magnitude: 0.05676

Collected Steps per Second: 10,608.25250
Overall Steps per Second: 8,855.87799

Timestep Collection Time: 4.71539
Timestep Consumption Time: 0.93307
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 5.64845

Cumulative Model Updates: 2,090
Cumulative Timesteps: 34,961,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.79277
Policy Entropy: 1.13659
Value Function Loss: 7.66209

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.06593
Value Function Update Magnitude: 0.05693

Collected Steps per Second: 10,968.26497
Overall Steps per Second: 9,172.35779

Timestep Collection Time: 4.56134
Timestep Consumption Time: 0.89309
PPO Batch Consumption Time: 0.04703
Total Iteration Time: 5.45443

Cumulative Model Updates: 2,093
Cumulative Timesteps: 35,011,544

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 35011544...
Checkpoint 35011544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.08643
Policy Entropy: 1.13925
Value Function Loss: 7.60922

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.05272

Collected Steps per Second: 10,739.96978
Overall Steps per Second: 9,007.95293

Timestep Collection Time: 4.65569
Timestep Consumption Time: 0.89518
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 5.55087

Cumulative Model Updates: 2,096
Cumulative Timesteps: 35,061,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.73125
Policy Entropy: 1.13705
Value Function Loss: 7.74443

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.04256

Collected Steps per Second: 10,170.90468
Overall Steps per Second: 8,745.61036

Timestep Collection Time: 4.91677
Timestep Consumption Time: 0.80130
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 5.71807

Cumulative Model Updates: 2,099
Cumulative Timesteps: 35,111,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 35111554...
Checkpoint 35111554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.58576
Policy Entropy: 1.12070
Value Function Loss: 8.10365

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.05718

Collected Steps per Second: 10,380.13557
Overall Steps per Second: 8,801.35532

Timestep Collection Time: 4.81824
Timestep Consumption Time: 0.86429
PPO Batch Consumption Time: 0.04755
Total Iteration Time: 5.68253

Cumulative Model Updates: 2,102
Cumulative Timesteps: 35,161,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.24216
Policy Entropy: 1.12663
Value Function Loss: 8.05225

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.05147

Collected Steps per Second: 10,717.10736
Overall Steps per Second: 9,132.16117

Timestep Collection Time: 4.66749
Timestep Consumption Time: 0.81007
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 5.47756

Cumulative Model Updates: 2,105
Cumulative Timesteps: 35,211,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 35211590...
Checkpoint 35211590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.94390
Policy Entropy: 1.14463
Value Function Loss: 7.40790

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.07829
Value Function Update Magnitude: 0.04409

Collected Steps per Second: 10,360.11488
Overall Steps per Second: 8,809.19397

Timestep Collection Time: 4.82736
Timestep Consumption Time: 0.84989
PPO Batch Consumption Time: 0.04470
Total Iteration Time: 5.67725

Cumulative Model Updates: 2,108
Cumulative Timesteps: 35,261,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.76762
Policy Entropy: 1.14691
Value Function Loss: 7.11864

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.06943
Value Function Update Magnitude: 0.04416

Collected Steps per Second: 10,748.54825
Overall Steps per Second: 9,106.66511

Timestep Collection Time: 4.65179
Timestep Consumption Time: 0.83869
PPO Batch Consumption Time: 0.04690
Total Iteration Time: 5.49048

Cumulative Model Updates: 2,111
Cumulative Timesteps: 35,311,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 35311602...
Checkpoint 35311602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.97648
Policy Entropy: 1.14507
Value Function Loss: 7.04101

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.06599
Value Function Update Magnitude: 0.04555

Collected Steps per Second: 10,891.88360
Overall Steps per Second: 9,282.48193

Timestep Collection Time: 4.59204
Timestep Consumption Time: 0.79617
PPO Batch Consumption Time: 0.03886
Total Iteration Time: 5.38821

Cumulative Model Updates: 2,114
Cumulative Timesteps: 35,361,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.96308
Policy Entropy: 1.16219
Value Function Loss: 6.94734

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.06468
Value Function Update Magnitude: 0.05139

Collected Steps per Second: 10,640.46310
Overall Steps per Second: 8,941.77524

Timestep Collection Time: 4.70149
Timestep Consumption Time: 0.89315
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 5.59464

Cumulative Model Updates: 2,117
Cumulative Timesteps: 35,411,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 35411644...
Checkpoint 35411644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.64708
Policy Entropy: 1.16166
Value Function Loss: 6.86598

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.07734
Value Function Update Magnitude: 0.07220

Collected Steps per Second: 10,564.96281
Overall Steps per Second: 9,074.60521

Timestep Collection Time: 4.73546
Timestep Consumption Time: 0.77772
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.51319

Cumulative Model Updates: 2,120
Cumulative Timesteps: 35,461,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.68443
Policy Entropy: 1.15277
Value Function Loss: 6.74213

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.08265
Value Function Update Magnitude: 0.08005

Collected Steps per Second: 9,990.23170
Overall Steps per Second: 8,517.95096

Timestep Collection Time: 5.00609
Timestep Consumption Time: 0.86528
PPO Batch Consumption Time: 0.04765
Total Iteration Time: 5.87137

Cumulative Model Updates: 2,123
Cumulative Timesteps: 35,511,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 35511686...
Checkpoint 35511686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.20477
Policy Entropy: 1.14681
Value Function Loss: 6.76784

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.07818
Value Function Update Magnitude: 0.08484

Collected Steps per Second: 10,776.39999
Overall Steps per Second: 9,084.81211

Timestep Collection Time: 4.64348
Timestep Consumption Time: 0.86461
PPO Batch Consumption Time: 0.03897
Total Iteration Time: 5.50809

Cumulative Model Updates: 2,126
Cumulative Timesteps: 35,561,726

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.80593
Policy Entropy: 1.15503
Value Function Loss: 6.64391

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.07932
Value Function Update Magnitude: 0.07256

Collected Steps per Second: 11,050.99248
Overall Steps per Second: 9,279.00274

Timestep Collection Time: 4.52448
Timestep Consumption Time: 0.86403
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 5.38851

Cumulative Model Updates: 2,129
Cumulative Timesteps: 35,611,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 35611726...
Checkpoint 35611726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.49501
Policy Entropy: 1.16213
Value Function Loss: 6.68749

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.06922
Value Function Update Magnitude: 0.06567

Collected Steps per Second: 10,595.49795
Overall Steps per Second: 8,905.31523

Timestep Collection Time: 4.72125
Timestep Consumption Time: 0.89607
PPO Batch Consumption Time: 0.04282
Total Iteration Time: 5.61732

Cumulative Model Updates: 2,132
Cumulative Timesteps: 35,661,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.19374
Policy Entropy: 1.14143
Value Function Loss: 6.45029

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.09646
Value Function Update Magnitude: 0.06957

Collected Steps per Second: 10,741.16093
Overall Steps per Second: 9,187.23389

Timestep Collection Time: 4.65797
Timestep Consumption Time: 0.78785
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 5.44582

Cumulative Model Updates: 2,135
Cumulative Timesteps: 35,711,782

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 35711782...
Checkpoint 35711782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.21031
Policy Entropy: 1.16216
Value Function Loss: 6.58024

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.06940
Value Function Update Magnitude: 0.07004

Collected Steps per Second: 11,050.77094
Overall Steps per Second: 9,262.75753

Timestep Collection Time: 4.52674
Timestep Consumption Time: 0.87381
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 5.40055

Cumulative Model Updates: 2,138
Cumulative Timesteps: 35,761,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.65238
Policy Entropy: 1.16286
Value Function Loss: 6.44633

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.07406
Value Function Update Magnitude: 0.07892

Collected Steps per Second: 10,682.44441
Overall Steps per Second: 9,044.45378

Timestep Collection Time: 4.68170
Timestep Consumption Time: 0.84788
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 5.52958

Cumulative Model Updates: 2,141
Cumulative Timesteps: 35,811,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 35811818...
Checkpoint 35811818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.80952
Policy Entropy: 1.15009
Value Function Loss: 6.70084

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.07469

Collected Steps per Second: 11,239.81447
Overall Steps per Second: 9,363.39616

Timestep Collection Time: 4.44936
Timestep Consumption Time: 0.89165
PPO Batch Consumption Time: 0.04620
Total Iteration Time: 5.34101

Cumulative Model Updates: 2,144
Cumulative Timesteps: 35,861,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.72802
Policy Entropy: 1.14531
Value Function Loss: 6.54194

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 10,878.87463
Overall Steps per Second: 9,128.95398

Timestep Collection Time: 4.59680
Timestep Consumption Time: 0.88116
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 5.47796

Cumulative Model Updates: 2,147
Cumulative Timesteps: 35,911,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 35911836...
Checkpoint 35911836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.34356
Policy Entropy: 1.15099
Value Function Loss: 6.38495

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.07677

Collected Steps per Second: 11,003.67214
Overall Steps per Second: 9,396.08194

Timestep Collection Time: 4.54539
Timestep Consumption Time: 0.77768
PPO Batch Consumption Time: 0.04797
Total Iteration Time: 5.32307

Cumulative Model Updates: 2,150
Cumulative Timesteps: 35,961,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.46766
Policy Entropy: 1.15259
Value Function Loss: 6.17166

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.07542

Collected Steps per Second: 10,703.41847
Overall Steps per Second: 9,056.54052

Timestep Collection Time: 4.67253
Timestep Consumption Time: 0.84967
PPO Batch Consumption Time: 0.04132
Total Iteration Time: 5.52220

Cumulative Model Updates: 2,153
Cumulative Timesteps: 36,011,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 36011864...
Checkpoint 36011864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.20904
Policy Entropy: 1.14889
Value Function Loss: 6.20191

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.07034
Value Function Update Magnitude: 0.08586

Collected Steps per Second: 10,362.29758
Overall Steps per Second: 8,894.16446

Timestep Collection Time: 4.82711
Timestep Consumption Time: 0.79680
PPO Batch Consumption Time: 0.04663
Total Iteration Time: 5.62391

Cumulative Model Updates: 2,156
Cumulative Timesteps: 36,061,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.84793
Policy Entropy: 1.14327
Value Function Loss: 6.29609

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.08527

Collected Steps per Second: 10,437.27139
Overall Steps per Second: 8,927.14968

Timestep Collection Time: 4.79340
Timestep Consumption Time: 0.81085
PPO Batch Consumption Time: 0.03856
Total Iteration Time: 5.60425

Cumulative Model Updates: 2,159
Cumulative Timesteps: 36,111,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 36111914...
Checkpoint 36111914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.12091
Policy Entropy: 1.14414
Value Function Loss: 6.60029

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.07377
Value Function Update Magnitude: 0.08311

Collected Steps per Second: 10,749.62598
Overall Steps per Second: 9,113.32743

Timestep Collection Time: 4.65300
Timestep Consumption Time: 0.83545
PPO Batch Consumption Time: 0.04620
Total Iteration Time: 5.48845

Cumulative Model Updates: 2,162
Cumulative Timesteps: 36,161,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.61571
Policy Entropy: 1.13982
Value Function Loss: 6.71972

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.08960

Collected Steps per Second: 10,888.55406
Overall Steps per Second: 9,219.52990

Timestep Collection Time: 4.59492
Timestep Consumption Time: 0.83182
PPO Batch Consumption Time: 0.04819
Total Iteration Time: 5.42674

Cumulative Model Updates: 2,165
Cumulative Timesteps: 36,211,964

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 36211964...
Checkpoint 36211964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.60869
Policy Entropy: 1.13541
Value Function Loss: 6.71975

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.07334
Value Function Update Magnitude: 0.09250

Collected Steps per Second: 10,539.31166
Overall Steps per Second: 9,029.71946

Timestep Collection Time: 4.74604
Timestep Consumption Time: 0.79345
PPO Batch Consumption Time: 0.03811
Total Iteration Time: 5.53949

Cumulative Model Updates: 2,168
Cumulative Timesteps: 36,261,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.51337
Policy Entropy: 1.13518
Value Function Loss: 6.42071

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.10584

Collected Steps per Second: 10,594.67126
Overall Steps per Second: 9,015.87622

Timestep Collection Time: 4.72011
Timestep Consumption Time: 0.82655
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.54666

Cumulative Model Updates: 2,171
Cumulative Timesteps: 36,311,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 36311992...
Checkpoint 36311992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.14224
Policy Entropy: 1.13380
Value Function Loss: 6.30552

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.07951
Value Function Update Magnitude: 0.10853

Collected Steps per Second: 10,425.38115
Overall Steps per Second: 8,872.51729

Timestep Collection Time: 4.79637
Timestep Consumption Time: 0.83946
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 5.63583

Cumulative Model Updates: 2,174
Cumulative Timesteps: 36,361,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.25061
Policy Entropy: 1.13622
Value Function Loss: 6.47235

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.07071
Value Function Update Magnitude: 0.09040

Collected Steps per Second: 10,701.37358
Overall Steps per Second: 9,123.70836

Timestep Collection Time: 4.67473
Timestep Consumption Time: 0.80835
PPO Batch Consumption Time: 0.04196
Total Iteration Time: 5.48308

Cumulative Model Updates: 2,177
Cumulative Timesteps: 36,412,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 36412022...
Checkpoint 36412022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.15027
Policy Entropy: 1.12243
Value Function Loss: 6.44948

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.10846
Value Function Update Magnitude: 0.08795

Collected Steps per Second: 10,956.25956
Overall Steps per Second: 9,190.12210

Timestep Collection Time: 4.56415
Timestep Consumption Time: 0.87713
PPO Batch Consumption Time: 0.03849
Total Iteration Time: 5.44128

Cumulative Model Updates: 2,180
Cumulative Timesteps: 36,462,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.71340
Policy Entropy: 1.14314
Value Function Loss: 6.79220

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.09758
Value Function Update Magnitude: 0.07528

Collected Steps per Second: 10,751.12764
Overall Steps per Second: 9,106.83181

Timestep Collection Time: 4.65309
Timestep Consumption Time: 0.84015
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 5.49324

Cumulative Model Updates: 2,183
Cumulative Timesteps: 36,512,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 36512054...
Checkpoint 36512054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.77554
Policy Entropy: 1.15907
Value Function Loss: 6.76389

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.08282
Value Function Update Magnitude: 0.07376

Collected Steps per Second: 10,693.27382
Overall Steps per Second: 9,249.25876

Timestep Collection Time: 4.67808
Timestep Consumption Time: 0.73035
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 5.40843

Cumulative Model Updates: 2,186
Cumulative Timesteps: 36,562,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.68464
Policy Entropy: 1.13688
Value Function Loss: 6.98341

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.07703
Value Function Update Magnitude: 0.08392

Collected Steps per Second: 10,049.54694
Overall Steps per Second: 8,556.47915

Timestep Collection Time: 4.97575
Timestep Consumption Time: 0.86825
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 5.84399

Cumulative Model Updates: 2,189
Cumulative Timesteps: 36,612,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 36612082...
Checkpoint 36612082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.51405
Policy Entropy: 1.16114
Value Function Loss: 6.59562

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.09518

Collected Steps per Second: 10,669.64799
Overall Steps per Second: 9,260.73016

Timestep Collection Time: 4.68731
Timestep Consumption Time: 0.71312
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 5.40044

Cumulative Model Updates: 2,192
Cumulative Timesteps: 36,662,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.45157
Policy Entropy: 1.15096
Value Function Loss: 6.61705

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.06939
Value Function Update Magnitude: 0.08911

Collected Steps per Second: 10,825.82694
Overall Steps per Second: 9,089.05078

Timestep Collection Time: 4.62062
Timestep Consumption Time: 0.88293
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 5.50355

Cumulative Model Updates: 2,195
Cumulative Timesteps: 36,712,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 36712116...
Checkpoint 36712116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.73313
Policy Entropy: 1.13994
Value Function Loss: 6.62319

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.07440
Value Function Update Magnitude: 0.06786

Collected Steps per Second: 10,523.04185
Overall Steps per Second: 8,962.75271

Timestep Collection Time: 4.75205
Timestep Consumption Time: 0.82726
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 5.57931

Cumulative Model Updates: 2,198
Cumulative Timesteps: 36,762,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.02002
Policy Entropy: 1.13362
Value Function Loss: 6.65385

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.06996
Value Function Update Magnitude: 0.07229

Collected Steps per Second: 10,669.23321
Overall Steps per Second: 9,218.96060

Timestep Collection Time: 4.68843
Timestep Consumption Time: 0.73756
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 5.42599

Cumulative Model Updates: 2,201
Cumulative Timesteps: 36,812,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 36812144...
Checkpoint 36812144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.50074
Policy Entropy: 1.13744
Value Function Loss: 6.49510

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.08147
Value Function Update Magnitude: 0.07900

Collected Steps per Second: 10,550.78181
Overall Steps per Second: 8,926.39724

Timestep Collection Time: 4.74183
Timestep Consumption Time: 0.86290
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.60472

Cumulative Model Updates: 2,204
Cumulative Timesteps: 36,862,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.99549
Policy Entropy: 1.14636
Value Function Loss: 6.60204

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.07779
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 10,565.80452
Overall Steps per Second: 8,999.17355

Timestep Collection Time: 4.73244
Timestep Consumption Time: 0.82385
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 5.55629

Cumulative Model Updates: 2,207
Cumulative Timesteps: 36,912,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 36912176...
Checkpoint 36912176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.39977
Policy Entropy: 1.13049
Value Function Loss: 6.55913

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.17309
Policy Update Magnitude: 0.07624
Value Function Update Magnitude: 0.06337

Collected Steps per Second: 10,632.89837
Overall Steps per Second: 8,966.27377

Timestep Collection Time: 4.70295
Timestep Consumption Time: 0.87417
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 5.57712

Cumulative Model Updates: 2,210
Cumulative Timesteps: 36,962,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.72119
Policy Entropy: 1.15612
Value Function Loss: 6.59111

Mean KL Divergence: 0.02576
SB3 Clip Fraction: 0.17212
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.06097

Collected Steps per Second: 10,961.39483
Overall Steps per Second: 9,316.40792

Timestep Collection Time: 4.56402
Timestep Consumption Time: 0.80586
PPO Batch Consumption Time: 0.04613
Total Iteration Time: 5.36988

Cumulative Model Updates: 2,213
Cumulative Timesteps: 37,012,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 37012210...
Checkpoint 37012210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.37678
Policy Entropy: 1.13924
Value Function Loss: 6.30894

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.06030

Collected Steps per Second: 10,674.55020
Overall Steps per Second: 9,136.80256

Timestep Collection Time: 4.68460
Timestep Consumption Time: 0.78843
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 5.47303

Cumulative Model Updates: 2,216
Cumulative Timesteps: 37,062,216

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.47437
Policy Entropy: 1.15826
Value Function Loss: 6.13852

Mean KL Divergence: 0.02944
SB3 Clip Fraction: 0.17530
Policy Update Magnitude: 0.04416
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 10,768.82483
Overall Steps per Second: 9,078.40886

Timestep Collection Time: 4.64600
Timestep Consumption Time: 0.86509
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 5.51110

Cumulative Model Updates: 2,219
Cumulative Timesteps: 37,112,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 37112248...
Checkpoint 37112248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.43144
Policy Entropy: 1.15186
Value Function Loss: 5.95981

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.03866
Value Function Update Magnitude: 0.06291

Collected Steps per Second: 10,103.42241
Overall Steps per Second: 8,742.28644

Timestep Collection Time: 4.95020
Timestep Consumption Time: 0.77073
PPO Batch Consumption Time: 0.04580
Total Iteration Time: 5.72093

Cumulative Model Updates: 2,222
Cumulative Timesteps: 37,162,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.97238
Policy Entropy: 1.17362
Value Function Loss: 5.84706

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.16312
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.05808

Collected Steps per Second: 10,823.73750
Overall Steps per Second: 9,080.12505

Timestep Collection Time: 4.62040
Timestep Consumption Time: 0.88723
PPO Batch Consumption Time: 0.04819
Total Iteration Time: 5.50763

Cumulative Model Updates: 2,225
Cumulative Timesteps: 37,212,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 37212272...
Checkpoint 37212272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.52159
Policy Entropy: 1.15820
Value Function Loss: 5.93085

Mean KL Divergence: 0.02628
SB3 Clip Fraction: 0.16327
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.05892

Collected Steps per Second: 10,827.77444
Overall Steps per Second: 9,146.85598

Timestep Collection Time: 4.61923
Timestep Consumption Time: 0.84888
PPO Batch Consumption Time: 0.04105
Total Iteration Time: 5.46811

Cumulative Model Updates: 2,228
Cumulative Timesteps: 37,262,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.94172
Policy Entropy: 1.17539
Value Function Loss: 6.16402

Mean KL Divergence: 0.02435
SB3 Clip Fraction: 0.15937
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.06686

Collected Steps per Second: 10,266.34303
Overall Steps per Second: 8,644.70195

Timestep Collection Time: 4.87204
Timestep Consumption Time: 0.91393
PPO Batch Consumption Time: 0.04443
Total Iteration Time: 5.78597

Cumulative Model Updates: 2,231
Cumulative Timesteps: 37,312,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 37312306...
Checkpoint 37312306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.20229
Policy Entropy: 1.16059
Value Function Loss: 6.44311

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.03610
Value Function Update Magnitude: 0.06032

Collected Steps per Second: 10,675.46654
Overall Steps per Second: 8,909.62720

Timestep Collection Time: 4.68588
Timestep Consumption Time: 0.92872
PPO Batch Consumption Time: 0.04654
Total Iteration Time: 5.61460

Cumulative Model Updates: 2,234
Cumulative Timesteps: 37,362,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.42967
Policy Entropy: 1.17375
Value Function Loss: 6.57625

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.04231
Value Function Update Magnitude: 0.05919

Collected Steps per Second: 10,084.57325
Overall Steps per Second: 8,811.89636

Timestep Collection Time: 4.95886
Timestep Consumption Time: 0.71619
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.67506

Cumulative Model Updates: 2,237
Cumulative Timesteps: 37,412,338

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 37412338...
Checkpoint 37412338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.04686
Policy Entropy: 1.14816
Value Function Loss: 6.50967

Mean KL Divergence: 0.02932
SB3 Clip Fraction: 0.17452
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.06064

Collected Steps per Second: 10,718.07180
Overall Steps per Second: 9,045.13064

Timestep Collection Time: 4.66595
Timestep Consumption Time: 0.86299
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 5.52894

Cumulative Model Updates: 2,240
Cumulative Timesteps: 37,462,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.49049
Policy Entropy: 1.16136
Value Function Loss: 6.07471

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.04158
Value Function Update Magnitude: 0.05224

Collected Steps per Second: 10,881.79687
Overall Steps per Second: 9,210.64374

Timestep Collection Time: 4.59703
Timestep Consumption Time: 0.83407
PPO Batch Consumption Time: 0.04684
Total Iteration Time: 5.43111

Cumulative Model Updates: 2,243
Cumulative Timesteps: 37,512,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 37512372...
Checkpoint 37512372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.17684
Policy Entropy: 1.14351
Value Function Loss: 6.21697

Mean KL Divergence: 0.02603
SB3 Clip Fraction: 0.16434
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.04441

Collected Steps per Second: 10,805.03356
Overall Steps per Second: 9,106.93747

Timestep Collection Time: 4.62747
Timestep Consumption Time: 0.86285
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 5.49032

Cumulative Model Updates: 2,246
Cumulative Timesteps: 37,562,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.09108
Policy Entropy: 1.15697
Value Function Loss: 6.27377

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.15502
Policy Update Magnitude: 0.04216
Value Function Update Magnitude: 0.05831

Collected Steps per Second: 10,621.91287
Overall Steps per Second: 8,995.52010

Timestep Collection Time: 4.70838
Timestep Consumption Time: 0.85128
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 5.55966

Cumulative Model Updates: 2,249
Cumulative Timesteps: 37,612,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 37612384...
Checkpoint 37612384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.33313
Policy Entropy: 1.14335
Value Function Loss: 6.52099

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.15615
Policy Update Magnitude: 0.04088
Value Function Update Magnitude: 0.05974

Collected Steps per Second: 10,753.05921
Overall Steps per Second: 9,131.75531

Timestep Collection Time: 4.65133
Timestep Consumption Time: 0.82582
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 5.47715

Cumulative Model Updates: 2,252
Cumulative Timesteps: 37,662,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.01812
Policy Entropy: 1.16389
Value Function Loss: 6.41942

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.04007
Value Function Update Magnitude: 0.05724

Collected Steps per Second: 10,320.01945
Overall Steps per Second: 8,737.20500

Timestep Collection Time: 4.84592
Timestep Consumption Time: 0.87788
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 5.72380

Cumulative Model Updates: 2,255
Cumulative Timesteps: 37,712,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 37712410...
Checkpoint 37712410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.95212
Policy Entropy: 1.14636
Value Function Loss: 6.43057

Mean KL Divergence: 0.02812
SB3 Clip Fraction: 0.16477
Policy Update Magnitude: 0.03905
Value Function Update Magnitude: 0.04849

Collected Steps per Second: 10,302.17857
Overall Steps per Second: 8,892.85707

Timestep Collection Time: 4.85567
Timestep Consumption Time: 0.76952
PPO Batch Consumption Time: 0.04589
Total Iteration Time: 5.62519

Cumulative Model Updates: 2,258
Cumulative Timesteps: 37,762,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.01357
Policy Entropy: 1.14897
Value Function Loss: 6.53658

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.03919
Value Function Update Magnitude: 0.04035

Collected Steps per Second: 10,217.89320
Overall Steps per Second: 8,702.14804

Timestep Collection Time: 4.89533
Timestep Consumption Time: 0.85267
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 5.74801

Cumulative Model Updates: 2,261
Cumulative Timesteps: 37,812,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 37812454...
Checkpoint 37812454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.03531
Policy Entropy: 1.12761
Value Function Loss: 6.55386

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.15230
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.03833

Collected Steps per Second: 10,719.06068
Overall Steps per Second: 9,103.40206

Timestep Collection Time: 4.66720
Timestep Consumption Time: 0.82833
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.49553

Cumulative Model Updates: 2,264
Cumulative Timesteps: 37,862,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.41098
Policy Entropy: 1.13543
Value Function Loss: 6.55158

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.15072
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.03647

Collected Steps per Second: 10,269.83776
Overall Steps per Second: 8,685.79950

Timestep Collection Time: 4.86999
Timestep Consumption Time: 0.88815
PPO Batch Consumption Time: 0.04654
Total Iteration Time: 5.75813

Cumulative Model Updates: 2,267
Cumulative Timesteps: 37,912,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 37912496...
Checkpoint 37912496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.77988
Policy Entropy: 1.13010
Value Function Loss: 6.38326

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.14270
Policy Update Magnitude: 0.03901
Value Function Update Magnitude: 0.03990

Collected Steps per Second: 10,165.37696
Overall Steps per Second: 8,712.32884

Timestep Collection Time: 4.92141
Timestep Consumption Time: 0.82080
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 5.74221

Cumulative Model Updates: 2,270
Cumulative Timesteps: 37,962,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.25626
Policy Entropy: 1.14134
Value Function Loss: 6.36872

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.03897
Value Function Update Magnitude: 0.03849

Collected Steps per Second: 10,851.90091
Overall Steps per Second: 9,191.04050

Timestep Collection Time: 4.60878
Timestep Consumption Time: 0.83283
PPO Batch Consumption Time: 0.04863
Total Iteration Time: 5.44160

Cumulative Model Updates: 2,273
Cumulative Timesteps: 38,012,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 38012538...
Checkpoint 38012538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.10870
Policy Entropy: 1.13526
Value Function Loss: 6.30663

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.04267
Value Function Update Magnitude: 0.03370

Collected Steps per Second: 10,741.49826
Overall Steps per Second: 9,010.42453

Timestep Collection Time: 4.65540
Timestep Consumption Time: 0.89439
PPO Batch Consumption Time: 0.04524
Total Iteration Time: 5.54979

Cumulative Model Updates: 2,276
Cumulative Timesteps: 38,062,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.98882
Policy Entropy: 1.15263
Value Function Loss: 6.49234

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.04348
Value Function Update Magnitude: 0.04987

Collected Steps per Second: 10,798.58222
Overall Steps per Second: 9,082.27635

Timestep Collection Time: 4.63283
Timestep Consumption Time: 0.87548
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 5.50831

Cumulative Model Updates: 2,279
Cumulative Timesteps: 38,112,572

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 38112572...
Checkpoint 38112572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.09025
Policy Entropy: 1.14671
Value Function Loss: 6.44502

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.05467

Collected Steps per Second: 10,875.70112
Overall Steps per Second: 9,157.91937

Timestep Collection Time: 4.59980
Timestep Consumption Time: 0.86280
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 5.46259

Cumulative Model Updates: 2,282
Cumulative Timesteps: 38,162,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.68155
Policy Entropy: 1.16598
Value Function Loss: 6.52242

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.03944
Value Function Update Magnitude: 0.04811

Collected Steps per Second: 10,083.80530
Overall Steps per Second: 8,560.32944

Timestep Collection Time: 4.95845
Timestep Consumption Time: 0.88245
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 5.84090

Cumulative Model Updates: 2,285
Cumulative Timesteps: 38,212,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 38212598...
Checkpoint 38212598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.48083
Policy Entropy: 1.15091
Value Function Loss: 6.28075

Mean KL Divergence: 0.02363
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.03887
Value Function Update Magnitude: 0.03970

Collected Steps per Second: 10,668.55738
Overall Steps per Second: 9,174.43207

Timestep Collection Time: 4.68873
Timestep Consumption Time: 0.76360
PPO Batch Consumption Time: 0.04035
Total Iteration Time: 5.45233

Cumulative Model Updates: 2,288
Cumulative Timesteps: 38,262,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.71072
Policy Entropy: 1.16086
Value Function Loss: 6.51358

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.04070
Value Function Update Magnitude: 0.03701

Collected Steps per Second: 10,934.27909
Overall Steps per Second: 9,168.36873

Timestep Collection Time: 4.57479
Timestep Consumption Time: 0.88115
PPO Batch Consumption Time: 0.04742
Total Iteration Time: 5.45593

Cumulative Model Updates: 2,291
Cumulative Timesteps: 38,312,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 38312642...
Checkpoint 38312642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.29917
Policy Entropy: 1.14837
Value Function Loss: 6.56193

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.03514
Value Function Update Magnitude: 0.03124

Collected Steps per Second: 10,493.07578
Overall Steps per Second: 8,910.44035

Timestep Collection Time: 4.76829
Timestep Consumption Time: 0.84692
PPO Batch Consumption Time: 0.04786
Total Iteration Time: 5.61521

Cumulative Model Updates: 2,294
Cumulative Timesteps: 38,362,676

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.21333
Policy Entropy: 1.16376
Value Function Loss: 6.72780

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.04519

Collected Steps per Second: 10,526.89200
Overall Steps per Second: 9,066.24972

Timestep Collection Time: 4.74974
Timestep Consumption Time: 0.76522
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 5.51496

Cumulative Model Updates: 2,297
Cumulative Timesteps: 38,412,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 38412676...
Checkpoint 38412676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.85710
Policy Entropy: 1.15248
Value Function Loss: 6.51177

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.15363
Policy Update Magnitude: 0.03446
Value Function Update Magnitude: 0.04306

Collected Steps per Second: 10,705.48248
Overall Steps per Second: 8,993.47329

Timestep Collection Time: 4.67405
Timestep Consumption Time: 0.88976
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 5.56381

Cumulative Model Updates: 2,300
Cumulative Timesteps: 38,462,714

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.05199
Policy Entropy: 1.16526
Value Function Loss: 6.22736

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.03574
Value Function Update Magnitude: 0.04226

Collected Steps per Second: 10,311.34901
Overall Steps per Second: 8,982.91579

Timestep Collection Time: 4.84980
Timestep Consumption Time: 0.71721
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 5.56701

Cumulative Model Updates: 2,303
Cumulative Timesteps: 38,512,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 38512722...
Checkpoint 38512722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.84802
Policy Entropy: 1.14881
Value Function Loss: 6.41947

Mean KL Divergence: 0.02459
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.03811
Value Function Update Magnitude: 0.03790

Collected Steps per Second: 10,763.51324
Overall Steps per Second: 9,163.39575

Timestep Collection Time: 4.64662
Timestep Consumption Time: 0.81140
PPO Batch Consumption Time: 0.03941
Total Iteration Time: 5.45802

Cumulative Model Updates: 2,306
Cumulative Timesteps: 38,562,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.65432
Policy Entropy: 1.15272
Value Function Loss: 6.19883

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.03638

Collected Steps per Second: 10,917.05321
Overall Steps per Second: 9,288.31250

Timestep Collection Time: 4.58036
Timestep Consumption Time: 0.80318
PPO Batch Consumption Time: 0.04612
Total Iteration Time: 5.38354

Cumulative Model Updates: 2,309
Cumulative Timesteps: 38,612,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 38612740...
Checkpoint 38612740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.46426
Policy Entropy: 1.13965
Value Function Loss: 6.50800

Mean KL Divergence: 0.02629
SB3 Clip Fraction: 0.15560
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.04841

Collected Steps per Second: 10,491.07485
Overall Steps per Second: 9,060.98053

Timestep Collection Time: 4.76748
Timestep Consumption Time: 0.75245
PPO Batch Consumption Time: 0.04428
Total Iteration Time: 5.51993

Cumulative Model Updates: 2,312
Cumulative Timesteps: 38,662,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.66940
Policy Entropy: 1.15327
Value Function Loss: 6.30936

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.05415

Collected Steps per Second: 10,751.52909
Overall Steps per Second: 9,090.05843

Timestep Collection Time: 4.65050
Timestep Consumption Time: 0.85001
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 5.50051

Cumulative Model Updates: 2,315
Cumulative Timesteps: 38,712,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 38712756...
Checkpoint 38712756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.68105
Policy Entropy: 1.14095
Value Function Loss: 6.61087

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.03921
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 10,276.20470
Overall Steps per Second: 8,864.67842

Timestep Collection Time: 4.86658
Timestep Consumption Time: 0.77491
PPO Batch Consumption Time: 0.04831
Total Iteration Time: 5.64149

Cumulative Model Updates: 2,318
Cumulative Timesteps: 38,762,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.40077
Policy Entropy: 1.13842
Value Function Loss: 6.79191

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.04410
Value Function Update Magnitude: 0.05913

Collected Steps per Second: 10,765.83910
Overall Steps per Second: 9,141.93766

Timestep Collection Time: 4.64655
Timestep Consumption Time: 0.82538
PPO Batch Consumption Time: 0.04691
Total Iteration Time: 5.47193

Cumulative Model Updates: 2,321
Cumulative Timesteps: 38,812,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 38812790...
Checkpoint 38812790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.37923
Policy Entropy: 1.11702
Value Function Loss: 6.71219

Mean KL Divergence: 0.02610
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.06041

Collected Steps per Second: 10,681.92079
Overall Steps per Second: 9,044.54282

Timestep Collection Time: 4.68081
Timestep Consumption Time: 0.84739
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 5.52820

Cumulative Model Updates: 2,324
Cumulative Timesteps: 38,862,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.17348
Policy Entropy: 1.12804
Value Function Loss: 7.00696

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.04304
Value Function Update Magnitude: 0.05440

Collected Steps per Second: 11,060.73497
Overall Steps per Second: 9,326.03083

Timestep Collection Time: 4.52176
Timestep Consumption Time: 0.84108
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 5.36284

Cumulative Model Updates: 2,327
Cumulative Timesteps: 38,912,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 38912804...
Checkpoint 38912804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.85095
Policy Entropy: 1.11559
Value Function Loss: 6.78929

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.04063
Value Function Update Magnitude: 0.06319

Collected Steps per Second: 10,751.18434
Overall Steps per Second: 9,162.54544

Timestep Collection Time: 4.65121
Timestep Consumption Time: 0.80645
PPO Batch Consumption Time: 0.04208
Total Iteration Time: 5.45765

Cumulative Model Updates: 2,330
Cumulative Timesteps: 38,962,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.94500
Policy Entropy: 1.12587
Value Function Loss: 6.94461

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.04242
Value Function Update Magnitude: 0.07425

Collected Steps per Second: 10,714.30973
Overall Steps per Second: 8,999.64398

Timestep Collection Time: 4.66890
Timestep Consumption Time: 0.88955
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 5.55844

Cumulative Model Updates: 2,333
Cumulative Timesteps: 39,012,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 39012834...
Checkpoint 39012834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.74997
Policy Entropy: 1.11678
Value Function Loss: 6.90406

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.07730

Collected Steps per Second: 10,676.67067
Overall Steps per Second: 9,050.18905

Timestep Collection Time: 4.68442
Timestep Consumption Time: 0.84187
PPO Batch Consumption Time: 0.03926
Total Iteration Time: 5.52629

Cumulative Model Updates: 2,336
Cumulative Timesteps: 39,062,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.92648
Policy Entropy: 1.13367
Value Function Loss: 6.89030

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.06619

Collected Steps per Second: 10,846.19088
Overall Steps per Second: 9,122.20555

Timestep Collection Time: 4.61194
Timestep Consumption Time: 0.87160
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 5.48354

Cumulative Model Updates: 2,339
Cumulative Timesteps: 39,112,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 39112870...
Checkpoint 39112870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.32577
Policy Entropy: 1.12793
Value Function Loss: 6.98267

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.15811
Policy Update Magnitude: 0.04618
Value Function Update Magnitude: 0.05975

Collected Steps per Second: 10,866.12640
Overall Steps per Second: 9,151.61634

Timestep Collection Time: 4.60440
Timestep Consumption Time: 0.86261
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 5.46701

Cumulative Model Updates: 2,342
Cumulative Timesteps: 39,162,902

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.39123
Policy Entropy: 1.14344
Value Function Loss: 6.95896

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.04158
Value Function Update Magnitude: 0.05790

Collected Steps per Second: 10,802.59150
Overall Steps per Second: 9,131.91688

Timestep Collection Time: 4.62852
Timestep Consumption Time: 0.84678
PPO Batch Consumption Time: 0.04631
Total Iteration Time: 5.47530

Cumulative Model Updates: 2,345
Cumulative Timesteps: 39,212,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 39212902...
Checkpoint 39212902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.43667
Policy Entropy: 1.12787
Value Function Loss: 6.97670

Mean KL Divergence: 0.02544
SB3 Clip Fraction: 0.16711
Policy Update Magnitude: 0.04338
Value Function Update Magnitude: 0.04958

Collected Steps per Second: 10,746.24801
Overall Steps per Second: 9,217.93185

Timestep Collection Time: 4.65576
Timestep Consumption Time: 0.77192
PPO Batch Consumption Time: 0.03911
Total Iteration Time: 5.42768

Cumulative Model Updates: 2,348
Cumulative Timesteps: 39,262,934

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.13526
Policy Entropy: 1.13404
Value Function Loss: 6.75516

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.04783

Collected Steps per Second: 10,206.95491
Overall Steps per Second: 8,612.25487

Timestep Collection Time: 4.90019
Timestep Consumption Time: 0.90735
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 5.80754

Cumulative Model Updates: 2,351
Cumulative Timesteps: 39,312,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 39312950...
Checkpoint 39312950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.20368
Policy Entropy: 1.11363
Value Function Loss: 6.90183

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.16519
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.05280

Collected Steps per Second: 10,702.99430
Overall Steps per Second: 9,070.38262

Timestep Collection Time: 4.67308
Timestep Consumption Time: 0.84113
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 5.51421

Cumulative Model Updates: 2,354
Cumulative Timesteps: 39,362,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.83549
Policy Entropy: 1.13453
Value Function Loss: 7.11600

Mean KL Divergence: 0.02676
SB3 Clip Fraction: 0.15559
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.05668

Collected Steps per Second: 10,853.02117
Overall Steps per Second: 9,118.22838

Timestep Collection Time: 4.60904
Timestep Consumption Time: 0.87689
PPO Batch Consumption Time: 0.04610
Total Iteration Time: 5.48593

Cumulative Model Updates: 2,357
Cumulative Timesteps: 39,412,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 39412988...
Checkpoint 39412988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.30144
Policy Entropy: 1.13063
Value Function Loss: 7.21482

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.16683
Policy Update Magnitude: 0.04012
Value Function Update Magnitude: 0.05589

Collected Steps per Second: 10,683.87681
Overall Steps per Second: 9,022.52314

Timestep Collection Time: 4.68276
Timestep Consumption Time: 0.86225
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 5.54501

Cumulative Model Updates: 2,360
Cumulative Timesteps: 39,463,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.88698
Policy Entropy: 1.15031
Value Function Loss: 6.79220

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.06362

Collected Steps per Second: 10,409.07741
Overall Steps per Second: 8,931.87166

Timestep Collection Time: 4.80504
Timestep Consumption Time: 0.79469
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 5.59972

Cumulative Model Updates: 2,363
Cumulative Timesteps: 39,513,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 39513034...
Checkpoint 39513034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.71817
Policy Entropy: 1.14372
Value Function Loss: 6.49025

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.16263
Policy Update Magnitude: 0.04104
Value Function Update Magnitude: 0.05864

Collected Steps per Second: 10,305.44324
Overall Steps per Second: 8,717.72211

Timestep Collection Time: 4.85180
Timestep Consumption Time: 0.88364
PPO Batch Consumption Time: 0.04630
Total Iteration Time: 5.73544

Cumulative Model Updates: 2,366
Cumulative Timesteps: 39,563,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.47264
Policy Entropy: 1.15983
Value Function Loss: 6.19696

Mean KL Divergence: 0.02475
SB3 Clip Fraction: 0.15612
Policy Update Magnitude: 0.03934
Value Function Update Magnitude: 0.05287

Collected Steps per Second: 10,696.49495
Overall Steps per Second: 9,045.75564

Timestep Collection Time: 4.67462
Timestep Consumption Time: 0.85306
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.52768

Cumulative Model Updates: 2,369
Cumulative Timesteps: 39,613,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 39613036...
Checkpoint 39613036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.18940
Policy Entropy: 1.13751
Value Function Loss: 6.09319

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.15761
Policy Update Magnitude: 0.03715
Value Function Update Magnitude: 0.05076

Collected Steps per Second: 10,915.22556
Overall Steps per Second: 9,204.38854

Timestep Collection Time: 4.58332
Timestep Consumption Time: 0.85191
PPO Batch Consumption Time: 0.03907
Total Iteration Time: 5.43523

Cumulative Model Updates: 2,372
Cumulative Timesteps: 39,663,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.36622
Policy Entropy: 1.14178
Value Function Loss: 6.29990

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.04884

Collected Steps per Second: 10,706.86462
Overall Steps per Second: 9,149.90345

Timestep Collection Time: 4.67027
Timestep Consumption Time: 0.79470
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.46498

Cumulative Model Updates: 2,375
Cumulative Timesteps: 39,713,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 39713068...
Checkpoint 39713068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.51383
Policy Entropy: 1.12560
Value Function Loss: 6.54187

Mean KL Divergence: 0.02402
SB3 Clip Fraction: 0.15815
Policy Update Magnitude: 0.04250
Value Function Update Magnitude: 0.04609

Collected Steps per Second: 10,709.20921
Overall Steps per Second: 9,196.29961

Timestep Collection Time: 4.67019
Timestep Consumption Time: 0.76831
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 5.43849

Cumulative Model Updates: 2,378
Cumulative Timesteps: 39,763,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.30858
Policy Entropy: 1.15276
Value Function Loss: 6.71472

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.06335

Collected Steps per Second: 10,828.14756
Overall Steps per Second: 9,137.61940

Timestep Collection Time: 4.61778
Timestep Consumption Time: 0.85432
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.47210

Cumulative Model Updates: 2,381
Cumulative Timesteps: 39,813,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 39813084...
Checkpoint 39813084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.55018
Policy Entropy: 1.13488
Value Function Loss: 6.42677

Mean KL Divergence: 0.03323
SB3 Clip Fraction: 0.18787
Policy Update Magnitude: 0.04290
Value Function Update Magnitude: 0.08701

Collected Steps per Second: 10,016.53887
Overall Steps per Second: 8,563.22133

Timestep Collection Time: 4.99254
Timestep Consumption Time: 0.84732
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 5.83986

Cumulative Model Updates: 2,384
Cumulative Timesteps: 39,863,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.83802
Policy Entropy: 1.14653
Value Function Loss: 6.53240

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.03816
Value Function Update Magnitude: 0.07178

Collected Steps per Second: 11,019.19903
Overall Steps per Second: 9,187.62982

Timestep Collection Time: 4.53953
Timestep Consumption Time: 0.90496
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 5.44449

Cumulative Model Updates: 2,387
Cumulative Timesteps: 39,913,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 39913114...
Checkpoint 39913114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.39097
Policy Entropy: 1.12719
Value Function Loss: 6.43649

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.15800
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.07776

Collected Steps per Second: 10,557.04949
Overall Steps per Second: 9,030.90742

Timestep Collection Time: 4.73863
Timestep Consumption Time: 0.80079
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 5.53942

Cumulative Model Updates: 2,390
Cumulative Timesteps: 39,963,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.34707
Policy Entropy: 1.13705
Value Function Loss: 6.49011

Mean KL Divergence: 0.02529
SB3 Clip Fraction: 0.15850
Policy Update Magnitude: 0.04575
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 10,803.44397
Overall Steps per Second: 9,258.36295

Timestep Collection Time: 4.62834
Timestep Consumption Time: 0.77240
PPO Batch Consumption Time: 0.04208
Total Iteration Time: 5.40074

Cumulative Model Updates: 2,393
Cumulative Timesteps: 40,013,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 40013142...
Checkpoint 40013142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.59209
Policy Entropy: 1.12971
Value Function Loss: 6.24474

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.04091
Value Function Update Magnitude: 0.06450

Collected Steps per Second: 10,862.19640
Overall Steps per Second: 9,172.51647

Timestep Collection Time: 4.60312
Timestep Consumption Time: 0.84795
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 5.45107

Cumulative Model Updates: 2,396
Cumulative Timesteps: 40,063,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.09113
Policy Entropy: 1.14146
Value Function Loss: 6.15635

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.05599

Collected Steps per Second: 10,294.76956
Overall Steps per Second: 8,694.57130

Timestep Collection Time: 4.85742
Timestep Consumption Time: 0.89399
PPO Batch Consumption Time: 0.03846
Total Iteration Time: 5.75140

Cumulative Model Updates: 2,399
Cumulative Timesteps: 40,113,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 40113148...
Checkpoint 40113148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.61910
Policy Entropy: 1.13381
Value Function Loss: 6.37588

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.15966
Policy Update Magnitude: 0.04039
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 11,090.41998
Overall Steps per Second: 9,264.63351

Timestep Collection Time: 4.51020
Timestep Consumption Time: 0.88883
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 5.39903

Cumulative Model Updates: 2,402
Cumulative Timesteps: 40,163,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.94039
Policy Entropy: 1.13400
Value Function Loss: 6.69788

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.03983
Value Function Update Magnitude: 0.06018

Collected Steps per Second: 11,126.99195
Overall Steps per Second: 9,313.52492

Timestep Collection Time: 4.49591
Timestep Consumption Time: 0.87541
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 5.37133

Cumulative Model Updates: 2,405
Cumulative Timesteps: 40,213,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 40213194...
Checkpoint 40213194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.36691
Policy Entropy: 1.11796
Value Function Loss: 6.87770

Mean KL Divergence: 0.02666
SB3 Clip Fraction: 0.15653
Policy Update Magnitude: 0.04156
Value Function Update Magnitude: 0.06408

Collected Steps per Second: 10,918.29903
Overall Steps per Second: 9,308.66737

Timestep Collection Time: 4.58038
Timestep Consumption Time: 0.79203
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 5.37241

Cumulative Model Updates: 2,408
Cumulative Timesteps: 40,263,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.77727
Policy Entropy: 1.11923
Value Function Loss: 6.64589

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.03873
Value Function Update Magnitude: 0.05804

Collected Steps per Second: 10,754.18010
Overall Steps per Second: 9,104.54486

Timestep Collection Time: 4.65010
Timestep Consumption Time: 0.84254
PPO Batch Consumption Time: 0.03992
Total Iteration Time: 5.49264

Cumulative Model Updates: 2,411
Cumulative Timesteps: 40,313,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 40313212...
Checkpoint 40313212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.28901
Policy Entropy: 1.11498
Value Function Loss: 6.47940

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.03977
Value Function Update Magnitude: 0.05215

Collected Steps per Second: 10,529.89867
Overall Steps per Second: 9,095.49747

Timestep Collection Time: 4.75066
Timestep Consumption Time: 0.74920
PPO Batch Consumption Time: 0.04849
Total Iteration Time: 5.49986

Cumulative Model Updates: 2,414
Cumulative Timesteps: 40,363,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.04045
Policy Entropy: 1.13378
Value Function Loss: 6.46095

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.14417
Policy Update Magnitude: 0.03939
Value Function Update Magnitude: 0.04681

Collected Steps per Second: 10,354.52177
Overall Steps per Second: 8,865.31674

Timestep Collection Time: 4.83016
Timestep Consumption Time: 0.81138
PPO Batch Consumption Time: 0.03976
Total Iteration Time: 5.64154

Cumulative Model Updates: 2,417
Cumulative Timesteps: 40,413,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 40413250...
Checkpoint 40413250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.10260
Policy Entropy: 1.11936
Value Function Loss: 6.54270

Mean KL Divergence: 0.02497
SB3 Clip Fraction: 0.15902
Policy Update Magnitude: 0.04070
Value Function Update Magnitude: 0.05111

Collected Steps per Second: 10,540.42084
Overall Steps per Second: 8,944.34266

Timestep Collection Time: 4.74649
Timestep Consumption Time: 0.84699
PPO Batch Consumption Time: 0.04653
Total Iteration Time: 5.59348

Cumulative Model Updates: 2,420
Cumulative Timesteps: 40,463,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.97140
Policy Entropy: 1.11917
Value Function Loss: 6.48394

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.03906
Value Function Update Magnitude: 0.06094

Collected Steps per Second: 10,448.04749
Overall Steps per Second: 8,870.86952

Timestep Collection Time: 4.78845
Timestep Consumption Time: 0.85135
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 5.63981

Cumulative Model Updates: 2,423
Cumulative Timesteps: 40,513,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 40513310...
Checkpoint 40513310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.00596
Policy Entropy: 1.09600
Value Function Loss: 6.43367

Mean KL Divergence: 0.02778
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.06561

Collected Steps per Second: 10,907.12976
Overall Steps per Second: 9,084.15434

Timestep Collection Time: 4.58599
Timestep Consumption Time: 0.92030
PPO Batch Consumption Time: 0.03963
Total Iteration Time: 5.50629

Cumulative Model Updates: 2,426
Cumulative Timesteps: 40,563,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.50278
Policy Entropy: 1.09570
Value Function Loss: 6.46189

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.04003
Value Function Update Magnitude: 0.07979

Collected Steps per Second: 10,462.19695
Overall Steps per Second: 8,872.79412

Timestep Collection Time: 4.78045
Timestep Consumption Time: 0.85633
PPO Batch Consumption Time: 0.04630
Total Iteration Time: 5.63678

Cumulative Model Updates: 2,429
Cumulative Timesteps: 40,613,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 40613344...
Checkpoint 40613344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.34090
Policy Entropy: 1.08681
Value Function Loss: 6.70651

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.08269

Collected Steps per Second: 10,046.80918
Overall Steps per Second: 8,560.90877

Timestep Collection Time: 4.97830
Timestep Consumption Time: 0.86407
PPO Batch Consumption Time: 0.04616
Total Iteration Time: 5.84237

Cumulative Model Updates: 2,432
Cumulative Timesteps: 40,663,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.90276
Policy Entropy: 1.09367
Value Function Loss: 6.89121

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.07529

Collected Steps per Second: 10,632.45298
Overall Steps per Second: 9,089.16527

Timestep Collection Time: 4.70296
Timestep Consumption Time: 0.79854
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 5.50150

Cumulative Model Updates: 2,435
Cumulative Timesteps: 40,713,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 40713364...
Checkpoint 40713364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.33216
Policy Entropy: 1.10211
Value Function Loss: 6.84683

Mean KL Divergence: 0.02391
SB3 Clip Fraction: 0.16056
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.06838

Collected Steps per Second: 10,944.38476
Overall Steps per Second: 9,247.24085

Timestep Collection Time: 4.57276
Timestep Consumption Time: 0.83924
PPO Batch Consumption Time: 0.04467
Total Iteration Time: 5.41199

Cumulative Model Updates: 2,438
Cumulative Timesteps: 40,763,410

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.91020
Policy Entropy: 1.11882
Value Function Loss: 6.94394

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.15961
Policy Update Magnitude: 0.04381
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 10,700.38908
Overall Steps per Second: 9,057.11874

Timestep Collection Time: 4.67516
Timestep Consumption Time: 0.84823
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 5.52339

Cumulative Model Updates: 2,441
Cumulative Timesteps: 40,813,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 40813436...
Checkpoint 40813436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.98324
Policy Entropy: 1.10408
Value Function Loss: 6.66909

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.15323
Policy Update Magnitude: 0.03882
Value Function Update Magnitude: 0.06133

Collected Steps per Second: 10,639.96598
Overall Steps per Second: 9,070.89083

Timestep Collection Time: 4.70020
Timestep Consumption Time: 0.81304
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 5.51324

Cumulative Model Updates: 2,444
Cumulative Timesteps: 40,863,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.37231
Policy Entropy: 1.10091
Value Function Loss: 6.90024

Mean KL Divergence: 0.02143
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.03918
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 10,400.17331
Overall Steps per Second: 8,715.95661

Timestep Collection Time: 4.80800
Timestep Consumption Time: 0.92907
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 5.73706

Cumulative Model Updates: 2,447
Cumulative Timesteps: 40,913,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 40913450...
Checkpoint 40913450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.30599
Policy Entropy: 1.08718
Value Function Loss: 6.65674

Mean KL Divergence: 0.02428
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.04083
Value Function Update Magnitude: 0.06342

Collected Steps per Second: 10,389.23636
Overall Steps per Second: 8,866.87547

Timestep Collection Time: 4.81383
Timestep Consumption Time: 0.82649
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 5.64032

Cumulative Model Updates: 2,450
Cumulative Timesteps: 40,963,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.02251
Policy Entropy: 1.11017
Value Function Loss: 6.81472

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 10,869.83215
Overall Steps per Second: 9,195.33383

Timestep Collection Time: 4.60136
Timestep Consumption Time: 0.83792
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.43928

Cumulative Model Updates: 2,453
Cumulative Timesteps: 41,013,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 41013478...
Checkpoint 41013478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.92869
Policy Entropy: 1.10102
Value Function Loss: 6.84081

Mean KL Divergence: 0.02457
SB3 Clip Fraction: 0.15362
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.06724

Collected Steps per Second: 10,610.10029
Overall Steps per Second: 8,812.66504

Timestep Collection Time: 4.71287
Timestep Consumption Time: 0.96124
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 5.67411

Cumulative Model Updates: 2,456
Cumulative Timesteps: 41,063,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.23056
Policy Entropy: 1.12348
Value Function Loss: 7.02607

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.04188
Value Function Update Magnitude: 0.06294

Collected Steps per Second: 10,617.67798
Overall Steps per Second: 9,172.15137

Timestep Collection Time: 4.71214
Timestep Consumption Time: 0.74263
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 5.45477

Cumulative Model Updates: 2,459
Cumulative Timesteps: 41,113,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 41113514...
Checkpoint 41113514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.00942
Policy Entropy: 1.10852
Value Function Loss: 7.07661

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.04071
Value Function Update Magnitude: 0.05820

Collected Steps per Second: 10,676.14899
Overall Steps per Second: 9,055.53877

Timestep Collection Time: 4.68577
Timestep Consumption Time: 0.83858
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 5.52435

Cumulative Model Updates: 2,462
Cumulative Timesteps: 41,163,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.58381
Policy Entropy: 1.11148
Value Function Loss: 6.90304

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.04068
Value Function Update Magnitude: 0.04752

Collected Steps per Second: 10,333.00675
Overall Steps per Second: 8,846.52809

Timestep Collection Time: 4.84060
Timestep Consumption Time: 0.81336
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.65397

Cumulative Model Updates: 2,465
Cumulative Timesteps: 41,213,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 41213558...
Checkpoint 41213558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.16959
Policy Entropy: 1.09716
Value Function Loss: 6.77997

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.04158

Collected Steps per Second: 10,894.35440
Overall Steps per Second: 9,177.78698

Timestep Collection Time: 4.59137
Timestep Consumption Time: 0.85875
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.45012

Cumulative Model Updates: 2,468
Cumulative Timesteps: 41,263,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.82106
Policy Entropy: 1.12475
Value Function Loss: 6.70362

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.04087

Collected Steps per Second: 10,684.07919
Overall Steps per Second: 9,070.98089

Timestep Collection Time: 4.68267
Timestep Consumption Time: 0.83272
PPO Batch Consumption Time: 0.03972
Total Iteration Time: 5.51539

Cumulative Model Updates: 2,471
Cumulative Timesteps: 41,313,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 41313608...
Checkpoint 41313608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.27648
Policy Entropy: 1.11018
Value Function Loss: 6.38065

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.04122
Value Function Update Magnitude: 0.03392

Collected Steps per Second: 10,680.88758
Overall Steps per Second: 9,242.59895

Timestep Collection Time: 4.68313
Timestep Consumption Time: 0.72877
PPO Batch Consumption Time: 0.03926
Total Iteration Time: 5.41190

Cumulative Model Updates: 2,474
Cumulative Timesteps: 41,363,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.28392
Policy Entropy: 1.10988
Value Function Loss: 6.41048

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.04339
Value Function Update Magnitude: 0.05322

Collected Steps per Second: 10,632.31770
Overall Steps per Second: 8,991.62517

Timestep Collection Time: 4.70509
Timestep Consumption Time: 0.85853
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 5.56362

Cumulative Model Updates: 2,477
Cumulative Timesteps: 41,413,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 41413654...
Checkpoint 41413654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.12334
Policy Entropy: 1.09418
Value Function Loss: 6.47995

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.03843
Value Function Update Magnitude: 0.05317

Collected Steps per Second: 10,050.51248
Overall Steps per Second: 8,545.37485

Timestep Collection Time: 4.97845
Timestep Consumption Time: 0.87688
PPO Batch Consumption Time: 0.04668
Total Iteration Time: 5.85533

Cumulative Model Updates: 2,480
Cumulative Timesteps: 41,463,690

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.31882
Policy Entropy: 1.09999
Value Function Loss: 6.57706

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.03982
Value Function Update Magnitude: 0.05415

Collected Steps per Second: 10,724.80273
Overall Steps per Second: 9,056.64997

Timestep Collection Time: 4.66340
Timestep Consumption Time: 0.85896
PPO Batch Consumption Time: 0.04497
Total Iteration Time: 5.52235

Cumulative Model Updates: 2,483
Cumulative Timesteps: 41,513,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 41513704...
Checkpoint 41513704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.95383
Policy Entropy: 1.09301
Value Function Loss: 6.30001

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.06285

Collected Steps per Second: 10,456.16318
Overall Steps per Second: 8,842.04401

Timestep Collection Time: 4.78378
Timestep Consumption Time: 0.87328
PPO Batch Consumption Time: 0.04477
Total Iteration Time: 5.65706

Cumulative Model Updates: 2,486
Cumulative Timesteps: 41,563,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.00546
Policy Entropy: 1.09733
Value Function Loss: 6.54601

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.05064

Collected Steps per Second: 10,724.21146
Overall Steps per Second: 9,162.83091

Timestep Collection Time: 4.66403
Timestep Consumption Time: 0.79477
PPO Batch Consumption Time: 0.04606
Total Iteration Time: 5.45879

Cumulative Model Updates: 2,489
Cumulative Timesteps: 41,613,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 41613742...
Checkpoint 41613742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.74731
Policy Entropy: 1.09135
Value Function Loss: 6.53037

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.04469

Collected Steps per Second: 10,681.98788
Overall Steps per Second: 9,049.57114

Timestep Collection Time: 4.68078
Timestep Consumption Time: 0.84435
PPO Batch Consumption Time: 0.04391
Total Iteration Time: 5.52512

Cumulative Model Updates: 2,492
Cumulative Timesteps: 41,663,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.38294
Policy Entropy: 1.09190
Value Function Loss: 7.02739

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.04794

Collected Steps per Second: 10,571.82825
Overall Steps per Second: 8,885.48427

Timestep Collection Time: 4.72974
Timestep Consumption Time: 0.89764
PPO Batch Consumption Time: 0.04673
Total Iteration Time: 5.62738

Cumulative Model Updates: 2,495
Cumulative Timesteps: 41,713,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 41713744...
Checkpoint 41713744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.52874
Policy Entropy: 1.09640
Value Function Loss: 7.05768

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.06375
Value Function Update Magnitude: 0.04475

Collected Steps per Second: 11,004.06977
Overall Steps per Second: 9,287.08088

Timestep Collection Time: 4.54468
Timestep Consumption Time: 0.84022
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 5.38490

Cumulative Model Updates: 2,498
Cumulative Timesteps: 41,763,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.11271
Policy Entropy: 1.09784
Value Function Loss: 7.09574

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.06127
Value Function Update Magnitude: 0.03720

Collected Steps per Second: 10,993.30618
Overall Steps per Second: 9,290.53805

Timestep Collection Time: 4.54840
Timestep Consumption Time: 0.83363
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 5.38203

Cumulative Model Updates: 2,501
Cumulative Timesteps: 41,813,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 41813756...
Checkpoint 41813756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.91698
Policy Entropy: 1.12779
Value Function Loss: 6.88667

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07067
Policy Update Magnitude: 0.06696
Value Function Update Magnitude: 0.03565

Collected Steps per Second: 10,659.33669
Overall Steps per Second: 9,176.48646

Timestep Collection Time: 4.69335
Timestep Consumption Time: 0.75841
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 5.45176

Cumulative Model Updates: 2,504
Cumulative Timesteps: 41,863,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.53299
Policy Entropy: 1.11577
Value Function Loss: 6.77463

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.03652

Collected Steps per Second: 10,872.31309
Overall Steps per Second: 9,212.30890

Timestep Collection Time: 4.59921
Timestep Consumption Time: 0.82875
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 5.42796

Cumulative Model Updates: 2,507
Cumulative Timesteps: 41,913,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 41913788...
Checkpoint 41913788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.72350
Policy Entropy: 1.12067
Value Function Loss: 6.48184

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.03586

Collected Steps per Second: 10,680.00442
Overall Steps per Second: 9,081.20229

Timestep Collection Time: 4.68221
Timestep Consumption Time: 0.82433
PPO Batch Consumption Time: 0.04561
Total Iteration Time: 5.50654

Cumulative Model Updates: 2,510
Cumulative Timesteps: 41,963,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.43285
Policy Entropy: 1.11183
Value Function Loss: 6.44581

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.03335

Collected Steps per Second: 10,393.22280
Overall Steps per Second: 8,874.71868

Timestep Collection Time: 4.81083
Timestep Consumption Time: 0.82315
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 5.63398

Cumulative Model Updates: 2,513
Cumulative Timesteps: 42,013,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 42013794...
Checkpoint 42013794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.94697
Policy Entropy: 1.11223
Value Function Loss: 6.49297

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08287
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.05629

Collected Steps per Second: 10,671.44898
Overall Steps per Second: 8,956.79981

Timestep Collection Time: 4.68727
Timestep Consumption Time: 0.89731
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 5.58458

Cumulative Model Updates: 2,516
Cumulative Timesteps: 42,063,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.82734
Policy Entropy: 1.09723
Value Function Loss: 6.61957

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.07574
Value Function Update Magnitude: 0.08086

Collected Steps per Second: 10,863.22750
Overall Steps per Second: 9,184.91350

Timestep Collection Time: 4.60305
Timestep Consumption Time: 0.84109
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.44414

Cumulative Model Updates: 2,519
Cumulative Timesteps: 42,113,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 42113818...
Checkpoint 42113818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.36100
Policy Entropy: 1.09799
Value Function Loss: 6.93853

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.07284
Value Function Update Magnitude: 0.07691

Collected Steps per Second: 10,671.79728
Overall Steps per Second: 8,989.57717

Timestep Collection Time: 4.68675
Timestep Consumption Time: 0.87703
PPO Batch Consumption Time: 0.04488
Total Iteration Time: 5.56378

Cumulative Model Updates: 2,522
Cumulative Timesteps: 42,163,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.47983
Policy Entropy: 1.08645
Value Function Loss: 6.91165

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 10,413.83900
Overall Steps per Second: 8,976.40770

Timestep Collection Time: 4.80188
Timestep Consumption Time: 0.76895
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.57083

Cumulative Model Updates: 2,525
Cumulative Timesteps: 42,213,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 42213840...
Checkpoint 42213840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.44619
Policy Entropy: 1.08992
Value Function Loss: 6.98544

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.07437
Value Function Update Magnitude: 0.04578

Collected Steps per Second: 9,614.06041
Overall Steps per Second: 8,228.39170

Timestep Collection Time: 5.20342
Timestep Consumption Time: 0.87626
PPO Batch Consumption Time: 0.03956
Total Iteration Time: 6.07968

Cumulative Model Updates: 2,528
Cumulative Timesteps: 42,263,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.89195
Policy Entropy: 1.10122
Value Function Loss: 7.06661

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.04167

Collected Steps per Second: 10,639.31608
Overall Steps per Second: 8,992.51690

Timestep Collection Time: 4.69955
Timestep Consumption Time: 0.86063
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 5.56018

Cumulative Model Updates: 2,531
Cumulative Timesteps: 42,313,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 42313866...
Checkpoint 42313866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.61686
Policy Entropy: 1.12306
Value Function Loss: 6.69965

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.07053
Value Function Update Magnitude: 0.03635

Collected Steps per Second: 10,757.70635
Overall Steps per Second: 9,100.22014

Timestep Collection Time: 4.65062
Timestep Consumption Time: 0.84705
PPO Batch Consumption Time: 0.04637
Total Iteration Time: 5.49767

Cumulative Model Updates: 2,534
Cumulative Timesteps: 42,363,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.19437
Policy Entropy: 1.13853
Value Function Loss: 6.75640

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.03440

Collected Steps per Second: 10,891.39692
Overall Steps per Second: 9,209.02504

Timestep Collection Time: 4.59170
Timestep Consumption Time: 0.83884
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.43054

Cumulative Model Updates: 2,537
Cumulative Timesteps: 42,413,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 42413906...
Checkpoint 42413906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.72517
Policy Entropy: 1.10172
Value Function Loss: 6.51136

Mean KL Divergence: 0.03095
SB3 Clip Fraction: 0.16135
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.02975

Collected Steps per Second: 10,477.93586
Overall Steps per Second: 9,024.38126

Timestep Collection Time: 4.77231
Timestep Consumption Time: 0.76868
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 5.54099

Cumulative Model Updates: 2,540
Cumulative Timesteps: 42,463,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.01557
Policy Entropy: 1.12947
Value Function Loss: 6.48321

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.06063

Collected Steps per Second: 9,910.77390
Overall Steps per Second: 8,312.07822

Timestep Collection Time: 5.04623
Timestep Consumption Time: 0.97056
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 6.01679

Cumulative Model Updates: 2,543
Cumulative Timesteps: 42,513,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 42513922...
Checkpoint 42513922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.67939
Policy Entropy: 1.09693
Value Function Loss: 6.12075

Mean KL Divergence: 0.02953
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.06730

Collected Steps per Second: 9,650.65278
Overall Steps per Second: 8,474.82488

Timestep Collection Time: 5.18162
Timestep Consumption Time: 0.71892
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 5.90053

Cumulative Model Updates: 2,546
Cumulative Timesteps: 42,563,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.99035
Policy Entropy: 1.10814
Value Function Loss: 6.21462

Mean KL Divergence: 0.02643
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.06772

Collected Steps per Second: 10,418.60530
Overall Steps per Second: 8,839.33925

Timestep Collection Time: 4.80256
Timestep Consumption Time: 0.85804
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 5.66060

Cumulative Model Updates: 2,549
Cumulative Timesteps: 42,613,964

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 42613964...
Checkpoint 42613964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.56223
Policy Entropy: 1.09124
Value Function Loss: 6.30679

Mean KL Divergence: 0.02717
SB3 Clip Fraction: 0.15368
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.06188

Collected Steps per Second: 10,544.39869
Overall Steps per Second: 8,990.12720

Timestep Collection Time: 4.74394
Timestep Consumption Time: 0.82016
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 5.56410

Cumulative Model Updates: 2,552
Cumulative Timesteps: 42,663,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.05146
Policy Entropy: 1.10327
Value Function Loss: 6.62020

Mean KL Divergence: 0.02661
SB3 Clip Fraction: 0.16208
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.05475

Collected Steps per Second: 10,740.64857
Overall Steps per Second: 9,115.22953

Timestep Collection Time: 4.65819
Timestep Consumption Time: 0.83064
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 5.48884

Cumulative Model Updates: 2,555
Cumulative Timesteps: 42,714,018

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 42714018...
Checkpoint 42714018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.05085
Policy Entropy: 1.09531
Value Function Loss: 6.30154

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.06035

Collected Steps per Second: 10,536.44908
Overall Steps per Second: 8,923.96084

Timestep Collection Time: 4.74600
Timestep Consumption Time: 0.85756
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.60357

Cumulative Model Updates: 2,558
Cumulative Timesteps: 42,764,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.42147
Policy Entropy: 1.11533
Value Function Loss: 6.31197

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.06132

Collected Steps per Second: 10,005.66349
Overall Steps per Second: 8,694.66176

Timestep Collection Time: 4.99957
Timestep Consumption Time: 0.75385
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.75342

Cumulative Model Updates: 2,561
Cumulative Timesteps: 42,814,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 42814048...
Checkpoint 42814048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.91603
Policy Entropy: 1.10523
Value Function Loss: 6.13092

Mean KL Divergence: 0.03023
SB3 Clip Fraction: 0.17411
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.06215

Collected Steps per Second: 10,398.26827
Overall Steps per Second: 8,848.07448

Timestep Collection Time: 4.81099
Timestep Consumption Time: 0.84289
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 5.65389

Cumulative Model Updates: 2,564
Cumulative Timesteps: 42,864,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.74012
Policy Entropy: 1.12180
Value Function Loss: 6.44123

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.15665
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.05738

Collected Steps per Second: 10,620.26746
Overall Steps per Second: 9,142.33660

Timestep Collection Time: 4.70836
Timestep Consumption Time: 0.76114
PPO Batch Consumption Time: 0.04455
Total Iteration Time: 5.46950

Cumulative Model Updates: 2,567
Cumulative Timesteps: 42,914,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 42914078...
Checkpoint 42914078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.94838
Policy Entropy: 1.09933
Value Function Loss: 6.43900

Mean KL Divergence: 0.02759
SB3 Clip Fraction: 0.15922
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.05162

Collected Steps per Second: 10,648.74701
Overall Steps per Second: 9,062.14765

Timestep Collection Time: 4.69539
Timestep Consumption Time: 0.82207
PPO Batch Consumption Time: 0.04325
Total Iteration Time: 5.51746

Cumulative Model Updates: 2,570
Cumulative Timesteps: 42,964,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.73135
Policy Entropy: 1.11136
Value Function Loss: 6.47767

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.06111

Collected Steps per Second: 10,661.66865
Overall Steps per Second: 9,023.04286

Timestep Collection Time: 4.69007
Timestep Consumption Time: 0.85174
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 5.54181

Cumulative Model Updates: 2,573
Cumulative Timesteps: 43,014,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 43014082...
Checkpoint 43014082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.31564
Policy Entropy: 1.08525
Value Function Loss: 6.65509

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.14861
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.05986

Collected Steps per Second: 10,457.11379
Overall Steps per Second: 8,926.88178

Timestep Collection Time: 4.78392
Timestep Consumption Time: 0.82005
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.60397

Cumulative Model Updates: 2,576
Cumulative Timesteps: 43,064,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.64385
Policy Entropy: 1.10581
Value Function Loss: 6.66110

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.14787
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 10,550.17812
Overall Steps per Second: 8,934.36956

Timestep Collection Time: 4.74039
Timestep Consumption Time: 0.85731
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 5.59771

Cumulative Model Updates: 2,579
Cumulative Timesteps: 43,114,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 43114120...
Checkpoint 43114120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.29615
Policy Entropy: 1.09182
Value Function Loss: 6.64869

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.15502
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.05568

Collected Steps per Second: 10,557.19240
Overall Steps per Second: 9,139.31552

Timestep Collection Time: 4.73705
Timestep Consumption Time: 0.73491
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.47196

Cumulative Model Updates: 2,582
Cumulative Timesteps: 43,164,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.70064
Policy Entropy: 1.11238
Value Function Loss: 6.39551

Mean KL Divergence: 0.02502
SB3 Clip Fraction: 0.15802
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.05360

Collected Steps per Second: 10,084.99377
Overall Steps per Second: 8,504.64797

Timestep Collection Time: 4.95965
Timestep Consumption Time: 0.92161
PPO Batch Consumption Time: 0.04651
Total Iteration Time: 5.88125

Cumulative Model Updates: 2,585
Cumulative Timesteps: 43,214,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 43214148...
Checkpoint 43214148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.91744
Policy Entropy: 1.09924
Value Function Loss: 6.31548

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.05440

Collected Steps per Second: 10,274.52060
Overall Steps per Second: 8,794.24808

Timestep Collection Time: 4.86641
Timestep Consumption Time: 0.81913
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 5.68553

Cumulative Model Updates: 2,588
Cumulative Timesteps: 43,264,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.62589
Policy Entropy: 1.11033
Value Function Loss: 6.32225

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.05494

Collected Steps per Second: 10,790.49327
Overall Steps per Second: 9,127.71072

Timestep Collection Time: 4.63538
Timestep Consumption Time: 0.84442
PPO Batch Consumption Time: 0.04406
Total Iteration Time: 5.47980

Cumulative Model Updates: 2,591
Cumulative Timesteps: 43,314,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 43314166...
Checkpoint 43314166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.43115
Policy Entropy: 1.10628
Value Function Loss: 6.51760

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.05306

Collected Steps per Second: 10,190.70973
Overall Steps per Second: 8,660.60154

Timestep Collection Time: 4.90878
Timestep Consumption Time: 0.86726
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 5.77604

Cumulative Model Updates: 2,594
Cumulative Timesteps: 43,364,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.50450
Policy Entropy: 1.09992
Value Function Loss: 6.74486

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.04895

Collected Steps per Second: 10,757.95288
Overall Steps per Second: 9,267.71044

Timestep Collection Time: 4.64996
Timestep Consumption Time: 0.74771
PPO Batch Consumption Time: 0.03927
Total Iteration Time: 5.39767

Cumulative Model Updates: 2,597
Cumulative Timesteps: 43,414,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 43414214...
Checkpoint 43414214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.37843
Policy Entropy: 1.10810
Value Function Loss: 6.78653

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.05851

Collected Steps per Second: 10,626.88778
Overall Steps per Second: 8,950.77170

Timestep Collection Time: 4.70580
Timestep Consumption Time: 0.88121
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 5.58700

Cumulative Model Updates: 2,600
Cumulative Timesteps: 43,464,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.98013
Policy Entropy: 1.12133
Value Function Loss: 6.58293

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.05411

Collected Steps per Second: 10,450.25635
Overall Steps per Second: 8,978.12270

Timestep Collection Time: 4.78706
Timestep Consumption Time: 0.78493
PPO Batch Consumption Time: 0.04440
Total Iteration Time: 5.57199

Cumulative Model Updates: 2,603
Cumulative Timesteps: 43,514,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 43514248...
Checkpoint 43514248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.24170
Policy Entropy: 1.10888
Value Function Loss: 6.34925

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09669
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 10,386.01171
Overall Steps per Second: 8,809.11738

Timestep Collection Time: 4.81706
Timestep Consumption Time: 0.86229
PPO Batch Consumption Time: 0.04022
Total Iteration Time: 5.67934

Cumulative Model Updates: 2,606
Cumulative Timesteps: 43,564,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.19224
Policy Entropy: 1.10254
Value Function Loss: 6.24346

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.08890

Collected Steps per Second: 10,065.72146
Overall Steps per Second: 8,552.98503

Timestep Collection Time: 4.96815
Timestep Consumption Time: 0.87870
PPO Batch Consumption Time: 0.04538
Total Iteration Time: 5.84685

Cumulative Model Updates: 2,609
Cumulative Timesteps: 43,614,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 43614286...
Checkpoint 43614286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.10703
Policy Entropy: 1.09639
Value Function Loss: 6.50587

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.06479
Value Function Update Magnitude: 0.07326

Collected Steps per Second: 10,800.46660
Overall Steps per Second: 9,081.16929

Timestep Collection Time: 4.63202
Timestep Consumption Time: 0.87696
PPO Batch Consumption Time: 0.04002
Total Iteration Time: 5.50898

Cumulative Model Updates: 2,612
Cumulative Timesteps: 43,664,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.23652
Policy Entropy: 1.09401
Value Function Loss: 6.73318

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07374
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 10,563.48130
Overall Steps per Second: 9,004.81482

Timestep Collection Time: 4.73707
Timestep Consumption Time: 0.81995
PPO Batch Consumption Time: 0.04588
Total Iteration Time: 5.55703

Cumulative Model Updates: 2,615
Cumulative Timesteps: 43,714,354

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 43714354...
Checkpoint 43714354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.22624
Policy Entropy: 1.09652
Value Function Loss: 6.83320

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.05496

Collected Steps per Second: 10,491.26416
Overall Steps per Second: 9,034.99050

Timestep Collection Time: 4.76701
Timestep Consumption Time: 0.76835
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 5.53537

Cumulative Model Updates: 2,618
Cumulative Timesteps: 43,764,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.00524
Policy Entropy: 1.10534
Value Function Loss: 6.58297

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.05088

Collected Steps per Second: 10,556.46143
Overall Steps per Second: 8,997.22735

Timestep Collection Time: 4.73833
Timestep Consumption Time: 0.82116
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.55949

Cumulative Model Updates: 2,621
Cumulative Timesteps: 43,814,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 43814386...
Checkpoint 43814386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.45639
Policy Entropy: 1.09648
Value Function Loss: 6.42738

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.07112

Collected Steps per Second: 10,014.30647
Overall Steps per Second: 8,549.03658

Timestep Collection Time: 4.99445
Timestep Consumption Time: 0.85603
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 5.85048

Cumulative Model Updates: 2,624
Cumulative Timesteps: 43,864,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.83790
Policy Entropy: 1.07976
Value Function Loss: 6.25914

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.09032

Collected Steps per Second: 10,984.49442
Overall Steps per Second: 9,294.76949

Timestep Collection Time: 4.55442
Timestep Consumption Time: 0.82796
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 5.38238

Cumulative Model Updates: 2,627
Cumulative Timesteps: 43,914,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 43914430...
Checkpoint 43914430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.17179
Policy Entropy: 1.08185
Value Function Loss: 6.48026

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.08081

Collected Steps per Second: 10,762.98376
Overall Steps per Second: 8,981.35009

Timestep Collection Time: 4.64611
Timestep Consumption Time: 0.92165
PPO Batch Consumption Time: 0.04597
Total Iteration Time: 5.56776

Cumulative Model Updates: 2,630
Cumulative Timesteps: 43,964,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.44822
Policy Entropy: 1.09904
Value Function Loss: 6.38637

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.07655

Collected Steps per Second: 10,677.24668
Overall Steps per Second: 9,166.71484

Timestep Collection Time: 4.68566
Timestep Consumption Time: 0.77212
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 5.45779

Cumulative Model Updates: 2,633
Cumulative Timesteps: 44,014,466

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 44014466...
Checkpoint 44014466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.13646
Policy Entropy: 1.09617
Value Function Loss: 6.64789

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.07605

Collected Steps per Second: 10,696.41468
Overall Steps per Second: 8,999.60078

Timestep Collection Time: 4.67446
Timestep Consumption Time: 0.88134
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 5.55580

Cumulative Model Updates: 2,636
Cumulative Timesteps: 44,064,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.40564
Policy Entropy: 1.09097
Value Function Loss: 6.68623

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.06073

Collected Steps per Second: 10,644.49023
Overall Steps per Second: 9,043.59980

Timestep Collection Time: 4.69745
Timestep Consumption Time: 0.83154
PPO Batch Consumption Time: 0.04904
Total Iteration Time: 5.52899

Cumulative Model Updates: 2,639
Cumulative Timesteps: 44,114,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 44114468...
Checkpoint 44114468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.15609
Policy Entropy: 1.08146
Value Function Loss: 6.77062

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.07302

Collected Steps per Second: 10,143.55563
Overall Steps per Second: 8,798.78623

Timestep Collection Time: 4.93062
Timestep Consumption Time: 0.75357
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 5.68419

Cumulative Model Updates: 2,642
Cumulative Timesteps: 44,164,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.62067
Policy Entropy: 1.08468
Value Function Loss: 6.63242

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.06929

Collected Steps per Second: 10,727.81901
Overall Steps per Second: 9,082.40894

Timestep Collection Time: 4.66376
Timestep Consumption Time: 0.84491
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.50867

Cumulative Model Updates: 2,645
Cumulative Timesteps: 44,214,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 44214514...
Checkpoint 44214514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.59181
Policy Entropy: 1.07829
Value Function Loss: 6.52704

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.06701

Collected Steps per Second: 10,678.86998
Overall Steps per Second: 9,187.95094

Timestep Collection Time: 4.68271
Timestep Consumption Time: 0.75986
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 5.44256

Cumulative Model Updates: 2,648
Cumulative Timesteps: 44,264,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.97924
Policy Entropy: 1.05950
Value Function Loss: 6.37946

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.06822
Value Function Update Magnitude: 0.05934

Collected Steps per Second: 10,694.14695
Overall Steps per Second: 9,043.54585

Timestep Collection Time: 4.67714
Timestep Consumption Time: 0.85366
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 5.53080

Cumulative Model Updates: 2,651
Cumulative Timesteps: 44,314,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 44314538...
Checkpoint 44314538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.69128
Policy Entropy: 1.06232
Value Function Loss: 6.41449

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.06640
Value Function Update Magnitude: 0.07021

Collected Steps per Second: 11,045.43691
Overall Steps per Second: 9,363.26853

Timestep Collection Time: 4.52676
Timestep Consumption Time: 0.81326
PPO Batch Consumption Time: 0.03809
Total Iteration Time: 5.34002

Cumulative Model Updates: 2,654
Cumulative Timesteps: 44,364,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.32821
Policy Entropy: 1.07527
Value Function Loss: 6.53674

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.05748

Collected Steps per Second: 10,275.17275
Overall Steps per Second: 8,878.65902

Timestep Collection Time: 4.86727
Timestep Consumption Time: 0.76557
PPO Batch Consumption Time: 0.04680
Total Iteration Time: 5.63283

Cumulative Model Updates: 2,657
Cumulative Timesteps: 44,414,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 44414550...
Checkpoint 44414550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.16048
Policy Entropy: 1.08699
Value Function Loss: 6.62480

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 11,136.48638
Overall Steps per Second: 9,359.22533

Timestep Collection Time: 4.49208
Timestep Consumption Time: 0.85302
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 5.34510

Cumulative Model Updates: 2,660
Cumulative Timesteps: 44,464,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.70885
Policy Entropy: 1.08454
Value Function Loss: 6.62979

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.08159

Collected Steps per Second: 10,811.04863
Overall Steps per Second: 9,315.15564

Timestep Collection Time: 4.62767
Timestep Consumption Time: 0.74314
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 5.37082

Cumulative Model Updates: 2,663
Cumulative Timesteps: 44,514,606

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 44514606...
Checkpoint 44514606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.41141
Policy Entropy: 1.07637
Value Function Loss: 6.64734

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.07513

Collected Steps per Second: 11,013.67962
Overall Steps per Second: 9,335.93356

Timestep Collection Time: 4.54054
Timestep Consumption Time: 0.81597
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 5.35651

Cumulative Model Updates: 2,666
Cumulative Timesteps: 44,564,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.67433
Policy Entropy: 1.09030
Value Function Loss: 6.65288

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.06032

Collected Steps per Second: 10,817.95622
Overall Steps per Second: 9,185.09243

Timestep Collection Time: 4.62379
Timestep Consumption Time: 0.82199
PPO Batch Consumption Time: 0.04685
Total Iteration Time: 5.44578

Cumulative Model Updates: 2,669
Cumulative Timesteps: 44,614,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 44614634...
Checkpoint 44614634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.25322
Policy Entropy: 1.08338
Value Function Loss: 6.51625

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.05439

Collected Steps per Second: 10,721.80793
Overall Steps per Second: 9,075.31438

Timestep Collection Time: 4.66433
Timestep Consumption Time: 0.84623
PPO Batch Consumption Time: 0.04105
Total Iteration Time: 5.51055

Cumulative Model Updates: 2,672
Cumulative Timesteps: 44,664,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.92972
Policy Entropy: 1.08617
Value Function Loss: 6.43536

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.06242

Collected Steps per Second: 10,263.76497
Overall Steps per Second: 8,807.82863

Timestep Collection Time: 4.87307
Timestep Consumption Time: 0.80552
PPO Batch Consumption Time: 0.04595
Total Iteration Time: 5.67858

Cumulative Model Updates: 2,675
Cumulative Timesteps: 44,714,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 44714660...
Checkpoint 44714660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.31213
Policy Entropy: 1.07126
Value Function Loss: 6.60022

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.06801

Collected Steps per Second: 10,385.03910
Overall Steps per Second: 8,947.66085

Timestep Collection Time: 4.81674
Timestep Consumption Time: 0.77377
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 5.59051

Cumulative Model Updates: 2,678
Cumulative Timesteps: 44,764,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.27532
Policy Entropy: 1.08152
Value Function Loss: 6.75959

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.07026
Value Function Update Magnitude: 0.06583

Collected Steps per Second: 10,671.24786
Overall Steps per Second: 9,022.84351

Timestep Collection Time: 4.68699
Timestep Consumption Time: 0.85628
PPO Batch Consumption Time: 0.04719
Total Iteration Time: 5.54326

Cumulative Model Updates: 2,681
Cumulative Timesteps: 44,814,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 44814698...
Checkpoint 44814698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.01741
Policy Entropy: 1.08642
Value Function Loss: 6.43082

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.05698

Collected Steps per Second: 10,679.32268
Overall Steps per Second: 9,067.39182

Timestep Collection Time: 4.68419
Timestep Consumption Time: 0.83272
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.51691

Cumulative Model Updates: 2,684
Cumulative Timesteps: 44,864,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.64664
Policy Entropy: 1.06365
Value Function Loss: 6.55289

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.06744
Value Function Update Magnitude: 0.05254

Collected Steps per Second: 10,620.55509
Overall Steps per Second: 9,050.13752

Timestep Collection Time: 4.70842
Timestep Consumption Time: 0.81702
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 5.52544

Cumulative Model Updates: 2,687
Cumulative Timesteps: 44,914,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 44914728...
Checkpoint 44914728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.56639
Policy Entropy: 1.08790
Value Function Loss: 6.51972

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.05551

Collected Steps per Second: 10,077.93298
Overall Steps per Second: 8,641.89566

Timestep Collection Time: 4.96193
Timestep Consumption Time: 0.82453
PPO Batch Consumption Time: 0.04573
Total Iteration Time: 5.78646

Cumulative Model Updates: 2,690
Cumulative Timesteps: 44,964,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.79612
Policy Entropy: 1.08601
Value Function Loss: 6.67458

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.05311

Collected Steps per Second: 10,323.04138
Overall Steps per Second: 8,999.11450

Timestep Collection Time: 4.84392
Timestep Consumption Time: 0.71263
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 5.55655

Cumulative Model Updates: 2,693
Cumulative Timesteps: 45,014,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 45014738...
Checkpoint 45014738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.78873
Policy Entropy: 1.08027
Value Function Loss: 6.49948

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.07672
Value Function Update Magnitude: 0.05278

Collected Steps per Second: 10,466.65329
Overall Steps per Second: 8,883.11173

Timestep Collection Time: 4.77899
Timestep Consumption Time: 0.85192
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 5.63091

Cumulative Model Updates: 2,696
Cumulative Timesteps: 45,064,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.78556
Policy Entropy: 1.08170
Value Function Loss: 6.06279

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.07482
Value Function Update Magnitude: 0.04684

Collected Steps per Second: 10,498.74012
Overall Steps per Second: 9,108.81305

Timestep Collection Time: 4.76305
Timestep Consumption Time: 0.72680
PPO Batch Consumption Time: 0.04501
Total Iteration Time: 5.48985

Cumulative Model Updates: 2,699
Cumulative Timesteps: 45,114,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 45114764...
Checkpoint 45114764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.29359
Policy Entropy: 1.08985
Value Function Loss: 6.21702

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.08288
Value Function Update Magnitude: 0.03828

Collected Steps per Second: 10,655.64825
Overall Steps per Second: 9,052.04901

Timestep Collection Time: 4.69497
Timestep Consumption Time: 0.83173
PPO Batch Consumption Time: 0.04477
Total Iteration Time: 5.52670

Cumulative Model Updates: 2,702
Cumulative Timesteps: 45,164,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.87700
Policy Entropy: 1.11043
Value Function Loss: 6.26889

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.06561
Value Function Update Magnitude: 0.03701

Collected Steps per Second: 10,454.40359
Overall Steps per Second: 8,873.93396

Timestep Collection Time: 4.78554
Timestep Consumption Time: 0.85232
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.63786

Cumulative Model Updates: 2,705
Cumulative Timesteps: 45,214,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 45214822...
Checkpoint 45214822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.91913
Policy Entropy: 1.08798
Value Function Loss: 6.50351

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.14203
Policy Update Magnitude: 0.07307
Value Function Update Magnitude: 0.03249

Collected Steps per Second: 10,785.98539
Overall Steps per Second: 9,066.57811

Timestep Collection Time: 4.63657
Timestep Consumption Time: 0.87929
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 5.51586

Cumulative Model Updates: 2,708
Cumulative Timesteps: 45,264,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.43775
Policy Entropy: 1.10393
Value Function Loss: 6.61466

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.04517

Collected Steps per Second: 10,645.74622
Overall Steps per Second: 9,055.61705

Timestep Collection Time: 4.69803
Timestep Consumption Time: 0.82495
PPO Batch Consumption Time: 0.04268
Total Iteration Time: 5.52298

Cumulative Model Updates: 2,711
Cumulative Timesteps: 45,314,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 45314846...
Checkpoint 45314846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.04519
Policy Entropy: 1.08009
Value Function Loss: 6.58283

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.04313

Collected Steps per Second: 10,778.58943
Overall Steps per Second: 9,258.35937

Timestep Collection Time: 4.64087
Timestep Consumption Time: 0.76203
PPO Batch Consumption Time: 0.04610
Total Iteration Time: 5.40290

Cumulative Model Updates: 2,714
Cumulative Timesteps: 45,364,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.96620
Policy Entropy: 1.09220
Value Function Loss: 6.60694

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.05056

Collected Steps per Second: 10,674.33090
Overall Steps per Second: 8,944.37877

Timestep Collection Time: 4.68601
Timestep Consumption Time: 0.90633
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 5.59234

Cumulative Model Updates: 2,717
Cumulative Timesteps: 45,414,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 45414888...
Checkpoint 45414888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.59173
Policy Entropy: 1.10716
Value Function Loss: 6.73978

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.04701

Collected Steps per Second: 10,200.40880
Overall Steps per Second: 8,812.61232

Timestep Collection Time: 4.90196
Timestep Consumption Time: 0.77195
PPO Batch Consumption Time: 0.03955
Total Iteration Time: 5.67391

Cumulative Model Updates: 2,720
Cumulative Timesteps: 45,464,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.89619
Policy Entropy: 1.12101
Value Function Loss: 6.52042

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.03657
Value Function Update Magnitude: 0.03743

Collected Steps per Second: 9,979.32922
Overall Steps per Second: 8,469.97234

Timestep Collection Time: 5.01176
Timestep Consumption Time: 0.89310
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 5.90486

Cumulative Model Updates: 2,723
Cumulative Timesteps: 45,514,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 45514904...
Checkpoint 45514904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.54272
Policy Entropy: 1.08960
Value Function Loss: 6.31340

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 10,583.79520
Overall Steps per Second: 8,994.45224

Timestep Collection Time: 4.72704
Timestep Consumption Time: 0.83528
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 5.56232

Cumulative Model Updates: 2,726
Cumulative Timesteps: 45,564,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.05116
Policy Entropy: 1.07988
Value Function Loss: 6.20780

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.04389
Value Function Update Magnitude: 0.07531

Collected Steps per Second: 10,661.88439
Overall Steps per Second: 9,270.68962

Timestep Collection Time: 4.69110
Timestep Consumption Time: 0.70396
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.39507

Cumulative Model Updates: 2,729
Cumulative Timesteps: 45,614,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 45614950...
Checkpoint 45614950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.92738
Policy Entropy: 1.08736
Value Function Loss: 6.27735

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06828
Policy Update Magnitude: 0.06091
Value Function Update Magnitude: 0.09357

Collected Steps per Second: 10,978.03302
Overall Steps per Second: 9,278.81450

Timestep Collection Time: 4.55528
Timestep Consumption Time: 0.83420
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 5.38948

Cumulative Model Updates: 2,732
Cumulative Timesteps: 45,664,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.98360
Policy Entropy: 1.12535
Value Function Loss: 6.06750

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.07052
Value Function Update Magnitude: 0.08242

Collected Steps per Second: 10,566.60070
Overall Steps per Second: 8,940.88284

Timestep Collection Time: 4.73454
Timestep Consumption Time: 0.86088
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 5.59542

Cumulative Model Updates: 2,735
Cumulative Timesteps: 45,714,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 45714986...
Checkpoint 45714986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.26773
Policy Entropy: 1.10078
Value Function Loss: 6.04537

Mean KL Divergence: 0.03217
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.07457

Collected Steps per Second: 10,247.50030
Overall Steps per Second: 8,757.40454

Timestep Collection Time: 4.88178
Timestep Consumption Time: 0.83065
PPO Batch Consumption Time: 0.03963
Total Iteration Time: 5.71242

Cumulative Model Updates: 2,738
Cumulative Timesteps: 45,765,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.48665
Policy Entropy: 1.11418
Value Function Loss: 5.94851

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 10,218.61190
Overall Steps per Second: 8,667.63226

Timestep Collection Time: 4.89499
Timestep Consumption Time: 0.87591
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 5.77090

Cumulative Model Updates: 2,741
Cumulative Timesteps: 45,815,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 45815032...
Checkpoint 45815032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.42132
Policy Entropy: 1.10207
Value Function Loss: 6.09926

Mean KL Divergence: 0.03280
SB3 Clip Fraction: 0.16593
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.06704

Collected Steps per Second: 10,452.95068
Overall Steps per Second: 9,054.22497

Timestep Collection Time: 4.78583
Timestep Consumption Time: 0.73933
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 5.52516

Cumulative Model Updates: 2,744
Cumulative Timesteps: 45,865,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.61548
Policy Entropy: 1.10613
Value Function Loss: 6.03365

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.04184
Value Function Update Magnitude: 0.05511

Collected Steps per Second: 10,561.88587
Overall Steps per Second: 8,909.77184

Timestep Collection Time: 4.73665
Timestep Consumption Time: 0.87830
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.61496

Cumulative Model Updates: 2,747
Cumulative Timesteps: 45,915,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 45915086...
Checkpoint 45915086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.93055
Policy Entropy: 1.10243
Value Function Loss: 6.17356

Mean KL Divergence: 0.03453
SB3 Clip Fraction: 0.15203
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.05389

Collected Steps per Second: 10,492.47783
Overall Steps per Second: 9,008.47285

Timestep Collection Time: 4.76646
Timestep Consumption Time: 0.78520
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 5.55166

Cumulative Model Updates: 2,750
Cumulative Timesteps: 45,965,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.03494
Policy Entropy: 1.10276
Value Function Loss: 6.29331

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.05070

Collected Steps per Second: 10,801.38598
Overall Steps per Second: 8,992.93077

Timestep Collection Time: 4.62941
Timestep Consumption Time: 0.93096
PPO Batch Consumption Time: 0.03889
Total Iteration Time: 5.56037

Cumulative Model Updates: 2,753
Cumulative Timesteps: 46,015,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 46015102...
Checkpoint 46015102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.01272
Policy Entropy: 1.09903
Value Function Loss: 6.21261

Mean KL Divergence: 0.02927
SB3 Clip Fraction: 0.15531
Policy Update Magnitude: 0.04462
Value Function Update Magnitude: 0.05356

Collected Steps per Second: 10,202.06017
Overall Steps per Second: 8,650.67094

Timestep Collection Time: 4.90097
Timestep Consumption Time: 0.87893
PPO Batch Consumption Time: 0.04586
Total Iteration Time: 5.77990

Cumulative Model Updates: 2,756
Cumulative Timesteps: 46,065,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.16123
Policy Entropy: 1.10261
Value Function Loss: 6.01661

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.05969

Collected Steps per Second: 10,761.15313
Overall Steps per Second: 9,336.21912

Timestep Collection Time: 4.64839
Timestep Consumption Time: 0.70946
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.35784

Cumulative Model Updates: 2,759
Cumulative Timesteps: 46,115,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 46115124...
Checkpoint 46115124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.56956
Policy Entropy: 1.09785
Value Function Loss: 5.96900

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.11968
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.05729

Collected Steps per Second: 10,387.21355
Overall Steps per Second: 8,852.24415

Timestep Collection Time: 4.81457
Timestep Consumption Time: 0.83484
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 5.64941

Cumulative Model Updates: 2,762
Cumulative Timesteps: 46,165,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.23550
Policy Entropy: 1.08654
Value Function Loss: 6.13056

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.05090

Collected Steps per Second: 10,849.31441
Overall Steps per Second: 9,209.52933

Timestep Collection Time: 4.60969
Timestep Consumption Time: 0.82077
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 5.43046

Cumulative Model Updates: 2,765
Cumulative Timesteps: 46,215,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 46215146...
Checkpoint 46215146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.47722
Policy Entropy: 1.09821
Value Function Loss: 6.06222

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.04412

Collected Steps per Second: 10,659.16191
Overall Steps per Second: 9,013.12011

Timestep Collection Time: 4.69249
Timestep Consumption Time: 0.85698
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 5.54947

Cumulative Model Updates: 2,768
Cumulative Timesteps: 46,265,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.76632
Policy Entropy: 1.10706
Value Function Loss: 6.31386

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.06479

Collected Steps per Second: 10,202.48578
Overall Steps per Second: 8,684.78719

Timestep Collection Time: 4.90175
Timestep Consumption Time: 0.85660
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 5.75834

Cumulative Model Updates: 2,771
Cumulative Timesteps: 46,315,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 46315174...
Checkpoint 46315174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.52076
Policy Entropy: 1.09946
Value Function Loss: 6.00015

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07323
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.06226

Collected Steps per Second: 10,824.70133
Overall Steps per Second: 9,093.96786

Timestep Collection Time: 4.61999
Timestep Consumption Time: 0.87926
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 5.49925

Cumulative Model Updates: 2,774
Cumulative Timesteps: 46,365,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.84185
Policy Entropy: 1.07724
Value Function Loss: 6.20322

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.07184
Value Function Update Magnitude: 0.05824

Collected Steps per Second: 10,551.36640
Overall Steps per Second: 8,947.43794

Timestep Collection Time: 4.73891
Timestep Consumption Time: 0.84950
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 5.58842

Cumulative Model Updates: 2,777
Cumulative Timesteps: 46,415,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 46415186...
Checkpoint 46415186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.27180
Policy Entropy: 1.07718
Value Function Loss: 6.16016

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.06771
Value Function Update Magnitude: 0.05468

Collected Steps per Second: 10,505.93233
Overall Steps per Second: 9,077.59754

Timestep Collection Time: 4.76093
Timestep Consumption Time: 0.74912
PPO Batch Consumption Time: 0.04277
Total Iteration Time: 5.51005

Cumulative Model Updates: 2,780
Cumulative Timesteps: 46,465,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.35441
Policy Entropy: 1.07494
Value Function Loss: 6.20607

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.04789

Collected Steps per Second: 10,872.25137
Overall Steps per Second: 9,057.90095

Timestep Collection Time: 4.59886
Timestep Consumption Time: 0.92118
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.52004

Cumulative Model Updates: 2,783
Cumulative Timesteps: 46,515,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 46515204...
Checkpoint 46515204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.77966
Policy Entropy: 1.07463
Value Function Loss: 6.02988

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.06803
Value Function Update Magnitude: 0.04901

Collected Steps per Second: 10,380.03499
Overall Steps per Second: 8,837.61878

Timestep Collection Time: 4.81732
Timestep Consumption Time: 0.84076
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 5.65809

Cumulative Model Updates: 2,786
Cumulative Timesteps: 46,565,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.79874
Policy Entropy: 1.07983
Value Function Loss: 5.93545

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.04639

Collected Steps per Second: 11,246.65534
Overall Steps per Second: 9,260.24674

Timestep Collection Time: 4.44701
Timestep Consumption Time: 0.95392
PPO Batch Consumption Time: 0.04766
Total Iteration Time: 5.40094

Cumulative Model Updates: 2,789
Cumulative Timesteps: 46,615,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 46615222...
Checkpoint 46615222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.00108
Policy Entropy: 1.09614
Value Function Loss: 5.80113

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.05413

Collected Steps per Second: 10,843.77324
Overall Steps per Second: 9,219.51081

Timestep Collection Time: 4.61131
Timestep Consumption Time: 0.81241
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 5.42372

Cumulative Model Updates: 2,792
Cumulative Timesteps: 46,665,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.91678
Policy Entropy: 1.08673
Value Function Loss: 5.86426

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.05393

Collected Steps per Second: 10,859.87425
Overall Steps per Second: 9,324.75411

Timestep Collection Time: 4.60503
Timestep Consumption Time: 0.75812
PPO Batch Consumption Time: 0.03952
Total Iteration Time: 5.36314

Cumulative Model Updates: 2,795
Cumulative Timesteps: 46,715,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 46715236...
Checkpoint 46715236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.72462
Policy Entropy: 1.08998
Value Function Loss: 5.94204

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.06127

Collected Steps per Second: 10,767.29380
Overall Steps per Second: 9,043.59376

Timestep Collection Time: 4.64499
Timestep Consumption Time: 0.88533
PPO Batch Consumption Time: 0.04708
Total Iteration Time: 5.53032

Cumulative Model Updates: 2,798
Cumulative Timesteps: 46,765,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.73562
Policy Entropy: 1.09840
Value Function Loss: 5.96348

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.07170
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 10,729.33294
Overall Steps per Second: 9,164.60078

Timestep Collection Time: 4.66180
Timestep Consumption Time: 0.79594
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 5.45774

Cumulative Model Updates: 2,801
Cumulative Timesteps: 46,815,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 46815268...
Checkpoint 46815268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.91065
Policy Entropy: 1.09957
Value Function Loss: 6.20025

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.07535
Value Function Update Magnitude: 0.05851

Collected Steps per Second: 10,204.36977
Overall Steps per Second: 8,653.50395

Timestep Collection Time: 4.90123
Timestep Consumption Time: 0.87839
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 5.77962

Cumulative Model Updates: 2,804
Cumulative Timesteps: 46,865,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.30329
Policy Entropy: 1.10978
Value Function Loss: 6.17031

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.06651
Value Function Update Magnitude: 0.05454

Collected Steps per Second: 10,824.04228
Overall Steps per Second: 9,223.07226

Timestep Collection Time: 4.62027
Timestep Consumption Time: 0.80200
PPO Batch Consumption Time: 0.03877
Total Iteration Time: 5.42227

Cumulative Model Updates: 2,807
Cumulative Timesteps: 46,915,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 46915292...
Checkpoint 46915292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.67832
Policy Entropy: 1.08962
Value Function Loss: 6.37171

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.08085
Value Function Update Magnitude: 0.05192

Collected Steps per Second: 10,610.69176
Overall Steps per Second: 9,102.70606

Timestep Collection Time: 4.71242
Timestep Consumption Time: 0.78068
PPO Batch Consumption Time: 0.04943
Total Iteration Time: 5.49309

Cumulative Model Updates: 2,810
Cumulative Timesteps: 46,965,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.44852
Policy Entropy: 1.09195
Value Function Loss: 6.46810

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.08584
Value Function Update Magnitude: 0.05840

Collected Steps per Second: 10,724.17144
Overall Steps per Second: 9,150.03509

Timestep Collection Time: 4.66423
Timestep Consumption Time: 0.80242
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 5.46665

Cumulative Model Updates: 2,813
Cumulative Timesteps: 47,015,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 47015314...
Checkpoint 47015314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.80354
Policy Entropy: 1.09135
Value Function Loss: 6.43955

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.07088
Value Function Update Magnitude: 0.04767

Collected Steps per Second: 10,598.87119
Overall Steps per Second: 8,992.30643

Timestep Collection Time: 4.71843
Timestep Consumption Time: 0.84299
PPO Batch Consumption Time: 0.04580
Total Iteration Time: 5.56142

Cumulative Model Updates: 2,816
Cumulative Timesteps: 47,065,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.25475
Policy Entropy: 1.11861
Value Function Loss: 6.20496

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.04633

Collected Steps per Second: 10,395.11733
Overall Steps per Second: 8,866.56155

Timestep Collection Time: 4.81168
Timestep Consumption Time: 0.82951
PPO Batch Consumption Time: 0.04605
Total Iteration Time: 5.64119

Cumulative Model Updates: 2,819
Cumulative Timesteps: 47,115,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 47115342...
Checkpoint 47115342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.25324
Policy Entropy: 1.12457
Value Function Loss: 5.86271

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.04602

Collected Steps per Second: 10,605.59680
Overall Steps per Second: 8,979.06820

Timestep Collection Time: 4.71525
Timestep Consumption Time: 0.85415
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 5.56940

Cumulative Model Updates: 2,822
Cumulative Timesteps: 47,165,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.51387
Policy Entropy: 1.11355
Value Function Loss: 5.97328

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.05033

Collected Steps per Second: 10,667.56206
Overall Steps per Second: 9,242.13820

Timestep Collection Time: 4.69011
Timestep Consumption Time: 0.72336
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 5.41347

Cumulative Model Updates: 2,825
Cumulative Timesteps: 47,215,382

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 47215382...
Checkpoint 47215382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.91245
Policy Entropy: 1.09586
Value Function Loss: 6.15203

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.05091

Collected Steps per Second: 10,805.68173
Overall Steps per Second: 9,172.48986

Timestep Collection Time: 4.62757
Timestep Consumption Time: 0.82395
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 5.45152

Cumulative Model Updates: 2,828
Cumulative Timesteps: 47,265,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.99788
Policy Entropy: 1.12351
Value Function Loss: 6.14206

Mean KL Divergence: 0.03140
SB3 Clip Fraction: 0.16260
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.06758

Collected Steps per Second: 10,348.46872
Overall Steps per Second: 8,791.95037

Timestep Collection Time: 4.83337
Timestep Consumption Time: 0.85570
PPO Batch Consumption Time: 0.04177
Total Iteration Time: 5.68907

Cumulative Model Updates: 2,831
Cumulative Timesteps: 47,315,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 47315404...
Checkpoint 47315404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.50283
Policy Entropy: 1.10495
Value Function Loss: 6.10060

Mean KL Divergence: 0.02455
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.04216
Value Function Update Magnitude: 0.05822

Collected Steps per Second: 10,541.89900
Overall Steps per Second: 9,019.14784

Timestep Collection Time: 4.74526
Timestep Consumption Time: 0.80117
PPO Batch Consumption Time: 0.04604
Total Iteration Time: 5.54642

Cumulative Model Updates: 2,834
Cumulative Timesteps: 47,365,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.39925
Policy Entropy: 1.12807
Value Function Loss: 6.21235

Mean KL Divergence: 0.03205
SB3 Clip Fraction: 0.15569
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.06119

Collected Steps per Second: 10,558.06980
Overall Steps per Second: 8,978.51306

Timestep Collection Time: 4.73837
Timestep Consumption Time: 0.83360
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 5.57197

Cumulative Model Updates: 2,837
Cumulative Timesteps: 47,415,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 47415456...
Checkpoint 47415456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.48049
Policy Entropy: 1.11144
Value Function Loss: 6.21150

Mean KL Divergence: 0.03724
SB3 Clip Fraction: 0.15591
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 10,622.21448
Overall Steps per Second: 9,173.11168

Timestep Collection Time: 4.70712
Timestep Consumption Time: 0.74360
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 5.45071

Cumulative Model Updates: 2,840
Cumulative Timesteps: 47,465,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.52485
Policy Entropy: 1.11047
Value Function Loss: 6.41700

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.05404

Collected Steps per Second: 10,692.31911
Overall Steps per Second: 8,925.45548

Timestep Collection Time: 4.67887
Timestep Consumption Time: 0.92622
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 5.60509

Cumulative Model Updates: 2,843
Cumulative Timesteps: 47,515,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 47515484...
Checkpoint 47515484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.42862
Policy Entropy: 1.10656
Value Function Loss: 6.29666

Mean KL Divergence: 0.03173
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.04801

Collected Steps per Second: 10,857.79230
Overall Steps per Second: 9,204.38642

Timestep Collection Time: 4.60536
Timestep Consumption Time: 0.82727
PPO Batch Consumption Time: 0.04446
Total Iteration Time: 5.43263

Cumulative Model Updates: 2,846
Cumulative Timesteps: 47,565,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.17615
Policy Entropy: 1.11040
Value Function Loss: 6.30415

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.04145

Collected Steps per Second: 10,846.34819
Overall Steps per Second: 9,345.13045

Timestep Collection Time: 4.61224
Timestep Consumption Time: 0.74092
PPO Batch Consumption Time: 0.03963
Total Iteration Time: 5.35316

Cumulative Model Updates: 2,849
Cumulative Timesteps: 47,615,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 47615514...
Checkpoint 47615514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.49234
Policy Entropy: 1.10374
Value Function Loss: 6.36828

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.04308

Collected Steps per Second: 10,020.14425
Overall Steps per Second: 8,560.19985

Timestep Collection Time: 4.99234
Timestep Consumption Time: 0.85145
PPO Batch Consumption Time: 0.04425
Total Iteration Time: 5.84379

Cumulative Model Updates: 2,852
Cumulative Timesteps: 47,665,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.95483
Policy Entropy: 1.10182
Value Function Loss: 6.19256

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.04772

Collected Steps per Second: 10,133.31755
Overall Steps per Second: 8,756.82159

Timestep Collection Time: 4.93619
Timestep Consumption Time: 0.77593
PPO Batch Consumption Time: 0.04755
Total Iteration Time: 5.71212

Cumulative Model Updates: 2,855
Cumulative Timesteps: 47,715,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 47715558...
Checkpoint 47715558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.35433
Policy Entropy: 1.10022
Value Function Loss: 6.34750

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.05900

Collected Steps per Second: 10,668.87636
Overall Steps per Second: 9,041.75996

Timestep Collection Time: 4.68915
Timestep Consumption Time: 0.84384
PPO Batch Consumption Time: 0.03842
Total Iteration Time: 5.53299

Cumulative Model Updates: 2,858
Cumulative Timesteps: 47,765,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.19767
Policy Entropy: 1.10425
Value Function Loss: 6.30562

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.10676
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.07051

Collected Steps per Second: 10,834.10312
Overall Steps per Second: 9,170.11891

Timestep Collection Time: 4.61635
Timestep Consumption Time: 0.83767
PPO Batch Consumption Time: 0.03993
Total Iteration Time: 5.45402

Cumulative Model Updates: 2,861
Cumulative Timesteps: 47,815,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 47815600...
Checkpoint 47815600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.62672
Policy Entropy: 1.08610
Value Function Loss: 6.42091

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07391
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.05876

Collected Steps per Second: 10,756.12556
Overall Steps per Second: 9,028.96184

Timestep Collection Time: 4.65000
Timestep Consumption Time: 0.88951
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 5.53951

Cumulative Model Updates: 2,864
Cumulative Timesteps: 47,865,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.93652
Policy Entropy: 1.08494
Value Function Loss: 6.46449

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.06294
Value Function Update Magnitude: 0.06193

Collected Steps per Second: 10,109.39635
Overall Steps per Second: 8,622.46202

Timestep Collection Time: 4.94629
Timestep Consumption Time: 0.85298
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 5.79927

Cumulative Model Updates: 2,867
Cumulative Timesteps: 47,915,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 47915620...
Checkpoint 47915620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.58921
Policy Entropy: 1.10098
Value Function Loss: 6.21267

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.05555
Policy Update Magnitude: 0.07578
Value Function Update Magnitude: 0.06977

Collected Steps per Second: 10,529.97956
Overall Steps per Second: 9,078.75836

Timestep Collection Time: 4.74949
Timestep Consumption Time: 0.75920
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 5.50868

Cumulative Model Updates: 2,870
Cumulative Timesteps: 47,965,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.85047
Policy Entropy: 1.11343
Value Function Loss: 6.14681

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07061
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.05957

Collected Steps per Second: 10,752.12247
Overall Steps per Second: 8,981.99286

Timestep Collection Time: 4.65117
Timestep Consumption Time: 0.91663
PPO Batch Consumption Time: 0.04693
Total Iteration Time: 5.56781

Cumulative Model Updates: 2,873
Cumulative Timesteps: 48,015,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 48015642...
Checkpoint 48015642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.34218
Policy Entropy: 1.10773
Value Function Loss: 5.83248

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.05645

Collected Steps per Second: 10,600.89488
Overall Steps per Second: 9,109.47604

Timestep Collection Time: 4.71734
Timestep Consumption Time: 0.77233
PPO Batch Consumption Time: 0.04846
Total Iteration Time: 5.48967

Cumulative Model Updates: 2,876
Cumulative Timesteps: 48,065,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.65930
Policy Entropy: 1.13346
Value Function Loss: 6.09533

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.04438

Collected Steps per Second: 10,752.76563
Overall Steps per Second: 9,023.74717

Timestep Collection Time: 4.65052
Timestep Consumption Time: 0.89108
PPO Batch Consumption Time: 0.03972
Total Iteration Time: 5.54160

Cumulative Model Updates: 2,879
Cumulative Timesteps: 48,115,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 48115656...
Checkpoint 48115656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.67034
Policy Entropy: 1.10824
Value Function Loss: 6.07345

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.06273
Value Function Update Magnitude: 0.05830

Collected Steps per Second: 10,615.58549
Overall Steps per Second: 8,898.88332

Timestep Collection Time: 4.71006
Timestep Consumption Time: 0.90863
PPO Batch Consumption Time: 0.04602
Total Iteration Time: 5.61868

Cumulative Model Updates: 2,882
Cumulative Timesteps: 48,165,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.65100
Policy Entropy: 1.11604
Value Function Loss: 6.00027

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.06691
Value Function Update Magnitude: 0.04386

Collected Steps per Second: 10,448.29326
Overall Steps per Second: 8,919.36733

Timestep Collection Time: 4.78566
Timestep Consumption Time: 0.82034
PPO Batch Consumption Time: 0.04172
Total Iteration Time: 5.60600

Cumulative Model Updates: 2,885
Cumulative Timesteps: 48,215,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 48215658...
Checkpoint 48215658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.34044
Policy Entropy: 1.09737
Value Function Loss: 5.95956

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.07483
Value Function Update Magnitude: 0.04165

Collected Steps per Second: 10,547.19078
Overall Steps per Second: 8,912.54971

Timestep Collection Time: 4.74136
Timestep Consumption Time: 0.86961
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 5.61096

Cumulative Model Updates: 2,888
Cumulative Timesteps: 48,265,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.16532
Policy Entropy: 1.10306
Value Function Loss: 6.16021

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06731
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.05059

Collected Steps per Second: 10,642.01830
Overall Steps per Second: 8,991.73845

Timestep Collection Time: 4.70005
Timestep Consumption Time: 0.86261
PPO Batch Consumption Time: 0.03942
Total Iteration Time: 5.56266

Cumulative Model Updates: 2,891
Cumulative Timesteps: 48,315,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 48315684...
Checkpoint 48315684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.25885
Policy Entropy: 1.08422
Value Function Loss: 6.32577

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.06836
Value Function Update Magnitude: 0.03949

Collected Steps per Second: 10,700.95743
Overall Steps per Second: 8,991.25956

Timestep Collection Time: 4.67379
Timestep Consumption Time: 0.88873
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 5.56251

Cumulative Model Updates: 2,894
Cumulative Timesteps: 48,365,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.59859
Policy Entropy: 1.11414
Value Function Loss: 6.33138

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.03200

Collected Steps per Second: 10,532.35959
Overall Steps per Second: 9,065.73884

Timestep Collection Time: 4.74936
Timestep Consumption Time: 0.76833
PPO Batch Consumption Time: 0.03923
Total Iteration Time: 5.51770

Cumulative Model Updates: 2,897
Cumulative Timesteps: 48,415,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 48415720...
Checkpoint 48415720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.70567
Policy Entropy: 1.10541
Value Function Loss: 5.84948

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.03292

Collected Steps per Second: 10,060.82686
Overall Steps per Second: 8,612.60908

Timestep Collection Time: 4.97076
Timestep Consumption Time: 0.83584
PPO Batch Consumption Time: 0.04068
Total Iteration Time: 5.80660

Cumulative Model Updates: 2,900
Cumulative Timesteps: 48,465,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.49134
Policy Entropy: 1.10072
Value Function Loss: 5.82290

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.04184

Collected Steps per Second: 10,489.48240
Overall Steps per Second: 8,876.39828

Timestep Collection Time: 4.76744
Timestep Consumption Time: 0.86637
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 5.63382

Cumulative Model Updates: 2,903
Cumulative Timesteps: 48,515,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 48515738...
Checkpoint 48515738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.17989
Policy Entropy: 1.10566
Value Function Loss: 5.68574

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.04021

Collected Steps per Second: 10,576.57205
Overall Steps per Second: 8,819.43062

Timestep Collection Time: 4.72894
Timestep Consumption Time: 0.94217
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.67111

Cumulative Model Updates: 2,906
Cumulative Timesteps: 48,565,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.57912
Policy Entropy: 1.08991
Value Function Loss: 5.89184

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.04069

Collected Steps per Second: 10,791.95953
Overall Steps per Second: 9,089.71041

Timestep Collection Time: 4.63308
Timestep Consumption Time: 0.86765
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 5.50073

Cumulative Model Updates: 2,909
Cumulative Timesteps: 48,615,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 48615754...
Checkpoint 48615754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.88620
Policy Entropy: 1.10076
Value Function Loss: 6.08687

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.05361

Collected Steps per Second: 10,981.90247
Overall Steps per Second: 9,335.98637

Timestep Collection Time: 4.55513
Timestep Consumption Time: 0.80306
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 5.35819

Cumulative Model Updates: 2,912
Cumulative Timesteps: 48,665,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.23469
Policy Entropy: 1.08349
Value Function Loss: 6.23702

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.05330

Collected Steps per Second: 10,748.05283
Overall Steps per Second: 9,066.27976

Timestep Collection Time: 4.65405
Timestep Consumption Time: 0.86332
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 5.51737

Cumulative Model Updates: 2,915
Cumulative Timesteps: 48,715,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 48715800...
Checkpoint 48715800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.09534
Policy Entropy: 1.10763
Value Function Loss: 6.18273

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.05940

Collected Steps per Second: 10,891.99456
Overall Steps per Second: 9,343.43207

Timestep Collection Time: 4.59273
Timestep Consumption Time: 0.76119
PPO Batch Consumption Time: 0.03937
Total Iteration Time: 5.35392

Cumulative Model Updates: 2,918
Cumulative Timesteps: 48,765,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.09865
Policy Entropy: 1.10147
Value Function Loss: 6.12974

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.07352
Value Function Update Magnitude: 0.05658

Collected Steps per Second: 11,070.83248
Overall Steps per Second: 9,319.40682

Timestep Collection Time: 4.51836
Timestep Consumption Time: 0.84915
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 5.36751

Cumulative Model Updates: 2,921
Cumulative Timesteps: 48,815,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 48815846...
Checkpoint 48815846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.78758
Policy Entropy: 1.11555
Value Function Loss: 6.01684

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.07379
Value Function Update Magnitude: 0.06406

Collected Steps per Second: 10,882.71742
Overall Steps per Second: 9,218.46139

Timestep Collection Time: 4.59701
Timestep Consumption Time: 0.82992
PPO Batch Consumption Time: 0.04533
Total Iteration Time: 5.42694

Cumulative Model Updates: 2,924
Cumulative Timesteps: 48,865,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.32328
Policy Entropy: 1.10138
Value Function Loss: 6.15293

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.09187
Policy Update Magnitude: 0.07047
Value Function Update Magnitude: 0.07133

Collected Steps per Second: 10,847.67471
Overall Steps per Second: 9,222.42358

Timestep Collection Time: 4.60965
Timestep Consumption Time: 0.81235
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.42200

Cumulative Model Updates: 2,927
Cumulative Timesteps: 48,915,878

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 48915878...
Checkpoint 48915878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.99355
Policy Entropy: 1.09971
Value Function Loss: 6.04146

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.08624

Collected Steps per Second: 10,647.01405
Overall Steps per Second: 8,948.59581

Timestep Collection Time: 4.69841
Timestep Consumption Time: 0.89174
PPO Batch Consumption Time: 0.04689
Total Iteration Time: 5.59015

Cumulative Model Updates: 2,930
Cumulative Timesteps: 48,965,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.30786
Policy Entropy: 1.11206
Value Function Loss: 6.23046

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.10124

Collected Steps per Second: 10,155.94916
Overall Steps per Second: 8,849.30485

Timestep Collection Time: 4.92559
Timestep Consumption Time: 0.72729
PPO Batch Consumption Time: 0.04054
Total Iteration Time: 5.65287

Cumulative Model Updates: 2,933
Cumulative Timesteps: 49,015,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 49015926...
Checkpoint 49015926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.88563
Policy Entropy: 1.11676
Value Function Loss: 5.98841

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.09587

Collected Steps per Second: 10,812.76529
Overall Steps per Second: 9,214.34203

Timestep Collection Time: 4.62583
Timestep Consumption Time: 0.80245
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 5.42828

Cumulative Model Updates: 2,936
Cumulative Timesteps: 49,065,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.68478
Policy Entropy: 1.07384
Value Function Loss: 6.13273

Mean KL Divergence: 0.04977
SB3 Clip Fraction: 0.21327
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.09642

Collected Steps per Second: 10,699.37542
Overall Steps per Second: 9,210.39479

Timestep Collection Time: 4.67541
Timestep Consumption Time: 0.75584
PPO Batch Consumption Time: 0.04006
Total Iteration Time: 5.43125

Cumulative Model Updates: 2,939
Cumulative Timesteps: 49,115,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 49115968...
Checkpoint 49115968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.23780
Policy Entropy: 1.08789
Value Function Loss: 5.99140

Mean KL Divergence: 0.03205
SB3 Clip Fraction: 0.18211
Policy Update Magnitude: 0.03919
Value Function Update Magnitude: 0.10132

Collected Steps per Second: 10,660.38055
Overall Steps per Second: 9,045.84018

Timestep Collection Time: 4.69233
Timestep Consumption Time: 0.83751
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.52983

Cumulative Model Updates: 2,942
Cumulative Timesteps: 49,165,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.95799
Policy Entropy: 1.07639
Value Function Loss: 6.06318

Mean KL Divergence: 0.03765
SB3 Clip Fraction: 0.19465
Policy Update Magnitude: 0.04352
Value Function Update Magnitude: 0.09117

Collected Steps per Second: 10,759.96086
Overall Steps per Second: 9,180.22048

Timestep Collection Time: 4.64723
Timestep Consumption Time: 0.79970
PPO Batch Consumption Time: 0.04616
Total Iteration Time: 5.44693

Cumulative Model Updates: 2,945
Cumulative Timesteps: 49,215,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 49215994...
Checkpoint 49215994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.56117
Policy Entropy: 1.10837
Value Function Loss: 5.86830

Mean KL Divergence: 0.04512
SB3 Clip Fraction: 0.19772
Policy Update Magnitude: 0.03771
Value Function Update Magnitude: 0.08205

Collected Steps per Second: 10,250.82793
Overall Steps per Second: 8,805.06443

Timestep Collection Time: 4.87785
Timestep Consumption Time: 0.80093
PPO Batch Consumption Time: 0.04580
Total Iteration Time: 5.67878

Cumulative Model Updates: 2,948
Cumulative Timesteps: 49,265,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.54219
Policy Entropy: 1.10783
Value Function Loss: 6.08324

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.15862
Policy Update Magnitude: 0.03068
Value Function Update Magnitude: 0.07415

Collected Steps per Second: 10,722.70840
Overall Steps per Second: 9,000.78213

Timestep Collection Time: 4.66300
Timestep Consumption Time: 0.89207
PPO Batch Consumption Time: 0.03953
Total Iteration Time: 5.55507

Cumulative Model Updates: 2,951
Cumulative Timesteps: 49,315,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 49315996...
Checkpoint 49315996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.86030
Policy Entropy: 1.11181
Value Function Loss: 6.03402

Mean KL Divergence: 0.03254
SB3 Clip Fraction: 0.17249
Policy Update Magnitude: 0.03557
Value Function Update Magnitude: 0.06782

Collected Steps per Second: 10,807.15475
Overall Steps per Second: 9,183.81586

Timestep Collection Time: 4.62823
Timestep Consumption Time: 0.81809
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 5.44632

Cumulative Model Updates: 2,954
Cumulative Timesteps: 49,366,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.29419
Policy Entropy: 1.07514
Value Function Loss: 6.12469

Mean KL Divergence: 0.03451
SB3 Clip Fraction: 0.17153
Policy Update Magnitude: 0.03485
Value Function Update Magnitude: 0.07464

Collected Steps per Second: 10,804.68620
Overall Steps per Second: 9,169.07974

Timestep Collection Time: 4.62873
Timestep Consumption Time: 0.82569
PPO Batch Consumption Time: 0.04014
Total Iteration Time: 5.45442

Cumulative Model Updates: 2,957
Cumulative Timesteps: 49,416,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 49416026...
Checkpoint 49416026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.99938
Policy Entropy: 1.06756
Value Function Loss: 5.91210

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.16543
Policy Update Magnitude: 0.03563
Value Function Update Magnitude: 0.06852

Collected Steps per Second: 10,690.92616
Overall Steps per Second: 9,215.00736

Timestep Collection Time: 4.67967
Timestep Consumption Time: 0.74952
PPO Batch Consumption Time: 0.04044
Total Iteration Time: 5.42919

Cumulative Model Updates: 2,960
Cumulative Timesteps: 49,466,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.73836
Policy Entropy: 1.07552
Value Function Loss: 6.01403

Mean KL Divergence: 0.02906
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.03375
Value Function Update Magnitude: 0.06444

Collected Steps per Second: 10,775.17779
Overall Steps per Second: 9,156.96534

Timestep Collection Time: 4.64085
Timestep Consumption Time: 0.82013
PPO Batch Consumption Time: 0.04305
Total Iteration Time: 5.46098

Cumulative Model Updates: 2,963
Cumulative Timesteps: 49,516,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 49516062...
Checkpoint 49516062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.49675
Policy Entropy: 1.09411
Value Function Loss: 6.04027

Mean KL Divergence: 0.02858
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.03328
Value Function Update Magnitude: 0.06102

Collected Steps per Second: 10,112.44868
Overall Steps per Second: 8,653.28582

Timestep Collection Time: 4.94658
Timestep Consumption Time: 0.83412
PPO Batch Consumption Time: 0.04940
Total Iteration Time: 5.78069

Cumulative Model Updates: 2,966
Cumulative Timesteps: 49,566,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.81157
Policy Entropy: 1.09785
Value Function Loss: 6.34377

Mean KL Divergence: 0.02402
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.03166
Value Function Update Magnitude: 0.04750

Collected Steps per Second: 10,673.18800
Overall Steps per Second: 9,110.19605

Timestep Collection Time: 4.68632
Timestep Consumption Time: 0.80401
PPO Batch Consumption Time: 0.04208
Total Iteration Time: 5.49033

Cumulative Model Updates: 2,969
Cumulative Timesteps: 49,616,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 49616102...
Checkpoint 49616102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.21754
Policy Entropy: 1.09654
Value Function Loss: 6.19350

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.04231

Collected Steps per Second: 10,417.09395
Overall Steps per Second: 8,877.36738

Timestep Collection Time: 4.80268
Timestep Consumption Time: 0.83300
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 5.63568

Cumulative Model Updates: 2,972
Cumulative Timesteps: 49,666,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.89861
Policy Entropy: 1.09894
Value Function Loss: 5.92464

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.04098

Collected Steps per Second: 10,719.45976
Overall Steps per Second: 9,285.01624

Timestep Collection Time: 4.66497
Timestep Consumption Time: 0.72069
PPO Batch Consumption Time: 0.04101
Total Iteration Time: 5.38567

Cumulative Model Updates: 2,975
Cumulative Timesteps: 49,716,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 49716138...
Checkpoint 49716138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.77484
Policy Entropy: 1.09064
Value Function Loss: 5.79361

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.03914
Value Function Update Magnitude: 0.03147

Collected Steps per Second: 10,850.73996
Overall Steps per Second: 9,218.52049

Timestep Collection Time: 4.61019
Timestep Consumption Time: 0.81627
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.42647

Cumulative Model Updates: 2,978
Cumulative Timesteps: 49,766,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.13570
Policy Entropy: 1.10575
Value Function Loss: 5.89238

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.03523

Collected Steps per Second: 10,205.77420
Overall Steps per Second: 8,854.79977

Timestep Collection Time: 4.89958
Timestep Consumption Time: 0.74753
PPO Batch Consumption Time: 0.04440
Total Iteration Time: 5.64711

Cumulative Model Updates: 2,981
Cumulative Timesteps: 49,816,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 49816166...
Checkpoint 49816166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.14905
Policy Entropy: 1.11316
Value Function Loss: 5.86832

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.03215

Collected Steps per Second: 10,773.86976
Overall Steps per Second: 9,102.07694

Timestep Collection Time: 4.64123
Timestep Consumption Time: 0.85246
PPO Batch Consumption Time: 0.04533
Total Iteration Time: 5.49369

Cumulative Model Updates: 2,984
Cumulative Timesteps: 49,866,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.47574
Policy Entropy: 1.09351
Value Function Loss: 5.77027

Mean KL Divergence: 0.03138
SB3 Clip Fraction: 0.17173
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.04196

Collected Steps per Second: 10,943.14132
Overall Steps per Second: 9,360.42060

Timestep Collection Time: 4.57127
Timestep Consumption Time: 0.77294
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 5.34420

Cumulative Model Updates: 2,987
Cumulative Timesteps: 49,916,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 49916194...
Checkpoint 49916194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.05183
Policy Entropy: 1.12152
Value Function Loss: 5.74769

Mean KL Divergence: 0.03065
SB3 Clip Fraction: 0.18057
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.05413

Collected Steps per Second: 10,804.67803
Overall Steps per Second: 9,205.18885

Timestep Collection Time: 4.62874
Timestep Consumption Time: 0.80429
PPO Batch Consumption Time: 0.04480
Total Iteration Time: 5.43302

Cumulative Model Updates: 2,990
Cumulative Timesteps: 49,966,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.05159
Policy Entropy: 1.10707
Value Function Loss: 5.86996

Mean KL Divergence: 0.02995
SB3 Clip Fraction: 0.16290
Policy Update Magnitude: 0.03745
Value Function Update Magnitude: 0.05593

Collected Steps per Second: 10,545.36890
Overall Steps per Second: 8,839.15334

Timestep Collection Time: 4.74237
Timestep Consumption Time: 0.91542
PPO Batch Consumption Time: 0.05008
Total Iteration Time: 5.65778

Cumulative Model Updates: 2,993
Cumulative Timesteps: 50,016,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 50016216...
Checkpoint 50016216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.41900
Policy Entropy: 1.10661
Value Function Loss: 5.82538

Mean KL Divergence: 0.02803
SB3 Clip Fraction: 0.16617
Policy Update Magnitude: 0.03690
Value Function Update Magnitude: 0.05202

Collected Steps per Second: 10,663.67795
Overall Steps per Second: 8,873.12863

Timestep Collection Time: 4.69106
Timestep Consumption Time: 0.94663
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.63770

Cumulative Model Updates: 2,996
Cumulative Timesteps: 50,066,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.41387
Policy Entropy: 1.08885
Value Function Loss: 5.95924

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.14409
Policy Update Magnitude: 0.03776
Value Function Update Magnitude: 0.05002

Collected Steps per Second: 10,539.88873
Overall Steps per Second: 8,865.92748

Timestep Collection Time: 4.74388
Timestep Consumption Time: 0.89568
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 5.63957

Cumulative Model Updates: 2,999
Cumulative Timesteps: 50,116,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 50116240...
Checkpoint 50116240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.86291
Policy Entropy: 1.10134
Value Function Loss: 5.96126

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.03963
Value Function Update Magnitude: 0.04786

Collected Steps per Second: 10,644.17150
Overall Steps per Second: 9,151.22473

Timestep Collection Time: 4.70060
Timestep Consumption Time: 0.76686
PPO Batch Consumption Time: 0.04662
Total Iteration Time: 5.46746

Cumulative Model Updates: 3,002
Cumulative Timesteps: 50,166,274

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.42563
Policy Entropy: 1.12090
Value Function Loss: 5.99578

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.04611

Collected Steps per Second: 10,441.52841
Overall Steps per Second: 8,880.59710

Timestep Collection Time: 4.78953
Timestep Consumption Time: 0.84185
PPO Batch Consumption Time: 0.04630
Total Iteration Time: 5.63138

Cumulative Model Updates: 3,005
Cumulative Timesteps: 50,216,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 50216284...
Checkpoint 50216284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.27774
Policy Entropy: 1.10454
Value Function Loss: 5.79816

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.03837
Value Function Update Magnitude: 0.05205

Collected Steps per Second: 10,361.82404
Overall Steps per Second: 8,794.97130

Timestep Collection Time: 4.82734
Timestep Consumption Time: 0.86001
PPO Batch Consumption Time: 0.04764
Total Iteration Time: 5.68734

Cumulative Model Updates: 3,008
Cumulative Timesteps: 50,266,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.32160
Policy Entropy: 1.12151
Value Function Loss: 5.82005

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.04463

Collected Steps per Second: 10,748.30549
Overall Steps per Second: 9,086.64126

Timestep Collection Time: 4.65469
Timestep Consumption Time: 0.85120
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 5.50588

Cumulative Model Updates: 3,011
Cumulative Timesteps: 50,316,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 50316334...
Checkpoint 50316334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.44153
Policy Entropy: 1.11037
Value Function Loss: 5.83497

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.05362

Collected Steps per Second: 10,226.96088
Overall Steps per Second: 8,728.40014

Timestep Collection Time: 4.89138
Timestep Consumption Time: 0.83979
PPO Batch Consumption Time: 0.04079
Total Iteration Time: 5.73118

Cumulative Model Updates: 3,014
Cumulative Timesteps: 50,366,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.62977
Policy Entropy: 1.13286
Value Function Loss: 5.84756

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.05453

Collected Steps per Second: 10,400.51487
Overall Steps per Second: 8,941.95081

Timestep Collection Time: 4.80803
Timestep Consumption Time: 0.78426
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 5.59229

Cumulative Model Updates: 3,017
Cumulative Timesteps: 50,416,364

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 50416364...
Checkpoint 50416364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.92727
Policy Entropy: 1.14017
Value Function Loss: 5.73454

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.05321

Collected Steps per Second: 10,541.83235
Overall Steps per Second: 8,887.34964

Timestep Collection Time: 4.74434
Timestep Consumption Time: 0.88321
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.62755

Cumulative Model Updates: 3,020
Cumulative Timesteps: 50,466,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.04736
Policy Entropy: 1.13579
Value Function Loss: 5.76345

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.05165

Collected Steps per Second: 10,515.71711
Overall Steps per Second: 9,033.06068

Timestep Collection Time: 4.75650
Timestep Consumption Time: 0.78072
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 5.53722

Cumulative Model Updates: 3,023
Cumulative Timesteps: 50,516,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 50516396...
Checkpoint 50516396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.94575
Policy Entropy: 1.11686
Value Function Loss: 5.93753

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.07234
Value Function Update Magnitude: 0.05626

Collected Steps per Second: 10,556.81276
Overall Steps per Second: 8,963.51867

Timestep Collection Time: 4.73666
Timestep Consumption Time: 0.84196
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 5.57861

Cumulative Model Updates: 3,026
Cumulative Timesteps: 50,566,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.10398
Policy Entropy: 1.14043
Value Function Loss: 5.99949

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.06182
Value Function Update Magnitude: 0.05004

Collected Steps per Second: 10,249.21079
Overall Steps per Second: 8,757.37583

Timestep Collection Time: 4.87842
Timestep Consumption Time: 0.83105
PPO Batch Consumption Time: 0.04558
Total Iteration Time: 5.70947

Cumulative Model Updates: 3,029
Cumulative Timesteps: 50,616,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 50616400...
Checkpoint 50616400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.49165
Policy Entropy: 1.14315
Value Function Loss: 5.83956

Mean KL Divergence: 0.02854
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.04818

Collected Steps per Second: 10,789.62433
Overall Steps per Second: 9,081.50154

Timestep Collection Time: 4.63631
Timestep Consumption Time: 0.87203
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.50834

Cumulative Model Updates: 3,032
Cumulative Timesteps: 50,666,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.01584
Policy Entropy: 1.15351
Value Function Loss: 5.70129

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.05130

Collected Steps per Second: 10,775.07737
Overall Steps per Second: 9,105.06533

Timestep Collection Time: 4.64294
Timestep Consumption Time: 0.85159
PPO Batch Consumption Time: 0.04034
Total Iteration Time: 5.49452

Cumulative Model Updates: 3,035
Cumulative Timesteps: 50,716,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 50716452...
Checkpoint 50716452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.90543
Policy Entropy: 1.14523
Value Function Loss: 5.42698

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 10,536.59682
Overall Steps per Second: 9,034.25354

Timestep Collection Time: 4.74783
Timestep Consumption Time: 0.78954
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 5.53737

Cumulative Model Updates: 3,038
Cumulative Timesteps: 50,766,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.43420
Policy Entropy: 1.17133
Value Function Loss: 5.63381

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.04574

Collected Steps per Second: 11,098.25077
Overall Steps per Second: 9,292.23776

Timestep Collection Time: 4.50576
Timestep Consumption Time: 0.87573
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 5.38148

Cumulative Model Updates: 3,041
Cumulative Timesteps: 50,816,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 50816484...
Checkpoint 50816484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.59303
Policy Entropy: 1.13963
Value Function Loss: 5.13567

Mean KL Divergence: 0.03667
SB3 Clip Fraction: 0.17791
Policy Update Magnitude: 0.04129
Value Function Update Magnitude: 0.06050

Collected Steps per Second: 10,921.02555
Overall Steps per Second: 9,401.66616

Timestep Collection Time: 4.58107
Timestep Consumption Time: 0.74033
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 5.32140

Cumulative Model Updates: 3,044
Cumulative Timesteps: 50,866,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.42338
Policy Entropy: 1.14283
Value Function Loss: 5.25051

Mean KL Divergence: 0.02693
SB3 Clip Fraction: 0.15236
Policy Update Magnitude: 0.03916
Value Function Update Magnitude: 0.05459

Collected Steps per Second: 10,465.09888
Overall Steps per Second: 8,884.93103

Timestep Collection Time: 4.77912
Timestep Consumption Time: 0.84996
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 5.62908

Cumulative Model Updates: 3,047
Cumulative Timesteps: 50,916,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 50916528...
Checkpoint 50916528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.73544
Policy Entropy: 1.11442
Value Function Loss: 5.18465

Mean KL Divergence: 0.03219
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.06215

Collected Steps per Second: 10,938.17057
Overall Steps per Second: 9,264.63446

Timestep Collection Time: 4.57188
Timestep Consumption Time: 0.82585
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 5.39773

Cumulative Model Updates: 3,050
Cumulative Timesteps: 50,966,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.05448
Policy Entropy: 1.12439
Value Function Loss: 5.28919

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.06131

Collected Steps per Second: 11,167.96745
Overall Steps per Second: 9,419.66461

Timestep Collection Time: 4.47942
Timestep Consumption Time: 0.83139
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.31080

Cumulative Model Updates: 3,053
Cumulative Timesteps: 51,016,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 51016562...
Checkpoint 51016562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.56821
Policy Entropy: 1.10229
Value Function Loss: 5.71368

Mean KL Divergence: 0.03022
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.04113
Value Function Update Magnitude: 0.06316

Collected Steps per Second: 10,761.87175
Overall Steps per Second: 9,130.18552

Timestep Collection Time: 4.64715
Timestep Consumption Time: 0.83051
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 5.47765

Cumulative Model Updates: 3,056
Cumulative Timesteps: 51,066,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.44429
Policy Entropy: 1.11540
Value Function Loss: 5.45660

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.04247
Value Function Update Magnitude: 0.05836

Collected Steps per Second: 10,516.56625
Overall Steps per Second: 9,097.16783

Timestep Collection Time: 4.75726
Timestep Consumption Time: 0.74226
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 5.49951

Cumulative Model Updates: 3,059
Cumulative Timesteps: 51,116,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 51116604...
Checkpoint 51116604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.11793
Policy Entropy: 1.10440
Value Function Loss: 5.75535

Mean KL Divergence: 0.03038
SB3 Clip Fraction: 0.16267
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.04930

Collected Steps per Second: 9,978.71954
Overall Steps per Second: 8,526.08500

Timestep Collection Time: 5.01427
Timestep Consumption Time: 0.85431
PPO Batch Consumption Time: 0.04028
Total Iteration Time: 5.86858

Cumulative Model Updates: 3,062
Cumulative Timesteps: 51,166,640

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.75020
Policy Entropy: 1.13887
Value Function Loss: 5.36715

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.04822

Collected Steps per Second: 10,763.92256
Overall Steps per Second: 9,105.72874

Timestep Collection Time: 4.64645
Timestep Consumption Time: 0.84614
PPO Batch Consumption Time: 0.04496
Total Iteration Time: 5.49259

Cumulative Model Updates: 3,065
Cumulative Timesteps: 51,216,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 51216654...
Checkpoint 51216654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.50531
Policy Entropy: 1.13523
Value Function Loss: 5.62646

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.04838

Collected Steps per Second: 10,645.20460
Overall Steps per Second: 8,777.46291

Timestep Collection Time: 4.69939
Timestep Consumption Time: 0.99998
PPO Batch Consumption Time: 0.04643
Total Iteration Time: 5.69937

Cumulative Model Updates: 3,068
Cumulative Timesteps: 51,266,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.10428
Policy Entropy: 1.12240
Value Function Loss: 5.55590

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.04252
Value Function Update Magnitude: 0.04461

Collected Steps per Second: 10,586.37809
Overall Steps per Second: 8,900.40831

Timestep Collection Time: 4.72513
Timestep Consumption Time: 0.89506
PPO Batch Consumption Time: 0.04669
Total Iteration Time: 5.62019

Cumulative Model Updates: 3,071
Cumulative Timesteps: 51,316,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 51316702...
Checkpoint 51316702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.59886
Policy Entropy: 1.12350
Value Function Loss: 5.76360

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.04474

Collected Steps per Second: 10,569.83867
Overall Steps per Second: 9,148.65665

Timestep Collection Time: 4.73290
Timestep Consumption Time: 0.73522
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 5.46813

Cumulative Model Updates: 3,074
Cumulative Timesteps: 51,366,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.25961
Policy Entropy: 1.11401
Value Function Loss: 6.05305

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.03655

Collected Steps per Second: 10,380.79658
Overall Steps per Second: 8,705.00406

Timestep Collection Time: 4.81948
Timestep Consumption Time: 0.92779
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 5.74727

Cumulative Model Updates: 3,077
Cumulative Timesteps: 51,416,758

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 51416758...
Checkpoint 51416758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.33965
Policy Entropy: 1.11210
Value Function Loss: 6.09556

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.03537

Collected Steps per Second: 10,577.36817
Overall Steps per Second: 9,114.03247

Timestep Collection Time: 4.73048
Timestep Consumption Time: 0.75952
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 5.49000

Cumulative Model Updates: 3,080
Cumulative Timesteps: 51,466,794

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.83687
Policy Entropy: 1.13111
Value Function Loss: 5.86496

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.03322

Collected Steps per Second: 10,549.90038
Overall Steps per Second: 8,915.35275

Timestep Collection Time: 4.74204
Timestep Consumption Time: 0.86941
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.61144

Cumulative Model Updates: 3,083
Cumulative Timesteps: 51,516,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 51516822...
Checkpoint 51516822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.49150
Policy Entropy: 1.14224
Value Function Loss: 5.62215

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.03667

Collected Steps per Second: 10,646.25266
Overall Steps per Second: 9,016.75904

Timestep Collection Time: 4.69649
Timestep Consumption Time: 0.84874
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 5.54523

Cumulative Model Updates: 3,086
Cumulative Timesteps: 51,566,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.70463
Policy Entropy: 1.12696
Value Function Loss: 5.48870

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.04846

Collected Steps per Second: 10,944.51985
Overall Steps per Second: 9,257.33576

Timestep Collection Time: 4.56923
Timestep Consumption Time: 0.83276
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 5.40199

Cumulative Model Updates: 3,089
Cumulative Timesteps: 51,616,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 51616830...
Checkpoint 51616830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.35242
Policy Entropy: 1.13505
Value Function Loss: 5.59386

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.06127

Collected Steps per Second: 10,618.43814
Overall Steps per Second: 8,951.76199

Timestep Collection Time: 4.71011
Timestep Consumption Time: 0.87695
PPO Batch Consumption Time: 0.04625
Total Iteration Time: 5.58706

Cumulative Model Updates: 3,092
Cumulative Timesteps: 51,666,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.81619
Policy Entropy: 1.12610
Value Function Loss: 5.58985

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.05250

Collected Steps per Second: 10,067.52178
Overall Steps per Second: 8,821.71667

Timestep Collection Time: 4.96666
Timestep Consumption Time: 0.70139
PPO Batch Consumption Time: 0.04002
Total Iteration Time: 5.66806

Cumulative Model Updates: 3,095
Cumulative Timesteps: 51,716,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 51716846...
Checkpoint 51716846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.38254
Policy Entropy: 1.12665
Value Function Loss: 5.50596

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.05837

Collected Steps per Second: 10,587.40583
Overall Steps per Second: 8,938.44771

Timestep Collection Time: 4.72354
Timestep Consumption Time: 0.87139
PPO Batch Consumption Time: 0.04604
Total Iteration Time: 5.59493

Cumulative Model Updates: 3,098
Cumulative Timesteps: 51,766,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.20743
Policy Entropy: 1.11362
Value Function Loss: 5.46695

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.06244
Value Function Update Magnitude: 0.06083

Collected Steps per Second: 10,606.63767
Overall Steps per Second: 9,089.86901

Timestep Collection Time: 4.71610
Timestep Consumption Time: 0.78695
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 5.50305

Cumulative Model Updates: 3,101
Cumulative Timesteps: 51,816,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 51816878...
Checkpoint 51816878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.84059
Policy Entropy: 1.11182
Value Function Loss: 5.49163

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.05613

Collected Steps per Second: 10,482.79844
Overall Steps per Second: 8,898.29543

Timestep Collection Time: 4.77182
Timestep Consumption Time: 0.84971
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 5.62153

Cumulative Model Updates: 3,104
Cumulative Timesteps: 51,866,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.13895
Policy Entropy: 1.10212
Value Function Loss: 5.73468

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.07147
Value Function Update Magnitude: 0.04948

Collected Steps per Second: 10,594.81967
Overall Steps per Second: 9,015.62618

Timestep Collection Time: 4.72193
Timestep Consumption Time: 0.82710
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 5.54903

Cumulative Model Updates: 3,107
Cumulative Timesteps: 51,916,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 51916928...
Checkpoint 51916928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.95646
Policy Entropy: 1.11421
Value Function Loss: 5.89972

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.07688
Value Function Update Magnitude: 0.06096

Collected Steps per Second: 10,224.72431
Overall Steps per Second: 8,909.73117

Timestep Collection Time: 4.89011
Timestep Consumption Time: 0.72173
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 5.61184

Cumulative Model Updates: 3,110
Cumulative Timesteps: 51,966,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.39332
Policy Entropy: 1.08411
Value Function Loss: 5.95965

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.07183
Value Function Update Magnitude: 0.07614

Collected Steps per Second: 10,896.41211
Overall Steps per Second: 9,218.35238

Timestep Collection Time: 4.59069
Timestep Consumption Time: 0.83566
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.42635

Cumulative Model Updates: 3,113
Cumulative Timesteps: 52,016,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 52016950...
Checkpoint 52016950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.87608
Policy Entropy: 1.09769
Value Function Loss: 5.94313

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.08449

Collected Steps per Second: 10,629.24108
Overall Steps per Second: 9,074.19204

Timestep Collection Time: 4.70589
Timestep Consumption Time: 0.80645
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 5.51234

Cumulative Model Updates: 3,116
Cumulative Timesteps: 52,066,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.74360
Policy Entropy: 1.09494
Value Function Loss: 5.93372

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.08309

Collected Steps per Second: 10,612.06903
Overall Steps per Second: 8,950.39283

Timestep Collection Time: 4.71237
Timestep Consumption Time: 0.87487
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 5.58724

Cumulative Model Updates: 3,119
Cumulative Timesteps: 52,116,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 52116978...
Checkpoint 52116978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.61727
Policy Entropy: 1.09125
Value Function Loss: 5.85489

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.07201

Collected Steps per Second: 10,651.41215
Overall Steps per Second: 9,062.50569

Timestep Collection Time: 4.69628
Timestep Consumption Time: 0.82339
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 5.51967

Cumulative Model Updates: 3,122
Cumulative Timesteps: 52,167,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.40350
Policy Entropy: 1.09442
Value Function Loss: 5.86203

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.05859

Collected Steps per Second: 10,709.97299
Overall Steps per Second: 9,218.70201

Timestep Collection Time: 4.67097
Timestep Consumption Time: 0.75560
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 5.42658

Cumulative Model Updates: 3,125
Cumulative Timesteps: 52,217,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 52217026...
Checkpoint 52217026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.13873
Policy Entropy: 1.10125
Value Function Loss: 5.72817

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.05439

Collected Steps per Second: 10,245.88190
Overall Steps per Second: 8,683.60103

Timestep Collection Time: 4.88020
Timestep Consumption Time: 0.87801
PPO Batch Consumption Time: 0.04927
Total Iteration Time: 5.75821

Cumulative Model Updates: 3,128
Cumulative Timesteps: 52,267,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.24591
Policy Entropy: 1.10577
Value Function Loss: 5.96045

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.05203

Collected Steps per Second: 10,721.27017
Overall Steps per Second: 9,168.85499

Timestep Collection Time: 4.66475
Timestep Consumption Time: 0.78981
PPO Batch Consumption Time: 0.04055
Total Iteration Time: 5.45455

Cumulative Model Updates: 3,131
Cumulative Timesteps: 52,317,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 52317040...
Checkpoint 52317040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.31886
Policy Entropy: 1.09710
Value Function Loss: 6.08305

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.05323

Collected Steps per Second: 10,710.00167
Overall Steps per Second: 9,019.40987

Timestep Collection Time: 4.66965
Timestep Consumption Time: 0.87528
PPO Batch Consumption Time: 0.04547
Total Iteration Time: 5.54493

Cumulative Model Updates: 3,134
Cumulative Timesteps: 52,367,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.43356
Policy Entropy: 1.09178
Value Function Loss: 6.23685

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.06771
Value Function Update Magnitude: 0.05007

Collected Steps per Second: 10,568.27717
Overall Steps per Second: 8,960.05711

Timestep Collection Time: 4.73152
Timestep Consumption Time: 0.84925
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 5.58077

Cumulative Model Updates: 3,137
Cumulative Timesteps: 52,417,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 52417056...
Checkpoint 52417056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.31124
Policy Entropy: 1.10652
Value Function Loss: 5.88278

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.06303

Collected Steps per Second: 10,894.09713
Overall Steps per Second: 9,221.38948

Timestep Collection Time: 4.59184
Timestep Consumption Time: 0.83293
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 5.42478

Cumulative Model Updates: 3,140
Cumulative Timesteps: 52,467,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.31208
Policy Entropy: 1.09729
Value Function Loss: 5.85760

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.06170

Collected Steps per Second: 10,339.64408
Overall Steps per Second: 8,857.96264

Timestep Collection Time: 4.83769
Timestep Consumption Time: 0.80921
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 5.64690

Cumulative Model Updates: 3,143
Cumulative Timesteps: 52,517,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 52517100...
Checkpoint 52517100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.93969
Policy Entropy: 1.09392
Value Function Loss: 5.65335

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.06028

Collected Steps per Second: 10,647.86656
Overall Steps per Second: 9,148.77554

Timestep Collection Time: 4.69728
Timestep Consumption Time: 0.76968
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 5.46696

Cumulative Model Updates: 3,146
Cumulative Timesteps: 52,567,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.99861
Policy Entropy: 1.09753
Value Function Loss: 5.57013

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.05367

Collected Steps per Second: 10,709.88618
Overall Steps per Second: 9,016.08002

Timestep Collection Time: 4.66989
Timestep Consumption Time: 0.87731
PPO Batch Consumption Time: 0.04032
Total Iteration Time: 5.54720

Cumulative Model Updates: 3,149
Cumulative Timesteps: 52,617,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 52617130...
Checkpoint 52617130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.70054
Policy Entropy: 1.11078
Value Function Loss: 5.35371

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.05220

Collected Steps per Second: 10,590.56255
Overall Steps per Second: 8,991.97847

Timestep Collection Time: 4.72270
Timestep Consumption Time: 0.83960
PPO Batch Consumption Time: 0.04547
Total Iteration Time: 5.56229

Cumulative Model Updates: 3,152
Cumulative Timesteps: 52,667,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.14329
Policy Entropy: 1.10556
Value Function Loss: 5.54080

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.05289

Collected Steps per Second: 10,956.09165
Overall Steps per Second: 9,188.52839

Timestep Collection Time: 4.56404
Timestep Consumption Time: 0.87797
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 5.44200

Cumulative Model Updates: 3,155
Cumulative Timesteps: 52,717,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 52717150...
Checkpoint 52717150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.72399
Policy Entropy: 1.09016
Value Function Loss: 5.62892

Mean KL Divergence: 0.03702
SB3 Clip Fraction: 0.18129
Policy Update Magnitude: 0.06726
Value Function Update Magnitude: 0.06309

Collected Steps per Second: 10,485.59466
Overall Steps per Second: 8,822.93077

Timestep Collection Time: 4.77112
Timestep Consumption Time: 0.89911
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 5.67022

Cumulative Model Updates: 3,158
Cumulative Timesteps: 52,767,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.87353
Policy Entropy: 1.11119
Value Function Loss: 5.70417

Mean KL Divergence: 0.03540
SB3 Clip Fraction: 0.18709
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.09481

Collected Steps per Second: 10,759.12272
Overall Steps per Second: 9,238.51066

Timestep Collection Time: 4.64796
Timestep Consumption Time: 0.76503
PPO Batch Consumption Time: 0.03937
Total Iteration Time: 5.41299

Cumulative Model Updates: 3,161
Cumulative Timesteps: 52,817,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 52817186...
Checkpoint 52817186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.48469
Policy Entropy: 1.09631
Value Function Loss: 5.64763

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.16505
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.07515

Collected Steps per Second: 10,770.16966
Overall Steps per Second: 9,081.16500

Timestep Collection Time: 4.64245
Timestep Consumption Time: 0.86345
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 5.50590

Cumulative Model Updates: 3,164
Cumulative Timesteps: 52,867,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.06103
Policy Entropy: 1.10052
Value Function Loss: 5.82799

Mean KL Divergence: 0.02720
SB3 Clip Fraction: 0.16303
Policy Update Magnitude: 0.04243
Value Function Update Magnitude: 0.06629

Collected Steps per Second: 10,896.70475
Overall Steps per Second: 9,308.91668

Timestep Collection Time: 4.59093
Timestep Consumption Time: 0.78306
PPO Batch Consumption Time: 0.04050
Total Iteration Time: 5.37399

Cumulative Model Updates: 3,167
Cumulative Timesteps: 52,917,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 52917212...
Checkpoint 52917212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.85269
Policy Entropy: 1.08487
Value Function Loss: 5.62379

Mean KL Divergence: 0.02969
SB3 Clip Fraction: 0.16794
Policy Update Magnitude: 0.04101
Value Function Update Magnitude: 0.06704

Collected Steps per Second: 10,753.91800
Overall Steps per Second: 9,132.22711

Timestep Collection Time: 4.64965
Timestep Consumption Time: 0.82568
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.47533

Cumulative Model Updates: 3,170
Cumulative Timesteps: 52,967,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.60001
Policy Entropy: 1.12933
Value Function Loss: 5.51756

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.16079
Policy Update Magnitude: 0.03755
Value Function Update Magnitude: 0.05903

Collected Steps per Second: 10,974.55111
Overall Steps per Second: 9,260.75993

Timestep Collection Time: 4.55782
Timestep Consumption Time: 0.84347
PPO Batch Consumption Time: 0.04454
Total Iteration Time: 5.40128

Cumulative Model Updates: 3,173
Cumulative Timesteps: 53,017,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 53017234...
Checkpoint 53017234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.08234
Policy Entropy: 1.11090
Value Function Loss: 5.49450

Mean KL Divergence: 0.03381
SB3 Clip Fraction: 0.17900
Policy Update Magnitude: 0.03707
Value Function Update Magnitude: 0.06114

Collected Steps per Second: 10,286.42051
Overall Steps per Second: 8,818.26661

Timestep Collection Time: 4.86350
Timestep Consumption Time: 0.80972
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 5.67322

Cumulative Model Updates: 3,176
Cumulative Timesteps: 53,067,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.31645
Policy Entropy: 1.12651
Value Function Loss: 5.71342

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.03569
Value Function Update Magnitude: 0.06262

Collected Steps per Second: 10,744.51699
Overall Steps per Second: 9,013.44392

Timestep Collection Time: 4.65391
Timestep Consumption Time: 0.89380
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 5.54771

Cumulative Model Updates: 3,179
Cumulative Timesteps: 53,117,266

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 53117266...
Checkpoint 53117266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.85079
Policy Entropy: 1.09872
Value Function Loss: 5.83742

Mean KL Divergence: 0.03282
SB3 Clip Fraction: 0.15943
Policy Update Magnitude: 0.03982
Value Function Update Magnitude: 0.07945

Collected Steps per Second: 10,963.23121
Overall Steps per Second: 9,389.88435

Timestep Collection Time: 4.56125
Timestep Consumption Time: 0.76427
PPO Batch Consumption Time: 0.04070
Total Iteration Time: 5.32552

Cumulative Model Updates: 3,182
Cumulative Timesteps: 53,167,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.09453
Policy Entropy: 1.11232
Value Function Loss: 5.86245

Mean KL Divergence: 0.02590
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.03757
Value Function Update Magnitude: 0.07222

Collected Steps per Second: 10,957.32681
Overall Steps per Second: 9,265.28650

Timestep Collection Time: 4.56407
Timestep Consumption Time: 0.83350
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 5.39757

Cumulative Model Updates: 3,185
Cumulative Timesteps: 53,217,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 53217282...
Checkpoint 53217282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.30637
Policy Entropy: 1.10004
Value Function Loss: 5.69709

Mean KL Divergence: 0.02801
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.03550
Value Function Update Magnitude: 0.05717

Collected Steps per Second: 10,325.83624
Overall Steps per Second: 8,835.02018

Timestep Collection Time: 4.84455
Timestep Consumption Time: 0.81747
PPO Batch Consumption Time: 0.04576
Total Iteration Time: 5.66201

Cumulative Model Updates: 3,188
Cumulative Timesteps: 53,267,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.53468
Policy Entropy: 1.12092
Value Function Loss: 5.55545

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.03815
Value Function Update Magnitude: 0.05749

Collected Steps per Second: 10,125.98542
Overall Steps per Second: 8,738.06416

Timestep Collection Time: 4.93898
Timestep Consumption Time: 0.78449
PPO Batch Consumption Time: 0.04896
Total Iteration Time: 5.72346

Cumulative Model Updates: 3,191
Cumulative Timesteps: 53,317,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 53317318...
Checkpoint 53317318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.29476
Policy Entropy: 1.10698
Value Function Loss: 5.62528

Mean KL Divergence: 0.02539
SB3 Clip Fraction: 0.15171
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 10,648.81142
Overall Steps per Second: 9,044.23705

Timestep Collection Time: 4.69536
Timestep Consumption Time: 0.83302
PPO Batch Consumption Time: 0.04676
Total Iteration Time: 5.52838

Cumulative Model Updates: 3,194
Cumulative Timesteps: 53,367,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.09142
Policy Entropy: 1.12705
Value Function Loss: 5.69082

Mean KL Divergence: 0.02485
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.05876

Collected Steps per Second: 10,394.59155
Overall Steps per Second: 9,015.02385

Timestep Collection Time: 4.81231
Timestep Consumption Time: 0.73643
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 5.54874

Cumulative Model Updates: 3,197
Cumulative Timesteps: 53,417,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 53417340...
Checkpoint 53417340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.27809
Policy Entropy: 1.10027
Value Function Loss: 5.70553

Mean KL Divergence: 0.03956
SB3 Clip Fraction: 0.18950
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 10,725.99300
Overall Steps per Second: 9,100.49634

Timestep Collection Time: 4.66288
Timestep Consumption Time: 0.83287
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 5.49574

Cumulative Model Updates: 3,200
Cumulative Timesteps: 53,467,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.56243
Policy Entropy: 1.11672
Value Function Loss: 5.46879

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.15620
Policy Update Magnitude: 0.03752
Value Function Update Magnitude: 0.06162

Collected Steps per Second: 10,747.73853
Overall Steps per Second: 9,181.46881

Timestep Collection Time: 4.65419
Timestep Consumption Time: 0.79396
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.44815

Cumulative Model Updates: 3,203
Cumulative Timesteps: 53,517,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 53517376...
Checkpoint 53517376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.37490
Policy Entropy: 1.10951
Value Function Loss: 5.50784

Mean KL Divergence: 0.02896
SB3 Clip Fraction: 0.15685
Policy Update Magnitude: 0.03762
Value Function Update Magnitude: 0.06118

Collected Steps per Second: 10,602.17761
Overall Steps per Second: 8,839.32315

Timestep Collection Time: 4.71601
Timestep Consumption Time: 0.94053
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 5.65654

Cumulative Model Updates: 3,206
Cumulative Timesteps: 53,567,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.85033
Policy Entropy: 1.12994
Value Function Loss: 5.61795

Mean KL Divergence: 0.02925
SB3 Clip Fraction: 0.16532
Policy Update Magnitude: 0.03668
Value Function Update Magnitude: 0.06253

Collected Steps per Second: 10,112.02829
Overall Steps per Second: 8,676.05571

Timestep Collection Time: 4.94738
Timestep Consumption Time: 0.81884
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.76621

Cumulative Model Updates: 3,209
Cumulative Timesteps: 53,617,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 53617404...
Checkpoint 53617404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.79532
Policy Entropy: 1.11154
Value Function Loss: 5.89941

Mean KL Divergence: 0.03098
SB3 Clip Fraction: 0.16155
Policy Update Magnitude: 0.03836
Value Function Update Magnitude: 0.05463

Collected Steps per Second: 10,779.24570
Overall Steps per Second: 9,259.86257

Timestep Collection Time: 4.63947
Timestep Consumption Time: 0.76126
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 5.40073

Cumulative Model Updates: 3,212
Cumulative Timesteps: 53,667,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.64242
Policy Entropy: 1.12010
Value Function Loss: 5.88362

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.03411
Value Function Update Magnitude: 0.04793

Collected Steps per Second: 10,716.32230
Overall Steps per Second: 9,060.74394

Timestep Collection Time: 4.66765
Timestep Consumption Time: 0.85287
PPO Batch Consumption Time: 0.04211
Total Iteration Time: 5.52052

Cumulative Model Updates: 3,215
Cumulative Timesteps: 53,717,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 53717434...
Checkpoint 53717434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.86147
Policy Entropy: 1.08914
Value Function Loss: 5.82057

Mean KL Divergence: 0.02827
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.03485
Value Function Update Magnitude: 0.04323

Collected Steps per Second: 10,577.74911
Overall Steps per Second: 9,070.77415

Timestep Collection Time: 4.72823
Timestep Consumption Time: 0.78553
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 5.51375

Cumulative Model Updates: 3,218
Cumulative Timesteps: 53,767,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.76221
Policy Entropy: 1.10980
Value Function Loss: 5.76576

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.03710
Value Function Update Magnitude: 0.05714

Collected Steps per Second: 10,797.59724
Overall Steps per Second: 9,117.49707

Timestep Collection Time: 4.63103
Timestep Consumption Time: 0.85337
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.48440

Cumulative Model Updates: 3,221
Cumulative Timesteps: 53,817,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 53817452...
Checkpoint 53817452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.40668
Policy Entropy: 1.09555
Value Function Loss: 5.75050

Mean KL Divergence: 0.03026
SB3 Clip Fraction: 0.15961
Policy Update Magnitude: 0.04037
Value Function Update Magnitude: 0.05155

Collected Steps per Second: 10,200.07467
Overall Steps per Second: 8,782.70707

Timestep Collection Time: 4.90447
Timestep Consumption Time: 0.79149
PPO Batch Consumption Time: 0.04438
Total Iteration Time: 5.69597

Cumulative Model Updates: 3,224
Cumulative Timesteps: 53,867,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.42202
Policy Entropy: 1.12260
Value Function Loss: 5.87261

Mean KL Divergence: 0.02372
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 10,696.55475
Overall Steps per Second: 9,006.25474

Timestep Collection Time: 4.67665
Timestep Consumption Time: 0.87772
PPO Batch Consumption Time: 0.04663
Total Iteration Time: 5.55436

Cumulative Model Updates: 3,227
Cumulative Timesteps: 53,917,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 53917502...
Checkpoint 53917502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.93724
Policy Entropy: 1.09105
Value Function Loss: 5.72281

Mean KL Divergence: 0.03324
SB3 Clip Fraction: 0.16297
Policy Update Magnitude: 0.04424
Value Function Update Magnitude: 0.05421

Collected Steps per Second: 10,484.34250
Overall Steps per Second: 8,843.97582

Timestep Collection Time: 4.77131
Timestep Consumption Time: 0.88497
PPO Batch Consumption Time: 0.04563
Total Iteration Time: 5.65628

Cumulative Model Updates: 3,230
Cumulative Timesteps: 53,967,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.48310
Policy Entropy: 1.09194
Value Function Loss: 5.54569

Mean KL Divergence: 0.02451
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.03855
Value Function Update Magnitude: 0.05199

Collected Steps per Second: 10,439.09830
Overall Steps per Second: 8,880.22450

Timestep Collection Time: 4.78988
Timestep Consumption Time: 0.84084
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 5.63071

Cumulative Model Updates: 3,233
Cumulative Timesteps: 54,017,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 54017528...
Checkpoint 54017528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.33116
Policy Entropy: 1.07515
Value Function Loss: 5.54734

Mean KL Divergence: 0.03086
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.04494

Collected Steps per Second: 10,413.38530
Overall Steps per Second: 8,879.93339

Timestep Collection Time: 4.80459
Timestep Consumption Time: 0.82969
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 5.63428

Cumulative Model Updates: 3,236
Cumulative Timesteps: 54,067,560

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.30175
Policy Entropy: 1.09951
Value Function Loss: 5.49457

Mean KL Divergence: 0.02675
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.03506

Collected Steps per Second: 10,723.61459
Overall Steps per Second: 9,013.97056

Timestep Collection Time: 4.66447
Timestep Consumption Time: 0.88469
PPO Batch Consumption Time: 0.04691
Total Iteration Time: 5.54916

Cumulative Model Updates: 3,239
Cumulative Timesteps: 54,117,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 54117580...
Checkpoint 54117580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.81867
Policy Entropy: 1.09286
Value Function Loss: 5.54476

Mean KL Divergence: 0.02806
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.03170

Collected Steps per Second: 11,012.97364
Overall Steps per Second: 9,312.48422

Timestep Collection Time: 4.54228
Timestep Consumption Time: 0.82943
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 5.37171

Cumulative Model Updates: 3,242
Cumulative Timesteps: 54,167,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.14986
Policy Entropy: 1.10317
Value Function Loss: 5.34470

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.03913
Value Function Update Magnitude: 0.03127

Collected Steps per Second: 10,798.72246
Overall Steps per Second: 9,150.07296

Timestep Collection Time: 4.63184
Timestep Consumption Time: 0.83456
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 5.46640

Cumulative Model Updates: 3,245
Cumulative Timesteps: 54,217,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 54217622...
Checkpoint 54217622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.48485
Policy Entropy: 1.08493
Value Function Loss: 5.39637

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.04245
Value Function Update Magnitude: 0.03031

Collected Steps per Second: 10,555.60664
Overall Steps per Second: 9,015.58313

Timestep Collection Time: 4.73947
Timestep Consumption Time: 0.80959
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 5.54906

Cumulative Model Updates: 3,248
Cumulative Timesteps: 54,267,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.45215
Policy Entropy: 1.09489
Value Function Loss: 5.42211

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.03233

Collected Steps per Second: 10,715.65221
Overall Steps per Second: 9,060.34891

Timestep Collection Time: 4.66887
Timestep Consumption Time: 0.85299
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.52186

Cumulative Model Updates: 3,251
Cumulative Timesteps: 54,317,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 54317680...
Checkpoint 54317680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.68746
Policy Entropy: 1.09736
Value Function Loss: 5.66442

Mean KL Divergence: 0.02610
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.03942
Value Function Update Magnitude: 0.04027

Collected Steps per Second: 10,753.96532
Overall Steps per Second: 8,989.71064

Timestep Collection Time: 4.65168
Timestep Consumption Time: 0.91290
PPO Batch Consumption Time: 0.04652
Total Iteration Time: 5.56458

Cumulative Model Updates: 3,254
Cumulative Timesteps: 54,367,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.22201
Policy Entropy: 1.11144
Value Function Loss: 5.67167

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.04004
Value Function Update Magnitude: 0.03934

Collected Steps per Second: 10,097.74765
Overall Steps per Second: 8,757.71751

Timestep Collection Time: 4.95259
Timestep Consumption Time: 0.75780
PPO Batch Consumption Time: 0.03959
Total Iteration Time: 5.71039

Cumulative Model Updates: 3,257
Cumulative Timesteps: 54,417,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 54417714...
Checkpoint 54417714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.98294
Policy Entropy: 1.09828
Value Function Loss: 5.87504

Mean KL Divergence: 0.03292
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.03549

Collected Steps per Second: 10,488.95594
Overall Steps per Second: 8,913.66951

Timestep Collection Time: 4.76921
Timestep Consumption Time: 0.84285
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 5.61205

Cumulative Model Updates: 3,260
Cumulative Timesteps: 54,467,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.17868
Policy Entropy: 1.11109
Value Function Loss: 5.79900

Mean KL Divergence: 0.02390
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.03827
Value Function Update Magnitude: 0.04857

Collected Steps per Second: 10,722.38114
Overall Steps per Second: 9,120.46871

Timestep Collection Time: 4.66445
Timestep Consumption Time: 0.81926
PPO Batch Consumption Time: 0.04561
Total Iteration Time: 5.48371

Cumulative Model Updates: 3,263
Cumulative Timesteps: 54,517,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 54517752...
Checkpoint 54517752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.12398
Policy Entropy: 1.09296
Value Function Loss: 5.75367

Mean KL Divergence: 0.03143
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.03782
Value Function Update Magnitude: 0.05118

Collected Steps per Second: 10,662.40011
Overall Steps per Second: 9,021.50811

Timestep Collection Time: 4.68938
Timestep Consumption Time: 0.85293
PPO Batch Consumption Time: 0.03980
Total Iteration Time: 5.54231

Cumulative Model Updates: 3,266
Cumulative Timesteps: 54,567,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.11660
Policy Entropy: 1.10572
Value Function Loss: 5.77581

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.03653
Value Function Update Magnitude: 0.04770

Collected Steps per Second: 10,884.13528
Overall Steps per Second: 9,229.61428

Timestep Collection Time: 4.59623
Timestep Consumption Time: 0.82393
PPO Batch Consumption Time: 0.04182
Total Iteration Time: 5.42016

Cumulative Model Updates: 3,269
Cumulative Timesteps: 54,617,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 54617778...
Checkpoint 54617778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.76932
Policy Entropy: 1.10930
Value Function Loss: 5.80022

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.03367
Value Function Update Magnitude: 0.04822

Collected Steps per Second: 10,181.20460
Overall Steps per Second: 8,829.85750

Timestep Collection Time: 4.91376
Timestep Consumption Time: 0.75202
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 5.66578

Cumulative Model Updates: 3,272
Cumulative Timesteps: 54,667,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.49445
Policy Entropy: 1.13246
Value Function Loss: 5.82795

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.03721
Value Function Update Magnitude: 0.04071

Collected Steps per Second: 10,335.37953
Overall Steps per Second: 8,822.00873

Timestep Collection Time: 4.83949
Timestep Consumption Time: 0.83019
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 5.66968

Cumulative Model Updates: 3,275
Cumulative Timesteps: 54,717,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 54717824...
Checkpoint 54717824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.56562
Policy Entropy: 1.11851
Value Function Loss: 5.76913

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.03600
Value Function Update Magnitude: 0.03384

Collected Steps per Second: 10,628.73502
Overall Steps per Second: 9,145.92368

Timestep Collection Time: 4.70649
Timestep Consumption Time: 0.76305
PPO Batch Consumption Time: 0.04531
Total Iteration Time: 5.46954

Cumulative Model Updates: 3,278
Cumulative Timesteps: 54,767,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.63253
Policy Entropy: 1.11190
Value Function Loss: 5.57337

Mean KL Divergence: 0.02595
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.03859
Value Function Update Magnitude: 0.03017

Collected Steps per Second: 10,722.58032
Overall Steps per Second: 9,030.29382

Timestep Collection Time: 4.66306
Timestep Consumption Time: 0.87386
PPO Batch Consumption Time: 0.04735
Total Iteration Time: 5.53692

Cumulative Model Updates: 3,281
Cumulative Timesteps: 54,817,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 54817848...
Checkpoint 54817848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.81576
Policy Entropy: 1.08877
Value Function Loss: 5.52749

Mean KL Divergence: 0.02818
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.03532
Value Function Update Magnitude: 0.05401

Collected Steps per Second: 10,795.69416
Overall Steps per Second: 9,139.08176

Timestep Collection Time: 4.63259
Timestep Consumption Time: 0.83973
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 5.47232

Cumulative Model Updates: 3,284
Cumulative Timesteps: 54,867,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.68868
Policy Entropy: 1.09704
Value Function Loss: 5.51365

Mean KL Divergence: 0.02635
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.03783
Value Function Update Magnitude: 0.04454

Collected Steps per Second: 10,592.70419
Overall Steps per Second: 9,058.87204

Timestep Collection Time: 4.72250
Timestep Consumption Time: 0.79960
PPO Batch Consumption Time: 0.04370
Total Iteration Time: 5.52210

Cumulative Model Updates: 3,287
Cumulative Timesteps: 54,917,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 54917884...
Checkpoint 54917884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.12504
Policy Entropy: 1.09230
Value Function Loss: 5.69108

Mean KL Divergence: 0.02600
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.03713
Value Function Update Magnitude: 0.03732

Collected Steps per Second: 10,299.86479
Overall Steps per Second: 8,751.62070

Timestep Collection Time: 4.85579
Timestep Consumption Time: 0.85904
PPO Batch Consumption Time: 0.04104
Total Iteration Time: 5.71483

Cumulative Model Updates: 3,290
Cumulative Timesteps: 54,967,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.58948
Policy Entropy: 1.10732
Value Function Loss: 5.74727

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.03738
Value Function Update Magnitude: 0.05162

Collected Steps per Second: 10,738.42320
Overall Steps per Second: 9,190.63760

Timestep Collection Time: 4.65823
Timestep Consumption Time: 0.78449
PPO Batch Consumption Time: 0.04490
Total Iteration Time: 5.44271

Cumulative Model Updates: 3,293
Cumulative Timesteps: 55,017,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 55017920...
Checkpoint 55017920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.29871
Policy Entropy: 1.09833
Value Function Loss: 5.79639

Mean KL Divergence: 0.03016
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.04140

Collected Steps per Second: 10,558.98955
Overall Steps per Second: 8,927.44454

Timestep Collection Time: 4.73549
Timestep Consumption Time: 0.86544
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.60093

Cumulative Model Updates: 3,296
Cumulative Timesteps: 55,067,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.88632
Policy Entropy: 1.10698
Value Function Loss: 5.57214

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.03895
Value Function Update Magnitude: 0.03847

Collected Steps per Second: 10,768.90702
Overall Steps per Second: 9,104.41745

Timestep Collection Time: 4.64560
Timestep Consumption Time: 0.84932
PPO Batch Consumption Time: 0.04598
Total Iteration Time: 5.49492

Cumulative Model Updates: 3,299
Cumulative Timesteps: 55,117,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 55117950...
Checkpoint 55117950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.15082
Policy Entropy: 1.11384
Value Function Loss: 5.47952

Mean KL Divergence: 0.02636
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.03893
Value Function Update Magnitude: 0.03587

Collected Steps per Second: 10,936.95755
Overall Steps per Second: 9,365.25545

Timestep Collection Time: 4.57275
Timestep Consumption Time: 0.76741
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.34016

Cumulative Model Updates: 3,302
Cumulative Timesteps: 55,167,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.77690
Policy Entropy: 1.13170
Value Function Loss: 5.59343

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.03974
Value Function Update Magnitude: 0.04435

Collected Steps per Second: 10,392.23531
Overall Steps per Second: 8,828.14268

Timestep Collection Time: 4.81340
Timestep Consumption Time: 0.85280
PPO Batch Consumption Time: 0.04615
Total Iteration Time: 5.66620

Cumulative Model Updates: 3,305
Cumulative Timesteps: 55,217,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 55217984...
Checkpoint 55217984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.52005
Policy Entropy: 1.12614
Value Function Loss: 5.59850

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.03436

Collected Steps per Second: 11,074.10539
Overall Steps per Second: 9,372.22758

Timestep Collection Time: 4.51504
Timestep Consumption Time: 0.81987
PPO Batch Consumption Time: 0.03991
Total Iteration Time: 5.33491

Cumulative Model Updates: 3,308
Cumulative Timesteps: 55,267,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.00847
Policy Entropy: 1.11259
Value Function Loss: 5.60794

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.03382

Collected Steps per Second: 11,074.86919
Overall Steps per Second: 9,214.80944

Timestep Collection Time: 4.51653
Timestep Consumption Time: 0.91169
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 5.42822

Cumulative Model Updates: 3,311
Cumulative Timesteps: 55,318,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 55318004...
Checkpoint 55318004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.15061
Policy Entropy: 1.09475
Value Function Loss: 5.49902

Mean KL Divergence: 0.02907
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.03176

Collected Steps per Second: 10,952.74376
Overall Steps per Second: 9,148.79131

Timestep Collection Time: 4.56707
Timestep Consumption Time: 0.90053
PPO Batch Consumption Time: 0.04934
Total Iteration Time: 5.46761

Cumulative Model Updates: 3,314
Cumulative Timesteps: 55,368,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.34118
Policy Entropy: 1.09243
Value Function Loss: 5.41540

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.04078
Value Function Update Magnitude: 0.03065

Collected Steps per Second: 10,776.07585
Overall Steps per Second: 9,153.39796

Timestep Collection Time: 4.64251
Timestep Consumption Time: 0.82301
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.46551

Cumulative Model Updates: 3,317
Cumulative Timesteps: 55,418,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 55418054...
Checkpoint 55418054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.59953
Policy Entropy: 1.09339
Value Function Loss: 5.61099

Mean KL Divergence: 0.02836
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.03912

Collected Steps per Second: 10,679.31787
Overall Steps per Second: 8,907.45352

Timestep Collection Time: 4.68345
Timestep Consumption Time: 0.93163
PPO Batch Consumption Time: 0.04549
Total Iteration Time: 5.61507

Cumulative Model Updates: 3,320
Cumulative Timesteps: 55,468,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.90221
Policy Entropy: 1.10802
Value Function Loss: 5.63349

Mean KL Divergence: 0.02509
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.03519

Collected Steps per Second: 10,679.60114
Overall Steps per Second: 9,163.22669

Timestep Collection Time: 4.68313
Timestep Consumption Time: 0.77499
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 5.45812

Cumulative Model Updates: 3,323
Cumulative Timesteps: 55,518,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 55518084...
Checkpoint 55518084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.66057
Policy Entropy: 1.09492
Value Function Loss: 5.74860

Mean KL Divergence: 0.03023
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.03943

Collected Steps per Second: 10,614.66299
Overall Steps per Second: 9,032.05747

Timestep Collection Time: 4.71310
Timestep Consumption Time: 0.82583
PPO Batch Consumption Time: 0.04616
Total Iteration Time: 5.53894

Cumulative Model Updates: 3,326
Cumulative Timesteps: 55,568,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.34908
Policy Entropy: 1.09442
Value Function Loss: 5.73548

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.03470

Collected Steps per Second: 10,852.84680
Overall Steps per Second: 9,251.58808

Timestep Collection Time: 4.60745
Timestep Consumption Time: 0.79746
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 5.40491

Cumulative Model Updates: 3,329
Cumulative Timesteps: 55,618,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 55618116...
Checkpoint 55618116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.75405
Policy Entropy: 1.09267
Value Function Loss: 5.90066

Mean KL Divergence: 0.02956
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.03924

Collected Steps per Second: 10,921.08343
Overall Steps per Second: 9,260.70261

Timestep Collection Time: 4.57922
Timestep Consumption Time: 0.82102
PPO Batch Consumption Time: 0.04186
Total Iteration Time: 5.40024

Cumulative Model Updates: 3,332
Cumulative Timesteps: 55,668,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.47318
Policy Entropy: 1.11276
Value Function Loss: 5.87692

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.03673

Collected Steps per Second: 10,540.29437
Overall Steps per Second: 8,936.57060

Timestep Collection Time: 4.74674
Timestep Consumption Time: 0.85183
PPO Batch Consumption Time: 0.04465
Total Iteration Time: 5.59857

Cumulative Model Updates: 3,335
Cumulative Timesteps: 55,718,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 55718158...
Checkpoint 55718158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.96655
Policy Entropy: 1.10518
Value Function Loss: 5.78193

Mean KL Divergence: 0.03148
SB3 Clip Fraction: 0.16131
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.03157

Collected Steps per Second: 9,972.39521
Overall Steps per Second: 8,710.65207

Timestep Collection Time: 5.01384
Timestep Consumption Time: 0.72626
PPO Batch Consumption Time: 0.04598
Total Iteration Time: 5.74010

Cumulative Model Updates: 3,338
Cumulative Timesteps: 55,768,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.80422
Policy Entropy: 1.11004
Value Function Loss: 5.76660

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.03697

Collected Steps per Second: 10,430.44330
Overall Steps per Second: 8,913.48681

Timestep Collection Time: 4.79443
Timestep Consumption Time: 0.81595
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 5.61037

Cumulative Model Updates: 3,341
Cumulative Timesteps: 55,818,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 55818166...
Checkpoint 55818166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.10646
Policy Entropy: 1.09782
Value Function Loss: 5.97836

Mean KL Divergence: 0.02656
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.03548

Collected Steps per Second: 10,559.60189
Overall Steps per Second: 8,984.56197

Timestep Collection Time: 4.73597
Timestep Consumption Time: 0.83024
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.56621

Cumulative Model Updates: 3,344
Cumulative Timesteps: 55,868,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.95250
Policy Entropy: 1.11318
Value Function Loss: 5.96822

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.03333

Collected Steps per Second: 11,112.38660
Overall Steps per Second: 9,408.15575

Timestep Collection Time: 4.50110
Timestep Consumption Time: 0.81535
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 5.31645

Cumulative Model Updates: 3,347
Cumulative Timesteps: 55,918,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 55918194...
Checkpoint 55918194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.47863
Policy Entropy: 1.09260
Value Function Loss: 6.08140

Mean KL Divergence: 0.02869
SB3 Clip Fraction: 0.15355
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.05223

Collected Steps per Second: 10,670.80006
Overall Steps per Second: 9,073.25836

Timestep Collection Time: 4.68793
Timestep Consumption Time: 0.82541
PPO Batch Consumption Time: 0.04069
Total Iteration Time: 5.51334

Cumulative Model Updates: 3,350
Cumulative Timesteps: 55,968,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.73903
Policy Entropy: 1.10602
Value Function Loss: 5.88445

Mean KL Divergence: 0.02628
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.04605

Collected Steps per Second: 10,563.76861
Overall Steps per Second: 9,017.68819

Timestep Collection Time: 4.73505
Timestep Consumption Time: 0.81182
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 5.54688

Cumulative Model Updates: 3,353
Cumulative Timesteps: 56,018,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 56018238...
Checkpoint 56018238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.99201
Policy Entropy: 1.09395
Value Function Loss: 5.64766

Mean KL Divergence: 0.02678
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.04186

Collected Steps per Second: 10,835.78416
Overall Steps per Second: 9,127.09674

Timestep Collection Time: 4.61582
Timestep Consumption Time: 0.86413
PPO Batch Consumption Time: 0.04343
Total Iteration Time: 5.47995

Cumulative Model Updates: 3,356
Cumulative Timesteps: 56,068,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.07001
Policy Entropy: 1.10129
Value Function Loss: 5.47979

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.04145
Value Function Update Magnitude: 0.03870

Collected Steps per Second: 10,880.43359
Overall Steps per Second: 9,306.38334

Timestep Collection Time: 4.59541
Timestep Consumption Time: 0.77725
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 5.37266

Cumulative Model Updates: 3,359
Cumulative Timesteps: 56,118,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 56118254...
Checkpoint 56118254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.44368
Policy Entropy: 1.08866
Value Function Loss: 5.66651

Mean KL Divergence: 0.02882
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.03337

Collected Steps per Second: 10,905.03984
Overall Steps per Second: 9,245.74478

Timestep Collection Time: 4.58779
Timestep Consumption Time: 0.82335
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 5.41114

Cumulative Model Updates: 3,362
Cumulative Timesteps: 56,168,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.97593
Policy Entropy: 1.09657
Value Function Loss: 6.06148

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.04386
Value Function Update Magnitude: 0.04115

Collected Steps per Second: 10,858.44357
Overall Steps per Second: 9,105.79038

Timestep Collection Time: 4.60637
Timestep Consumption Time: 0.88662
PPO Batch Consumption Time: 0.04723
Total Iteration Time: 5.49299

Cumulative Model Updates: 3,365
Cumulative Timesteps: 56,218,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 56218302...
Checkpoint 56218302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.23107
Policy Entropy: 1.08876
Value Function Loss: 5.91926

Mean KL Divergence: 0.02775
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.04280
Value Function Update Magnitude: 0.04417

Collected Steps per Second: 10,841.59918
Overall Steps per Second: 9,249.22348

Timestep Collection Time: 4.61445
Timestep Consumption Time: 0.79444
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 5.40889

Cumulative Model Updates: 3,368
Cumulative Timesteps: 56,268,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.08911
Policy Entropy: 1.11685
Value Function Loss: 5.83860

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.04168
Value Function Update Magnitude: 0.05309

Collected Steps per Second: 10,290.20710
Overall Steps per Second: 8,761.70369

Timestep Collection Time: 4.85899
Timestep Consumption Time: 0.84766
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 5.70665

Cumulative Model Updates: 3,371
Cumulative Timesteps: 56,318,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 56318330...
Checkpoint 56318330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.80616
Policy Entropy: 1.11188
Value Function Loss: 5.74971

Mean KL Divergence: 0.03618
SB3 Clip Fraction: 0.17394
Policy Update Magnitude: 0.03794
Value Function Update Magnitude: 0.06916

Collected Steps per Second: 11,137.94108
Overall Steps per Second: 9,298.87660

Timestep Collection Time: 4.49096
Timestep Consumption Time: 0.88819
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 5.37914

Cumulative Model Updates: 3,374
Cumulative Timesteps: 56,368,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.82603
Policy Entropy: 1.12039
Value Function Loss: 6.19871

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.03479
Value Function Update Magnitude: 0.08770

Collected Steps per Second: 11,024.01346
Overall Steps per Second: 9,285.27895

Timestep Collection Time: 4.53682
Timestep Consumption Time: 0.84955
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 5.38638

Cumulative Model Updates: 3,377
Cumulative Timesteps: 56,418,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 56418364...
Checkpoint 56418364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.22418
Policy Entropy: 1.09091
Value Function Loss: 6.06998

Mean KL Divergence: 0.02748
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.03814
Value Function Update Magnitude: 0.09542

Collected Steps per Second: 10,901.02475
Overall Steps per Second: 9,201.42381

Timestep Collection Time: 4.58819
Timestep Consumption Time: 0.84749
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 5.43568

Cumulative Model Updates: 3,380
Cumulative Timesteps: 56,468,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.69067
Policy Entropy: 1.10334
Value Function Loss: 5.80624

Mean KL Divergence: 0.02980
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.03927
Value Function Update Magnitude: 0.09376

Collected Steps per Second: 10,747.02506
Overall Steps per Second: 9,175.69344

Timestep Collection Time: 4.65264
Timestep Consumption Time: 0.79676
PPO Batch Consumption Time: 0.04576
Total Iteration Time: 5.44940

Cumulative Model Updates: 3,383
Cumulative Timesteps: 56,518,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 56518382...
Checkpoint 56518382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.33978
Policy Entropy: 1.08288
Value Function Loss: 5.49359

Mean KL Divergence: 0.02831
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.03960
Value Function Update Magnitude: 0.07721

Collected Steps per Second: 10,441.30277
Overall Steps per Second: 8,817.99248

Timestep Collection Time: 4.79002
Timestep Consumption Time: 0.88180
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.67181

Cumulative Model Updates: 3,386
Cumulative Timesteps: 56,568,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.84670
Policy Entropy: 1.09826
Value Function Loss: 5.52312

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.06802

Collected Steps per Second: 10,725.20039
Overall Steps per Second: 9,155.37736

Timestep Collection Time: 4.66397
Timestep Consumption Time: 0.79971
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 5.46367

Cumulative Model Updates: 3,389
Cumulative Timesteps: 56,618,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 56618418...
Checkpoint 56618418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.45920
Policy Entropy: 1.07555
Value Function Loss: 5.56714

Mean KL Divergence: 0.02818
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.06236

Collected Steps per Second: 10,604.92746
Overall Steps per Second: 9,005.27557

Timestep Collection Time: 4.71573
Timestep Consumption Time: 0.83768
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 5.55341

Cumulative Model Updates: 3,392
Cumulative Timesteps: 56,668,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.12555
Policy Entropy: 1.11834
Value Function Loss: 5.59194

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.06523

Collected Steps per Second: 10,330.38499
Overall Steps per Second: 8,823.02433

Timestep Collection Time: 4.84164
Timestep Consumption Time: 0.82716
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 5.66880

Cumulative Model Updates: 3,395
Cumulative Timesteps: 56,718,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 56718444...
Checkpoint 56718444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.56542
Policy Entropy: 1.11169
Value Function Loss: 5.81538

Mean KL Divergence: 0.03152
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.05711

Collected Steps per Second: 10,533.10221
Overall Steps per Second: 9,138.90830

Timestep Collection Time: 4.74694
Timestep Consumption Time: 0.72417
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 5.47111

Cumulative Model Updates: 3,398
Cumulative Timesteps: 56,768,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.39092
Policy Entropy: 1.12780
Value Function Loss: 5.86629

Mean KL Divergence: 0.02773
SB3 Clip Fraction: 0.16043
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.06199

Collected Steps per Second: 10,955.30035
Overall Steps per Second: 9,268.92816

Timestep Collection Time: 4.56601
Timestep Consumption Time: 0.83073
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 5.39674

Cumulative Model Updates: 3,401
Cumulative Timesteps: 56,818,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 56818466...
Checkpoint 56818466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.32834
Policy Entropy: 1.08690
Value Function Loss: 5.87785

Mean KL Divergence: 0.02792
SB3 Clip Fraction: 0.14838
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.07453

Collected Steps per Second: 10,308.99667
Overall Steps per Second: 8,830.88492

Timestep Collection Time: 4.85304
Timestep Consumption Time: 0.81230
PPO Batch Consumption Time: 0.03930
Total Iteration Time: 5.66534

Cumulative Model Updates: 3,404
Cumulative Timesteps: 56,868,496

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.61006
Policy Entropy: 1.10387
Value Function Loss: 5.77838

Mean KL Divergence: 0.02690
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.07286

Collected Steps per Second: 11,044.80650
Overall Steps per Second: 9,386.57235

Timestep Collection Time: 4.52864
Timestep Consumption Time: 0.80003
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 5.32868

Cumulative Model Updates: 3,407
Cumulative Timesteps: 56,918,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 56918514...
Checkpoint 56918514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.71370
Policy Entropy: 1.09345
Value Function Loss: 5.91244

Mean KL Divergence: 0.03279
SB3 Clip Fraction: 0.16285
Policy Update Magnitude: 0.04170
Value Function Update Magnitude: 0.08144

Collected Steps per Second: 10,689.57525
Overall Steps per Second: 9,074.54546

Timestep Collection Time: 4.68007
Timestep Consumption Time: 0.83293
PPO Batch Consumption Time: 0.04015
Total Iteration Time: 5.51300

Cumulative Model Updates: 3,410
Cumulative Timesteps: 56,968,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.75407
Policy Entropy: 1.13003
Value Function Loss: 5.96257

Mean KL Divergence: 0.02776
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.04072
Value Function Update Magnitude: 0.07704

Collected Steps per Second: 11,134.15319
Overall Steps per Second: 9,318.77607

Timestep Collection Time: 4.49087
Timestep Consumption Time: 0.87486
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 5.36573

Cumulative Model Updates: 3,413
Cumulative Timesteps: 57,018,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 57018544...
Checkpoint 57018544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.22385
Policy Entropy: 1.11558
Value Function Loss: 6.02934

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.14824
Policy Update Magnitude: 0.03638
Value Function Update Magnitude: 0.08362

Collected Steps per Second: 10,636.07724
Overall Steps per Second: 9,027.58930

Timestep Collection Time: 4.70155
Timestep Consumption Time: 0.83770
PPO Batch Consumption Time: 0.03924
Total Iteration Time: 5.53924

Cumulative Model Updates: 3,416
Cumulative Timesteps: 57,068,550

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.98258
Policy Entropy: 1.13222
Value Function Loss: 5.88470

Mean KL Divergence: 0.02554
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.08714

Collected Steps per Second: 10,224.86629
Overall Steps per Second: 8,847.42469

Timestep Collection Time: 4.89063
Timestep Consumption Time: 0.76141
PPO Batch Consumption Time: 0.03961
Total Iteration Time: 5.65204

Cumulative Model Updates: 3,419
Cumulative Timesteps: 57,118,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 57118556...
Checkpoint 57118556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.40300
Policy Entropy: 1.11717
Value Function Loss: 5.76229

Mean KL Divergence: 0.02916
SB3 Clip Fraction: 0.15505
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.08750

Collected Steps per Second: 10,547.84132
Overall Steps per Second: 8,796.20889

Timestep Collection Time: 4.74296
Timestep Consumption Time: 0.94449
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 5.68745

Cumulative Model Updates: 3,422
Cumulative Timesteps: 57,168,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.23650
Policy Entropy: 1.14080
Value Function Loss: 5.43575

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.04311
Value Function Update Magnitude: 0.08925

Collected Steps per Second: 10,665.38380
Overall Steps per Second: 9,023.43828

Timestep Collection Time: 4.69031
Timestep Consumption Time: 0.85347
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 5.54378

Cumulative Model Updates: 3,425
Cumulative Timesteps: 57,218,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 57218608...
Checkpoint 57218608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.57760
Policy Entropy: 1.11694
Value Function Loss: 5.51212

Mean KL Divergence: 0.02687
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 10,794.31235
Overall Steps per Second: 9,075.95806

Timestep Collection Time: 4.63244
Timestep Consumption Time: 0.87706
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 5.50950

Cumulative Model Updates: 3,428
Cumulative Timesteps: 57,268,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.59534
Policy Entropy: 1.12950
Value Function Loss: 5.63355

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.10613

Collected Steps per Second: 10,717.31716
Overall Steps per Second: 9,063.73163

Timestep Collection Time: 4.66703
Timestep Consumption Time: 0.85145
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.51848

Cumulative Model Updates: 3,431
Cumulative Timesteps: 57,318,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 57318630...
Checkpoint 57318630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.75103
Policy Entropy: 1.11892
Value Function Loss: 5.74288

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.10346

Collected Steps per Second: 10,942.91087
Overall Steps per Second: 9,251.28231

Timestep Collection Time: 4.57008
Timestep Consumption Time: 0.83566
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 5.40574

Cumulative Model Updates: 3,434
Cumulative Timesteps: 57,368,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.67849
Policy Entropy: 1.15531
Value Function Loss: 5.73468

Mean KL Divergence: 0.02981
SB3 Clip Fraction: 0.15207
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.10144

Collected Steps per Second: 10,997.12170
Overall Steps per Second: 9,244.07590

Timestep Collection Time: 4.54737
Timestep Consumption Time: 0.86236
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 5.40973

Cumulative Model Updates: 3,437
Cumulative Timesteps: 57,418,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 57418648...
Checkpoint 57418648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.50926
Policy Entropy: 1.13565
Value Function Loss: 5.64872

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 11,301.56117
Overall Steps per Second: 9,645.48243

Timestep Collection Time: 4.42594
Timestep Consumption Time: 0.75991
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 5.18585

Cumulative Model Updates: 3,440
Cumulative Timesteps: 57,468,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.41243
Policy Entropy: 1.14205
Value Function Loss: 5.62278

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.07981

Collected Steps per Second: 11,208.37161
Overall Steps per Second: 9,422.86737

Timestep Collection Time: 4.46184
Timestep Consumption Time: 0.84546
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.30730

Cumulative Model Updates: 3,443
Cumulative Timesteps: 57,518,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 57518678...
Checkpoint 57518678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.19496
Policy Entropy: 1.12095
Value Function Loss: 5.66366

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.07585

Collected Steps per Second: 10,889.15330
Overall Steps per Second: 9,279.70785

Timestep Collection Time: 4.59430
Timestep Consumption Time: 0.79682
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 5.39112

Cumulative Model Updates: 3,446
Cumulative Timesteps: 57,568,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.06521
Policy Entropy: 1.13520
Value Function Loss: 5.64548

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.10108

Collected Steps per Second: 10,484.64695
Overall Steps per Second: 8,918.84000

Timestep Collection Time: 4.77098
Timestep Consumption Time: 0.83760
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.60858

Cumulative Model Updates: 3,449
Cumulative Timesteps: 57,618,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 57618728...
Checkpoint 57618728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.52426
Policy Entropy: 1.13493
Value Function Loss: 5.68148

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.10261

Collected Steps per Second: 10,187.85320
Overall Steps per Second: 8,747.72364

Timestep Collection Time: 4.91095
Timestep Consumption Time: 0.80848
PPO Batch Consumption Time: 0.04759
Total Iteration Time: 5.71943

Cumulative Model Updates: 3,452
Cumulative Timesteps: 57,668,760

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.51058
Policy Entropy: 1.13475
Value Function Loss: 5.54062

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.08650

Collected Steps per Second: 10,639.53548
Overall Steps per Second: 9,158.28229

Timestep Collection Time: 4.70021
Timestep Consumption Time: 0.76021
PPO Batch Consumption Time: 0.04467
Total Iteration Time: 5.46041

Cumulative Model Updates: 3,455
Cumulative Timesteps: 57,718,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 57718768...
Checkpoint 57718768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.42885
Policy Entropy: 1.12258
Value Function Loss: 5.70841

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.08480

Collected Steps per Second: 10,606.16938
Overall Steps per Second: 8,964.91488

Timestep Collection Time: 4.71650
Timestep Consumption Time: 0.86347
PPO Batch Consumption Time: 0.05052
Total Iteration Time: 5.57997

Cumulative Model Updates: 3,458
Cumulative Timesteps: 57,768,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.47281
Policy Entropy: 1.12856
Value Function Loss: 5.65041

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.10048

Collected Steps per Second: 10,814.34898
Overall Steps per Second: 9,127.83945

Timestep Collection Time: 4.62478
Timestep Consumption Time: 0.85450
PPO Batch Consumption Time: 0.04935
Total Iteration Time: 5.47928

Cumulative Model Updates: 3,461
Cumulative Timesteps: 57,818,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 57818806...
Checkpoint 57818806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.51522
Policy Entropy: 1.13418
Value Function Loss: 5.87255

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.10902

Collected Steps per Second: 10,944.06959
Overall Steps per Second: 9,254.76573

Timestep Collection Time: 4.56868
Timestep Consumption Time: 0.83394
PPO Batch Consumption Time: 0.03870
Total Iteration Time: 5.40262

Cumulative Model Updates: 3,464
Cumulative Timesteps: 57,868,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.56125
Policy Entropy: 1.11554
Value Function Loss: 5.67819

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.10303

Collected Steps per Second: 10,815.39292
Overall Steps per Second: 8,947.87826

Timestep Collection Time: 4.62433
Timestep Consumption Time: 0.96515
PPO Batch Consumption Time: 0.04055
Total Iteration Time: 5.58948

Cumulative Model Updates: 3,467
Cumulative Timesteps: 57,918,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 57918820...
Checkpoint 57918820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.03576
Policy Entropy: 1.13330
Value Function Loss: 5.93001

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.08791

Collected Steps per Second: 10,546.72337
Overall Steps per Second: 9,117.10868

Timestep Collection Time: 4.74081
Timestep Consumption Time: 0.74339
PPO Batch Consumption Time: 0.04255
Total Iteration Time: 5.48419

Cumulative Model Updates: 3,470
Cumulative Timesteps: 57,968,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.80334
Policy Entropy: 1.11788
Value Function Loss: 5.96523

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 10,721.13047
Overall Steps per Second: 8,976.97979

Timestep Collection Time: 4.66369
Timestep Consumption Time: 0.90611
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 5.56980

Cumulative Model Updates: 3,473
Cumulative Timesteps: 58,018,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 58018820...
Checkpoint 58018820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.65797
Policy Entropy: 1.10522
Value Function Loss: 5.99341

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.06994

Collected Steps per Second: 10,681.67191
Overall Steps per Second: 9,175.11626

Timestep Collection Time: 4.68316
Timestep Consumption Time: 0.76898
PPO Batch Consumption Time: 0.04000
Total Iteration Time: 5.45214

Cumulative Model Updates: 3,476
Cumulative Timesteps: 58,068,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.02407
Policy Entropy: 1.11291
Value Function Loss: 5.99485

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.06806

Collected Steps per Second: 11,101.42151
Overall Steps per Second: 9,336.47950

Timestep Collection Time: 4.50483
Timestep Consumption Time: 0.85158
PPO Batch Consumption Time: 0.03926
Total Iteration Time: 5.35641

Cumulative Model Updates: 3,479
Cumulative Timesteps: 58,118,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 58118854...
Checkpoint 58118854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.58730
Policy Entropy: 1.11523
Value Function Loss: 6.04865

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.08037
Value Function Update Magnitude: 0.06651

Collected Steps per Second: 10,565.88704
Overall Steps per Second: 9,007.27629

Timestep Collection Time: 4.73467
Timestep Consumption Time: 0.81928
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.55395

Cumulative Model Updates: 3,482
Cumulative Timesteps: 58,168,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.41969
Policy Entropy: 1.12348
Value Function Loss: 6.08028

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06702
Policy Update Magnitude: 0.08279
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 10,181.25094
Overall Steps per Second: 8,844.34244

Timestep Collection Time: 4.91256
Timestep Consumption Time: 0.74258
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 5.65514

Cumulative Model Updates: 3,485
Cumulative Timesteps: 58,218,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 58218896...
Checkpoint 58218896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.65488
Policy Entropy: 1.13528
Value Function Loss: 5.93413

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07199
Policy Update Magnitude: 0.08364
Value Function Update Magnitude: 0.05905

Collected Steps per Second: 10,698.34034
Overall Steps per Second: 9,107.69760

Timestep Collection Time: 4.67605
Timestep Consumption Time: 0.81666
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 5.49272

Cumulative Model Updates: 3,488
Cumulative Timesteps: 58,268,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.46377
Policy Entropy: 1.13811
Value Function Loss: 5.77412

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07343
Policy Update Magnitude: 0.07957
Value Function Update Magnitude: 0.05421

Collected Steps per Second: 10,790.91919
Overall Steps per Second: 9,114.36212

Timestep Collection Time: 4.63501
Timestep Consumption Time: 0.85259
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 5.48760

Cumulative Model Updates: 3,491
Cumulative Timesteps: 58,318,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 58318938...
Checkpoint 58318938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.96768
Policy Entropy: 1.14788
Value Function Loss: 5.81782

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.07111
Value Function Update Magnitude: 0.05353

Collected Steps per Second: 10,809.22082
Overall Steps per Second: 9,145.56273

Timestep Collection Time: 4.62624
Timestep Consumption Time: 0.84155
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.46779

Cumulative Model Updates: 3,494
Cumulative Timesteps: 58,368,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.84843
Policy Entropy: 1.11224
Value Function Loss: 5.71682

Mean KL Divergence: 0.02935
SB3 Clip Fraction: 0.15713
Policy Update Magnitude: 0.08828
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 10,661.98737
Overall Steps per Second: 8,985.80967

Timestep Collection Time: 4.68993
Timestep Consumption Time: 0.87484
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 5.56477

Cumulative Model Updates: 3,497
Cumulative Timesteps: 58,418,948

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 58418948...
Checkpoint 58418948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.68645
Policy Entropy: 1.13354
Value Function Loss: 5.63988

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.15403
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.07191

Collected Steps per Second: 10,362.45790
Overall Steps per Second: 8,877.09757

Timestep Collection Time: 4.82627
Timestep Consumption Time: 0.80756
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.63382

Cumulative Model Updates: 3,500
Cumulative Timesteps: 58,468,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.60925
Policy Entropy: 1.12256
Value Function Loss: 5.67513

Mean KL Divergence: 0.02772
SB3 Clip Fraction: 0.15144
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 10,569.54953
Overall Steps per Second: 8,976.95544

Timestep Collection Time: 4.73076
Timestep Consumption Time: 0.83928
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.57004

Cumulative Model Updates: 3,503
Cumulative Timesteps: 58,518,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 58518962...
Checkpoint 58518962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.86641
Policy Entropy: 1.14957
Value Function Loss: 5.89793

Mean KL Divergence: 0.03175
SB3 Clip Fraction: 0.15702
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.07958

Collected Steps per Second: 10,647.06917
Overall Steps per Second: 9,196.62244

Timestep Collection Time: 4.69932
Timestep Consumption Time: 0.74115
PPO Batch Consumption Time: 0.03993
Total Iteration Time: 5.44048

Cumulative Model Updates: 3,506
Cumulative Timesteps: 58,568,996

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.20491
Policy Entropy: 1.13838
Value Function Loss: 5.83864

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.03986
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 10,847.71014
Overall Steps per Second: 9,181.89911

Timestep Collection Time: 4.61056
Timestep Consumption Time: 0.83646
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 5.44702

Cumulative Model Updates: 3,509
Cumulative Timesteps: 58,619,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 58619010...
Checkpoint 58619010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.24503
Policy Entropy: 1.15202
Value Function Loss: 5.76475

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.05836

Collected Steps per Second: 10,609.70248
Overall Steps per Second: 9,014.50125

Timestep Collection Time: 4.71568
Timestep Consumption Time: 0.83448
PPO Batch Consumption Time: 0.04572
Total Iteration Time: 5.55017

Cumulative Model Updates: 3,512
Cumulative Timesteps: 58,669,042

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.20020
Policy Entropy: 1.13071
Value Function Loss: 5.70383

Mean KL Divergence: 0.02710
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.05331

Collected Steps per Second: 10,741.52689
Overall Steps per Second: 9,064.09897

Timestep Collection Time: 4.65520
Timestep Consumption Time: 0.86151
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.51671

Cumulative Model Updates: 3,515
Cumulative Timesteps: 58,719,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 58719046...
Checkpoint 58719046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.01660
Policy Entropy: 1.15315
Value Function Loss: 5.81314

Mean KL Divergence: 0.02590
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.06682

Collected Steps per Second: 10,048.05079
Overall Steps per Second: 8,699.08637

Timestep Collection Time: 4.97748
Timestep Consumption Time: 0.77186
PPO Batch Consumption Time: 0.03858
Total Iteration Time: 5.74934

Cumulative Model Updates: 3,518
Cumulative Timesteps: 58,769,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.60066
Policy Entropy: 1.13643
Value Function Loss: 5.72128

Mean KL Divergence: 0.03176
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.07398

Collected Steps per Second: 10,611.76404
Overall Steps per Second: 9,110.17283

Timestep Collection Time: 4.71401
Timestep Consumption Time: 0.77699
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 5.49100

Cumulative Model Updates: 3,521
Cumulative Timesteps: 58,819,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 58819084...
Checkpoint 58819084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.60527
Policy Entropy: 1.15648
Value Function Loss: 5.53778

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.04207
Value Function Update Magnitude: 0.08037

Collected Steps per Second: 10,694.57912
Overall Steps per Second: 9,043.45725

Timestep Collection Time: 4.67527
Timestep Consumption Time: 0.85359
PPO Batch Consumption Time: 0.04271
Total Iteration Time: 5.52886

Cumulative Model Updates: 3,524
Cumulative Timesteps: 58,869,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.77385
Policy Entropy: 1.13609
Value Function Loss: 5.68021

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.06577

Collected Steps per Second: 10,628.17437
Overall Steps per Second: 9,097.72827

Timestep Collection Time: 4.70561
Timestep Consumption Time: 0.79159
PPO Batch Consumption Time: 0.03965
Total Iteration Time: 5.49720

Cumulative Model Updates: 3,527
Cumulative Timesteps: 58,919,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 58919096...
Checkpoint 58919096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.67575
Policy Entropy: 1.15325
Value Function Loss: 5.72095

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.05675

Collected Steps per Second: 10,649.87077
Overall Steps per Second: 8,983.84383

Timestep Collection Time: 4.69715
Timestep Consumption Time: 0.87107
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 5.56822

Cumulative Model Updates: 3,530
Cumulative Timesteps: 58,969,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.31690
Policy Entropy: 1.15365
Value Function Loss: 5.64253

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.05476

Collected Steps per Second: 9,997.35883
Overall Steps per Second: 8,521.82264

Timestep Collection Time: 5.00232
Timestep Consumption Time: 0.86614
PPO Batch Consumption Time: 0.04692
Total Iteration Time: 5.86846

Cumulative Model Updates: 3,533
Cumulative Timesteps: 59,019,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 59019130...
Checkpoint 59019130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.48041
Policy Entropy: 1.16162
Value Function Loss: 5.44878

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.05152

Collected Steps per Second: 10,673.85628
Overall Steps per Second: 9,091.52917

Timestep Collection Time: 4.68528
Timestep Consumption Time: 0.81545
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 5.50072

Cumulative Model Updates: 3,536
Cumulative Timesteps: 59,069,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.98986
Policy Entropy: 1.16699
Value Function Loss: 5.54772

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.05172

Collected Steps per Second: 10,779.32745
Overall Steps per Second: 9,045.62884

Timestep Collection Time: 4.64073
Timestep Consumption Time: 0.88945
PPO Batch Consumption Time: 0.04490
Total Iteration Time: 5.53018

Cumulative Model Updates: 3,539
Cumulative Timesteps: 59,119,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 59119164...
Checkpoint 59119164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.72088
Policy Entropy: 1.14901
Value Function Loss: 5.51245

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.08119
Value Function Update Magnitude: 0.04966

Collected Steps per Second: 10,718.40259
Overall Steps per Second: 9,066.48310

Timestep Collection Time: 4.66581
Timestep Consumption Time: 0.85011
PPO Batch Consumption Time: 0.04531
Total Iteration Time: 5.51592

Cumulative Model Updates: 3,542
Cumulative Timesteps: 59,169,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.79813
Policy Entropy: 1.15530
Value Function Loss: 5.43730

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.05064

Collected Steps per Second: 10,947.59434
Overall Steps per Second: 9,187.20407

Timestep Collection Time: 4.56941
Timestep Consumption Time: 0.87556
PPO Batch Consumption Time: 0.04027
Total Iteration Time: 5.44496

Cumulative Model Updates: 3,545
Cumulative Timesteps: 59,219,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 59219198...
Checkpoint 59219198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.75370
Policy Entropy: 1.15144
Value Function Loss: 5.44891

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.08937
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.05636

Collected Steps per Second: 10,578.54391
Overall Steps per Second: 8,896.94732

Timestep Collection Time: 4.72863
Timestep Consumption Time: 0.89375
PPO Batch Consumption Time: 0.04161
Total Iteration Time: 5.62238

Cumulative Model Updates: 3,548
Cumulative Timesteps: 59,269,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.81845
Policy Entropy: 1.13269
Value Function Loss: 5.43797

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.05398

Collected Steps per Second: 10,614.20369
Overall Steps per Second: 8,995.76308

Timestep Collection Time: 4.71086
Timestep Consumption Time: 0.84754
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 5.55839

Cumulative Model Updates: 3,551
Cumulative Timesteps: 59,319,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 59319222...
Checkpoint 59319222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.88793
Policy Entropy: 1.13081
Value Function Loss: 5.56357

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.04439

Collected Steps per Second: 10,649.05322
Overall Steps per Second: 8,971.85681

Timestep Collection Time: 4.69732
Timestep Consumption Time: 0.87812
PPO Batch Consumption Time: 0.03943
Total Iteration Time: 5.57543

Cumulative Model Updates: 3,554
Cumulative Timesteps: 59,369,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.20212
Policy Entropy: 1.13474
Value Function Loss: 5.53993

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.04544

Collected Steps per Second: 10,228.87156
Overall Steps per Second: 8,822.29597

Timestep Collection Time: 4.89028
Timestep Consumption Time: 0.77968
PPO Batch Consumption Time: 0.04485
Total Iteration Time: 5.66995

Cumulative Model Updates: 3,557
Cumulative Timesteps: 59,419,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 59419266...
Checkpoint 59419266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.55703
Policy Entropy: 1.14501
Value Function Loss: 5.72766

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08200
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.05575

Collected Steps per Second: 10,728.61682
Overall Steps per Second: 9,071.45784

Timestep Collection Time: 4.66137
Timestep Consumption Time: 0.85153
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 5.51290

Cumulative Model Updates: 3,560
Cumulative Timesteps: 59,469,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.44502
Policy Entropy: 1.14290
Value Function Loss: 5.71012

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.06359

Collected Steps per Second: 10,858.51352
Overall Steps per Second: 9,112.86309

Timestep Collection Time: 4.60671
Timestep Consumption Time: 0.88246
PPO Batch Consumption Time: 0.04135
Total Iteration Time: 5.48916

Cumulative Model Updates: 3,563
Cumulative Timesteps: 59,519,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 59519298...
Checkpoint 59519298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.67591
Policy Entropy: 1.13091
Value Function Loss: 5.67626

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.06347

Collected Steps per Second: 10,716.64654
Overall Steps per Second: 9,079.32361

Timestep Collection Time: 4.66620
Timestep Consumption Time: 0.84148
PPO Batch Consumption Time: 0.03923
Total Iteration Time: 5.50768

Cumulative Model Updates: 3,566
Cumulative Timesteps: 59,569,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.13828
Policy Entropy: 1.14822
Value Function Loss: 5.59155

Mean KL Divergence: 0.03211
SB3 Clip Fraction: 0.15671
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.06034

Collected Steps per Second: 11,217.15180
Overall Steps per Second: 9,306.33044

Timestep Collection Time: 4.45889
Timestep Consumption Time: 0.91552
PPO Batch Consumption Time: 0.04771
Total Iteration Time: 5.37441

Cumulative Model Updates: 3,569
Cumulative Timesteps: 59,619,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 59619320...
Checkpoint 59619320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.17068
Policy Entropy: 1.14433
Value Function Loss: 5.60807

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.04417
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 10,870.61963
Overall Steps per Second: 9,349.91553

Timestep Collection Time: 4.59974
Timestep Consumption Time: 0.74812
PPO Batch Consumption Time: 0.04631
Total Iteration Time: 5.34786

Cumulative Model Updates: 3,572
Cumulative Timesteps: 59,669,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.22910
Policy Entropy: 1.16815
Value Function Loss: 5.62392

Mean KL Divergence: 0.03410
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 11,104.84134
Overall Steps per Second: 9,293.54559

Timestep Collection Time: 4.50362
Timestep Consumption Time: 0.87775
PPO Batch Consumption Time: 0.04282
Total Iteration Time: 5.38137

Cumulative Model Updates: 3,575
Cumulative Timesteps: 59,719,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 59719334...
Checkpoint 59719334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.25998
Policy Entropy: 1.15741
Value Function Loss: 5.78703

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.04147
Value Function Update Magnitude: 0.07286

Collected Steps per Second: 10,749.38601
Overall Steps per Second: 9,228.31997

Timestep Collection Time: 4.65385
Timestep Consumption Time: 0.76707
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 5.42092

Cumulative Model Updates: 3,578
Cumulative Timesteps: 59,769,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.75621
Policy Entropy: 1.16966
Value Function Loss: 5.57415

Mean KL Divergence: 0.02641
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.04011
Value Function Update Magnitude: 0.07299

Collected Steps per Second: 10,522.36002
Overall Steps per Second: 8,783.77176

Timestep Collection Time: 4.75388
Timestep Consumption Time: 0.94094
PPO Batch Consumption Time: 0.05320
Total Iteration Time: 5.69482

Cumulative Model Updates: 3,581
Cumulative Timesteps: 59,819,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 59819382...
Checkpoint 59819382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.15649
Policy Entropy: 1.14925
Value Function Loss: 5.56772

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.03527
Value Function Update Magnitude: 0.07749

Collected Steps per Second: 10,664.87381
Overall Steps per Second: 9,085.86253

Timestep Collection Time: 4.68941
Timestep Consumption Time: 0.81496
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 5.50438

Cumulative Model Updates: 3,584
Cumulative Timesteps: 59,869,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.61158
Policy Entropy: 1.16370
Value Function Loss: 5.30424

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.11652
Policy Update Magnitude: 0.04041
Value Function Update Magnitude: 0.07043

Collected Steps per Second: 10,870.71946
Overall Steps per Second: 9,196.57285

Timestep Collection Time: 4.60025
Timestep Consumption Time: 0.83743
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 5.43768

Cumulative Model Updates: 3,587
Cumulative Timesteps: 59,919,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 59919402...
Checkpoint 59919402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.75052
Policy Entropy: 1.15864
Value Function Loss: 5.31103

Mean KL Divergence: 0.02813
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.03758
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 10,723.49026
Overall Steps per Second: 9,099.35966

Timestep Collection Time: 4.66509
Timestep Consumption Time: 0.83266
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 5.49775

Cumulative Model Updates: 3,590
Cumulative Timesteps: 59,969,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.01300
Policy Entropy: 1.17226
Value Function Loss: 5.16593

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.06347

Collected Steps per Second: 10,696.90718
Overall Steps per Second: 9,266.97439

Timestep Collection Time: 4.67537
Timestep Consumption Time: 0.72143
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 5.39680

Cumulative Model Updates: 3,593
Cumulative Timesteps: 60,019,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 60019440...
Checkpoint 60019440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.26835
Policy Entropy: 1.17533
Value Function Loss: 5.26263

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.04412
Value Function Update Magnitude: 0.07799

Collected Steps per Second: 10,598.49223
Overall Steps per Second: 9,049.46554

Timestep Collection Time: 4.71822
Timestep Consumption Time: 0.80763
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 5.52585

Cumulative Model Updates: 3,596
Cumulative Timesteps: 60,069,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.90247
Policy Entropy: 1.15607
Value Function Loss: 5.27212

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.06336

Collected Steps per Second: 10,260.68098
Overall Steps per Second: 8,827.22632

Timestep Collection Time: 4.87589
Timestep Consumption Time: 0.79180
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 5.66769

Cumulative Model Updates: 3,599
Cumulative Timesteps: 60,119,476

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 60119476...
Checkpoint 60119476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.12850
Policy Entropy: 1.15860
Value Function Loss: 5.44551

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.07587
Policy Update Magnitude: 0.07415
Value Function Update Magnitude: 0.05387

Collected Steps per Second: 10,854.71071
Overall Steps per Second: 9,063.93860

Timestep Collection Time: 4.60832
Timestep Consumption Time: 0.91047
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 5.51879

Cumulative Model Updates: 3,602
Cumulative Timesteps: 60,169,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.84256
Policy Entropy: 1.14631
Value Function Loss: 5.35304

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.06731
Value Function Update Magnitude: 0.04534

Collected Steps per Second: 10,825.31093
Overall Steps per Second: 9,181.41129

Timestep Collection Time: 4.62065
Timestep Consumption Time: 0.82731
PPO Batch Consumption Time: 0.03956
Total Iteration Time: 5.44796

Cumulative Model Updates: 3,605
Cumulative Timesteps: 60,219,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 60219518...
Checkpoint 60219518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.67860
Policy Entropy: 1.15880
Value Function Loss: 5.50804

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.04853

Collected Steps per Second: 10,506.26254
Overall Steps per Second: 9,086.82067

Timestep Collection Time: 4.76059
Timestep Consumption Time: 0.74365
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 5.50424

Cumulative Model Updates: 3,608
Cumulative Timesteps: 60,269,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.18027
Policy Entropy: 1.15797
Value Function Loss: 5.45689

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.08578
Value Function Update Magnitude: 0.04642

Collected Steps per Second: 10,687.26282
Overall Steps per Second: 9,004.57762

Timestep Collection Time: 4.67847
Timestep Consumption Time: 0.87426
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 5.55273

Cumulative Model Updates: 3,611
Cumulative Timesteps: 60,319,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 60319534...
Checkpoint 60319534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.30132
Policy Entropy: 1.14978
Value Function Loss: 5.72041

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.07331
Value Function Update Magnitude: 0.05626

Collected Steps per Second: 10,146.05085
Overall Steps per Second: 8,789.09257

Timestep Collection Time: 4.93118
Timestep Consumption Time: 0.76133
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 5.69251

Cumulative Model Updates: 3,614
Cumulative Timesteps: 60,369,566

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.64527
Policy Entropy: 1.16307
Value Function Loss: 5.71934

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.05065

Collected Steps per Second: 10,545.40921
Overall Steps per Second: 8,886.34349

Timestep Collection Time: 4.74311
Timestep Consumption Time: 0.88553
PPO Batch Consumption Time: 0.04656
Total Iteration Time: 5.62864

Cumulative Model Updates: 3,617
Cumulative Timesteps: 60,419,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 60419584...
Checkpoint 60419584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.97420
Policy Entropy: 1.16129
Value Function Loss: 5.77559

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07711
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.04855

Collected Steps per Second: 10,719.91688
Overall Steps per Second: 9,006.72559

Timestep Collection Time: 4.66701
Timestep Consumption Time: 0.88772
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.55474

Cumulative Model Updates: 3,620
Cumulative Timesteps: 60,469,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.29402
Policy Entropy: 1.15643
Value Function Loss: 5.55268

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.04548

Collected Steps per Second: 10,599.80165
Overall Steps per Second: 9,074.33671

Timestep Collection Time: 4.71707
Timestep Consumption Time: 0.79298
PPO Batch Consumption Time: 0.04121
Total Iteration Time: 5.51004

Cumulative Model Updates: 3,623
Cumulative Timesteps: 60,519,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 60519614...
Checkpoint 60519614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.18416
Policy Entropy: 1.15525
Value Function Loss: 5.43589

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 10,702.01441
Overall Steps per Second: 8,996.45679

Timestep Collection Time: 4.67426
Timestep Consumption Time: 0.88615
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 5.56041

Cumulative Model Updates: 3,626
Cumulative Timesteps: 60,569,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.23229
Policy Entropy: 1.16992
Value Function Loss: 5.32731

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.07232
Value Function Update Magnitude: 0.06172

Collected Steps per Second: 10,993.28861
Overall Steps per Second: 9,425.46580

Timestep Collection Time: 4.54859
Timestep Consumption Time: 0.75661
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 5.30520

Cumulative Model Updates: 3,629
Cumulative Timesteps: 60,619,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 60619642...
Checkpoint 60619642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.96979
Policy Entropy: 1.15525
Value Function Loss: 5.26928

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.06275

Collected Steps per Second: 10,281.87237
Overall Steps per Second: 8,775.77146

Timestep Collection Time: 4.86507
Timestep Consumption Time: 0.83494
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 5.70001

Cumulative Model Updates: 3,632
Cumulative Timesteps: 60,669,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.84527
Policy Entropy: 1.16732
Value Function Loss: 5.37490

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.07143
Value Function Update Magnitude: 0.05465

Collected Steps per Second: 10,750.31480
Overall Steps per Second: 9,134.39483

Timestep Collection Time: 4.65289
Timestep Consumption Time: 0.82312
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.47601

Cumulative Model Updates: 3,635
Cumulative Timesteps: 60,719,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 60719684...
Checkpoint 60719684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.49018
Policy Entropy: 1.17122
Value Function Loss: 5.42220

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.07486
Value Function Update Magnitude: 0.05550

Collected Steps per Second: 10,768.52906
Overall Steps per Second: 9,179.45265

Timestep Collection Time: 4.64539
Timestep Consumption Time: 0.80417
PPO Batch Consumption Time: 0.04660
Total Iteration Time: 5.44956

Cumulative Model Updates: 3,638
Cumulative Timesteps: 60,769,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.01819
Policy Entropy: 1.16349
Value Function Loss: 5.56325

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.07437
Value Function Update Magnitude: 0.05336

Collected Steps per Second: 10,732.90658
Overall Steps per Second: 9,023.39798

Timestep Collection Time: 4.65894
Timestep Consumption Time: 0.88265
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 5.54159

Cumulative Model Updates: 3,641
Cumulative Timesteps: 60,819,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 60819712...
Checkpoint 60819712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.62205
Policy Entropy: 1.14414
Value Function Loss: 5.59723

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.06929

Collected Steps per Second: 10,571.57873
Overall Steps per Second: 9,107.55236

Timestep Collection Time: 4.73174
Timestep Consumption Time: 0.76062
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 5.49236

Cumulative Model Updates: 3,644
Cumulative Timesteps: 60,869,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.94130
Policy Entropy: 1.15323
Value Function Loss: 5.49482

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.07152

Collected Steps per Second: 10,337.20154
Overall Steps per Second: 8,818.41928

Timestep Collection Time: 4.83787
Timestep Consumption Time: 0.83322
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.67108

Cumulative Model Updates: 3,647
Cumulative Timesteps: 60,919,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 60919744...
Checkpoint 60919744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.25956
Policy Entropy: 1.15574
Value Function Loss: 5.51198

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.06331

Collected Steps per Second: 10,560.02743
Overall Steps per Second: 8,941.41772

Timestep Collection Time: 4.73730
Timestep Consumption Time: 0.85756
PPO Batch Consumption Time: 0.04132
Total Iteration Time: 5.59486

Cumulative Model Updates: 3,650
Cumulative Timesteps: 60,969,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.47871
Policy Entropy: 1.15497
Value Function Loss: 5.31875

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07763
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.05774

Collected Steps per Second: 10,790.86626
Overall Steps per Second: 9,043.45774

Timestep Collection Time: 4.63355
Timestep Consumption Time: 0.89531
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 5.52886

Cumulative Model Updates: 3,653
Cumulative Timesteps: 61,019,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 61019770...
Checkpoint 61019770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.85088
Policy Entropy: 1.15785
Value Function Loss: 5.45848

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.04394

Collected Steps per Second: 10,892.59416
Overall Steps per Second: 9,223.43060

Timestep Collection Time: 4.59101
Timestep Consumption Time: 0.83083
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 5.42184

Cumulative Model Updates: 3,656
Cumulative Timesteps: 61,069,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.76755
Policy Entropy: 1.16893
Value Function Loss: 5.55408

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.04247

Collected Steps per Second: 10,760.93429
Overall Steps per Second: 9,192.40883

Timestep Collection Time: 4.64644
Timestep Consumption Time: 0.79283
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 5.43927

Cumulative Model Updates: 3,659
Cumulative Timesteps: 61,119,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 61119778...
Checkpoint 61119778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.92346
Policy Entropy: 1.17009
Value Function Loss: 5.57535

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.04320
Value Function Update Magnitude: 0.04550

Collected Steps per Second: 10,427.20863
Overall Steps per Second: 8,781.40853

Timestep Collection Time: 4.79591
Timestep Consumption Time: 0.89884
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.69476

Cumulative Model Updates: 3,662
Cumulative Timesteps: 61,169,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.23827
Policy Entropy: 1.15433
Value Function Loss: 5.48867

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.07076
Value Function Update Magnitude: 0.05161

Collected Steps per Second: 10,547.69784
Overall Steps per Second: 9,006.35489

Timestep Collection Time: 4.74284
Timestep Consumption Time: 0.81169
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 5.55452

Cumulative Model Updates: 3,665
Cumulative Timesteps: 61,219,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 61219812...
Checkpoint 61219812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.64097
Policy Entropy: 1.15346
Value Function Loss: 5.32762

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.06885
Value Function Update Magnitude: 0.06234

Collected Steps per Second: 10,751.08714
Overall Steps per Second: 9,067.13099

Timestep Collection Time: 4.65292
Timestep Consumption Time: 0.86415
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.51707

Cumulative Model Updates: 3,668
Cumulative Timesteps: 61,269,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.60109
Policy Entropy: 1.15632
Value Function Loss: 5.45556

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.08059
Value Function Update Magnitude: 0.06127

Collected Steps per Second: 10,711.91932
Overall Steps per Second: 9,070.93125

Timestep Collection Time: 4.66788
Timestep Consumption Time: 0.84445
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.51233

Cumulative Model Updates: 3,671
Cumulative Timesteps: 61,319,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 61319838...
Checkpoint 61319838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.68666
Policy Entropy: 1.15843
Value Function Loss: 5.45289

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.07111

Collected Steps per Second: 10,420.55235
Overall Steps per Second: 9,010.57445

Timestep Collection Time: 4.79859
Timestep Consumption Time: 0.75089
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 5.54948

Cumulative Model Updates: 3,674
Cumulative Timesteps: 61,369,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.04483
Policy Entropy: 1.15596
Value Function Loss: 5.70140

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.07443
Policy Update Magnitude: 0.07872
Value Function Update Magnitude: 0.07209

Collected Steps per Second: 10,696.54759
Overall Steps per Second: 8,987.35430

Timestep Collection Time: 4.67534
Timestep Consumption Time: 0.88914
PPO Batch Consumption Time: 0.04375
Total Iteration Time: 5.56449

Cumulative Model Updates: 3,677
Cumulative Timesteps: 61,419,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 61419852...
Checkpoint 61419852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.42577
Policy Entropy: 1.14152
Value Function Loss: 5.74914

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 9,911.72389
Overall Steps per Second: 8,458.85701

Timestep Collection Time: 5.04514
Timestep Consumption Time: 0.86654
PPO Batch Consumption Time: 0.04656
Total Iteration Time: 5.91167

Cumulative Model Updates: 3,680
Cumulative Timesteps: 61,469,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.27916
Policy Entropy: 1.14401
Value Function Loss: 5.82817

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05772
Policy Update Magnitude: 0.07146
Value Function Update Magnitude: 0.07442

Collected Steps per Second: 10,805.19879
Overall Steps per Second: 9,071.29062

Timestep Collection Time: 4.62925
Timestep Consumption Time: 0.88485
PPO Batch Consumption Time: 0.03842
Total Iteration Time: 5.51410

Cumulative Model Updates: 3,683
Cumulative Timesteps: 61,519,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 61519878...
Checkpoint 61519878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.94801
Policy Entropy: 1.15665
Value Function Loss: 5.80541

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.08273
Value Function Update Magnitude: 0.09332

Collected Steps per Second: 10,659.70826
Overall Steps per Second: 8,985.27724

Timestep Collection Time: 4.69150
Timestep Consumption Time: 0.87427
PPO Batch Consumption Time: 0.04480
Total Iteration Time: 5.56577

Cumulative Model Updates: 3,686
Cumulative Timesteps: 61,569,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.49735
Policy Entropy: 1.13244
Value Function Loss: 5.85150

Mean KL Divergence: 0.03814
SB3 Clip Fraction: 0.17126
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.08551

Collected Steps per Second: 10,760.37958
Overall Steps per Second: 9,188.81164

Timestep Collection Time: 4.64853
Timestep Consumption Time: 0.79504
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 5.44358

Cumulative Model Updates: 3,689
Cumulative Timesteps: 61,619,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 61619908...
Checkpoint 61619908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.79152
Policy Entropy: 1.14402
Value Function Loss: 5.72843

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.06861

Collected Steps per Second: 11,051.03598
Overall Steps per Second: 9,310.99806

Timestep Collection Time: 4.52609
Timestep Consumption Time: 0.84584
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.37193

Cumulative Model Updates: 3,692
Cumulative Timesteps: 61,669,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.93449
Policy Entropy: 1.13775
Value Function Loss: 5.56046

Mean KL Divergence: 0.02902
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.07529

Collected Steps per Second: 10,322.33768
Overall Steps per Second: 8,776.96045

Timestep Collection Time: 4.84561
Timestep Consumption Time: 0.85318
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 5.69878

Cumulative Model Updates: 3,695
Cumulative Timesteps: 61,719,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 61719944...
Checkpoint 61719944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.04048
Policy Entropy: 1.15737
Value Function Loss: 5.51050

Mean KL Divergence: 0.02848
SB3 Clip Fraction: 0.15762
Policy Update Magnitude: 0.04093
Value Function Update Magnitude: 0.08846

Collected Steps per Second: 10,580.06632
Overall Steps per Second: 8,880.50480

Timestep Collection Time: 4.72644
Timestep Consumption Time: 0.90455
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 5.63099

Cumulative Model Updates: 3,698
Cumulative Timesteps: 61,769,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.63742
Policy Entropy: 1.14939
Value Function Loss: 5.81733

Mean KL Divergence: 0.02865
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.03707
Value Function Update Magnitude: 0.08956

Collected Steps per Second: 11,105.41476
Overall Steps per Second: 9,341.24714

Timestep Collection Time: 4.50483
Timestep Consumption Time: 0.85077
PPO Batch Consumption Time: 0.04006
Total Iteration Time: 5.35560

Cumulative Model Updates: 3,701
Cumulative Timesteps: 61,819,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 61819978...
Checkpoint 61819978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.52781
Policy Entropy: 1.15621
Value Function Loss: 5.96176

Mean KL Divergence: 0.02681
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.03388
Value Function Update Magnitude: 0.07890

Collected Steps per Second: 11,173.43325
Overall Steps per Second: 9,480.57724

Timestep Collection Time: 4.47562
Timestep Consumption Time: 0.79917
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 5.27478

Cumulative Model Updates: 3,704
Cumulative Timesteps: 61,869,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.66383
Policy Entropy: 1.14214
Value Function Loss: 5.80366

Mean KL Divergence: 0.02880
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.03413
Value Function Update Magnitude: 0.06418

Collected Steps per Second: 10,758.15185
Overall Steps per Second: 9,146.99115

Timestep Collection Time: 4.64987
Timestep Consumption Time: 0.81903
PPO Batch Consumption Time: 0.04340
Total Iteration Time: 5.46890

Cumulative Model Updates: 3,707
Cumulative Timesteps: 61,920,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 61920010...
Checkpoint 61920010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.77696
Policy Entropy: 1.15625
Value Function Loss: 5.58578

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.03708
Value Function Update Magnitude: 0.07207

Collected Steps per Second: 10,806.55294
Overall Steps per Second: 9,148.96029

Timestep Collection Time: 4.62812
Timestep Consumption Time: 0.83851
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 5.46663

Cumulative Model Updates: 3,710
Cumulative Timesteps: 61,970,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.09830
Policy Entropy: 1.14127
Value Function Loss: 5.24733

Mean KL Divergence: 0.02715
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.03275
Value Function Update Magnitude: 0.07074

Collected Steps per Second: 10,255.08961
Overall Steps per Second: 8,746.74286

Timestep Collection Time: 4.87797
Timestep Consumption Time: 0.84119
PPO Batch Consumption Time: 0.04352
Total Iteration Time: 5.71916

Cumulative Model Updates: 3,713
Cumulative Timesteps: 62,020,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 62020048...
Checkpoint 62020048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.58349
Policy Entropy: 1.15707
Value Function Loss: 5.16637

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.03486
Value Function Update Magnitude: 0.06446

Collected Steps per Second: 10,375.02804
Overall Steps per Second: 8,829.97906

Timestep Collection Time: 4.82177
Timestep Consumption Time: 0.84370
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.66547

Cumulative Model Updates: 3,716
Cumulative Timesteps: 62,070,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.85218
Policy Entropy: 1.13757
Value Function Loss: 5.26630

Mean KL Divergence: 0.03436
SB3 Clip Fraction: 0.15217
Policy Update Magnitude: 0.03034
Value Function Update Magnitude: 0.06940

Collected Steps per Second: 10,218.25077
Overall Steps per Second: 8,748.90241

Timestep Collection Time: 4.89379
Timestep Consumption Time: 0.82190
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.71569

Cumulative Model Updates: 3,719
Cumulative Timesteps: 62,120,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 62120080...
Checkpoint 62120080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.03274
Policy Entropy: 1.15888
Value Function Loss: 5.65247

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.03120
Value Function Update Magnitude: 0.08336

Collected Steps per Second: 10,709.09161
Overall Steps per Second: 8,983.28924

Timestep Collection Time: 4.66930
Timestep Consumption Time: 0.89703
PPO Batch Consumption Time: 0.04419
Total Iteration Time: 5.56634

Cumulative Model Updates: 3,722
Cumulative Timesteps: 62,170,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.70885
Policy Entropy: 1.14366
Value Function Loss: 5.68785

Mean KL Divergence: 0.03082
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.03233
Value Function Update Magnitude: 0.08875

Collected Steps per Second: 10,587.39695
Overall Steps per Second: 9,148.13108

Timestep Collection Time: 4.72543
Timestep Consumption Time: 0.74345
PPO Batch Consumption Time: 0.04039
Total Iteration Time: 5.46888

Cumulative Model Updates: 3,725
Cumulative Timesteps: 62,220,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 62220114...
Checkpoint 62220114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.61586
Policy Entropy: 1.16418
Value Function Loss: 5.56045

Mean KL Divergence: 0.02613
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.03304
Value Function Update Magnitude: 0.07735

Collected Steps per Second: 10,143.72056
Overall Steps per Second: 8,657.36814

Timestep Collection Time: 4.93074
Timestep Consumption Time: 0.84654
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 5.77728

Cumulative Model Updates: 3,728
Cumulative Timesteps: 62,270,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.35634
Policy Entropy: 1.14941
Value Function Loss: 5.44256

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.03110
Value Function Update Magnitude: 0.06552

Collected Steps per Second: 10,605.37908
Overall Steps per Second: 9,076.05183

Timestep Collection Time: 4.71534
Timestep Consumption Time: 0.79454
PPO Batch Consumption Time: 0.04668
Total Iteration Time: 5.50988

Cumulative Model Updates: 3,731
Cumulative Timesteps: 62,320,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 62320138...
Checkpoint 62320138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.82059
Policy Entropy: 1.17091
Value Function Loss: 5.49520

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.03706
Value Function Update Magnitude: 0.06650

Collected Steps per Second: 10,874.83494
Overall Steps per Second: 9,164.82953

Timestep Collection Time: 4.59887
Timestep Consumption Time: 0.85807
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 5.45695

Cumulative Model Updates: 3,734
Cumulative Timesteps: 62,370,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.33452
Policy Entropy: 1.14970
Value Function Loss: 5.49872

Mean KL Divergence: 0.03590
SB3 Clip Fraction: 0.16109
Policy Update Magnitude: 0.03305
Value Function Update Magnitude: 0.05712

Collected Steps per Second: 10,798.99173
Overall Steps per Second: 9,070.04672

Timestep Collection Time: 4.63117
Timestep Consumption Time: 0.88280
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 5.51397

Cumulative Model Updates: 3,737
Cumulative Timesteps: 62,420,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 62420162...
Checkpoint 62420162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.22105
Policy Entropy: 1.16580
Value Function Loss: 5.39443

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.03072
Value Function Update Magnitude: 0.05500

Collected Steps per Second: 10,361.16177
Overall Steps per Second: 9,035.75263

Timestep Collection Time: 4.82861
Timestep Consumption Time: 0.70828
PPO Batch Consumption Time: 0.04101
Total Iteration Time: 5.53689

Cumulative Model Updates: 3,740
Cumulative Timesteps: 62,470,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.11094
Policy Entropy: 1.15037
Value Function Loss: 5.28453

Mean KL Divergence: 0.03194
SB3 Clip Fraction: 0.15816
Policy Update Magnitude: 0.03228
Value Function Update Magnitude: 0.06459

Collected Steps per Second: 10,219.77668
Overall Steps per Second: 8,599.73997

Timestep Collection Time: 4.89463
Timestep Consumption Time: 0.92206
PPO Batch Consumption Time: 0.04792
Total Iteration Time: 5.81669

Cumulative Model Updates: 3,743
Cumulative Timesteps: 62,520,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 62520214...
Checkpoint 62520214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.17550
Policy Entropy: 1.17181
Value Function Loss: 5.25613

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.14645
Policy Update Magnitude: 0.03022
Value Function Update Magnitude: 0.06819

Collected Steps per Second: 10,564.65103
Overall Steps per Second: 9,020.36785

Timestep Collection Time: 4.73466
Timestep Consumption Time: 0.81057
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 5.54523

Cumulative Model Updates: 3,746
Cumulative Timesteps: 62,570,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.93032
Policy Entropy: 1.15773
Value Function Loss: 5.31155

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.02657
Value Function Update Magnitude: 0.06091

Collected Steps per Second: 10,704.55220
Overall Steps per Second: 9,032.65039

Timestep Collection Time: 4.67240
Timestep Consumption Time: 0.86484
PPO Batch Consumption Time: 0.04905
Total Iteration Time: 5.53725

Cumulative Model Updates: 3,749
Cumulative Timesteps: 62,620,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 62620250...
Checkpoint 62620250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.33634
Policy Entropy: 1.17333
Value Function Loss: 5.35070

Mean KL Divergence: 0.02610
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.03799
Value Function Update Magnitude: 0.05678

Collected Steps per Second: 10,599.82104
Overall Steps per Second: 8,980.98699

Timestep Collection Time: 4.71782
Timestep Consumption Time: 0.85039
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 5.56821

Cumulative Model Updates: 3,752
Cumulative Timesteps: 62,670,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.13484
Policy Entropy: 1.15037
Value Function Loss: 5.39381

Mean KL Divergence: 0.03292
SB3 Clip Fraction: 0.15098
Policy Update Magnitude: 0.03024
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 10,668.00690
Overall Steps per Second: 9,060.85192

Timestep Collection Time: 4.68935
Timestep Consumption Time: 0.83177
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 5.52111

Cumulative Model Updates: 3,755
Cumulative Timesteps: 62,720,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 62720284...
Checkpoint 62720284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.54312
Policy Entropy: 1.16568
Value Function Loss: 5.48523

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.03078
Value Function Update Magnitude: 0.04347

Collected Steps per Second: 10,992.96435
Overall Steps per Second: 9,302.49640

Timestep Collection Time: 4.54836
Timestep Consumption Time: 0.82654
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 5.37490

Cumulative Model Updates: 3,758
Cumulative Timesteps: 62,770,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.55031
Policy Entropy: 1.13891
Value Function Loss: 5.61491

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.04514

Collected Steps per Second: 10,164.60829
Overall Steps per Second: 8,560.31126

Timestep Collection Time: 4.92060
Timestep Consumption Time: 0.92218
PPO Batch Consumption Time: 0.04567
Total Iteration Time: 5.84278

Cumulative Model Updates: 3,761
Cumulative Timesteps: 62,820,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 62820300...
Checkpoint 62820300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.14473
Policy Entropy: 1.15484
Value Function Loss: 5.53340

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.03022
Value Function Update Magnitude: 0.04869

Collected Steps per Second: 10,717.47825
Overall Steps per Second: 9,221.88667

Timestep Collection Time: 4.66770
Timestep Consumption Time: 0.75700
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.42470

Cumulative Model Updates: 3,764
Cumulative Timesteps: 62,870,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.49916
Policy Entropy: 1.13753
Value Function Loss: 5.40039

Mean KL Divergence: 0.02853
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.03130
Value Function Update Magnitude: 0.04383

Collected Steps per Second: 10,883.25728
Overall Steps per Second: 9,171.39912

Timestep Collection Time: 4.59660
Timestep Consumption Time: 0.85796
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 5.45457

Cumulative Model Updates: 3,767
Cumulative Timesteps: 62,920,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 62920352...
Checkpoint 62920352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.95011
Policy Entropy: 1.16528
Value Function Loss: 5.26360

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.03028
Value Function Update Magnitude: 0.04321

Collected Steps per Second: 10,678.04884
Overall Steps per Second: 9,165.05391

Timestep Collection Time: 4.68363
Timestep Consumption Time: 0.77319
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 5.45681

Cumulative Model Updates: 3,770
Cumulative Timesteps: 62,970,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.68456
Policy Entropy: 1.15508
Value Function Loss: 5.35355

Mean KL Divergence: 0.02848
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.03358
Value Function Update Magnitude: 0.04454

Collected Steps per Second: 10,876.19456
Overall Steps per Second: 9,154.44734

Timestep Collection Time: 4.59830
Timestep Consumption Time: 0.86484
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 5.46314

Cumulative Model Updates: 3,773
Cumulative Timesteps: 63,020,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 63020376...
Checkpoint 63020376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.62088
Policy Entropy: 1.16800
Value Function Loss: 5.46252

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.02982
Value Function Update Magnitude: 0.03200

Collected Steps per Second: 10,077.32472
Overall Steps per Second: 8,591.69240

Timestep Collection Time: 4.96163
Timestep Consumption Time: 0.85794
PPO Batch Consumption Time: 0.04684
Total Iteration Time: 5.81958

Cumulative Model Updates: 3,776
Cumulative Timesteps: 63,070,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.13449
Policy Entropy: 1.14283
Value Function Loss: 5.50216

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.02781
Value Function Update Magnitude: 0.02941

Collected Steps per Second: 10,742.47539
Overall Steps per Second: 9,155.04751

Timestep Collection Time: 4.65535
Timestep Consumption Time: 0.80721
PPO Batch Consumption Time: 0.04645
Total Iteration Time: 5.46256

Cumulative Model Updates: 3,779
Cumulative Timesteps: 63,120,386

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 63120386...
Checkpoint 63120386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.80647
Policy Entropy: 1.15625
Value Function Loss: 5.47948

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.03734
Value Function Update Magnitude: 0.04098

Collected Steps per Second: 10,739.02794
Overall Steps per Second: 9,032.34429

Timestep Collection Time: 4.65703
Timestep Consumption Time: 0.87996
PPO Batch Consumption Time: 0.04936
Total Iteration Time: 5.53699

Cumulative Model Updates: 3,782
Cumulative Timesteps: 63,170,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.63674
Policy Entropy: 1.14628
Value Function Loss: 5.43308

Mean KL Divergence: 0.03042
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.03261
Value Function Update Magnitude: 0.03647

Collected Steps per Second: 10,960.34453
Overall Steps per Second: 9,170.19877

Timestep Collection Time: 4.56336
Timestep Consumption Time: 0.89083
PPO Batch Consumption Time: 0.04483
Total Iteration Time: 5.45419

Cumulative Model Updates: 3,785
Cumulative Timesteps: 63,220,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 63220414...
Checkpoint 63220414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.26259
Policy Entropy: 1.17434
Value Function Loss: 5.41956

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.03035
Value Function Update Magnitude: 0.03230

Collected Steps per Second: 10,699.87124
Overall Steps per Second: 9,077.82838

Timestep Collection Time: 4.67370
Timestep Consumption Time: 0.83511
PPO Batch Consumption Time: 0.03908
Total Iteration Time: 5.50881

Cumulative Model Updates: 3,788
Cumulative Timesteps: 63,270,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.99093
Policy Entropy: 1.14692
Value Function Loss: 5.51388

Mean KL Divergence: 0.03098
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.02974
Value Function Update Magnitude: 0.03771

Collected Steps per Second: 10,830.36141
Overall Steps per Second: 9,133.82995

Timestep Collection Time: 4.61831
Timestep Consumption Time: 0.85781
PPO Batch Consumption Time: 0.04405
Total Iteration Time: 5.47613

Cumulative Model Updates: 3,791
Cumulative Timesteps: 63,320,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 63320440...
Checkpoint 63320440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.66483
Policy Entropy: 1.16232
Value Function Loss: 5.52391

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.02914
Value Function Update Magnitude: 0.03311

Collected Steps per Second: 10,312.18782
Overall Steps per Second: 8,764.85797

Timestep Collection Time: 4.84980
Timestep Consumption Time: 0.85617
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 5.70597

Cumulative Model Updates: 3,794
Cumulative Timesteps: 63,370,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.73895
Policy Entropy: 1.15457
Value Function Loss: 5.38344

Mean KL Divergence: 0.02787
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.02997
Value Function Update Magnitude: 0.03119

Collected Steps per Second: 10,761.27072
Overall Steps per Second: 9,261.38793

Timestep Collection Time: 4.64796
Timestep Consumption Time: 0.75274
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 5.40070

Cumulative Model Updates: 3,797
Cumulative Timesteps: 63,420,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 63420470...
Checkpoint 63420470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.39372
Policy Entropy: 1.17866
Value Function Loss: 5.60265

Mean KL Divergence: 0.02216
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.03122
Value Function Update Magnitude: 0.03471

Collected Steps per Second: 10,850.75595
Overall Steps per Second: 9,110.23593

Timestep Collection Time: 4.60816
Timestep Consumption Time: 0.88039
PPO Batch Consumption Time: 0.03967
Total Iteration Time: 5.48855

Cumulative Model Updates: 3,800
Cumulative Timesteps: 63,470,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.15834
Policy Entropy: 1.15710
Value Function Loss: 5.48859

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.02860
Value Function Update Magnitude: 0.03215

Collected Steps per Second: 10,564.01184
Overall Steps per Second: 8,907.46449

Timestep Collection Time: 4.73343
Timestep Consumption Time: 0.88029
PPO Batch Consumption Time: 0.04940
Total Iteration Time: 5.61372

Cumulative Model Updates: 3,803
Cumulative Timesteps: 63,520,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 63520476...
Checkpoint 63520476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.27324
Policy Entropy: 1.15447
Value Function Loss: 5.67754

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.03210
Value Function Update Magnitude: 0.05112

Collected Steps per Second: 10,731.33089
Overall Steps per Second: 9,020.23553

Timestep Collection Time: 4.66075
Timestep Consumption Time: 0.88412
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 5.54487

Cumulative Model Updates: 3,806
Cumulative Timesteps: 63,570,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.41639
Policy Entropy: 1.14014
Value Function Loss: 5.55803

Mean KL Divergence: 0.02844
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.03801
Value Function Update Magnitude: 0.05318

Collected Steps per Second: 10,162.78024
Overall Steps per Second: 8,615.48317

Timestep Collection Time: 4.92168
Timestep Consumption Time: 0.88391
PPO Batch Consumption Time: 0.04622
Total Iteration Time: 5.80559

Cumulative Model Updates: 3,809
Cumulative Timesteps: 63,620,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 63620510...
Checkpoint 63620510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.31076
Policy Entropy: 1.16323
Value Function Loss: 5.54319

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.03046
Value Function Update Magnitude: 0.05675

Collected Steps per Second: 10,771.30960
Overall Steps per Second: 9,207.04780

Timestep Collection Time: 4.64270
Timestep Consumption Time: 0.78879
PPO Batch Consumption Time: 0.04453
Total Iteration Time: 5.43149

Cumulative Model Updates: 3,812
Cumulative Timesteps: 63,670,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.05850
Policy Entropy: 1.14226
Value Function Loss: 5.56130

Mean KL Divergence: 0.03184
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.03522
Value Function Update Magnitude: 0.05642

Collected Steps per Second: 10,565.35397
Overall Steps per Second: 8,993.28104

Timestep Collection Time: 4.73340
Timestep Consumption Time: 0.82742
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 5.56082

Cumulative Model Updates: 3,815
Cumulative Timesteps: 63,720,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 63720528...
Checkpoint 63720528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.61764
Policy Entropy: 1.15713
Value Function Loss: 5.97180

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.04125
Value Function Update Magnitude: 0.05075

Collected Steps per Second: 10,632.19465
Overall Steps per Second: 9,024.07853

Timestep Collection Time: 4.70383
Timestep Consumption Time: 0.83824
PPO Batch Consumption Time: 0.04715
Total Iteration Time: 5.54206

Cumulative Model Updates: 3,818
Cumulative Timesteps: 63,770,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.75546
Policy Entropy: 1.13021
Value Function Loss: 5.81203

Mean KL Divergence: 0.03282
SB3 Clip Fraction: 0.15022
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.05558

Collected Steps per Second: 11,054.11581
Overall Steps per Second: 9,300.23583

Timestep Collection Time: 4.52374
Timestep Consumption Time: 0.85311
PPO Batch Consumption Time: 0.03993
Total Iteration Time: 5.37685

Cumulative Model Updates: 3,821
Cumulative Timesteps: 63,820,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 63820546...
Checkpoint 63820546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.92859
Policy Entropy: 1.15510
Value Function Loss: 5.76024

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.04128
Value Function Update Magnitude: 0.05964

Collected Steps per Second: 10,503.12444
Overall Steps per Second: 8,795.73280

Timestep Collection Time: 4.76144
Timestep Consumption Time: 0.92427
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.68571

Cumulative Model Updates: 3,824
Cumulative Timesteps: 63,870,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.93111
Policy Entropy: 1.14654
Value Function Loss: 5.28389

Mean KL Divergence: 0.02923
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.03928
Value Function Update Magnitude: 0.05424

Collected Steps per Second: 10,565.66999
Overall Steps per Second: 9,079.95804

Timestep Collection Time: 4.73382
Timestep Consumption Time: 0.77457
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 5.50840

Cumulative Model Updates: 3,827
Cumulative Timesteps: 63,920,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 63920572...
Checkpoint 63920572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.59247
Policy Entropy: 1.16729
Value Function Loss: 5.47798

Mean KL Divergence: 0.02343
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.03504
Value Function Update Magnitude: 0.04677

Collected Steps per Second: 10,779.00551
Overall Steps per Second: 9,168.49092

Timestep Collection Time: 4.63883
Timestep Consumption Time: 0.81485
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.45368

Cumulative Model Updates: 3,830
Cumulative Timesteps: 63,970,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.95598
Policy Entropy: 1.14859
Value Function Loss: 5.34653

Mean KL Divergence: 0.03109
SB3 Clip Fraction: 0.15079
Policy Update Magnitude: 0.03234
Value Function Update Magnitude: 0.04237

Collected Steps per Second: 10,934.79922
Overall Steps per Second: 9,392.94432

Timestep Collection Time: 4.57530
Timestep Consumption Time: 0.75104
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 5.32634

Cumulative Model Updates: 3,833
Cumulative Timesteps: 64,020,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 64020604...
Checkpoint 64020604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.53162
Policy Entropy: 1.16724
Value Function Loss: 5.46222

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.03699
Value Function Update Magnitude: 0.04181

Collected Steps per Second: 10,482.11327
Overall Steps per Second: 8,947.67359

Timestep Collection Time: 4.77003
Timestep Consumption Time: 0.81801
PPO Batch Consumption Time: 0.04491
Total Iteration Time: 5.58804

Cumulative Model Updates: 3,836
Cumulative Timesteps: 64,070,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.85317
Policy Entropy: 1.14586
Value Function Loss: 5.11350

Mean KL Divergence: 0.02916
SB3 Clip Fraction: 0.14366
Policy Update Magnitude: 0.03438
Value Function Update Magnitude: 0.03357

Collected Steps per Second: 10,577.54522
Overall Steps per Second: 8,893.56516

Timestep Collection Time: 4.72964
Timestep Consumption Time: 0.89555
PPO Batch Consumption Time: 0.04019
Total Iteration Time: 5.62519

Cumulative Model Updates: 3,839
Cumulative Timesteps: 64,120,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 64120632...
Checkpoint 64120632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.97324
Policy Entropy: 1.16354
Value Function Loss: 5.46822

Mean KL Divergence: 0.02555
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.03767
Value Function Update Magnitude: 0.05263

Collected Steps per Second: 10,204.19679
Overall Steps per Second: 8,690.80799

Timestep Collection Time: 4.89994
Timestep Consumption Time: 0.85326
PPO Batch Consumption Time: 0.03931
Total Iteration Time: 5.75320

Cumulative Model Updates: 3,842
Cumulative Timesteps: 64,170,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.95554
Policy Entropy: 1.14142
Value Function Loss: 5.40525

Mean KL Divergence: 0.02947
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.03273
Value Function Update Magnitude: 0.05541

Collected Steps per Second: 10,502.43969
Overall Steps per Second: 8,916.94500

Timestep Collection Time: 4.76327
Timestep Consumption Time: 0.84694
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 5.61022

Cumulative Model Updates: 3,845
Cumulative Timesteps: 64,220,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 64220658...
Checkpoint 64220658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.21682
Policy Entropy: 1.16949
Value Function Loss: 5.53286

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.03258
Value Function Update Magnitude: 0.05129

Collected Steps per Second: 10,738.81622
Overall Steps per Second: 9,229.05647

Timestep Collection Time: 4.65843
Timestep Consumption Time: 0.76206
PPO Batch Consumption Time: 0.04534
Total Iteration Time: 5.42049

Cumulative Model Updates: 3,848
Cumulative Timesteps: 64,270,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.70000
Policy Entropy: 1.13829
Value Function Loss: 5.47240

Mean KL Divergence: 0.03698
SB3 Clip Fraction: 0.16619
Policy Update Magnitude: 0.03458
Value Function Update Magnitude: 0.06101

Collected Steps per Second: 10,744.73621
Overall Steps per Second: 9,059.59525

Timestep Collection Time: 4.65605
Timestep Consumption Time: 0.86605
PPO Batch Consumption Time: 0.03982
Total Iteration Time: 5.52210

Cumulative Model Updates: 3,851
Cumulative Timesteps: 64,320,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 64320712...
Checkpoint 64320712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.93733
Policy Entropy: 1.15986
Value Function Loss: 5.63513

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.03198
Value Function Update Magnitude: 0.06510

Collected Steps per Second: 10,576.32695
Overall Steps per Second: 9,043.99244

Timestep Collection Time: 4.73019
Timestep Consumption Time: 0.80144
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.53163

Cumulative Model Updates: 3,854
Cumulative Timesteps: 64,370,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.49091
Policy Entropy: 1.13088
Value Function Loss: 5.73001

Mean KL Divergence: 0.03157
SB3 Clip Fraction: 0.15044
Policy Update Magnitude: 0.03238
Value Function Update Magnitude: 0.06577

Collected Steps per Second: 10,062.14009
Overall Steps per Second: 8,677.41692

Timestep Collection Time: 4.97270
Timestep Consumption Time: 0.79353
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.76623

Cumulative Model Updates: 3,857
Cumulative Timesteps: 64,420,776

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 64420776...
Checkpoint 64420776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.38273
Policy Entropy: 1.15758
Value Function Loss: 5.52446

Mean KL Divergence: 0.02530
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.03959
Value Function Update Magnitude: 0.06664

Collected Steps per Second: 10,657.82351
Overall Steps per Second: 9,074.57648

Timestep Collection Time: 4.69214
Timestep Consumption Time: 0.81864
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 5.51078

Cumulative Model Updates: 3,860
Cumulative Timesteps: 64,470,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.34069
Policy Entropy: 1.13888
Value Function Loss: 5.54357

Mean KL Divergence: 0.03069
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.04243
Value Function Update Magnitude: 0.07360

Collected Steps per Second: 10,601.43180
Overall Steps per Second: 9,191.06415

Timestep Collection Time: 4.71785
Timestep Consumption Time: 0.72395
PPO Batch Consumption Time: 0.04581
Total Iteration Time: 5.44181

Cumulative Model Updates: 3,863
Cumulative Timesteps: 64,520,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 64520800...
Checkpoint 64520800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.30553
Policy Entropy: 1.15456
Value Function Loss: 5.49933

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.03663
Value Function Update Magnitude: 0.07286

Collected Steps per Second: 10,553.02279
Overall Steps per Second: 8,973.50151

Timestep Collection Time: 4.73931
Timestep Consumption Time: 0.83422
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 5.57352

Cumulative Model Updates: 3,866
Cumulative Timesteps: 64,570,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.20362
Policy Entropy: 1.14918
Value Function Loss: 5.51595

Mean KL Divergence: 0.02812
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.04195
Value Function Update Magnitude: 0.09031

Collected Steps per Second: 10,905.27923
Overall Steps per Second: 9,265.19186

Timestep Collection Time: 4.58695
Timestep Consumption Time: 0.81196
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 5.39892

Cumulative Model Updates: 3,869
Cumulative Timesteps: 64,620,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 64620836...
Checkpoint 64620836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.51481
Policy Entropy: 1.16425
Value Function Loss: 5.18077

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.03780
Value Function Update Magnitude: 0.09592

Collected Steps per Second: 10,955.24853
Overall Steps per Second: 9,164.56210

Timestep Collection Time: 4.56603
Timestep Consumption Time: 0.89217
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 5.45820

Cumulative Model Updates: 3,872
Cumulative Timesteps: 64,670,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.71267
Policy Entropy: 1.15515
Value Function Loss: 5.17727

Mean KL Divergence: 0.02943
SB3 Clip Fraction: 0.15023
Policy Update Magnitude: 0.03813
Value Function Update Magnitude: 0.07007

Collected Steps per Second: 10,327.30666
Overall Steps per Second: 8,838.34357

Timestep Collection Time: 4.84347
Timestep Consumption Time: 0.81596
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 5.65943

Cumulative Model Updates: 3,875
Cumulative Timesteps: 64,720,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 64720878...
Checkpoint 64720878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.93729
Policy Entropy: 1.16700
Value Function Loss: 5.20674

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.03861
Value Function Update Magnitude: 0.06529

Collected Steps per Second: 10,712.09910
Overall Steps per Second: 9,142.03701

Timestep Collection Time: 4.66949
Timestep Consumption Time: 0.80194
PPO Batch Consumption Time: 0.05031
Total Iteration Time: 5.47143

Cumulative Model Updates: 3,878
Cumulative Timesteps: 64,770,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.04248
Policy Entropy: 1.15094
Value Function Loss: 5.38361

Mean KL Divergence: 0.02959
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.06430

Collected Steps per Second: 10,273.32963
Overall Steps per Second: 8,777.84356

Timestep Collection Time: 4.86931
Timestep Consumption Time: 0.82959
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 5.69889

Cumulative Model Updates: 3,881
Cumulative Timesteps: 64,820,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 64820922...
Checkpoint 64820922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.07619
Policy Entropy: 1.17405
Value Function Loss: 5.47091

Mean KL Divergence: 0.02532
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.04203
Value Function Update Magnitude: 0.06889

Collected Steps per Second: 10,527.91618
Overall Steps per Second: 8,891.89105

Timestep Collection Time: 4.75213
Timestep Consumption Time: 0.87435
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 5.62647

Cumulative Model Updates: 3,884
Cumulative Timesteps: 64,870,952

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.68325
Policy Entropy: 1.15936
Value Function Loss: 5.45590

Mean KL Divergence: 0.02730
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.08195

Collected Steps per Second: 10,670.00380
Overall Steps per Second: 9,226.02670

Timestep Collection Time: 4.68810
Timestep Consumption Time: 0.73374
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.42184

Cumulative Model Updates: 3,887
Cumulative Timesteps: 64,920,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 64920974...
Checkpoint 64920974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.76900
Policy Entropy: 1.16234
Value Function Loss: 5.39563

Mean KL Divergence: 0.02450
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.06595

Collected Steps per Second: 10,124.50223
Overall Steps per Second: 8,654.58716

Timestep Collection Time: 4.94049
Timestep Consumption Time: 0.83910
PPO Batch Consumption Time: 0.04552
Total Iteration Time: 5.77959

Cumulative Model Updates: 3,890
Cumulative Timesteps: 64,970,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.90204
Policy Entropy: 1.13793
Value Function Loss: 5.38949

Mean KL Divergence: 0.02950
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.05470

Collected Steps per Second: 10,698.09555
Overall Steps per Second: 9,259.20182

Timestep Collection Time: 4.67429
Timestep Consumption Time: 0.72639
PPO Batch Consumption Time: 0.04412
Total Iteration Time: 5.40068

Cumulative Model Updates: 3,893
Cumulative Timesteps: 65,021,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 65021000...
Checkpoint 65021000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.97651
Policy Entropy: 1.15106
Value Function Loss: 5.50199

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.05221

Collected Steps per Second: 10,837.47000
Overall Steps per Second: 9,200.66127

Timestep Collection Time: 4.61436
Timestep Consumption Time: 0.82090
PPO Batch Consumption Time: 0.04570
Total Iteration Time: 5.43526

Cumulative Model Updates: 3,896
Cumulative Timesteps: 65,071,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.61128
Policy Entropy: 1.13011
Value Function Loss: 5.55112

Mean KL Divergence: 0.03063
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.04369
Value Function Update Magnitude: 0.04412

Collected Steps per Second: 10,800.15822
Overall Steps per Second: 9,132.28902

Timestep Collection Time: 4.63067
Timestep Consumption Time: 0.84572
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 5.47639

Cumulative Model Updates: 3,899
Cumulative Timesteps: 65,121,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 65121020...
Checkpoint 65121020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.04552
Policy Entropy: 1.14121
Value Function Loss: 5.48682

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.05871

Collected Steps per Second: 10,538.20206
Overall Steps per Second: 8,939.79490

Timestep Collection Time: 4.74692
Timestep Consumption Time: 0.84873
PPO Batch Consumption Time: 0.04094
Total Iteration Time: 5.59565

Cumulative Model Updates: 3,902
Cumulative Timesteps: 65,171,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.81673
Policy Entropy: 1.12236
Value Function Loss: 5.41832

Mean KL Divergence: 0.03060
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.07215

Collected Steps per Second: 10,432.67457
Overall Steps per Second: 8,721.56594

Timestep Collection Time: 4.79340
Timestep Consumption Time: 0.94043
PPO Batch Consumption Time: 0.05009
Total Iteration Time: 5.73383

Cumulative Model Updates: 3,905
Cumulative Timesteps: 65,221,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 65221052...
Checkpoint 65221052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.00602
Policy Entropy: 1.14921
Value Function Loss: 5.43177

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 10,638.84931
Overall Steps per Second: 9,089.50799

Timestep Collection Time: 4.70145
Timestep Consumption Time: 0.80138
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 5.50283

Cumulative Model Updates: 3,908
Cumulative Timesteps: 65,271,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.94997
Policy Entropy: 1.12646
Value Function Loss: 5.46633

Mean KL Divergence: 0.03344
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.07005

Collected Steps per Second: 10,572.82119
Overall Steps per Second: 8,876.54781

Timestep Collection Time: 4.72986
Timestep Consumption Time: 0.90386
PPO Batch Consumption Time: 0.05001
Total Iteration Time: 5.63372

Cumulative Model Updates: 3,911
Cumulative Timesteps: 65,321,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 65321078...
Checkpoint 65321078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.06616
Policy Entropy: 1.15082
Value Function Loss: 5.53632

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.04303
Value Function Update Magnitude: 0.06049

Collected Steps per Second: 10,847.95765
Overall Steps per Second: 9,094.48857

Timestep Collection Time: 4.61101
Timestep Consumption Time: 0.88903
PPO Batch Consumption Time: 0.03989
Total Iteration Time: 5.50003

Cumulative Model Updates: 3,914
Cumulative Timesteps: 65,371,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.23470
Policy Entropy: 1.13061
Value Function Loss: 5.44258

Mean KL Divergence: 0.03397
SB3 Clip Fraction: 0.15842
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.05496

Collected Steps per Second: 11,053.24800
Overall Steps per Second: 9,347.95510

Timestep Collection Time: 4.52681
Timestep Consumption Time: 0.82580
PPO Batch Consumption Time: 0.03801
Total Iteration Time: 5.35261

Cumulative Model Updates: 3,917
Cumulative Timesteps: 65,421,134

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 65421134...
Checkpoint 65421134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.01435
Policy Entropy: 1.16241
Value Function Loss: 5.29785

Mean KL Divergence: 0.02952
SB3 Clip Fraction: 0.15273
Policy Update Magnitude: 0.03956
Value Function Update Magnitude: 0.05637

Collected Steps per Second: 10,789.63779
Overall Steps per Second: 9,108.28283

Timestep Collection Time: 4.63537
Timestep Consumption Time: 0.85567
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 5.49105

Cumulative Model Updates: 3,920
Cumulative Timesteps: 65,471,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.12755
Policy Entropy: 1.13989
Value Function Loss: 5.45651

Mean KL Divergence: 0.03145
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.03464
Value Function Update Magnitude: 0.05814

Collected Steps per Second: 10,101.69200
Overall Steps per Second: 8,707.55931

Timestep Collection Time: 4.95204
Timestep Consumption Time: 0.79285
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 5.74489

Cumulative Model Updates: 3,923
Cumulative Timesteps: 65,521,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 65521172...
Checkpoint 65521172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.06587
Policy Entropy: 1.16440
Value Function Loss: 5.55863

Mean KL Divergence: 0.02703
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.03479
Value Function Update Magnitude: 0.06634

Collected Steps per Second: 10,617.56652
Overall Steps per Second: 8,912.28849

Timestep Collection Time: 4.71087
Timestep Consumption Time: 0.90138
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 5.61225

Cumulative Model Updates: 3,926
Cumulative Timesteps: 65,571,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.07360
Policy Entropy: 1.14625
Value Function Loss: 5.51610

Mean KL Divergence: 0.03323
SB3 Clip Fraction: 0.16299
Policy Update Magnitude: 0.03771
Value Function Update Magnitude: 0.05761

Collected Steps per Second: 10,774.61007
Overall Steps per Second: 9,063.31159

Timestep Collection Time: 4.64258
Timestep Consumption Time: 0.87659
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.51917

Cumulative Model Updates: 3,929
Cumulative Timesteps: 65,621,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 65621212...
Checkpoint 65621212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.16138
Policy Entropy: 1.17393
Value Function Loss: 5.26144

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.15205
Policy Update Magnitude: 0.03474
Value Function Update Magnitude: 0.05606

Collected Steps per Second: 10,726.97855
Overall Steps per Second: 9,104.08172

Timestep Collection Time: 4.66208
Timestep Consumption Time: 0.83106
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 5.49314

Cumulative Model Updates: 3,932
Cumulative Timesteps: 65,671,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.79532
Policy Entropy: 1.15625
Value Function Loss: 5.19095

Mean KL Divergence: 0.03037
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.03807
Value Function Update Magnitude: 0.05222

Collected Steps per Second: 10,573.11803
Overall Steps per Second: 8,959.06830

Timestep Collection Time: 4.73162
Timestep Consumption Time: 0.85244
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 5.58406

Cumulative Model Updates: 3,935
Cumulative Timesteps: 65,721,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 65721250...
Checkpoint 65721250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.73301
Policy Entropy: 1.17349
Value Function Loss: 5.19554

Mean KL Divergence: 0.02870
SB3 Clip Fraction: 0.14922
Policy Update Magnitude: 0.03790
Value Function Update Magnitude: 0.05215

Collected Steps per Second: 10,212.55018
Overall Steps per Second: 8,806.46280

Timestep Collection Time: 4.89711
Timestep Consumption Time: 0.78190
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 5.67901

Cumulative Model Updates: 3,938
Cumulative Timesteps: 65,771,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.00057
Policy Entropy: 1.14404
Value Function Loss: 5.18725

Mean KL Divergence: 0.02593
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.03404
Value Function Update Magnitude: 0.05273

Collected Steps per Second: 10,586.89006
Overall Steps per Second: 8,903.86771

Timestep Collection Time: 4.72490
Timestep Consumption Time: 0.89311
PPO Batch Consumption Time: 0.04156
Total Iteration Time: 5.61801

Cumulative Model Updates: 3,941
Cumulative Timesteps: 65,821,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 65821284...
Checkpoint 65821284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.10138
Policy Entropy: 1.15891
Value Function Loss: 5.23229

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.04061
Value Function Update Magnitude: 0.05007

Collected Steps per Second: 10,422.94689
Overall Steps per Second: 8,830.68203

Timestep Collection Time: 4.79730
Timestep Consumption Time: 0.86500
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 5.66230

Cumulative Model Updates: 3,944
Cumulative Timesteps: 65,871,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.51044
Policy Entropy: 1.13570
Value Function Loss: 5.44417

Mean KL Divergence: 0.02802
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.03711
Value Function Update Magnitude: 0.05332

Collected Steps per Second: 11,031.54474
Overall Steps per Second: 9,285.21780

Timestep Collection Time: 4.53264
Timestep Consumption Time: 0.85248
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 5.38512

Cumulative Model Updates: 3,947
Cumulative Timesteps: 65,921,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 65921288...
Checkpoint 65921288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.77601
Policy Entropy: 1.15858
Value Function Loss: 5.54031

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.04123
Value Function Update Magnitude: 0.04730

Collected Steps per Second: 10,945.17301
Overall Steps per Second: 9,068.50351

Timestep Collection Time: 4.56877
Timestep Consumption Time: 0.94548
PPO Batch Consumption Time: 0.04335
Total Iteration Time: 5.51425

Cumulative Model Updates: 3,950
Cumulative Timesteps: 65,971,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.28055
Policy Entropy: 1.14023
Value Function Loss: 5.44485

Mean KL Divergence: 0.03340
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.03553
Value Function Update Magnitude: 0.03872

Collected Steps per Second: 10,869.57939
Overall Steps per Second: 9,274.29366

Timestep Collection Time: 4.60128
Timestep Consumption Time: 0.79147
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 5.39276

Cumulative Model Updates: 3,953
Cumulative Timesteps: 66,021,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 66021308...
Checkpoint 66021308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.85237
Policy Entropy: 1.15894
Value Function Loss: 5.28277

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.03351
Value Function Update Magnitude: 0.03298

Collected Steps per Second: 10,662.65678
Overall Steps per Second: 9,018.96289

Timestep Collection Time: 4.69001
Timestep Consumption Time: 0.85475
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 5.54476

Cumulative Model Updates: 3,956
Cumulative Timesteps: 66,071,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.21686
Policy Entropy: 1.14961
Value Function Loss: 5.12056

Mean KL Divergence: 0.02997
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.03542
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 10,993.46570
Overall Steps per Second: 9,288.46757

Timestep Collection Time: 4.54834
Timestep Consumption Time: 0.83490
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.38323

Cumulative Model Updates: 3,959
Cumulative Timesteps: 66,121,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 66121318...
Checkpoint 66121318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.82437
Policy Entropy: 1.17040
Value Function Loss: 5.35881

Mean KL Divergence: 0.02515
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.03384
Value Function Update Magnitude: 0.04477

Collected Steps per Second: 11,122.39640
Overall Steps per Second: 9,336.52519

Timestep Collection Time: 4.49651
Timestep Consumption Time: 0.86008
PPO Batch Consumption Time: 0.04586
Total Iteration Time: 5.35660

Cumulative Model Updates: 3,962
Cumulative Timesteps: 66,171,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.21492
Policy Entropy: 1.15391
Value Function Loss: 5.34913

Mean KL Divergence: 0.03227
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.03412
Value Function Update Magnitude: 0.05288

Collected Steps per Second: 10,866.20385
Overall Steps per Second: 9,267.90500

Timestep Collection Time: 4.60216
Timestep Consumption Time: 0.79367
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 5.39583

Cumulative Model Updates: 3,965
Cumulative Timesteps: 66,221,338

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 66221338...
Checkpoint 66221338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.50462
Policy Entropy: 1.16415
Value Function Loss: 5.13066

Mean KL Divergence: 0.02529
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.03707
Value Function Update Magnitude: 0.04960

Collected Steps per Second: 10,511.73062
Overall Steps per Second: 9,007.13904

Timestep Collection Time: 4.75811
Timestep Consumption Time: 0.79482
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 5.55293

Cumulative Model Updates: 3,968
Cumulative Timesteps: 66,271,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.78111
Policy Entropy: 1.14389
Value Function Loss: 5.09213

Mean KL Divergence: 0.03425
SB3 Clip Fraction: 0.15567
Policy Update Magnitude: 0.03747
Value Function Update Magnitude: 0.04138

Collected Steps per Second: 10,057.88937
Overall Steps per Second: 8,574.43577

Timestep Collection Time: 4.97281
Timestep Consumption Time: 0.86034
PPO Batch Consumption Time: 0.04094
Total Iteration Time: 5.83315

Cumulative Model Updates: 3,971
Cumulative Timesteps: 66,321,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 66321370...
Checkpoint 66321370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.19179
Policy Entropy: 1.14895
Value Function Loss: 4.98169

Mean KL Divergence: 0.02497
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.03630
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 10,633.58625
Overall Steps per Second: 8,999.89637

Timestep Collection Time: 4.70340
Timestep Consumption Time: 0.85378
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 5.55718

Cumulative Model Updates: 3,974
Cumulative Timesteps: 66,371,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.86293
Policy Entropy: 1.13486
Value Function Loss: 5.26564

Mean KL Divergence: 0.03287
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.03737
Value Function Update Magnitude: 0.06272

Collected Steps per Second: 11,080.17870
Overall Steps per Second: 9,283.97440

Timestep Collection Time: 4.51256
Timestep Consumption Time: 0.87306
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 5.38562

Cumulative Model Updates: 3,977
Cumulative Timesteps: 66,421,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 66421384...
Checkpoint 66421384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.02532
Policy Entropy: 1.15526
Value Function Loss: 5.14300

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.03423
Value Function Update Magnitude: 0.06502

Collected Steps per Second: 10,504.57303
Overall Steps per Second: 8,894.25020

Timestep Collection Time: 4.76059
Timestep Consumption Time: 0.86192
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 5.62251

Cumulative Model Updates: 3,980
Cumulative Timesteps: 66,471,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.96419
Policy Entropy: 1.14706
Value Function Loss: 5.26456

Mean KL Divergence: 0.03068
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.03709
Value Function Update Magnitude: 0.06058

Collected Steps per Second: 10,603.67368
Overall Steps per Second: 9,014.02740

Timestep Collection Time: 4.71648
Timestep Consumption Time: 0.83176
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 5.54824

Cumulative Model Updates: 3,983
Cumulative Timesteps: 66,521,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 66521404...
Checkpoint 66521404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.11537
Policy Entropy: 1.15927
Value Function Loss: 5.27442

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.03625
Value Function Update Magnitude: 0.05755

Collected Steps per Second: 10,861.15183
Overall Steps per Second: 8,997.12737

Timestep Collection Time: 4.60485
Timestep Consumption Time: 0.95403
PPO Batch Consumption Time: 0.03829
Total Iteration Time: 5.55889

Cumulative Model Updates: 3,986
Cumulative Timesteps: 66,571,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.06093
Policy Entropy: 1.13669
Value Function Loss: 5.07970

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.03450
Value Function Update Magnitude: 0.05929

Collected Steps per Second: 10,508.52975
Overall Steps per Second: 8,900.06223

Timestep Collection Time: 4.75861
Timestep Consumption Time: 0.86000
PPO Batch Consumption Time: 0.04147
Total Iteration Time: 5.61861

Cumulative Model Updates: 3,989
Cumulative Timesteps: 66,621,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 66621424...
Checkpoint 66621424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.32785
Policy Entropy: 1.15895
Value Function Loss: 5.00178

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.03998
Value Function Update Magnitude: 0.05517

Collected Steps per Second: 10,801.68995
Overall Steps per Second: 9,235.79961

Timestep Collection Time: 4.63150
Timestep Consumption Time: 0.78525
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 5.41675

Cumulative Model Updates: 3,992
Cumulative Timesteps: 66,671,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.87179
Policy Entropy: 1.14038
Value Function Loss: 5.15688

Mean KL Divergence: 0.02999
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.03617
Value Function Update Magnitude: 0.05245

Collected Steps per Second: 10,496.47266
Overall Steps per Second: 8,922.41396

Timestep Collection Time: 4.76446
Timestep Consumption Time: 0.84053
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 5.60499

Cumulative Model Updates: 3,995
Cumulative Timesteps: 66,721,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 66721462...
Checkpoint 66721462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.75421
Policy Entropy: 1.15301
Value Function Loss: 5.33388

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.04676

Collected Steps per Second: 10,140.52860
Overall Steps per Second: 8,805.72643

Timestep Collection Time: 4.93189
Timestep Consumption Time: 0.74759
PPO Batch Consumption Time: 0.04806
Total Iteration Time: 5.67949

Cumulative Model Updates: 3,998
Cumulative Timesteps: 66,771,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.92178
Policy Entropy: 1.13289
Value Function Loss: 5.38821

Mean KL Divergence: 0.03078
SB3 Clip Fraction: 0.14546
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.05305

Collected Steps per Second: 10,655.45553
Overall Steps per Second: 9,056.53624

Timestep Collection Time: 4.69619
Timestep Consumption Time: 0.82911
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.52529

Cumulative Model Updates: 4,001
Cumulative Timesteps: 66,821,514

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 66821514...
Checkpoint 66821514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.68314
Policy Entropy: 1.15788
Value Function Loss: 5.11807

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.04164
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 10,045.88660
Overall Steps per Second: 8,498.49204

Timestep Collection Time: 4.97716
Timestep Consumption Time: 0.90624
PPO Batch Consumption Time: 0.04771
Total Iteration Time: 5.88340

Cumulative Model Updates: 4,004
Cumulative Timesteps: 66,871,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.59519
Policy Entropy: 1.14613
Value Function Loss: 5.21357

Mean KL Divergence: 0.02628
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.04194
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 10,743.76389
Overall Steps per Second: 9,072.59449

Timestep Collection Time: 4.65554
Timestep Consumption Time: 0.85755
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 5.51309

Cumulative Model Updates: 4,007
Cumulative Timesteps: 66,921,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 66921532...
Checkpoint 66921532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.79279
Policy Entropy: 1.15131
Value Function Loss: 5.02842

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.06565

Collected Steps per Second: 10,499.44892
Overall Steps per Second: 8,896.89433

Timestep Collection Time: 4.76349
Timestep Consumption Time: 0.85802
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 5.62151

Cumulative Model Updates: 4,010
Cumulative Timesteps: 66,971,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.96653
Policy Entropy: 1.12640
Value Function Loss: 5.07429

Mean KL Divergence: 0.03216
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.05870

Collected Steps per Second: 10,648.49514
Overall Steps per Second: 9,119.00170

Timestep Collection Time: 4.69775
Timestep Consumption Time: 0.78794
PPO Batch Consumption Time: 0.04736
Total Iteration Time: 5.48569

Cumulative Model Updates: 4,013
Cumulative Timesteps: 67,021,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 67021570...
Checkpoint 67021570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.20679
Policy Entropy: 1.13453
Value Function Loss: 5.16848

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.05546

Collected Steps per Second: 10,805.16308
Overall Steps per Second: 9,070.86769

Timestep Collection Time: 4.62927
Timestep Consumption Time: 0.88509
PPO Batch Consumption Time: 0.04630
Total Iteration Time: 5.51436

Cumulative Model Updates: 4,016
Cumulative Timesteps: 67,071,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.68106
Policy Entropy: 1.12646
Value Function Loss: 5.31619

Mean KL Divergence: 0.03253
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.05244

Collected Steps per Second: 10,206.39770
Overall Steps per Second: 8,725.14726

Timestep Collection Time: 4.90144
Timestep Consumption Time: 0.83211
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 5.73354

Cumulative Model Updates: 4,019
Cumulative Timesteps: 67,121,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 67121616...
Checkpoint 67121616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.77225
Policy Entropy: 1.15368
Value Function Loss: 5.43157

Mean KL Divergence: 0.02326
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.05142

Collected Steps per Second: 10,750.56358
Overall Steps per Second: 9,081.26583

Timestep Collection Time: 4.65111
Timestep Consumption Time: 0.85496
PPO Batch Consumption Time: 0.03972
Total Iteration Time: 5.50606

Cumulative Model Updates: 4,022
Cumulative Timesteps: 67,171,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.99679
Policy Entropy: 1.14089
Value Function Loss: 5.28271

Mean KL Divergence: 0.03101
SB3 Clip Fraction: 0.14659
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.04895

Collected Steps per Second: 10,806.17379
Overall Steps per Second: 9,200.05603

Timestep Collection Time: 4.62902
Timestep Consumption Time: 0.80812
PPO Batch Consumption Time: 0.03873
Total Iteration Time: 5.43714

Cumulative Model Updates: 4,025
Cumulative Timesteps: 67,221,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 67221640...
Checkpoint 67221640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.55993
Policy Entropy: 1.15950
Value Function Loss: 5.43841

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.04602

Collected Steps per Second: 10,757.71663
Overall Steps per Second: 9,239.41435

Timestep Collection Time: 4.64838
Timestep Consumption Time: 0.76386
PPO Batch Consumption Time: 0.04255
Total Iteration Time: 5.41225

Cumulative Model Updates: 4,028
Cumulative Timesteps: 67,271,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.70483
Policy Entropy: 1.12873
Value Function Loss: 5.26309

Mean KL Divergence: 0.02830
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.06652

Collected Steps per Second: 10,835.47687
Overall Steps per Second: 9,099.17462

Timestep Collection Time: 4.61687
Timestep Consumption Time: 0.88099
PPO Batch Consumption Time: 0.04075
Total Iteration Time: 5.49786

Cumulative Model Updates: 4,031
Cumulative Timesteps: 67,321,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 67321672...
Checkpoint 67321672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.23013
Policy Entropy: 1.15267
Value Function Loss: 5.27572

Mean KL Divergence: 0.02676
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.07991

Collected Steps per Second: 10,549.58552
Overall Steps per Second: 8,825.20701

Timestep Collection Time: 4.74047
Timestep Consumption Time: 0.92625
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 5.66672

Cumulative Model Updates: 4,034
Cumulative Timesteps: 67,371,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.11538
Policy Entropy: 1.13025
Value Function Loss: 5.16836

Mean KL Divergence: 0.03147
SB3 Clip Fraction: 0.14558
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.07484

Collected Steps per Second: 10,743.86879
Overall Steps per Second: 8,982.99156

Timestep Collection Time: 4.65568
Timestep Consumption Time: 0.91262
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.56830

Cumulative Model Updates: 4,037
Cumulative Timesteps: 67,421,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 67421702...
Checkpoint 67421702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.55390
Policy Entropy: 1.16146
Value Function Loss: 5.38325

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.03620
Value Function Update Magnitude: 0.07533

Collected Steps per Second: 10,775.30622
Overall Steps per Second: 9,150.64041

Timestep Collection Time: 4.64302
Timestep Consumption Time: 0.82435
PPO Batch Consumption Time: 0.04605
Total Iteration Time: 5.46738

Cumulative Model Updates: 4,040
Cumulative Timesteps: 67,471,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.74665
Policy Entropy: 1.14959
Value Function Loss: 5.29863

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 10,269.93868
Overall Steps per Second: 8,863.50676

Timestep Collection Time: 4.87111
Timestep Consumption Time: 0.77293
PPO Batch Consumption Time: 0.04438
Total Iteration Time: 5.64404

Cumulative Model Updates: 4,043
Cumulative Timesteps: 67,521,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 67521758...
Checkpoint 67521758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.28868
Policy Entropy: 1.16810
Value Function Loss: 5.24724

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.04052
Value Function Update Magnitude: 0.07827

Collected Steps per Second: 10,423.82417
Overall Steps per Second: 8,874.91085

Timestep Collection Time: 4.79843
Timestep Consumption Time: 0.83746
PPO Batch Consumption Time: 0.03889
Total Iteration Time: 5.63589

Cumulative Model Updates: 4,046
Cumulative Timesteps: 67,571,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.09311
Policy Entropy: 1.14125
Value Function Loss: 5.14728

Mean KL Divergence: 0.02842
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.03708
Value Function Update Magnitude: 0.06009

Collected Steps per Second: 10,697.13635
Overall Steps per Second: 9,000.77084

Timestep Collection Time: 4.67602
Timestep Consumption Time: 0.88128
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 5.55730

Cumulative Model Updates: 4,049
Cumulative Timesteps: 67,621,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 67621796...
Checkpoint 67621796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.31310
Policy Entropy: 1.15282
Value Function Loss: 5.29215

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.09298

Collected Steps per Second: 10,230.25330
Overall Steps per Second: 8,670.62553

Timestep Collection Time: 4.88981
Timestep Consumption Time: 0.87955
PPO Batch Consumption Time: 0.04679
Total Iteration Time: 5.76936

Cumulative Model Updates: 4,052
Cumulative Timesteps: 67,671,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.91896
Policy Entropy: 1.14191
Value Function Loss: 5.25234

Mean KL Divergence: 0.03610
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.10330

Collected Steps per Second: 10,832.74519
Overall Steps per Second: 9,089.39603

Timestep Collection Time: 4.61637
Timestep Consumption Time: 0.88542
PPO Batch Consumption Time: 0.04069
Total Iteration Time: 5.50180

Cumulative Model Updates: 4,055
Cumulative Timesteps: 67,721,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 67721828...
Checkpoint 67721828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.89599
Policy Entropy: 1.15174
Value Function Loss: 5.16869

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.03917
Value Function Update Magnitude: 0.10877

Collected Steps per Second: 10,690.74411
Overall Steps per Second: 9,136.14615

Timestep Collection Time: 4.67881
Timestep Consumption Time: 0.79614
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 5.47496

Cumulative Model Updates: 4,058
Cumulative Timesteps: 67,771,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.18192
Policy Entropy: 1.13164
Value Function Loss: 5.21308

Mean KL Divergence: 0.03367
SB3 Clip Fraction: 0.15031
Policy Update Magnitude: 0.04194
Value Function Update Magnitude: 0.10144

Collected Steps per Second: 10,726.34742
Overall Steps per Second: 9,080.23797

Timestep Collection Time: 4.66328
Timestep Consumption Time: 0.84538
PPO Batch Consumption Time: 0.04135
Total Iteration Time: 5.50867

Cumulative Model Updates: 4,061
Cumulative Timesteps: 67,821,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 67821868...
Checkpoint 67821868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.75188
Policy Entropy: 1.13861
Value Function Loss: 5.35325

Mean KL Divergence: 0.02546
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.03856
Value Function Update Magnitude: 0.10403

Collected Steps per Second: 10,658.99273
Overall Steps per Second: 9,201.79092

Timestep Collection Time: 4.69106
Timestep Consumption Time: 0.74288
PPO Batch Consumption Time: 0.04104
Total Iteration Time: 5.43394

Cumulative Model Updates: 4,064
Cumulative Timesteps: 67,871,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.66481
Policy Entropy: 1.12876
Value Function Loss: 5.51648

Mean KL Divergence: 0.03043
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.08430

Collected Steps per Second: 10,345.95462
Overall Steps per Second: 8,802.47570

Timestep Collection Time: 4.83571
Timestep Consumption Time: 0.84792
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.68363

Cumulative Model Updates: 4,067
Cumulative Timesteps: 67,921,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 67921900...
Checkpoint 67921900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.58110
Policy Entropy: 1.14108
Value Function Loss: 5.46859

Mean KL Divergence: 0.02720
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.06993

Collected Steps per Second: 10,609.80275
Overall Steps per Second: 9,000.07313

Timestep Collection Time: 4.71432
Timestep Consumption Time: 0.84319
PPO Batch Consumption Time: 0.04768
Total Iteration Time: 5.55751

Cumulative Model Updates: 4,070
Cumulative Timesteps: 67,971,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.89469
Policy Entropy: 1.12558
Value Function Loss: 5.35186

Mean KL Divergence: 0.03284
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.06357

Collected Steps per Second: 11,099.66454
Overall Steps per Second: 9,378.45783

Timestep Collection Time: 4.50518
Timestep Consumption Time: 0.82683
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 5.33201

Cumulative Model Updates: 4,073
Cumulative Timesteps: 68,021,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 68021924...
Checkpoint 68021924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.05193
Policy Entropy: 1.15599
Value Function Loss: 5.18168

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.04344
Value Function Update Magnitude: 0.07278

Collected Steps per Second: 10,504.14985
Overall Steps per Second: 8,940.50639

Timestep Collection Time: 4.76269
Timestep Consumption Time: 0.83297
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.59566

Cumulative Model Updates: 4,076
Cumulative Timesteps: 68,071,952

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.02823
Policy Entropy: 1.14555
Value Function Loss: 5.03465

Mean KL Divergence: 0.02889
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.06743

Collected Steps per Second: 11,121.30938
Overall Steps per Second: 9,434.79001

Timestep Collection Time: 4.49695
Timestep Consumption Time: 0.80385
PPO Batch Consumption Time: 0.03959
Total Iteration Time: 5.30081

Cumulative Model Updates: 4,079
Cumulative Timesteps: 68,121,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 68121964...
Checkpoint 68121964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.01685
Policy Entropy: 1.16152
Value Function Loss: 5.15339

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.05941

Collected Steps per Second: 11,122.61774
Overall Steps per Second: 9,268.78840

Timestep Collection Time: 4.49876
Timestep Consumption Time: 0.89979
PPO Batch Consumption Time: 0.04651
Total Iteration Time: 5.39855

Cumulative Model Updates: 4,082
Cumulative Timesteps: 68,172,002

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.24347
Policy Entropy: 1.13759
Value Function Loss: 5.42489

Mean KL Divergence: 0.03283
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.05732

Collected Steps per Second: 10,442.95808
Overall Steps per Second: 8,913.85028

Timestep Collection Time: 4.78887
Timestep Consumption Time: 0.82150
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 5.61037

Cumulative Model Updates: 4,085
Cumulative Timesteps: 68,222,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 68222012...
Checkpoint 68222012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.66171
Policy Entropy: 1.16563
Value Function Loss: 5.61767

Mean KL Divergence: 0.03154
SB3 Clip Fraction: 0.15668
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 11,269.53088
Overall Steps per Second: 9,495.47572

Timestep Collection Time: 4.43798
Timestep Consumption Time: 0.82916
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 5.26714

Cumulative Model Updates: 4,088
Cumulative Timesteps: 68,272,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.39750
Policy Entropy: 1.14264
Value Function Loss: 5.55381

Mean KL Divergence: 0.02852
SB3 Clip Fraction: 0.15079
Policy Update Magnitude: 0.04364
Value Function Update Magnitude: 0.08321

Collected Steps per Second: 11,251.25277
Overall Steps per Second: 9,437.59479

Timestep Collection Time: 4.44555
Timestep Consumption Time: 0.85432
PPO Batch Consumption Time: 0.04389
Total Iteration Time: 5.29987

Cumulative Model Updates: 4,091
Cumulative Timesteps: 68,322,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 68322044...
Checkpoint 68322044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.87403
Policy Entropy: 1.15982
Value Function Loss: 5.39791

Mean KL Divergence: 0.02951
SB3 Clip Fraction: 0.15183
Policy Update Magnitude: 0.04341
Value Function Update Magnitude: 0.09041

Collected Steps per Second: 10,982.68313
Overall Steps per Second: 9,438.96100

Timestep Collection Time: 4.55408
Timestep Consumption Time: 0.74481
PPO Batch Consumption Time: 0.04301
Total Iteration Time: 5.29889

Cumulative Model Updates: 4,094
Cumulative Timesteps: 68,372,060

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.00642
Policy Entropy: 1.14618
Value Function Loss: 5.39442

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.08697

Collected Steps per Second: 10,716.59054
Overall Steps per Second: 9,040.50744

Timestep Collection Time: 4.66846
Timestep Consumption Time: 0.86552
PPO Batch Consumption Time: 0.04039
Total Iteration Time: 5.53398

Cumulative Model Updates: 4,097
Cumulative Timesteps: 68,422,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 68422090...
Checkpoint 68422090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.20490
Policy Entropy: 1.16847
Value Function Loss: 5.57278

Mean KL Divergence: 0.02710
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.07275

Collected Steps per Second: 10,198.21569
Overall Steps per Second: 8,807.36679

Timestep Collection Time: 4.90517
Timestep Consumption Time: 0.77462
PPO Batch Consumption Time: 0.04662
Total Iteration Time: 5.67979

Cumulative Model Updates: 4,100
Cumulative Timesteps: 68,472,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.88142
Policy Entropy: 1.14988
Value Function Loss: 5.45496

Mean KL Divergence: 0.03564
SB3 Clip Fraction: 0.15922
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 10,914.90349
Overall Steps per Second: 9,234.08081

Timestep Collection Time: 4.58272
Timestep Consumption Time: 0.83417
PPO Batch Consumption Time: 0.03869
Total Iteration Time: 5.41689

Cumulative Model Updates: 4,103
Cumulative Timesteps: 68,522,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 68522134...
Checkpoint 68522134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.72408
Policy Entropy: 1.16281
Value Function Loss: 5.51027

Mean KL Divergence: 0.02732
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.09682

Collected Steps per Second: 10,734.18309
Overall Steps per Second: 9,077.52535

Timestep Collection Time: 4.65876
Timestep Consumption Time: 0.85023
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 5.50899

Cumulative Model Updates: 4,106
Cumulative Timesteps: 68,572,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.13128
Policy Entropy: 1.14820
Value Function Loss: 5.44516

Mean KL Divergence: 0.03097
SB3 Clip Fraction: 0.14871
Policy Update Magnitude: 0.04304
Value Function Update Magnitude: 0.10740

Collected Steps per Second: 10,738.10324
Overall Steps per Second: 9,232.18292

Timestep Collection Time: 4.65836
Timestep Consumption Time: 0.75986
PPO Batch Consumption Time: 0.04104
Total Iteration Time: 5.41822

Cumulative Model Updates: 4,109
Cumulative Timesteps: 68,622,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 68622164...
Checkpoint 68622164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.85777
Policy Entropy: 1.15543
Value Function Loss: 5.52575

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.04242
Value Function Update Magnitude: 0.10430

Collected Steps per Second: 10,751.79242
Overall Steps per Second: 9,135.90759

Timestep Collection Time: 4.65039
Timestep Consumption Time: 0.82252
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 5.47291

Cumulative Model Updates: 4,112
Cumulative Timesteps: 68,672,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.83962
Policy Entropy: 1.13130
Value Function Loss: 5.62689

Mean KL Divergence: 0.03839
SB3 Clip Fraction: 0.15593
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.09970

Collected Steps per Second: 10,740.78713
Overall Steps per Second: 9,253.77027

Timestep Collection Time: 4.65795
Timestep Consumption Time: 0.74850
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 5.40645

Cumulative Model Updates: 4,115
Cumulative Timesteps: 68,722,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 68722194...
Checkpoint 68722194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.97889
Policy Entropy: 1.14998
Value Function Loss: 5.58904

Mean KL Divergence: 0.02524
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.03651
Value Function Update Magnitude: 0.07815

Collected Steps per Second: 10,473.53582
Overall Steps per Second: 8,977.01087

Timestep Collection Time: 4.77432
Timestep Consumption Time: 0.79591
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 5.57023

Cumulative Model Updates: 4,118
Cumulative Timesteps: 68,772,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.80192
Policy Entropy: 1.13995
Value Function Loss: 5.66189

Mean KL Divergence: 0.02941
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.04425
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 10,859.06883
Overall Steps per Second: 9,223.13793

Timestep Collection Time: 4.60500
Timestep Consumption Time: 0.81680
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.42180

Cumulative Model Updates: 4,121
Cumulative Timesteps: 68,822,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 68822204...
Checkpoint 68822204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.39239
Policy Entropy: 1.16214
Value Function Loss: 5.38339

Mean KL Divergence: 0.02693
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.06007

Collected Steps per Second: 10,754.39951
Overall Steps per Second: 9,262.52039

Timestep Collection Time: 4.65019
Timestep Consumption Time: 0.74899
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 5.39918

Cumulative Model Updates: 4,124
Cumulative Timesteps: 68,872,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.08439
Policy Entropy: 1.15059
Value Function Loss: 5.28564

Mean KL Divergence: 0.03873
SB3 Clip Fraction: 0.16725
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.06794

Collected Steps per Second: 10,843.40981
Overall Steps per Second: 9,157.08238

Timestep Collection Time: 4.61165
Timestep Consumption Time: 0.84926
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 5.46091

Cumulative Model Updates: 4,127
Cumulative Timesteps: 68,922,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 68922220...
Checkpoint 68922220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.86988
Policy Entropy: 1.16824
Value Function Loss: 5.05444

Mean KL Divergence: 0.02578
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.03747
Value Function Update Magnitude: 0.05440

Collected Steps per Second: 10,740.36306
Overall Steps per Second: 9,268.55367

Timestep Collection Time: 4.65794
Timestep Consumption Time: 0.73966
PPO Batch Consumption Time: 0.04081
Total Iteration Time: 5.39761

Cumulative Model Updates: 4,130
Cumulative Timesteps: 68,972,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.36962
Policy Entropy: 1.15033
Value Function Loss: 5.11217

Mean KL Divergence: 0.03476
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.03687
Value Function Update Magnitude: 0.06874

Collected Steps per Second: 10,304.03877
Overall Steps per Second: 8,809.35725

Timestep Collection Time: 4.85441
Timestep Consumption Time: 0.82365
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 5.67805

Cumulative Model Updates: 4,133
Cumulative Timesteps: 69,022,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 69022268...
Checkpoint 69022268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.40406
Policy Entropy: 1.15644
Value Function Loss: 5.14771

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.03594
Value Function Update Magnitude: 0.07844

Collected Steps per Second: 10,688.02447
Overall Steps per Second: 9,077.36714

Timestep Collection Time: 4.67813
Timestep Consumption Time: 0.83007
PPO Batch Consumption Time: 0.03992
Total Iteration Time: 5.50821

Cumulative Model Updates: 4,136
Cumulative Timesteps: 69,072,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.79911
Policy Entropy: 1.14416
Value Function Loss: 5.11347

Mean KL Divergence: 0.03431
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.07884

Collected Steps per Second: 10,838.69563
Overall Steps per Second: 9,104.21358

Timestep Collection Time: 4.61605
Timestep Consumption Time: 0.87942
PPO Batch Consumption Time: 0.04461
Total Iteration Time: 5.49548

Cumulative Model Updates: 4,139
Cumulative Timesteps: 69,122,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 69122300...
Checkpoint 69122300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.57535
Policy Entropy: 1.16719
Value Function Loss: 5.16643

Mean KL Divergence: 0.02803
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.03682
Value Function Update Magnitude: 0.07275

Collected Steps per Second: 10,627.58052
Overall Steps per Second: 9,075.55243

Timestep Collection Time: 4.70474
Timestep Consumption Time: 0.80457
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 5.50931

Cumulative Model Updates: 4,142
Cumulative Timesteps: 69,172,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.40603
Policy Entropy: 1.13796
Value Function Loss: 5.28097

Mean KL Divergence: 0.03010
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.03392
Value Function Update Magnitude: 0.06814

Collected Steps per Second: 10,852.44551
Overall Steps per Second: 9,333.48734

Timestep Collection Time: 4.60892
Timestep Consumption Time: 0.75007
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 5.35898

Cumulative Model Updates: 4,145
Cumulative Timesteps: 69,222,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 69222318...
Checkpoint 69222318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.17997
Policy Entropy: 1.14102
Value Function Loss: 5.33388

Mean KL Divergence: 0.02897
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.04116
Value Function Update Magnitude: 0.05198

Collected Steps per Second: 10,827.96231
Overall Steps per Second: 9,098.82661

Timestep Collection Time: 4.62044
Timestep Consumption Time: 0.87807
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 5.49851

Cumulative Model Updates: 4,148
Cumulative Timesteps: 69,272,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.09753
Policy Entropy: 1.11609
Value Function Loss: 5.31315

Mean KL Divergence: 0.03218
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.03820

Collected Steps per Second: 10,170.39210
Overall Steps per Second: 8,676.48607

Timestep Collection Time: 4.91662
Timestep Consumption Time: 0.84654
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 5.76316

Cumulative Model Updates: 4,151
Cumulative Timesteps: 69,322,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 69322352...
Checkpoint 69322352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.40193
Policy Entropy: 1.14772
Value Function Loss: 5.19987

Mean KL Divergence: 0.03060
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.04355

Collected Steps per Second: 10,724.07907
Overall Steps per Second: 9,077.38277

Timestep Collection Time: 4.66296
Timestep Consumption Time: 0.84589
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.50886

Cumulative Model Updates: 4,154
Cumulative Timesteps: 69,372,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.06820
Policy Entropy: 1.14347
Value Function Loss: 5.26078

Mean KL Divergence: 0.03220
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.04041
Value Function Update Magnitude: 0.05379

Collected Steps per Second: 10,933.45420
Overall Steps per Second: 9,267.02970

Timestep Collection Time: 4.57330
Timestep Consumption Time: 0.82238
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 5.39569

Cumulative Model Updates: 4,157
Cumulative Timesteps: 69,422,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 69422360...
Checkpoint 69422360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.73249
Policy Entropy: 1.16598
Value Function Loss: 5.17020

Mean KL Divergence: 0.03022
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.03934
Value Function Update Magnitude: 0.05413

Collected Steps per Second: 10,924.48886
Overall Steps per Second: 9,121.59074

Timestep Collection Time: 4.57889
Timestep Consumption Time: 0.90502
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 5.48391

Cumulative Model Updates: 4,160
Cumulative Timesteps: 69,472,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.98371
Policy Entropy: 1.14316
Value Function Loss: 5.22336

Mean KL Divergence: 0.02866
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.03719
Value Function Update Magnitude: 0.04959

Collected Steps per Second: 10,975.31397
Overall Steps per Second: 9,212.03932

Timestep Collection Time: 4.55750
Timestep Consumption Time: 0.87235
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.42985

Cumulative Model Updates: 4,163
Cumulative Timesteps: 69,522,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 69522402...
Checkpoint 69522402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.24589
Policy Entropy: 1.14802
Value Function Loss: 5.31995

Mean KL Divergence: 0.03311
SB3 Clip Fraction: 0.15507
Policy Update Magnitude: 0.03603
Value Function Update Magnitude: 0.05247

Collected Steps per Second: 10,157.77930
Overall Steps per Second: 8,683.12063

Timestep Collection Time: 4.92332
Timestep Consumption Time: 0.83613
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 5.75945

Cumulative Model Updates: 4,166
Cumulative Timesteps: 69,572,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.96689
Policy Entropy: 1.14661
Value Function Loss: 5.21572

Mean KL Divergence: 0.02954
SB3 Clip Fraction: 0.14162
Policy Update Magnitude: 0.03940
Value Function Update Magnitude: 0.05773

Collected Steps per Second: 10,651.93006
Overall Steps per Second: 9,133.61107

Timestep Collection Time: 4.69586
Timestep Consumption Time: 0.78061
PPO Batch Consumption Time: 0.04504
Total Iteration Time: 5.47648

Cumulative Model Updates: 4,169
Cumulative Timesteps: 69,622,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 69622432...
Checkpoint 69622432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.82464
Policy Entropy: 1.16928
Value Function Loss: 5.17782

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.04121
Value Function Update Magnitude: 0.05924

Collected Steps per Second: 10,826.94084
Overall Steps per Second: 9,098.61410

Timestep Collection Time: 4.61922
Timestep Consumption Time: 0.87744
PPO Batch Consumption Time: 0.04336
Total Iteration Time: 5.49666

Cumulative Model Updates: 4,172
Cumulative Timesteps: 69,672,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.61583
Policy Entropy: 1.16280
Value Function Loss: 5.18482

Mean KL Divergence: 0.03135
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.04840

Collected Steps per Second: 10,789.00366
Overall Steps per Second: 9,277.11155

Timestep Collection Time: 4.63528
Timestep Consumption Time: 0.75541
PPO Batch Consumption Time: 0.04161
Total Iteration Time: 5.39069

Cumulative Model Updates: 4,175
Cumulative Timesteps: 69,722,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 69722454...
Checkpoint 69722454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.88530
Policy Entropy: 1.16940
Value Function Loss: 5.24506

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.04717

Collected Steps per Second: 10,663.32913
Overall Steps per Second: 9,044.54473

Timestep Collection Time: 4.69009
Timestep Consumption Time: 0.83943
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.52952

Cumulative Model Updates: 4,178
Cumulative Timesteps: 69,772,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.10595
Policy Entropy: 1.15899
Value Function Loss: 5.36170

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.05979

Collected Steps per Second: 10,481.88781
Overall Steps per Second: 8,783.30868

Timestep Collection Time: 4.77013
Timestep Consumption Time: 0.92248
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 5.69262

Cumulative Model Updates: 4,181
Cumulative Timesteps: 69,822,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 69822466...
Checkpoint 69822466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.74340
Policy Entropy: 1.15639
Value Function Loss: 5.01647

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.05725

Collected Steps per Second: 10,791.04279
Overall Steps per Second: 9,137.81895

Timestep Collection Time: 4.63681
Timestep Consumption Time: 0.83890
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.47570

Cumulative Model Updates: 4,184
Cumulative Timesteps: 69,872,502

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.65919
Policy Entropy: 1.16853
Value Function Loss: 4.97432

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.05603

Collected Steps per Second: 10,332.74295
Overall Steps per Second: 8,803.40951

Timestep Collection Time: 4.84208
Timestep Consumption Time: 0.84117
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 5.68325

Cumulative Model Updates: 4,187
Cumulative Timesteps: 69,922,534

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 69922534...
Checkpoint 69922534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.18388
Policy Entropy: 1.15389
Value Function Loss: 4.88140

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.11382
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.05259

Collected Steps per Second: 10,483.92244
Overall Steps per Second: 9,109.71978

Timestep Collection Time: 4.77073
Timestep Consumption Time: 0.71967
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 5.49040

Cumulative Model Updates: 4,190
Cumulative Timesteps: 69,972,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.29663
Policy Entropy: 1.14645
Value Function Loss: 5.25236

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.05610

Collected Steps per Second: 10,917.71015
Overall Steps per Second: 9,218.06739

Timestep Collection Time: 4.58155
Timestep Consumption Time: 0.84475
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 5.42630

Cumulative Model Updates: 4,193
Cumulative Timesteps: 70,022,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 70022570...
Checkpoint 70022570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.79496
Policy Entropy: 1.15228
Value Function Loss: 5.53876

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.04604

Collected Steps per Second: 10,806.47529
Overall Steps per Second: 9,083.01081

Timestep Collection Time: 4.62926
Timestep Consumption Time: 0.87838
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 5.50765

Cumulative Model Updates: 4,196
Cumulative Timesteps: 70,072,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.75753
Policy Entropy: 1.14426
Value Function Loss: 5.41590

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.04742

Collected Steps per Second: 10,353.41373
Overall Steps per Second: 8,839.88414

Timestep Collection Time: 4.83164
Timestep Consumption Time: 0.82725
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 5.65890

Cumulative Model Updates: 4,199
Cumulative Timesteps: 70,122,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 70122620...
Checkpoint 70122620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.07065
Policy Entropy: 1.12941
Value Function Loss: 5.22232

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.07136
Value Function Update Magnitude: 0.05328

Collected Steps per Second: 10,337.15286
Overall Steps per Second: 8,841.26035

Timestep Collection Time: 4.83692
Timestep Consumption Time: 0.81838
PPO Batch Consumption Time: 0.03919
Total Iteration Time: 5.65530

Cumulative Model Updates: 4,202
Cumulative Timesteps: 70,172,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.24830
Policy Entropy: 1.14091
Value Function Loss: 5.00431

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.06634

Collected Steps per Second: 10,745.28339
Overall Steps per Second: 9,190.24310

Timestep Collection Time: 4.65581
Timestep Consumption Time: 0.78779
PPO Batch Consumption Time: 0.04674
Total Iteration Time: 5.44360

Cumulative Model Updates: 4,205
Cumulative Timesteps: 70,222,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 70222648...
Checkpoint 70222648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.09859
Policy Entropy: 1.14302
Value Function Loss: 5.06130

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.06548

Collected Steps per Second: 10,202.54002
Overall Steps per Second: 8,691.11472

Timestep Collection Time: 4.90407
Timestep Consumption Time: 0.85284
PPO Batch Consumption Time: 0.03900
Total Iteration Time: 5.75691

Cumulative Model Updates: 4,208
Cumulative Timesteps: 70,272,682

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.30412
Policy Entropy: 1.14720
Value Function Loss: 5.31514

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.04837

Collected Steps per Second: 11,168.05204
Overall Steps per Second: 9,425.01295

Timestep Collection Time: 4.47706
Timestep Consumption Time: 0.82798
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 5.30503

Cumulative Model Updates: 4,211
Cumulative Timesteps: 70,322,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 70322682...
Checkpoint 70322682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.38461
Policy Entropy: 1.15853
Value Function Loss: 5.40334

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.04772

Collected Steps per Second: 10,608.49281
Overall Steps per Second: 8,956.54753

Timestep Collection Time: 4.71339
Timestep Consumption Time: 0.86934
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.58273

Cumulative Model Updates: 4,214
Cumulative Timesteps: 70,372,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.40552
Policy Entropy: 1.16457
Value Function Loss: 5.49753

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.04696

Collected Steps per Second: 10,964.05800
Overall Steps per Second: 9,252.50067

Timestep Collection Time: 4.56291
Timestep Consumption Time: 0.84406
PPO Batch Consumption Time: 0.04458
Total Iteration Time: 5.40697

Cumulative Model Updates: 4,217
Cumulative Timesteps: 70,422,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 70422712...
Checkpoint 70422712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.95338
Policy Entropy: 1.17679
Value Function Loss: 5.22591

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.04462

Collected Steps per Second: 10,865.33284
Overall Steps per Second: 9,320.81837

Timestep Collection Time: 4.60271
Timestep Consumption Time: 0.76270
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 5.36541

Cumulative Model Updates: 4,220
Cumulative Timesteps: 70,472,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.92916
Policy Entropy: 1.14737
Value Function Loss: 5.38300

Mean KL Divergence: 0.04233
SB3 Clip Fraction: 0.17646
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.04764

Collected Steps per Second: 11,038.86198
Overall Steps per Second: 9,297.00374

Timestep Collection Time: 4.53036
Timestep Consumption Time: 0.84879
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 5.37915

Cumulative Model Updates: 4,223
Cumulative Timesteps: 70,522,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 70522732...
Checkpoint 70522732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.41065
Policy Entropy: 1.16862
Value Function Loss: 5.36565

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.04259
Value Function Update Magnitude: 0.04763

Collected Steps per Second: 10,870.15199
Overall Steps per Second: 8,928.83537

Timestep Collection Time: 4.60141
Timestep Consumption Time: 1.00044
PPO Batch Consumption Time: 0.04906
Total Iteration Time: 5.60185

Cumulative Model Updates: 4,226
Cumulative Timesteps: 70,572,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.24312
Policy Entropy: 1.15913
Value Function Loss: 5.51234

Mean KL Divergence: 0.03938
SB3 Clip Fraction: 0.16573
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.04883

Collected Steps per Second: 10,147.15464
Overall Steps per Second: 8,661.81340

Timestep Collection Time: 4.92769
Timestep Consumption Time: 0.84501
PPO Batch Consumption Time: 0.04986
Total Iteration Time: 5.77269

Cumulative Model Updates: 4,229
Cumulative Timesteps: 70,622,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 70622752...
Checkpoint 70622752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.00592
Policy Entropy: 1.18184
Value Function Loss: 5.28378

Mean KL Divergence: 0.03259
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.05330

Collected Steps per Second: 10,063.00010
Overall Steps per Second: 8,520.92967

Timestep Collection Time: 4.96969
Timestep Consumption Time: 0.89939
PPO Batch Consumption Time: 0.04569
Total Iteration Time: 5.86908

Cumulative Model Updates: 4,232
Cumulative Timesteps: 70,672,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.70569
Policy Entropy: 1.15285
Value Function Loss: 5.05190

Mean KL Divergence: 0.03602
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.04174
Value Function Update Magnitude: 0.04983

Collected Steps per Second: 10,820.16421
Overall Steps per Second: 9,288.15293

Timestep Collection Time: 4.62211
Timestep Consumption Time: 0.76238
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 5.38449

Cumulative Model Updates: 4,235
Cumulative Timesteps: 70,722,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 70722774...
Checkpoint 70722774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.74911
Policy Entropy: 1.16171
Value Function Loss: 4.85611

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.03728
Value Function Update Magnitude: 0.05413

Collected Steps per Second: 10,863.08045
Overall Steps per Second: 9,172.91304

Timestep Collection Time: 4.60477
Timestep Consumption Time: 0.84846
PPO Batch Consumption Time: 0.03980
Total Iteration Time: 5.45323

Cumulative Model Updates: 4,238
Cumulative Timesteps: 70,772,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.48958
Policy Entropy: 1.14167
Value Function Loss: 4.85046

Mean KL Divergence: 0.04352
SB3 Clip Fraction: 0.16134
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.07228

Collected Steps per Second: 10,778.86116
Overall Steps per Second: 9,146.91648

Timestep Collection Time: 4.64149
Timestep Consumption Time: 0.82811
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 5.46960

Cumulative Model Updates: 4,241
Cumulative Timesteps: 70,822,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 70822826...
Checkpoint 70822826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.97405
Policy Entropy: 1.15981
Value Function Loss: 5.02465

Mean KL Divergence: 0.02730
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.04184
Value Function Update Magnitude: 0.08172

Collected Steps per Second: 10,551.51166
Overall Steps per Second: 9,055.06976

Timestep Collection Time: 4.73942
Timestep Consumption Time: 0.78324
PPO Batch Consumption Time: 0.04582
Total Iteration Time: 5.52265

Cumulative Model Updates: 4,244
Cumulative Timesteps: 70,872,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.78637
Policy Entropy: 1.15171
Value Function Loss: 5.21847

Mean KL Divergence: 0.03127
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.04205
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 10,386.25506
Overall Steps per Second: 8,905.90669

Timestep Collection Time: 4.81405
Timestep Consumption Time: 0.80020
PPO Batch Consumption Time: 0.04039
Total Iteration Time: 5.61425

Cumulative Model Updates: 4,247
Cumulative Timesteps: 70,922,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 70922834...
Checkpoint 70922834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.25228
Policy Entropy: 1.16465
Value Function Loss: 5.46219

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.05458

Collected Steps per Second: 10,718.28082
Overall Steps per Second: 9,172.17978

Timestep Collection Time: 4.66642
Timestep Consumption Time: 0.78659
PPO Batch Consumption Time: 0.04522
Total Iteration Time: 5.45301

Cumulative Model Updates: 4,250
Cumulative Timesteps: 70,972,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.66455
Policy Entropy: 1.14501
Value Function Loss: 5.51916

Mean KL Divergence: 0.03779
SB3 Clip Fraction: 0.15162
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 10,824.09114
Overall Steps per Second: 9,183.64948

Timestep Collection Time: 4.61988
Timestep Consumption Time: 0.82523
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.44511

Cumulative Model Updates: 4,253
Cumulative Timesteps: 71,022,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 71022856...
Checkpoint 71022856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.69134
Policy Entropy: 1.16127
Value Function Loss: 5.41486

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.03985
Value Function Update Magnitude: 0.05995

Collected Steps per Second: 10,937.39697
Overall Steps per Second: 9,341.45994

Timestep Collection Time: 4.57385
Timestep Consumption Time: 0.78142
PPO Batch Consumption Time: 0.03846
Total Iteration Time: 5.35527

Cumulative Model Updates: 4,256
Cumulative Timesteps: 71,072,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.70557
Policy Entropy: 1.14108
Value Function Loss: 5.38711

Mean KL Divergence: 0.03807
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.05749

Collected Steps per Second: 10,787.02809
Overall Steps per Second: 9,158.87477

Timestep Collection Time: 4.63575
Timestep Consumption Time: 0.82409
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 5.45984

Cumulative Model Updates: 4,259
Cumulative Timesteps: 71,122,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 71122888...
Checkpoint 71122888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.07212
Policy Entropy: 1.15711
Value Function Loss: 5.36276

Mean KL Divergence: 0.03141
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.06146

Collected Steps per Second: 10,837.94461
Overall Steps per Second: 9,104.71304

Timestep Collection Time: 4.61600
Timestep Consumption Time: 0.87873
PPO Batch Consumption Time: 0.04156
Total Iteration Time: 5.49474

Cumulative Model Updates: 4,262
Cumulative Timesteps: 71,172,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.33169
Policy Entropy: 1.13501
Value Function Loss: 5.48302

Mean KL Divergence: 0.03358
SB3 Clip Fraction: 0.14578
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.05724

Collected Steps per Second: 10,421.53770
Overall Steps per Second: 8,996.42605

Timestep Collection Time: 4.80006
Timestep Consumption Time: 0.76037
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 5.56043

Cumulative Model Updates: 4,265
Cumulative Timesteps: 71,222,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 71222940...
Checkpoint 71222940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.12595
Policy Entropy: 1.15978
Value Function Loss: 5.21908

Mean KL Divergence: 0.02832
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.04054
Value Function Update Magnitude: 0.06470

Collected Steps per Second: 10,652.37828
Overall Steps per Second: 9,045.76463

Timestep Collection Time: 4.69416
Timestep Consumption Time: 0.83373
PPO Batch Consumption Time: 0.04737
Total Iteration Time: 5.52789

Cumulative Model Updates: 4,268
Cumulative Timesteps: 71,272,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.74399
Policy Entropy: 1.14878
Value Function Loss: 5.16656

Mean KL Divergence: 0.03285
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.09200

Collected Steps per Second: 10,905.31491
Overall Steps per Second: 9,195.43391

Timestep Collection Time: 4.58657
Timestep Consumption Time: 0.85287
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 5.43944

Cumulative Model Updates: 4,271
Cumulative Timesteps: 71,322,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 71322962...
Checkpoint 71322962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.30351
Policy Entropy: 1.16802
Value Function Loss: 5.03416

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.04032
Value Function Update Magnitude: 0.08088

Collected Steps per Second: 10,864.99627
Overall Steps per Second: 9,176.67223

Timestep Collection Time: 4.60267
Timestep Consumption Time: 0.84680
PPO Batch Consumption Time: 0.04068
Total Iteration Time: 5.44947

Cumulative Model Updates: 4,274
Cumulative Timesteps: 71,372,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.71951
Policy Entropy: 1.15040
Value Function Loss: 5.33007

Mean KL Divergence: 0.03489
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.04052
Value Function Update Magnitude: 0.06780

Collected Steps per Second: 10,833.54998
Overall Steps per Second: 9,152.73933

Timestep Collection Time: 4.61658
Timestep Consumption Time: 0.84779
PPO Batch Consumption Time: 0.03930
Total Iteration Time: 5.46437

Cumulative Model Updates: 4,277
Cumulative Timesteps: 71,422,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 71422984...
Checkpoint 71422984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.39550
Policy Entropy: 1.17315
Value Function Loss: 5.46118

Mean KL Divergence: 0.02756
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.03901
Value Function Update Magnitude: 0.06611

Collected Steps per Second: 10,018.50234
Overall Steps per Second: 8,762.54002

Timestep Collection Time: 4.99196
Timestep Consumption Time: 0.71551
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 5.70748

Cumulative Model Updates: 4,280
Cumulative Timesteps: 71,472,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.24684
Policy Entropy: 1.15336
Value Function Loss: 5.31572

Mean KL Divergence: 0.03264
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.03969
Value Function Update Magnitude: 0.07223

Collected Steps per Second: 10,769.13418
Overall Steps per Second: 8,956.35693

Timestep Collection Time: 4.64308
Timestep Consumption Time: 0.93977
PPO Batch Consumption Time: 0.04723
Total Iteration Time: 5.58285

Cumulative Model Updates: 4,283
Cumulative Timesteps: 71,522,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 71522998...
Checkpoint 71522998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.24025
Policy Entropy: 1.16484
Value Function Loss: 5.15580

Mean KL Divergence: 0.02869
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.07457

Collected Steps per Second: 10,778.97756
Overall Steps per Second: 9,203.32404

Timestep Collection Time: 4.64033
Timestep Consumption Time: 0.79445
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.43478

Cumulative Model Updates: 4,286
Cumulative Timesteps: 71,573,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.18453
Policy Entropy: 1.14963
Value Function Loss: 5.27377

Mean KL Divergence: 0.03486
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.04242
Value Function Update Magnitude: 0.06644

Collected Steps per Second: 10,951.28443
Overall Steps per Second: 9,284.71008

Timestep Collection Time: 4.56641
Timestep Consumption Time: 0.81965
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 5.38606

Cumulative Model Updates: 4,289
Cumulative Timesteps: 71,623,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 71623024...
Checkpoint 71623024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.99421
Policy Entropy: 1.17262
Value Function Loss: 5.17762

Mean KL Divergence: 0.02673
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.04026
Value Function Update Magnitude: 0.07479

Collected Steps per Second: 10,552.17010
Overall Steps per Second: 8,850.26853

Timestep Collection Time: 4.73931
Timestep Consumption Time: 0.91137
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 5.65068

Cumulative Model Updates: 4,292
Cumulative Timesteps: 71,673,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.20460
Policy Entropy: 1.16118
Value Function Loss: 5.10951

Mean KL Divergence: 0.03076
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.09101

Collected Steps per Second: 10,633.82551
Overall Steps per Second: 8,994.07312

Timestep Collection Time: 4.70216
Timestep Consumption Time: 0.85727
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 5.55944

Cumulative Model Updates: 4,295
Cumulative Timesteps: 71,723,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 71723036...
Checkpoint 71723036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.22727
Policy Entropy: 1.16332
Value Function Loss: 5.14786

Mean KL Divergence: 0.02549
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.04189
Value Function Update Magnitude: 0.08249

Collected Steps per Second: 10,666.76404
Overall Steps per Second: 9,038.94179

Timestep Collection Time: 4.68839
Timestep Consumption Time: 0.84433
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 5.53273

Cumulative Model Updates: 4,298
Cumulative Timesteps: 71,773,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.19019
Policy Entropy: 1.14204
Value Function Loss: 5.44070

Mean KL Divergence: 0.02993
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.07614

Collected Steps per Second: 10,906.51404
Overall Steps per Second: 9,245.34579

Timestep Collection Time: 4.58625
Timestep Consumption Time: 0.82404
PPO Batch Consumption Time: 0.04562
Total Iteration Time: 5.41029

Cumulative Model Updates: 4,301
Cumulative Timesteps: 71,823,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 71823066...
Checkpoint 71823066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.88631
Policy Entropy: 1.15186
Value Function Loss: 5.62410

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.03936
Value Function Update Magnitude: 0.08259

Collected Steps per Second: 10,602.57150
Overall Steps per Second: 9,157.04029

Timestep Collection Time: 4.71810
Timestep Consumption Time: 0.74480
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 5.46290

Cumulative Model Updates: 4,304
Cumulative Timesteps: 71,873,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.35472
Policy Entropy: 1.13897
Value Function Loss: 5.27591

Mean KL Divergence: 0.03166
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.04023
Value Function Update Magnitude: 0.07868

Collected Steps per Second: 10,846.67931
Overall Steps per Second: 9,222.65360

Timestep Collection Time: 4.61210
Timestep Consumption Time: 0.81215
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.42425

Cumulative Model Updates: 4,307
Cumulative Timesteps: 71,923,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 71923116...
Checkpoint 71923116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.02144
Policy Entropy: 1.15534
Value Function Loss: 5.11665

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.03958
Value Function Update Magnitude: 0.06708

Collected Steps per Second: 10,647.27286
Overall Steps per Second: 9,195.36596

Timestep Collection Time: 4.69923
Timestep Consumption Time: 0.74199
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 5.44122

Cumulative Model Updates: 4,310
Cumulative Timesteps: 71,973,150

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.03390
Policy Entropy: 1.13845
Value Function Loss: 4.93526

Mean KL Divergence: 0.03349
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.04170
Value Function Update Magnitude: 0.06082

Collected Steps per Second: 10,122.66023
Overall Steps per Second: 8,613.71637

Timestep Collection Time: 4.93981
Timestep Consumption Time: 0.86535
PPO Batch Consumption Time: 0.04533
Total Iteration Time: 5.80516

Cumulative Model Updates: 4,313
Cumulative Timesteps: 72,023,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 72023154...
Checkpoint 72023154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.72963
Policy Entropy: 1.15923
Value Function Loss: 5.09043

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.05513

Collected Steps per Second: 10,311.75019
Overall Steps per Second: 8,730.80559

Timestep Collection Time: 4.84884
Timestep Consumption Time: 0.87801
PPO Batch Consumption Time: 0.04563
Total Iteration Time: 5.72685

Cumulative Model Updates: 4,316
Cumulative Timesteps: 72,073,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.99882
Policy Entropy: 1.15396
Value Function Loss: 4.95581

Mean KL Divergence: 0.03455
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 10,821.97458
Overall Steps per Second: 9,152.23122

Timestep Collection Time: 4.62171
Timestep Consumption Time: 0.84319
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 5.46490

Cumulative Model Updates: 4,319
Cumulative Timesteps: 72,123,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 72123170...
Checkpoint 72123170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.52180
Policy Entropy: 1.16765
Value Function Loss: 5.01320

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.04296
Value Function Update Magnitude: 0.07309

Collected Steps per Second: 10,795.98891
Overall Steps per Second: 9,106.44406

Timestep Collection Time: 4.63376
Timestep Consumption Time: 0.85971
PPO Batch Consumption Time: 0.03887
Total Iteration Time: 5.49347

Cumulative Model Updates: 4,322
Cumulative Timesteps: 72,173,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.30181
Policy Entropy: 1.15100
Value Function Loss: 5.07795

Mean KL Divergence: 0.03226
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.04073
Value Function Update Magnitude: 0.09565

Collected Steps per Second: 10,825.09526
Overall Steps per Second: 9,296.83231

Timestep Collection Time: 4.62056
Timestep Consumption Time: 0.75955
PPO Batch Consumption Time: 0.03900
Total Iteration Time: 5.38011

Cumulative Model Updates: 4,325
Cumulative Timesteps: 72,223,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 72223214...
Checkpoint 72223214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.55567
Policy Entropy: 1.15933
Value Function Loss: 5.16625

Mean KL Divergence: 0.02585
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.03804
Value Function Update Magnitude: 0.09643

Collected Steps per Second: 10,288.92323
Overall Steps per Second: 8,771.81447

Timestep Collection Time: 4.86212
Timestep Consumption Time: 0.84092
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 5.70304

Cumulative Model Updates: 4,328
Cumulative Timesteps: 72,273,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.11611
Policy Entropy: 1.14865
Value Function Loss: 5.27076

Mean KL Divergence: 0.03275
SB3 Clip Fraction: 0.14345
Policy Update Magnitude: 0.03739
Value Function Update Magnitude: 0.09088

Collected Steps per Second: 10,474.48947
Overall Steps per Second: 8,876.65897

Timestep Collection Time: 4.77522
Timestep Consumption Time: 0.85956
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 5.63478

Cumulative Model Updates: 4,331
Cumulative Timesteps: 72,323,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 72323258...
Checkpoint 72323258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.35522
Policy Entropy: 1.16575
Value Function Loss: 5.04300

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.03636
Value Function Update Magnitude: 0.09102

Collected Steps per Second: 10,801.63718
Overall Steps per Second: 9,089.29350

Timestep Collection Time: 4.63078
Timestep Consumption Time: 0.87240
PPO Batch Consumption Time: 0.04696
Total Iteration Time: 5.50318

Cumulative Model Updates: 4,334
Cumulative Timesteps: 72,373,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.39567
Policy Entropy: 1.14728
Value Function Loss: 5.15926

Mean KL Divergence: 0.03419
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.03456
Value Function Update Magnitude: 0.07529

Collected Steps per Second: 10,703.88970
Overall Steps per Second: 9,015.29062

Timestep Collection Time: 4.67157
Timestep Consumption Time: 0.87500
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 5.54658

Cumulative Model Updates: 4,337
Cumulative Timesteps: 72,423,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 72423282...
Checkpoint 72423282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.84796
Policy Entropy: 1.16377
Value Function Loss: 5.14088

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.03347
Value Function Update Magnitude: 0.06298

Collected Steps per Second: 11,064.41554
Overall Steps per Second: 9,457.85118

Timestep Collection Time: 4.51953
Timestep Consumption Time: 0.76771
PPO Batch Consumption Time: 0.04338
Total Iteration Time: 5.28725

Cumulative Model Updates: 4,340
Cumulative Timesteps: 72,473,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.12680
Policy Entropy: 1.14292
Value Function Loss: 5.07747

Mean KL Divergence: 0.03071
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.03157
Value Function Update Magnitude: 0.05350

Collected Steps per Second: 10,977.13997
Overall Steps per Second: 9,171.50040

Timestep Collection Time: 4.55547
Timestep Consumption Time: 0.89686
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.45232

Cumulative Model Updates: 4,343
Cumulative Timesteps: 72,523,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 72523294...
Checkpoint 72523294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.80770
Policy Entropy: 1.15370
Value Function Loss: 5.15006

Mean KL Divergence: 0.02707
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.03439
Value Function Update Magnitude: 0.05109

Collected Steps per Second: 10,513.54984
Overall Steps per Second: 8,990.38420

Timestep Collection Time: 4.75805
Timestep Consumption Time: 0.80612
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 5.56417

Cumulative Model Updates: 4,346
Cumulative Timesteps: 72,573,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.70832
Policy Entropy: 1.13198
Value Function Loss: 5.20622

Mean KL Divergence: 0.03352
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.03810
Value Function Update Magnitude: 0.04679

Collected Steps per Second: 11,095.33527
Overall Steps per Second: 9,343.23958

Timestep Collection Time: 4.50640
Timestep Consumption Time: 0.84506
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 5.35146

Cumulative Model Updates: 4,349
Cumulative Timesteps: 72,623,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 72623318...
Checkpoint 72623318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.08130
Policy Entropy: 1.14936
Value Function Loss: 5.34263

Mean KL Divergence: 0.02421
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.03696
Value Function Update Magnitude: 0.04327

Collected Steps per Second: 11,188.19514
Overall Steps per Second: 9,423.81888

Timestep Collection Time: 4.46971
Timestep Consumption Time: 0.83684
PPO Batch Consumption Time: 0.03959
Total Iteration Time: 5.30655

Cumulative Model Updates: 4,352
Cumulative Timesteps: 72,673,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.64828
Policy Entropy: 1.14311
Value Function Loss: 5.25539

Mean KL Divergence: 0.03187
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.03792
Value Function Update Magnitude: 0.03984

Collected Steps per Second: 10,873.07185
Overall Steps per Second: 9,316.27315

Timestep Collection Time: 4.60091
Timestep Consumption Time: 0.76884
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 5.36974

Cumulative Model Updates: 4,355
Cumulative Timesteps: 72,723,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 72723352...
Checkpoint 72723352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.14769
Policy Entropy: 1.15805
Value Function Loss: 5.13832

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.03758
Value Function Update Magnitude: 0.03399

Collected Steps per Second: 10,562.38100
Overall Steps per Second: 8,990.65087

Timestep Collection Time: 4.73511
Timestep Consumption Time: 0.82778
PPO Batch Consumption Time: 0.03918
Total Iteration Time: 5.56289

Cumulative Model Updates: 4,358
Cumulative Timesteps: 72,773,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.77200
Policy Entropy: 1.13108
Value Function Loss: 5.37057

Mean KL Divergence: 0.03237
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.04140
Value Function Update Magnitude: 0.03500

Collected Steps per Second: 10,232.79098
Overall Steps per Second: 8,913.05458

Timestep Collection Time: 4.88645
Timestep Consumption Time: 0.72353
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.60997

Cumulative Model Updates: 4,361
Cumulative Timesteps: 72,823,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 72823368...
Checkpoint 72823368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.86956
Policy Entropy: 1.13984
Value Function Loss: 5.59513

Mean KL Divergence: 0.02664
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.03893
Value Function Update Magnitude: 0.03582

Collected Steps per Second: 10,758.30938
Overall Steps per Second: 9,087.33098

Timestep Collection Time: 4.64906
Timestep Consumption Time: 0.85487
PPO Batch Consumption Time: 0.04836
Total Iteration Time: 5.50393

Cumulative Model Updates: 4,364
Cumulative Timesteps: 72,873,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.55955
Policy Entropy: 1.12042
Value Function Loss: 5.70719

Mean KL Divergence: 0.03410
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.03910
Value Function Update Magnitude: 0.03734

Collected Steps per Second: 10,720.60592
Overall Steps per Second: 9,149.25116

Timestep Collection Time: 4.66559
Timestep Consumption Time: 0.80130
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 5.46690

Cumulative Model Updates: 4,367
Cumulative Timesteps: 72,923,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 72923402...
Checkpoint 72923402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.46130
Policy Entropy: 1.14950
Value Function Loss: 5.58003

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.03983
Value Function Update Magnitude: 0.03713

Collected Steps per Second: 10,750.65519
Overall Steps per Second: 9,256.46146

Timestep Collection Time: 4.65125
Timestep Consumption Time: 0.75081
PPO Batch Consumption Time: 0.04144
Total Iteration Time: 5.40206

Cumulative Model Updates: 4,370
Cumulative Timesteps: 72,973,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.42509
Policy Entropy: 1.12652
Value Function Loss: 5.54902

Mean KL Divergence: 0.03510
SB3 Clip Fraction: 0.15273
Policy Update Magnitude: 0.03743
Value Function Update Magnitude: 0.03745

Collected Steps per Second: 10,768.09614
Overall Steps per Second: 9,108.39209

Timestep Collection Time: 4.64576
Timestep Consumption Time: 0.84654
PPO Batch Consumption Time: 0.04693
Total Iteration Time: 5.49230

Cumulative Model Updates: 4,373
Cumulative Timesteps: 73,023,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 73023432...
Checkpoint 73023432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.73770
Policy Entropy: 1.14945
Value Function Loss: 5.45805

Mean KL Divergence: 0.02542
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.03638
Value Function Update Magnitude: 0.05079

Collected Steps per Second: 10,416.02330
Overall Steps per Second: 9,007.15249

Timestep Collection Time: 4.80222
Timestep Consumption Time: 0.75115
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 5.55336

Cumulative Model Updates: 4,376
Cumulative Timesteps: 73,073,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.19075
Policy Entropy: 1.12361
Value Function Loss: 5.55674

Mean KL Divergence: 0.03079
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.03809
Value Function Update Magnitude: 0.05684

Collected Steps per Second: 10,240.15297
Overall Steps per Second: 8,741.13681

Timestep Collection Time: 4.88352
Timestep Consumption Time: 0.83747
PPO Batch Consumption Time: 0.03916
Total Iteration Time: 5.72100

Cumulative Model Updates: 4,379
Cumulative Timesteps: 73,123,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 73123460...
Checkpoint 73123460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.16257
Policy Entropy: 1.15234
Value Function Loss: 5.50250

Mean KL Divergence: 0.03028
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.04011
Value Function Update Magnitude: 0.05244

Collected Steps per Second: 10,544.52263
Overall Steps per Second: 9,022.35192

Timestep Collection Time: 4.74483
Timestep Consumption Time: 0.80051
PPO Batch Consumption Time: 0.04469
Total Iteration Time: 5.54534

Cumulative Model Updates: 4,382
Cumulative Timesteps: 73,173,492

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.39111
Policy Entropy: 1.13515
Value Function Loss: 5.55825

Mean KL Divergence: 0.02934
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.03876
Value Function Update Magnitude: 0.06058

Collected Steps per Second: 10,750.02782
Overall Steps per Second: 9,121.70430

Timestep Collection Time: 4.65376
Timestep Consumption Time: 0.83075
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 5.48450

Cumulative Model Updates: 4,385
Cumulative Timesteps: 73,223,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 73223520...
Checkpoint 73223520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.02718
Policy Entropy: 1.15881
Value Function Loss: 5.37357

Mean KL Divergence: 0.03508
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.04106
Value Function Update Magnitude: 0.06079

Collected Steps per Second: 10,670.19655
Overall Steps per Second: 9,089.99609

Timestep Collection Time: 4.68745
Timestep Consumption Time: 0.81486
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.50231

Cumulative Model Updates: 4,388
Cumulative Timesteps: 73,273,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.15659
Policy Entropy: 1.13885
Value Function Loss: 5.29742

Mean KL Divergence: 0.02840
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.03638
Value Function Update Magnitude: 0.07867

Collected Steps per Second: 10,643.13756
Overall Steps per Second: 9,201.32083

Timestep Collection Time: 4.70049
Timestep Consumption Time: 0.73655
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 5.43705

Cumulative Model Updates: 4,391
Cumulative Timesteps: 73,323,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 73323564...
Checkpoint 73323564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.65130
Policy Entropy: 1.16212
Value Function Loss: 5.40632

Mean KL Divergence: 0.02873
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.07575

Collected Steps per Second: 10,109.68380
Overall Steps per Second: 8,665.61335

Timestep Collection Time: 4.94773
Timestep Consumption Time: 0.82451
PPO Batch Consumption Time: 0.04752
Total Iteration Time: 5.77224

Cumulative Model Updates: 4,394
Cumulative Timesteps: 73,373,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.93273
Policy Entropy: 1.13806
Value Function Loss: 5.45553

Mean KL Divergence: 0.04587
SB3 Clip Fraction: 0.16556
Policy Update Magnitude: 0.04104
Value Function Update Magnitude: 0.09326

Collected Steps per Second: 10,719.05053
Overall Steps per Second: 9,167.30441

Timestep Collection Time: 4.66515
Timestep Consumption Time: 0.78967
PPO Batch Consumption Time: 0.04704
Total Iteration Time: 5.45482

Cumulative Model Updates: 4,397
Cumulative Timesteps: 73,423,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 73423590...
Checkpoint 73423590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.00564
Policy Entropy: 1.15468
Value Function Loss: 5.48926

Mean KL Divergence: 0.02455
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.03458
Value Function Update Magnitude: 0.10341

Collected Steps per Second: 10,882.78991
Overall Steps per Second: 9,212.82848

Timestep Collection Time: 4.59606
Timestep Consumption Time: 0.83310
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 5.42917

Cumulative Model Updates: 4,400
Cumulative Timesteps: 73,473,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.05840
Policy Entropy: 1.11923
Value Function Loss: 5.38977

Mean KL Divergence: 0.04096
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.04299
Value Function Update Magnitude: 0.09613

Collected Steps per Second: 10,595.11594
Overall Steps per Second: 8,905.18560

Timestep Collection Time: 4.71934
Timestep Consumption Time: 0.89559
PPO Batch Consumption Time: 0.04357
Total Iteration Time: 5.61493

Cumulative Model Updates: 4,403
Cumulative Timesteps: 73,523,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 73523610...
Checkpoint 73523610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.44874
Policy Entropy: 1.13680
Value Function Loss: 5.38590

Mean KL Divergence: 0.02676
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.03873
Value Function Update Magnitude: 0.08118

Collected Steps per Second: 10,547.02548
Overall Steps per Second: 9,101.35053

Timestep Collection Time: 4.74276
Timestep Consumption Time: 0.75335
PPO Batch Consumption Time: 0.04676
Total Iteration Time: 5.49611

Cumulative Model Updates: 4,406
Cumulative Timesteps: 73,573,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.25483
Policy Entropy: 1.12274
Value Function Loss: 5.35639

Mean KL Divergence: 0.03435
SB3 Clip Fraction: 0.15833
Policy Update Magnitude: 0.03686
Value Function Update Magnitude: 0.08019

Collected Steps per Second: 10,686.78573
Overall Steps per Second: 8,946.40955

Timestep Collection Time: 4.67924
Timestep Consumption Time: 0.91027
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 5.58950

Cumulative Model Updates: 4,409
Cumulative Timesteps: 73,623,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 73623638...
Checkpoint 73623638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.92425
Policy Entropy: 1.15820
Value Function Loss: 5.52530

Mean KL Divergence: 0.02816
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.03940
Value Function Update Magnitude: 0.06228

Collected Steps per Second: 11,050.29350
Overall Steps per Second: 9,425.83262

Timestep Collection Time: 4.52658
Timestep Consumption Time: 0.78012
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.30669

Cumulative Model Updates: 4,412
Cumulative Timesteps: 73,673,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.76702
Policy Entropy: 1.13551
Value Function Loss: 5.66857

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.03665
Value Function Update Magnitude: 0.05554

Collected Steps per Second: 10,947.25472
Overall Steps per Second: 9,231.60195

Timestep Collection Time: 4.56827
Timestep Consumption Time: 0.84899
PPO Batch Consumption Time: 0.04587
Total Iteration Time: 5.41726

Cumulative Model Updates: 4,415
Cumulative Timesteps: 73,723,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 73723668...
Checkpoint 73723668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.57299
Policy Entropy: 1.15269
Value Function Loss: 5.74987

Mean KL Divergence: 0.02796
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.04009
Value Function Update Magnitude: 0.04636

Collected Steps per Second: 10,899.29065
Overall Steps per Second: 9,169.96470

Timestep Collection Time: 4.58782
Timestep Consumption Time: 0.86520
PPO Batch Consumption Time: 0.04585
Total Iteration Time: 5.45302

Cumulative Model Updates: 4,418
Cumulative Timesteps: 73,773,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.73674
Policy Entropy: 1.12757
Value Function Loss: 5.61515

Mean KL Divergence: 0.03201
SB3 Clip Fraction: 0.15293
Policy Update Magnitude: 0.03833
Value Function Update Magnitude: 0.05939

Collected Steps per Second: 11,147.78261
Overall Steps per Second: 9,435.30280

Timestep Collection Time: 4.48753
Timestep Consumption Time: 0.81447
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.30200

Cumulative Model Updates: 4,421
Cumulative Timesteps: 73,823,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 73823698...
Checkpoint 73823698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.40888
Policy Entropy: 1.14577
Value Function Loss: 5.44227

Mean KL Divergence: 0.02548
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.03738
Value Function Update Magnitude: 0.05471

Collected Steps per Second: 10,738.45544
Overall Steps per Second: 9,108.42634

Timestep Collection Time: 4.65896
Timestep Consumption Time: 0.83376
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.49272

Cumulative Model Updates: 4,424
Cumulative Timesteps: 73,873,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.47391
Policy Entropy: 1.11883
Value Function Loss: 5.47122

Mean KL Divergence: 0.03374
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.04009
Value Function Update Magnitude: 0.05100

Collected Steps per Second: 10,189.19114
Overall Steps per Second: 8,815.36362

Timestep Collection Time: 4.90952
Timestep Consumption Time: 0.76512
PPO Batch Consumption Time: 0.04182
Total Iteration Time: 5.67464

Cumulative Model Updates: 4,427
Cumulative Timesteps: 73,923,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 73923752...
Checkpoint 73923752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.49508
Policy Entropy: 1.14487
Value Function Loss: 5.40159

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.04126
Value Function Update Magnitude: 0.06923

Collected Steps per Second: 10,599.16392
Overall Steps per Second: 8,835.75991

Timestep Collection Time: 4.71792
Timestep Consumption Time: 0.94158
PPO Batch Consumption Time: 0.04669
Total Iteration Time: 5.65950

Cumulative Model Updates: 4,430
Cumulative Timesteps: 73,973,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.47619
Policy Entropy: 1.13525
Value Function Loss: 5.32655

Mean KL Divergence: 0.03263
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.06713

Collected Steps per Second: 10,488.81827
Overall Steps per Second: 8,850.19612

Timestep Collection Time: 4.76832
Timestep Consumption Time: 0.88286
PPO Batch Consumption Time: 0.04608
Total Iteration Time: 5.65117

Cumulative Model Updates: 4,433
Cumulative Timesteps: 74,023,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 74023772...
Checkpoint 74023772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.38861
Policy Entropy: 1.15769
Value Function Loss: 5.31334

Mean KL Divergence: 0.02639
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.04007
Value Function Update Magnitude: 0.05998

Collected Steps per Second: 10,827.54570
Overall Steps per Second: 9,101.66325

Timestep Collection Time: 4.61822
Timestep Consumption Time: 0.87572
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 5.49394

Cumulative Model Updates: 4,436
Cumulative Timesteps: 74,073,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.02689
Policy Entropy: 1.13041
Value Function Loss: 5.22915

Mean KL Divergence: 0.03440
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.03970
Value Function Update Magnitude: 0.06750

Collected Steps per Second: 10,712.03116
Overall Steps per Second: 9,017.20197

Timestep Collection Time: 4.66896
Timestep Consumption Time: 0.87755
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.54651

Cumulative Model Updates: 4,439
Cumulative Timesteps: 74,123,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 74123790...
Checkpoint 74123790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.29524
Policy Entropy: 1.15283
Value Function Loss: 5.58144

Mean KL Divergence: 0.02556
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.03786
Value Function Update Magnitude: 0.06513

Collected Steps per Second: 10,369.41604
Overall Steps per Second: 8,894.62107

Timestep Collection Time: 4.82419
Timestep Consumption Time: 0.79989
PPO Batch Consumption Time: 0.04151
Total Iteration Time: 5.62407

Cumulative Model Updates: 4,442
Cumulative Timesteps: 74,173,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.71726
Policy Entropy: 1.14159
Value Function Loss: 5.52907

Mean KL Divergence: 0.03015
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 10,629.80285
Overall Steps per Second: 9,020.34441

Timestep Collection Time: 4.70376
Timestep Consumption Time: 0.83927
PPO Batch Consumption Time: 0.03963
Total Iteration Time: 5.54303

Cumulative Model Updates: 4,445
Cumulative Timesteps: 74,223,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 74223814...
Checkpoint 74223814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.18996
Policy Entropy: 1.16044
Value Function Loss: 5.61360

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.04036
Value Function Update Magnitude: 0.06439

Collected Steps per Second: 10,658.10449
Overall Steps per Second: 9,022.61826

Timestep Collection Time: 4.69164
Timestep Consumption Time: 0.85043
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 5.54207

Cumulative Model Updates: 4,448
Cumulative Timesteps: 74,273,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.59859
Policy Entropy: 1.13672
Value Function Loss: 5.31048

Mean KL Divergence: 0.03199
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 10,788.70752
Overall Steps per Second: 9,278.86567

Timestep Collection Time: 4.63744
Timestep Consumption Time: 0.75460
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.39204

Cumulative Model Updates: 4,451
Cumulative Timesteps: 74,323,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 74323850...
Checkpoint 74323850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.45219
Policy Entropy: 1.14211
Value Function Loss: 5.24731

Mean KL Divergence: 0.02619
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.03751
Value Function Update Magnitude: 0.08252

Collected Steps per Second: 10,406.09049
Overall Steps per Second: 8,765.83794

Timestep Collection Time: 4.80699
Timestep Consumption Time: 0.89948
PPO Batch Consumption Time: 0.03932
Total Iteration Time: 5.70647

Cumulative Model Updates: 4,454
Cumulative Timesteps: 74,373,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.21696
Policy Entropy: 1.12693
Value Function Loss: 5.31783

Mean KL Divergence: 0.02910
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.03751
Value Function Update Magnitude: 0.08859

Collected Steps per Second: 10,932.14541
Overall Steps per Second: 9,399.99764

Timestep Collection Time: 4.57458
Timestep Consumption Time: 0.74563
PPO Batch Consumption Time: 0.03923
Total Iteration Time: 5.32021

Cumulative Model Updates: 4,457
Cumulative Timesteps: 74,423,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 74423882...
Checkpoint 74423882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.95844
Policy Entropy: 1.13371
Value Function Loss: 5.33596

Mean KL Divergence: 0.02856
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.04646
Value Function Update Magnitude: 0.07136

Collected Steps per Second: 10,054.12801
Overall Steps per Second: 8,646.94312

Timestep Collection Time: 4.97308
Timestep Consumption Time: 0.80931
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.78239

Cumulative Model Updates: 4,460
Cumulative Timesteps: 74,473,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.22924
Policy Entropy: 1.11491
Value Function Loss: 5.52552

Mean KL Divergence: 0.02827
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.04139
Value Function Update Magnitude: 0.05744

Collected Steps per Second: 10,741.73734
Overall Steps per Second: 9,157.25015

Timestep Collection Time: 4.65679
Timestep Consumption Time: 0.80577
PPO Batch Consumption Time: 0.04042
Total Iteration Time: 5.46256

Cumulative Model Updates: 4,463
Cumulative Timesteps: 74,523,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 74523904...
Checkpoint 74523904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.59689
Policy Entropy: 1.13232
Value Function Loss: 5.31044

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.04032
Value Function Update Magnitude: 0.04748

Collected Steps per Second: 10,943.77552
Overall Steps per Second: 9,149.71929

Timestep Collection Time: 4.57173
Timestep Consumption Time: 0.89641
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 5.46815

Cumulative Model Updates: 4,466
Cumulative Timesteps: 74,573,936

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.59604
Policy Entropy: 1.12303
Value Function Loss: 5.47847

Mean KL Divergence: 0.03013
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.04419

Collected Steps per Second: 10,590.25078
Overall Steps per Second: 8,950.35742

Timestep Collection Time: 4.72378
Timestep Consumption Time: 0.86550
PPO Batch Consumption Time: 0.04583
Total Iteration Time: 5.58927

Cumulative Model Updates: 4,469
Cumulative Timesteps: 74,623,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 74623962...
Checkpoint 74623962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.21546
Policy Entropy: 1.15470
Value Function Loss: 5.34504

Mean KL Divergence: 0.03053
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.05252

Collected Steps per Second: 10,772.75515
Overall Steps per Second: 9,280.78914

Timestep Collection Time: 4.64134
Timestep Consumption Time: 0.74613
PPO Batch Consumption Time: 0.04016
Total Iteration Time: 5.38747

Cumulative Model Updates: 4,472
Cumulative Timesteps: 74,673,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.39746
Policy Entropy: 1.13426
Value Function Loss: 5.60616

Mean KL Divergence: 0.02933
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.04188
Value Function Update Magnitude: 0.06737

Collected Steps per Second: 9,985.12413
Overall Steps per Second: 8,449.08564

Timestep Collection Time: 5.00885
Timestep Consumption Time: 0.91061
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 5.91946

Cumulative Model Updates: 4,475
Cumulative Timesteps: 74,723,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 74723976...
Checkpoint 74723976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.35360
Policy Entropy: 1.16236
Value Function Loss: 5.36285

Mean KL Divergence: 0.02851
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.06919

Collected Steps per Second: 9,388.31632
Overall Steps per Second: 8,040.72579

Timestep Collection Time: 5.32875
Timestep Consumption Time: 0.89308
PPO Batch Consumption Time: 0.04211
Total Iteration Time: 6.22183

Cumulative Model Updates: 4,478
Cumulative Timesteps: 74,774,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.87465
Policy Entropy: 1.13901
Value Function Loss: 5.46794

Mean KL Divergence: 0.02525
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.03809
Value Function Update Magnitude: 0.05575

Collected Steps per Second: 10,106.39118
Overall Steps per Second: 8,761.19134

Timestep Collection Time: 4.94756
Timestep Consumption Time: 0.75965
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 5.70721

Cumulative Model Updates: 4,481
Cumulative Timesteps: 74,824,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 74824006...
Checkpoint 74824006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.29488
Policy Entropy: 1.16467
Value Function Loss: 5.29764

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.05074

Collected Steps per Second: 10,458.10477
Overall Steps per Second: 8,816.19263

Timestep Collection Time: 4.78155
Timestep Consumption Time: 0.89051
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 5.67206

Cumulative Model Updates: 4,484
Cumulative Timesteps: 74,874,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.10500
Policy Entropy: 1.14725
Value Function Loss: 5.25482

Mean KL Divergence: 0.02760
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.05260

Collected Steps per Second: 10,290.67316
Overall Steps per Second: 8,898.50790

Timestep Collection Time: 4.86168
Timestep Consumption Time: 0.76061
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 5.62229

Cumulative Model Updates: 4,487
Cumulative Timesteps: 74,924,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 74924042...
Checkpoint 74924042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.60519
Policy Entropy: 1.16948
Value Function Loss: 5.14374

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.04099
Value Function Update Magnitude: 0.05744

Collected Steps per Second: 9,646.75486
Overall Steps per Second: 8,199.26627

Timestep Collection Time: 5.18537
Timestep Consumption Time: 0.91542
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 6.10079

Cumulative Model Updates: 4,490
Cumulative Timesteps: 74,974,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.33426
Policy Entropy: 1.14740
Value Function Loss: 5.28421

Mean KL Divergence: 0.02966
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.04290
Value Function Update Magnitude: 0.05399

Collected Steps per Second: 10,459.39809
Overall Steps per Second: 8,958.01271

Timestep Collection Time: 4.78154
Timestep Consumption Time: 0.80140
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 5.58293

Cumulative Model Updates: 4,493
Cumulative Timesteps: 75,024,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 75024076...
Checkpoint 75024076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.18694
Policy Entropy: 1.15769
Value Function Loss: 5.39825

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.04831

Collected Steps per Second: 10,596.04186
Overall Steps per Second: 8,997.23605

Timestep Collection Time: 4.72120
Timestep Consumption Time: 0.83896
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 5.56015

Cumulative Model Updates: 4,496
Cumulative Timesteps: 75,074,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.23238
Policy Entropy: 1.13497
Value Function Loss: 5.60082

Mean KL Divergence: 0.03027
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.04067
Value Function Update Magnitude: 0.04977

Collected Steps per Second: 10,543.99731
Overall Steps per Second: 8,972.56070

Timestep Collection Time: 4.74298
Timestep Consumption Time: 0.83068
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 5.57366

Cumulative Model Updates: 4,499
Cumulative Timesteps: 75,124,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 75124112...
Checkpoint 75124112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.61403
Policy Entropy: 1.15182
Value Function Loss: 5.46063

Mean KL Divergence: 0.02661
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.04004
Value Function Update Magnitude: 0.06355

Collected Steps per Second: 10,629.29801
Overall Steps per Second: 9,146.89217

Timestep Collection Time: 4.70492
Timestep Consumption Time: 0.76251
PPO Batch Consumption Time: 0.04161
Total Iteration Time: 5.46743

Cumulative Model Updates: 4,502
Cumulative Timesteps: 75,174,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.05851
Policy Entropy: 1.14282
Value Function Loss: 5.40801

Mean KL Divergence: 0.02664
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.05992

Collected Steps per Second: 10,517.29929
Overall Steps per Second: 8,881.38995

Timestep Collection Time: 4.75654
Timestep Consumption Time: 0.87613
PPO Batch Consumption Time: 0.04667
Total Iteration Time: 5.63268

Cumulative Model Updates: 4,505
Cumulative Timesteps: 75,224,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 75224148...
Checkpoint 75224148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.49978
Policy Entropy: 1.16582
Value Function Loss: 5.38872

Mean KL Divergence: 0.02393
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.06769

Collected Steps per Second: 10,539.36615
Overall Steps per Second: 8,948.76872

Timestep Collection Time: 4.74583
Timestep Consumption Time: 0.84355
PPO Batch Consumption Time: 0.04745
Total Iteration Time: 5.58937

Cumulative Model Updates: 4,508
Cumulative Timesteps: 75,274,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.67678
Policy Entropy: 1.14869
Value Function Loss: 5.49465

Mean KL Divergence: 0.02876
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.06167

Collected Steps per Second: 10,830.35899
Overall Steps per Second: 9,175.95180

Timestep Collection Time: 4.61905
Timestep Consumption Time: 0.83281
PPO Batch Consumption Time: 0.04485
Total Iteration Time: 5.45186

Cumulative Model Updates: 4,511
Cumulative Timesteps: 75,324,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 75324192...
Checkpoint 75324192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.37723
Policy Entropy: 1.16607
Value Function Loss: 5.42314

Mean KL Divergence: 0.02734
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.05811

Collected Steps per Second: 10,665.15430
Overall Steps per Second: 8,938.43816

Timestep Collection Time: 4.69023
Timestep Consumption Time: 0.90605
PPO Batch Consumption Time: 0.04655
Total Iteration Time: 5.59628

Cumulative Model Updates: 4,514
Cumulative Timesteps: 75,374,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.22673
Policy Entropy: 1.14384
Value Function Loss: 5.37015

Mean KL Divergence: 0.03711
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.04810

Collected Steps per Second: 10,783.99329
Overall Steps per Second: 9,328.40362

Timestep Collection Time: 4.63743
Timestep Consumption Time: 0.72362
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 5.36105

Cumulative Model Updates: 4,517
Cumulative Timesteps: 75,424,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 75424224...
Checkpoint 75424224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.56477
Policy Entropy: 1.15851
Value Function Loss: 5.32943

Mean KL Divergence: 0.02973
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.04194
Value Function Update Magnitude: 0.03913

Collected Steps per Second: 10,756.49654
Overall Steps per Second: 9,072.58523

Timestep Collection Time: 4.65077
Timestep Consumption Time: 0.86320
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 5.51397

Cumulative Model Updates: 4,520
Cumulative Timesteps: 75,474,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.84336
Policy Entropy: 1.13486
Value Function Loss: 5.53399

Mean KL Divergence: 0.03305
SB3 Clip Fraction: 0.15048
Policy Update Magnitude: 0.04076
Value Function Update Magnitude: 0.04290

Collected Steps per Second: 10,078.59421
Overall Steps per Second: 8,725.21606

Timestep Collection Time: 4.96180
Timestep Consumption Time: 0.76963
PPO Batch Consumption Time: 0.04626
Total Iteration Time: 5.73143

Cumulative Model Updates: 4,523
Cumulative Timesteps: 75,524,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 75524258...
Checkpoint 75524258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.49355
Policy Entropy: 1.15536
Value Function Loss: 5.32506

Mean KL Divergence: 0.02733
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.04289

Collected Steps per Second: 10,656.67247
Overall Steps per Second: 8,965.46833

Timestep Collection Time: 4.69190
Timestep Consumption Time: 0.88506
PPO Batch Consumption Time: 0.04560
Total Iteration Time: 5.57695

Cumulative Model Updates: 4,526
Cumulative Timesteps: 75,574,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.15298
Policy Entropy: 1.14098
Value Function Loss: 5.22506

Mean KL Divergence: 0.03698
SB3 Clip Fraction: 0.15139
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.03961

Collected Steps per Second: 10,666.23116
Overall Steps per Second: 9,071.96215

Timestep Collection Time: 4.68788
Timestep Consumption Time: 0.82383
PPO Batch Consumption Time: 0.04830
Total Iteration Time: 5.51171

Cumulative Model Updates: 4,529
Cumulative Timesteps: 75,624,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 75624260...
Checkpoint 75624260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.65652
Policy Entropy: 1.16206
Value Function Loss: 5.19815

Mean KL Divergence: 0.02553
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.04179
Value Function Update Magnitude: 0.04137

Collected Steps per Second: 10,938.83476
Overall Steps per Second: 9,285.18383

Timestep Collection Time: 4.57105
Timestep Consumption Time: 0.81408
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.38514

Cumulative Model Updates: 4,532
Cumulative Timesteps: 75,674,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.98263
Policy Entropy: 1.13568
Value Function Loss: 5.21493

Mean KL Divergence: 0.03917
SB3 Clip Fraction: 0.16428
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.03689

Collected Steps per Second: 10,998.63987
Overall Steps per Second: 9,331.52414

Timestep Collection Time: 4.54802
Timestep Consumption Time: 0.81252
PPO Batch Consumption Time: 0.04161
Total Iteration Time: 5.36054

Cumulative Model Updates: 4,535
Cumulative Timesteps: 75,724,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 75724284...
Checkpoint 75724284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.38825
Policy Entropy: 1.16310
Value Function Loss: 5.29027

Mean KL Divergence: 0.02788
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.03815
Value Function Update Magnitude: 0.03398

Collected Steps per Second: 10,320.63102
Overall Steps per Second: 8,898.64394

Timestep Collection Time: 4.84486
Timestep Consumption Time: 0.77420
PPO Batch Consumption Time: 0.04449
Total Iteration Time: 5.61906

Cumulative Model Updates: 4,538
Cumulative Timesteps: 75,774,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.04679
Policy Entropy: 1.14242
Value Function Loss: 5.27774

Mean KL Divergence: 0.03230
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.03576
Value Function Update Magnitude: 0.03679

Collected Steps per Second: 11,009.32911
Overall Steps per Second: 9,340.58856

Timestep Collection Time: 4.54215
Timestep Consumption Time: 0.81148
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 5.35362

Cumulative Model Updates: 4,541
Cumulative Timesteps: 75,824,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 75824292...
Checkpoint 75824292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.85230
Policy Entropy: 1.16053
Value Function Loss: 5.29164

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.03218
Value Function Update Magnitude: 0.03712

Collected Steps per Second: 10,740.21334
Overall Steps per Second: 9,000.19629

Timestep Collection Time: 4.65764
Timestep Consumption Time: 0.90047
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 5.55810

Cumulative Model Updates: 4,544
Cumulative Timesteps: 75,874,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.08133
Policy Entropy: 1.13643
Value Function Loss: 5.20622

Mean KL Divergence: 0.03341
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.03442
Value Function Update Magnitude: 0.05053

Collected Steps per Second: 10,827.88430
Overall Steps per Second: 9,093.11671

Timestep Collection Time: 4.61845
Timestep Consumption Time: 0.88110
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.49954

Cumulative Model Updates: 4,547
Cumulative Timesteps: 75,924,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 75924324...
Checkpoint 75924324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.92379
Policy Entropy: 1.14576
Value Function Loss: 5.03507

Mean KL Divergence: 0.02603
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.03333
Value Function Update Magnitude: 0.05335

Collected Steps per Second: 10,191.90383
Overall Steps per Second: 8,684.70596

Timestep Collection Time: 4.90605
Timestep Consumption Time: 0.85143
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.75748

Cumulative Model Updates: 4,550
Cumulative Timesteps: 75,974,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.96881
Policy Entropy: 1.13177
Value Function Loss: 5.14143

Mean KL Divergence: 0.03403
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.03783
Value Function Update Magnitude: 0.05371

Collected Steps per Second: 10,695.76373
Overall Steps per Second: 9,175.46139

Timestep Collection Time: 4.67643
Timestep Consumption Time: 0.77485
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 5.45128

Cumulative Model Updates: 4,553
Cumulative Timesteps: 76,024,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 76024344...
Checkpoint 76024344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.72517
Policy Entropy: 1.14217
Value Function Loss: 5.11775

Mean KL Divergence: 0.02719
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.03238
Value Function Update Magnitude: 0.04920

Collected Steps per Second: 10,015.84911
Overall Steps per Second: 8,475.80372

Timestep Collection Time: 4.99309
Timestep Consumption Time: 0.90724
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.90033

Cumulative Model Updates: 4,556
Cumulative Timesteps: 76,074,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.20481
Policy Entropy: 1.13883
Value Function Loss: 5.41745

Mean KL Divergence: 0.02652
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.03388
Value Function Update Magnitude: 0.05140

Collected Steps per Second: 10,658.82999
Overall Steps per Second: 8,985.01969

Timestep Collection Time: 4.69301
Timestep Consumption Time: 0.87426
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 5.56727

Cumulative Model Updates: 4,559
Cumulative Timesteps: 76,124,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 76124376...
Checkpoint 76124376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.52238
Policy Entropy: 1.15413
Value Function Loss: 5.50105

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.03898
Value Function Update Magnitude: 0.07526

Collected Steps per Second: 10,769.26655
Overall Steps per Second: 9,250.65188

Timestep Collection Time: 4.64396
Timestep Consumption Time: 0.76237
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 5.40632

Cumulative Model Updates: 4,562
Cumulative Timesteps: 76,174,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.15383
Policy Entropy: 1.14279
Value Function Loss: 5.51369

Mean KL Divergence: 0.03325
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.08982

Collected Steps per Second: 10,800.24794
Overall Steps per Second: 9,118.70204

Timestep Collection Time: 4.63193
Timestep Consumption Time: 0.85416
PPO Batch Consumption Time: 0.03930
Total Iteration Time: 5.48609

Cumulative Model Updates: 4,565
Cumulative Timesteps: 76,224,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 76224414...
Checkpoint 76224414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.60559
Policy Entropy: 1.15066
Value Function Loss: 5.45144

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.03461
Value Function Update Magnitude: 0.07916

Collected Steps per Second: 10,571.01776
Overall Steps per Second: 9,114.16932

Timestep Collection Time: 4.73199
Timestep Consumption Time: 0.75638
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 5.48838

Cumulative Model Updates: 4,568
Cumulative Timesteps: 76,274,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.98410
Policy Entropy: 1.12496
Value Function Loss: 5.41899

Mean KL Divergence: 0.03414
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.03804
Value Function Update Magnitude: 0.07749

Collected Steps per Second: 10,411.49744
Overall Steps per Second: 8,845.47069

Timestep Collection Time: 4.80488
Timestep Consumption Time: 0.85067
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 5.65555

Cumulative Model Updates: 4,571
Cumulative Timesteps: 76,324,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 76324462...
Checkpoint 76324462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.80785
Policy Entropy: 1.13927
Value Function Loss: 5.61121

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.03751
Value Function Update Magnitude: 0.08321

Collected Steps per Second: 10,517.87803
Overall Steps per Second: 8,835.15706

Timestep Collection Time: 4.75419
Timestep Consumption Time: 0.90547
PPO Batch Consumption Time: 0.04954
Total Iteration Time: 5.65966

Cumulative Model Updates: 4,574
Cumulative Timesteps: 76,374,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.04417
Policy Entropy: 1.13323
Value Function Loss: 5.68461

Mean KL Divergence: 0.03567
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.04174
Value Function Update Magnitude: 0.07612

Collected Steps per Second: 10,928.31083
Overall Steps per Second: 9,236.77507

Timestep Collection Time: 4.57527
Timestep Consumption Time: 0.83787
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.41314

Cumulative Model Updates: 4,577
Cumulative Timesteps: 76,424,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 76424466...
Checkpoint 76424466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.88330
Policy Entropy: 1.15732
Value Function Loss: 5.56238

Mean KL Divergence: 0.02979
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.04117
Value Function Update Magnitude: 0.07314

Collected Steps per Second: 10,641.36045
Overall Steps per Second: 9,029.94246

Timestep Collection Time: 4.70053
Timestep Consumption Time: 0.83882
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 5.53935

Cumulative Model Updates: 4,580
Cumulative Timesteps: 76,474,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.97553
Policy Entropy: 1.14713
Value Function Loss: 5.34104

Mean KL Divergence: 0.02719
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.03976
Value Function Update Magnitude: 0.06541

Collected Steps per Second: 10,718.34769
Overall Steps per Second: 9,130.92459

Timestep Collection Time: 4.66583
Timestep Consumption Time: 0.81116
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 5.47699

Cumulative Model Updates: 4,583
Cumulative Timesteps: 76,524,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 76524496...
Checkpoint 76524496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.49724
Policy Entropy: 1.15754
Value Function Loss: 5.23205

Mean KL Divergence: 0.03221
SB3 Clip Fraction: 0.14518
Policy Update Magnitude: 0.04315
Value Function Update Magnitude: 0.06158

Collected Steps per Second: 10,621.03558
Overall Steps per Second: 8,953.18860

Timestep Collection Time: 4.70839
Timestep Consumption Time: 0.87710
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 5.58550

Cumulative Model Updates: 4,586
Cumulative Timesteps: 76,574,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.80296
Policy Entropy: 1.14463
Value Function Loss: 5.17349

Mean KL Divergence: 0.03105
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.03828
Value Function Update Magnitude: 0.06258

Collected Steps per Second: 10,144.88691
Overall Steps per Second: 8,780.49277

Timestep Collection Time: 4.93056
Timestep Consumption Time: 0.76616
PPO Batch Consumption Time: 0.04617
Total Iteration Time: 5.69672

Cumulative Model Updates: 4,589
Cumulative Timesteps: 76,624,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 76624524...
Checkpoint 76624524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.94475
Policy Entropy: 1.15501
Value Function Loss: 5.26201

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.03645
Value Function Update Magnitude: 0.05791

Collected Steps per Second: 10,704.32035
Overall Steps per Second: 9,027.95731

Timestep Collection Time: 4.67157
Timestep Consumption Time: 0.86744
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 5.53902

Cumulative Model Updates: 4,592
Cumulative Timesteps: 76,674,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.81198
Policy Entropy: 1.14356
Value Function Loss: 5.19950

Mean KL Divergence: 0.03336
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.03429
Value Function Update Magnitude: 0.05332

Collected Steps per Second: 10,911.09498
Overall Steps per Second: 9,224.69419

Timestep Collection Time: 4.58286
Timestep Consumption Time: 0.83781
PPO Batch Consumption Time: 0.04311
Total Iteration Time: 5.42067

Cumulative Model Updates: 4,595
Cumulative Timesteps: 76,724,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 76724534...
Checkpoint 76724534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171.98965
Policy Entropy: 1.14984
Value Function Loss: 5.48481

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.03465
Value Function Update Magnitude: 0.06051

Collected Steps per Second: 11,135.98445
Overall Steps per Second: 9,329.74775

Timestep Collection Time: 4.48995
Timestep Consumption Time: 0.86925
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.35920

Cumulative Model Updates: 4,598
Cumulative Timesteps: 76,774,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.44600
Policy Entropy: 1.13819
Value Function Loss: 5.55914

Mean KL Divergence: 0.03397
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.03604
Value Function Update Magnitude: 0.05487

Collected Steps per Second: 11,263.72994
Overall Steps per Second: 9,428.00645

Timestep Collection Time: 4.44169
Timestep Consumption Time: 0.86484
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.30653

Cumulative Model Updates: 4,601
Cumulative Timesteps: 76,824,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 76824564...
Checkpoint 76824564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.53585
Policy Entropy: 1.15154
Value Function Loss: 5.55050

Mean KL Divergence: 0.02492
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.03405
Value Function Update Magnitude: 0.06096

Collected Steps per Second: 10,386.92004
Overall Steps per Second: 8,988.57167

Timestep Collection Time: 4.81567
Timestep Consumption Time: 0.74917
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 5.56484

Cumulative Model Updates: 4,604
Cumulative Timesteps: 76,874,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.15330
Policy Entropy: 1.14179
Value Function Loss: 5.30463

Mean KL Divergence: 0.03075
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.03631
Value Function Update Magnitude: 0.05794

Collected Steps per Second: 10,962.61714
Overall Steps per Second: 9,231.57367

Timestep Collection Time: 4.56150
Timestep Consumption Time: 0.85534
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.41684

Cumulative Model Updates: 4,607
Cumulative Timesteps: 76,924,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 76924590...
Checkpoint 76924590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.65378
Policy Entropy: 1.14874
Value Function Loss: 5.22672

Mean KL Divergence: 0.02834
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.03770
Value Function Update Magnitude: 0.06088

Collected Steps per Second: 11,128.16629
Overall Steps per Second: 9,414.80982

Timestep Collection Time: 4.49580
Timestep Consumption Time: 0.81817
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.31397

Cumulative Model Updates: 4,610
Cumulative Timesteps: 76,974,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.49369
Policy Entropy: 1.13864
Value Function Loss: 5.29746

Mean KL Divergence: 0.02958
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.04044
Value Function Update Magnitude: 0.06551

Collected Steps per Second: 11,333.69763
Overall Steps per Second: 9,479.94986

Timestep Collection Time: 4.41162
Timestep Consumption Time: 0.86267
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 5.27429

Cumulative Model Updates: 4,613
Cumulative Timesteps: 77,024,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 77024620...
Checkpoint 77024620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.35623
Policy Entropy: 1.15975
Value Function Loss: 5.24949

Mean KL Divergence: 0.02529
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.05795

Collected Steps per Second: 10,400.74764
Overall Steps per Second: 8,828.27272

Timestep Collection Time: 4.81100
Timestep Consumption Time: 0.85693
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 5.66793

Cumulative Model Updates: 4,616
Cumulative Timesteps: 77,074,658

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.96585
Policy Entropy: 1.15137
Value Function Loss: 5.24776

Mean KL Divergence: 0.03366
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.06700
Value Function Update Magnitude: 0.06096

Collected Steps per Second: 10,678.26954
Overall Steps per Second: 9,117.13462

Timestep Collection Time: 4.68353
Timestep Consumption Time: 0.80196
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 5.48550

Cumulative Model Updates: 4,619
Cumulative Timesteps: 77,124,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 77124670...
Checkpoint 77124670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.13247
Policy Entropy: 1.15311
Value Function Loss: 5.37134

Mean KL Divergence: 0.02641
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.06025

Collected Steps per Second: 10,538.78440
Overall Steps per Second: 8,926.72719

Timestep Collection Time: 4.74666
Timestep Consumption Time: 0.85719
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 5.60385

Cumulative Model Updates: 4,622
Cumulative Timesteps: 77,174,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.91646
Policy Entropy: 1.13150
Value Function Loss: 5.54597

Mean KL Divergence: 0.03486
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.06341

Collected Steps per Second: 10,462.02721
Overall Steps per Second: 8,949.66512

Timestep Collection Time: 4.78206
Timestep Consumption Time: 0.80810
PPO Batch Consumption Time: 0.04975
Total Iteration Time: 5.59015

Cumulative Model Updates: 4,625
Cumulative Timesteps: 77,224,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 77224724...
Checkpoint 77224724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.39404
Policy Entropy: 1.14403
Value Function Loss: 5.72949

Mean KL Divergence: 0.02578
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.06469

Collected Steps per Second: 10,891.64426
Overall Steps per Second: 9,112.00365

Timestep Collection Time: 4.59141
Timestep Consumption Time: 0.89674
PPO Batch Consumption Time: 0.04651
Total Iteration Time: 5.48815

Cumulative Model Updates: 4,628
Cumulative Timesteps: 77,274,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.51627
Policy Entropy: 1.13957
Value Function Loss: 5.85394

Mean KL Divergence: 0.03481
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.05957

Collected Steps per Second: 10,394.88337
Overall Steps per Second: 8,874.92628

Timestep Collection Time: 4.81179
Timestep Consumption Time: 0.82409
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 5.63588

Cumulative Model Updates: 4,631
Cumulative Timesteps: 77,324,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 77324750...
Checkpoint 77324750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.52555
Policy Entropy: 1.15592
Value Function Loss: 6.05752

Mean KL Divergence: 0.02616
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.04714

Collected Steps per Second: 10,789.85883
Overall Steps per Second: 9,263.44157

Timestep Collection Time: 4.63546
Timestep Consumption Time: 0.76383
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 5.39929

Cumulative Model Updates: 4,634
Cumulative Timesteps: 77,374,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.85299
Policy Entropy: 1.13064
Value Function Loss: 5.93618

Mean KL Divergence: 0.04138
SB3 Clip Fraction: 0.16016
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.07189

Collected Steps per Second: 10,174.64308
Overall Steps per Second: 8,632.60100

Timestep Collection Time: 4.91713
Timestep Consumption Time: 0.87835
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 5.79547

Cumulative Model Updates: 4,637
Cumulative Timesteps: 77,424,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 77424796...
Checkpoint 77424796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.88241
Policy Entropy: 1.14077
Value Function Loss: 5.60940

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.04009
Value Function Update Magnitude: 0.07039

Collected Steps per Second: 10,527.44504
Overall Steps per Second: 9,127.04658

Timestep Collection Time: 4.75025
Timestep Consumption Time: 0.72885
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.47910

Cumulative Model Updates: 4,640
Cumulative Timesteps: 77,474,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.68017
Policy Entropy: 1.12203
Value Function Loss: 5.54570

Mean KL Divergence: 0.03434
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.06187

Collected Steps per Second: 10,774.17265
Overall Steps per Second: 9,075.74536

Timestep Collection Time: 4.64351
Timestep Consumption Time: 0.86898
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 5.51249

Cumulative Model Updates: 4,643
Cumulative Timesteps: 77,524,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 77524834...
Checkpoint 77524834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.74464
Policy Entropy: 1.15681
Value Function Loss: 5.64632

Mean KL Divergence: 0.02928
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.04017
Value Function Update Magnitude: 0.06050

Collected Steps per Second: 10,532.48970
Overall Steps per Second: 9,013.56913

Timestep Collection Time: 4.74817
Timestep Consumption Time: 0.80014
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 5.54830

Cumulative Model Updates: 4,646
Cumulative Timesteps: 77,574,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.52764
Policy Entropy: 1.14781
Value Function Loss: 5.57535

Mean KL Divergence: 0.02980
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.03613
Value Function Update Magnitude: 0.06840

Collected Steps per Second: 10,602.94321
Overall Steps per Second: 9,174.04143

Timestep Collection Time: 4.71586
Timestep Consumption Time: 0.73452
PPO Batch Consumption Time: 0.04655
Total Iteration Time: 5.45038

Cumulative Model Updates: 4,649
Cumulative Timesteps: 77,624,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 77624846...
Checkpoint 77624846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.66230
Policy Entropy: 1.15756
Value Function Loss: 5.26011

Mean KL Divergence: 0.02700
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.03596
Value Function Update Magnitude: 0.06099

Collected Steps per Second: 10,405.89417
Overall Steps per Second: 8,776.98569

Timestep Collection Time: 4.80612
Timestep Consumption Time: 0.89196
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 5.69808

Cumulative Model Updates: 4,652
Cumulative Timesteps: 77,674,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.47913
Policy Entropy: 1.13370
Value Function Loss: 5.05399

Mean KL Divergence: 0.03101
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.05451

Collected Steps per Second: 10,779.93365
Overall Steps per Second: 9,045.53838

Timestep Collection Time: 4.64029
Timestep Consumption Time: 0.88973
PPO Batch Consumption Time: 0.04421
Total Iteration Time: 5.53002

Cumulative Model Updates: 4,655
Cumulative Timesteps: 77,724,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 77724880...
Checkpoint 77724880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.59022
Policy Entropy: 1.15352
Value Function Loss: 4.97919

Mean KL Divergence: 0.02673
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.03990
Value Function Update Magnitude: 0.05309

Collected Steps per Second: 10,810.85498
Overall Steps per Second: 8,972.87140

Timestep Collection Time: 4.62609
Timestep Consumption Time: 0.94760
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.57369

Cumulative Model Updates: 4,658
Cumulative Timesteps: 77,774,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.98309
Policy Entropy: 1.14477
Value Function Loss: 5.20029

Mean KL Divergence: 0.02900
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.04211
Value Function Update Magnitude: 0.05526

Collected Steps per Second: 10,754.16617
Overall Steps per Second: 9,115.35839

Timestep Collection Time: 4.65029
Timestep Consumption Time: 0.83605
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 5.48634

Cumulative Model Updates: 4,661
Cumulative Timesteps: 77,824,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 77824902...
Checkpoint 77824902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.72689
Policy Entropy: 1.16239
Value Function Loss: 5.09776

Mean KL Divergence: 0.02695
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.05334

Collected Steps per Second: 10,651.95791
Overall Steps per Second: 9,047.56255

Timestep Collection Time: 4.69641
Timestep Consumption Time: 0.83281
PPO Batch Consumption Time: 0.04338
Total Iteration Time: 5.52922

Cumulative Model Updates: 4,664
Cumulative Timesteps: 77,874,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.78527
Policy Entropy: 1.12717
Value Function Loss: 5.23627

Mean KL Divergence: 0.03018
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.03931
Value Function Update Magnitude: 0.05922

Collected Steps per Second: 10,998.94640
Overall Steps per Second: 9,307.67625

Timestep Collection Time: 4.54662
Timestep Consumption Time: 0.82615
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 5.37277

Cumulative Model Updates: 4,667
Cumulative Timesteps: 77,924,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 77924936...
Checkpoint 77924936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.97807
Policy Entropy: 1.14179
Value Function Loss: 5.27084

Mean KL Divergence: 0.02439
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.04061
Value Function Update Magnitude: 0.05835

Collected Steps per Second: 10,125.19302
Overall Steps per Second: 8,672.81571

Timestep Collection Time: 4.93917
Timestep Consumption Time: 0.82713
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 5.76629

Cumulative Model Updates: 4,670
Cumulative Timesteps: 77,974,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.38452
Policy Entropy: 1.12978
Value Function Loss: 5.23837

Mean KL Divergence: 0.03348
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.06873

Collected Steps per Second: 10,784.54271
Overall Steps per Second: 9,294.58338

Timestep Collection Time: 4.63775
Timestep Consumption Time: 0.74345
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 5.38120

Cumulative Model Updates: 4,673
Cumulative Timesteps: 78,024,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 78024962...
Checkpoint 78024962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.31872
Policy Entropy: 1.17252
Value Function Loss: 5.23226

Mean KL Divergence: 0.02648
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.04075
Value Function Update Magnitude: 0.07594

Collected Steps per Second: 10,176.87099
Overall Steps per Second: 8,695.45357

Timestep Collection Time: 4.91566
Timestep Consumption Time: 0.83747
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 5.75312

Cumulative Model Updates: 4,676
Cumulative Timesteps: 78,074,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.56427
Policy Entropy: 1.16263
Value Function Loss: 5.12965

Mean KL Divergence: 0.02950
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.03755
Value Function Update Magnitude: 0.07089

Collected Steps per Second: 10,590.36847
Overall Steps per Second: 9,104.53708

Timestep Collection Time: 4.72259
Timestep Consumption Time: 0.77071
PPO Batch Consumption Time: 0.03965
Total Iteration Time: 5.49331

Cumulative Model Updates: 4,679
Cumulative Timesteps: 78,125,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 78125002...
Checkpoint 78125002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.31647
Policy Entropy: 1.17328
Value Function Loss: 5.24287

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.04246
Value Function Update Magnitude: 0.05887

Collected Steps per Second: 10,439.63548
Overall Steps per Second: 8,854.79433

Timestep Collection Time: 4.79078
Timestep Consumption Time: 0.85746
PPO Batch Consumption Time: 0.04418
Total Iteration Time: 5.64824

Cumulative Model Updates: 4,682
Cumulative Timesteps: 78,175,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.37024
Policy Entropy: 1.13204
Value Function Loss: 5.29832

Mean KL Divergence: 0.03159
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.04072
Value Function Update Magnitude: 0.05193

Collected Steps per Second: 10,393.67072
Overall Steps per Second: 8,906.27426

Timestep Collection Time: 4.81158
Timestep Consumption Time: 0.80356
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 5.61514

Cumulative Model Updates: 4,685
Cumulative Timesteps: 78,225,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 78225026...
Checkpoint 78225026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.96652
Policy Entropy: 1.15138
Value Function Loss: 5.27354

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.04344
Value Function Update Magnitude: 0.04859

Collected Steps per Second: 10,475.71357
Overall Steps per Second: 8,861.91540

Timestep Collection Time: 4.77562
Timestep Consumption Time: 0.86966
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 5.64528

Cumulative Model Updates: 4,688
Cumulative Timesteps: 78,275,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.46299
Policy Entropy: 1.13670
Value Function Loss: 5.23247

Mean KL Divergence: 0.03453
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.04250
Value Function Update Magnitude: 0.05853

Collected Steps per Second: 10,796.73000
Overall Steps per Second: 9,110.69050

Timestep Collection Time: 4.63325
Timestep Consumption Time: 0.85744
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 5.49069

Cumulative Model Updates: 4,691
Cumulative Timesteps: 78,325,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 78325078...
Checkpoint 78325078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.19175
Policy Entropy: 1.16291
Value Function Loss: 5.23367

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.04022
Value Function Update Magnitude: 0.05980

Collected Steps per Second: 10,639.35766
Overall Steps per Second: 9,123.85756

Timestep Collection Time: 4.70085
Timestep Consumption Time: 0.78082
PPO Batch Consumption Time: 0.04585
Total Iteration Time: 5.48167

Cumulative Model Updates: 4,694
Cumulative Timesteps: 78,375,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.20537
Policy Entropy: 1.14918
Value Function Loss: 5.12713

Mean KL Divergence: 0.03214
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.04386
Value Function Update Magnitude: 0.05987

Collected Steps per Second: 10,533.44064
Overall Steps per Second: 8,836.36977

Timestep Collection Time: 4.74736
Timestep Consumption Time: 0.91175
PPO Batch Consumption Time: 0.04006
Total Iteration Time: 5.65911

Cumulative Model Updates: 4,697
Cumulative Timesteps: 78,425,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 78425098...
Checkpoint 78425098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.49055
Policy Entropy: 1.16871
Value Function Loss: 5.18137

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.07694

Collected Steps per Second: 10,847.83167
Overall Steps per Second: 9,021.83817

Timestep Collection Time: 4.60958
Timestep Consumption Time: 0.93297
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 5.54255

Cumulative Model Updates: 4,700
Cumulative Timesteps: 78,475,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.26652
Policy Entropy: 1.15317
Value Function Loss: 5.04873

Mean KL Divergence: 0.03859
SB3 Clip Fraction: 0.15176
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.06268

Collected Steps per Second: 10,362.43308
Overall Steps per Second: 8,841.30093

Timestep Collection Time: 4.82782
Timestep Consumption Time: 0.83062
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 5.65844

Cumulative Model Updates: 4,703
Cumulative Timesteps: 78,525,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 78525130...
Checkpoint 78525130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.68730
Policy Entropy: 1.16630
Value Function Loss: 5.21180

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.04477
Value Function Update Magnitude: 0.06461

Collected Steps per Second: 10,780.87340
Overall Steps per Second: 9,122.33923

Timestep Collection Time: 4.63970
Timestep Consumption Time: 0.84354
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 5.48324

Cumulative Model Updates: 4,706
Cumulative Timesteps: 78,575,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.08687
Policy Entropy: 1.13006
Value Function Loss: 5.00977

Mean KL Divergence: 0.04310
SB3 Clip Fraction: 0.15563
Policy Update Magnitude: 0.04441
Value Function Update Magnitude: 0.07673

Collected Steps per Second: 10,588.67390
Overall Steps per Second: 9,040.63760

Timestep Collection Time: 4.72222
Timestep Consumption Time: 0.80859
PPO Batch Consumption Time: 0.04651
Total Iteration Time: 5.53080

Cumulative Model Updates: 4,709
Cumulative Timesteps: 78,625,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 78625152...
Checkpoint 78625152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.25973
Policy Entropy: 1.13681
Value Function Loss: 5.15896

Mean KL Divergence: 0.02856
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.04011
Value Function Update Magnitude: 0.07099

Collected Steps per Second: 10,624.84232
Overall Steps per Second: 8,968.41566

Timestep Collection Time: 4.70896
Timestep Consumption Time: 0.86972
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 5.57869

Cumulative Model Updates: 4,712
Cumulative Timesteps: 78,675,184

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.15984
Policy Entropy: 1.11167
Value Function Loss: 5.01045

Mean KL Divergence: 0.03649
SB3 Clip Fraction: 0.15811
Policy Update Magnitude: 0.03733
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 10,506.25804
Overall Steps per Second: 9,006.35232

Timestep Collection Time: 4.75926
Timestep Consumption Time: 0.79260
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.55186

Cumulative Model Updates: 4,715
Cumulative Timesteps: 78,725,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 78725186...
Checkpoint 78725186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.88218
Policy Entropy: 1.13779
Value Function Loss: 5.12821

Mean KL Divergence: 0.02879
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.03675
Value Function Update Magnitude: 0.09876

Collected Steps per Second: 10,413.08983
Overall Steps per Second: 8,799.36740

Timestep Collection Time: 4.80261
Timestep Consumption Time: 0.88075
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 5.68336

Cumulative Model Updates: 4,718
Cumulative Timesteps: 78,775,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.56684
Policy Entropy: 1.11645
Value Function Loss: 5.26307

Mean KL Divergence: 0.03794
SB3 Clip Fraction: 0.15957
Policy Update Magnitude: 0.03828
Value Function Update Magnitude: 0.10406

Collected Steps per Second: 10,655.14941
Overall Steps per Second: 9,063.33201

Timestep Collection Time: 4.69501
Timestep Consumption Time: 0.82460
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 5.51960

Cumulative Model Updates: 4,721
Cumulative Timesteps: 78,825,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 78825222...
Checkpoint 78825222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.77634
Policy Entropy: 1.13065
Value Function Loss: 5.48349

Mean KL Divergence: 0.02958
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.08252

Collected Steps per Second: 11,176.06028
Overall Steps per Second: 9,377.18764

Timestep Collection Time: 4.47600
Timestep Consumption Time: 0.85865
PPO Batch Consumption Time: 0.04004
Total Iteration Time: 5.33465

Cumulative Model Updates: 4,724
Cumulative Timesteps: 78,875,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.57154
Policy Entropy: 1.11336
Value Function Loss: 5.42974

Mean KL Divergence: 0.03362
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.03729
Value Function Update Magnitude: 0.07669

Collected Steps per Second: 10,673.59592
Overall Steps per Second: 9,063.50416

Timestep Collection Time: 4.68614
Timestep Consumption Time: 0.83247
PPO Batch Consumption Time: 0.04135
Total Iteration Time: 5.51862

Cumulative Model Updates: 4,727
Cumulative Timesteps: 78,925,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 78925264...
Checkpoint 78925264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.30623
Policy Entropy: 1.13188
Value Function Loss: 5.25499

Mean KL Divergence: 0.02828
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.03948
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 10,870.68799
Overall Steps per Second: 9,227.49316

Timestep Collection Time: 4.60136
Timestep Consumption Time: 0.81939
PPO Batch Consumption Time: 0.04024
Total Iteration Time: 5.42076

Cumulative Model Updates: 4,730
Cumulative Timesteps: 78,975,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.17796
Policy Entropy: 1.11928
Value Function Loss: 5.13351

Mean KL Divergence: 0.02883
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.04180
Value Function Update Magnitude: 0.10002

Collected Steps per Second: 10,530.06743
Overall Steps per Second: 8,885.15722

Timestep Collection Time: 4.74964
Timestep Consumption Time: 0.87930
PPO Batch Consumption Time: 0.04595
Total Iteration Time: 5.62894

Cumulative Model Updates: 4,733
Cumulative Timesteps: 79,025,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 79025298...
Checkpoint 79025298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.48813
Policy Entropy: 1.14262
Value Function Loss: 5.19081

Mean KL Divergence: 0.02974
SB3 Clip Fraction: 0.15176
Policy Update Magnitude: 0.04485
Value Function Update Magnitude: 0.09441

Collected Steps per Second: 11,031.60993
Overall Steps per Second: 9,371.71208

Timestep Collection Time: 4.53352
Timestep Consumption Time: 0.80297
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 5.33648

Cumulative Model Updates: 4,736
Cumulative Timesteps: 79,075,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.99671
Policy Entropy: 1.13535
Value Function Loss: 5.02532

Mean KL Divergence: 0.03774
SB3 Clip Fraction: 0.16923
Policy Update Magnitude: 0.03881
Value Function Update Magnitude: 0.07631

Collected Steps per Second: 11,412.13059
Overall Steps per Second: 9,505.41784

Timestep Collection Time: 4.38323
Timestep Consumption Time: 0.87924
PPO Batch Consumption Time: 0.04046
Total Iteration Time: 5.26247

Cumulative Model Updates: 4,739
Cumulative Timesteps: 79,125,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 79125332...
Checkpoint 79125332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.28982
Policy Entropy: 1.14975
Value Function Loss: 4.96580

Mean KL Divergence: 0.02748
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.03658
Value Function Update Magnitude: 0.07168

Collected Steps per Second: 10,852.16881
Overall Steps per Second: 9,188.61637

Timestep Collection Time: 4.60959
Timestep Consumption Time: 0.83454
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 5.44413

Cumulative Model Updates: 4,742
Cumulative Timesteps: 79,175,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.48634
Policy Entropy: 1.12475
Value Function Loss: 4.73145

Mean KL Divergence: 0.03578
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.07038

Collected Steps per Second: 10,671.80354
Overall Steps per Second: 9,193.39339

Timestep Collection Time: 4.68768
Timestep Consumption Time: 0.75384
PPO Batch Consumption Time: 0.04510
Total Iteration Time: 5.44152

Cumulative Model Updates: 4,745
Cumulative Timesteps: 79,225,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 79225382...
Checkpoint 79225382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.86354
Policy Entropy: 1.13136
Value Function Loss: 4.99365

Mean KL Divergence: 0.02904
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.04300
Value Function Update Magnitude: 0.09316

Collected Steps per Second: 10,735.65926
Overall Steps per Second: 9,117.93837

Timestep Collection Time: 4.65868
Timestep Consumption Time: 0.82655
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 5.48523

Cumulative Model Updates: 4,748
Cumulative Timesteps: 79,275,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.16184
Policy Entropy: 1.12659
Value Function Loss: 4.83888

Mean KL Divergence: 0.03312
SB3 Clip Fraction: 0.14903
Policy Update Magnitude: 0.03934
Value Function Update Magnitude: 0.09451

Collected Steps per Second: 10,175.52175
Overall Steps per Second: 8,771.88260

Timestep Collection Time: 4.91552
Timestep Consumption Time: 0.78656
PPO Batch Consumption Time: 0.04344
Total Iteration Time: 5.70208

Cumulative Model Updates: 4,751
Cumulative Timesteps: 79,325,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 79325414...
Checkpoint 79325414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.94260
Policy Entropy: 1.14409
Value Function Loss: 5.06297

Mean KL Divergence: 0.02770
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 10,400.24080
Overall Steps per Second: 8,964.82018

Timestep Collection Time: 4.80797
Timestep Consumption Time: 0.76984
PPO Batch Consumption Time: 0.04105
Total Iteration Time: 5.57780

Cumulative Model Updates: 4,754
Cumulative Timesteps: 79,375,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.88644
Policy Entropy: 1.13456
Value Function Loss: 5.15758

Mean KL Divergence: 0.03705
SB3 Clip Fraction: 0.15917
Policy Update Magnitude: 0.04102
Value Function Update Magnitude: 0.07373

Collected Steps per Second: 10,779.88283
Overall Steps per Second: 9,150.75422

Timestep Collection Time: 4.64105
Timestep Consumption Time: 0.82626
PPO Batch Consumption Time: 0.04638
Total Iteration Time: 5.46731

Cumulative Model Updates: 4,757
Cumulative Timesteps: 79,425,448

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 79425448...
Checkpoint 79425448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.14370
Policy Entropy: 1.14327
Value Function Loss: 5.38886

Mean KL Divergence: 0.03139
SB3 Clip Fraction: 0.14373
Policy Update Magnitude: 0.04058
Value Function Update Magnitude: 0.06029

Collected Steps per Second: 10,513.47930
Overall Steps per Second: 9,015.24599

Timestep Collection Time: 4.75675
Timestep Consumption Time: 0.79052
PPO Batch Consumption Time: 0.04172
Total Iteration Time: 5.54727

Cumulative Model Updates: 4,760
Cumulative Timesteps: 79,475,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.04050
Policy Entropy: 1.13297
Value Function Loss: 5.40875

Mean KL Divergence: 0.03717
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.05793

Collected Steps per Second: 10,870.18869
Overall Steps per Second: 9,242.57613

Timestep Collection Time: 4.60084
Timestep Consumption Time: 0.81021
PPO Batch Consumption Time: 0.03849
Total Iteration Time: 5.41105

Cumulative Model Updates: 4,763
Cumulative Timesteps: 79,525,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 79525470...
Checkpoint 79525470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.39969
Policy Entropy: 1.14604
Value Function Loss: 5.36565

Mean KL Divergence: 0.02827
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.05496

Collected Steps per Second: 10,313.99155
Overall Steps per Second: 8,803.79469

Timestep Collection Time: 4.84972
Timestep Consumption Time: 0.83192
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.68164

Cumulative Model Updates: 4,766
Cumulative Timesteps: 79,575,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.25918
Policy Entropy: 1.12498
Value Function Loss: 5.41821

Mean KL Divergence: 0.03481
SB3 Clip Fraction: 0.14279
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.05532

Collected Steps per Second: 10,941.75679
Overall Steps per Second: 9,268.35309

Timestep Collection Time: 4.57093
Timestep Consumption Time: 0.82528
PPO Batch Consumption Time: 0.04039
Total Iteration Time: 5.39621

Cumulative Model Updates: 4,769
Cumulative Timesteps: 79,625,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 79625504...
Checkpoint 79625504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.40695
Policy Entropy: 1.13781
Value Function Loss: 5.33418

Mean KL Divergence: 0.03492
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.05255

Collected Steps per Second: 10,562.37363
Overall Steps per Second: 9,005.87745

Timestep Collection Time: 4.73435
Timestep Consumption Time: 0.81824
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.55260

Cumulative Model Updates: 4,772
Cumulative Timesteps: 79,675,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.79649
Policy Entropy: 1.13197
Value Function Loss: 5.36589

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.04976

Collected Steps per Second: 10,819.13589
Overall Steps per Second: 9,374.31912

Timestep Collection Time: 4.62218
Timestep Consumption Time: 0.71239
PPO Batch Consumption Time: 0.03932
Total Iteration Time: 5.33457

Cumulative Model Updates: 4,775
Cumulative Timesteps: 79,725,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 79725518...
Checkpoint 79725518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.32118
Policy Entropy: 1.13126
Value Function Loss: 5.33371

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.08281
Value Function Update Magnitude: 0.05646

Collected Steps per Second: 10,500.89817
Overall Steps per Second: 8,942.55726

Timestep Collection Time: 4.76416
Timestep Consumption Time: 0.83021
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 5.59437

Cumulative Model Updates: 4,778
Cumulative Timesteps: 79,775,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.85405
Policy Entropy: 1.14576
Value Function Loss: 5.27645

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.07401
Value Function Update Magnitude: 0.06100

Collected Steps per Second: 10,644.65188
Overall Steps per Second: 9,085.63474

Timestep Collection Time: 4.69832
Timestep Consumption Time: 0.80619
PPO Batch Consumption Time: 0.04015
Total Iteration Time: 5.50451

Cumulative Model Updates: 4,781
Cumulative Timesteps: 79,825,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 79825558...
Checkpoint 79825558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.68146
Policy Entropy: 1.10801
Value Function Loss: 5.12550

Mean KL Divergence: 0.05640
SB3 Clip Fraction: 0.18115
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.06507

Collected Steps per Second: 10,493.79937
Overall Steps per Second: 8,830.29264

Timestep Collection Time: 4.76472
Timestep Consumption Time: 0.89761
PPO Batch Consumption Time: 0.04754
Total Iteration Time: 5.66233

Cumulative Model Updates: 4,784
Cumulative Timesteps: 79,875,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.26655
Policy Entropy: 1.11690
Value Function Loss: 5.04132

Mean KL Divergence: 0.02979
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.06184
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 10,763.51421
Overall Steps per Second: 9,087.23965

Timestep Collection Time: 4.64551
Timestep Consumption Time: 0.85693
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 5.50244

Cumulative Model Updates: 4,787
Cumulative Timesteps: 79,925,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 79925560...
Checkpoint 79925560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.33134
Policy Entropy: 1.10593
Value Function Loss: 5.07967

Mean KL Divergence: 0.03142
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.07270
Value Function Update Magnitude: 0.05091

Collected Steps per Second: 10,848.64937
Overall Steps per Second: 9,254.44750

Timestep Collection Time: 4.61071
Timestep Consumption Time: 0.79426
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 5.40497

Cumulative Model Updates: 4,790
Cumulative Timesteps: 79,975,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.97286
Policy Entropy: 1.12169
Value Function Loss: 5.13531

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.07407
Value Function Update Magnitude: 0.04744

Collected Steps per Second: 10,753.94214
Overall Steps per Second: 9,066.71538

Timestep Collection Time: 4.65020
Timestep Consumption Time: 0.86536
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.51556

Cumulative Model Updates: 4,793
Cumulative Timesteps: 80,025,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 80025588...
Checkpoint 80025588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.45030
Policy Entropy: 1.12185
Value Function Loss: 5.07190

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.06614
Value Function Update Magnitude: 0.06141

Collected Steps per Second: 10,466.11864
Overall Steps per Second: 8,915.97523

Timestep Collection Time: 4.77732
Timestep Consumption Time: 0.83059
PPO Batch Consumption Time: 0.04406
Total Iteration Time: 5.60791

Cumulative Model Updates: 4,796
Cumulative Timesteps: 80,075,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.51646
Policy Entropy: 1.10216
Value Function Loss: 5.11325

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.05901

Collected Steps per Second: 10,282.19345
Overall Steps per Second: 8,855.63387

Timestep Collection Time: 4.86530
Timestep Consumption Time: 0.78375
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 5.64906

Cumulative Model Updates: 4,799
Cumulative Timesteps: 80,125,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 80125614...
Checkpoint 80125614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.76794
Policy Entropy: 1.11854
Value Function Loss: 5.20197

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.06882
Value Function Update Magnitude: 0.06255

Collected Steps per Second: 9,936.95573
Overall Steps per Second: 8,366.24674

Timestep Collection Time: 5.03253
Timestep Consumption Time: 0.94482
PPO Batch Consumption Time: 0.04718
Total Iteration Time: 5.97735

Cumulative Model Updates: 4,802
Cumulative Timesteps: 80,175,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.88514
Policy Entropy: 1.10679
Value Function Loss: 5.35180

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.06051

Collected Steps per Second: 9,349.90110
Overall Steps per Second: 8,230.71921

Timestep Collection Time: 5.34958
Timestep Consumption Time: 0.72741
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 6.07699

Cumulative Model Updates: 4,805
Cumulative Timesteps: 80,225,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 80225640...
Checkpoint 80225640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.13831
Policy Entropy: 1.12464
Value Function Loss: 5.38134

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.06196

Collected Steps per Second: 10,752.84147
Overall Steps per Second: 9,015.60667

Timestep Collection Time: 4.65049
Timestep Consumption Time: 0.89611
PPO Batch Consumption Time: 0.03982
Total Iteration Time: 5.54660

Cumulative Model Updates: 4,808
Cumulative Timesteps: 80,275,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.64597
Policy Entropy: 1.14310
Value Function Loss: 5.21549

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.09694

Collected Steps per Second: 10,649.05031
Overall Steps per Second: 9,110.82577

Timestep Collection Time: 4.69770
Timestep Consumption Time: 0.79313
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.49083

Cumulative Model Updates: 4,811
Cumulative Timesteps: 80,325,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 80325672...
Checkpoint 80325672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.94238
Policy Entropy: 1.14342
Value Function Loss: 5.24720

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.10366

Collected Steps per Second: 10,279.20580
Overall Steps per Second: 8,702.25231

Timestep Collection Time: 4.86672
Timestep Consumption Time: 0.88191
PPO Batch Consumption Time: 0.04644
Total Iteration Time: 5.74863

Cumulative Model Updates: 4,814
Cumulative Timesteps: 80,375,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.62277
Policy Entropy: 1.13866
Value Function Loss: 5.19926

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07709
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.08957

Collected Steps per Second: 10,660.24643
Overall Steps per Second: 8,957.87885

Timestep Collection Time: 4.69332
Timestep Consumption Time: 0.89193
PPO Batch Consumption Time: 0.04733
Total Iteration Time: 5.58525

Cumulative Model Updates: 4,817
Cumulative Timesteps: 80,425,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 80425730...
Checkpoint 80425730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.62668
Policy Entropy: 1.12666
Value Function Loss: 5.28867

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.08088

Collected Steps per Second: 10,603.31087
Overall Steps per Second: 9,085.02626

Timestep Collection Time: 4.71589
Timestep Consumption Time: 0.78812
PPO Batch Consumption Time: 0.04537
Total Iteration Time: 5.50400

Cumulative Model Updates: 4,820
Cumulative Timesteps: 80,475,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.80554
Policy Entropy: 1.14992
Value Function Loss: 5.26808

Mean KL Divergence: 0.02858
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.07372
Value Function Update Magnitude: 0.06887

Collected Steps per Second: 10,741.25045
Overall Steps per Second: 9,074.07050

Timestep Collection Time: 4.65607
Timestep Consumption Time: 0.85546
PPO Batch Consumption Time: 0.03929
Total Iteration Time: 5.51153

Cumulative Model Updates: 4,823
Cumulative Timesteps: 80,525,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 80525746...
Checkpoint 80525746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.63350
Policy Entropy: 1.13325
Value Function Loss: 5.22711

Mean KL Divergence: 0.02889
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.06155

Collected Steps per Second: 10,752.04986
Overall Steps per Second: 9,190.06911

Timestep Collection Time: 4.65102
Timestep Consumption Time: 0.79051
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 5.44153

Cumulative Model Updates: 4,826
Cumulative Timesteps: 80,575,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.19000
Policy Entropy: 1.13800
Value Function Loss: 5.34529

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.06047

Collected Steps per Second: 10,783.84183
Overall Steps per Second: 9,155.89520

Timestep Collection Time: 4.63916
Timestep Consumption Time: 0.82486
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.46402

Cumulative Model Updates: 4,829
Cumulative Timesteps: 80,625,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 80625782...
Checkpoint 80625782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.97518
Policy Entropy: 1.13692
Value Function Loss: 5.21660

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.05571

Collected Steps per Second: 10,191.59223
Overall Steps per Second: 8,790.08618

Timestep Collection Time: 4.90620
Timestep Consumption Time: 0.78225
PPO Batch Consumption Time: 0.03931
Total Iteration Time: 5.68845

Cumulative Model Updates: 4,832
Cumulative Timesteps: 80,675,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.77869
Policy Entropy: 1.13840
Value Function Loss: 5.40104

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.05867

Collected Steps per Second: 10,805.23670
Overall Steps per Second: 9,133.68608

Timestep Collection Time: 4.62757
Timestep Consumption Time: 0.84689
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.47446

Cumulative Model Updates: 4,835
Cumulative Timesteps: 80,725,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 80725786...
Checkpoint 80725786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.62204
Policy Entropy: 1.14328
Value Function Loss: 5.52154

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.07798
Value Function Update Magnitude: 0.05005

Collected Steps per Second: 10,722.34638
Overall Steps per Second: 9,050.87171

Timestep Collection Time: 4.66502
Timestep Consumption Time: 0.86152
PPO Batch Consumption Time: 0.04607
Total Iteration Time: 5.52654

Cumulative Model Updates: 4,838
Cumulative Timesteps: 80,775,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.07384
Policy Entropy: 1.14996
Value Function Loss: 5.57895

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.07131
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 10,827.13411
Overall Steps per Second: 9,071.60418

Timestep Collection Time: 4.61877
Timestep Consumption Time: 0.89382
PPO Batch Consumption Time: 0.04336
Total Iteration Time: 5.51259

Cumulative Model Updates: 4,841
Cumulative Timesteps: 80,825,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 80825814...
Checkpoint 80825814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.51361
Policy Entropy: 1.11830
Value Function Loss: 5.43655

Mean KL Divergence: 0.06059
SB3 Clip Fraction: 0.19107
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.06940

Collected Steps per Second: 10,738.37332
Overall Steps per Second: 9,052.51299

Timestep Collection Time: 4.65694
Timestep Consumption Time: 0.86727
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 5.52421

Cumulative Model Updates: 4,844
Cumulative Timesteps: 80,875,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.25156
Policy Entropy: 1.12706
Value Function Loss: 5.16541

Mean KL Divergence: 0.03485
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.06970

Collected Steps per Second: 10,144.39839
Overall Steps per Second: 8,758.55356

Timestep Collection Time: 4.93139
Timestep Consumption Time: 0.78028
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 5.71167

Cumulative Model Updates: 4,847
Cumulative Timesteps: 80,925,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 80925848...
Checkpoint 80925848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.75304
Policy Entropy: 1.11405
Value Function Loss: 5.19535

Mean KL Divergence: 0.03831
SB3 Clip Fraction: 0.16259
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.06293

Collected Steps per Second: 10,787.61701
Overall Steps per Second: 8,965.50367

Timestep Collection Time: 4.63754
Timestep Consumption Time: 0.94252
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 5.58005

Cumulative Model Updates: 4,850
Cumulative Timesteps: 80,975,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.15044
Policy Entropy: 1.14671
Value Function Loss: 5.18896

Mean KL Divergence: 0.04439
SB3 Clip Fraction: 0.17940
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.05380

Collected Steps per Second: 10,982.22738
Overall Steps per Second: 9,199.89683

Timestep Collection Time: 4.55445
Timestep Consumption Time: 0.88235
PPO Batch Consumption Time: 0.04335
Total Iteration Time: 5.43680

Cumulative Model Updates: 4,853
Cumulative Timesteps: 81,025,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 81025894...
Checkpoint 81025894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.78953
Policy Entropy: 1.12586
Value Function Loss: 5.13774

Mean KL Divergence: 0.04934
SB3 Clip Fraction: 0.17906
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.05299

Collected Steps per Second: 10,834.22962
Overall Steps per Second: 9,096.71877

Timestep Collection Time: 4.61722
Timestep Consumption Time: 0.88191
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 5.49913

Cumulative Model Updates: 4,856
Cumulative Timesteps: 81,075,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.69739
Policy Entropy: 1.15696
Value Function Loss: 4.91283

Mean KL Divergence: 0.03655
SB3 Clip Fraction: 0.15332
Policy Update Magnitude: 0.03611
Value Function Update Magnitude: 0.05197

Collected Steps per Second: 10,935.92297
Overall Steps per Second: 9,179.88959

Timestep Collection Time: 4.57209
Timestep Consumption Time: 0.87460
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.44669

Cumulative Model Updates: 4,859
Cumulative Timesteps: 81,125,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 81125918...
Checkpoint 81125918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.62752
Policy Entropy: 1.12234
Value Function Loss: 4.91505

Mean KL Divergence: 0.04661
SB3 Clip Fraction: 0.16542
Policy Update Magnitude: 0.03679
Value Function Update Magnitude: 0.05795

Collected Steps per Second: 11,041.97447
Overall Steps per Second: 9,250.96653

Timestep Collection Time: 4.52981
Timestep Consumption Time: 0.87698
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.40679

Cumulative Model Updates: 4,862
Cumulative Timesteps: 81,175,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.25498
Policy Entropy: 1.13984
Value Function Loss: 4.70406

Mean KL Divergence: 0.03156
SB3 Clip Fraction: 0.14906
Policy Update Magnitude: 0.03174
Value Function Update Magnitude: 0.05618

Collected Steps per Second: 10,901.32544
Overall Steps per Second: 9,208.78083

Timestep Collection Time: 4.58880
Timestep Consumption Time: 0.84341
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 5.43221

Cumulative Model Updates: 4,865
Cumulative Timesteps: 81,225,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 81225960...
Checkpoint 81225960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.28920
Policy Entropy: 1.12164
Value Function Loss: 4.80443

Mean KL Divergence: 0.04383
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.03297
Value Function Update Magnitude: 0.04954

Collected Steps per Second: 10,987.49580
Overall Steps per Second: 9,121.70197

Timestep Collection Time: 4.55318
Timestep Consumption Time: 0.93133
PPO Batch Consumption Time: 0.04589
Total Iteration Time: 5.48450

Cumulative Model Updates: 4,868
Cumulative Timesteps: 81,275,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.73302
Policy Entropy: 1.12802
Value Function Loss: 4.90962

Mean KL Divergence: 0.02938
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.03219
Value Function Update Magnitude: 0.05357

Collected Steps per Second: 11,512.01921
Overall Steps per Second: 9,636.09566

Timestep Collection Time: 4.34381
Timestep Consumption Time: 0.84564
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 5.18945

Cumulative Model Updates: 4,871
Cumulative Timesteps: 81,325,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 81325994...
Checkpoint 81325994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.90926
Policy Entropy: 1.11468
Value Function Loss: 5.21854

Mean KL Divergence: 0.04816
SB3 Clip Fraction: 0.17307
Policy Update Magnitude: 0.03543
Value Function Update Magnitude: 0.04338

Collected Steps per Second: 10,980.30807
Overall Steps per Second: 9,221.63516

Timestep Collection Time: 4.55361
Timestep Consumption Time: 0.86843
PPO Batch Consumption Time: 0.04310
Total Iteration Time: 5.42203

Cumulative Model Updates: 4,874
Cumulative Timesteps: 81,375,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.92902
Policy Entropy: 1.12486
Value Function Loss: 4.98962

Mean KL Divergence: 0.03112
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.03318
Value Function Update Magnitude: 0.04588

Collected Steps per Second: 10,577.55658
Overall Steps per Second: 9,151.73397

Timestep Collection Time: 4.72888
Timestep Consumption Time: 0.73675
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 5.46563

Cumulative Model Updates: 4,877
Cumulative Timesteps: 81,426,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 81426014...
Checkpoint 81426014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.50354
Policy Entropy: 1.12481
Value Function Loss: 4.99969

Mean KL Divergence: 0.03988
SB3 Clip Fraction: 0.15713
Policy Update Magnitude: 0.03458
Value Function Update Magnitude: 0.05343

Collected Steps per Second: 10,177.32108
Overall Steps per Second: 8,725.61999

Timestep Collection Time: 4.91406
Timestep Consumption Time: 0.81756
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 5.73163

Cumulative Model Updates: 4,880
Cumulative Timesteps: 81,476,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.70800
Policy Entropy: 1.14159
Value Function Loss: 4.96144

Mean KL Divergence: 0.03223
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.03202
Value Function Update Magnitude: 0.05023

Collected Steps per Second: 10,715.32106
Overall Steps per Second: 9,097.01446

Timestep Collection Time: 4.66752
Timestep Consumption Time: 0.83033
PPO Batch Consumption Time: 0.04472
Total Iteration Time: 5.49785

Cumulative Model Updates: 4,883
Cumulative Timesteps: 81,526,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 81526040...
Checkpoint 81526040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.48492
Policy Entropy: 1.12609
Value Function Loss: 5.04419

Mean KL Divergence: 0.04078
SB3 Clip Fraction: 0.15607
Policy Update Magnitude: 0.03148
Value Function Update Magnitude: 0.05196

Collected Steps per Second: 10,954.43475
Overall Steps per Second: 9,315.48593

Timestep Collection Time: 4.56564
Timestep Consumption Time: 0.80327
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 5.36891

Cumulative Model Updates: 4,886
Cumulative Timesteps: 81,576,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.82230
Policy Entropy: 1.13118
Value Function Loss: 4.90681

Mean KL Divergence: 0.02969
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.03273
Value Function Update Magnitude: 0.06428

Collected Steps per Second: 10,774.60153
Overall Steps per Second: 9,141.10206

Timestep Collection Time: 4.64277
Timestep Consumption Time: 0.82966
PPO Batch Consumption Time: 0.04132
Total Iteration Time: 5.47243

Cumulative Model Updates: 4,889
Cumulative Timesteps: 81,626,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 81626078...
Checkpoint 81626078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.81190
Policy Entropy: 1.09576
Value Function Loss: 5.06452

Mean KL Divergence: 0.05033
SB3 Clip Fraction: 0.16169
Policy Update Magnitude: 0.03395
Value Function Update Magnitude: 0.08110

Collected Steps per Second: 10,720.35112
Overall Steps per Second: 9,264.87595

Timestep Collection Time: 4.66421
Timestep Consumption Time: 0.73273
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 5.39694

Cumulative Model Updates: 4,892
Cumulative Timesteps: 81,676,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.14804
Policy Entropy: 1.12314
Value Function Loss: 5.21591

Mean KL Divergence: 0.02986
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.03233
Value Function Update Magnitude: 0.08843

Collected Steps per Second: 10,103.49345
Overall Steps per Second: 8,497.70032

Timestep Collection Time: 4.95136
Timestep Consumption Time: 0.93565
PPO Batch Consumption Time: 0.04784
Total Iteration Time: 5.88700

Cumulative Model Updates: 4,895
Cumulative Timesteps: 81,726,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 81726106...
Checkpoint 81726106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.48817
Policy Entropy: 1.10784
Value Function Loss: 5.27128

Mean KL Divergence: 0.04068
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.03518
Value Function Update Magnitude: 0.08224

Collected Steps per Second: 10,655.15774
Overall Steps per Second: 8,974.67634

Timestep Collection Time: 4.69275
Timestep Consumption Time: 0.87870
PPO Batch Consumption Time: 0.04769
Total Iteration Time: 5.57145

Cumulative Model Updates: 4,898
Cumulative Timesteps: 81,776,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.25684
Policy Entropy: 1.14287
Value Function Loss: 5.34127

Mean KL Divergence: 0.03355
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.03569
Value Function Update Magnitude: 0.06818

Collected Steps per Second: 10,885.38426
Overall Steps per Second: 9,175.16782

Timestep Collection Time: 4.59607
Timestep Consumption Time: 0.85669
PPO Batch Consumption Time: 0.04112
Total Iteration Time: 5.45276

Cumulative Model Updates: 4,901
Cumulative Timesteps: 81,826,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 81826138...
Checkpoint 81826138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.92067
Policy Entropy: 1.11314
Value Function Loss: 5.13613

Mean KL Divergence: 0.03920
SB3 Clip Fraction: 0.15913
Policy Update Magnitude: 0.03430
Value Function Update Magnitude: 0.06014

Collected Steps per Second: 10,709.92838
Overall Steps per Second: 9,148.44114

Timestep Collection Time: 4.66857
Timestep Consumption Time: 0.79685
PPO Batch Consumption Time: 0.04562
Total Iteration Time: 5.46541

Cumulative Model Updates: 4,904
Cumulative Timesteps: 81,876,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.40961
Policy Entropy: 1.13568
Value Function Loss: 5.42926

Mean KL Divergence: 0.03034
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.03206
Value Function Update Magnitude: 0.05768

Collected Steps per Second: 10,845.95524
Overall Steps per Second: 9,314.04959

Timestep Collection Time: 4.61223
Timestep Consumption Time: 0.75858
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.37081

Cumulative Model Updates: 4,907
Cumulative Timesteps: 81,926,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 81926162...
Checkpoint 81926162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.41947
Policy Entropy: 1.11778
Value Function Loss: 5.15953

Mean KL Divergence: 0.03600
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.03427
Value Function Update Magnitude: 0.06268

Collected Steps per Second: 10,704.03358
Overall Steps per Second: 9,073.30244

Timestep Collection Time: 4.67188
Timestep Consumption Time: 0.83967
PPO Batch Consumption Time: 0.04024
Total Iteration Time: 5.51155

Cumulative Model Updates: 4,910
Cumulative Timesteps: 81,976,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.00309
Policy Entropy: 1.13916
Value Function Loss: 5.23802

Mean KL Divergence: 0.03357
SB3 Clip Fraction: 0.15881
Policy Update Magnitude: 0.03545
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 10,151.49775
Overall Steps per Second: 8,725.09168

Timestep Collection Time: 4.92696
Timestep Consumption Time: 0.80547
PPO Batch Consumption Time: 0.04526
Total Iteration Time: 5.73243

Cumulative Model Updates: 4,913
Cumulative Timesteps: 82,026,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 82026186...
Checkpoint 82026186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.28538
Policy Entropy: 1.11810
Value Function Loss: 5.00072

Mean KL Divergence: 0.04141
SB3 Clip Fraction: 0.16036
Policy Update Magnitude: 0.03622
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 10,803.26122
Overall Steps per Second: 9,152.07011

Timestep Collection Time: 4.62971
Timestep Consumption Time: 0.83528
PPO Batch Consumption Time: 0.04665
Total Iteration Time: 5.46499

Cumulative Model Updates: 4,916
Cumulative Timesteps: 82,076,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.68557
Policy Entropy: 1.13416
Value Function Loss: 5.20699

Mean KL Divergence: 0.02916
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.03458
Value Function Update Magnitude: 0.06921

Collected Steps per Second: 10,716.57081
Overall Steps per Second: 9,088.04351

Timestep Collection Time: 4.66642
Timestep Consumption Time: 0.83620
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.50261

Cumulative Model Updates: 4,919
Cumulative Timesteps: 82,126,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 82126210...
Checkpoint 82126210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.83512
Policy Entropy: 1.11514
Value Function Loss: 5.25435

Mean KL Divergence: 0.04613
SB3 Clip Fraction: 0.16097
Policy Update Magnitude: 0.03501
Value Function Update Magnitude: 0.06201

Collected Steps per Second: 10,571.60921
Overall Steps per Second: 9,046.33657

Timestep Collection Time: 4.73249
Timestep Consumption Time: 0.79793
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 5.53042

Cumulative Model Updates: 4,922
Cumulative Timesteps: 82,176,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.29709
Policy Entropy: 1.13112
Value Function Loss: 5.27426

Mean KL Divergence: 0.02956
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.03256
Value Function Update Magnitude: 0.05750

Collected Steps per Second: 10,954.24508
Overall Steps per Second: 9,162.93166

Timestep Collection Time: 4.56535
Timestep Consumption Time: 0.89251
PPO Batch Consumption Time: 0.03991
Total Iteration Time: 5.45786

Cumulative Model Updates: 4,925
Cumulative Timesteps: 82,226,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 82226250...
Checkpoint 82226250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.80691
Policy Entropy: 1.11036
Value Function Loss: 5.21799

Mean KL Divergence: 0.04563
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.03631
Value Function Update Magnitude: 0.05302

Collected Steps per Second: 10,468.94499
Overall Steps per Second: 8,833.38516

Timestep Collection Time: 4.77813
Timestep Consumption Time: 0.88470
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.66283

Cumulative Model Updates: 4,928
Cumulative Timesteps: 82,276,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.95361
Policy Entropy: 1.13325
Value Function Loss: 5.18994

Mean KL Divergence: 0.03504
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.03468
Value Function Update Magnitude: 0.05032

Collected Steps per Second: 11,009.29612
Overall Steps per Second: 9,540.86863

Timestep Collection Time: 4.54325
Timestep Consumption Time: 0.69925
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 5.24250

Cumulative Model Updates: 4,931
Cumulative Timesteps: 82,326,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 82326290...
Checkpoint 82326290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.69738
Policy Entropy: 1.11257
Value Function Loss: 5.16798

Mean KL Divergence: 0.03515
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.03147
Value Function Update Magnitude: 0.05086

Collected Steps per Second: 10,934.44271
Overall Steps per Second: 9,228.60407

Timestep Collection Time: 4.57380
Timestep Consumption Time: 0.84543
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 5.41924

Cumulative Model Updates: 4,934
Cumulative Timesteps: 82,376,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.44953
Policy Entropy: 1.13230
Value Function Loss: 5.14784

Mean KL Divergence: 0.03651
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.03436
Value Function Update Magnitude: 0.05574

Collected Steps per Second: 10,928.14028
Overall Steps per Second: 9,441.41925

Timestep Collection Time: 4.57663
Timestep Consumption Time: 0.72067
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.29730

Cumulative Model Updates: 4,937
Cumulative Timesteps: 82,426,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 82426316...
Checkpoint 82426316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.89390
Policy Entropy: 1.11191
Value Function Loss: 5.13706

Mean KL Divergence: 0.03705
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.03343
Value Function Update Magnitude: 0.06188

Collected Steps per Second: 10,728.95796
Overall Steps per Second: 9,050.77914

Timestep Collection Time: 4.66308
Timestep Consumption Time: 0.86462
PPO Batch Consumption Time: 0.04622
Total Iteration Time: 5.52770

Cumulative Model Updates: 4,940
Cumulative Timesteps: 82,476,346

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.11728
Policy Entropy: 1.13439
Value Function Loss: 5.23250

Mean KL Divergence: 0.03131
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.03266
Value Function Update Magnitude: 0.08804

Collected Steps per Second: 10,632.37482
Overall Steps per Second: 8,878.22722

Timestep Collection Time: 4.70412
Timestep Consumption Time: 0.92943
PPO Batch Consumption Time: 0.04567
Total Iteration Time: 5.63356

Cumulative Model Updates: 4,943
Cumulative Timesteps: 82,526,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 82526362...
Checkpoint 82526362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.24193
Policy Entropy: 1.12002
Value Function Loss: 5.33718

Mean KL Divergence: 0.03891
SB3 Clip Fraction: 0.15398
Policy Update Magnitude: 0.03712
Value Function Update Magnitude: 0.11499

Collected Steps per Second: 10,035.77588
Overall Steps per Second: 8,697.53009

Timestep Collection Time: 4.98417
Timestep Consumption Time: 0.76689
PPO Batch Consumption Time: 0.04966
Total Iteration Time: 5.75106

Cumulative Model Updates: 4,946
Cumulative Timesteps: 82,576,382

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.81345
Policy Entropy: 1.14061
Value Function Loss: 5.28251

Mean KL Divergence: 0.03286
SB3 Clip Fraction: 0.14737
Policy Update Magnitude: 0.03289
Value Function Update Magnitude: 0.10645

Collected Steps per Second: 10,812.49509
Overall Steps per Second: 9,136.24516

Timestep Collection Time: 4.62465
Timestep Consumption Time: 0.84850
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.47315

Cumulative Model Updates: 4,949
Cumulative Timesteps: 82,626,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 82626386...
Checkpoint 82626386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.87763
Policy Entropy: 1.12200
Value Function Loss: 5.16162

Mean KL Divergence: 0.03849
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.03442
Value Function Update Magnitude: 0.09214

Collected Steps per Second: 10,646.75538
Overall Steps per Second: 9,134.88881

Timestep Collection Time: 4.69871
Timestep Consumption Time: 0.77766
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 5.47637

Cumulative Model Updates: 4,952
Cumulative Timesteps: 82,676,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.91675
Policy Entropy: 1.13982
Value Function Loss: 5.30069

Mean KL Divergence: 0.03408
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.03654
Value Function Update Magnitude: 0.08097

Collected Steps per Second: 10,813.02788
Overall Steps per Second: 9,072.57763

Timestep Collection Time: 4.62553
Timestep Consumption Time: 0.88735
PPO Batch Consumption Time: 0.04732
Total Iteration Time: 5.51288

Cumulative Model Updates: 4,955
Cumulative Timesteps: 82,726,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 82726428...
Checkpoint 82726428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.18187
Policy Entropy: 1.12754
Value Function Loss: 5.18568

Mean KL Divergence: 0.03705
SB3 Clip Fraction: 0.15121
Policy Update Magnitude: 0.03221
Value Function Update Magnitude: 0.06689

Collected Steps per Second: 10,672.35107
Overall Steps per Second: 9,119.29583

Timestep Collection Time: 4.68519
Timestep Consumption Time: 0.79791
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.48310

Cumulative Model Updates: 4,958
Cumulative Timesteps: 82,776,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.03932
Policy Entropy: 1.14775
Value Function Loss: 5.35903

Mean KL Divergence: 0.03096
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.03472
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 10,254.65389
Overall Steps per Second: 8,755.28531

Timestep Collection Time: 4.87779
Timestep Consumption Time: 0.83534
PPO Batch Consumption Time: 0.04601
Total Iteration Time: 5.71312

Cumulative Model Updates: 4,961
Cumulative Timesteps: 82,826,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 82826450...
Checkpoint 82826450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.33691
Policy Entropy: 1.12103
Value Function Loss: 5.07024

Mean KL Divergence: 0.04689
SB3 Clip Fraction: 0.15931
Policy Update Magnitude: 0.03900
Value Function Update Magnitude: 0.07144

Collected Steps per Second: 10,605.41386
Overall Steps per Second: 9,076.70904

Timestep Collection Time: 4.71684
Timestep Consumption Time: 0.79441
PPO Batch Consumption Time: 0.04066
Total Iteration Time: 5.51125

Cumulative Model Updates: 4,964
Cumulative Timesteps: 82,876,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.21623
Policy Entropy: 1.12669
Value Function Loss: 5.08956

Mean KL Divergence: 0.03219
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.03537
Value Function Update Magnitude: 0.06621

Collected Steps per Second: 10,666.06203
Overall Steps per Second: 9,131.05473

Timestep Collection Time: 4.68908
Timestep Consumption Time: 0.78827
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.47735

Cumulative Model Updates: 4,967
Cumulative Timesteps: 82,926,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 82926488...
Checkpoint 82926488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.24678
Policy Entropy: 1.10996
Value Function Loss: 4.82234

Mean KL Divergence: 0.04132
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.03553
Value Function Update Magnitude: 0.06174

Collected Steps per Second: 11,005.67649
Overall Steps per Second: 9,323.01713

Timestep Collection Time: 4.54311
Timestep Consumption Time: 0.81996
PPO Batch Consumption Time: 0.04186
Total Iteration Time: 5.36307

Cumulative Model Updates: 4,970
Cumulative Timesteps: 82,976,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.49429
Policy Entropy: 1.13409
Value Function Loss: 4.96809

Mean KL Divergence: 0.03101
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.03382
Value Function Update Magnitude: 0.05186

Collected Steps per Second: 10,753.54586
Overall Steps per Second: 9,091.90067

Timestep Collection Time: 4.65242
Timestep Consumption Time: 0.85028
PPO Batch Consumption Time: 0.03824
Total Iteration Time: 5.50270

Cumulative Model Updates: 4,973
Cumulative Timesteps: 83,026,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 83026518...
Checkpoint 83026518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.25162
Policy Entropy: 1.11888
Value Function Loss: 5.18724

Mean KL Divergence: 0.03749
SB3 Clip Fraction: 0.15222
Policy Update Magnitude: 0.03308
Value Function Update Magnitude: 0.05113

Collected Steps per Second: 11,028.90450
Overall Steps per Second: 9,225.22802

Timestep Collection Time: 4.53554
Timestep Consumption Time: 0.88677
PPO Batch Consumption Time: 0.04587
Total Iteration Time: 5.42231

Cumulative Model Updates: 4,976
Cumulative Timesteps: 83,076,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.58361
Policy Entropy: 1.12530
Value Function Loss: 5.28149

Mean KL Divergence: 0.03237
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.03650
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 10,181.45557
Overall Steps per Second: 8,695.35800

Timestep Collection Time: 4.91266
Timestep Consumption Time: 0.83961
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.75226

Cumulative Model Updates: 4,979
Cumulative Timesteps: 83,126,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 83126558...
Checkpoint 83126558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.25644
Policy Entropy: 1.10156
Value Function Loss: 5.17856

Mean KL Divergence: 0.03527
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.03118
Value Function Update Magnitude: 0.06276

Collected Steps per Second: 10,621.76240
Overall Steps per Second: 9,136.08015

Timestep Collection Time: 4.70845
Timestep Consumption Time: 0.76567
PPO Batch Consumption Time: 0.04504
Total Iteration Time: 5.47412

Cumulative Model Updates: 4,982
Cumulative Timesteps: 83,176,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.29458
Policy Entropy: 1.12414
Value Function Loss: 5.10267

Mean KL Divergence: 0.03408
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.03909
Value Function Update Magnitude: 0.06244

Collected Steps per Second: 10,679.85832
Overall Steps per Second: 9,013.10387

Timestep Collection Time: 4.68377
Timestep Consumption Time: 0.86615
PPO Batch Consumption Time: 0.04024
Total Iteration Time: 5.54992

Cumulative Model Updates: 4,985
Cumulative Timesteps: 83,226,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 83226592...
Checkpoint 83226592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.05118
Policy Entropy: 1.11738
Value Function Loss: 5.09906

Mean KL Divergence: 0.03611
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.03745
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 10,985.52988
Overall Steps per Second: 9,321.28918

Timestep Collection Time: 4.55235
Timestep Consumption Time: 0.81279
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.36514

Cumulative Model Updates: 4,988
Cumulative Timesteps: 83,276,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.85109
Policy Entropy: 1.14044
Value Function Loss: 5.22077

Mean KL Divergence: 0.02876
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.03627
Value Function Update Magnitude: 0.05802

Collected Steps per Second: 11,240.70355
Overall Steps per Second: 9,409.05871

Timestep Collection Time: 4.45061
Timestep Consumption Time: 0.86639
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 5.31700

Cumulative Model Updates: 4,991
Cumulative Timesteps: 83,326,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 83326630...
Checkpoint 83326630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.70301
Policy Entropy: 1.12971
Value Function Loss: 5.10884

Mean KL Divergence: 0.03794
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.03801
Value Function Update Magnitude: 0.07004

Collected Steps per Second: 10,199.26175
Overall Steps per Second: 8,635.68189

Timestep Collection Time: 4.90506
Timestep Consumption Time: 0.88811
PPO Batch Consumption Time: 0.04307
Total Iteration Time: 5.79317

Cumulative Model Updates: 4,994
Cumulative Timesteps: 83,376,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.15994
Policy Entropy: 1.14212
Value Function Loss: 5.34803

Mean KL Divergence: 0.02678
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.03327
Value Function Update Magnitude: 0.06592

Collected Steps per Second: 11,183.08976
Overall Steps per Second: 9,507.75594

Timestep Collection Time: 4.47372
Timestep Consumption Time: 0.78830
PPO Batch Consumption Time: 0.04612
Total Iteration Time: 5.26202

Cumulative Model Updates: 4,997
Cumulative Timesteps: 83,426,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 83426688...
Checkpoint 83426688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.69918
Policy Entropy: 1.12548
Value Function Loss: 5.35446

Mean KL Divergence: 0.03543
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.03636
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 11,190.18224
Overall Steps per Second: 9,440.86492

Timestep Collection Time: 4.47088
Timestep Consumption Time: 0.82842
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.29930

Cumulative Model Updates: 5,000
Cumulative Timesteps: 83,476,718

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.28282
Policy Entropy: 1.14145
Value Function Loss: 5.54290

Mean KL Divergence: 0.03329
SB3 Clip Fraction: 0.14752
Policy Update Magnitude: 0.03619
Value Function Update Magnitude: 0.06846

Collected Steps per Second: 10,975.58866
Overall Steps per Second: 9,398.58615

Timestep Collection Time: 4.55629
Timestep Consumption Time: 0.76451
PPO Batch Consumption Time: 0.03872
Total Iteration Time: 5.32080

Cumulative Model Updates: 5,003
Cumulative Timesteps: 83,526,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 83526726...
Checkpoint 83526726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.97891
Policy Entropy: 1.12144
Value Function Loss: 5.34169

Mean KL Divergence: 0.02883
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.03523
Value Function Update Magnitude: 0.06189

Collected Steps per Second: 10,801.30803
Overall Steps per Second: 9,138.05769

Timestep Collection Time: 4.62999
Timestep Consumption Time: 0.84272
PPO Batch Consumption Time: 0.04293
Total Iteration Time: 5.47272

Cumulative Model Updates: 5,006
Cumulative Timesteps: 83,576,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.80318
Policy Entropy: 1.14468
Value Function Loss: 5.29842

Mean KL Divergence: 0.03298
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.03992
Value Function Update Magnitude: 0.07053

Collected Steps per Second: 10,667.25080
Overall Steps per Second: 9,037.66142

Timestep Collection Time: 4.68931
Timestep Consumption Time: 0.84553
PPO Batch Consumption Time: 0.04070
Total Iteration Time: 5.53484

Cumulative Model Updates: 5,009
Cumulative Timesteps: 83,626,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 83626758...
Checkpoint 83626758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.35403
Policy Entropy: 1.13053
Value Function Loss: 5.07945

Mean KL Divergence: 0.03626
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.03747
Value Function Update Magnitude: 0.06832

Collected Steps per Second: 10,310.51888
Overall Steps per Second: 8,976.73335

Timestep Collection Time: 4.85077
Timestep Consumption Time: 0.72074
PPO Batch Consumption Time: 0.04052
Total Iteration Time: 5.57151

Cumulative Model Updates: 5,012
Cumulative Timesteps: 83,676,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.47619
Policy Entropy: 1.14988
Value Function Loss: 5.15567

Mean KL Divergence: 0.02683
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.04008
Value Function Update Magnitude: 0.07103

Collected Steps per Second: 10,910.57598
Overall Steps per Second: 9,232.21717

Timestep Collection Time: 4.58528
Timestep Consumption Time: 0.83357
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.41885

Cumulative Model Updates: 5,015
Cumulative Timesteps: 83,726,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 83726800...
Checkpoint 83726800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.50154
Policy Entropy: 1.13448
Value Function Loss: 5.00216

Mean KL Divergence: 0.03722
SB3 Clip Fraction: 0.15090
Policy Update Magnitude: 0.04412
Value Function Update Magnitude: 0.07932

Collected Steps per Second: 10,542.05003
Overall Steps per Second: 9,140.95741

Timestep Collection Time: 4.74500
Timestep Consumption Time: 0.72730
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.47229

Cumulative Model Updates: 5,018
Cumulative Timesteps: 83,776,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.74068
Policy Entropy: 1.15167
Value Function Loss: 4.95960

Mean KL Divergence: 0.03250
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.08578

Collected Steps per Second: 10,751.10510
Overall Steps per Second: 9,186.31358

Timestep Collection Time: 4.65273
Timestep Consumption Time: 0.79254
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 5.44527

Cumulative Model Updates: 5,021
Cumulative Timesteps: 83,826,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 83826844...
Checkpoint 83826844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.40820
Policy Entropy: 1.13268
Value Function Loss: 4.89914

Mean KL Divergence: 0.03123
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.04148
Value Function Update Magnitude: 0.07478

Collected Steps per Second: 10,683.50938
Overall Steps per Second: 9,101.90055

Timestep Collection Time: 4.68067
Timestep Consumption Time: 0.81335
PPO Batch Consumption Time: 0.04535
Total Iteration Time: 5.49402

Cumulative Model Updates: 5,024
Cumulative Timesteps: 83,876,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.49210
Policy Entropy: 1.14201
Value Function Loss: 5.14432

Mean KL Divergence: 0.03253
SB3 Clip Fraction: 0.14829
Policy Update Magnitude: 0.04102
Value Function Update Magnitude: 0.07575

Collected Steps per Second: 10,421.26752
Overall Steps per Second: 8,898.07694

Timestep Collection Time: 4.79961
Timestep Consumption Time: 0.82161
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 5.62121

Cumulative Model Updates: 5,027
Cumulative Timesteps: 83,926,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 83926868...
Checkpoint 83926868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.55863
Policy Entropy: 1.12143
Value Function Loss: 5.36973

Mean KL Divergence: 0.03036
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.03929
Value Function Update Magnitude: 0.07410

Collected Steps per Second: 10,889.26328
Overall Steps per Second: 9,274.97910

Timestep Collection Time: 4.59425
Timestep Consumption Time: 0.79962
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 5.39387

Cumulative Model Updates: 5,030
Cumulative Timesteps: 83,976,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.42968
Policy Entropy: 1.13692
Value Function Loss: 5.54298

Mean KL Divergence: 0.02689
SB3 Clip Fraction: 0.13950
Policy Update Magnitude: 0.03718
Value Function Update Magnitude: 0.07081

Collected Steps per Second: 10,863.43783
Overall Steps per Second: 9,359.58393

Timestep Collection Time: 4.60388
Timestep Consumption Time: 0.73973
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.34361

Cumulative Model Updates: 5,033
Cumulative Timesteps: 84,026,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 84026910...
Checkpoint 84026910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.43617
Policy Entropy: 1.12770
Value Function Loss: 5.48015

Mean KL Divergence: 0.03479
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.04133
Value Function Update Magnitude: 0.06195

Collected Steps per Second: 10,833.05936
Overall Steps per Second: 9,159.35386

Timestep Collection Time: 4.61698
Timestep Consumption Time: 0.84367
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 5.46065

Cumulative Model Updates: 5,036
Cumulative Timesteps: 84,076,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.79613
Policy Entropy: 1.14662
Value Function Loss: 5.56515

Mean KL Divergence: 0.02910
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.03786
Value Function Update Magnitude: 0.05348

Collected Steps per Second: 10,571.28355
Overall Steps per Second: 9,018.23884

Timestep Collection Time: 4.73244
Timestep Consumption Time: 0.81498
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 5.54742

Cumulative Model Updates: 5,039
Cumulative Timesteps: 84,126,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 84126954...
Checkpoint 84126954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.10235
Policy Entropy: 1.13084
Value Function Loss: 5.56382

Mean KL Divergence: 0.03325
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.04650

Collected Steps per Second: 10,867.13754
Overall Steps per Second: 9,043.79527

Timestep Collection Time: 4.60360
Timestep Consumption Time: 0.92814
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 5.53175

Cumulative Model Updates: 5,042
Cumulative Timesteps: 84,176,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.83110
Policy Entropy: 1.13891
Value Function Loss: 5.55243

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.04345
Value Function Update Magnitude: 0.04160

Collected Steps per Second: 10,790.51036
Overall Steps per Second: 9,082.25228

Timestep Collection Time: 4.63630
Timestep Consumption Time: 0.87203
PPO Batch Consumption Time: 0.04467
Total Iteration Time: 5.50833

Cumulative Model Updates: 5,045
Cumulative Timesteps: 84,227,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 84227010...
Checkpoint 84227010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.49316
Policy Entropy: 1.12399
Value Function Loss: 5.59798

Mean KL Divergence: 0.03326
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.04259

Collected Steps per Second: 10,756.49228
Overall Steps per Second: 9,156.40261

Timestep Collection Time: 4.64947
Timestep Consumption Time: 0.81250
PPO Batch Consumption Time: 0.04459
Total Iteration Time: 5.46197

Cumulative Model Updates: 5,048
Cumulative Timesteps: 84,277,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.55591
Policy Entropy: 1.15083
Value Function Loss: 5.51211

Mean KL Divergence: 0.02731
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.04443

Collected Steps per Second: 10,293.02045
Overall Steps per Second: 8,667.12978

Timestep Collection Time: 4.86038
Timestep Consumption Time: 0.91177
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 5.77215

Cumulative Model Updates: 5,051
Cumulative Timesteps: 84,327,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 84327050...
Checkpoint 84327050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.22754
Policy Entropy: 1.14147
Value Function Loss: 5.75397

Mean KL Divergence: 0.03302
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.04124

Collected Steps per Second: 10,803.46268
Overall Steps per Second: 9,111.10196

Timestep Collection Time: 4.63129
Timestep Consumption Time: 0.86025
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 5.49154

Cumulative Model Updates: 5,054
Cumulative Timesteps: 84,377,084

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.54473
Policy Entropy: 1.15211
Value Function Loss: 5.64843

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.04324
Value Function Update Magnitude: 0.03572

Collected Steps per Second: 10,796.41570
Overall Steps per Second: 9,128.44921

Timestep Collection Time: 4.63228
Timestep Consumption Time: 0.84642
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.47870

Cumulative Model Updates: 5,057
Cumulative Timesteps: 84,427,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 84427096...
Checkpoint 84427096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.83141
Policy Entropy: 1.13901
Value Function Loss: 5.75796

Mean KL Divergence: 0.03210
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.04502
Value Function Update Magnitude: 0.04559

Collected Steps per Second: 10,406.86415
Overall Steps per Second: 8,745.07065

Timestep Collection Time: 4.80606
Timestep Consumption Time: 0.91328
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 5.71934

Cumulative Model Updates: 5,060
Cumulative Timesteps: 84,477,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.15162
Policy Entropy: 1.16254
Value Function Loss: 5.23844

Mean KL Divergence: 0.02884
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.04547
Value Function Update Magnitude: 0.03959

Collected Steps per Second: 10,795.18129
Overall Steps per Second: 9,296.48811

Timestep Collection Time: 4.63392
Timestep Consumption Time: 0.74704
PPO Batch Consumption Time: 0.04101
Total Iteration Time: 5.38096

Cumulative Model Updates: 5,063
Cumulative Timesteps: 84,527,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 84527136...
Checkpoint 84527136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.94742
Policy Entropy: 1.13943
Value Function Loss: 5.12675

Mean KL Divergence: 0.03565
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.03507

Collected Steps per Second: 10,725.31181
Overall Steps per Second: 8,966.25627

Timestep Collection Time: 4.66280
Timestep Consumption Time: 0.91478
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 5.57758

Cumulative Model Updates: 5,066
Cumulative Timesteps: 84,577,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.10030
Policy Entropy: 1.14457
Value Function Loss: 4.87278

Mean KL Divergence: 0.03055
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.04465

Collected Steps per Second: 10,810.73885
Overall Steps per Second: 9,129.41875

Timestep Collection Time: 4.62725
Timestep Consumption Time: 0.85218
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.47943

Cumulative Model Updates: 5,069
Cumulative Timesteps: 84,627,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 84627170...
Checkpoint 84627170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.61877
Policy Entropy: 1.12340
Value Function Loss: 5.11154

Mean KL Divergence: 0.03240
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.04044

Collected Steps per Second: 10,952.26159
Overall Steps per Second: 9,273.28848

Timestep Collection Time: 4.56618
Timestep Consumption Time: 0.82673
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.39291

Cumulative Model Updates: 5,072
Cumulative Timesteps: 84,677,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.78901
Policy Entropy: 1.14886
Value Function Loss: 5.28342

Mean KL Divergence: 0.02666
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.04185
Value Function Update Magnitude: 0.04896

Collected Steps per Second: 10,440.01236
Overall Steps per Second: 8,813.05397

Timestep Collection Time: 4.78965
Timestep Consumption Time: 0.88421
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 5.67386

Cumulative Model Updates: 5,075
Cumulative Timesteps: 84,727,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 84727184...
Checkpoint 84727184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.41997
Policy Entropy: 1.13980
Value Function Loss: 5.39142

Mean KL Divergence: 0.03172
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.04553

Collected Steps per Second: 10,799.76394
Overall Steps per Second: 9,307.91525

Timestep Collection Time: 4.63010
Timestep Consumption Time: 0.74210
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 5.37220

Cumulative Model Updates: 5,078
Cumulative Timesteps: 84,777,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.51440
Policy Entropy: 1.14284
Value Function Loss: 5.24086

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.05926
Value Function Update Magnitude: 0.03889

Collected Steps per Second: 10,598.67556
Overall Steps per Second: 8,991.31393

Timestep Collection Time: 4.71908
Timestep Consumption Time: 0.84362
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 5.56270

Cumulative Model Updates: 5,081
Cumulative Timesteps: 84,827,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 84827204...
Checkpoint 84827204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.17411
Policy Entropy: 1.12115
Value Function Loss: 5.00227

Mean KL Divergence: 0.03416
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.05530

Collected Steps per Second: 10,648.75087
Overall Steps per Second: 9,133.48375

Timestep Collection Time: 4.69539
Timestep Consumption Time: 0.77898
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.47436

Cumulative Model Updates: 5,084
Cumulative Timesteps: 84,877,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.43207
Policy Entropy: 1.14881
Value Function Loss: 5.09784

Mean KL Divergence: 0.02929
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.06001

Collected Steps per Second: 10,862.07102
Overall Steps per Second: 9,082.23688

Timestep Collection Time: 4.60501
Timestep Consumption Time: 0.90244
PPO Batch Consumption Time: 0.04351
Total Iteration Time: 5.50745

Cumulative Model Updates: 5,087
Cumulative Timesteps: 84,927,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 84927224...
Checkpoint 84927224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.97011
Policy Entropy: 1.15351
Value Function Loss: 5.05536

Mean KL Divergence: 0.03583
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.07340

Collected Steps per Second: 10,651.07684
Overall Steps per Second: 9,064.36475

Timestep Collection Time: 4.69455
Timestep Consumption Time: 0.82178
PPO Batch Consumption Time: 0.03955
Total Iteration Time: 5.51633

Cumulative Model Updates: 5,090
Cumulative Timesteps: 84,977,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.76299
Policy Entropy: 1.17384
Value Function Loss: 5.29256

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.03896
Value Function Update Magnitude: 0.06829

Collected Steps per Second: 10,244.97010
Overall Steps per Second: 8,884.05995

Timestep Collection Time: 4.88240
Timestep Consumption Time: 0.74791
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.63031

Cumulative Model Updates: 5,093
Cumulative Timesteps: 85,027,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 85027246...
Checkpoint 85027246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.73656
Policy Entropy: 1.14302
Value Function Loss: 5.29422

Mean KL Divergence: 0.03241
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.03637
Value Function Update Magnitude: 0.05935

Collected Steps per Second: 10,753.72434
Overall Steps per Second: 9,011.66296

Timestep Collection Time: 4.65216
Timestep Consumption Time: 0.89932
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 5.55147

Cumulative Model Updates: 5,096
Cumulative Timesteps: 85,077,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.45295
Policy Entropy: 1.14964
Value Function Loss: 5.41868

Mean KL Divergence: 0.02764
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.04068
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 10,603.76940
Overall Steps per Second: 9,098.91660

Timestep Collection Time: 4.71757
Timestep Consumption Time: 0.78023
PPO Batch Consumption Time: 0.04007
Total Iteration Time: 5.49780

Cumulative Model Updates: 5,099
Cumulative Timesteps: 85,127,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 85127298...
Checkpoint 85127298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.36793
Policy Entropy: 1.13708
Value Function Loss: 5.20760

Mean KL Divergence: 0.03207
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.03796
Value Function Update Magnitude: 0.04968

Collected Steps per Second: 10,715.71707
Overall Steps per Second: 9,039.94919

Timestep Collection Time: 4.66866
Timestep Consumption Time: 0.86545
PPO Batch Consumption Time: 0.03900
Total Iteration Time: 5.53410

Cumulative Model Updates: 5,102
Cumulative Timesteps: 85,177,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.93663
Policy Entropy: 1.16346
Value Function Loss: 5.27216

Mean KL Divergence: 0.02919
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.03792
Value Function Update Magnitude: 0.05280

Collected Steps per Second: 10,398.41157
Overall Steps per Second: 8,910.68410

Timestep Collection Time: 4.81093
Timestep Consumption Time: 0.80323
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 5.61416

Cumulative Model Updates: 5,105
Cumulative Timesteps: 85,227,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 85227352...
Checkpoint 85227352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.82919
Policy Entropy: 1.15017
Value Function Loss: 5.00687

Mean KL Divergence: 0.03622
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.03672
Value Function Update Magnitude: 0.06159

Collected Steps per Second: 10,081.96468
Overall Steps per Second: 8,797.02565

Timestep Collection Time: 4.96193
Timestep Consumption Time: 0.72477
PPO Batch Consumption Time: 0.03809
Total Iteration Time: 5.68669

Cumulative Model Updates: 5,108
Cumulative Timesteps: 85,277,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.55396
Policy Entropy: 1.15655
Value Function Loss: 5.12405

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.03831
Value Function Update Magnitude: 0.05757

Collected Steps per Second: 10,611.11553
Overall Steps per Second: 8,993.81239

Timestep Collection Time: 4.71430
Timestep Consumption Time: 0.84774
PPO Batch Consumption Time: 0.04114
Total Iteration Time: 5.56205

Cumulative Model Updates: 5,111
Cumulative Timesteps: 85,327,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 85327402...
Checkpoint 85327402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.33583
Policy Entropy: 1.13875
Value Function Loss: 5.11437

Mean KL Divergence: 0.03794
SB3 Clip Fraction: 0.15089
Policy Update Magnitude: 0.03567
Value Function Update Magnitude: 0.05756

Collected Steps per Second: 10,760.53832
Overall Steps per Second: 9,193.81629

Timestep Collection Time: 4.64754
Timestep Consumption Time: 0.79199
PPO Batch Consumption Time: 0.04114
Total Iteration Time: 5.43953

Cumulative Model Updates: 5,114
Cumulative Timesteps: 85,377,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.33517
Policy Entropy: 1.15148
Value Function Loss: 5.40318

Mean KL Divergence: 0.02556
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.03354
Value Function Update Magnitude: 0.06474

Collected Steps per Second: 10,434.15311
Overall Steps per Second: 8,804.75325

Timestep Collection Time: 4.79330
Timestep Consumption Time: 0.88704
PPO Batch Consumption Time: 0.04335
Total Iteration Time: 5.68034

Cumulative Model Updates: 5,117
Cumulative Timesteps: 85,427,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 85427426...
Checkpoint 85427426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.45603
Policy Entropy: 1.12792
Value Function Loss: 5.36099

Mean KL Divergence: 0.03670
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.03678
Value Function Update Magnitude: 0.06225

Collected Steps per Second: 10,923.46082
Overall Steps per Second: 9,203.26816

Timestep Collection Time: 4.57767
Timestep Consumption Time: 0.85562
PPO Batch Consumption Time: 0.04849
Total Iteration Time: 5.43329

Cumulative Model Updates: 5,120
Cumulative Timesteps: 85,477,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.74599
Policy Entropy: 1.15969
Value Function Loss: 5.10880

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.07024

Collected Steps per Second: 10,805.99666
Overall Steps per Second: 9,195.12400

Timestep Collection Time: 4.62780
Timestep Consumption Time: 0.81073
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 5.43853

Cumulative Model Updates: 5,123
Cumulative Timesteps: 85,527,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 85527438...
Checkpoint 85527438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.33003
Policy Entropy: 1.14496
Value Function Loss: 4.94326

Mean KL Divergence: 0.04355
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.04103
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 10,714.83393
Overall Steps per Second: 8,989.90005

Timestep Collection Time: 4.66773
Timestep Consumption Time: 0.89562
PPO Batch Consumption Time: 0.04354
Total Iteration Time: 5.56335

Cumulative Model Updates: 5,126
Cumulative Timesteps: 85,577,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.53776
Policy Entropy: 1.16955
Value Function Loss: 4.94828

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.03744
Value Function Update Magnitude: 0.06123

Collected Steps per Second: 10,909.91366
Overall Steps per Second: 9,286.44013

Timestep Collection Time: 4.58592
Timestep Consumption Time: 0.80172
PPO Batch Consumption Time: 0.04186
Total Iteration Time: 5.38764

Cumulative Model Updates: 5,129
Cumulative Timesteps: 85,627,484

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 85627484...
Checkpoint 85627484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.47696
Policy Entropy: 1.13792
Value Function Loss: 5.11541

Mean KL Divergence: 0.03124
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.04179
Value Function Update Magnitude: 0.04943

Collected Steps per Second: 11,096.10372
Overall Steps per Second: 9,279.04386

Timestep Collection Time: 4.50645
Timestep Consumption Time: 0.88247
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 5.38892

Cumulative Model Updates: 5,132
Cumulative Timesteps: 85,677,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.52740
Policy Entropy: 1.15280
Value Function Loss: 5.04548

Mean KL Divergence: 0.02955
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.04352

Collected Steps per Second: 10,841.81169
Overall Steps per Second: 8,983.26770

Timestep Collection Time: 4.61344
Timestep Consumption Time: 0.95447
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 5.56791

Cumulative Model Updates: 5,135
Cumulative Timesteps: 85,727,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 85727506...
Checkpoint 85727506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.83210
Policy Entropy: 1.14070
Value Function Loss: 5.09843

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.04112
Value Function Update Magnitude: 0.04662

Collected Steps per Second: 10,500.69129
Overall Steps per Second: 9,069.14982

Timestep Collection Time: 4.76197
Timestep Consumption Time: 0.75166
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 5.51364

Cumulative Model Updates: 5,138
Cumulative Timesteps: 85,777,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.63985
Policy Entropy: 1.16659
Value Function Loss: 4.99336

Mean KL Divergence: 0.02763
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.04175

Collected Steps per Second: 9,925.79018
Overall Steps per Second: 8,467.30015

Timestep Collection Time: 5.03839
Timestep Consumption Time: 0.86786
PPO Batch Consumption Time: 0.04803
Total Iteration Time: 5.90625

Cumulative Model Updates: 5,141
Cumulative Timesteps: 85,827,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 85827520...
Checkpoint 85827520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.81415
Policy Entropy: 1.14849
Value Function Loss: 5.16480

Mean KL Divergence: 0.03641
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.03896

Collected Steps per Second: 10,484.70841
Overall Steps per Second: 9,089.67090

Timestep Collection Time: 4.76942
Timestep Consumption Time: 0.73199
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 5.50141

Cumulative Model Updates: 5,144
Cumulative Timesteps: 85,877,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.86603
Policy Entropy: 1.16576
Value Function Loss: 5.35497

Mean KL Divergence: 0.02634
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.04299
Value Function Update Magnitude: 0.04995

Collected Steps per Second: 10,776.72512
Overall Steps per Second: 9,104.35730

Timestep Collection Time: 4.64223
Timestep Consumption Time: 0.85272
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 5.49495

Cumulative Model Updates: 5,147
Cumulative Timesteps: 85,927,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 85927554...
Checkpoint 85927554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.68938
Policy Entropy: 1.14378
Value Function Loss: 5.27602

Mean KL Divergence: 0.03113
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 10,562.09486
Overall Steps per Second: 9,037.93264

Timestep Collection Time: 4.73429
Timestep Consumption Time: 0.79839
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 5.53268

Cumulative Model Updates: 5,150
Cumulative Timesteps: 85,977,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.07328
Policy Entropy: 1.15647
Value Function Loss: 5.11481

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.05271

Collected Steps per Second: 10,947.43354
Overall Steps per Second: 9,264.09944

Timestep Collection Time: 4.56984
Timestep Consumption Time: 0.83036
PPO Batch Consumption Time: 0.03780
Total Iteration Time: 5.40020

Cumulative Model Updates: 5,153
Cumulative Timesteps: 86,027,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 86027586...
Checkpoint 86027586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.04832
Policy Entropy: 1.13651
Value Function Loss: 4.87299

Mean KL Divergence: 0.04004
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.05570

Collected Steps per Second: 10,077.83536
Overall Steps per Second: 8,552.44498

Timestep Collection Time: 4.96138
Timestep Consumption Time: 0.88490
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 5.84628

Cumulative Model Updates: 5,156
Cumulative Timesteps: 86,077,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.13884
Policy Entropy: 1.15210
Value Function Loss: 5.00489

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.04110

Collected Steps per Second: 10,691.59694
Overall Steps per Second: 9,159.14843

Timestep Collection Time: 4.67938
Timestep Consumption Time: 0.78292
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 5.46230

Cumulative Model Updates: 5,159
Cumulative Timesteps: 86,127,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 86127616...
Checkpoint 86127616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.67462
Policy Entropy: 1.13920
Value Function Loss: 5.08159

Mean KL Divergence: 0.03517
SB3 Clip Fraction: 0.15299
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.04273

Collected Steps per Second: 10,739.19689
Overall Steps per Second: 9,141.80911

Timestep Collection Time: 4.65621
Timestep Consumption Time: 0.81360
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 5.46981

Cumulative Model Updates: 5,162
Cumulative Timesteps: 86,177,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.16491
Policy Entropy: 1.15062
Value Function Loss: 5.09005

Mean KL Divergence: 0.02947
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.03898

Collected Steps per Second: 10,292.38613
Overall Steps per Second: 8,703.57567

Timestep Collection Time: 4.86126
Timestep Consumption Time: 0.88741
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 5.74867

Cumulative Model Updates: 5,165
Cumulative Timesteps: 86,227,654

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 86227654...
Checkpoint 86227654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.02284
Policy Entropy: 1.14451
Value Function Loss: 4.91572

Mean KL Divergence: 0.03492
SB3 Clip Fraction: 0.15441
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.03693

Collected Steps per Second: 10,599.57469
Overall Steps per Second: 8,967.74557

Timestep Collection Time: 4.72151
Timestep Consumption Time: 0.85916
PPO Batch Consumption Time: 0.04363
Total Iteration Time: 5.58067

Cumulative Model Updates: 5,168
Cumulative Timesteps: 86,277,700

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.84252
Policy Entropy: 1.15340
Value Function Loss: 4.78247

Mean KL Divergence: 0.03573
SB3 Clip Fraction: 0.14709
Policy Update Magnitude: 0.04189
Value Function Update Magnitude: 0.03812

Collected Steps per Second: 10,690.85076
Overall Steps per Second: 9,016.63259

Timestep Collection Time: 4.67895
Timestep Consumption Time: 0.86879
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 5.54775

Cumulative Model Updates: 5,171
Cumulative Timesteps: 86,327,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 86327722...
Checkpoint 86327722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.66828
Policy Entropy: 1.14620
Value Function Loss: 4.82110

Mean KL Divergence: 0.03536
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.04280
Value Function Update Magnitude: 0.03850

Collected Steps per Second: 10,134.26267
Overall Steps per Second: 8,771.29380

Timestep Collection Time: 4.93474
Timestep Consumption Time: 0.76681
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.70155

Cumulative Model Updates: 5,174
Cumulative Timesteps: 86,377,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.42437
Policy Entropy: 1.15931
Value Function Loss: 5.06916

Mean KL Divergence: 0.02928
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.03737

Collected Steps per Second: 10,335.44887
Overall Steps per Second: 8,791.43334

Timestep Collection Time: 4.83869
Timestep Consumption Time: 0.84981
PPO Batch Consumption Time: 0.04050
Total Iteration Time: 5.68849

Cumulative Model Updates: 5,177
Cumulative Timesteps: 86,427,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 86427742...
Checkpoint 86427742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.39751
Policy Entropy: 1.14171
Value Function Loss: 5.21512

Mean KL Divergence: 0.03960
SB3 Clip Fraction: 0.15998
Policy Update Magnitude: 0.04023
Value Function Update Magnitude: 0.04691

Collected Steps per Second: 10,640.34807
Overall Steps per Second: 9,027.97780

Timestep Collection Time: 4.70116
Timestep Consumption Time: 0.83961
PPO Batch Consumption Time: 0.04687
Total Iteration Time: 5.54078

Cumulative Model Updates: 5,180
Cumulative Timesteps: 86,477,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.99206
Policy Entropy: 1.15650
Value Function Loss: 5.29264

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.05016

Collected Steps per Second: 10,782.12993
Overall Steps per Second: 9,061.76822

Timestep Collection Time: 4.63916
Timestep Consumption Time: 0.88074
PPO Batch Consumption Time: 0.04620
Total Iteration Time: 5.51989

Cumulative Model Updates: 5,183
Cumulative Timesteps: 86,527,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 86527784...
Checkpoint 86527784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.80686
Policy Entropy: 1.12156
Value Function Loss: 5.25669

Mean KL Divergence: 0.03950
SB3 Clip Fraction: 0.16532
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.04621

Collected Steps per Second: 10,809.28893
Overall Steps per Second: 9,131.22502

Timestep Collection Time: 4.62658
Timestep Consumption Time: 0.85024
PPO Batch Consumption Time: 0.04096
Total Iteration Time: 5.47681

Cumulative Model Updates: 5,186
Cumulative Timesteps: 86,577,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.94941
Policy Entropy: 1.14328
Value Function Loss: 5.39806

Mean KL Divergence: 0.02856
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.04602

Collected Steps per Second: 10,430.20738
Overall Steps per Second: 8,999.82497

Timestep Collection Time: 4.79664
Timestep Consumption Time: 0.76235
PPO Batch Consumption Time: 0.04612
Total Iteration Time: 5.55900

Cumulative Model Updates: 5,189
Cumulative Timesteps: 86,627,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 86627824...
Checkpoint 86627824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.36259
Policy Entropy: 1.12671
Value Function Loss: 5.35389

Mean KL Divergence: 0.04133
SB3 Clip Fraction: 0.15610
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.04096

Collected Steps per Second: 10,909.78943
Overall Steps per Second: 9,221.50142

Timestep Collection Time: 4.58579
Timestep Consumption Time: 0.83957
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.42536

Cumulative Model Updates: 5,192
Cumulative Timesteps: 86,677,854

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.62461
Policy Entropy: 1.14462
Value Function Loss: 5.27504

Mean KL Divergence: 0.02943
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.04098
Value Function Update Magnitude: 0.04022

Collected Steps per Second: 10,857.82952
Overall Steps per Second: 9,207.77214

Timestep Collection Time: 4.60755
Timestep Consumption Time: 0.82569
PPO Batch Consumption Time: 0.04743
Total Iteration Time: 5.43324

Cumulative Model Updates: 5,195
Cumulative Timesteps: 86,727,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 86727882...
Checkpoint 86727882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.19731
Policy Entropy: 1.13101
Value Function Loss: 5.29009

Mean KL Divergence: 0.03323
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.03927

Collected Steps per Second: 10,897.81185
Overall Steps per Second: 9,223.10892

Timestep Collection Time: 4.58881
Timestep Consumption Time: 0.83322
PPO Batch Consumption Time: 0.03865
Total Iteration Time: 5.42203

Cumulative Model Updates: 5,198
Cumulative Timesteps: 86,777,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.59310
Policy Entropy: 1.14030
Value Function Loss: 5.45398

Mean KL Divergence: 0.03618
SB3 Clip Fraction: 0.16647
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.04200

Collected Steps per Second: 10,705.94368
Overall Steps per Second: 9,037.22763

Timestep Collection Time: 4.67311
Timestep Consumption Time: 0.86288
PPO Batch Consumption Time: 0.04206
Total Iteration Time: 5.53599

Cumulative Model Updates: 5,201
Cumulative Timesteps: 86,827,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 86827920...
Checkpoint 86827920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.89061
Policy Entropy: 1.13138
Value Function Loss: 5.28080

Mean KL Divergence: 0.03123
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.04167

Collected Steps per Second: 10,780.65380
Overall Steps per Second: 9,008.89383

Timestep Collection Time: 4.64072
Timestep Consumption Time: 0.91268
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 5.55340

Cumulative Model Updates: 5,204
Cumulative Timesteps: 86,877,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.71867
Policy Entropy: 1.14617
Value Function Loss: 5.25019

Mean KL Divergence: 0.02918
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.04132

Collected Steps per Second: 10,688.80135
Overall Steps per Second: 9,089.89652

Timestep Collection Time: 4.67798
Timestep Consumption Time: 0.82285
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.50083

Cumulative Model Updates: 5,207
Cumulative Timesteps: 86,927,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 86927952...
Checkpoint 86927952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.51543
Policy Entropy: 1.13037
Value Function Loss: 5.11846

Mean KL Divergence: 0.04138
SB3 Clip Fraction: 0.16102
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.04507

Collected Steps per Second: 10,838.29744
Overall Steps per Second: 9,178.12211

Timestep Collection Time: 4.61327
Timestep Consumption Time: 0.83447
PPO Batch Consumption Time: 0.04161
Total Iteration Time: 5.44774

Cumulative Model Updates: 5,210
Cumulative Timesteps: 86,977,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.02373
Policy Entropy: 1.14099
Value Function Loss: 5.23206

Mean KL Divergence: 0.02685
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.03888
Value Function Update Magnitude: 0.04017

Collected Steps per Second: 10,806.85173
Overall Steps per Second: 9,283.95622

Timestep Collection Time: 4.62706
Timestep Consumption Time: 0.75900
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 5.38607

Cumulative Model Updates: 5,213
Cumulative Timesteps: 87,027,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 87027956...
Checkpoint 87027956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.76186
Policy Entropy: 1.12551
Value Function Loss: 5.39724

Mean KL Divergence: 0.03138
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.04339
Value Function Update Magnitude: 0.04049

Collected Steps per Second: 10,730.85903
Overall Steps per Second: 9,086.46395

Timestep Collection Time: 4.66132
Timestep Consumption Time: 0.84357
PPO Batch Consumption Time: 0.04228
Total Iteration Time: 5.50489

Cumulative Model Updates: 5,216
Cumulative Timesteps: 87,077,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.75605
Policy Entropy: 1.13708
Value Function Loss: 5.35265

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.04002

Collected Steps per Second: 10,534.88950
Overall Steps per Second: 9,057.08855

Timestep Collection Time: 4.74670
Timestep Consumption Time: 0.77450
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 5.52120

Cumulative Model Updates: 5,219
Cumulative Timesteps: 87,127,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 87127982...
Checkpoint 87127982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.78464
Policy Entropy: 1.12637
Value Function Loss: 5.43189

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.07326
Value Function Update Magnitude: 0.04914

Collected Steps per Second: 10,409.20581
Overall Steps per Second: 8,848.77263

Timestep Collection Time: 4.80382
Timestep Consumption Time: 0.84713
PPO Batch Consumption Time: 0.03884
Total Iteration Time: 5.65095

Cumulative Model Updates: 5,222
Cumulative Timesteps: 87,177,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.29069
Policy Entropy: 1.13229
Value Function Loss: 5.39222

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.04874

Collected Steps per Second: 10,676.81904
Overall Steps per Second: 9,051.08526

Timestep Collection Time: 4.68435
Timestep Consumption Time: 0.84139
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 5.52575

Cumulative Model Updates: 5,225
Cumulative Timesteps: 87,228,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 87228000...
Checkpoint 87228000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.95807
Policy Entropy: 1.14414
Value Function Loss: 5.41314

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.06904

Collected Steps per Second: 10,982.76781
Overall Steps per Second: 9,270.24352

Timestep Collection Time: 4.55477
Timestep Consumption Time: 0.84142
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 5.39619

Cumulative Model Updates: 5,228
Cumulative Timesteps: 87,278,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.52217
Policy Entropy: 1.13539
Value Function Loss: 5.27421

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.06631

Collected Steps per Second: 10,753.94448
Overall Steps per Second: 9,071.74037

Timestep Collection Time: 4.65094
Timestep Consumption Time: 0.86244
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 5.51339

Cumulative Model Updates: 5,231
Cumulative Timesteps: 87,328,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 87328040...
Checkpoint 87328040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.91170
Policy Entropy: 1.14611
Value Function Loss: 5.27367

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.03897
Value Function Update Magnitude: 0.05879

Collected Steps per Second: 10,787.44463
Overall Steps per Second: 9,239.90629

Timestep Collection Time: 4.63576
Timestep Consumption Time: 0.77642
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 5.41218

Cumulative Model Updates: 5,234
Cumulative Timesteps: 87,378,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.96552
Policy Entropy: 1.14316
Value Function Loss: 5.06018

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.04937

Collected Steps per Second: 10,663.09687
Overall Steps per Second: 8,945.46926

Timestep Collection Time: 4.69151
Timestep Consumption Time: 0.90082
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 5.59233

Cumulative Model Updates: 5,237
Cumulative Timesteps: 87,428,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 87428074...
Checkpoint 87428074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.63058
Policy Entropy: 1.15317
Value Function Loss: 5.15279

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.04580

Collected Steps per Second: 10,738.13639
Overall Steps per Second: 9,154.39502

Timestep Collection Time: 4.65686
Timestep Consumption Time: 0.80565
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 5.46251

Cumulative Model Updates: 5,240
Cumulative Timesteps: 87,478,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.73641
Policy Entropy: 1.11663
Value Function Loss: 5.00508

Mean KL Divergence: 0.07050
SB3 Clip Fraction: 0.19099
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.04918

Collected Steps per Second: 10,733.47463
Overall Steps per Second: 9,087.35250

Timestep Collection Time: 4.66075
Timestep Consumption Time: 0.84427
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.50501

Cumulative Model Updates: 5,243
Cumulative Timesteps: 87,528,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 87528106...
Checkpoint 87528106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.99678
Policy Entropy: 1.13030
Value Function Loss: 5.44504

Mean KL Divergence: 0.04897
SB3 Clip Fraction: 0.17110
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.05739

Collected Steps per Second: 10,592.46979
Overall Steps per Second: 8,975.13693

Timestep Collection Time: 4.72109
Timestep Consumption Time: 0.85075
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.57184

Cumulative Model Updates: 5,246
Cumulative Timesteps: 87,578,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.44339
Policy Entropy: 1.13730
Value Function Loss: 5.25418

Mean KL Divergence: 0.04171
SB3 Clip Fraction: 0.15369
Policy Update Magnitude: 0.04117
Value Function Update Magnitude: 0.04730

Collected Steps per Second: 10,729.63468
Overall Steps per Second: 9,184.82122

Timestep Collection Time: 4.66036
Timestep Consumption Time: 0.78384
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 5.44420

Cumulative Model Updates: 5,249
Cumulative Timesteps: 87,628,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 87628118...
Checkpoint 87628118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.96933
Policy Entropy: 1.14039
Value Function Loss: 5.26767

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.04301

Collected Steps per Second: 10,731.54771
Overall Steps per Second: 8,957.43138

Timestep Collection Time: 4.66140
Timestep Consumption Time: 0.92324
PPO Batch Consumption Time: 0.04631
Total Iteration Time: 5.58464

Cumulative Model Updates: 5,252
Cumulative Timesteps: 87,678,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.66343
Policy Entropy: 1.14645
Value Function Loss: 5.18595

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.03925

Collected Steps per Second: 10,263.71619
Overall Steps per Second: 8,780.53881

Timestep Collection Time: 4.87289
Timestep Consumption Time: 0.82311
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 5.69601

Cumulative Model Updates: 5,255
Cumulative Timesteps: 87,728,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 87728156...
Checkpoint 87728156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.34235
Policy Entropy: 1.11390
Value Function Loss: 5.63178

Mean KL Divergence: 0.02976
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.04514

Collected Steps per Second: 11,172.22425
Overall Steps per Second: 9,434.53648

Timestep Collection Time: 4.47574
Timestep Consumption Time: 0.82436
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 5.30010

Cumulative Model Updates: 5,258
Cumulative Timesteps: 87,778,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.47244
Policy Entropy: 1.13231
Value Function Loss: 5.66098

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.04191

Collected Steps per Second: 10,959.42871
Overall Steps per Second: 9,229.51757

Timestep Collection Time: 4.56447
Timestep Consumption Time: 0.85553
PPO Batch Consumption Time: 0.04028
Total Iteration Time: 5.42000

Cumulative Model Updates: 5,261
Cumulative Timesteps: 87,828,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 87828184...
Checkpoint 87828184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.43752
Policy Entropy: 1.12271
Value Function Loss: 5.54794

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.04227

Collected Steps per Second: 10,812.08057
Overall Steps per Second: 9,284.01482

Timestep Collection Time: 4.62483
Timestep Consumption Time: 0.76121
PPO Batch Consumption Time: 0.04925
Total Iteration Time: 5.38603

Cumulative Model Updates: 5,264
Cumulative Timesteps: 87,878,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.53951
Policy Entropy: 1.13928
Value Function Loss: 5.13442

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.04312

Collected Steps per Second: 10,788.82365
Overall Steps per Second: 9,179.84351

Timestep Collection Time: 4.63646
Timestep Consumption Time: 0.81265
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 5.44911

Cumulative Model Updates: 5,267
Cumulative Timesteps: 87,928,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 87928210...
Checkpoint 87928210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.13829
Policy Entropy: 1.14114
Value Function Loss: 5.36715

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.05875
Value Function Update Magnitude: 0.04294

Collected Steps per Second: 9,868.58465
Overall Steps per Second: 8,431.66738

Timestep Collection Time: 5.06699
Timestep Consumption Time: 0.86351
PPO Batch Consumption Time: 0.04192
Total Iteration Time: 5.93050

Cumulative Model Updates: 5,270
Cumulative Timesteps: 87,978,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.02189
Policy Entropy: 1.14605
Value Function Loss: 5.53437

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.03764

Collected Steps per Second: 10,805.48680
Overall Steps per Second: 9,143.60351

Timestep Collection Time: 4.62728
Timestep Consumption Time: 0.84102
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 5.46830

Cumulative Model Updates: 5,273
Cumulative Timesteps: 88,028,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 88028214...
Checkpoint 88028214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.48582
Policy Entropy: 1.12221
Value Function Loss: 5.68928

Mean KL Divergence: 0.03259
SB3 Clip Fraction: 0.15437
Policy Update Magnitude: 0.08180
Value Function Update Magnitude: 0.06725

Collected Steps per Second: 10,699.50244
Overall Steps per Second: 9,082.38177

Timestep Collection Time: 4.67386
Timestep Consumption Time: 0.83218
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 5.50604

Cumulative Model Updates: 5,276
Cumulative Timesteps: 88,078,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.32295
Policy Entropy: 1.14498
Value Function Loss: 5.71262

Mean KL Divergence: 0.02835
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.06627

Collected Steps per Second: 10,687.92536
Overall Steps per Second: 9,254.42896

Timestep Collection Time: 4.67967
Timestep Consumption Time: 0.72487
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.40455

Cumulative Model Updates: 5,279
Cumulative Timesteps: 88,128,238

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 88128238...
Checkpoint 88128238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.55596
Policy Entropy: 1.12067
Value Function Loss: 5.47476

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.06142

Collected Steps per Second: 10,669.62285
Overall Steps per Second: 9,051.49194

Timestep Collection Time: 4.68676
Timestep Consumption Time: 0.83785
PPO Batch Consumption Time: 0.04991
Total Iteration Time: 5.52461

Cumulative Model Updates: 5,282
Cumulative Timesteps: 88,178,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.05966
Policy Entropy: 1.13227
Value Function Loss: 5.34655

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.07251
Value Function Update Magnitude: 0.08659

Collected Steps per Second: 10,510.16616
Overall Steps per Second: 8,883.93576

Timestep Collection Time: 4.75768
Timestep Consumption Time: 0.87091
PPO Batch Consumption Time: 0.04689
Total Iteration Time: 5.62859

Cumulative Model Updates: 5,285
Cumulative Timesteps: 88,228,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 88228248...
Checkpoint 88228248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.12441
Policy Entropy: 1.12361
Value Function Loss: 5.25626

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.07929

Collected Steps per Second: 10,080.72849
Overall Steps per Second: 8,647.79404

Timestep Collection Time: 4.96016
Timestep Consumption Time: 0.82190
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 5.78205

Cumulative Model Updates: 5,288
Cumulative Timesteps: 88,278,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.70663
Policy Entropy: 1.14725
Value Function Loss: 5.51787

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.06557

Collected Steps per Second: 10,454.03889
Overall Steps per Second: 8,921.03882

Timestep Collection Time: 4.78361
Timestep Consumption Time: 0.82202
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 5.60563

Cumulative Model Updates: 5,291
Cumulative Timesteps: 88,328,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 88328258...
Checkpoint 88328258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.08668
Policy Entropy: 1.13733
Value Function Loss: 5.55418

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.06242

Collected Steps per Second: 10,726.20094
Overall Steps per Second: 9,223.20461

Timestep Collection Time: 4.66372
Timestep Consumption Time: 0.75999
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 5.42371

Cumulative Model Updates: 5,294
Cumulative Timesteps: 88,378,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.63358
Policy Entropy: 1.14887
Value Function Loss: 5.53368

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.12026
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.07162

Collected Steps per Second: 10,593.58707
Overall Steps per Second: 9,004.65384

Timestep Collection Time: 4.71984
Timestep Consumption Time: 0.83285
PPO Batch Consumption Time: 0.03899
Total Iteration Time: 5.55268

Cumulative Model Updates: 5,297
Cumulative Timesteps: 88,428,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 88428282...
Checkpoint 88428282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.86338
Policy Entropy: 1.15414
Value Function Loss: 5.27537

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.06586

Collected Steps per Second: 10,596.46617
Overall Steps per Second: 9,017.43039

Timestep Collection Time: 4.71988
Timestep Consumption Time: 0.82649
PPO Batch Consumption Time: 0.04703
Total Iteration Time: 5.54637

Cumulative Model Updates: 5,300
Cumulative Timesteps: 88,478,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.40333
Policy Entropy: 1.16302
Value Function Loss: 5.43772

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 9,890.51552
Overall Steps per Second: 8,608.88762

Timestep Collection Time: 5.05656
Timestep Consumption Time: 0.75278
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 5.80935

Cumulative Model Updates: 5,303
Cumulative Timesteps: 88,528,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 88528308...
Checkpoint 88528308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.78082
Policy Entropy: 1.13079
Value Function Loss: 5.45204

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.07830

Collected Steps per Second: 10,782.48384
Overall Steps per Second: 9,195.66853

Timestep Collection Time: 4.63938
Timestep Consumption Time: 0.80058
PPO Batch Consumption Time: 0.04015
Total Iteration Time: 5.43995

Cumulative Model Updates: 5,306
Cumulative Timesteps: 88,578,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.53662
Policy Entropy: 1.15204
Value Function Loss: 5.54262

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.07220

Collected Steps per Second: 10,638.13251
Overall Steps per Second: 9,101.54407

Timestep Collection Time: 4.70289
Timestep Consumption Time: 0.79398
PPO Batch Consumption Time: 0.04535
Total Iteration Time: 5.49687

Cumulative Model Updates: 5,309
Cumulative Timesteps: 88,628,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 88628362...
Checkpoint 88628362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.47191
Policy Entropy: 1.14873
Value Function Loss: 5.19292

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.06576

Collected Steps per Second: 10,470.16344
Overall Steps per Second: 8,859.28981

Timestep Collection Time: 4.77605
Timestep Consumption Time: 0.86842
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.64447

Cumulative Model Updates: 5,312
Cumulative Timesteps: 88,678,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.20654
Policy Entropy: 1.15066
Value Function Loss: 5.27850

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.05216

Collected Steps per Second: 10,749.93498
Overall Steps per Second: 9,120.42757

Timestep Collection Time: 4.65305
Timestep Consumption Time: 0.83134
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.48439

Cumulative Model Updates: 5,315
Cumulative Timesteps: 88,728,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 88728388...
Checkpoint 88728388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.72429
Policy Entropy: 1.13749
Value Function Loss: 5.19388

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.04381

Collected Steps per Second: 10,740.84877
Overall Steps per Second: 8,966.82027

Timestep Collection Time: 4.65531
Timestep Consumption Time: 0.92102
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.57634

Cumulative Model Updates: 5,318
Cumulative Timesteps: 88,778,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.31810
Policy Entropy: 1.14621
Value Function Loss: 5.44358

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.04877

Collected Steps per Second: 10,557.83867
Overall Steps per Second: 9,042.65877

Timestep Collection Time: 4.73658
Timestep Consumption Time: 0.79366
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 5.53023

Cumulative Model Updates: 5,321
Cumulative Timesteps: 88,828,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 88828398...
Checkpoint 88828398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.63722
Policy Entropy: 1.15510
Value Function Loss: 5.23872

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.04439

Collected Steps per Second: 10,753.16326
Overall Steps per Second: 9,309.46598

Timestep Collection Time: 4.65110
Timestep Consumption Time: 0.72128
PPO Batch Consumption Time: 0.03838
Total Iteration Time: 5.37238

Cumulative Model Updates: 5,324
Cumulative Timesteps: 88,878,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.88777
Policy Entropy: 1.14150
Value Function Loss: 5.40376

Mean KL Divergence: 0.04833
SB3 Clip Fraction: 0.16791
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.05187

Collected Steps per Second: 10,930.02542
Overall Steps per Second: 9,211.98622

Timestep Collection Time: 4.57638
Timestep Consumption Time: 0.85350
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 5.42988

Cumulative Model Updates: 5,327
Cumulative Timesteps: 88,928,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 88928432...
Checkpoint 88928432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.38105
Policy Entropy: 1.15340
Value Function Loss: 5.27754

Mean KL Divergence: 0.03275
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.05974

Collected Steps per Second: 10,773.92880
Overall Steps per Second: 9,140.17351

Timestep Collection Time: 4.64250
Timestep Consumption Time: 0.82982
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 5.47233

Cumulative Model Updates: 5,330
Cumulative Timesteps: 88,978,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.80663
Policy Entropy: 1.13966
Value Function Loss: 5.32718

Mean KL Divergence: 0.03356
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.05134

Collected Steps per Second: 11,077.82149
Overall Steps per Second: 9,324.25512

Timestep Collection Time: 4.51479
Timestep Consumption Time: 0.84907
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 5.36386

Cumulative Model Updates: 5,333
Cumulative Timesteps: 89,028,464

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 89028464...
Checkpoint 89028464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.93068
Policy Entropy: 1.15601
Value Function Loss: 5.26352

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.05205

Collected Steps per Second: 10,132.85280
Overall Steps per Second: 8,663.35740

Timestep Collection Time: 4.93642
Timestep Consumption Time: 0.83732
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 5.77374

Cumulative Model Updates: 5,336
Cumulative Timesteps: 89,078,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.20038
Policy Entropy: 1.15352
Value Function Loss: 5.50661

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.04994

Collected Steps per Second: 10,724.62830
Overall Steps per Second: 9,197.42963

Timestep Collection Time: 4.66273
Timestep Consumption Time: 0.77423
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.43695

Cumulative Model Updates: 5,339
Cumulative Timesteps: 89,128,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 89128490...
Checkpoint 89128490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.02326
Policy Entropy: 1.14463
Value Function Loss: 5.37168

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.05487

Collected Steps per Second: 10,755.16705
Overall Steps per Second: 9,080.26496

Timestep Collection Time: 4.65135
Timestep Consumption Time: 0.85796
PPO Batch Consumption Time: 0.04015
Total Iteration Time: 5.50931

Cumulative Model Updates: 5,342
Cumulative Timesteps: 89,178,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.99395
Policy Entropy: 1.14764
Value Function Loss: 5.27307

Mean KL Divergence: 0.02493
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.08472

Collected Steps per Second: 10,500.11022
Overall Steps per Second: 8,977.60813

Timestep Collection Time: 4.76243
Timestep Consumption Time: 0.80765
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.57008

Cumulative Model Updates: 5,345
Cumulative Timesteps: 89,228,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 89228522...
Checkpoint 89228522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.95496
Policy Entropy: 1.15330
Value Function Loss: 5.17974

Mean KL Divergence: 0.02935
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.07602
Value Function Update Magnitude: 0.07533

Collected Steps per Second: 10,839.71484
Overall Steps per Second: 9,126.93819

Timestep Collection Time: 4.61359
Timestep Consumption Time: 0.86579
PPO Batch Consumption Time: 0.04470
Total Iteration Time: 5.47938

Cumulative Model Updates: 5,348
Cumulative Timesteps: 89,278,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.66092
Policy Entropy: 1.15108
Value Function Loss: 5.36486

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.06512
Value Function Update Magnitude: 0.06561

Collected Steps per Second: 10,167.67620
Overall Steps per Second: 8,621.69468

Timestep Collection Time: 4.91971
Timestep Consumption Time: 0.88217
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 5.80188

Cumulative Model Updates: 5,351
Cumulative Timesteps: 89,328,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 89328554...
Checkpoint 89328554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.29031
Policy Entropy: 1.16516
Value Function Loss: 5.61935

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.05824

Collected Steps per Second: 10,768.96346
Overall Steps per Second: 9,312.93979

Timestep Collection Time: 4.64409
Timestep Consumption Time: 0.72608
PPO Batch Consumption Time: 0.03982
Total Iteration Time: 5.37016

Cumulative Model Updates: 5,354
Cumulative Timesteps: 89,378,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.79250
Policy Entropy: 1.16488
Value Function Loss: 5.41546

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.04889

Collected Steps per Second: 10,770.44341
Overall Steps per Second: 9,046.12042

Timestep Collection Time: 4.64252
Timestep Consumption Time: 0.88493
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 5.52745

Cumulative Model Updates: 5,357
Cumulative Timesteps: 89,428,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 89428568...
Checkpoint 89428568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.01768
Policy Entropy: 1.15382
Value Function Loss: 5.25221

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.05033

Collected Steps per Second: 10,344.81396
Overall Steps per Second: 8,870.87984

Timestep Collection Time: 4.83508
Timestep Consumption Time: 0.80337
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 5.63845

Cumulative Model Updates: 5,360
Cumulative Timesteps: 89,478,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.40426
Policy Entropy: 1.15158
Value Function Loss: 5.10958

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.04701

Collected Steps per Second: 10,848.88091
Overall Steps per Second: 9,132.16235

Timestep Collection Time: 4.61098
Timestep Consumption Time: 0.86680
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 5.47778

Cumulative Model Updates: 5,363
Cumulative Timesteps: 89,528,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 89528610...
Checkpoint 89528610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.71649
Policy Entropy: 1.17659
Value Function Loss: 5.17293

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.06809
Value Function Update Magnitude: 0.07509

Collected Steps per Second: 10,743.47483
Overall Steps per Second: 9,078.68085

Timestep Collection Time: 4.65641
Timestep Consumption Time: 0.85386
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 5.51027

Cumulative Model Updates: 5,366
Cumulative Timesteps: 89,578,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.11142
Policy Entropy: 1.16215
Value Function Loss: 5.33053

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.07548

Collected Steps per Second: 10,211.36393
Overall Steps per Second: 8,855.13817

Timestep Collection Time: 4.89964
Timestep Consumption Time: 0.75041
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.65005

Cumulative Model Updates: 5,369
Cumulative Timesteps: 89,628,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 89628668...
Checkpoint 89628668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.98291
Policy Entropy: 1.15703
Value Function Loss: 5.36555

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.07634
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 10,589.46168
Overall Steps per Second: 8,904.55509

Timestep Collection Time: 4.72300
Timestep Consumption Time: 0.89368
PPO Batch Consumption Time: 0.04646
Total Iteration Time: 5.61668

Cumulative Model Updates: 5,372
Cumulative Timesteps: 89,678,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.24364
Policy Entropy: 1.16315
Value Function Loss: 5.24746

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.07126
Value Function Update Magnitude: 0.09606

Collected Steps per Second: 10,638.29131
Overall Steps per Second: 9,141.15706

Timestep Collection Time: 4.70169
Timestep Consumption Time: 0.77004
PPO Batch Consumption Time: 0.04591
Total Iteration Time: 5.47174

Cumulative Model Updates: 5,375
Cumulative Timesteps: 89,728,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 89728700...
Checkpoint 89728700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.57550
Policy Entropy: 1.17015
Value Function Loss: 5.12665

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.10503

Collected Steps per Second: 10,701.14661
Overall Steps per Second: 9,040.42396

Timestep Collection Time: 4.67258
Timestep Consumption Time: 0.85835
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 5.53094

Cumulative Model Updates: 5,378
Cumulative Timesteps: 89,778,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.55674
Policy Entropy: 1.17193
Value Function Loss: 5.11134

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.09338

Collected Steps per Second: 10,663.97370
Overall Steps per Second: 8,966.56792

Timestep Collection Time: 4.69093
Timestep Consumption Time: 0.88801
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 5.57895

Cumulative Model Updates: 5,381
Cumulative Timesteps: 89,828,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 89828726...
Checkpoint 89828726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.13966
Policy Entropy: 1.16479
Value Function Loss: 5.11822

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.08309

Collected Steps per Second: 10,212.17392
Overall Steps per Second: 8,857.84731

Timestep Collection Time: 4.89847
Timestep Consumption Time: 0.74895
PPO Batch Consumption Time: 0.04022
Total Iteration Time: 5.64742

Cumulative Model Updates: 5,384
Cumulative Timesteps: 89,878,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.14288
Policy Entropy: 1.17817
Value Function Loss: 5.38272

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.08878
Value Function Update Magnitude: 0.07691

Collected Steps per Second: 11,009.12651
Overall Steps per Second: 9,333.89950

Timestep Collection Time: 4.54441
Timestep Consumption Time: 0.81562
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 5.36003

Cumulative Model Updates: 5,387
Cumulative Timesteps: 89,928,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 89928780...
Checkpoint 89928780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.23843
Policy Entropy: 1.17049
Value Function Loss: 5.42681

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.08011
Value Function Update Magnitude: 0.07482

Collected Steps per Second: 11,087.05489
Overall Steps per Second: 9,425.15099

Timestep Collection Time: 4.50994
Timestep Consumption Time: 0.79522
PPO Batch Consumption Time: 0.03922
Total Iteration Time: 5.30517

Cumulative Model Updates: 5,390
Cumulative Timesteps: 89,978,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.58452
Policy Entropy: 1.15856
Value Function Loss: 5.32289

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.07753
Value Function Update Magnitude: 0.07516

Collected Steps per Second: 11,423.40624
Overall Steps per Second: 9,610.44318

Timestep Collection Time: 4.37943
Timestep Consumption Time: 0.82616
PPO Batch Consumption Time: 0.04104
Total Iteration Time: 5.20559

Cumulative Model Updates: 5,393
Cumulative Timesteps: 90,028,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 90028810...
Checkpoint 90028810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.15016
Policy Entropy: 1.15714
Value Function Loss: 5.11301

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.07170
Value Function Update Magnitude: 0.08505

Collected Steps per Second: 10,645.30709
Overall Steps per Second: 8,981.17435

Timestep Collection Time: 4.69822
Timestep Consumption Time: 0.87054
PPO Batch Consumption Time: 0.04567
Total Iteration Time: 5.56876

Cumulative Model Updates: 5,396
Cumulative Timesteps: 90,078,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.79020
Policy Entropy: 1.16028
Value Function Loss: 5.30880

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07234
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.09342

Collected Steps per Second: 10,588.79801
Overall Steps per Second: 9,067.89291

Timestep Collection Time: 4.72348
Timestep Consumption Time: 0.79224
PPO Batch Consumption Time: 0.04931
Total Iteration Time: 5.51572

Cumulative Model Updates: 5,399
Cumulative Timesteps: 90,128,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 90128840...
Checkpoint 90128840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.06181
Policy Entropy: 1.16405
Value Function Loss: 5.26549

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.04983
Policy Update Magnitude: 0.07111
Value Function Update Magnitude: 0.06477

Collected Steps per Second: 10,119.16464
Overall Steps per Second: 8,651.35957

Timestep Collection Time: 4.94231
Timestep Consumption Time: 0.83852
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 5.78083

Cumulative Model Updates: 5,402
Cumulative Timesteps: 90,178,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.23637
Policy Entropy: 1.16282
Value Function Loss: 5.25278

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.07905
Value Function Update Magnitude: 0.08338

Collected Steps per Second: 10,697.38061
Overall Steps per Second: 9,115.85814

Timestep Collection Time: 4.67703
Timestep Consumption Time: 0.81142
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 5.48846

Cumulative Model Updates: 5,405
Cumulative Timesteps: 90,228,884

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 90228884...
Checkpoint 90228884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.61128
Policy Entropy: 1.16276
Value Function Loss: 5.02932

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.06026

Collected Steps per Second: 11,002.49564
Overall Steps per Second: 9,281.73425

Timestep Collection Time: 4.54461
Timestep Consumption Time: 0.84253
PPO Batch Consumption Time: 0.04647
Total Iteration Time: 5.38714

Cumulative Model Updates: 5,408
Cumulative Timesteps: 90,278,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.09187
Policy Entropy: 1.17421
Value Function Loss: 5.09686

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.07983

Collected Steps per Second: 10,580.64040
Overall Steps per Second: 8,948.77909

Timestep Collection Time: 4.72807
Timestep Consumption Time: 0.86219
PPO Batch Consumption Time: 0.04682
Total Iteration Time: 5.59026

Cumulative Model Updates: 5,411
Cumulative Timesteps: 90,328,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 90328912...
Checkpoint 90328912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.15120
Policy Entropy: 1.17419
Value Function Loss: 4.98434

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.06465

Collected Steps per Second: 10,685.54278
Overall Steps per Second: 9,167.81292

Timestep Collection Time: 4.68034
Timestep Consumption Time: 0.77483
PPO Batch Consumption Time: 0.04471
Total Iteration Time: 5.45517

Cumulative Model Updates: 5,414
Cumulative Timesteps: 90,378,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.77297
Policy Entropy: 1.16997
Value Function Loss: 5.02792

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.05604

Collected Steps per Second: 10,174.68219
Overall Steps per Second: 8,706.10391

Timestep Collection Time: 4.91593
Timestep Consumption Time: 0.82924
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 5.74516

Cumulative Model Updates: 5,417
Cumulative Timesteps: 90,428,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 90428942...
Checkpoint 90428942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.63954
Policy Entropy: 1.17842
Value Function Loss: 5.03996

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.04262
Value Function Update Magnitude: 0.05522

Collected Steps per Second: 10,916.19904
Overall Steps per Second: 9,322.97213

Timestep Collection Time: 4.58200
Timestep Consumption Time: 0.78303
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.36503

Cumulative Model Updates: 5,420
Cumulative Timesteps: 90,478,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.53558
Policy Entropy: 1.18549
Value Function Loss: 5.11810

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.05141

Collected Steps per Second: 10,965.66013
Overall Steps per Second: 9,304.21898

Timestep Collection Time: 4.56133
Timestep Consumption Time: 0.81451
PPO Batch Consumption Time: 0.04044
Total Iteration Time: 5.37584

Cumulative Model Updates: 5,423
Cumulative Timesteps: 90,528,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 90528978...
Checkpoint 90528978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.44808
Policy Entropy: 1.19579
Value Function Loss: 5.07104

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.04947

Collected Steps per Second: 10,842.66854
Overall Steps per Second: 9,237.25663

Timestep Collection Time: 4.61399
Timestep Consumption Time: 0.80190
PPO Batch Consumption Time: 0.04480
Total Iteration Time: 5.41589

Cumulative Model Updates: 5,426
Cumulative Timesteps: 90,579,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.22285
Policy Entropy: 1.16198
Value Function Loss: 5.22970

Mean KL Divergence: 0.05693
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.05280

Collected Steps per Second: 10,749.47240
Overall Steps per Second: 9,214.57339

Timestep Collection Time: 4.65381
Timestep Consumption Time: 0.77520
PPO Batch Consumption Time: 0.04282
Total Iteration Time: 5.42901

Cumulative Model Updates: 5,429
Cumulative Timesteps: 90,629,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 90629032...
Checkpoint 90629032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.84393
Policy Entropy: 1.17294
Value Function Loss: 5.07501

Mean KL Divergence: 0.03281
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.04367
Value Function Update Magnitude: 0.05499

Collected Steps per Second: 10,790.21238
Overall Steps per Second: 8,981.48185

Timestep Collection Time: 4.63457
Timestep Consumption Time: 0.93333
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 5.56790

Cumulative Model Updates: 5,432
Cumulative Timesteps: 90,679,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.80494
Policy Entropy: 1.15826
Value Function Loss: 4.94580

Mean KL Divergence: 0.04159
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.08454

Collected Steps per Second: 10,898.03124
Overall Steps per Second: 9,263.13815

Timestep Collection Time: 4.59037
Timestep Consumption Time: 0.81018
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 5.40055

Cumulative Model Updates: 5,435
Cumulative Timesteps: 90,729,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 90729066...
Checkpoint 90729066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.59067
Policy Entropy: 1.17454
Value Function Loss: 4.85460

Mean KL Divergence: 0.04096
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.04148
Value Function Update Magnitude: 0.07965

Collected Steps per Second: 10,868.54806
Overall Steps per Second: 9,249.16979

Timestep Collection Time: 4.60043
Timestep Consumption Time: 0.80546
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 5.40589

Cumulative Model Updates: 5,438
Cumulative Timesteps: 90,779,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.10068
Policy Entropy: 1.16689
Value Function Loss: 4.83073

Mean KL Divergence: 0.03465
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.07013

Collected Steps per Second: 10,764.79814
Overall Steps per Second: 9,209.83559

Timestep Collection Time: 4.64551
Timestep Consumption Time: 0.78434
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 5.42985

Cumulative Model Updates: 5,441
Cumulative Timesteps: 90,829,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 90829074...
Checkpoint 90829074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.15281
Policy Entropy: 1.18506
Value Function Loss: 5.03063

Mean KL Divergence: 0.03332
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.03775
Value Function Update Magnitude: 0.06395

Collected Steps per Second: 10,606.64896
Overall Steps per Second: 9,089.30262

Timestep Collection Time: 4.71553
Timestep Consumption Time: 0.78720
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 5.50273

Cumulative Model Updates: 5,444
Cumulative Timesteps: 90,879,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.98488
Policy Entropy: 1.16959
Value Function Loss: 4.96242

Mean KL Divergence: 0.03790
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.03483
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 10,957.51930
Overall Steps per Second: 9,243.08166

Timestep Collection Time: 4.56381
Timestep Consumption Time: 0.84651
PPO Batch Consumption Time: 0.03884
Total Iteration Time: 5.41032

Cumulative Model Updates: 5,447
Cumulative Timesteps: 90,929,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 90929098...
Checkpoint 90929098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.35274
Policy Entropy: 1.18331
Value Function Loss: 5.08914

Mean KL Divergence: 0.03179
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.03302
Value Function Update Magnitude: 0.06124

Collected Steps per Second: 10,104.19152
Overall Steps per Second: 8,688.63387

Timestep Collection Time: 4.94983
Timestep Consumption Time: 0.80643
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 5.75626

Cumulative Model Updates: 5,450
Cumulative Timesteps: 90,979,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.29130
Policy Entropy: 1.17333
Value Function Loss: 5.21607

Mean KL Divergence: 0.03552
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.03083
Value Function Update Magnitude: 0.06260

Collected Steps per Second: 10,609.15639
Overall Steps per Second: 8,943.43076

Timestep Collection Time: 4.71555
Timestep Consumption Time: 0.87828
PPO Batch Consumption Time: 0.04711
Total Iteration Time: 5.59383

Cumulative Model Updates: 5,453
Cumulative Timesteps: 91,029,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 91029140...
Checkpoint 91029140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.53013
Policy Entropy: 1.19100
Value Function Loss: 5.08844

Mean KL Divergence: 0.03110
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.03505
Value Function Update Magnitude: 0.08216

Collected Steps per Second: 11,040.48479
Overall Steps per Second: 9,286.03751

Timestep Collection Time: 4.53005
Timestep Consumption Time: 0.85588
PPO Batch Consumption Time: 0.03967
Total Iteration Time: 5.38594

Cumulative Model Updates: 5,456
Cumulative Timesteps: 91,079,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.77166
Policy Entropy: 1.16970
Value Function Loss: 5.01817

Mean KL Divergence: 0.03743
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.03330
Value Function Update Magnitude: 0.09604

Collected Steps per Second: 10,972.56149
Overall Steps per Second: 9,288.02250

Timestep Collection Time: 4.55901
Timestep Consumption Time: 0.82685
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 5.38586

Cumulative Model Updates: 5,459
Cumulative Timesteps: 91,129,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 91129178...
Checkpoint 91129178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.37730
Policy Entropy: 1.18132
Value Function Loss: 4.89401

Mean KL Divergence: 0.02895
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.03519
Value Function Update Magnitude: 0.08522

Collected Steps per Second: 10,684.26968
Overall Steps per Second: 9,031.69844

Timestep Collection Time: 4.68071
Timestep Consumption Time: 0.85645
PPO Batch Consumption Time: 0.03886
Total Iteration Time: 5.53716

Cumulative Model Updates: 5,462
Cumulative Timesteps: 91,179,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.53525
Policy Entropy: 1.16790
Value Function Loss: 4.84336

Mean KL Divergence: 0.03937
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.03478
Value Function Update Magnitude: 0.07087

Collected Steps per Second: 10,218.37007
Overall Steps per Second: 8,713.67507

Timestep Collection Time: 4.89628
Timestep Consumption Time: 0.84550
PPO Batch Consumption Time: 0.04690
Total Iteration Time: 5.74178

Cumulative Model Updates: 5,465
Cumulative Timesteps: 91,229,220

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 91229220...
Checkpoint 91229220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.52519
Policy Entropy: 1.18212
Value Function Loss: 4.87125

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.03495
Value Function Update Magnitude: 0.08380

Collected Steps per Second: 10,657.99266
Overall Steps per Second: 9,069.25366

Timestep Collection Time: 4.69338
Timestep Consumption Time: 0.82218
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 5.51556

Cumulative Model Updates: 5,468
Cumulative Timesteps: 91,279,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.02130
Policy Entropy: 1.16713
Value Function Loss: 4.86516

Mean KL Divergence: 0.03772
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.03524
Value Function Update Magnitude: 0.07079

Collected Steps per Second: 10,602.98442
Overall Steps per Second: 9,049.80045

Timestep Collection Time: 4.71679
Timestep Consumption Time: 0.80952
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.52631

Cumulative Model Updates: 5,471
Cumulative Timesteps: 91,329,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 91329254...
Checkpoint 91329254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.89172
Policy Entropy: 1.18378
Value Function Loss: 5.11588

Mean KL Divergence: 0.03067
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.03479
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 11,038.24489
Overall Steps per Second: 9,195.26437

Timestep Collection Time: 4.53170
Timestep Consumption Time: 0.90828
PPO Batch Consumption Time: 0.04702
Total Iteration Time: 5.43997

Cumulative Model Updates: 5,474
Cumulative Timesteps: 91,379,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.27471
Policy Entropy: 1.16506
Value Function Loss: 5.09659

Mean KL Divergence: 0.03558
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.03498
Value Function Update Magnitude: 0.06033

Collected Steps per Second: 10,448.58502
Overall Steps per Second: 8,775.99840

Timestep Collection Time: 4.78744
Timestep Consumption Time: 0.91242
PPO Batch Consumption Time: 0.03975
Total Iteration Time: 5.69986

Cumulative Model Updates: 5,477
Cumulative Timesteps: 91,429,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 91429298...
Checkpoint 91429298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.19568
Policy Entropy: 1.18404
Value Function Loss: 4.82221

Mean KL Divergence: 0.02642
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.03429
Value Function Update Magnitude: 0.06359

Collected Steps per Second: 10,878.29943
Overall Steps per Second: 9,114.07083

Timestep Collection Time: 4.59649
Timestep Consumption Time: 0.88975
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 5.48624

Cumulative Model Updates: 5,480
Cumulative Timesteps: 91,479,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.05794
Policy Entropy: 1.16613
Value Function Loss: 4.63857

Mean KL Divergence: 0.03634
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.04384
Value Function Update Magnitude: 0.07368

Collected Steps per Second: 10,039.44014
Overall Steps per Second: 8,518.15225

Timestep Collection Time: 4.98036
Timestep Consumption Time: 0.88946
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 5.86982

Cumulative Model Updates: 5,483
Cumulative Timesteps: 91,529,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 91529300...
Checkpoint 91529300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.57572
Policy Entropy: 1.19252
Value Function Loss: 4.77311

Mean KL Divergence: 0.03147
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.03862
Value Function Update Magnitude: 0.09108

Collected Steps per Second: 10,747.05177
Overall Steps per Second: 9,241.22990

Timestep Collection Time: 4.65560
Timestep Consumption Time: 0.75861
PPO Batch Consumption Time: 0.04081
Total Iteration Time: 5.41421

Cumulative Model Updates: 5,486
Cumulative Timesteps: 91,579,334

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.28430
Policy Entropy: 1.17623
Value Function Loss: 5.08872

Mean KL Divergence: 0.02996
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.03572
Value Function Update Magnitude: 0.08128

Collected Steps per Second: 10,799.16032
Overall Steps per Second: 9,083.16330

Timestep Collection Time: 4.63147
Timestep Consumption Time: 0.87498
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 5.50645

Cumulative Model Updates: 5,489
Cumulative Timesteps: 91,629,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 91629350...
Checkpoint 91629350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.71200
Policy Entropy: 1.19303
Value Function Loss: 4.97243

Mean KL Divergence: 0.03352
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.03737
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 10,720.54981
Overall Steps per Second: 9,064.96746

Timestep Collection Time: 4.66394
Timestep Consumption Time: 0.85180
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 5.51574

Cumulative Model Updates: 5,492
Cumulative Timesteps: 91,679,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.95314
Policy Entropy: 1.17257
Value Function Loss: 5.10476

Mean KL Divergence: 0.03344
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.03850
Value Function Update Magnitude: 0.06656

Collected Steps per Second: 11,097.10193
Overall Steps per Second: 9,342.43394

Timestep Collection Time: 4.50712
Timestep Consumption Time: 0.84651
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 5.35364

Cumulative Model Updates: 5,495
Cumulative Timesteps: 91,729,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 91729366...
Checkpoint 91729366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.72676
Policy Entropy: 1.19837
Value Function Loss: 4.79593

Mean KL Divergence: 0.03333
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.03858
Value Function Update Magnitude: 0.07990

Collected Steps per Second: 10,296.40759
Overall Steps per Second: 8,668.03310

Timestep Collection Time: 4.85781
Timestep Consumption Time: 0.91259
PPO Batch Consumption Time: 0.04654
Total Iteration Time: 5.77040

Cumulative Model Updates: 5,498
Cumulative Timesteps: 91,779,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.45056
Policy Entropy: 1.17792
Value Function Loss: 4.86549

Mean KL Divergence: 0.03663
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.03686
Value Function Update Magnitude: 0.08307

Collected Steps per Second: 10,636.62059
Overall Steps per Second: 9,183.81161

Timestep Collection Time: 4.70112
Timestep Consumption Time: 0.74368
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 5.44480

Cumulative Model Updates: 5,501
Cumulative Timesteps: 91,829,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 91829388...
Checkpoint 91829388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.82350
Policy Entropy: 1.20209
Value Function Loss: 4.70852

Mean KL Divergence: 0.02999
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.03589
Value Function Update Magnitude: 0.08828

Collected Steps per Second: 10,606.13848
Overall Steps per Second: 8,981.52586

Timestep Collection Time: 4.71425
Timestep Consumption Time: 0.85273
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 5.56698

Cumulative Model Updates: 5,504
Cumulative Timesteps: 91,879,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.30724
Policy Entropy: 1.18905
Value Function Loss: 4.91539

Mean KL Divergence: 0.03029
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.04030
Value Function Update Magnitude: 0.08811

Collected Steps per Second: 10,730.20725
Overall Steps per Second: 9,184.03043

Timestep Collection Time: 4.66235
Timestep Consumption Time: 0.78493
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 5.44728

Cumulative Model Updates: 5,507
Cumulative Timesteps: 91,929,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 91929416...
Checkpoint 91929416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.35331
Policy Entropy: 1.20918
Value Function Loss: 4.92857

Mean KL Divergence: 0.02614
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.08615

Collected Steps per Second: 11,013.28836
Overall Steps per Second: 9,249.91568

Timestep Collection Time: 4.54215
Timestep Consumption Time: 0.86590
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 5.40805

Cumulative Model Updates: 5,510
Cumulative Timesteps: 91,979,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.77103
Policy Entropy: 1.19393
Value Function Loss: 4.95778

Mean KL Divergence: 0.04532
SB3 Clip Fraction: 0.15898
Policy Update Magnitude: 0.03971
Value Function Update Magnitude: 0.07819

Collected Steps per Second: 11,206.74360
Overall Steps per Second: 9,476.73291

Timestep Collection Time: 4.46285
Timestep Consumption Time: 0.81471
PPO Batch Consumption Time: 0.03984
Total Iteration Time: 5.27756

Cumulative Model Updates: 5,513
Cumulative Timesteps: 92,029,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 92029454...
Checkpoint 92029454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.02515
Policy Entropy: 1.19841
Value Function Loss: 4.98977

Mean KL Divergence: 0.02565
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.03583
Value Function Update Magnitude: 0.06357

Collected Steps per Second: 10,763.47974
Overall Steps per Second: 9,130.54204

Timestep Collection Time: 4.64720
Timestep Consumption Time: 0.83112
PPO Batch Consumption Time: 0.03847
Total Iteration Time: 5.47832

Cumulative Model Updates: 5,516
Cumulative Timesteps: 92,079,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.34054
Policy Entropy: 1.18447
Value Function Loss: 5.06828

Mean KL Divergence: 0.03925
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.03606
Value Function Update Magnitude: 0.06178

Collected Steps per Second: 10,935.49634
Overall Steps per Second: 9,256.87758

Timestep Collection Time: 4.57373
Timestep Consumption Time: 0.82939
PPO Batch Consumption Time: 0.03906
Total Iteration Time: 5.40312

Cumulative Model Updates: 5,519
Cumulative Timesteps: 92,129,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 92129490...
Checkpoint 92129490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.10073
Policy Entropy: 1.19053
Value Function Loss: 4.95413

Mean KL Divergence: 0.02991
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.03438
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 11,205.63563
Overall Steps per Second: 9,530.29321

Timestep Collection Time: 4.46204
Timestep Consumption Time: 0.78439
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 5.24643

Cumulative Model Updates: 5,522
Cumulative Timesteps: 92,179,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.13307
Policy Entropy: 1.17020
Value Function Loss: 4.91848

Mean KL Divergence: 0.03838
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.03867
Value Function Update Magnitude: 0.09541

Collected Steps per Second: 11,060.21956
Overall Steps per Second: 9,378.56208

Timestep Collection Time: 4.52251
Timestep Consumption Time: 0.81093
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.33344

Cumulative Model Updates: 5,525
Cumulative Timesteps: 92,229,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 92229510...
Checkpoint 92229510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.35968
Policy Entropy: 1.17598
Value Function Loss: 4.84292

Mean KL Divergence: 0.02896
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.03904
Value Function Update Magnitude: 0.07809

Collected Steps per Second: 10,644.30942
Overall Steps per Second: 9,053.18857

Timestep Collection Time: 4.69735
Timestep Consumption Time: 0.82557
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 5.52292

Cumulative Model Updates: 5,528
Cumulative Timesteps: 92,279,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.94504
Policy Entropy: 1.15760
Value Function Loss: 4.99677

Mean KL Divergence: 0.04024
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.06978

Collected Steps per Second: 10,331.31645
Overall Steps per Second: 8,796.84753

Timestep Collection Time: 4.84236
Timestep Consumption Time: 0.84467
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.68704

Cumulative Model Updates: 5,531
Cumulative Timesteps: 92,329,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 92329538...
Checkpoint 92329538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.46980
Policy Entropy: 1.17310
Value Function Loss: 5.00464

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.06455

Collected Steps per Second: 10,616.34120
Overall Steps per Second: 9,008.61867

Timestep Collection Time: 4.71010
Timestep Consumption Time: 0.84059
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 5.55068

Cumulative Model Updates: 5,534
Cumulative Timesteps: 92,379,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.75489
Policy Entropy: 1.16288
Value Function Loss: 4.94913

Mean KL Divergence: 0.03343
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 10,740.95543
Overall Steps per Second: 9,255.69964

Timestep Collection Time: 4.65694
Timestep Consumption Time: 0.74730
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 5.40424

Cumulative Model Updates: 5,537
Cumulative Timesteps: 92,429,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 92429562...
Checkpoint 92429562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.38119
Policy Entropy: 1.18654
Value Function Loss: 4.95978

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.06596

Collected Steps per Second: 10,795.79048
Overall Steps per Second: 9,148.96880

Timestep Collection Time: 4.63199
Timestep Consumption Time: 0.83376
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 5.46575

Cumulative Model Updates: 5,540
Cumulative Timesteps: 92,479,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.61921
Policy Entropy: 1.15855
Value Function Loss: 5.18588

Mean KL Divergence: 0.05723
SB3 Clip Fraction: 0.16209
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.07302

Collected Steps per Second: 10,621.01282
Overall Steps per Second: 9,154.90550

Timestep Collection Time: 4.70878
Timestep Consumption Time: 0.75408
PPO Batch Consumption Time: 0.04623
Total Iteration Time: 5.46286

Cumulative Model Updates: 5,543
Cumulative Timesteps: 92,529,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 92529580...
Checkpoint 92529580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.13700
Policy Entropy: 1.16773
Value Function Loss: 5.34899

Mean KL Divergence: 0.02988
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.04159
Value Function Update Magnitude: 0.06808

Collected Steps per Second: 10,524.00057
Overall Steps per Second: 8,834.57994

Timestep Collection Time: 4.75162
Timestep Consumption Time: 0.90864
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 5.66026

Cumulative Model Updates: 5,546
Cumulative Timesteps: 92,579,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.19350
Policy Entropy: 1.15355
Value Function Loss: 5.34231

Mean KL Divergence: 0.03164
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.05877

Collected Steps per Second: 10,809.39259
Overall Steps per Second: 9,069.00004

Timestep Collection Time: 4.62857
Timestep Consumption Time: 0.88825
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.51682

Cumulative Model Updates: 5,549
Cumulative Timesteps: 92,629,618

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 92629618...
Checkpoint 92629618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.66279
Policy Entropy: 1.17374
Value Function Loss: 5.23850

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.05216

Collected Steps per Second: 10,900.73489
Overall Steps per Second: 9,214.63475

Timestep Collection Time: 4.58905
Timestep Consumption Time: 0.83971
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.42876

Cumulative Model Updates: 5,552
Cumulative Timesteps: 92,679,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.03110
Policy Entropy: 1.16848
Value Function Loss: 5.01120

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.06001

Collected Steps per Second: 10,640.06767
Overall Steps per Second: 9,053.71791

Timestep Collection Time: 4.69941
Timestep Consumption Time: 0.82341
PPO Batch Consumption Time: 0.04628
Total Iteration Time: 5.52281

Cumulative Model Updates: 5,555
Cumulative Timesteps: 92,729,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 92729644...
Checkpoint 92729644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.02897
Policy Entropy: 1.15755
Value Function Loss: 5.22162

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.07137

Collected Steps per Second: 10,608.07376
Overall Steps per Second: 9,128.87515

Timestep Collection Time: 4.71415
Timestep Consumption Time: 0.76386
PPO Batch Consumption Time: 0.04608
Total Iteration Time: 5.47800

Cumulative Model Updates: 5,558
Cumulative Timesteps: 92,779,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.37322
Policy Entropy: 1.16752
Value Function Loss: 5.25501

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.08649

Collected Steps per Second: 10,784.41152
Overall Steps per Second: 9,150.43557

Timestep Collection Time: 4.63669
Timestep Consumption Time: 0.82797
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.46466

Cumulative Model Updates: 5,561
Cumulative Timesteps: 92,829,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 92829656...
Checkpoint 92829656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.98564
Policy Entropy: 1.15988
Value Function Loss: 5.31730

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.08998

Collected Steps per Second: 10,276.42393
Overall Steps per Second: 8,824.95796

Timestep Collection Time: 4.86765
Timestep Consumption Time: 0.80060
PPO Batch Consumption Time: 0.04478
Total Iteration Time: 5.66824

Cumulative Model Updates: 5,564
Cumulative Timesteps: 92,879,678

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.31779
Policy Entropy: 1.16022
Value Function Loss: 5.12573

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.07051

Collected Steps per Second: 10,764.68575
Overall Steps per Second: 9,093.78309

Timestep Collection Time: 4.64556
Timestep Consumption Time: 0.85358
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 5.49914

Cumulative Model Updates: 5,567
Cumulative Timesteps: 92,929,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 92929686...
Checkpoint 92929686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.24694
Policy Entropy: 1.16320
Value Function Loss: 5.13741

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.07623

Collected Steps per Second: 10,827.47219
Overall Steps per Second: 9,143.08907

Timestep Collection Time: 4.61881
Timestep Consumption Time: 0.85090
PPO Batch Consumption Time: 0.04483
Total Iteration Time: 5.46970

Cumulative Model Updates: 5,570
Cumulative Timesteps: 92,979,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.99153
Policy Entropy: 1.17201
Value Function Loss: 5.20326

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.06731

Collected Steps per Second: 10,763.20455
Overall Steps per Second: 9,179.08030

Timestep Collection Time: 4.64713
Timestep Consumption Time: 0.80200
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 5.44913

Cumulative Model Updates: 5,573
Cumulative Timesteps: 93,029,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 93029714...
Checkpoint 93029714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.46454
Policy Entropy: 1.16034
Value Function Loss: 5.04916

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.07622

Collected Steps per Second: 10,864.45277
Overall Steps per Second: 9,253.07693

Timestep Collection Time: 4.60364
Timestep Consumption Time: 0.80170
PPO Batch Consumption Time: 0.04068
Total Iteration Time: 5.40534

Cumulative Model Updates: 5,576
Cumulative Timesteps: 93,079,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.73288
Policy Entropy: 1.15981
Value Function Loss: 4.92422

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.06570

Collected Steps per Second: 10,794.08472
Overall Steps per Second: 9,156.28557

Timestep Collection Time: 4.63383
Timestep Consumption Time: 0.82886
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.46270

Cumulative Model Updates: 5,579
Cumulative Timesteps: 93,129,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 93129748...
Checkpoint 93129748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.14810
Policy Entropy: 1.16745
Value Function Loss: 4.75891

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.06334

Collected Steps per Second: 10,592.82849
Overall Steps per Second: 9,022.20232

Timestep Collection Time: 4.72282
Timestep Consumption Time: 0.82217
PPO Batch Consumption Time: 0.03907
Total Iteration Time: 5.54499

Cumulative Model Updates: 5,582
Cumulative Timesteps: 93,179,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.48618
Policy Entropy: 1.17390
Value Function Loss: 4.70161

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.06684

Collected Steps per Second: 10,835.22266
Overall Steps per Second: 9,216.85305

Timestep Collection Time: 4.61716
Timestep Consumption Time: 0.81072
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 5.42788

Cumulative Model Updates: 5,585
Cumulative Timesteps: 93,229,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 93229804...
Checkpoint 93229804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.21858
Policy Entropy: 1.14561
Value Function Loss: 4.81314

Mean KL Divergence: 0.06029
SB3 Clip Fraction: 0.17139
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.05983

Collected Steps per Second: 11,201.13344
Overall Steps per Second: 9,471.83893

Timestep Collection Time: 4.46526
Timestep Consumption Time: 0.81523
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 5.28050

Cumulative Model Updates: 5,588
Cumulative Timesteps: 93,279,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.13764
Policy Entropy: 1.15636
Value Function Loss: 5.01569

Mean KL Divergence: 0.02892
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.05931

Collected Steps per Second: 10,847.13637
Overall Steps per Second: 9,183.68527

Timestep Collection Time: 4.61154
Timestep Consumption Time: 0.83529
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.44683

Cumulative Model Updates: 5,591
Cumulative Timesteps: 93,329,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 93329842...
Checkpoint 93329842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.74063
Policy Entropy: 1.14136
Value Function Loss: 5.15733

Mean KL Divergence: 0.04951
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.06321

Collected Steps per Second: 10,552.00921
Overall Steps per Second: 9,119.63252

Timestep Collection Time: 4.73957
Timestep Consumption Time: 0.74442
PPO Batch Consumption Time: 0.03911
Total Iteration Time: 5.48399

Cumulative Model Updates: 5,594
Cumulative Timesteps: 93,379,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.02934
Policy Entropy: 1.15463
Value Function Loss: 5.06817

Mean KL Divergence: 0.02973
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.04562
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 10,231.71016
Overall Steps per Second: 8,679.05266

Timestep Collection Time: 4.88814
Timestep Consumption Time: 0.87447
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 5.76261

Cumulative Model Updates: 5,597
Cumulative Timesteps: 93,429,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 93429868...
Checkpoint 93429868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.57588
Policy Entropy: 1.13064
Value Function Loss: 5.22283

Mean KL Divergence: 0.03890
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.05602

Collected Steps per Second: 10,803.67431
Overall Steps per Second: 9,148.01278

Timestep Collection Time: 4.63139
Timestep Consumption Time: 0.83822
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 5.46960

Cumulative Model Updates: 5,600
Cumulative Timesteps: 93,479,904

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.18014
Policy Entropy: 1.13880
Value Function Loss: 5.40748

Mean KL Divergence: 0.02954
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.05404

Collected Steps per Second: 11,023.29700
Overall Steps per Second: 9,332.32430

Timestep Collection Time: 4.53621
Timestep Consumption Time: 0.82194
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 5.35815

Cumulative Model Updates: 5,603
Cumulative Timesteps: 93,529,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 93529908...
Checkpoint 93529908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.71867
Policy Entropy: 1.12256
Value Function Loss: 5.34048

Mean KL Divergence: 0.03533
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.03734
Value Function Update Magnitude: 0.06331

Collected Steps per Second: 10,851.62893
Overall Steps per Second: 9,195.89977

Timestep Collection Time: 4.60834
Timestep Consumption Time: 0.82974
PPO Batch Consumption Time: 0.03888
Total Iteration Time: 5.43808

Cumulative Model Updates: 5,606
Cumulative Timesteps: 93,579,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.98754
Policy Entropy: 1.14036
Value Function Loss: 5.45577

Mean KL Divergence: 0.03541
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.04133
Value Function Update Magnitude: 0.06391

Collected Steps per Second: 10,731.28013
Overall Steps per Second: 9,154.43832

Timestep Collection Time: 4.66170
Timestep Consumption Time: 0.80297
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 5.46467

Cumulative Model Updates: 5,609
Cumulative Timesteps: 93,629,942

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 93629942...
Checkpoint 93629942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.45521
Policy Entropy: 1.13188
Value Function Loss: 5.23261

Mean KL Divergence: 0.03402
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.03849
Value Function Update Magnitude: 0.06223

Collected Steps per Second: 10,416.98210
Overall Steps per Second: 8,815.92867

Timestep Collection Time: 4.80158
Timestep Consumption Time: 0.87201
PPO Batch Consumption Time: 0.04490
Total Iteration Time: 5.67359

Cumulative Model Updates: 5,612
Cumulative Timesteps: 93,679,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.36778
Policy Entropy: 1.14413
Value Function Loss: 5.30904

Mean KL Divergence: 0.03020
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.03876
Value Function Update Magnitude: 0.07465

Collected Steps per Second: 10,354.03758
Overall Steps per Second: 8,753.25434

Timestep Collection Time: 4.83077
Timestep Consumption Time: 0.88345
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 5.71422

Cumulative Model Updates: 5,615
Cumulative Timesteps: 93,729,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 93729978...
Checkpoint 93729978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.85403
Policy Entropy: 1.13060
Value Function Loss: 4.97209

Mean KL Divergence: 0.04055
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.08615

Collected Steps per Second: 10,909.55284
Overall Steps per Second: 9,258.78148

Timestep Collection Time: 4.58552
Timestep Consumption Time: 0.81756
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.40309

Cumulative Model Updates: 5,618
Cumulative Timesteps: 93,780,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.61391
Policy Entropy: 1.15523
Value Function Loss: 5.13686

Mean KL Divergence: 0.03345
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.09471

Collected Steps per Second: 10,772.13346
Overall Steps per Second: 9,085.95652

Timestep Collection Time: 4.64402
Timestep Consumption Time: 0.86184
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 5.50586

Cumulative Model Updates: 5,621
Cumulative Timesteps: 93,830,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 93830030...
Checkpoint 93830030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.30764
Policy Entropy: 1.13728
Value Function Loss: 5.38946

Mean KL Divergence: 0.03376
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.03854
Value Function Update Magnitude: 0.09061

Collected Steps per Second: 10,836.75455
Overall Steps per Second: 9,314.77281

Timestep Collection Time: 4.61614
Timestep Consumption Time: 0.75425
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.37039

Cumulative Model Updates: 5,624
Cumulative Timesteps: 93,880,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.03394
Policy Entropy: 1.15722
Value Function Loss: 5.59280

Mean KL Divergence: 0.03139
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.03743
Value Function Update Magnitude: 0.07958

Collected Steps per Second: 10,704.95952
Overall Steps per Second: 9,088.12972

Timestep Collection Time: 4.67148
Timestep Consumption Time: 0.83108
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.50256

Cumulative Model Updates: 5,627
Cumulative Timesteps: 93,930,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 93930062...
Checkpoint 93930062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.97512
Policy Entropy: 1.14070
Value Function Loss: 5.65734

Mean KL Divergence: 0.03624
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.03787
Value Function Update Magnitude: 0.08394

Collected Steps per Second: 10,060.76820
Overall Steps per Second: 8,604.01988

Timestep Collection Time: 4.97040
Timestep Consumption Time: 0.84154
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 5.81193

Cumulative Model Updates: 5,630
Cumulative Timesteps: 93,980,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.99239
Policy Entropy: 1.16412
Value Function Loss: 5.35165

Mean KL Divergence: 0.02894
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.03973
Value Function Update Magnitude: 0.07853

Collected Steps per Second: 10,728.01267
Overall Steps per Second: 9,136.21610

Timestep Collection Time: 4.66293
Timestep Consumption Time: 0.81242
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.47535

Cumulative Model Updates: 5,633
Cumulative Timesteps: 94,030,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 94030092...
Checkpoint 94030092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.26036
Policy Entropy: 1.14339
Value Function Loss: 5.23832

Mean KL Divergence: 0.03431
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.08144

Collected Steps per Second: 10,912.26434
Overall Steps per Second: 9,177.20356

Timestep Collection Time: 4.58512
Timestep Consumption Time: 0.86687
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 5.45199

Cumulative Model Updates: 5,636
Cumulative Timesteps: 94,080,126

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.61447
Policy Entropy: 1.15780
Value Function Loss: 5.02237

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 10,923.36139
Overall Steps per Second: 9,370.95379

Timestep Collection Time: 4.57973
Timestep Consumption Time: 0.75868
PPO Batch Consumption Time: 0.04179
Total Iteration Time: 5.33841

Cumulative Model Updates: 5,639
Cumulative Timesteps: 94,130,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 94130152...
Checkpoint 94130152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.26811
Policy Entropy: 1.13495
Value Function Loss: 5.12341

Mean KL Divergence: 0.03509
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.08293

Collected Steps per Second: 11,352.14441
Overall Steps per Second: 9,543.35719

Timestep Collection Time: 4.40516
Timestep Consumption Time: 0.83493
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.24008

Cumulative Model Updates: 5,642
Cumulative Timesteps: 94,180,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.84121
Policy Entropy: 1.15731
Value Function Loss: 5.23878

Mean KL Divergence: 0.02523
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.04021
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 10,523.26089
Overall Steps per Second: 8,879.47238

Timestep Collection Time: 4.75233
Timestep Consumption Time: 0.87976
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 5.63209

Cumulative Model Updates: 5,645
Cumulative Timesteps: 94,230,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 94230170...
Checkpoint 94230170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.91204
Policy Entropy: 1.14886
Value Function Loss: 5.33470

Mean KL Divergence: 0.03694
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.07884

Collected Steps per Second: 11,550.70968
Overall Steps per Second: 9,568.39375

Timestep Collection Time: 4.33064
Timestep Consumption Time: 0.89719
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 5.22784

Cumulative Model Updates: 5,648
Cumulative Timesteps: 94,280,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.19510
Policy Entropy: 1.17435
Value Function Loss: 5.42616

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.07622

Collected Steps per Second: 11,121.94381
Overall Steps per Second: 9,302.53750

Timestep Collection Time: 4.49760
Timestep Consumption Time: 0.87965
PPO Batch Consumption Time: 0.03969
Total Iteration Time: 5.37724

Cumulative Model Updates: 5,651
Cumulative Timesteps: 94,330,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 94330214...
Checkpoint 94330214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.86289
Policy Entropy: 1.16682
Value Function Loss: 5.32378

Mean KL Divergence: 0.03483
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.04326
Value Function Update Magnitude: 0.07164

Collected Steps per Second: 11,427.60305
Overall Steps per Second: 9,635.25730

Timestep Collection Time: 4.37607
Timestep Consumption Time: 0.81403
PPO Batch Consumption Time: 0.04977
Total Iteration Time: 5.19011

Cumulative Model Updates: 5,654
Cumulative Timesteps: 94,380,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.93591
Policy Entropy: 1.17501
Value Function Loss: 5.57920

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.08160

Collected Steps per Second: 10,410.74678
Overall Steps per Second: 8,791.47876

Timestep Collection Time: 4.80407
Timestep Consumption Time: 0.88484
PPO Batch Consumption Time: 0.04501
Total Iteration Time: 5.68892

Cumulative Model Updates: 5,657
Cumulative Timesteps: 94,430,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 94430236...
Checkpoint 94430236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.35918
Policy Entropy: 1.15694
Value Function Loss: 5.42592

Mean KL Divergence: 0.03746
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.07648

Collected Steps per Second: 10,732.86862
Overall Steps per Second: 9,161.29471

Timestep Collection Time: 4.66120
Timestep Consumption Time: 0.79960
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.46080

Cumulative Model Updates: 5,660
Cumulative Timesteps: 94,480,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.29140
Policy Entropy: 1.15679
Value Function Loss: 5.45727

Mean KL Divergence: 0.02821
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 10,395.13177
Overall Steps per Second: 8,821.73207

Timestep Collection Time: 4.81302
Timestep Consumption Time: 0.85843
PPO Batch Consumption Time: 0.04473
Total Iteration Time: 5.67145

Cumulative Model Updates: 5,663
Cumulative Timesteps: 94,530,296

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 94530296...
Checkpoint 94530296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.56578
Policy Entropy: 1.14729
Value Function Loss: 5.30031

Mean KL Divergence: 0.03097
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.06249

Collected Steps per Second: 10,463.47858
Overall Steps per Second: 8,903.98681

Timestep Collection Time: 4.77910
Timestep Consumption Time: 0.83704
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 5.61614

Cumulative Model Updates: 5,666
Cumulative Timesteps: 94,580,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.50210
Policy Entropy: 1.17013
Value Function Loss: 5.16918

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.06601
Value Function Update Magnitude: 0.05060

Collected Steps per Second: 10,594.51463
Overall Steps per Second: 9,178.40235

Timestep Collection Time: 4.72169
Timestep Consumption Time: 0.72850
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.45019

Cumulative Model Updates: 5,669
Cumulative Timesteps: 94,630,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 94630326...
Checkpoint 94630326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.43889
Policy Entropy: 1.15445
Value Function Loss: 5.05616

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.04761

Collected Steps per Second: 10,498.21198
Overall Steps per Second: 8,919.02654

Timestep Collection Time: 4.76291
Timestep Consumption Time: 0.84331
PPO Batch Consumption Time: 0.04478
Total Iteration Time: 5.60622

Cumulative Model Updates: 5,672
Cumulative Timesteps: 94,680,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.96935
Policy Entropy: 1.14220
Value Function Loss: 4.96681

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.05480

Collected Steps per Second: 10,507.52404
Overall Steps per Second: 8,920.53311

Timestep Collection Time: 4.76116
Timestep Consumption Time: 0.84703
PPO Batch Consumption Time: 0.04549
Total Iteration Time: 5.60818

Cumulative Model Updates: 5,675
Cumulative Timesteps: 94,730,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 94730356...
Checkpoint 94730356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.54658
Policy Entropy: 1.15168
Value Function Loss: 5.02018

Mean KL Divergence: 0.02927
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.07901
Value Function Update Magnitude: 0.05939

Collected Steps per Second: 10,383.83098
Overall Steps per Second: 8,792.02205

Timestep Collection Time: 4.81710
Timestep Consumption Time: 0.87214
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 5.68925

Cumulative Model Updates: 5,678
Cumulative Timesteps: 94,780,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.24580
Policy Entropy: 1.15234
Value Function Loss: 4.89614

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.05358

Collected Steps per Second: 10,807.86933
Overall Steps per Second: 9,171.00922

Timestep Collection Time: 4.62866
Timestep Consumption Time: 0.82613
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 5.45480

Cumulative Model Updates: 5,681
Cumulative Timesteps: 94,830,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 94830402...
Checkpoint 94830402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.61351
Policy Entropy: 1.18068
Value Function Loss: 5.03143

Mean KL Divergence: 0.02925
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.06309
Value Function Update Magnitude: 0.05308

Collected Steps per Second: 10,596.76337
Overall Steps per Second: 9,159.54651

Timestep Collection Time: 4.72012
Timestep Consumption Time: 0.74063
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.46075

Cumulative Model Updates: 5,684
Cumulative Timesteps: 94,880,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.79762
Policy Entropy: 1.17559
Value Function Loss: 5.08695

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.04971

Collected Steps per Second: 10,983.93815
Overall Steps per Second: 9,307.42157

Timestep Collection Time: 4.55301
Timestep Consumption Time: 0.82012
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.37313

Cumulative Model Updates: 5,687
Cumulative Timesteps: 94,930,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 94930430...
Checkpoint 94930430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.51188
Policy Entropy: 1.17363
Value Function Loss: 5.26045

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.05072

Collected Steps per Second: 10,674.57840
Overall Steps per Second: 9,100.24292

Timestep Collection Time: 4.68421
Timestep Consumption Time: 0.81037
PPO Batch Consumption Time: 0.04682
Total Iteration Time: 5.49458

Cumulative Model Updates: 5,690
Cumulative Timesteps: 94,980,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.67997
Policy Entropy: 1.17447
Value Function Loss: 5.25984

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.04747

Collected Steps per Second: 11,028.36188
Overall Steps per Second: 9,334.63612

Timestep Collection Time: 4.53413
Timestep Consumption Time: 0.82270
PPO Batch Consumption Time: 0.04799
Total Iteration Time: 5.35682

Cumulative Model Updates: 5,693
Cumulative Timesteps: 95,030,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 95030436...
Checkpoint 95030436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.11597
Policy Entropy: 1.18108
Value Function Loss: 5.15716

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.06208
Value Function Update Magnitude: 0.05497

Collected Steps per Second: 10,205.83516
Overall Steps per Second: 8,686.70381

Timestep Collection Time: 4.89916
Timestep Consumption Time: 0.85677
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 5.75592

Cumulative Model Updates: 5,696
Cumulative Timesteps: 95,080,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.00481
Policy Entropy: 1.17611
Value Function Loss: 5.12537

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.10522

Collected Steps per Second: 10,696.24836
Overall Steps per Second: 9,134.28958

Timestep Collection Time: 4.67641
Timestep Consumption Time: 0.79966
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.47607

Cumulative Model Updates: 5,699
Cumulative Timesteps: 95,130,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 95130456...
Checkpoint 95130456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.68771
Policy Entropy: 1.15928
Value Function Loss: 5.02037

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.06359
Value Function Update Magnitude: 0.11466

Collected Steps per Second: 10,931.68586
Overall Steps per Second: 9,008.63248

Timestep Collection Time: 4.57441
Timestep Consumption Time: 0.97649
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 5.55090

Cumulative Model Updates: 5,702
Cumulative Timesteps: 95,180,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.90558
Policy Entropy: 1.15499
Value Function Loss: 5.15510

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.10095

Collected Steps per Second: 10,889.67201
Overall Steps per Second: 9,180.57868

Timestep Collection Time: 4.59481
Timestep Consumption Time: 0.85539
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 5.45020

Cumulative Model Updates: 5,705
Cumulative Timesteps: 95,230,498

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 95230498...
Checkpoint 95230498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.57315
Policy Entropy: 1.19227
Value Function Loss: 4.99264

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.08065

Collected Steps per Second: 10,747.33718
Overall Steps per Second: 9,280.63915

Timestep Collection Time: 4.65455
Timestep Consumption Time: 0.73560
PPO Batch Consumption Time: 0.03982
Total Iteration Time: 5.39015

Cumulative Model Updates: 5,708
Cumulative Timesteps: 95,280,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.11517
Policy Entropy: 1.18332
Value Function Loss: 4.90505

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.06695

Collected Steps per Second: 10,316.90759
Overall Steps per Second: 8,786.67370

Timestep Collection Time: 4.84855
Timestep Consumption Time: 0.84439
PPO Batch Consumption Time: 0.04665
Total Iteration Time: 5.69294

Cumulative Model Updates: 5,711
Cumulative Timesteps: 95,330,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 95330544...
Checkpoint 95330544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.94161
Policy Entropy: 1.19111
Value Function Loss: 4.60478

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.05884

Collected Steps per Second: 10,383.33838
Overall Steps per Second: 8,911.03979

Timestep Collection Time: 4.81695
Timestep Consumption Time: 0.79587
PPO Batch Consumption Time: 0.04567
Total Iteration Time: 5.61281

Cumulative Model Updates: 5,714
Cumulative Timesteps: 95,380,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.81103
Policy Entropy: 1.18309
Value Function Loss: 4.59828

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.06124

Collected Steps per Second: 10,766.60088
Overall Steps per Second: 9,000.88778

Timestep Collection Time: 4.64548
Timestep Consumption Time: 0.91131
PPO Batch Consumption Time: 0.04754
Total Iteration Time: 5.55679

Cumulative Model Updates: 5,717
Cumulative Timesteps: 95,430,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 95430576...
Checkpoint 95430576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.35326
Policy Entropy: 1.17288
Value Function Loss: 4.51405

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.09976

Collected Steps per Second: 11,022.12627
Overall Steps per Second: 9,368.28695

Timestep Collection Time: 4.53833
Timestep Consumption Time: 0.80118
PPO Batch Consumption Time: 0.03887
Total Iteration Time: 5.33950

Cumulative Model Updates: 5,720
Cumulative Timesteps: 95,480,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.75577
Policy Entropy: 1.17281
Value Function Loss: 4.51370

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.10861

Collected Steps per Second: 10,957.04579
Overall Steps per Second: 9,171.99183

Timestep Collection Time: 4.56327
Timestep Consumption Time: 0.88810
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.45138

Cumulative Model Updates: 5,723
Cumulative Timesteps: 95,530,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 95530598...
Checkpoint 95530598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.35497
Policy Entropy: 1.16877
Value Function Loss: 4.55220

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.08993

Collected Steps per Second: 10,653.14050
Overall Steps per Second: 8,872.25671

Timestep Collection Time: 4.69364
Timestep Consumption Time: 0.94213
PPO Batch Consumption Time: 0.05156
Total Iteration Time: 5.63577

Cumulative Model Updates: 5,726
Cumulative Timesteps: 95,580,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.00667
Policy Entropy: 1.17647
Value Function Loss: 4.54098

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.09055

Collected Steps per Second: 10,836.55050
Overall Steps per Second: 9,341.53917

Timestep Collection Time: 4.61494
Timestep Consumption Time: 0.73857
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 5.35351

Cumulative Model Updates: 5,729
Cumulative Timesteps: 95,630,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 95630610...
Checkpoint 95630610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.28165
Policy Entropy: 1.14723
Value Function Loss: 4.62100

Mean KL Divergence: 0.04207
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.06448
Value Function Update Magnitude: 0.09321

Collected Steps per Second: 10,779.87054
Overall Steps per Second: 9,074.86385

Timestep Collection Time: 4.64050
Timestep Consumption Time: 0.87187
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 5.51237

Cumulative Model Updates: 5,732
Cumulative Timesteps: 95,680,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.99062
Policy Entropy: 1.17255
Value Function Loss: 4.73581

Mean KL Divergence: 0.03320
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.08138

Collected Steps per Second: 10,969.35115
Overall Steps per Second: 9,291.36524

Timestep Collection Time: 4.55852
Timestep Consumption Time: 0.82325
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 5.38177

Cumulative Model Updates: 5,735
Cumulative Timesteps: 95,730,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 95730638...
Checkpoint 95730638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.29061
Policy Entropy: 1.15036
Value Function Loss: 4.72502

Mean KL Divergence: 0.04682
SB3 Clip Fraction: 0.16906
Policy Update Magnitude: 0.04433
Value Function Update Magnitude: 0.06858

Collected Steps per Second: 10,938.58403
Overall Steps per Second: 9,164.44827

Timestep Collection Time: 4.57408
Timestep Consumption Time: 0.88549
PPO Batch Consumption Time: 0.03915
Total Iteration Time: 5.45958

Cumulative Model Updates: 5,738
Cumulative Timesteps: 95,780,672

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.99009
Policy Entropy: 1.16935
Value Function Loss: 4.68923

Mean KL Divergence: 0.02965
SB3 Clip Fraction: 0.14501
Policy Update Magnitude: 0.03870
Value Function Update Magnitude: 0.06411

Collected Steps per Second: 10,869.90155
Overall Steps per Second: 9,195.92886

Timestep Collection Time: 4.60207
Timestep Consumption Time: 0.83773
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 5.43980

Cumulative Model Updates: 5,741
Cumulative Timesteps: 95,830,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 95830696...
Checkpoint 95830696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.28761
Policy Entropy: 1.15006
Value Function Loss: 4.45645

Mean KL Divergence: 0.04300
SB3 Clip Fraction: 0.15547
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.06488

Collected Steps per Second: 10,313.66129
Overall Steps per Second: 8,883.86177

Timestep Collection Time: 4.84988
Timestep Consumption Time: 0.78056
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 5.63043

Cumulative Model Updates: 5,744
Cumulative Timesteps: 95,880,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.82989
Policy Entropy: 1.17997
Value Function Loss: 4.64057

Mean KL Divergence: 0.03829
SB3 Clip Fraction: 0.16773
Policy Update Magnitude: 0.04153
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 10,766.23045
Overall Steps per Second: 9,081.86073

Timestep Collection Time: 4.64694
Timestep Consumption Time: 0.86185
PPO Batch Consumption Time: 0.04135
Total Iteration Time: 5.50878

Cumulative Model Updates: 5,747
Cumulative Timesteps: 95,930,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 95930746...
Checkpoint 95930746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.07631
Policy Entropy: 1.16154
Value Function Loss: 4.65247

Mean KL Divergence: 0.03037
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.03718
Value Function Update Magnitude: 0.05411

Collected Steps per Second: 10,780.73992
Overall Steps per Second: 9,242.58859

Timestep Collection Time: 4.63920
Timestep Consumption Time: 0.77206
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 5.41125

Cumulative Model Updates: 5,750
Cumulative Timesteps: 95,980,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.22591
Policy Entropy: 1.18574
Value Function Loss: 4.64521

Mean KL Divergence: 0.03158
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.04516

Collected Steps per Second: 10,755.47304
Overall Steps per Second: 9,093.50433

Timestep Collection Time: 4.64917
Timestep Consumption Time: 0.84970
PPO Batch Consumption Time: 0.04029
Total Iteration Time: 5.49887

Cumulative Model Updates: 5,753
Cumulative Timesteps: 96,030,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 96030764...
Checkpoint 96030764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.73539
Policy Entropy: 1.16564
Value Function Loss: 4.51350

Mean KL Divergence: 0.04251
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.03726
Value Function Update Magnitude: 0.04018

Collected Steps per Second: 10,498.94568
Overall Steps per Second: 8,930.97070

Timestep Collection Time: 4.76486
Timestep Consumption Time: 0.83655
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.60141

Cumulative Model Updates: 5,756
Cumulative Timesteps: 96,080,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.38529
Policy Entropy: 1.18475
Value Function Loss: 4.63129

Mean KL Divergence: 0.02987
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.03573
Value Function Update Magnitude: 0.07688

Collected Steps per Second: 10,507.15885
Overall Steps per Second: 9,043.02940

Timestep Collection Time: 4.76018
Timestep Consumption Time: 0.77071
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 5.53089

Cumulative Model Updates: 5,759
Cumulative Timesteps: 96,130,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 96130806...
Checkpoint 96130806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.00774
Policy Entropy: 1.16771
Value Function Loss: 4.86410

Mean KL Divergence: 0.03548
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.03644
Value Function Update Magnitude: 0.07272

Collected Steps per Second: 10,626.34437
Overall Steps per Second: 8,890.47090

Timestep Collection Time: 4.70698
Timestep Consumption Time: 0.91904
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.62602

Cumulative Model Updates: 5,762
Cumulative Timesteps: 96,180,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.18590
Policy Entropy: 1.17948
Value Function Loss: 4.85385

Mean KL Divergence: 0.02994
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.03548
Value Function Update Magnitude: 0.07160

Collected Steps per Second: 10,606.66133
Overall Steps per Second: 9,132.60885

Timestep Collection Time: 4.71553
Timestep Consumption Time: 0.76111
PPO Batch Consumption Time: 0.04496
Total Iteration Time: 5.47664

Cumulative Model Updates: 5,765
Cumulative Timesteps: 96,230,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 96230840...
Checkpoint 96230840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.37468
Policy Entropy: 1.15885
Value Function Loss: 4.74189

Mean KL Divergence: 0.03727
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.03665
Value Function Update Magnitude: 0.07300

Collected Steps per Second: 10,748.18213
Overall Steps per Second: 9,054.24489

Timestep Collection Time: 4.65325
Timestep Consumption Time: 0.87057
PPO Batch Consumption Time: 0.03868
Total Iteration Time: 5.52382

Cumulative Model Updates: 5,768
Cumulative Timesteps: 96,280,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.70670
Policy Entropy: 1.16800
Value Function Loss: 4.76041

Mean KL Divergence: 0.02719
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.03875
Value Function Update Magnitude: 0.07324

Collected Steps per Second: 10,818.10146
Overall Steps per Second: 9,045.13192

Timestep Collection Time: 4.62392
Timestep Consumption Time: 0.90635
PPO Batch Consumption Time: 0.04535
Total Iteration Time: 5.53027

Cumulative Model Updates: 5,771
Cumulative Timesteps: 96,330,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 96330876...
Checkpoint 96330876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.21382
Policy Entropy: 1.14562
Value Function Loss: 4.85955

Mean KL Divergence: 0.04164
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.07851

Collected Steps per Second: 10,969.00382
Overall Steps per Second: 9,229.74550

Timestep Collection Time: 4.55958
Timestep Consumption Time: 0.85921
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 5.41878

Cumulative Model Updates: 5,774
Cumulative Timesteps: 96,380,890

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.70763
Policy Entropy: 1.17287
Value Function Loss: 4.79757

Mean KL Divergence: 0.03187
SB3 Clip Fraction: 0.15288
Policy Update Magnitude: 0.04170
Value Function Update Magnitude: 0.07439

Collected Steps per Second: 10,303.31955
Overall Steps per Second: 8,741.12093

Timestep Collection Time: 4.85378
Timestep Consumption Time: 0.86746
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 5.72123

Cumulative Model Updates: 5,777
Cumulative Timesteps: 96,430,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 96430900...
Checkpoint 96430900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.29178
Policy Entropy: 1.17366
Value Function Loss: 4.73839

Mean KL Divergence: 0.03209
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.04060
Value Function Update Magnitude: 0.07817

Collected Steps per Second: 10,904.07155
Overall Steps per Second: 9,136.38516

Timestep Collection Time: 4.58819
Timestep Consumption Time: 0.88771
PPO Batch Consumption Time: 0.04055
Total Iteration Time: 5.47591

Cumulative Model Updates: 5,780
Cumulative Timesteps: 96,480,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.56877
Policy Entropy: 1.19649
Value Function Loss: 4.68044

Mean KL Divergence: 0.03299
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.03783
Value Function Update Magnitude: 0.07321

Collected Steps per Second: 11,086.28677
Overall Steps per Second: 9,300.07344

Timestep Collection Time: 4.51170
Timestep Consumption Time: 0.86654
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 5.37824

Cumulative Model Updates: 5,783
Cumulative Timesteps: 96,530,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 96530948...
Checkpoint 96530948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.30294
Policy Entropy: 1.18513
Value Function Loss: 4.70042

Mean KL Divergence: 0.03312
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.03384
Value Function Update Magnitude: 0.08720

Collected Steps per Second: 11,347.47975
Overall Steps per Second: 9,495.71779

Timestep Collection Time: 4.40644
Timestep Consumption Time: 0.85930
PPO Batch Consumption Time: 0.04971
Total Iteration Time: 5.26574

Cumulative Model Updates: 5,786
Cumulative Timesteps: 96,580,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.71698
Policy Entropy: 1.19736
Value Function Loss: 4.63706

Mean KL Divergence: 0.02871
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.03521
Value Function Update Magnitude: 0.09169

Collected Steps per Second: 10,730.21745
Overall Steps per Second: 9,123.24822

Timestep Collection Time: 4.66179
Timestep Consumption Time: 0.82113
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 5.48292

Cumulative Model Updates: 5,789
Cumulative Timesteps: 96,630,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 96630972...
Checkpoint 96630972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.75394
Policy Entropy: 1.17338
Value Function Loss: 4.74729

Mean KL Divergence: 0.03252
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.06934

Collected Steps per Second: 10,518.82229
Overall Steps per Second: 8,864.01594

Timestep Collection Time: 4.75471
Timestep Consumption Time: 0.88765
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 5.64236

Cumulative Model Updates: 5,792
Cumulative Timesteps: 96,680,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.63322
Policy Entropy: 1.18784
Value Function Loss: 4.83923

Mean KL Divergence: 0.02573
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.06900

Collected Steps per Second: 10,673.05203
Overall Steps per Second: 9,077.86044

Timestep Collection Time: 4.68488
Timestep Consumption Time: 0.82324
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.50813

Cumulative Model Updates: 5,795
Cumulative Timesteps: 96,730,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 96730988...
Checkpoint 96730988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.00506
Policy Entropy: 1.15827
Value Function Loss: 4.76123

Mean KL Divergence: 0.03956
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.06544

Collected Steps per Second: 10,624.61420
Overall Steps per Second: 9,182.54727

Timestep Collection Time: 4.70681
Timestep Consumption Time: 0.73918
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 5.44598

Cumulative Model Updates: 5,798
Cumulative Timesteps: 96,780,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.42643
Policy Entropy: 1.18330
Value Function Loss: 4.86363

Mean KL Divergence: 0.03376
SB3 Clip Fraction: 0.15357
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.06407

Collected Steps per Second: 10,934.63109
Overall Steps per Second: 9,250.01555

Timestep Collection Time: 4.57354
Timestep Consumption Time: 0.83293
PPO Batch Consumption Time: 0.03953
Total Iteration Time: 5.40648

Cumulative Model Updates: 5,801
Cumulative Timesteps: 96,831,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 96831006...
Checkpoint 96831006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.14486
Policy Entropy: 1.16510
Value Function Loss: 4.87271

Mean KL Divergence: 0.04599
SB3 Clip Fraction: 0.16773
Policy Update Magnitude: 0.04235
Value Function Update Magnitude: 0.06647

Collected Steps per Second: 10,701.96446
Overall Steps per Second: 9,155.19925

Timestep Collection Time: 4.67241
Timestep Consumption Time: 0.78940
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 5.46181

Cumulative Model Updates: 5,804
Cumulative Timesteps: 96,881,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.07705
Policy Entropy: 1.18525
Value Function Loss: 4.96232

Mean KL Divergence: 0.03348
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.03856
Value Function Update Magnitude: 0.05924

Collected Steps per Second: 10,793.60588
Overall Steps per Second: 9,193.61282

Timestep Collection Time: 4.63293
Timestep Consumption Time: 0.80628
PPO Batch Consumption Time: 0.04461
Total Iteration Time: 5.43921

Cumulative Model Updates: 5,807
Cumulative Timesteps: 96,931,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 96931016...
Checkpoint 96931016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.91575
Policy Entropy: 1.18310
Value Function Loss: 4.87935

Mean KL Divergence: 0.02820
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.04410
Value Function Update Magnitude: 0.06173

Collected Steps per Second: 10,381.49946
Overall Steps per Second: 8,920.84536

Timestep Collection Time: 4.81915
Timestep Consumption Time: 0.78906
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.60821

Cumulative Model Updates: 5,810
Cumulative Timesteps: 96,981,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.45109
Policy Entropy: 1.19498
Value Function Loss: 4.74243

Mean KL Divergence: 0.03183
SB3 Clip Fraction: 0.14685
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.06195

Collected Steps per Second: 10,690.25684
Overall Steps per Second: 9,244.89988

Timestep Collection Time: 4.67716
Timestep Consumption Time: 0.73123
PPO Batch Consumption Time: 0.04054
Total Iteration Time: 5.40839

Cumulative Model Updates: 5,813
Cumulative Timesteps: 97,031,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 97031046...
Checkpoint 97031046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.68723
Policy Entropy: 1.17089
Value Function Loss: 4.92200

Mean KL Divergence: 0.04357
SB3 Clip Fraction: 0.15827
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 10,861.85940
Overall Steps per Second: 9,213.73471

Timestep Collection Time: 4.60437
Timestep Consumption Time: 0.82362
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.42798

Cumulative Model Updates: 5,816
Cumulative Timesteps: 97,081,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.31024
Policy Entropy: 1.18187
Value Function Loss: 4.70859

Mean KL Divergence: 0.02784
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.04020
Value Function Update Magnitude: 0.07538

Collected Steps per Second: 10,804.76508
Overall Steps per Second: 9,197.81711

Timestep Collection Time: 4.62833
Timestep Consumption Time: 0.80861
PPO Batch Consumption Time: 0.04145
Total Iteration Time: 5.43694

Cumulative Model Updates: 5,819
Cumulative Timesteps: 97,131,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 97131066...
Checkpoint 97131066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.75904
Policy Entropy: 1.16649
Value Function Loss: 4.85809

Mean KL Divergence: 0.03643
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.04026
Value Function Update Magnitude: 0.08313

Collected Steps per Second: 11,143.82294
Overall Steps per Second: 9,451.05334

Timestep Collection Time: 4.48679
Timestep Consumption Time: 0.80363
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 5.29042

Cumulative Model Updates: 5,822
Cumulative Timesteps: 97,181,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.71760
Policy Entropy: 1.17858
Value Function Loss: 4.55601

Mean KL Divergence: 0.02845
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.08892

Collected Steps per Second: 10,240.81833
Overall Steps per Second: 8,806.86181

Timestep Collection Time: 4.88379
Timestep Consumption Time: 0.79519
PPO Batch Consumption Time: 0.03930
Total Iteration Time: 5.67898

Cumulative Model Updates: 5,825
Cumulative Timesteps: 97,231,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 97231080...
Checkpoint 97231080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.89568
Policy Entropy: 1.16570
Value Function Loss: 4.63465

Mean KL Divergence: 0.03716
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.03947
Value Function Update Magnitude: 0.08268

Collected Steps per Second: 10,576.87244
Overall Steps per Second: 8,927.13631

Timestep Collection Time: 4.72862
Timestep Consumption Time: 0.87385
PPO Batch Consumption Time: 0.04524
Total Iteration Time: 5.60247

Cumulative Model Updates: 5,828
Cumulative Timesteps: 97,281,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.72357
Policy Entropy: 1.18497
Value Function Loss: 4.58220

Mean KL Divergence: 0.03023
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.03765
Value Function Update Magnitude: 0.08389

Collected Steps per Second: 10,938.26577
Overall Steps per Second: 9,306.56164

Timestep Collection Time: 4.57385
Timestep Consumption Time: 0.80193
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 5.37578

Cumulative Model Updates: 5,831
Cumulative Timesteps: 97,331,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 97331124...
Checkpoint 97331124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.25734
Policy Entropy: 1.17662
Value Function Loss: 4.59482

Mean KL Divergence: 0.02815
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.03837
Value Function Update Magnitude: 0.08108

Collected Steps per Second: 10,948.80789
Overall Steps per Second: 9,192.04683

Timestep Collection Time: 4.56853
Timestep Consumption Time: 0.87313
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 5.44166

Cumulative Model Updates: 5,834
Cumulative Timesteps: 97,381,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.43577
Policy Entropy: 1.19204
Value Function Loss: 4.83360

Mean KL Divergence: 0.03100
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.06878

Collected Steps per Second: 10,972.40945
Overall Steps per Second: 9,392.50981

Timestep Collection Time: 4.55962
Timestep Consumption Time: 0.76697
PPO Batch Consumption Time: 0.05069
Total Iteration Time: 5.32658

Cumulative Model Updates: 5,837
Cumulative Timesteps: 97,431,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 97431174...
Checkpoint 97431174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.55087
Policy Entropy: 1.18857
Value Function Loss: 4.67477

Mean KL Divergence: 0.03471
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.03743
Value Function Update Magnitude: 0.07061

Collected Steps per Second: 10,814.81383
Overall Steps per Second: 9,164.30399

Timestep Collection Time: 4.62569
Timestep Consumption Time: 0.83310
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.45879

Cumulative Model Updates: 5,840
Cumulative Timesteps: 97,481,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.02577
Policy Entropy: 1.20153
Value Function Loss: 4.69964

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.03647
Value Function Update Magnitude: 0.06422

Collected Steps per Second: 10,373.48012
Overall Steps per Second: 8,971.85649

Timestep Collection Time: 4.82210
Timestep Consumption Time: 0.75333
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 5.57543

Cumulative Model Updates: 5,843
Cumulative Timesteps: 97,531,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 97531222...
Checkpoint 97531222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.78752
Policy Entropy: 1.17914
Value Function Loss: 4.58427

Mean KL Divergence: 0.03456
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.04204
Value Function Update Magnitude: 0.07004

Collected Steps per Second: 10,889.79628
Overall Steps per Second: 9,100.02069

Timestep Collection Time: 4.59329
Timestep Consumption Time: 0.90340
PPO Batch Consumption Time: 0.04725
Total Iteration Time: 5.49669

Cumulative Model Updates: 5,846
Cumulative Timesteps: 97,581,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.37770
Policy Entropy: 1.18804
Value Function Loss: 4.62134

Mean KL Divergence: 0.02933
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.03719
Value Function Update Magnitude: 0.05840

Collected Steps per Second: 11,045.39182
Overall Steps per Second: 9,423.14337

Timestep Collection Time: 4.52913
Timestep Consumption Time: 0.77972
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.30884

Cumulative Model Updates: 5,849
Cumulative Timesteps: 97,631,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 97631268...
Checkpoint 97631268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.97903
Policy Entropy: 1.17093
Value Function Loss: 4.63721

Mean KL Divergence: 0.03228
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.03993
Value Function Update Magnitude: 0.05571

Collected Steps per Second: 10,854.16502
Overall Steps per Second: 9,166.88425

Timestep Collection Time: 4.60800
Timestep Consumption Time: 0.84816
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 5.45616

Cumulative Model Updates: 5,852
Cumulative Timesteps: 97,681,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.66331
Policy Entropy: 1.17815
Value Function Loss: 4.51141

Mean KL Divergence: 0.02670
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.03991
Value Function Update Magnitude: 0.05272

Collected Steps per Second: 10,715.98134
Overall Steps per Second: 9,069.43451

Timestep Collection Time: 4.66873
Timestep Consumption Time: 0.84760
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 5.51633

Cumulative Model Updates: 5,855
Cumulative Timesteps: 97,731,314

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 97731314...
Checkpoint 97731314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.69491
Policy Entropy: 1.15785
Value Function Loss: 4.62034

Mean KL Divergence: 0.03371
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.03696
Value Function Update Magnitude: 0.05088

Collected Steps per Second: 10,066.04939
Overall Steps per Second: 8,738.84380

Timestep Collection Time: 4.96878
Timestep Consumption Time: 0.75463
PPO Batch Consumption Time: 0.04001
Total Iteration Time: 5.72341

Cumulative Model Updates: 5,858
Cumulative Timesteps: 97,781,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.03019
Policy Entropy: 1.16852
Value Function Loss: 4.44164

Mean KL Divergence: 0.02633
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.03752
Value Function Update Magnitude: 0.05288

Collected Steps per Second: 10,882.48649
Overall Steps per Second: 9,174.74026

Timestep Collection Time: 4.59564
Timestep Consumption Time: 0.85541
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 5.45105

Cumulative Model Updates: 5,861
Cumulative Timesteps: 97,831,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 97831342...
Checkpoint 97831342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.96825
Policy Entropy: 1.14869
Value Function Loss: 4.54886

Mean KL Divergence: 0.03235
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.03941
Value Function Update Magnitude: 0.05624

Collected Steps per Second: 10,780.85425
Overall Steps per Second: 9,151.88735

Timestep Collection Time: 4.63915
Timestep Consumption Time: 0.82573
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 5.46488

Cumulative Model Updates: 5,864
Cumulative Timesteps: 97,881,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.77042
Policy Entropy: 1.16800
Value Function Loss: 4.58401

Mean KL Divergence: 0.02635
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 11,088.21244
Overall Steps per Second: 9,359.52848

Timestep Collection Time: 4.51001
Timestep Consumption Time: 0.83299
PPO Batch Consumption Time: 0.03831
Total Iteration Time: 5.34300

Cumulative Model Updates: 5,867
Cumulative Timesteps: 97,931,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 97931364...
Checkpoint 97931364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.82766
Policy Entropy: 1.15189
Value Function Loss: 4.84385

Mean KL Divergence: 0.03437
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.03829
Value Function Update Magnitude: 0.06368

Collected Steps per Second: 10,781.29455
Overall Steps per Second: 8,990.01579

Timestep Collection Time: 4.64063
Timestep Consumption Time: 0.92465
PPO Batch Consumption Time: 0.04759
Total Iteration Time: 5.56529

Cumulative Model Updates: 5,870
Cumulative Timesteps: 97,981,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.70239
Policy Entropy: 1.18056
Value Function Loss: 5.01592

Mean KL Divergence: 0.02806
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.03480
Value Function Update Magnitude: 0.06671

Collected Steps per Second: 10,731.73629
Overall Steps per Second: 9,139.15944

Timestep Collection Time: 4.66076
Timestep Consumption Time: 0.81218
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.47293

Cumulative Model Updates: 5,873
Cumulative Timesteps: 98,031,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 98031414...
Checkpoint 98031414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.32682
Policy Entropy: 1.16388
Value Function Loss: 4.85499

Mean KL Divergence: 0.02902
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.03616
Value Function Update Magnitude: 0.05597

Collected Steps per Second: 10,545.40392
Overall Steps per Second: 8,882.90090

Timestep Collection Time: 4.74387
Timestep Consumption Time: 0.88785
PPO Batch Consumption Time: 0.04570
Total Iteration Time: 5.63172

Cumulative Model Updates: 5,876
Cumulative Timesteps: 98,081,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.46778
Policy Entropy: 1.17294
Value Function Loss: 4.71984

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.04690

Collected Steps per Second: 10,614.59913
Overall Steps per Second: 9,028.91282

Timestep Collection Time: 4.71068
Timestep Consumption Time: 0.82730
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.53799

Cumulative Model Updates: 5,879
Cumulative Timesteps: 98,131,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 98131442...
Checkpoint 98131442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.71325
Policy Entropy: 1.15088
Value Function Loss: 4.65995

Mean KL Divergence: 0.03684
SB3 Clip Fraction: 0.14270
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.04285

Collected Steps per Second: 10,630.51634
Overall Steps per Second: 9,172.72312

Timestep Collection Time: 4.70645
Timestep Consumption Time: 0.74798
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 5.45443

Cumulative Model Updates: 5,882
Cumulative Timesteps: 98,181,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.89464
Policy Entropy: 1.17082
Value Function Loss: 4.62094

Mean KL Divergence: 0.03138
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.03585
Value Function Update Magnitude: 0.03876

Collected Steps per Second: 10,683.44994
Overall Steps per Second: 9,042.22490

Timestep Collection Time: 4.68276
Timestep Consumption Time: 0.84995
PPO Batch Consumption Time: 0.04473
Total Iteration Time: 5.53271

Cumulative Model Updates: 5,885
Cumulative Timesteps: 98,231,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 98231502...
Checkpoint 98231502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.65602
Policy Entropy: 1.16426
Value Function Loss: 4.76326

Mean KL Divergence: 0.03110
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.03521
Value Function Update Magnitude: 0.03481

Collected Steps per Second: 10,883.61336
Overall Steps per Second: 9,308.80434

Timestep Collection Time: 4.59406
Timestep Consumption Time: 0.77720
PPO Batch Consumption Time: 0.04777
Total Iteration Time: 5.37126

Cumulative Model Updates: 5,888
Cumulative Timesteps: 98,281,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.06652
Policy Entropy: 1.19058
Value Function Loss: 4.65910

Mean KL Divergence: 0.02938
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.03612
Value Function Update Magnitude: 0.03416

Collected Steps per Second: 10,111.07487
Overall Steps per Second: 8,617.69739

Timestep Collection Time: 4.94705
Timestep Consumption Time: 0.85728
PPO Batch Consumption Time: 0.04653
Total Iteration Time: 5.80433

Cumulative Model Updates: 5,891
Cumulative Timesteps: 98,331,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 98331522...
Checkpoint 98331522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.51943
Policy Entropy: 1.17273
Value Function Loss: 4.66600

Mean KL Divergence: 0.03152
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.03281
Value Function Update Magnitude: 0.03686

Collected Steps per Second: 10,757.66555
Overall Steps per Second: 9,134.18151

Timestep Collection Time: 4.64878
Timestep Consumption Time: 0.82626
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 5.47504

Cumulative Model Updates: 5,894
Cumulative Timesteps: 98,381,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.77294
Policy Entropy: 1.18884
Value Function Loss: 4.50526

Mean KL Divergence: 0.02786
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.03407
Value Function Update Magnitude: 0.03566

Collected Steps per Second: 10,707.54937
Overall Steps per Second: 9,160.98743

Timestep Collection Time: 4.67035
Timestep Consumption Time: 0.78845
PPO Batch Consumption Time: 0.04578
Total Iteration Time: 5.45880

Cumulative Model Updates: 5,897
Cumulative Timesteps: 98,431,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 98431540...
Checkpoint 98431540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.59637
Policy Entropy: 1.17024
Value Function Loss: 4.62690

Mean KL Divergence: 0.03147
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.03686
Value Function Update Magnitude: 0.04563

Collected Steps per Second: 10,724.00776
Overall Steps per Second: 9,149.73227

Timestep Collection Time: 4.66337
Timestep Consumption Time: 0.80237
PPO Batch Consumption Time: 0.03922
Total Iteration Time: 5.46573

Cumulative Model Updates: 5,900
Cumulative Timesteps: 98,481,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.77953
Policy Entropy: 1.17425
Value Function Loss: 4.82323

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.03951
Value Function Update Magnitude: 0.04014

Collected Steps per Second: 11,114.48030
Overall Steps per Second: 9,495.98815

Timestep Collection Time: 4.50026
Timestep Consumption Time: 0.76702
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 5.26728

Cumulative Model Updates: 5,903
Cumulative Timesteps: 98,531,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 98531568...
Checkpoint 98531568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.51799
Policy Entropy: 1.15858
Value Function Loss: 4.89010

Mean KL Divergence: 0.03872
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.04415
Value Function Update Magnitude: 0.03708

Collected Steps per Second: 11,122.51918
Overall Steps per Second: 9,150.82887

Timestep Collection Time: 4.49808
Timestep Consumption Time: 0.96918
PPO Batch Consumption Time: 0.04312
Total Iteration Time: 5.46726

Cumulative Model Updates: 5,906
Cumulative Timesteps: 98,581,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.53712
Policy Entropy: 1.16852
Value Function Loss: 5.02235

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.04425
Value Function Update Magnitude: 0.04258

Collected Steps per Second: 11,013.44142
Overall Steps per Second: 9,338.73834

Timestep Collection Time: 4.54081
Timestep Consumption Time: 0.81430
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 5.35511

Cumulative Model Updates: 5,909
Cumulative Timesteps: 98,631,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 98631608...
Checkpoint 98631608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.61032
Policy Entropy: 1.15082
Value Function Loss: 4.94702

Mean KL Divergence: 0.03184
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.04156

Collected Steps per Second: 11,132.78614
Overall Steps per Second: 9,509.83117

Timestep Collection Time: 4.49339
Timestep Consumption Time: 0.76685
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 5.26024

Cumulative Model Updates: 5,912
Cumulative Timesteps: 98,681,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.01021
Policy Entropy: 1.16336
Value Function Loss: 5.07618

Mean KL Divergence: 0.03034
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.03739

Collected Steps per Second: 11,003.80074
Overall Steps per Second: 9,238.92324

Timestep Collection Time: 4.54443
Timestep Consumption Time: 0.86811
PPO Batch Consumption Time: 0.04441
Total Iteration Time: 5.41254

Cumulative Model Updates: 5,915
Cumulative Timesteps: 98,731,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 98731638...
Checkpoint 98731638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.10007
Policy Entropy: 1.15309
Value Function Loss: 5.02819

Mean KL Divergence: 0.03169
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.04165

Collected Steps per Second: 10,804.03981
Overall Steps per Second: 9,227.11304

Timestep Collection Time: 4.62864
Timestep Consumption Time: 0.79104
PPO Batch Consumption Time: 0.04255
Total Iteration Time: 5.41968

Cumulative Model Updates: 5,918
Cumulative Timesteps: 98,781,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.61257
Policy Entropy: 1.17573
Value Function Loss: 5.16403

Mean KL Divergence: 0.02917
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.03685

Collected Steps per Second: 10,821.67256
Overall Steps per Second: 9,170.46700

Timestep Collection Time: 4.62331
Timestep Consumption Time: 0.83246
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 5.45577

Cumulative Model Updates: 5,921
Cumulative Timesteps: 98,831,678

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 98831678...
Checkpoint 98831678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.72062
Policy Entropy: 1.15627
Value Function Loss: 5.08826

Mean KL Divergence: 0.04171
SB3 Clip Fraction: 0.15099
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.04914

Collected Steps per Second: 10,118.94925
Overall Steps per Second: 8,660.79909

Timestep Collection Time: 4.94241
Timestep Consumption Time: 0.83211
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 5.77452

Cumulative Model Updates: 5,924
Cumulative Timesteps: 98,881,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.38711
Policy Entropy: 1.17375
Value Function Loss: 5.38747

Mean KL Divergence: 0.02915
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.04399
Value Function Update Magnitude: 0.05211

Collected Steps per Second: 10,695.63593
Overall Steps per Second: 9,231.68400

Timestep Collection Time: 4.67593
Timestep Consumption Time: 0.74150
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.41743

Cumulative Model Updates: 5,927
Cumulative Timesteps: 98,931,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 98931702...
Checkpoint 98931702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.00404
Policy Entropy: 1.15677
Value Function Loss: 5.18958

Mean KL Divergence: 0.03410
SB3 Clip Fraction: 0.14183
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.04824

Collected Steps per Second: 10,440.60628
Overall Steps per Second: 8,954.89664

Timestep Collection Time: 4.79053
Timestep Consumption Time: 0.79480
PPO Batch Consumption Time: 0.03872
Total Iteration Time: 5.58532

Cumulative Model Updates: 5,930
Cumulative Timesteps: 98,981,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.46102
Policy Entropy: 1.18125
Value Function Loss: 5.12160

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.12370
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.06047

Collected Steps per Second: 10,517.40561
Overall Steps per Second: 9,155.86601

Timestep Collection Time: 4.75707
Timestep Consumption Time: 0.70741
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.46447

Cumulative Model Updates: 5,933
Cumulative Timesteps: 99,031,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 99031750...
Checkpoint 99031750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.79995
Policy Entropy: 1.17455
Value Function Loss: 4.76945

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.06037

Collected Steps per Second: 10,865.12546
Overall Steps per Second: 9,217.92592

Timestep Collection Time: 4.60243
Timestep Consumption Time: 0.82243
PPO Batch Consumption Time: 0.04373
Total Iteration Time: 5.42486

Cumulative Model Updates: 5,936
Cumulative Timesteps: 99,081,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.51011
Policy Entropy: 1.19371
Value Function Loss: 4.79646

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.06732

Collected Steps per Second: 10,850.48475
Overall Steps per Second: 8,986.23453

Timestep Collection Time: 4.60846
Timestep Consumption Time: 0.95605
PPO Batch Consumption Time: 0.04935
Total Iteration Time: 5.56451

Cumulative Model Updates: 5,939
Cumulative Timesteps: 99,131,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 99131760...
Checkpoint 99131760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.54006
Policy Entropy: 1.18811
Value Function Loss: 4.84261

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.05571

Collected Steps per Second: 10,687.65424
Overall Steps per Second: 8,928.62497

Timestep Collection Time: 4.68091
Timestep Consumption Time: 0.92219
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.60310

Cumulative Model Updates: 5,942
Cumulative Timesteps: 99,181,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.84012
Policy Entropy: 1.17976
Value Function Loss: 4.85076

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.04518

Collected Steps per Second: 10,820.74957
Overall Steps per Second: 9,221.45573

Timestep Collection Time: 4.62334
Timestep Consumption Time: 0.80183
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.42517

Cumulative Model Updates: 5,945
Cumulative Timesteps: 99,231,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 99231816...
Checkpoint 99231816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.12701
Policy Entropy: 1.16716
Value Function Loss: 4.81106

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.04317

Collected Steps per Second: 10,860.56190
Overall Steps per Second: 9,207.25884

Timestep Collection Time: 4.60639
Timestep Consumption Time: 0.82715
PPO Batch Consumption Time: 0.04514
Total Iteration Time: 5.43354

Cumulative Model Updates: 5,948
Cumulative Timesteps: 99,281,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.34863
Policy Entropy: 1.17711
Value Function Loss: 4.91059

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.05661

Collected Steps per Second: 10,942.57339
Overall Steps per Second: 9,209.28391

Timestep Collection Time: 4.56986
Timestep Consumption Time: 0.86010
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.42996

Cumulative Model Updates: 5,951
Cumulative Timesteps: 99,331,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 99331850...
Checkpoint 99331850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.65519
Policy Entropy: 1.17482
Value Function Loss: 5.09897

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.05935

Collected Steps per Second: 10,760.05577
Overall Steps per Second: 9,199.88772

Timestep Collection Time: 4.64793
Timestep Consumption Time: 0.78822
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 5.43615

Cumulative Model Updates: 5,954
Cumulative Timesteps: 99,381,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.09834
Policy Entropy: 1.17140
Value Function Loss: 5.02056

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.06080
Value Function Update Magnitude: 0.05435

Collected Steps per Second: 10,245.01018
Overall Steps per Second: 8,795.43671

Timestep Collection Time: 4.88355
Timestep Consumption Time: 0.80486
PPO Batch Consumption Time: 0.03963
Total Iteration Time: 5.68840

Cumulative Model Updates: 5,957
Cumulative Timesteps: 99,431,894

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 99431894...
Checkpoint 99431894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.04959
Policy Entropy: 1.15784
Value Function Loss: 5.07525

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.11774
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.04786

Collected Steps per Second: 10,528.22111
Overall Steps per Second: 8,873.89984

Timestep Collection Time: 4.75180
Timestep Consumption Time: 0.88586
PPO Batch Consumption Time: 0.04799
Total Iteration Time: 5.63766

Cumulative Model Updates: 5,960
Cumulative Timesteps: 99,481,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.86702
Policy Entropy: 1.17531
Value Function Loss: 4.87773

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.05638

Collected Steps per Second: 10,662.91294
Overall Steps per Second: 9,042.25333

Timestep Collection Time: 4.68953
Timestep Consumption Time: 0.84051
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 5.53004

Cumulative Model Updates: 5,963
Cumulative Timesteps: 99,531,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 99531926...
Checkpoint 99531926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.88382
Policy Entropy: 1.17110
Value Function Loss: 5.09611

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.06307

Collected Steps per Second: 10,864.83104
Overall Steps per Second: 9,273.62533

Timestep Collection Time: 4.60458
Timestep Consumption Time: 0.79007
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 5.39465

Cumulative Model Updates: 5,966
Cumulative Timesteps: 99,581,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.89871
Policy Entropy: 1.17033
Value Function Loss: 4.92677

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.06693

Collected Steps per Second: 10,839.20985
Overall Steps per Second: 9,254.84145

Timestep Collection Time: 4.61325
Timestep Consumption Time: 0.78976
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 5.40301

Cumulative Model Updates: 5,969
Cumulative Timesteps: 99,631,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 99631958...
Checkpoint 99631958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.35052
Policy Entropy: 1.16162
Value Function Loss: 4.79603

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 10,327.02117
Overall Steps per Second: 8,853.79358

Timestep Collection Time: 4.84360
Timestep Consumption Time: 0.80595
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.64956

Cumulative Model Updates: 5,972
Cumulative Timesteps: 99,681,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.19200
Policy Entropy: 1.15891
Value Function Loss: 4.67112

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.04513
Value Function Update Magnitude: 0.09553

Collected Steps per Second: 10,835.61567
Overall Steps per Second: 9,203.73826

Timestep Collection Time: 4.61570
Timestep Consumption Time: 0.81839
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 5.43410

Cumulative Model Updates: 5,975
Cumulative Timesteps: 99,731,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 99731992...
Checkpoint 99731992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.91516
Policy Entropy: 1.14606
Value Function Loss: 4.82447

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.07290
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 11,012.22370
Overall Steps per Second: 9,489.84982

Timestep Collection Time: 4.54331
Timestep Consumption Time: 0.72884
PPO Batch Consumption Time: 0.03941
Total Iteration Time: 5.27216

Cumulative Model Updates: 5,978
Cumulative Timesteps: 99,782,024

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.66613
Policy Entropy: 1.17119
Value Function Loss: 4.91777

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.08234

Collected Steps per Second: 10,601.49723
Overall Steps per Second: 8,959.28859

Timestep Collection Time: 4.71896
Timestep Consumption Time: 0.86497
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 5.58393

Cumulative Model Updates: 5,981
Cumulative Timesteps: 99,832,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 99832052...
Checkpoint 99832052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.64824
Policy Entropy: 1.17462
Value Function Loss: 4.88468

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.08576

Collected Steps per Second: 10,798.38549
Overall Steps per Second: 9,178.79212

Timestep Collection Time: 4.63143
Timestep Consumption Time: 0.81721
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 5.44865

Cumulative Model Updates: 5,984
Cumulative Timesteps: 99,882,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.65235
Policy Entropy: 1.16955
Value Function Loss: 4.78142

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.08455
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.07345

Collected Steps per Second: 10,831.71889
Overall Steps per Second: 9,124.47232

Timestep Collection Time: 4.61681
Timestep Consumption Time: 0.86383
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 5.48065

Cumulative Model Updates: 5,987
Cumulative Timesteps: 99,932,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 99932072...
Checkpoint 99932072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.75506
Policy Entropy: 1.16198
Value Function Loss: 4.68633

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.09068

Collected Steps per Second: 10,184.57299
Overall Steps per Second: 8,710.91061

Timestep Collection Time: 4.91174
Timestep Consumption Time: 0.83094
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 5.74268

Cumulative Model Updates: 5,990
Cumulative Timesteps: 99,982,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.32803
Policy Entropy: 1.16757
Value Function Loss: 4.67497

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.09208

Collected Steps per Second: 10,735.38112
Overall Steps per Second: 9,208.61205

Timestep Collection Time: 4.65917
Timestep Consumption Time: 0.77248
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 5.43165

Cumulative Model Updates: 5,993
Cumulative Timesteps: 100,032,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 100032114...
Checkpoint 100032114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.38676
Policy Entropy: 1.16647
Value Function Loss: 4.62013

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.04455
Value Function Update Magnitude: 0.08543

Collected Steps per Second: 10,574.95270
Overall Steps per Second: 8,991.50595

Timestep Collection Time: 4.73080
Timestep Consumption Time: 0.83312
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 5.56392

Cumulative Model Updates: 5,996
Cumulative Timesteps: 100,082,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.72801
Policy Entropy: 1.13589
Value Function Loss: 4.58435

Mean KL Divergence: 0.04525
SB3 Clip Fraction: 0.14778
Policy Update Magnitude: 0.08068
Value Function Update Magnitude: 0.07352

Collected Steps per Second: 10,798.31391
Overall Steps per Second: 9,229.29416

Timestep Collection Time: 4.63276
Timestep Consumption Time: 0.78759
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.42035

Cumulative Model Updates: 5,999
Cumulative Timesteps: 100,132,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 100132168...
Checkpoint 100132168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.76424
Policy Entropy: 1.17541
Value Function Loss: 4.48695

Mean KL Divergence: 0.04236
SB3 Clip Fraction: 0.15792
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.08341

Collected Steps per Second: 10,899.61230
Overall Steps per Second: 9,237.81966

Timestep Collection Time: 4.58805
Timestep Consumption Time: 0.82535
PPO Batch Consumption Time: 0.04742
Total Iteration Time: 5.41340

Cumulative Model Updates: 6,002
Cumulative Timesteps: 100,182,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.60397
Policy Entropy: 1.16455
Value Function Loss: 4.62389

Mean KL Divergence: 0.02953
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.07693

Collected Steps per Second: 10,212.86316
Overall Steps per Second: 8,743.87023

Timestep Collection Time: 4.89618
Timestep Consumption Time: 0.82257
PPO Batch Consumption Time: 0.04161
Total Iteration Time: 5.71875

Cumulative Model Updates: 6,005
Cumulative Timesteps: 100,232,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 100232180...
Checkpoint 100232180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.93833
Policy Entropy: 1.18507
Value Function Loss: 4.52030

Mean KL Divergence: 0.02560
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.07661

Collected Steps per Second: 10,688.12879
Overall Steps per Second: 9,192.06470

Timestep Collection Time: 4.68015
Timestep Consumption Time: 0.76172
PPO Batch Consumption Time: 0.03983
Total Iteration Time: 5.44187

Cumulative Model Updates: 6,008
Cumulative Timesteps: 100,282,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.15535
Policy Entropy: 1.15972
Value Function Loss: 4.84357

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.09135

Collected Steps per Second: 10,980.86114
Overall Steps per Second: 9,299.78010

Timestep Collection Time: 4.55520
Timestep Consumption Time: 0.82342
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 5.37862

Cumulative Model Updates: 6,011
Cumulative Timesteps: 100,332,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 100332222...
Checkpoint 100332222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.49956
Policy Entropy: 1.16018
Value Function Loss: 4.82398

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.09720

Collected Steps per Second: 10,666.94627
Overall Steps per Second: 9,092.27062

Timestep Collection Time: 4.68850
Timestep Consumption Time: 0.81199
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 5.50050

Cumulative Model Updates: 6,014
Cumulative Timesteps: 100,382,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.65687
Policy Entropy: 1.15363
Value Function Loss: 5.23182

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.09509

Collected Steps per Second: 10,726.40226
Overall Steps per Second: 9,204.68011

Timestep Collection Time: 4.66140
Timestep Consumption Time: 0.77062
PPO Batch Consumption Time: 0.04080
Total Iteration Time: 5.43202

Cumulative Model Updates: 6,017
Cumulative Timesteps: 100,432,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 100432234...
Checkpoint 100432234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.40761
Policy Entropy: 1.16992
Value Function Loss: 4.96047

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.06442
Value Function Update Magnitude: 0.07905

Collected Steps per Second: 10,628.61049
Overall Steps per Second: 8,980.57204

Timestep Collection Time: 4.70617
Timestep Consumption Time: 0.86364
PPO Batch Consumption Time: 0.03959
Total Iteration Time: 5.56980

Cumulative Model Updates: 6,020
Cumulative Timesteps: 100,482,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.51285
Policy Entropy: 1.14714
Value Function Loss: 4.96444

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.06171
Value Function Update Magnitude: 0.07884

Collected Steps per Second: 10,191.63638
Overall Steps per Second: 8,796.56146

Timestep Collection Time: 4.90795
Timestep Consumption Time: 0.77837
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 5.68631

Cumulative Model Updates: 6,023
Cumulative Timesteps: 100,532,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 100532274...
Checkpoint 100532274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.05552
Policy Entropy: 1.16574
Value Function Loss: 4.82654

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.07827

Collected Steps per Second: 10,788.61069
Overall Steps per Second: 9,041.46500

Timestep Collection Time: 4.63674
Timestep Consumption Time: 0.89599
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.53273

Cumulative Model Updates: 6,026
Cumulative Timesteps: 100,582,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.58325
Policy Entropy: 1.16507
Value Function Loss: 4.71884

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.06819

Collected Steps per Second: 10,909.37203
Overall Steps per Second: 9,121.31574

Timestep Collection Time: 4.58432
Timestep Consumption Time: 0.89867
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.48298

Cumulative Model Updates: 6,029
Cumulative Timesteps: 100,632,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 100632310...
Checkpoint 100632310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.46899
Policy Entropy: 1.17138
Value Function Loss: 4.77784

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.06673

Collected Steps per Second: 10,922.92609
Overall Steps per Second: 9,397.23289

Timestep Collection Time: 4.57808
Timestep Consumption Time: 0.74328
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 5.32135

Cumulative Model Updates: 6,032
Cumulative Timesteps: 100,682,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.30156
Policy Entropy: 1.16878
Value Function Loss: 4.69468

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.06067

Collected Steps per Second: 11,160.38164
Overall Steps per Second: 9,368.50234

Timestep Collection Time: 4.48246
Timestep Consumption Time: 0.85734
PPO Batch Consumption Time: 0.04625
Total Iteration Time: 5.33981

Cumulative Model Updates: 6,035
Cumulative Timesteps: 100,732,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 100732342...
Checkpoint 100732342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.55852
Policy Entropy: 1.16984
Value Function Loss: 4.77711

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.08639

Collected Steps per Second: 10,329.42702
Overall Steps per Second: 8,860.92989

Timestep Collection Time: 4.84189
Timestep Consumption Time: 0.80243
PPO Batch Consumption Time: 0.04747
Total Iteration Time: 5.64433

Cumulative Model Updates: 6,038
Cumulative Timesteps: 100,782,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.13921
Policy Entropy: 1.16734
Value Function Loss: 4.67657

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.11425

Collected Steps per Second: 10,942.24459
Overall Steps per Second: 9,126.29441

Timestep Collection Time: 4.57182
Timestep Consumption Time: 0.90970
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 5.48152

Cumulative Model Updates: 6,041
Cumulative Timesteps: 100,832,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 100832382...
Checkpoint 100832382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.77122
Policy Entropy: 1.14698
Value Function Loss: 4.75925

Mean KL Divergence: 0.04194
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.10806

Collected Steps per Second: 11,193.86323
Overall Steps per Second: 9,403.18650

Timestep Collection Time: 4.46995
Timestep Consumption Time: 0.85123
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 5.32117

Cumulative Model Updates: 6,044
Cumulative Timesteps: 100,882,418

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.23075
Policy Entropy: 1.16170
Value Function Loss: 4.88198

Mean KL Divergence: 0.03366
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.10428

Collected Steps per Second: 10,956.17984
Overall Steps per Second: 9,365.70944

Timestep Collection Time: 4.56455
Timestep Consumption Time: 0.77514
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 5.33969

Cumulative Model Updates: 6,047
Cumulative Timesteps: 100,932,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 100932428...
Checkpoint 100932428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.86816
Policy Entropy: 1.15919
Value Function Loss: 4.87027

Mean KL Divergence: 0.02923
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.09481

Collected Steps per Second: 10,541.58361
Overall Steps per Second: 8,873.18358

Timestep Collection Time: 4.74407
Timestep Consumption Time: 0.89201
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 5.63608

Cumulative Model Updates: 6,050
Cumulative Timesteps: 100,982,438

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.08240
Policy Entropy: 1.16227
Value Function Loss: 4.82830

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.10148

Collected Steps per Second: 10,719.78025
Overall Steps per Second: 9,163.79198

Timestep Collection Time: 4.66633
Timestep Consumption Time: 0.79233
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 5.45866

Cumulative Model Updates: 6,053
Cumulative Timesteps: 101,032,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 101032460...
Checkpoint 101032460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.46913
Policy Entropy: 1.16317
Value Function Loss: 4.94530

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07861
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.09238

Collected Steps per Second: 10,534.14356
Overall Steps per Second: 8,996.66413

Timestep Collection Time: 4.74666
Timestep Consumption Time: 0.81118
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 5.55784

Cumulative Model Updates: 6,056
Cumulative Timesteps: 101,082,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.24083
Policy Entropy: 1.15448
Value Function Loss: 4.90969

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.10302

Collected Steps per Second: 10,566.69488
Overall Steps per Second: 8,991.84921

Timestep Collection Time: 4.73450
Timestep Consumption Time: 0.82921
PPO Batch Consumption Time: 0.05098
Total Iteration Time: 5.56371

Cumulative Model Updates: 6,059
Cumulative Timesteps: 101,132,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 101132490...
Checkpoint 101132490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.80909
Policy Entropy: 1.17556
Value Function Loss: 4.96836

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.09265

Collected Steps per Second: 10,699.51320
Overall Steps per Second: 9,243.81046

Timestep Collection Time: 4.67311
Timestep Consumption Time: 0.73592
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.40902

Cumulative Model Updates: 6,062
Cumulative Timesteps: 101,182,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.37064
Policy Entropy: 1.18320
Value Function Loss: 4.69505

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.07370

Collected Steps per Second: 10,723.65968
Overall Steps per Second: 9,100.42314

Timestep Collection Time: 4.66520
Timestep Consumption Time: 0.83213
PPO Batch Consumption Time: 0.04537
Total Iteration Time: 5.49733

Cumulative Model Updates: 6,065
Cumulative Timesteps: 101,232,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 101232518...
Checkpoint 101232518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.01675
Policy Entropy: 1.17419
Value Function Loss: 4.71053

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.08566

Collected Steps per Second: 10,838.67416
Overall Steps per Second: 9,280.72076

Timestep Collection Time: 4.61422
Timestep Consumption Time: 0.77459
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.38881

Cumulative Model Updates: 6,068
Cumulative Timesteps: 101,282,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.33312
Policy Entropy: 1.16345
Value Function Loss: 4.64566

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.08322

Collected Steps per Second: 10,469.89517
Overall Steps per Second: 8,882.59754

Timestep Collection Time: 4.77636
Timestep Consumption Time: 0.85352
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 5.62988

Cumulative Model Updates: 6,071
Cumulative Timesteps: 101,332,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 101332538...
Checkpoint 101332538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.52071
Policy Entropy: 1.16678
Value Function Loss: 4.65904

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.08140

Collected Steps per Second: 10,814.52846
Overall Steps per Second: 9,252.10156

Timestep Collection Time: 4.62396
Timestep Consumption Time: 0.78086
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.40483

Cumulative Model Updates: 6,074
Cumulative Timesteps: 101,382,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.76477
Policy Entropy: 1.17035
Value Function Loss: 4.49671

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.07053

Collected Steps per Second: 10,710.08341
Overall Steps per Second: 9,227.12308

Timestep Collection Time: 4.66887
Timestep Consumption Time: 0.75037
PPO Batch Consumption Time: 0.03945
Total Iteration Time: 5.41924

Cumulative Model Updates: 6,077
Cumulative Timesteps: 101,432,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 101432548...
Checkpoint 101432548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.48335
Policy Entropy: 1.16899
Value Function Loss: 4.51555

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.06819
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.07678

Collected Steps per Second: 10,880.97463
Overall Steps per Second: 9,208.10245

Timestep Collection Time: 4.59518
Timestep Consumption Time: 0.83482
PPO Batch Consumption Time: 0.04156
Total Iteration Time: 5.43000

Cumulative Model Updates: 6,080
Cumulative Timesteps: 101,482,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.17430
Policy Entropy: 1.15912
Value Function Loss: 4.71569

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.06945

Collected Steps per Second: 10,629.82759
Overall Steps per Second: 9,086.05877

Timestep Collection Time: 4.70581
Timestep Consumption Time: 0.79954
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 5.50536

Cumulative Model Updates: 6,083
Cumulative Timesteps: 101,532,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 101532570...
Checkpoint 101532570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.18555
Policy Entropy: 1.16500
Value Function Loss: 4.87284

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.07110

Collected Steps per Second: 10,889.57317
Overall Steps per Second: 9,073.21228

Timestep Collection Time: 4.59247
Timestep Consumption Time: 0.91936
PPO Batch Consumption Time: 0.04378
Total Iteration Time: 5.51183

Cumulative Model Updates: 6,086
Cumulative Timesteps: 101,582,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.34481
Policy Entropy: 1.17240
Value Function Loss: 4.85763

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.07985

Collected Steps per Second: 10,491.49440
Overall Steps per Second: 9,013.00059

Timestep Collection Time: 4.76824
Timestep Consumption Time: 0.78218
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.55043

Cumulative Model Updates: 6,089
Cumulative Timesteps: 101,632,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 101632606...
Checkpoint 101632606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.30930
Policy Entropy: 1.16925
Value Function Loss: 4.76147

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.06821
Policy Update Magnitude: 0.07259
Value Function Update Magnitude: 0.07310

Collected Steps per Second: 10,612.18459
Overall Steps per Second: 9,189.03791

Timestep Collection Time: 4.71175
Timestep Consumption Time: 0.72973
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.44148

Cumulative Model Updates: 6,092
Cumulative Timesteps: 101,682,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.81315
Policy Entropy: 1.15208
Value Function Loss: 4.98402

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.06491
Value Function Update Magnitude: 0.06983

Collected Steps per Second: 10,767.83616
Overall Steps per Second: 9,118.86048

Timestep Collection Time: 4.64457
Timestep Consumption Time: 0.83988
PPO Batch Consumption Time: 0.04006
Total Iteration Time: 5.48446

Cumulative Model Updates: 6,095
Cumulative Timesteps: 101,732,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 101732620...
Checkpoint 101732620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.95112
Policy Entropy: 1.17658
Value Function Loss: 4.98717

Mean KL Divergence: 0.03826
SB3 Clip Fraction: 0.15204
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.07375

Collected Steps per Second: 10,695.69979
Overall Steps per Second: 9,056.00907

Timestep Collection Time: 4.67758
Timestep Consumption Time: 0.84693
PPO Batch Consumption Time: 0.03966
Total Iteration Time: 5.52451

Cumulative Model Updates: 6,098
Cumulative Timesteps: 101,782,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.59943
Policy Entropy: 1.17229
Value Function Loss: 5.08917

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.06973

Collected Steps per Second: 10,973.57171
Overall Steps per Second: 9,374.56277

Timestep Collection Time: 4.55859
Timestep Consumption Time: 0.77755
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 5.33614

Cumulative Model Updates: 6,101
Cumulative Timesteps: 101,832,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 101832674...
Checkpoint 101832674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.24310
Policy Entropy: 1.18984
Value Function Loss: 4.85378

Mean KL Divergence: 0.03608
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 10,234.33530
Overall Steps per Second: 8,753.11726

Timestep Collection Time: 4.88708
Timestep Consumption Time: 0.82700
PPO Batch Consumption Time: 0.03869
Total Iteration Time: 5.71408

Cumulative Model Updates: 6,104
Cumulative Timesteps: 101,882,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.41345
Policy Entropy: 1.17572
Value Function Loss: 4.87298

Mean KL Divergence: 0.02982
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.07346

Collected Steps per Second: 10,395.56010
Overall Steps per Second: 8,942.63215

Timestep Collection Time: 4.81263
Timestep Consumption Time: 0.78192
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 5.59455

Cumulative Model Updates: 6,107
Cumulative Timesteps: 101,932,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 101932720...
Checkpoint 101932720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.77062
Policy Entropy: 1.18781
Value Function Loss: 4.91073

Mean KL Divergence: 0.02540
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.04045
Value Function Update Magnitude: 0.07567

Collected Steps per Second: 10,953.48163
Overall Steps per Second: 9,354.49408

Timestep Collection Time: 4.56567
Timestep Consumption Time: 0.78042
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.34609

Cumulative Model Updates: 6,110
Cumulative Timesteps: 101,982,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.87007
Policy Entropy: 1.17257
Value Function Loss: 4.96706

Mean KL Divergence: 0.02726
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.04195
Value Function Update Magnitude: 0.07421

Collected Steps per Second: 10,746.74056
Overall Steps per Second: 9,096.22970

Timestep Collection Time: 4.65462
Timestep Consumption Time: 0.84458
PPO Batch Consumption Time: 0.03980
Total Iteration Time: 5.49920

Cumulative Model Updates: 6,113
Cumulative Timesteps: 102,032,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 102032752...
Checkpoint 102032752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.49759
Policy Entropy: 1.18550
Value Function Loss: 4.92205

Mean KL Divergence: 0.02673
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.04293
Value Function Update Magnitude: 0.06702

Collected Steps per Second: 10,945.60608
Overall Steps per Second: 9,228.69449

Timestep Collection Time: 4.56914
Timestep Consumption Time: 0.85005
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 5.41918

Cumulative Model Updates: 6,116
Cumulative Timesteps: 102,082,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.06907
Policy Entropy: 1.17484
Value Function Loss: 4.66327

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.04074
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 10,631.16064
Overall Steps per Second: 9,007.79427

Timestep Collection Time: 4.70353
Timestep Consumption Time: 0.84766
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 5.55119

Cumulative Model Updates: 6,119
Cumulative Timesteps: 102,132,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 102132768...
Checkpoint 102132768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.35417
Policy Entropy: 1.19396
Value Function Loss: 4.68404

Mean KL Divergence: 0.02528
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.04131
Value Function Update Magnitude: 0.06011

Collected Steps per Second: 10,672.27800
Overall Steps per Second: 9,178.91177

Timestep Collection Time: 4.68766
Timestep Consumption Time: 0.76266
PPO Batch Consumption Time: 0.04653
Total Iteration Time: 5.45032

Cumulative Model Updates: 6,122
Cumulative Timesteps: 102,182,796

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.60358
Policy Entropy: 1.18018
Value Function Loss: 4.76906

Mean KL Divergence: 0.02919
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.06207

Collected Steps per Second: 10,706.98575
Overall Steps per Second: 9,012.93319

Timestep Collection Time: 4.67209
Timestep Consumption Time: 0.87816
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 5.55025

Cumulative Model Updates: 6,125
Cumulative Timesteps: 102,232,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 102232820...
Checkpoint 102232820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.40147
Policy Entropy: 1.19174
Value Function Loss: 4.92663

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.05455

Collected Steps per Second: 10,734.41335
Overall Steps per Second: 9,074.27199

Timestep Collection Time: 4.65792
Timestep Consumption Time: 0.85217
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 5.51008

Cumulative Model Updates: 6,128
Cumulative Timesteps: 102,282,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.52644
Policy Entropy: 1.17658
Value Function Loss: 4.81681

Mean KL Divergence: 0.03216
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.04729

Collected Steps per Second: 10,932.50106
Overall Steps per Second: 9,280.90248

Timestep Collection Time: 4.57407
Timestep Consumption Time: 0.81399
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.38805

Cumulative Model Updates: 6,131
Cumulative Timesteps: 102,332,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 102332826...
Checkpoint 102332826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.90896
Policy Entropy: 1.19929
Value Function Loss: 4.82129

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.11898
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.04040

Collected Steps per Second: 10,915.50282
Overall Steps per Second: 9,186.45614

Timestep Collection Time: 4.58119
Timestep Consumption Time: 0.86226
PPO Batch Consumption Time: 0.05107
Total Iteration Time: 5.44345

Cumulative Model Updates: 6,134
Cumulative Timesteps: 102,382,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.02070
Policy Entropy: 1.18020
Value Function Loss: 4.84505

Mean KL Divergence: 0.04686
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.03920

Collected Steps per Second: 10,153.98636
Overall Steps per Second: 8,678.01282

Timestep Collection Time: 4.92496
Timestep Consumption Time: 0.83765
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 5.76261

Cumulative Model Updates: 6,137
Cumulative Timesteps: 102,432,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 102432840...
Checkpoint 102432840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.08888
Policy Entropy: 1.18627
Value Function Loss: 4.75095

Mean KL Divergence: 0.02920
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.04476
Value Function Update Magnitude: 0.04670

Collected Steps per Second: 10,837.32153
Overall Steps per Second: 9,068.43890

Timestep Collection Time: 4.61553
Timestep Consumption Time: 0.90030
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.51583

Cumulative Model Updates: 6,140
Cumulative Timesteps: 102,482,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.25718
Policy Entropy: 1.17343
Value Function Loss: 4.79092

Mean KL Divergence: 0.03005
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.04533

Collected Steps per Second: 10,787.19585
Overall Steps per Second: 9,216.28715

Timestep Collection Time: 4.63550
Timestep Consumption Time: 0.79012
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 5.42561

Cumulative Model Updates: 6,143
Cumulative Timesteps: 102,532,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 102532864...
Checkpoint 102532864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.84954
Policy Entropy: 1.18299
Value Function Loss: 4.50268

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.04984

Collected Steps per Second: 10,854.28430
Overall Steps per Second: 9,115.54582

Timestep Collection Time: 4.60777
Timestep Consumption Time: 0.87891
PPO Batch Consumption Time: 0.04019
Total Iteration Time: 5.48667

Cumulative Model Updates: 6,146
Cumulative Timesteps: 102,582,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.85389
Policy Entropy: 1.16730
Value Function Loss: 4.71926

Mean KL Divergence: 0.03451
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.05207

Collected Steps per Second: 10,638.80008
Overall Steps per Second: 9,016.03243

Timestep Collection Time: 4.70260
Timestep Consumption Time: 0.84641
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 5.54900

Cumulative Model Updates: 6,149
Cumulative Timesteps: 102,632,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 102632908...
Checkpoint 102632908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.67899
Policy Entropy: 1.18523
Value Function Loss: 4.56604

Mean KL Divergence: 0.02555
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.05106

Collected Steps per Second: 10,458.20081
Overall Steps per Second: 8,913.73172

Timestep Collection Time: 4.78208
Timestep Consumption Time: 0.82858
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 5.61067

Cumulative Model Updates: 6,152
Cumulative Timesteps: 102,682,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.43468
Policy Entropy: 1.17280
Value Function Loss: 4.63395

Mean KL Divergence: 0.03426
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.04193

Collected Steps per Second: 10,443.04391
Overall Steps per Second: 8,959.80767

Timestep Collection Time: 4.78960
Timestep Consumption Time: 0.79289
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 5.58249

Cumulative Model Updates: 6,155
Cumulative Timesteps: 102,732,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 102732938...
Checkpoint 102732938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.97266
Policy Entropy: 1.19425
Value Function Loss: 4.43477

Mean KL Divergence: 0.03430
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 10,690.06313
Overall Steps per Second: 9,222.95370

Timestep Collection Time: 4.67818
Timestep Consumption Time: 0.74416
PPO Batch Consumption Time: 0.03916
Total Iteration Time: 5.42234

Cumulative Model Updates: 6,158
Cumulative Timesteps: 102,782,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.20072
Policy Entropy: 1.17780
Value Function Loss: 4.61248

Mean KL Divergence: 0.03365
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.04287
Value Function Update Magnitude: 0.09211

Collected Steps per Second: 10,685.08230
Overall Steps per Second: 9,015.13426

Timestep Collection Time: 4.68054
Timestep Consumption Time: 0.86702
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 5.54756

Cumulative Model Updates: 6,161
Cumulative Timesteps: 102,832,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 102832960...
Checkpoint 102832960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.18640
Policy Entropy: 1.18994
Value Function Loss: 4.74668

Mean KL Divergence: 0.03067
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.10461

Collected Steps per Second: 10,846.69577
Overall Steps per Second: 9,105.94230

Timestep Collection Time: 4.61210
Timestep Consumption Time: 0.88168
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.49378

Cumulative Model Updates: 6,164
Cumulative Timesteps: 102,882,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.37727
Policy Entropy: 1.18147
Value Function Loss: 4.93142

Mean KL Divergence: 0.02724
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.12025

Collected Steps per Second: 11,365.43177
Overall Steps per Second: 9,420.45099

Timestep Collection Time: 4.40265
Timestep Consumption Time: 0.90899
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 5.31164

Cumulative Model Updates: 6,167
Cumulative Timesteps: 102,933,024

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 102933024...
Checkpoint 102933024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.36066
Policy Entropy: 1.19778
Value Function Loss: 5.01327

Mean KL Divergence: 0.02593
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.12125

Collected Steps per Second: 10,589.12923
Overall Steps per Second: 8,919.19744

Timestep Collection Time: 4.72371
Timestep Consumption Time: 0.88442
PPO Batch Consumption Time: 0.04255
Total Iteration Time: 5.60813

Cumulative Model Updates: 6,170
Cumulative Timesteps: 102,983,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.91813
Policy Entropy: 1.18187
Value Function Loss: 5.10445

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.10537

Collected Steps per Second: 11,098.33503
Overall Steps per Second: 9,452.01379

Timestep Collection Time: 4.50590
Timestep Consumption Time: 0.78482
PPO Batch Consumption Time: 0.04310
Total Iteration Time: 5.29072

Cumulative Model Updates: 6,173
Cumulative Timesteps: 103,033,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 103033052...
Checkpoint 103033052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.79204
Policy Entropy: 1.18933
Value Function Loss: 5.19992

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.08394

Collected Steps per Second: 11,010.92785
Overall Steps per Second: 9,210.76273

Timestep Collection Time: 4.54294
Timestep Consumption Time: 0.88788
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 5.43082

Cumulative Model Updates: 6,176
Cumulative Timesteps: 103,083,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.83587
Policy Entropy: 1.18820
Value Function Loss: 4.89468

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.08662

Collected Steps per Second: 10,735.84963
Overall Steps per Second: 9,146.61022

Timestep Collection Time: 4.65841
Timestep Consumption Time: 0.80941
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 5.46782

Cumulative Model Updates: 6,179
Cumulative Timesteps: 103,133,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 103133086...
Checkpoint 103133086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.45504
Policy Entropy: 1.18563
Value Function Loss: 4.80755

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.09116

Collected Steps per Second: 10,820.41317
Overall Steps per Second: 9,373.72092

Timestep Collection Time: 4.62330
Timestep Consumption Time: 0.71354
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 5.33683

Cumulative Model Updates: 6,182
Cumulative Timesteps: 103,183,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.49170
Policy Entropy: 1.20387
Value Function Loss: 4.50792

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.08312

Collected Steps per Second: 10,392.79791
Overall Steps per Second: 8,852.09146

Timestep Collection Time: 4.81391
Timestep Consumption Time: 0.83786
PPO Batch Consumption Time: 0.03980
Total Iteration Time: 5.65177

Cumulative Model Updates: 6,185
Cumulative Timesteps: 103,233,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 103233142...
Checkpoint 103233142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.18281
Policy Entropy: 1.19876
Value Function Loss: 4.42197

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.07238
Value Function Update Magnitude: 0.08214

Collected Steps per Second: 10,539.46703
Overall Steps per Second: 9,111.09902

Timestep Collection Time: 4.74616
Timestep Consumption Time: 0.74407
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 5.49023

Cumulative Model Updates: 6,188
Cumulative Timesteps: 103,283,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.77592
Policy Entropy: 1.19257
Value Function Loss: 4.46815

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.07227
Value Function Update Magnitude: 0.06842

Collected Steps per Second: 10,816.88896
Overall Steps per Second: 9,178.10481

Timestep Collection Time: 4.62480
Timestep Consumption Time: 0.82578
PPO Batch Consumption Time: 0.04604
Total Iteration Time: 5.45058

Cumulative Model Updates: 6,191
Cumulative Timesteps: 103,333,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 103333190...
Checkpoint 103333190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.57646
Policy Entropy: 1.17501
Value Function Loss: 4.57994

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.07450
Value Function Update Magnitude: 0.07125

Collected Steps per Second: 10,840.94717
Overall Steps per Second: 9,228.97492

Timestep Collection Time: 4.61251
Timestep Consumption Time: 0.80564
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 5.41815

Cumulative Model Updates: 6,194
Cumulative Timesteps: 103,383,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.13016
Policy Entropy: 1.16577
Value Function Loss: 4.87814

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.06409
Value Function Update Magnitude: 0.06576

Collected Steps per Second: 10,862.52477
Overall Steps per Second: 9,381.24654

Timestep Collection Time: 4.60537
Timestep Consumption Time: 0.72718
PPO Batch Consumption Time: 0.03888
Total Iteration Time: 5.33255

Cumulative Model Updates: 6,197
Cumulative Timesteps: 103,433,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 103433220...
Checkpoint 103433220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.79771
Policy Entropy: 1.18133
Value Function Loss: 4.99684

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.07321

Collected Steps per Second: 10,924.75805
Overall Steps per Second: 9,221.06568

Timestep Collection Time: 4.57859
Timestep Consumption Time: 0.84594
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 5.42454

Cumulative Model Updates: 6,200
Cumulative Timesteps: 103,483,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.28644
Policy Entropy: 1.17085
Value Function Loss: 5.14989

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.11760
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.07029

Collected Steps per Second: 10,168.21117
Overall Steps per Second: 8,864.73975

Timestep Collection Time: 4.91866
Timestep Consumption Time: 0.72324
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 5.64190

Cumulative Model Updates: 6,203
Cumulative Timesteps: 103,533,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 103533254...
Checkpoint 103533254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.77263
Policy Entropy: 1.18303
Value Function Loss: 5.07796

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.07277

Collected Steps per Second: 10,356.39827
Overall Steps per Second: 8,817.08644

Timestep Collection Time: 4.83025
Timestep Consumption Time: 0.84328
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 5.67353

Cumulative Model Updates: 6,206
Cumulative Timesteps: 103,583,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.89299
Policy Entropy: 1.18508
Value Function Loss: 5.11251

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.04575
Value Function Update Magnitude: 0.06505

Collected Steps per Second: 10,705.80887
Overall Steps per Second: 9,155.99956

Timestep Collection Time: 4.67130
Timestep Consumption Time: 0.79070
PPO Batch Consumption Time: 0.03886
Total Iteration Time: 5.46199

Cumulative Model Updates: 6,209
Cumulative Timesteps: 103,633,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 103633288...
Checkpoint 103633288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.06411
Policy Entropy: 1.17796
Value Function Loss: 5.08147

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.07005

Collected Steps per Second: 10,993.37185
Overall Steps per Second: 9,284.41607

Timestep Collection Time: 4.54820
Timestep Consumption Time: 0.83717
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 5.38537

Cumulative Model Updates: 6,212
Cumulative Timesteps: 103,683,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.79574
Policy Entropy: 1.18066
Value Function Loss: 5.15783

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.06343

Collected Steps per Second: 10,610.91309
Overall Steps per Second: 9,056.83024

Timestep Collection Time: 4.71496
Timestep Consumption Time: 0.80905
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 5.52401

Cumulative Model Updates: 6,215
Cumulative Timesteps: 103,733,318

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 103733318...
Checkpoint 103733318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.83514
Policy Entropy: 1.18398
Value Function Loss: 4.88970

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.07144

Collected Steps per Second: 10,144.01624
Overall Steps per Second: 8,819.68918

Timestep Collection Time: 4.93197
Timestep Consumption Time: 0.74056
PPO Batch Consumption Time: 0.04087
Total Iteration Time: 5.67254

Cumulative Model Updates: 6,218
Cumulative Timesteps: 103,783,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.33392
Policy Entropy: 1.19083
Value Function Loss: 4.99116

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.04421
Value Function Update Magnitude: 0.07122

Collected Steps per Second: 11,015.89157
Overall Steps per Second: 9,355.52207

Timestep Collection Time: 4.54035
Timestep Consumption Time: 0.80580
PPO Batch Consumption Time: 0.04006
Total Iteration Time: 5.34615

Cumulative Model Updates: 6,221
Cumulative Timesteps: 103,833,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 103833364...
Checkpoint 103833364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.48730
Policy Entropy: 1.18061
Value Function Loss: 4.83589

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.06949
Value Function Update Magnitude: 0.07690

Collected Steps per Second: 10,905.09711
Overall Steps per Second: 9,234.55159

Timestep Collection Time: 4.58556
Timestep Consumption Time: 0.82954
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 5.41510

Cumulative Model Updates: 6,224
Cumulative Timesteps: 103,883,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.08533
Policy Entropy: 1.18169
Value Function Loss: 4.83081

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.06448
Value Function Update Magnitude: 0.07654

Collected Steps per Second: 10,764.78192
Overall Steps per Second: 9,171.41398

Timestep Collection Time: 4.64756
Timestep Consumption Time: 0.80743
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 5.45499

Cumulative Model Updates: 6,227
Cumulative Timesteps: 103,933,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 103933400...
Checkpoint 103933400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.19137
Policy Entropy: 1.18318
Value Function Loss: 4.74421

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.06471

Collected Steps per Second: 10,842.98635
Overall Steps per Second: 9,183.14610

Timestep Collection Time: 4.61146
Timestep Consumption Time: 0.83351
PPO Batch Consumption Time: 0.03919
Total Iteration Time: 5.44497

Cumulative Model Updates: 6,230
Cumulative Timesteps: 103,983,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.92682
Policy Entropy: 1.17703
Value Function Loss: 4.75992

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07535
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.05155

Collected Steps per Second: 11,018.21139
Overall Steps per Second: 9,355.93971

Timestep Collection Time: 4.54085
Timestep Consumption Time: 0.80677
PPO Batch Consumption Time: 0.04068
Total Iteration Time: 5.34762

Cumulative Model Updates: 6,233
Cumulative Timesteps: 104,033,434

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 104033434...
Checkpoint 104033434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.40935
Policy Entropy: 1.17696
Value Function Loss: 4.65017

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.07659
Value Function Update Magnitude: 0.04191

Collected Steps per Second: 10,615.32795
Overall Steps per Second: 8,951.40889

Timestep Collection Time: 4.71092
Timestep Consumption Time: 0.87568
PPO Batch Consumption Time: 0.04084
Total Iteration Time: 5.58661

Cumulative Model Updates: 6,236
Cumulative Timesteps: 104,083,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.41417
Policy Entropy: 1.18107
Value Function Loss: 4.54360

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.07466
Value Function Update Magnitude: 0.04195

Collected Steps per Second: 10,990.67963
Overall Steps per Second: 9,279.96802

Timestep Collection Time: 4.55131
Timestep Consumption Time: 0.83901
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.39032

Cumulative Model Updates: 6,239
Cumulative Timesteps: 104,133,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 104133464...
Checkpoint 104133464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.92329
Policy Entropy: 1.18156
Value Function Loss: 4.50665

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.03972

Collected Steps per Second: 10,896.79916
Overall Steps per Second: 9,349.24874

Timestep Collection Time: 4.59034
Timestep Consumption Time: 0.75982
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 5.35016

Cumulative Model Updates: 6,242
Cumulative Timesteps: 104,183,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.71099
Policy Entropy: 1.18438
Value Function Loss: 4.75603

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.06277
Value Function Update Magnitude: 0.03910

Collected Steps per Second: 10,835.03358
Overall Steps per Second: 9,109.31581

Timestep Collection Time: 4.61688
Timestep Consumption Time: 0.87465
PPO Batch Consumption Time: 0.04543
Total Iteration Time: 5.49152

Cumulative Model Updates: 6,245
Cumulative Timesteps: 104,233,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 104233508...
Checkpoint 104233508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.67725
Policy Entropy: 1.17420
Value Function Loss: 4.98996

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.05674

Collected Steps per Second: 10,943.96308
Overall Steps per Second: 9,435.82816

Timestep Collection Time: 4.57110
Timestep Consumption Time: 0.73060
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 5.30171

Cumulative Model Updates: 6,248
Cumulative Timesteps: 104,283,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.34322
Policy Entropy: 1.17811
Value Function Loss: 5.17305

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.06920
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 10,226.90054
Overall Steps per Second: 8,722.82859

Timestep Collection Time: 4.89122
Timestep Consumption Time: 0.84339
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 5.73461

Cumulative Model Updates: 6,251
Cumulative Timesteps: 104,333,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 104333556...
Checkpoint 104333556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.70507
Policy Entropy: 1.17705
Value Function Loss: 5.09447

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.06346

Collected Steps per Second: 10,624.97788
Overall Steps per Second: 8,954.20878

Timestep Collection Time: 4.70721
Timestep Consumption Time: 0.87832
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.58553

Cumulative Model Updates: 6,254
Cumulative Timesteps: 104,383,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.86548
Policy Entropy: 1.18780
Value Function Loss: 5.02985

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.05913

Collected Steps per Second: 10,949.25322
Overall Steps per Second: 9,326.38486

Timestep Collection Time: 4.56689
Timestep Consumption Time: 0.79468
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.36156

Cumulative Model Updates: 6,257
Cumulative Timesteps: 104,433,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 104433574...
Checkpoint 104433574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.01119
Policy Entropy: 1.19491
Value Function Loss: 5.23234

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.05454

Collected Steps per Second: 10,687.52949
Overall Steps per Second: 8,936.86140

Timestep Collection Time: 4.67966
Timestep Consumption Time: 0.91671
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 5.59637

Cumulative Model Updates: 6,260
Cumulative Timesteps: 104,483,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.56188
Policy Entropy: 1.19961
Value Function Loss: 5.23322

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.05185

Collected Steps per Second: 10,837.48186
Overall Steps per Second: 9,179.44668

Timestep Collection Time: 4.61620
Timestep Consumption Time: 0.83380
PPO Batch Consumption Time: 0.05064
Total Iteration Time: 5.45000

Cumulative Model Updates: 6,263
Cumulative Timesteps: 104,533,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 104533616...
Checkpoint 104533616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.30741
Policy Entropy: 1.19626
Value Function Loss: 5.21033

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.05966

Collected Steps per Second: 10,794.35612
Overall Steps per Second: 8,984.22190

Timestep Collection Time: 4.63464
Timestep Consumption Time: 0.93378
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 5.56843

Cumulative Model Updates: 6,266
Cumulative Timesteps: 104,583,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.08414
Policy Entropy: 1.19044
Value Function Loss: 4.98348

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.06769

Collected Steps per Second: 10,628.28716
Overall Steps per Second: 9,066.54087

Timestep Collection Time: 4.70443
Timestep Consumption Time: 0.81036
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 5.51478

Cumulative Model Updates: 6,269
Cumulative Timesteps: 104,633,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 104633644...
Checkpoint 104633644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.47554
Policy Entropy: 1.18560
Value Function Loss: 4.86967

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.08670

Collected Steps per Second: 10,816.98430
Overall Steps per Second: 9,099.38772

Timestep Collection Time: 4.62273
Timestep Consumption Time: 0.87258
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.49531

Cumulative Model Updates: 6,272
Cumulative Timesteps: 104,683,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.43415
Policy Entropy: 1.18310
Value Function Loss: 4.95133

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.07891

Collected Steps per Second: 10,840.00879
Overall Steps per Second: 9,250.93282

Timestep Collection Time: 4.61420
Timestep Consumption Time: 0.79260
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 5.40681

Cumulative Model Updates: 6,275
Cumulative Timesteps: 104,733,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 104733666...
Checkpoint 104733666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.20905
Policy Entropy: 1.18714
Value Function Loss: 4.84017

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.06414

Collected Steps per Second: 10,787.71830
Overall Steps per Second: 9,358.47842

Timestep Collection Time: 4.63546
Timestep Consumption Time: 0.70793
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.34339

Cumulative Model Updates: 6,278
Cumulative Timesteps: 104,783,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.52295
Policy Entropy: 1.17333
Value Function Loss: 4.80288

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.07595

Collected Steps per Second: 10,831.70056
Overall Steps per Second: 9,166.42649

Timestep Collection Time: 4.61719
Timestep Consumption Time: 0.83881
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 5.45600

Cumulative Model Updates: 6,281
Cumulative Timesteps: 104,833,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 104833684...
Checkpoint 104833684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.05391
Policy Entropy: 1.19701
Value Function Loss: 4.81595

Mean KL Divergence: 0.03065
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.06537

Collected Steps per Second: 10,362.25155
Overall Steps per Second: 8,871.57220

Timestep Collection Time: 4.82617
Timestep Consumption Time: 0.81094
PPO Batch Consumption Time: 0.03850
Total Iteration Time: 5.63711

Cumulative Model Updates: 6,284
Cumulative Timesteps: 104,883,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.65977
Policy Entropy: 1.18378
Value Function Loss: 5.01180

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.11933
Policy Update Magnitude: 0.03917
Value Function Update Magnitude: 0.05278

Collected Steps per Second: 10,944.89696
Overall Steps per Second: 9,180.14259

Timestep Collection Time: 4.56925
Timestep Consumption Time: 0.87838
PPO Batch Consumption Time: 0.04476
Total Iteration Time: 5.44763

Cumulative Model Updates: 6,287
Cumulative Timesteps: 104,933,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 104933704...
Checkpoint 104933704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.81802
Policy Entropy: 1.19812
Value Function Loss: 5.07012

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.05151

Collected Steps per Second: 10,794.22836
Overall Steps per Second: 9,125.52224

Timestep Collection Time: 4.63303
Timestep Consumption Time: 0.84720
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.48023

Cumulative Model Updates: 6,290
Cumulative Timesteps: 104,983,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.21818
Policy Entropy: 1.19503
Value Function Loss: 5.03241

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.05287

Collected Steps per Second: 10,745.15701
Overall Steps per Second: 9,245.73000

Timestep Collection Time: 4.65549
Timestep Consumption Time: 0.75500
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 5.41050

Cumulative Model Updates: 6,293
Cumulative Timesteps: 105,033,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 105033738...
Checkpoint 105033738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.90585
Policy Entropy: 1.20324
Value Function Loss: 5.00451

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.05206

Collected Steps per Second: 10,982.05709
Overall Steps per Second: 9,262.58920

Timestep Collection Time: 4.55306
Timestep Consumption Time: 0.84521
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.39827

Cumulative Model Updates: 6,296
Cumulative Timesteps: 105,083,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.22635
Policy Entropy: 1.20398
Value Function Loss: 5.01535

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.06372

Collected Steps per Second: 10,879.92024
Overall Steps per Second: 8,946.04087

Timestep Collection Time: 4.59691
Timestep Consumption Time: 0.99372
PPO Batch Consumption Time: 0.04840
Total Iteration Time: 5.59063

Cumulative Model Updates: 6,299
Cumulative Timesteps: 105,133,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 105133754...
Checkpoint 105133754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.02294
Policy Entropy: 1.19409
Value Function Loss: 4.94424

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.05569

Collected Steps per Second: 11,241.26648
Overall Steps per Second: 9,282.25224

Timestep Collection Time: 4.44896
Timestep Consumption Time: 0.93895
PPO Batch Consumption Time: 0.04886
Total Iteration Time: 5.38792

Cumulative Model Updates: 6,302
Cumulative Timesteps: 105,183,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.73121
Policy Entropy: 1.18663
Value Function Loss: 4.94595

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.06785

Collected Steps per Second: 10,937.09563
Overall Steps per Second: 9,214.40967

Timestep Collection Time: 4.57306
Timestep Consumption Time: 0.85496
PPO Batch Consumption Time: 0.05029
Total Iteration Time: 5.42802

Cumulative Model Updates: 6,305
Cumulative Timesteps: 105,233,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 105233782...
Checkpoint 105233782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.85471
Policy Entropy: 1.19076
Value Function Loss: 4.77973

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07362
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.08718

Collected Steps per Second: 11,283.96901
Overall Steps per Second: 9,640.21748

Timestep Collection Time: 4.43195
Timestep Consumption Time: 0.75569
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 5.18764

Cumulative Model Updates: 6,308
Cumulative Timesteps: 105,283,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.83396
Policy Entropy: 1.19825
Value Function Loss: 4.83857

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.08128

Collected Steps per Second: 10,863.53856
Overall Steps per Second: 9,142.19325

Timestep Collection Time: 4.60274
Timestep Consumption Time: 0.86663
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 5.46937

Cumulative Model Updates: 6,311
Cumulative Timesteps: 105,333,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 105333794...
Checkpoint 105333794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.48884
Policy Entropy: 1.18451
Value Function Loss: 4.87442

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.07324

Collected Steps per Second: 10,952.09671
Overall Steps per Second: 9,384.15374

Timestep Collection Time: 4.56570
Timestep Consumption Time: 0.76286
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.32856

Cumulative Model Updates: 6,314
Cumulative Timesteps: 105,383,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.73782
Policy Entropy: 1.17818
Value Function Loss: 4.92561

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.08544

Collected Steps per Second: 10,180.84207
Overall Steps per Second: 8,698.12507

Timestep Collection Time: 4.91197
Timestep Consumption Time: 0.83731
PPO Batch Consumption Time: 0.04546
Total Iteration Time: 5.74928

Cumulative Model Updates: 6,317
Cumulative Timesteps: 105,433,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 105433806...
Checkpoint 105433806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.50394
Policy Entropy: 1.18429
Value Function Loss: 4.86387

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.07770

Collected Steps per Second: 10,680.12849
Overall Steps per Second: 9,020.27889

Timestep Collection Time: 4.68272
Timestep Consumption Time: 0.86168
PPO Batch Consumption Time: 0.04677
Total Iteration Time: 5.54440

Cumulative Model Updates: 6,320
Cumulative Timesteps: 105,483,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.77733
Policy Entropy: 1.19043
Value Function Loss: 4.86961

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.08603

Collected Steps per Second: 11,148.19273
Overall Steps per Second: 9,332.83396

Timestep Collection Time: 4.48503
Timestep Consumption Time: 0.87240
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 5.35743

Cumulative Model Updates: 6,323
Cumulative Timesteps: 105,533,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 105533818...
Checkpoint 105533818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.75123
Policy Entropy: 1.18878
Value Function Loss: 4.87398

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06700
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.07664

Collected Steps per Second: 10,755.35895
Overall Steps per Second: 9,110.43526

Timestep Collection Time: 4.65089
Timestep Consumption Time: 0.83974
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 5.49063

Cumulative Model Updates: 6,326
Cumulative Timesteps: 105,583,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.35897
Policy Entropy: 1.18255
Value Function Loss: 5.02307

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 10,947.09084
Overall Steps per Second: 9,302.31191

Timestep Collection Time: 4.56761
Timestep Consumption Time: 0.80762
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 5.37522

Cumulative Model Updates: 6,329
Cumulative Timesteps: 105,633,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 105633842...
Checkpoint 105633842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.56930
Policy Entropy: 1.19508
Value Function Loss: 5.17400

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.08621
Policy Update Magnitude: 0.06888
Value Function Update Magnitude: 0.06998

Collected Steps per Second: 10,590.30398
Overall Steps per Second: 8,901.71480

Timestep Collection Time: 4.72206
Timestep Consumption Time: 0.89574
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 5.61779

Cumulative Model Updates: 6,332
Cumulative Timesteps: 105,683,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.14757
Policy Entropy: 1.19612
Value Function Loss: 5.35285

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.07284

Collected Steps per Second: 10,790.54023
Overall Steps per Second: 9,200.78503

Timestep Collection Time: 4.63369
Timestep Consumption Time: 0.80063
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 5.43432

Cumulative Model Updates: 6,335
Cumulative Timesteps: 105,733,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 105733850...
Checkpoint 105733850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.35129
Policy Entropy: 1.18996
Value Function Loss: 5.40030

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.06195
Policy Update Magnitude: 0.06934
Value Function Update Magnitude: 0.08341

Collected Steps per Second: 10,902.00771
Overall Steps per Second: 9,255.02645

Timestep Collection Time: 4.58668
Timestep Consumption Time: 0.81622
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.40290

Cumulative Model Updates: 6,338
Cumulative Timesteps: 105,783,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.05282
Policy Entropy: 1.19145
Value Function Loss: 5.15238

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.04630
Policy Update Magnitude: 0.07731
Value Function Update Magnitude: 0.09362

Collected Steps per Second: 10,771.96073
Overall Steps per Second: 9,161.07775

Timestep Collection Time: 4.64391
Timestep Consumption Time: 0.81658
PPO Batch Consumption Time: 0.04497
Total Iteration Time: 5.46049

Cumulative Model Updates: 6,341
Cumulative Timesteps: 105,833,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 105833878...
Checkpoint 105833878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.93667
Policy Entropy: 1.18710
Value Function Loss: 5.03354

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.05050
Policy Update Magnitude: 0.08379
Value Function Update Magnitude: 0.09995

Collected Steps per Second: 10,684.61429
Overall Steps per Second: 9,100.11242

Timestep Collection Time: 4.68225
Timestep Consumption Time: 0.81527
PPO Batch Consumption Time: 0.04677
Total Iteration Time: 5.49751

Cumulative Model Updates: 6,344
Cumulative Timesteps: 105,883,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.64143
Policy Entropy: 1.17981
Value Function Loss: 5.02102

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.08464
Value Function Update Magnitude: 0.11387

Collected Steps per Second: 10,907.63736
Overall Steps per Second: 9,266.41344

Timestep Collection Time: 4.58614
Timestep Consumption Time: 0.81228
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 5.39842

Cumulative Model Updates: 6,347
Cumulative Timesteps: 105,933,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 105933930...
Checkpoint 105933930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.98947
Policy Entropy: 1.18140
Value Function Loss: 5.16485

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.08676
Value Function Update Magnitude: 0.12651

Collected Steps per Second: 10,231.46218
Overall Steps per Second: 8,822.41797

Timestep Collection Time: 4.88884
Timestep Consumption Time: 0.78081
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 5.66965

Cumulative Model Updates: 6,350
Cumulative Timesteps: 105,983,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.60969
Policy Entropy: 1.18540
Value Function Loss: 5.29109

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.07574
Value Function Update Magnitude: 0.10261

Collected Steps per Second: 10,712.47097
Overall Steps per Second: 9,129.50089

Timestep Collection Time: 4.66970
Timestep Consumption Time: 0.80968
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 5.47938

Cumulative Model Updates: 6,353
Cumulative Timesteps: 106,033,974

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 106033974...
Checkpoint 106033974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.81324
Policy Entropy: 1.19034
Value Function Loss: 5.18033

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.07946
Policy Update Magnitude: 0.08258
Value Function Update Magnitude: 0.08587

Collected Steps per Second: 10,938.27663
Overall Steps per Second: 9,211.06659

Timestep Collection Time: 4.57403
Timestep Consumption Time: 0.85770
PPO Batch Consumption Time: 0.04725
Total Iteration Time: 5.43173

Cumulative Model Updates: 6,356
Cumulative Timesteps: 106,084,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.40254
Policy Entropy: 1.19863
Value Function Loss: 5.13774

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06319
Policy Update Magnitude: 0.07653
Value Function Update Magnitude: 0.08802

Collected Steps per Second: 10,880.12911
Overall Steps per Second: 9,149.29330

Timestep Collection Time: 4.59811
Timestep Consumption Time: 0.86986
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.46796

Cumulative Model Updates: 6,359
Cumulative Timesteps: 106,134,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 106134034...
Checkpoint 106134034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.36482
Policy Entropy: 1.19434
Value Function Loss: 4.97447

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06157
Policy Update Magnitude: 0.07501
Value Function Update Magnitude: 0.08273

Collected Steps per Second: 11,032.55229
Overall Steps per Second: 9,304.75499

Timestep Collection Time: 4.53277
Timestep Consumption Time: 0.84169
PPO Batch Consumption Time: 0.04533
Total Iteration Time: 5.37446

Cumulative Model Updates: 6,362
Cumulative Timesteps: 106,184,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.25211
Policy Entropy: 1.19763
Value Function Loss: 5.09321

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06119
Policy Update Magnitude: 0.07041
Value Function Update Magnitude: 0.07505

Collected Steps per Second: 10,891.11197
Overall Steps per Second: 9,261.35113

Timestep Collection Time: 4.59163
Timestep Consumption Time: 0.80801
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.39964

Cumulative Model Updates: 6,365
Cumulative Timesteps: 106,234,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 106234050...
Checkpoint 106234050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.70059
Policy Entropy: 1.18643
Value Function Loss: 5.22194

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.07648
Value Function Update Magnitude: 0.06864

Collected Steps per Second: 10,694.68727
Overall Steps per Second: 9,075.43313

Timestep Collection Time: 4.67690
Timestep Consumption Time: 0.83446
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.51136

Cumulative Model Updates: 6,368
Cumulative Timesteps: 106,284,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.40245
Policy Entropy: 1.19530
Value Function Loss: 5.46288

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.07367
Value Function Update Magnitude: 0.05589

Collected Steps per Second: 10,540.13969
Overall Steps per Second: 8,894.39729

Timestep Collection Time: 4.74510
Timestep Consumption Time: 0.87799
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 5.62309

Cumulative Model Updates: 6,371
Cumulative Timesteps: 106,334,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 106334082...
Checkpoint 106334082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.37077
Policy Entropy: 1.18585
Value Function Loss: 5.45152

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.07342
Value Function Update Magnitude: 0.05284

Collected Steps per Second: 11,135.85597
Overall Steps per Second: 9,394.90655

Timestep Collection Time: 4.49108
Timestep Consumption Time: 0.83223
PPO Batch Consumption Time: 0.04455
Total Iteration Time: 5.32331

Cumulative Model Updates: 6,374
Cumulative Timesteps: 106,384,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.86219
Policy Entropy: 1.18375
Value Function Loss: 5.56124

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.07447
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 10,748.50100
Overall Steps per Second: 9,003.28093

Timestep Collection Time: 4.65349
Timestep Consumption Time: 0.90204
PPO Batch Consumption Time: 0.04706
Total Iteration Time: 5.55553

Cumulative Model Updates: 6,377
Cumulative Timesteps: 106,434,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 106434112...
Checkpoint 106434112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.39937
Policy Entropy: 1.17958
Value Function Loss: 5.19424

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.07466
Value Function Update Magnitude: 0.04653

Collected Steps per Second: 10,689.90596
Overall Steps per Second: 9,041.56108

Timestep Collection Time: 4.67787
Timestep Consumption Time: 0.85281
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 5.53068

Cumulative Model Updates: 6,380
Cumulative Timesteps: 106,484,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.07135
Policy Entropy: 1.18210
Value Function Loss: 5.21415

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.06582
Value Function Update Magnitude: 0.04615

Collected Steps per Second: 10,400.32303
Overall Steps per Second: 8,849.60183

Timestep Collection Time: 4.80947
Timestep Consumption Time: 0.84277
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 5.65223

Cumulative Model Updates: 6,383
Cumulative Timesteps: 106,534,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 106534138...
Checkpoint 106534138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.07242
Policy Entropy: 1.18654
Value Function Loss: 5.07742

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.04548

Collected Steps per Second: 10,951.05301
Overall Steps per Second: 9,393.43025

Timestep Collection Time: 4.56650
Timestep Consumption Time: 0.75722
PPO Batch Consumption Time: 0.04151
Total Iteration Time: 5.32372

Cumulative Model Updates: 6,386
Cumulative Timesteps: 106,584,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.22083
Policy Entropy: 1.17323
Value Function Loss: 5.07087

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.04978

Collected Steps per Second: 10,926.53220
Overall Steps per Second: 9,180.88003

Timestep Collection Time: 4.57931
Timestep Consumption Time: 0.87071
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 5.45002

Cumulative Model Updates: 6,389
Cumulative Timesteps: 106,634,182

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 106634182...
Checkpoint 106634182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.70655
Policy Entropy: 1.17911
Value Function Loss: 5.12359

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.04774

Collected Steps per Second: 10,625.98911
Overall Steps per Second: 9,051.94005

Timestep Collection Time: 4.70639
Timestep Consumption Time: 0.81840
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.52478

Cumulative Model Updates: 6,392
Cumulative Timesteps: 106,684,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.73145
Policy Entropy: 1.18998
Value Function Loss: 5.02695

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.04615

Collected Steps per Second: 10,886.96125
Overall Steps per Second: 9,180.55877

Timestep Collection Time: 4.59375
Timestep Consumption Time: 0.85385
PPO Batch Consumption Time: 0.04354
Total Iteration Time: 5.44760

Cumulative Model Updates: 6,395
Cumulative Timesteps: 106,734,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 106734204...
Checkpoint 106734204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.77583
Policy Entropy: 1.19271
Value Function Loss: 5.05942

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.08287
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.04082

Collected Steps per Second: 10,386.79772
Overall Steps per Second: 8,837.40327

Timestep Collection Time: 4.81457
Timestep Consumption Time: 0.84410
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 5.65868

Cumulative Model Updates: 6,398
Cumulative Timesteps: 106,784,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.33962
Policy Entropy: 1.19211
Value Function Loss: 5.22605

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.06934
Value Function Update Magnitude: 0.04404

Collected Steps per Second: 10,747.23425
Overall Steps per Second: 9,219.98649

Timestep Collection Time: 4.65385
Timestep Consumption Time: 0.77089
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 5.42474

Cumulative Model Updates: 6,401
Cumulative Timesteps: 106,834,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 106834228...
Checkpoint 106834228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.39641
Policy Entropy: 1.18169
Value Function Loss: 5.01328

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.06538
Value Function Update Magnitude: 0.04252

Collected Steps per Second: 10,883.56078
Overall Steps per Second: 9,254.31013

Timestep Collection Time: 4.59555
Timestep Consumption Time: 0.80906
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.40462

Cumulative Model Updates: 6,404
Cumulative Timesteps: 106,884,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.97170
Policy Entropy: 1.19578
Value Function Loss: 5.30422

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.07567
Value Function Update Magnitude: 0.04115

Collected Steps per Second: 10,823.11277
Overall Steps per Second: 9,356.59464

Timestep Collection Time: 4.62067
Timestep Consumption Time: 0.72423
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 5.34489

Cumulative Model Updates: 6,407
Cumulative Timesteps: 106,934,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 106934254...
Checkpoint 106934254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.73324
Policy Entropy: 1.17829
Value Function Loss: 5.00268

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.06345
Value Function Update Magnitude: 0.04367

Collected Steps per Second: 10,575.03849
Overall Steps per Second: 8,998.32609

Timestep Collection Time: 4.72982
Timestep Consumption Time: 0.82877
PPO Batch Consumption Time: 0.03900
Total Iteration Time: 5.55859

Cumulative Model Updates: 6,410
Cumulative Timesteps: 106,984,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.65590
Policy Entropy: 1.18156
Value Function Loss: 5.14469

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.06151
Value Function Update Magnitude: 0.04175

Collected Steps per Second: 10,851.00001
Overall Steps per Second: 9,141.72469

Timestep Collection Time: 4.60990
Timestep Consumption Time: 0.86194
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 5.47183

Cumulative Model Updates: 6,413
Cumulative Timesteps: 107,034,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 107034294...
Checkpoint 107034294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.10165
Policy Entropy: 1.19602
Value Function Loss: 5.03019

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.08126
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.04442

Collected Steps per Second: 10,318.32831
Overall Steps per Second: 8,922.88718

Timestep Collection Time: 4.84652
Timestep Consumption Time: 0.75794
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.60446

Cumulative Model Updates: 6,416
Cumulative Timesteps: 107,084,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.25264
Policy Entropy: 1.20390
Value Function Loss: 5.02754

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.04276

Collected Steps per Second: 10,810.70895
Overall Steps per Second: 9,094.02503

Timestep Collection Time: 4.62726
Timestep Consumption Time: 0.87349
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.50075

Cumulative Model Updates: 6,419
Cumulative Timesteps: 107,134,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 107134326...
Checkpoint 107134326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.79285
Policy Entropy: 1.18295
Value Function Loss: 5.11472

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.07935
Value Function Update Magnitude: 0.03918

Collected Steps per Second: 10,642.93216
Overall Steps per Second: 9,067.55113

Timestep Collection Time: 4.69833
Timestep Consumption Time: 0.81628
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 5.51461

Cumulative Model Updates: 6,422
Cumulative Timesteps: 107,184,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.52115
Policy Entropy: 1.19393
Value Function Loss: 5.36152

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.04538

Collected Steps per Second: 10,757.80496
Overall Steps per Second: 9,055.41312

Timestep Collection Time: 4.64946
Timestep Consumption Time: 0.87409
PPO Batch Consumption Time: 0.04695
Total Iteration Time: 5.52355

Cumulative Model Updates: 6,425
Cumulative Timesteps: 107,234,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 107234348...
Checkpoint 107234348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.97176
Policy Entropy: 1.19307
Value Function Loss: 5.32643

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.04527

Collected Steps per Second: 10,963.16615
Overall Steps per Second: 9,182.50781

Timestep Collection Time: 4.56146
Timestep Consumption Time: 0.88455
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 5.44601

Cumulative Model Updates: 6,428
Cumulative Timesteps: 107,284,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.07073
Policy Entropy: 1.18125
Value Function Loss: 5.50327

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.04175

Collected Steps per Second: 10,713.94107
Overall Steps per Second: 9,078.53356

Timestep Collection Time: 4.66738
Timestep Consumption Time: 0.84078
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.50816

Cumulative Model Updates: 6,431
Cumulative Timesteps: 107,334,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 107334362...
Checkpoint 107334362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.81328
Policy Entropy: 1.18464
Value Function Loss: 5.22509

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.04466

Collected Steps per Second: 10,419.09757
Overall Steps per Second: 8,743.33161

Timestep Collection Time: 4.79888
Timestep Consumption Time: 0.91976
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 5.71864

Cumulative Model Updates: 6,434
Cumulative Timesteps: 107,384,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.83549
Policy Entropy: 1.18820
Value Function Loss: 5.37050

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.04351

Collected Steps per Second: 10,644.69850
Overall Steps per Second: 9,133.64619

Timestep Collection Time: 4.69868
Timestep Consumption Time: 0.77734
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 5.47602

Cumulative Model Updates: 6,437
Cumulative Timesteps: 107,434,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 107434378...
Checkpoint 107434378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.10362
Policy Entropy: 1.20434
Value Function Loss: 5.08106

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.04828

Collected Steps per Second: 11,171.22289
Overall Steps per Second: 9,456.49535

Timestep Collection Time: 4.47847
Timestep Consumption Time: 0.81207
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.29054

Cumulative Model Updates: 6,440
Cumulative Timesteps: 107,484,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.21147
Policy Entropy: 1.18825
Value Function Loss: 5.12902

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.04913

Collected Steps per Second: 10,645.88695
Overall Steps per Second: 9,278.57562

Timestep Collection Time: 4.69684
Timestep Consumption Time: 0.69214
PPO Batch Consumption Time: 0.04200
Total Iteration Time: 5.38897

Cumulative Model Updates: 6,443
Cumulative Timesteps: 107,534,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 107534410...
Checkpoint 107534410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.57214
Policy Entropy: 1.20079
Value Function Loss: 5.08778

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.04614

Collected Steps per Second: 10,685.23046
Overall Steps per Second: 9,071.59794

Timestep Collection Time: 4.68123
Timestep Consumption Time: 0.83268
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.51391

Cumulative Model Updates: 6,446
Cumulative Timesteps: 107,584,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.70529
Policy Entropy: 1.20293
Value Function Loss: 5.14643

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.04678

Collected Steps per Second: 9,955.53032
Overall Steps per Second: 8,616.52432

Timestep Collection Time: 5.02414
Timestep Consumption Time: 0.78075
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 5.80489

Cumulative Model Updates: 6,449
Cumulative Timesteps: 107,634,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 107634448...
Checkpoint 107634448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.64747
Policy Entropy: 1.19853
Value Function Loss: 5.08198

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.04370

Collected Steps per Second: 11,075.99050
Overall Steps per Second: 9,332.76130

Timestep Collection Time: 4.51644
Timestep Consumption Time: 0.84361
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 5.36004

Cumulative Model Updates: 6,452
Cumulative Timesteps: 107,684,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.63219
Policy Entropy: 1.19489
Value Function Loss: 4.98444

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.04358
Value Function Update Magnitude: 0.03938

Collected Steps per Second: 10,959.12358
Overall Steps per Second: 9,266.39502

Timestep Collection Time: 4.56387
Timestep Consumption Time: 0.83370
PPO Batch Consumption Time: 0.04803
Total Iteration Time: 5.39757

Cumulative Model Updates: 6,455
Cumulative Timesteps: 107,734,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 107734488...
Checkpoint 107734488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.95213
Policy Entropy: 1.19498
Value Function Loss: 4.79795

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.06758
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.03966

Collected Steps per Second: 10,725.58089
Overall Steps per Second: 9,174.93476

Timestep Collection Time: 4.66343
Timestep Consumption Time: 0.78816
PPO Batch Consumption Time: 0.04501
Total Iteration Time: 5.45159

Cumulative Model Updates: 6,458
Cumulative Timesteps: 107,784,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.62965
Policy Entropy: 1.19920
Value Function Loss: 4.84888

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.05727

Collected Steps per Second: 10,840.46678
Overall Steps per Second: 9,153.53238

Timestep Collection Time: 4.61272
Timestep Consumption Time: 0.85009
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 5.46281

Cumulative Model Updates: 6,461
Cumulative Timesteps: 107,834,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 107834510...
Checkpoint 107834510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.00322
Policy Entropy: 1.19352
Value Function Loss: 4.87890

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.06479
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.05735

Collected Steps per Second: 10,215.15304
Overall Steps per Second: 8,753.36517

Timestep Collection Time: 4.89586
Timestep Consumption Time: 0.81760
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 5.71346

Cumulative Model Updates: 6,464
Cumulative Timesteps: 107,884,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.99727
Policy Entropy: 1.18408
Value Function Loss: 5.22861

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.05687

Collected Steps per Second: 11,110.06060
Overall Steps per Second: 9,357.16578

Timestep Collection Time: 4.50151
Timestep Consumption Time: 0.84328
PPO Batch Consumption Time: 0.04531
Total Iteration Time: 5.34478

Cumulative Model Updates: 6,467
Cumulative Timesteps: 107,934,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 107934534...
Checkpoint 107934534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.11210
Policy Entropy: 1.21436
Value Function Loss: 5.43347

Mean KL Divergence: 0.03169
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.06106

Collected Steps per Second: 10,620.90131
Overall Steps per Second: 8,990.71287

Timestep Collection Time: 4.71033
Timestep Consumption Time: 0.85407
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 5.56441

Cumulative Model Updates: 6,470
Cumulative Timesteps: 107,984,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.01833
Policy Entropy: 1.20257
Value Function Loss: 5.60480

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.05488

Collected Steps per Second: 10,852.61049
Overall Steps per Second: 9,246.38249

Timestep Collection Time: 4.60940
Timestep Consumption Time: 0.80072
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 5.41012

Cumulative Model Updates: 6,473
Cumulative Timesteps: 108,034,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 108034586...
Checkpoint 108034586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.77023
Policy Entropy: 1.21646
Value Function Loss: 5.38954

Mean KL Divergence: 0.02461
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.07536
Value Function Update Magnitude: 0.05887

Collected Steps per Second: 10,650.15322
Overall Steps per Second: 9,099.10707

Timestep Collection Time: 4.69552
Timestep Consumption Time: 0.80040
PPO Batch Consumption Time: 0.04331
Total Iteration Time: 5.49592

Cumulative Model Updates: 6,476
Cumulative Timesteps: 108,084,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.42258
Policy Entropy: 1.20717
Value Function Loss: 5.39413

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.06978
Value Function Update Magnitude: 0.07371

Collected Steps per Second: 10,881.57345
Overall Steps per Second: 9,201.41755

Timestep Collection Time: 4.59639
Timestep Consumption Time: 0.83929
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 5.43568

Cumulative Model Updates: 6,479
Cumulative Timesteps: 108,134,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 108134610...
Checkpoint 108134610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.33719
Policy Entropy: 1.21134
Value Function Loss: 5.24259

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.06656
Value Function Update Magnitude: 0.06148

Collected Steps per Second: 10,773.28151
Overall Steps per Second: 8,993.23009

Timestep Collection Time: 4.64390
Timestep Consumption Time: 0.91918
PPO Batch Consumption Time: 0.04395
Total Iteration Time: 5.56307

Cumulative Model Updates: 6,482
Cumulative Timesteps: 108,184,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.99038
Policy Entropy: 1.21369
Value Function Loss: 5.26557

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.05875

Collected Steps per Second: 10,823.49126
Overall Steps per Second: 9,222.55301

Timestep Collection Time: 4.62180
Timestep Consumption Time: 0.80230
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 5.42409

Cumulative Model Updates: 6,485
Cumulative Timesteps: 108,234,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 108234664...
Checkpoint 108234664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.78329
Policy Entropy: 1.20537
Value Function Loss: 5.03287

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.07395

Collected Steps per Second: 10,709.41776
Overall Steps per Second: 9,284.22461

Timestep Collection Time: 4.66916
Timestep Consumption Time: 0.71675
PPO Batch Consumption Time: 0.04418
Total Iteration Time: 5.38591

Cumulative Model Updates: 6,488
Cumulative Timesteps: 108,284,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.22748
Policy Entropy: 1.20843
Value Function Loss: 5.02962

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.07701
Value Function Update Magnitude: 0.08599

Collected Steps per Second: 10,748.11173
Overall Steps per Second: 9,113.10528

Timestep Collection Time: 4.65310
Timestep Consumption Time: 0.83482
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.48792

Cumulative Model Updates: 6,491
Cumulative Timesteps: 108,334,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 108334680...
Checkpoint 108334680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.04625
Policy Entropy: 1.21130
Value Function Loss: 5.02953

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.07576
Policy Update Magnitude: 0.08697
Value Function Update Magnitude: 0.06695

Collected Steps per Second: 10,899.72400
Overall Steps per Second: 9,275.83333

Timestep Collection Time: 4.58764
Timestep Consumption Time: 0.80314
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 5.39078

Cumulative Model Updates: 6,494
Cumulative Timesteps: 108,384,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.99407
Policy Entropy: 1.21955
Value Function Loss: 5.11616

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.07807
Value Function Update Magnitude: 0.05740

Collected Steps per Second: 10,613.16137
Overall Steps per Second: 9,068.66494

Timestep Collection Time: 4.71151
Timestep Consumption Time: 0.80242
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 5.51393

Cumulative Model Updates: 6,497
Cumulative Timesteps: 108,434,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 108434688...
Checkpoint 108434688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.03607
Policy Entropy: 1.21684
Value Function Loss: 4.99506

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.07970
Value Function Update Magnitude: 0.07156

Collected Steps per Second: 10,840.47640
Overall Steps per Second: 9,289.02702

Timestep Collection Time: 4.61290
Timestep Consumption Time: 0.77044
PPO Batch Consumption Time: 0.04147
Total Iteration Time: 5.38334

Cumulative Model Updates: 6,500
Cumulative Timesteps: 108,484,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.89948
Policy Entropy: 1.22058
Value Function Loss: 4.89304

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.06953
Value Function Update Magnitude: 0.07148

Collected Steps per Second: 10,793.40176
Overall Steps per Second: 9,303.66819

Timestep Collection Time: 4.63505
Timestep Consumption Time: 0.74218
PPO Batch Consumption Time: 0.04043
Total Iteration Time: 5.37723

Cumulative Model Updates: 6,503
Cumulative Timesteps: 108,534,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 108534722...
Checkpoint 108534722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.54613
Policy Entropy: 1.22304
Value Function Loss: 4.80519

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07346
Policy Update Magnitude: 0.07568
Value Function Update Magnitude: 0.08389

Collected Steps per Second: 10,628.71123
Overall Steps per Second: 8,969.40754

Timestep Collection Time: 4.70424
Timestep Consumption Time: 0.87027
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 5.57450

Cumulative Model Updates: 6,506
Cumulative Timesteps: 108,584,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.61884
Policy Entropy: 1.22357
Value Function Loss: 4.93902

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.07977

Collected Steps per Second: 10,750.15303
Overall Steps per Second: 9,228.97360

Timestep Collection Time: 4.65203
Timestep Consumption Time: 0.76678
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.41880

Cumulative Model Updates: 6,509
Cumulative Timesteps: 108,634,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 108634732...
Checkpoint 108634732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.20115
Policy Entropy: 1.21390
Value Function Loss: 4.95807

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.06803
Policy Update Magnitude: 0.08040
Value Function Update Magnitude: 0.07410

Collected Steps per Second: 10,960.69245
Overall Steps per Second: 9,153.72423

Timestep Collection Time: 4.56413
Timestep Consumption Time: 0.90097
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 5.46510

Cumulative Model Updates: 6,512
Cumulative Timesteps: 108,684,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.18575
Policy Entropy: 1.21933
Value Function Loss: 4.99933

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.07009
Value Function Update Magnitude: 0.07229

Collected Steps per Second: 10,452.52017
Overall Steps per Second: 8,903.94226

Timestep Collection Time: 4.78411
Timestep Consumption Time: 0.83205
PPO Batch Consumption Time: 0.04339
Total Iteration Time: 5.61616

Cumulative Model Updates: 6,515
Cumulative Timesteps: 108,734,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 108734764...
Checkpoint 108734764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.02085
Policy Entropy: 1.22054
Value Function Loss: 4.85681

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.07342

Collected Steps per Second: 10,824.85803
Overall Steps per Second: 9,185.90137

Timestep Collection Time: 4.62140
Timestep Consumption Time: 0.82455
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 5.44595

Cumulative Model Updates: 6,518
Cumulative Timesteps: 108,784,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.76255
Policy Entropy: 1.20754
Value Function Loss: 4.98762

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.06271
Value Function Update Magnitude: 0.08373

Collected Steps per Second: 11,161.73372
Overall Steps per Second: 9,406.25188

Timestep Collection Time: 4.48210
Timestep Consumption Time: 0.83649
PPO Batch Consumption Time: 0.03927
Total Iteration Time: 5.31859

Cumulative Model Updates: 6,521
Cumulative Timesteps: 108,834,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 108834818...
Checkpoint 108834818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.47670
Policy Entropy: 1.21358
Value Function Loss: 5.04937

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.08885

Collected Steps per Second: 10,711.52623
Overall Steps per Second: 9,050.94583

Timestep Collection Time: 4.66806
Timestep Consumption Time: 0.85645
PPO Batch Consumption Time: 0.04344
Total Iteration Time: 5.52451

Cumulative Model Updates: 6,524
Cumulative Timesteps: 108,884,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.33193
Policy Entropy: 1.21433
Value Function Loss: 5.31759

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.07123
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.08088

Collected Steps per Second: 10,882.24749
Overall Steps per Second: 9,446.80224

Timestep Collection Time: 4.59611
Timestep Consumption Time: 0.69838
PPO Batch Consumption Time: 0.04182
Total Iteration Time: 5.29449

Cumulative Model Updates: 6,527
Cumulative Timesteps: 108,934,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 108934836...
Checkpoint 108934836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.41071
Policy Entropy: 1.21890
Value Function Loss: 5.00380

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.06704
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.08462

Collected Steps per Second: 10,299.06167
Overall Steps per Second: 8,830.12509

Timestep Collection Time: 4.85753
Timestep Consumption Time: 0.80807
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 5.66560

Cumulative Model Updates: 6,530
Cumulative Timesteps: 108,984,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.97060
Policy Entropy: 1.21564
Value Function Loss: 5.10725

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.05676
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.06944

Collected Steps per Second: 10,347.70990
Overall Steps per Second: 8,858.05187

Timestep Collection Time: 4.83411
Timestep Consumption Time: 0.81295
PPO Batch Consumption Time: 0.03925
Total Iteration Time: 5.64707

Cumulative Model Updates: 6,533
Cumulative Timesteps: 109,034,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 109034886...
Checkpoint 109034886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.78936
Policy Entropy: 1.21795
Value Function Loss: 5.01674

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.05580

Collected Steps per Second: 10,730.22824
Overall Steps per Second: 8,971.77591

Timestep Collection Time: 4.66197
Timestep Consumption Time: 0.91374
PPO Batch Consumption Time: 0.04745
Total Iteration Time: 5.57571

Cumulative Model Updates: 6,536
Cumulative Timesteps: 109,084,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.51910
Policy Entropy: 1.21868
Value Function Loss: 5.22816

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.04575
Policy Update Magnitude: 0.08965
Value Function Update Magnitude: 0.05552

Collected Steps per Second: 10,900.56370
Overall Steps per Second: 9,228.81924

Timestep Collection Time: 4.58729
Timestep Consumption Time: 0.83096
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 5.41824

Cumulative Model Updates: 6,539
Cumulative Timesteps: 109,134,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 109134914...
Checkpoint 109134914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.84129
Policy Entropy: 1.22903
Value Function Loss: 5.28548

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06472
Policy Update Magnitude: 0.10512
Value Function Update Magnitude: 0.05506

Collected Steps per Second: 10,774.91802
Overall Steps per Second: 9,018.43022

Timestep Collection Time: 4.64115
Timestep Consumption Time: 0.90394
PPO Batch Consumption Time: 0.04612
Total Iteration Time: 5.54509

Cumulative Model Updates: 6,542
Cumulative Timesteps: 109,184,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.49412
Policy Entropy: 1.21216
Value Function Loss: 5.05578

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.08864
Value Function Update Magnitude: 0.05581

Collected Steps per Second: 10,540.34505
Overall Steps per Second: 8,912.05631

Timestep Collection Time: 4.74520
Timestep Consumption Time: 0.86698
PPO Batch Consumption Time: 0.04547
Total Iteration Time: 5.61217

Cumulative Model Updates: 6,545
Cumulative Timesteps: 109,234,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 109234938...
Checkpoint 109234938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.97515
Policy Entropy: 1.23748
Value Function Loss: 5.05409

Mean KL Divergence: 0.02382
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.08110
Value Function Update Magnitude: 0.05484

Collected Steps per Second: 10,583.80518
Overall Steps per Second: 9,150.27961

Timestep Collection Time: 4.72552
Timestep Consumption Time: 0.74032
PPO Batch Consumption Time: 0.04471
Total Iteration Time: 5.46584

Cumulative Model Updates: 6,548
Cumulative Timesteps: 109,284,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.84540
Policy Entropy: 1.21615
Value Function Loss: 4.90302

Mean KL Divergence: 0.03325
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.05388

Collected Steps per Second: 10,661.16516
Overall Steps per Second: 9,013.90250

Timestep Collection Time: 4.68992
Timestep Consumption Time: 0.85707
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.54699

Cumulative Model Updates: 6,551
Cumulative Timesteps: 109,334,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 109334952...
Checkpoint 109334952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.36749
Policy Entropy: 1.23423
Value Function Loss: 5.04132

Mean KL Divergence: 0.02613
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.05220

Collected Steps per Second: 10,715.99479
Overall Steps per Second: 9,013.65544

Timestep Collection Time: 4.66648
Timestep Consumption Time: 0.88132
PPO Batch Consumption Time: 0.04609
Total Iteration Time: 5.54780

Cumulative Model Updates: 6,554
Cumulative Timesteps: 109,384,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.73798
Policy Entropy: 1.22251
Value Function Loss: 4.86831

Mean KL Divergence: 0.02539
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.04780

Collected Steps per Second: 10,912.56928
Overall Steps per Second: 9,304.66447

Timestep Collection Time: 4.58187
Timestep Consumption Time: 0.79178
PPO Batch Consumption Time: 0.04673
Total Iteration Time: 5.37365

Cumulative Model Updates: 6,557
Cumulative Timesteps: 109,434,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 109434958...
Checkpoint 109434958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.49429
Policy Entropy: 1.23466
Value Function Loss: 5.13264

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.04633

Collected Steps per Second: 11,215.90148
Overall Steps per Second: 9,402.37370

Timestep Collection Time: 4.45974
Timestep Consumption Time: 0.86019
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.31993

Cumulative Model Updates: 6,560
Cumulative Timesteps: 109,484,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.79857
Policy Entropy: 1.21797
Value Function Loss: 5.10230

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.04866

Collected Steps per Second: 10,376.38904
Overall Steps per Second: 8,892.79669

Timestep Collection Time: 4.82172
Timestep Consumption Time: 0.80441
PPO Batch Consumption Time: 0.04431
Total Iteration Time: 5.62613

Cumulative Model Updates: 6,563
Cumulative Timesteps: 109,535,010

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 109535010...
Checkpoint 109535010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.77749
Policy Entropy: 1.23772
Value Function Loss: 5.29934

Mean KL Divergence: 0.02456
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 11,276.21544
Overall Steps per Second: 9,425.60027

Timestep Collection Time: 4.43464
Timestep Consumption Time: 0.87069
PPO Batch Consumption Time: 0.04788
Total Iteration Time: 5.30534

Cumulative Model Updates: 6,566
Cumulative Timesteps: 109,585,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.08626
Policy Entropy: 1.22739
Value Function Loss: 4.99952

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.05452

Collected Steps per Second: 11,174.42935
Overall Steps per Second: 9,441.87141

Timestep Collection Time: 4.47558
Timestep Consumption Time: 0.82126
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 5.29683

Cumulative Model Updates: 6,569
Cumulative Timesteps: 109,635,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 109635028...
Checkpoint 109635028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.16934
Policy Entropy: 1.24363
Value Function Loss: 5.10278

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.05804

Collected Steps per Second: 11,235.94471
Overall Steps per Second: 9,617.60944

Timestep Collection Time: 4.45072
Timestep Consumption Time: 0.74891
PPO Batch Consumption Time: 0.04074
Total Iteration Time: 5.19963

Cumulative Model Updates: 6,572
Cumulative Timesteps: 109,685,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.33129
Policy Entropy: 1.24490
Value Function Loss: 5.00750

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.08986

Collected Steps per Second: 10,969.89546
Overall Steps per Second: 9,208.71571

Timestep Collection Time: 4.56030
Timestep Consumption Time: 0.87216
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.43246

Cumulative Model Updates: 6,575
Cumulative Timesteps: 109,735,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 109735062...
Checkpoint 109735062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.74174
Policy Entropy: 1.23451
Value Function Loss: 4.77359

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.08819

Collected Steps per Second: 10,777.65485
Overall Steps per Second: 9,186.09481

Timestep Collection Time: 4.64145
Timestep Consumption Time: 0.80417
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 5.44562

Cumulative Model Updates: 6,578
Cumulative Timesteps: 109,785,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.67159
Policy Entropy: 1.23708
Value Function Loss: 4.60874

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 10,923.49502
Overall Steps per Second: 9,267.26572

Timestep Collection Time: 4.57912
Timestep Consumption Time: 0.81837
PPO Batch Consumption Time: 0.04453
Total Iteration Time: 5.39749

Cumulative Model Updates: 6,581
Cumulative Timesteps: 109,835,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 109835106...
Checkpoint 109835106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.31723
Policy Entropy: 1.24270
Value Function Loss: 4.69744

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 10,885.20731
Overall Steps per Second: 9,222.41225

Timestep Collection Time: 4.59504
Timestep Consumption Time: 0.82848
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.42353

Cumulative Model Updates: 6,584
Cumulative Timesteps: 109,885,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.84311
Policy Entropy: 1.24783
Value Function Loss: 4.82496

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07456
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.07990

Collected Steps per Second: 11,074.73558
Overall Steps per Second: 9,355.49281

Timestep Collection Time: 4.51641
Timestep Consumption Time: 0.82997
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 5.34638

Cumulative Model Updates: 6,587
Cumulative Timesteps: 109,935,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 109935142...
Checkpoint 109935142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.43429
Policy Entropy: 1.23317
Value Function Loss: 4.71969

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.07235
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.11425

Collected Steps per Second: 10,999.94482
Overall Steps per Second: 9,288.67171

Timestep Collection Time: 4.54693
Timestep Consumption Time: 0.83769
PPO Batch Consumption Time: 0.04121
Total Iteration Time: 5.38462

Cumulative Model Updates: 6,590
Cumulative Timesteps: 109,985,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.99400
Policy Entropy: 1.22311
Value Function Loss: 4.63121

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.11491

Collected Steps per Second: 10,706.92692
Overall Steps per Second: 9,166.18607

Timestep Collection Time: 4.67118
Timestep Consumption Time: 0.78518
PPO Batch Consumption Time: 0.04652
Total Iteration Time: 5.45636

Cumulative Model Updates: 6,593
Cumulative Timesteps: 110,035,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 110035172...
Checkpoint 110035172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.94529
Policy Entropy: 1.22284
Value Function Loss: 4.71319

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.06469
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.09730

Collected Steps per Second: 10,340.28294
Overall Steps per Second: 8,873.04519

Timestep Collection Time: 4.83623
Timestep Consumption Time: 0.79971
PPO Batch Consumption Time: 0.03876
Total Iteration Time: 5.63595

Cumulative Model Updates: 6,596
Cumulative Timesteps: 110,085,180

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.54562
Policy Entropy: 1.22831
Value Function Loss: 4.91520

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.07526

Collected Steps per Second: 10,647.55536
Overall Steps per Second: 9,136.79858

Timestep Collection Time: 4.69591
Timestep Consumption Time: 0.77646
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 5.47238

Cumulative Model Updates: 6,599
Cumulative Timesteps: 110,135,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 110135180...
Checkpoint 110135180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.89456
Policy Entropy: 1.22857
Value Function Loss: 5.15650

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.06746

Collected Steps per Second: 11,154.51332
Overall Steps per Second: 9,452.04045

Timestep Collection Time: 4.48249
Timestep Consumption Time: 0.80737
PPO Batch Consumption Time: 0.04446
Total Iteration Time: 5.28986

Cumulative Model Updates: 6,602
Cumulative Timesteps: 110,185,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.32263
Policy Entropy: 1.22665
Value Function Loss: 4.93503

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 10,704.53691
Overall Steps per Second: 9,120.09718

Timestep Collection Time: 4.67204
Timestep Consumption Time: 0.81168
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 5.48371

Cumulative Model Updates: 6,605
Cumulative Timesteps: 110,235,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 110235192...
Checkpoint 110235192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.33361
Policy Entropy: 1.23080
Value Function Loss: 4.90192

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.06536
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.05749

Collected Steps per Second: 10,673.82693
Overall Steps per Second: 9,097.19174

Timestep Collection Time: 4.68660
Timestep Consumption Time: 0.81224
PPO Batch Consumption Time: 0.04570
Total Iteration Time: 5.49884

Cumulative Model Updates: 6,608
Cumulative Timesteps: 110,285,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.49249
Policy Entropy: 1.23929
Value Function Loss: 4.73764

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07061
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.05915

Collected Steps per Second: 10,863.83844
Overall Steps per Second: 9,095.12934

Timestep Collection Time: 4.60537
Timestep Consumption Time: 0.89560
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 5.50097

Cumulative Model Updates: 6,611
Cumulative Timesteps: 110,335,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 110335248...
Checkpoint 110335248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.65613
Policy Entropy: 1.22717
Value Function Loss: 4.98002

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06344
Policy Update Magnitude: 0.08195
Value Function Update Magnitude: 0.05777

Collected Steps per Second: 10,689.95400
Overall Steps per Second: 9,051.56060

Timestep Collection Time: 4.67953
Timestep Consumption Time: 0.84703
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 5.52656

Cumulative Model Updates: 6,614
Cumulative Timesteps: 110,385,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.46733
Policy Entropy: 1.21950
Value Function Loss: 4.98113

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.07089
Value Function Update Magnitude: 0.06053

Collected Steps per Second: 10,736.02586
Overall Steps per Second: 9,281.37144

Timestep Collection Time: 4.65722
Timestep Consumption Time: 0.72992
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 5.38713

Cumulative Model Updates: 6,617
Cumulative Timesteps: 110,435,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 110435272...
Checkpoint 110435272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.31687
Policy Entropy: 1.21991
Value Function Loss: 5.17990

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.06504
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.06140

Collected Steps per Second: 10,859.76395
Overall Steps per Second: 9,246.62176

Timestep Collection Time: 4.60655
Timestep Consumption Time: 0.80365
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.41019

Cumulative Model Updates: 6,620
Cumulative Timesteps: 110,485,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.15360
Policy Entropy: 1.22124
Value Function Loss: 5.36559

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.06860

Collected Steps per Second: 10,737.60234
Overall Steps per Second: 9,303.83633

Timestep Collection Time: 4.65765
Timestep Consumption Time: 0.71777
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.37542

Cumulative Model Updates: 6,623
Cumulative Timesteps: 110,535,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 110535310...
Checkpoint 110535310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.44628
Policy Entropy: 1.21579
Value Function Loss: 5.66080

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.06698
Policy Update Magnitude: 0.06850
Value Function Update Magnitude: 0.05789

Collected Steps per Second: 10,786.93953
Overall Steps per Second: 9,188.66904

Timestep Collection Time: 4.63653
Timestep Consumption Time: 0.80648
PPO Batch Consumption Time: 0.03923
Total Iteration Time: 5.44301

Cumulative Model Updates: 6,626
Cumulative Timesteps: 110,585,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.50525
Policy Entropy: 1.21480
Value Function Loss: 5.41305

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.06234
Value Function Update Magnitude: 0.04985

Collected Steps per Second: 10,216.95372
Overall Steps per Second: 8,696.01948

Timestep Collection Time: 4.89637
Timestep Consumption Time: 0.85638
PPO Batch Consumption Time: 0.04576
Total Iteration Time: 5.75275

Cumulative Model Updates: 6,629
Cumulative Timesteps: 110,635,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 110635350...
Checkpoint 110635350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.15932
Policy Entropy: 1.21860
Value Function Loss: 5.26335

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.08885
Value Function Update Magnitude: 0.05529

Collected Steps per Second: 11,072.45979
Overall Steps per Second: 9,271.29257

Timestep Collection Time: 4.51679
Timestep Consumption Time: 0.87749
PPO Batch Consumption Time: 0.04160
Total Iteration Time: 5.39429

Cumulative Model Updates: 6,632
Cumulative Timesteps: 110,685,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.48674
Policy Entropy: 1.22162
Value Function Loss: 4.97618

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.08675
Value Function Update Magnitude: 0.05498

Collected Steps per Second: 10,782.20272
Overall Steps per Second: 9,196.57925

Timestep Collection Time: 4.63876
Timestep Consumption Time: 0.79979
PPO Batch Consumption Time: 0.04538
Total Iteration Time: 5.43854

Cumulative Model Updates: 6,635
Cumulative Timesteps: 110,735,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 110735378...
Checkpoint 110735378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.92200
Policy Entropy: 1.20359
Value Function Loss: 5.07182

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.07012
Value Function Update Magnitude: 0.06705

Collected Steps per Second: 11,028.12757
Overall Steps per Second: 9,496.46202

Timestep Collection Time: 4.53676
Timestep Consumption Time: 0.73173
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 5.26849

Cumulative Model Updates: 6,638
Cumulative Timesteps: 110,785,410

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.24639
Policy Entropy: 1.20460
Value Function Loss: 5.07397

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 10,947.46227
Overall Steps per Second: 9,227.43465

Timestep Collection Time: 4.57001
Timestep Consumption Time: 0.85187
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 5.42188

Cumulative Model Updates: 6,641
Cumulative Timesteps: 110,835,440

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 110835440...
Checkpoint 110835440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.84086
Policy Entropy: 1.21792
Value Function Loss: 5.10973

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.07411
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.04467

Collected Steps per Second: 10,289.61840
Overall Steps per Second: 8,757.45049

Timestep Collection Time: 4.86121
Timestep Consumption Time: 0.85050
PPO Batch Consumption Time: 0.04831
Total Iteration Time: 5.71171

Cumulative Model Updates: 6,644
Cumulative Timesteps: 110,885,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.02928
Policy Entropy: 1.22516
Value Function Loss: 5.04715

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07062
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.05727

Collected Steps per Second: 10,406.30754
Overall Steps per Second: 8,911.56150

Timestep Collection Time: 4.80555
Timestep Consumption Time: 0.80604
PPO Batch Consumption Time: 0.03974
Total Iteration Time: 5.61159

Cumulative Model Updates: 6,647
Cumulative Timesteps: 110,935,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 110935468...
Checkpoint 110935468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.61240
Policy Entropy: 1.21939
Value Function Loss: 4.96979

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.06390

Collected Steps per Second: 11,011.15665
Overall Steps per Second: 9,422.07239

Timestep Collection Time: 4.54176
Timestep Consumption Time: 0.76599
PPO Batch Consumption Time: 0.04032
Total Iteration Time: 5.30775

Cumulative Model Updates: 6,650
Cumulative Timesteps: 110,985,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.97260
Policy Entropy: 1.21633
Value Function Loss: 4.83423

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07801
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.07792

Collected Steps per Second: 10,982.55491
Overall Steps per Second: 9,290.23348

Timestep Collection Time: 4.55504
Timestep Consumption Time: 0.82975
PPO Batch Consumption Time: 0.03896
Total Iteration Time: 5.38479

Cumulative Model Updates: 6,653
Cumulative Timesteps: 111,035,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 111035504...
Checkpoint 111035504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.41309
Policy Entropy: 1.22206
Value Function Loss: 4.87455

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.06513
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.06836

Collected Steps per Second: 10,876.43606
Overall Steps per Second: 9,146.10846

Timestep Collection Time: 4.59930
Timestep Consumption Time: 0.87013
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.46943

Cumulative Model Updates: 6,656
Cumulative Timesteps: 111,085,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.93987
Policy Entropy: 1.22340
Value Function Loss: 5.05257

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.06733

Collected Steps per Second: 10,891.94382
Overall Steps per Second: 9,391.61277

Timestep Collection Time: 4.59110
Timestep Consumption Time: 0.73344
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.32454

Cumulative Model Updates: 6,659
Cumulative Timesteps: 111,135,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 111135534...
Checkpoint 111135534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.99051
Policy Entropy: 1.21299
Value Function Loss: 5.12923

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.06327
Policy Update Magnitude: 0.06693
Value Function Update Magnitude: 0.07869

Collected Steps per Second: 10,404.00104
Overall Steps per Second: 8,756.99568

Timestep Collection Time: 4.80853
Timestep Consumption Time: 0.90438
PPO Batch Consumption Time: 0.03898
Total Iteration Time: 5.71292

Cumulative Model Updates: 6,662
Cumulative Timesteps: 111,185,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.10430
Policy Entropy: 1.21038
Value Function Loss: 5.16022

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.06934

Collected Steps per Second: 10,889.29804
Overall Steps per Second: 9,217.37258

Timestep Collection Time: 4.59387
Timestep Consumption Time: 0.83327
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 5.42714

Cumulative Model Updates: 6,665
Cumulative Timesteps: 111,235,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 111235586...
Checkpoint 111235586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.75802
Policy Entropy: 1.22140
Value Function Loss: 5.09133

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.06541
Value Function Update Magnitude: 0.07447

Collected Steps per Second: 10,978.96351
Overall Steps per Second: 9,273.88352

Timestep Collection Time: 4.55453
Timestep Consumption Time: 0.83739
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 5.39192

Cumulative Model Updates: 6,668
Cumulative Timesteps: 111,285,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.48276
Policy Entropy: 1.22136
Value Function Loss: 5.06310

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 10,766.99463
Overall Steps per Second: 9,146.20311

Timestep Collection Time: 4.64419
Timestep Consumption Time: 0.82299
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.46719

Cumulative Model Updates: 6,671
Cumulative Timesteps: 111,335,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 111335594...
Checkpoint 111335594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.09915
Policy Entropy: 1.20932
Value Function Loss: 5.05000

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.08544

Collected Steps per Second: 10,764.52254
Overall Steps per Second: 9,247.81801

Timestep Collection Time: 4.64712
Timestep Consumption Time: 0.76216
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 5.40928

Cumulative Model Updates: 6,674
Cumulative Timesteps: 111,385,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.20347
Policy Entropy: 1.22012
Value Function Loss: 5.00163

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.06385
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.08684

Collected Steps per Second: 10,719.61767
Overall Steps per Second: 9,022.10042

Timestep Collection Time: 4.66976
Timestep Consumption Time: 0.87862
PPO Batch Consumption Time: 0.04055
Total Iteration Time: 5.54838

Cumulative Model Updates: 6,677
Cumulative Timesteps: 111,435,676

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


Saving checkpoint 111435676...
Checkpoint 111435676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.21617
Policy Entropy: 1.22239
Value Function Loss: 4.89642

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.08536

Collected Steps per Second: 10,859.51196
Overall Steps per Second: 9,350.23880

Timestep Collection Time: 4.60536
Timestep Consumption Time: 0.74338
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 5.34874

Cumulative Model Updates: 6,680
Cumulative Timesteps: 111,485,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.13164
Policy Entropy: 1.21685
Value Function Loss: 4.91747

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06465
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.10282

Collected Steps per Second: 10,682.01625
Overall Steps per Second: 9,079.64698

Timestep Collection Time: 4.68095
Timestep Consumption Time: 0.82609
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.50704

Cumulative Model Updates: 6,683
Cumulative Timesteps: 111,535,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 111535690...
Checkpoint 111535690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.37383
Policy Entropy: 1.20847
Value Function Loss: 5.05655

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.09253

Collected Steps per Second: 10,659.41232
Overall Steps per Second: 9,001.48587

Timestep Collection Time: 4.69332
Timestep Consumption Time: 0.86443
PPO Batch Consumption Time: 0.04428
Total Iteration Time: 5.55775

Cumulative Model Updates: 6,686
Cumulative Timesteps: 111,585,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.11821
Policy Entropy: 1.21642
Value Function Loss: 5.15194

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05807
Policy Update Magnitude: 0.06270
Value Function Update Magnitude: 0.07217

Collected Steps per Second: 11,477.59490
Overall Steps per Second: 9,699.17908

Timestep Collection Time: 4.35910
Timestep Consumption Time: 0.79927
PPO Batch Consumption Time: 0.03864
Total Iteration Time: 5.15837

Cumulative Model Updates: 6,689
Cumulative Timesteps: 111,635,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 111635750...
Checkpoint 111635750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.82830
Policy Entropy: 1.22237
Value Function Loss: 5.08954

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.06381

Collected Steps per Second: 11,092.15993
Overall Steps per Second: 9,384.31617

Timestep Collection Time: 4.50913
Timestep Consumption Time: 0.82061
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 5.32974

Cumulative Model Updates: 6,692
Cumulative Timesteps: 111,685,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.40898
Policy Entropy: 1.21152
Value Function Loss: 4.95388

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06111
Policy Update Magnitude: 0.06693
Value Function Update Magnitude: 0.05332

Collected Steps per Second: 10,481.62345
Overall Steps per Second: 9,074.08207

Timestep Collection Time: 4.77197
Timestep Consumption Time: 0.74021
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 5.51218

Cumulative Model Updates: 6,695
Cumulative Timesteps: 111,735,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 111735784...
Checkpoint 111735784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.32239
Policy Entropy: 1.20832
Value Function Loss: 4.90429

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.06864
Value Function Update Magnitude: 0.05263

Collected Steps per Second: 10,742.82120
Overall Steps per Second: 9,027.84592

Timestep Collection Time: 4.65613
Timestep Consumption Time: 0.88450
PPO Batch Consumption Time: 0.04027
Total Iteration Time: 5.54064

Cumulative Model Updates: 6,698
Cumulative Timesteps: 111,785,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.99167
Policy Entropy: 1.22388
Value Function Loss: 4.95141

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06452
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.07298

Collected Steps per Second: 11,155.94263
Overall Steps per Second: 9,250.46806

Timestep Collection Time: 4.48192
Timestep Consumption Time: 0.92322
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 5.40513

Cumulative Model Updates: 6,701
Cumulative Timesteps: 111,835,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 111835804...
Checkpoint 111835804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.26963
Policy Entropy: 1.22260
Value Function Loss: 5.01405

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 11,392.79428
Overall Steps per Second: 9,475.78779

Timestep Collection Time: 4.38891
Timestep Consumption Time: 0.88790
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 5.27682

Cumulative Model Updates: 6,704
Cumulative Timesteps: 111,885,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.46317
Policy Entropy: 1.21325
Value Function Loss: 5.09897

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.06182
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.08020

Collected Steps per Second: 10,812.66080
Overall Steps per Second: 9,121.84339

Timestep Collection Time: 4.62587
Timestep Consumption Time: 0.85745
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 5.48332

Cumulative Model Updates: 6,707
Cumulative Timesteps: 111,935,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 111935824...
Checkpoint 111935824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.85192
Policy Entropy: 1.19710
Value Function Loss: 5.02570

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.05921

Collected Steps per Second: 10,491.79442
Overall Steps per Second: 8,909.05588

Timestep Collection Time: 4.76696
Timestep Consumption Time: 0.84687
PPO Batch Consumption Time: 0.04609
Total Iteration Time: 5.61384

Cumulative Model Updates: 6,710
Cumulative Timesteps: 111,985,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.76542
Policy Entropy: 1.22476
Value Function Loss: 4.92667

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.05735

Collected Steps per Second: 10,761.65563
Overall Steps per Second: 9,081.59455

Timestep Collection Time: 4.64631
Timestep Consumption Time: 0.85955
PPO Batch Consumption Time: 0.05327
Total Iteration Time: 5.50586

Cumulative Model Updates: 6,713
Cumulative Timesteps: 112,035,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 112035840...
Checkpoint 112035840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.76764
Policy Entropy: 1.20835
Value Function Loss: 4.78315

Mean KL Divergence: 0.02991
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.05169

Collected Steps per Second: 10,771.02984
Overall Steps per Second: 9,134.12677

Timestep Collection Time: 4.64487
Timestep Consumption Time: 0.83239
PPO Batch Consumption Time: 0.04195
Total Iteration Time: 5.47726

Cumulative Model Updates: 6,716
Cumulative Timesteps: 112,085,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.05352
Policy Entropy: 1.22213
Value Function Loss: 4.75808

Mean KL Divergence: 0.02717
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.06494

Collected Steps per Second: 10,965.13990
Overall Steps per Second: 9,200.11898

Timestep Collection Time: 4.56191
Timestep Consumption Time: 0.87519
PPO Batch Consumption Time: 0.04729
Total Iteration Time: 5.43710

Cumulative Model Updates: 6,719
Cumulative Timesteps: 112,135,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 112135892...
Checkpoint 112135892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.18487
Policy Entropy: 1.22014
Value Function Loss: 4.72220

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.08637

Collected Steps per Second: 10,747.94748
Overall Steps per Second: 9,108.19029

Timestep Collection Time: 4.65428
Timestep Consumption Time: 0.83792
PPO Batch Consumption Time: 0.04754
Total Iteration Time: 5.49220

Cumulative Model Updates: 6,722
Cumulative Timesteps: 112,185,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.84365
Policy Entropy: 1.22737
Value Function Loss: 4.85630

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.07524

Collected Steps per Second: 10,828.69146
Overall Steps per Second: 9,362.53269

Timestep Collection Time: 4.61958
Timestep Consumption Time: 0.72342
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 5.34300

Cumulative Model Updates: 6,725
Cumulative Timesteps: 112,235,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 112235940...
Checkpoint 112235940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.49892
Policy Entropy: 1.22916
Value Function Loss: 5.16056

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.06538
Value Function Update Magnitude: 0.07998

Collected Steps per Second: 10,361.69523
Overall Steps per Second: 8,842.22903

Timestep Collection Time: 4.82624
Timestep Consumption Time: 0.82935
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 5.65559

Cumulative Model Updates: 6,728
Cumulative Timesteps: 112,285,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.46286
Policy Entropy: 1.20390
Value Function Loss: 5.30290

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 10,720.57040
Overall Steps per Second: 9,148.05571

Timestep Collection Time: 4.66412
Timestep Consumption Time: 0.80174
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 5.46586

Cumulative Model Updates: 6,731
Cumulative Timesteps: 112,335,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 112335950...
Checkpoint 112335950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.75746
Policy Entropy: 1.20231
Value Function Loss: 5.38039

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.06518

Collected Steps per Second: 10,925.37551
Overall Steps per Second: 9,200.16743

Timestep Collection Time: 4.57943
Timestep Consumption Time: 0.85873
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 5.43816

Cumulative Model Updates: 6,734
Cumulative Timesteps: 112,385,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.79025
Policy Entropy: 1.22007
Value Function Loss: 5.13603

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.05922

Collected Steps per Second: 10,836.35218
Overall Steps per Second: 9,246.12789

Timestep Collection Time: 4.61428
Timestep Consumption Time: 0.79360
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 5.40789

Cumulative Model Updates: 6,737
Cumulative Timesteps: 112,435,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 112435984...
Checkpoint 112435984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.18887
Policy Entropy: 1.22821
Value Function Loss: 5.12921

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.04399
Value Function Update Magnitude: 0.05169

Collected Steps per Second: 10,696.95639
Overall Steps per Second: 9,242.76617

Timestep Collection Time: 4.67591
Timestep Consumption Time: 0.73567
PPO Batch Consumption Time: 0.03854
Total Iteration Time: 5.41158

Cumulative Model Updates: 6,740
Cumulative Timesteps: 112,486,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.05540
Policy Entropy: 1.21823
Value Function Loss: 5.00631

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06767
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.05455

Collected Steps per Second: 10,545.04640
Overall Steps per Second: 8,883.55372

Timestep Collection Time: 4.74270
Timestep Consumption Time: 0.88703
PPO Batch Consumption Time: 0.04748
Total Iteration Time: 5.62973

Cumulative Model Updates: 6,743
Cumulative Timesteps: 112,536,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 112536014...
Checkpoint 112536014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.92670
Policy Entropy: 1.20646
Value Function Loss: 5.16563

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.05195

Collected Steps per Second: 10,741.78194
Overall Steps per Second: 9,136.39077

Timestep Collection Time: 4.65621
Timestep Consumption Time: 0.81816
PPO Batch Consumption Time: 0.04159
Total Iteration Time: 5.47437

Cumulative Model Updates: 6,746
Cumulative Timesteps: 112,586,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.08559
Policy Entropy: 1.22090
Value Function Loss: 5.13933

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.05116

Collected Steps per Second: 11,113.24896
Overall Steps per Second: 9,458.09206

Timestep Collection Time: 4.49985
Timestep Consumption Time: 0.78747
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 5.28732

Cumulative Model Updates: 6,749
Cumulative Timesteps: 112,636,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 112636038...
Checkpoint 112636038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.40222
Policy Entropy: 1.20497
Value Function Loss: 5.16571

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.05808

Collected Steps per Second: 10,761.97114
Overall Steps per Second: 9,146.49177

Timestep Collection Time: 4.64766
Timestep Consumption Time: 0.82088
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.46854

Cumulative Model Updates: 6,752
Cumulative Timesteps: 112,686,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.00959
Policy Entropy: 1.22028
Value Function Loss: 5.05107

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 10,933.67101
Overall Steps per Second: 9,327.26247

Timestep Collection Time: 4.57394
Timestep Consumption Time: 0.78776
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.36170

Cumulative Model Updates: 6,755
Cumulative Timesteps: 112,736,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 112736066...
Checkpoint 112736066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.40211
Policy Entropy: 1.21368
Value Function Loss: 4.84059

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.08090
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.07040

Collected Steps per Second: 10,744.86264
Overall Steps per Second: 8,963.25999

Timestep Collection Time: 4.65488
Timestep Consumption Time: 0.92524
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 5.58011

Cumulative Model Updates: 6,758
Cumulative Timesteps: 112,786,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.97109
Policy Entropy: 1.20644
Value Function Loss: 4.80066

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.07211

Collected Steps per Second: 10,226.98513
Overall Steps per Second: 8,658.73309

Timestep Collection Time: 4.89040
Timestep Consumption Time: 0.88574
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.77613

Cumulative Model Updates: 6,761
Cumulative Timesteps: 112,836,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 112836096...
Checkpoint 112836096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.42916
Policy Entropy: 1.22643
Value Function Loss: 4.79141

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.06501
Value Function Update Magnitude: 0.06997

Collected Steps per Second: 10,884.13206
Overall Steps per Second: 9,260.32274

Timestep Collection Time: 4.59568
Timestep Consumption Time: 0.80586
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 5.40154

Cumulative Model Updates: 6,764
Cumulative Timesteps: 112,886,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.08888
Policy Entropy: 1.21234
Value Function Loss: 5.04986

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.07188

Collected Steps per Second: 11,026.79608
Overall Steps per Second: 9,362.57907

Timestep Collection Time: 4.53513
Timestep Consumption Time: 0.80613
PPO Batch Consumption Time: 0.04307
Total Iteration Time: 5.34126

Cumulative Model Updates: 6,767
Cumulative Timesteps: 112,936,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 112936124...
Checkpoint 112936124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.28550
Policy Entropy: 1.22089
Value Function Loss: 5.02341

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.07376

Collected Steps per Second: 10,888.26638
Overall Steps per Second: 9,343.03624

Timestep Collection Time: 4.59394
Timestep Consumption Time: 0.75978
PPO Batch Consumption Time: 0.04359
Total Iteration Time: 5.35372

Cumulative Model Updates: 6,770
Cumulative Timesteps: 112,986,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.84365
Policy Entropy: 1.21298
Value Function Loss: 5.13908

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.08040
Value Function Update Magnitude: 0.07254

Collected Steps per Second: 10,759.51682
Overall Steps per Second: 9,081.17844

Timestep Collection Time: 4.64835
Timestep Consumption Time: 0.85909
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 5.50743

Cumulative Model Updates: 6,773
Cumulative Timesteps: 113,036,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 113036158...
Checkpoint 113036158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.71300
Policy Entropy: 1.21443
Value Function Loss: 5.16011

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.08065
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 10,270.81980
Overall Steps per Second: 8,717.30221

Timestep Collection Time: 4.86836
Timestep Consumption Time: 0.86759
PPO Batch Consumption Time: 0.04779
Total Iteration Time: 5.73595

Cumulative Model Updates: 6,776
Cumulative Timesteps: 113,086,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.56102
Policy Entropy: 1.21400
Value Function Loss: 5.16922

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.07472
Value Function Update Magnitude: 0.06292

Collected Steps per Second: 10,909.87269
Overall Steps per Second: 9,224.64021

Timestep Collection Time: 4.58300
Timestep Consumption Time: 0.83726
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 5.42027

Cumulative Model Updates: 6,779
Cumulative Timesteps: 113,136,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 113136160...
Checkpoint 113136160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.85223
Policy Entropy: 1.21474
Value Function Loss: 5.11955

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.06724
Policy Update Magnitude: 0.07516
Value Function Update Magnitude: 0.07051

Collected Steps per Second: 10,788.99282
Overall Steps per Second: 9,151.58921

Timestep Collection Time: 4.63639
Timestep Consumption Time: 0.82954
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 5.46594

Cumulative Model Updates: 6,782
Cumulative Timesteps: 113,186,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.49716
Policy Entropy: 1.21771
Value Function Loss: 5.03588

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06061
Policy Update Magnitude: 0.08004
Value Function Update Magnitude: 0.12883

Collected Steps per Second: 10,787.66964
Overall Steps per Second: 9,260.69552

Timestep Collection Time: 4.63603
Timestep Consumption Time: 0.76442
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 5.40046

Cumulative Model Updates: 6,785
Cumulative Timesteps: 113,236,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 113236194...
Checkpoint 113236194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.08223
Policy Entropy: 1.22252
Value Function Loss: 5.15901

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05697
Policy Update Magnitude: 0.09642
Value Function Update Magnitude: 0.13202

Collected Steps per Second: 10,872.42279
Overall Steps per Second: 9,139.60994

Timestep Collection Time: 4.59953
Timestep Consumption Time: 0.87204
PPO Batch Consumption Time: 0.04023
Total Iteration Time: 5.47157

Cumulative Model Updates: 6,788
Cumulative Timesteps: 113,286,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.56671
Policy Entropy: 1.22747
Value Function Loss: 5.06686

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.05503
Policy Update Magnitude: 0.09846
Value Function Update Magnitude: 0.12571

Collected Steps per Second: 10,762.21974
Overall Steps per Second: 9,064.57665

Timestep Collection Time: 4.64681
Timestep Consumption Time: 0.87027
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 5.51708

Cumulative Model Updates: 6,791
Cumulative Timesteps: 113,336,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 113336212...
Checkpoint 113336212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.56464
Policy Entropy: 1.22770
Value Function Loss: 5.16662

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.05756
Policy Update Magnitude: 0.08568
Value Function Update Magnitude: 0.10434

Collected Steps per Second: 10,485.23637
Overall Steps per Second: 8,950.88944

Timestep Collection Time: 4.77071
Timestep Consumption Time: 0.81779
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.58849

Cumulative Model Updates: 6,794
Cumulative Timesteps: 113,386,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.69898
Policy Entropy: 1.22207
Value Function Loss: 5.09269

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05018
Policy Update Magnitude: 0.08838
Value Function Update Magnitude: 0.09534

Collected Steps per Second: 10,959.24590
Overall Steps per Second: 9,314.21472

Timestep Collection Time: 4.56254
Timestep Consumption Time: 0.80581
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.36835

Cumulative Model Updates: 6,797
Cumulative Timesteps: 113,436,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 113436236...
Checkpoint 113436236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.41277
Policy Entropy: 1.21616
Value Function Loss: 5.17665

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.04738
Policy Update Magnitude: 0.08299
Value Function Update Magnitude: 0.08604

Collected Steps per Second: 10,632.00293
Overall Steps per Second: 9,246.40232

Timestep Collection Time: 4.70523
Timestep Consumption Time: 0.70509
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 5.41032

Cumulative Model Updates: 6,800
Cumulative Timesteps: 113,486,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.13412
Policy Entropy: 1.21696
Value Function Loss: 5.10675

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05562
Policy Update Magnitude: 0.08779
Value Function Update Magnitude: 0.07967

Collected Steps per Second: 10,723.89531
Overall Steps per Second: 8,955.78084

Timestep Collection Time: 4.66435
Timestep Consumption Time: 0.92087
PPO Batch Consumption Time: 0.04263
Total Iteration Time: 5.58522

Cumulative Model Updates: 6,803
Cumulative Timesteps: 113,536,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 113536282...
Checkpoint 113536282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.16216
Policy Entropy: 1.21403
Value Function Loss: 4.97197

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.08462
Value Function Update Magnitude: 0.08601

Collected Steps per Second: 10,919.98159
Overall Steps per Second: 9,191.94448

Timestep Collection Time: 4.57949
Timestep Consumption Time: 0.86092
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 5.44042

Cumulative Model Updates: 6,806
Cumulative Timesteps: 113,586,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.94843
Policy Entropy: 1.22893
Value Function Loss: 5.10370

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06181
Policy Update Magnitude: 0.06873
Value Function Update Magnitude: 0.07898

Collected Steps per Second: 10,599.18621
Overall Steps per Second: 8,975.85882

Timestep Collection Time: 4.72017
Timestep Consumption Time: 0.85367
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 5.57384

Cumulative Model Updates: 6,809
Cumulative Timesteps: 113,636,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 113636320...
Checkpoint 113636320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.03587
Policy Entropy: 1.23250
Value Function Loss: 4.94409

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.09145

Collected Steps per Second: 10,797.83033
Overall Steps per Second: 9,092.50244

Timestep Collection Time: 4.63149
Timestep Consumption Time: 0.86865
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 5.50014

Cumulative Model Updates: 6,812
Cumulative Timesteps: 113,686,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.31898
Policy Entropy: 1.21958
Value Function Loss: 4.96989

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06490
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.08122

Collected Steps per Second: 10,874.30892
Overall Steps per Second: 9,295.30266

Timestep Collection Time: 4.59946
Timestep Consumption Time: 0.78132
PPO Batch Consumption Time: 0.04712
Total Iteration Time: 5.38078

Cumulative Model Updates: 6,815
Cumulative Timesteps: 113,736,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 113736346...
Checkpoint 113736346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.10879
Policy Entropy: 1.21299
Value Function Loss: 4.90161

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.06347

Collected Steps per Second: 10,773.71971
Overall Steps per Second: 9,048.44342

Timestep Collection Time: 4.64259
Timestep Consumption Time: 0.88521
PPO Batch Consumption Time: 0.04044
Total Iteration Time: 5.52780

Cumulative Model Updates: 6,818
Cumulative Timesteps: 113,786,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.01061
Policy Entropy: 1.22757
Value Function Loss: 4.95608

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06531
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.05144

Collected Steps per Second: 11,497.60634
Overall Steps per Second: 9,649.22309

Timestep Collection Time: 4.34891
Timestep Consumption Time: 0.83307
PPO Batch Consumption Time: 0.04160
Total Iteration Time: 5.18197

Cumulative Model Updates: 6,821
Cumulative Timesteps: 113,836,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 113836366...
Checkpoint 113836366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.43714
Policy Entropy: 1.21956
Value Function Loss: 5.06711

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.06601
Value Function Update Magnitude: 0.04636

Collected Steps per Second: 11,372.88924
Overall Steps per Second: 9,484.80340

Timestep Collection Time: 4.39765
Timestep Consumption Time: 0.87542
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.27307

Cumulative Model Updates: 6,824
Cumulative Timesteps: 113,886,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.38881
Policy Entropy: 1.21517
Value Function Loss: 4.91960

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.04791

Collected Steps per Second: 10,480.63918
Overall Steps per Second: 8,849.79216

Timestep Collection Time: 4.77070
Timestep Consumption Time: 0.87915
PPO Batch Consumption Time: 0.03827
Total Iteration Time: 5.64985

Cumulative Model Updates: 6,827
Cumulative Timesteps: 113,936,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 113936380...
Checkpoint 113936380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.53716
Policy Entropy: 1.22103
Value Function Loss: 4.85811

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.04285

Collected Steps per Second: 11,318.40165
Overall Steps per Second: 9,653.56589

Timestep Collection Time: 4.41865
Timestep Consumption Time: 0.76203
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 5.18068

Cumulative Model Updates: 6,830
Cumulative Timesteps: 113,986,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.85575
Policy Entropy: 1.22289
Value Function Loss: 4.69549

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.05190

Collected Steps per Second: 11,251.48458
Overall Steps per Second: 9,429.89574

Timestep Collection Time: 4.44510
Timestep Consumption Time: 0.85867
PPO Batch Consumption Time: 0.03801
Total Iteration Time: 5.30377

Cumulative Model Updates: 6,833
Cumulative Timesteps: 114,036,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 114036406...
Checkpoint 114036406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.39526
Policy Entropy: 1.22190
Value Function Loss: 4.74309

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.04843

Collected Steps per Second: 10,729.85611
Overall Steps per Second: 9,191.24640

Timestep Collection Time: 4.66139
Timestep Consumption Time: 0.78031
PPO Batch Consumption Time: 0.04056
Total Iteration Time: 5.44170

Cumulative Model Updates: 6,836
Cumulative Timesteps: 114,086,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.17401
Policy Entropy: 1.21845
Value Function Loss: 4.67666

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08195
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.04143

Collected Steps per Second: 10,967.68179
Overall Steps per Second: 9,313.75747

Timestep Collection Time: 4.55976
Timestep Consumption Time: 0.80972
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 5.36948

Cumulative Model Updates: 6,839
Cumulative Timesteps: 114,136,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 114136432...
Checkpoint 114136432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.48451
Policy Entropy: 1.21729
Value Function Loss: 4.76055

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.04668

Collected Steps per Second: 10,306.14131
Overall Steps per Second: 8,828.10997

Timestep Collection Time: 4.85322
Timestep Consumption Time: 0.81254
PPO Batch Consumption Time: 0.04626
Total Iteration Time: 5.66577

Cumulative Model Updates: 6,842
Cumulative Timesteps: 114,186,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.51223
Policy Entropy: 1.22511
Value Function Loss: 4.93371

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.03942

Collected Steps per Second: 10,919.62865
Overall Steps per Second: 9,464.10620

Timestep Collection Time: 4.58056
Timestep Consumption Time: 0.70446
PPO Batch Consumption Time: 0.04056
Total Iteration Time: 5.28502

Cumulative Model Updates: 6,845
Cumulative Timesteps: 114,236,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 114236468...
Checkpoint 114236468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.98629
Policy Entropy: 1.21870
Value Function Loss: 5.10933

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.04577

Collected Steps per Second: 10,827.06207
Overall Steps per Second: 9,244.55135

Timestep Collection Time: 4.62101
Timestep Consumption Time: 0.79104
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 5.41205

Cumulative Model Updates: 6,848
Cumulative Timesteps: 114,286,500

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.29182
Policy Entropy: 1.22993
Value Function Loss: 5.28712

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.04675

Collected Steps per Second: 10,681.35133
Overall Steps per Second: 9,132.06333

Timestep Collection Time: 4.68349
Timestep Consumption Time: 0.79457
PPO Batch Consumption Time: 0.04828
Total Iteration Time: 5.47806

Cumulative Model Updates: 6,851
Cumulative Timesteps: 114,336,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 114336526...
Checkpoint 114336526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.42182
Policy Entropy: 1.22840
Value Function Loss: 4.88338

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06486
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.04396

Collected Steps per Second: 10,903.22623
Overall Steps per Second: 9,259.27469

Timestep Collection Time: 4.58672
Timestep Consumption Time: 0.81436
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 5.40107

Cumulative Model Updates: 6,854
Cumulative Timesteps: 114,386,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.14684
Policy Entropy: 1.21285
Value Function Loss: 4.87957

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.06815

Collected Steps per Second: 10,764.85152
Overall Steps per Second: 9,091.97424

Timestep Collection Time: 4.64660
Timestep Consumption Time: 0.85495
PPO Batch Consumption Time: 0.04559
Total Iteration Time: 5.50156

Cumulative Model Updates: 6,857
Cumulative Timesteps: 114,436,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 114436556...
Checkpoint 114436556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.70568
Policy Entropy: 1.21058
Value Function Loss: 4.80701

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.04423
Value Function Update Magnitude: 0.06397

Collected Steps per Second: 10,478.44051
Overall Steps per Second: 9,118.97845

Timestep Collection Time: 4.77247
Timestep Consumption Time: 0.71148
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 5.48395

Cumulative Model Updates: 6,860
Cumulative Timesteps: 114,486,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.21497
Policy Entropy: 1.20866
Value Function Loss: 4.98079

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.06241

Collected Steps per Second: 10,247.10797
Overall Steps per Second: 8,663.18580

Timestep Collection Time: 4.88118
Timestep Consumption Time: 0.89244
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 5.77363

Cumulative Model Updates: 6,863
Cumulative Timesteps: 114,536,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 114536582...
Checkpoint 114536582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.23703
Policy Entropy: 1.21377
Value Function Loss: 4.88408

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.04276
Value Function Update Magnitude: 0.05406

Collected Steps per Second: 10,824.95038
Overall Steps per Second: 9,323.15689

Timestep Collection Time: 4.62081
Timestep Consumption Time: 0.74433
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 5.36514

Cumulative Model Updates: 6,866
Cumulative Timesteps: 114,586,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.76703
Policy Entropy: 1.21303
Value Function Loss: 4.93310

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07156
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.05821

Collected Steps per Second: 10,661.29052
Overall Steps per Second: 9,068.27877

Timestep Collection Time: 4.69174
Timestep Consumption Time: 0.82419
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 5.51593

Cumulative Model Updates: 6,869
Cumulative Timesteps: 114,636,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 114636622...
Checkpoint 114636622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.89203
Policy Entropy: 1.21057
Value Function Loss: 5.16917

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.05041

Collected Steps per Second: 10,751.62452
Overall Steps per Second: 9,167.42804

Timestep Collection Time: 4.65325
Timestep Consumption Time: 0.80411
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 5.45736

Cumulative Model Updates: 6,872
Cumulative Timesteps: 114,686,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.36970
Policy Entropy: 1.21188
Value Function Loss: 5.17285

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.04726
Policy Update Magnitude: 0.06518
Value Function Update Magnitude: 0.04490

Collected Steps per Second: 10,401.08749
Overall Steps per Second: 8,825.96711

Timestep Collection Time: 4.80930
Timestep Consumption Time: 0.85829
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 5.66759

Cumulative Model Updates: 6,875
Cumulative Timesteps: 114,736,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 114736674...
Checkpoint 114736674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.87730
Policy Entropy: 1.21889
Value Function Loss: 5.47388

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.06820
Value Function Update Magnitude: 0.05755

Collected Steps per Second: 10,628.90508
Overall Steps per Second: 9,057.46188

Timestep Collection Time: 4.70585
Timestep Consumption Time: 0.81645
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 5.52230

Cumulative Model Updates: 6,878
Cumulative Timesteps: 114,786,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.93004
Policy Entropy: 1.19803
Value Function Loss: 5.42533

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.06456
Value Function Update Magnitude: 0.05085

Collected Steps per Second: 10,671.66095
Overall Steps per Second: 9,272.75313

Timestep Collection Time: 4.68568
Timestep Consumption Time: 0.70689
PPO Batch Consumption Time: 0.03941
Total Iteration Time: 5.39257

Cumulative Model Updates: 6,881
Cumulative Timesteps: 114,836,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 114836696...
Checkpoint 114836696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.31404
Policy Entropy: 1.21379
Value Function Loss: 5.48395

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.04733

Collected Steps per Second: 10,797.16694
Overall Steps per Second: 9,074.67799

Timestep Collection Time: 4.63307
Timestep Consumption Time: 0.87941
PPO Batch Consumption Time: 0.04633
Total Iteration Time: 5.51248

Cumulative Model Updates: 6,884
Cumulative Timesteps: 114,886,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.50529
Policy Entropy: 1.20370
Value Function Loss: 5.28607

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.05679

Collected Steps per Second: 10,912.04463
Overall Steps per Second: 9,272.46670

Timestep Collection Time: 4.58429
Timestep Consumption Time: 0.81060
PPO Batch Consumption Time: 0.04039
Total Iteration Time: 5.39490

Cumulative Model Updates: 6,887
Cumulative Timesteps: 114,936,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 114936744...
Checkpoint 114936744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.50732
Policy Entropy: 1.20867
Value Function Loss: 5.21763

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.06818
Value Function Update Magnitude: 0.05365

Collected Steps per Second: 11,055.01155
Overall Steps per Second: 9,315.75247

Timestep Collection Time: 4.52392
Timestep Consumption Time: 0.84462
PPO Batch Consumption Time: 0.04603
Total Iteration Time: 5.36854

Cumulative Model Updates: 6,890
Cumulative Timesteps: 114,986,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.21072
Policy Entropy: 1.23013
Value Function Loss: 5.00564

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.04897

Collected Steps per Second: 10,362.87631
Overall Steps per Second: 8,861.84943

Timestep Collection Time: 4.82800
Timestep Consumption Time: 0.81777
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 5.64577

Cumulative Model Updates: 6,893
Cumulative Timesteps: 115,036,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 115036788...
Checkpoint 115036788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.07482
Policy Entropy: 1.23483
Value Function Loss: 5.02390

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.08752

Collected Steps per Second: 10,811.35993
Overall Steps per Second: 9,388.51505

Timestep Collection Time: 4.62661
Timestep Consumption Time: 0.70117
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 5.32779

Cumulative Model Updates: 6,896
Cumulative Timesteps: 115,086,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.99281
Policy Entropy: 1.22571
Value Function Loss: 4.88312

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.09959

Collected Steps per Second: 11,078.78513
Overall Steps per Second: 9,401.76421

Timestep Collection Time: 4.51439
Timestep Consumption Time: 0.80525
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.31964

Cumulative Model Updates: 6,899
Cumulative Timesteps: 115,136,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 115136822...
Checkpoint 115136822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.23909
Policy Entropy: 1.21695
Value Function Loss: 5.02747

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.04352
Value Function Update Magnitude: 0.07887

Collected Steps per Second: 10,745.75081
Overall Steps per Second: 9,156.70231

Timestep Collection Time: 4.65579
Timestep Consumption Time: 0.80796
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 5.46376

Cumulative Model Updates: 6,902
Cumulative Timesteps: 115,186,852

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.86600
Policy Entropy: 1.21356
Value Function Loss: 5.03594

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.06399

Collected Steps per Second: 11,113.80799
Overall Steps per Second: 9,423.49189

Timestep Collection Time: 4.49945
Timestep Consumption Time: 0.80708
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.30653

Cumulative Model Updates: 6,905
Cumulative Timesteps: 115,236,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 115236858...
Checkpoint 115236858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.91566
Policy Entropy: 1.21712
Value Function Loss: 4.86534

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.06979

Collected Steps per Second: 9,982.25302
Overall Steps per Second: 8,485.08533

Timestep Collection Time: 5.01009
Timestep Consumption Time: 0.88402
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 5.89411

Cumulative Model Updates: 6,908
Cumulative Timesteps: 115,286,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.46729
Policy Entropy: 1.21839
Value Function Loss: 4.96525

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.06788

Collected Steps per Second: 10,808.67670
Overall Steps per Second: 9,332.40482

Timestep Collection Time: 4.62702
Timestep Consumption Time: 0.73194
PPO Batch Consumption Time: 0.04415
Total Iteration Time: 5.35896

Cumulative Model Updates: 6,911
Cumulative Timesteps: 115,336,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 115336882...
Checkpoint 115336882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.27276
Policy Entropy: 1.21892
Value Function Loss: 4.85761

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.05484

Collected Steps per Second: 10,853.27206
Overall Steps per Second: 9,159.40293

Timestep Collection Time: 4.60856
Timestep Consumption Time: 0.85227
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 5.46084

Cumulative Model Updates: 6,914
Cumulative Timesteps: 115,386,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.71530
Policy Entropy: 1.23496
Value Function Loss: 5.19009

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 10,607.70039
Overall Steps per Second: 9,183.47549

Timestep Collection Time: 4.71375
Timestep Consumption Time: 0.73103
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 5.44478

Cumulative Model Updates: 6,917
Cumulative Timesteps: 115,436,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 115436902...
Checkpoint 115436902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.80179
Policy Entropy: 1.20861
Value Function Loss: 5.02933

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.07907

Collected Steps per Second: 10,818.40423
Overall Steps per Second: 9,161.67319

Timestep Collection Time: 4.62249
Timestep Consumption Time: 0.83590
PPO Batch Consumption Time: 0.03922
Total Iteration Time: 5.45839

Cumulative Model Updates: 6,920
Cumulative Timesteps: 115,486,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.00983
Policy Entropy: 1.22496
Value Function Loss: 5.05304

Mean KL Divergence: 0.02597
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.06976

Collected Steps per Second: 10,893.98456
Overall Steps per Second: 9,136.94334

Timestep Collection Time: 4.58969
Timestep Consumption Time: 0.88260
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 5.47229

Cumulative Model Updates: 6,923
Cumulative Timesteps: 115,536,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 115536910...
Checkpoint 115536910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.68590
Policy Entropy: 1.22101
Value Function Loss: 5.03414

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.05696

Collected Steps per Second: 10,396.56503
Overall Steps per Second: 8,956.89113

Timestep Collection Time: 4.81024
Timestep Consumption Time: 0.77317
PPO Batch Consumption Time: 0.04475
Total Iteration Time: 5.58341

Cumulative Model Updates: 6,926
Cumulative Timesteps: 115,586,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.29534
Policy Entropy: 1.23191
Value Function Loss: 4.90904

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.06934

Collected Steps per Second: 10,661.31234
Overall Steps per Second: 8,988.84917

Timestep Collection Time: 4.69173
Timestep Consumption Time: 0.87294
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 5.56467

Cumulative Model Updates: 6,929
Cumulative Timesteps: 115,636,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 115636940...
Checkpoint 115636940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.01483
Policy Entropy: 1.21898
Value Function Loss: 5.06011

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.06263
Value Function Update Magnitude: 0.07363

Collected Steps per Second: 10,956.97054
Overall Steps per Second: 9,428.60266

Timestep Collection Time: 4.56477
Timestep Consumption Time: 0.73994
PPO Batch Consumption Time: 0.04018
Total Iteration Time: 5.30471

Cumulative Model Updates: 6,932
Cumulative Timesteps: 115,686,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.51519
Policy Entropy: 1.22302
Value Function Loss: 5.22262

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.07003

Collected Steps per Second: 10,708.07625
Overall Steps per Second: 9,017.47357

Timestep Collection Time: 4.66937
Timestep Consumption Time: 0.87542
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 5.54479

Cumulative Model Updates: 6,935
Cumulative Timesteps: 115,736,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 115736956...
Checkpoint 115736956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.77240
Policy Entropy: 1.23325
Value Function Loss: 5.20168

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.06005
Value Function Update Magnitude: 0.08090

Collected Steps per Second: 10,926.49432
Overall Steps per Second: 9,214.76234

Timestep Collection Time: 4.57768
Timestep Consumption Time: 0.85035
PPO Batch Consumption Time: 0.04165
Total Iteration Time: 5.42803

Cumulative Model Updates: 6,938
Cumulative Timesteps: 115,786,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.03239
Policy Entropy: 1.22080
Value Function Loss: 5.13099

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.06468
Policy Update Magnitude: 0.05982
Value Function Update Magnitude: 0.10029

Collected Steps per Second: 10,420.06507
Overall Steps per Second: 8,873.03907

Timestep Collection Time: 4.80035
Timestep Consumption Time: 0.83695
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 5.63730

Cumulative Model Updates: 6,941
Cumulative Timesteps: 115,836,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 115836994...
Checkpoint 115836994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.16744
Policy Entropy: 1.23153
Value Function Loss: 5.14497

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.09121

Collected Steps per Second: 11,045.50870
Overall Steps per Second: 9,272.60219

Timestep Collection Time: 4.52836
Timestep Consumption Time: 0.86581
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.39417

Cumulative Model Updates: 6,944
Cumulative Timesteps: 115,887,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.16195
Policy Entropy: 1.22834
Value Function Loss: 5.11666

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.07386

Collected Steps per Second: 10,831.71172
Overall Steps per Second: 9,218.45967

Timestep Collection Time: 4.61829
Timestep Consumption Time: 0.80821
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 5.42650

Cumulative Model Updates: 6,947
Cumulative Timesteps: 115,937,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 115937036...
Checkpoint 115937036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.65549
Policy Entropy: 1.22843
Value Function Loss: 5.01140

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.06644
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 10,929.49820
Overall Steps per Second: 9,175.97567

Timestep Collection Time: 4.57770
Timestep Consumption Time: 0.87480
PPO Batch Consumption Time: 0.05225
Total Iteration Time: 5.45250

Cumulative Model Updates: 6,950
Cumulative Timesteps: 115,987,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.05661
Policy Entropy: 1.22373
Value Function Loss: 4.83980

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.08407

Collected Steps per Second: 11,063.12798
Overall Steps per Second: 9,490.04733

Timestep Collection Time: 4.52096
Timestep Consumption Time: 0.74940
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 5.27036

Cumulative Model Updates: 6,953
Cumulative Timesteps: 116,037,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 116037084...
Checkpoint 116037084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.38698
Policy Entropy: 1.22042
Value Function Loss: 4.94470

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.05573
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.09000

Collected Steps per Second: 11,064.12513
Overall Steps per Second: 9,240.02946

Timestep Collection Time: 4.52182
Timestep Consumption Time: 0.89266
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 5.41448

Cumulative Model Updates: 6,956
Cumulative Timesteps: 116,087,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.59097
Policy Entropy: 1.22241
Value Function Loss: 4.79917

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.05985
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.09365

Collected Steps per Second: 10,738.38990
Overall Steps per Second: 9,145.25576

Timestep Collection Time: 4.65768
Timestep Consumption Time: 0.81138
PPO Batch Consumption Time: 0.04782
Total Iteration Time: 5.46907

Cumulative Model Updates: 6,959
Cumulative Timesteps: 116,137,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 116137130...
Checkpoint 116137130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.06209
Policy Entropy: 1.21735
Value Function Loss: 4.89822

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05129
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.07831

Collected Steps per Second: 11,449.87983
Overall Steps per Second: 9,632.70340

Timestep Collection Time: 4.36860
Timestep Consumption Time: 0.82412
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 5.19273

Cumulative Model Updates: 6,962
Cumulative Timesteps: 116,187,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.79865
Policy Entropy: 1.22416
Value Function Loss: 4.88319

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07118
Policy Update Magnitude: 0.06545
Value Function Update Magnitude: 0.07939

Collected Steps per Second: 11,022.54256
Overall Steps per Second: 9,256.98801

Timestep Collection Time: 4.53815
Timestep Consumption Time: 0.86555
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 5.40370

Cumulative Model Updates: 6,965
Cumulative Timesteps: 116,237,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 116237172...
Checkpoint 116237172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.27982
Policy Entropy: 1.22765
Value Function Loss: 4.99505

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06586
Policy Update Magnitude: 0.06459
Value Function Update Magnitude: 0.08060

Collected Steps per Second: 10,662.86185
Overall Steps per Second: 9,163.01463

Timestep Collection Time: 4.68936
Timestep Consumption Time: 0.76758
PPO Batch Consumption Time: 0.04105
Total Iteration Time: 5.45694

Cumulative Model Updates: 6,968
Cumulative Timesteps: 116,287,174

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.71066
Policy Entropy: 1.22790
Value Function Loss: 4.72639

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.07883

Collected Steps per Second: 10,849.65410
Overall Steps per Second: 9,221.20925

Timestep Collection Time: 4.60918
Timestep Consumption Time: 0.81397
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 5.42315

Cumulative Model Updates: 6,971
Cumulative Timesteps: 116,337,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 116337182...
Checkpoint 116337182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.70238
Policy Entropy: 1.23577
Value Function Loss: 4.72901

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.06097
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.08115

Collected Steps per Second: 10,131.17926
Overall Steps per Second: 8,665.35497

Timestep Collection Time: 4.93664
Timestep Consumption Time: 0.83508
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 5.77172

Cumulative Model Updates: 6,974
Cumulative Timesteps: 116,387,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.34562
Policy Entropy: 1.23328
Value Function Loss: 4.74279

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04096
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.06982

Collected Steps per Second: 10,885.41248
Overall Steps per Second: 9,215.80292

Timestep Collection Time: 4.59385
Timestep Consumption Time: 0.83226
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 5.42611

Cumulative Model Updates: 6,977
Cumulative Timesteps: 116,437,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 116437202...
Checkpoint 116437202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.91274
Policy Entropy: 1.22852
Value Function Loss: 4.89983

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.04794
Policy Update Magnitude: 0.07192
Value Function Update Magnitude: 0.06957

Collected Steps per Second: 10,603.29099
Overall Steps per Second: 9,027.58012

Timestep Collection Time: 4.71552
Timestep Consumption Time: 0.82307
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 5.53858

Cumulative Model Updates: 6,980
Cumulative Timesteps: 116,487,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.89766
Policy Entropy: 1.21880
Value Function Loss: 4.78701

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.07946
Policy Update Magnitude: 0.07622
Value Function Update Magnitude: 0.07206

Collected Steps per Second: 10,606.38174
Overall Steps per Second: 9,215.10150

Timestep Collection Time: 4.71678
Timestep Consumption Time: 0.71213
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 5.42891

Cumulative Model Updates: 6,983
Cumulative Timesteps: 116,537,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 116537230...
Checkpoint 116537230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.13280
Policy Entropy: 1.22861
Value Function Loss: 4.89713

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.05865
Policy Update Magnitude: 0.06548
Value Function Update Magnitude: 0.07633

Collected Steps per Second: 10,915.37896
Overall Steps per Second: 9,253.86922

Timestep Collection Time: 4.58069
Timestep Consumption Time: 0.82245
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 5.40315

Cumulative Model Updates: 6,986
Cumulative Timesteps: 116,587,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.16849
Policy Entropy: 1.23757
Value Function Loss: 5.02102

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.07589

Collected Steps per Second: 10,880.11190
Overall Steps per Second: 9,287.07235

Timestep Collection Time: 4.59664
Timestep Consumption Time: 0.78848
PPO Batch Consumption Time: 0.04002
Total Iteration Time: 5.38512

Cumulative Model Updates: 6,989
Cumulative Timesteps: 116,637,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 116637242...
Checkpoint 116637242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.88254
Policy Entropy: 1.22135
Value Function Loss: 5.06428

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.07621

Collected Steps per Second: 10,469.56111
Overall Steps per Second: 8,959.58647

Timestep Collection Time: 4.77651
Timestep Consumption Time: 0.80499
PPO Batch Consumption Time: 0.03849
Total Iteration Time: 5.58151

Cumulative Model Updates: 6,992
Cumulative Timesteps: 116,687,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.58398
Policy Entropy: 1.23104
Value Function Loss: 5.11027

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.07342

Collected Steps per Second: 10,638.10330
Overall Steps per Second: 9,089.81198

Timestep Collection Time: 4.70197
Timestep Consumption Time: 0.80090
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 5.50286

Cumulative Model Updates: 6,995
Cumulative Timesteps: 116,737,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 116737270...
Checkpoint 116737270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.68133
Policy Entropy: 1.21897
Value Function Loss: 5.11245

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.07019

Collected Steps per Second: 10,926.35730
Overall Steps per Second: 9,252.05454

Timestep Collection Time: 4.57646
Timestep Consumption Time: 0.82818
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.40464

Cumulative Model Updates: 6,998
Cumulative Timesteps: 116,787,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.25676
Policy Entropy: 1.22589
Value Function Loss: 5.06509

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.07355
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.06936

Collected Steps per Second: 10,697.76416
Overall Steps per Second: 8,963.54699

Timestep Collection Time: 4.67443
Timestep Consumption Time: 0.90438
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 5.57882

Cumulative Model Updates: 7,001
Cumulative Timesteps: 116,837,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 116837280...
Checkpoint 116837280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.37663
Policy Entropy: 1.23436
Value Function Loss: 4.90367

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.06769
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.08690

Collected Steps per Second: 10,905.77683
Overall Steps per Second: 9,270.69741

Timestep Collection Time: 4.58693
Timestep Consumption Time: 0.80900
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 5.39593

Cumulative Model Updates: 7,004
Cumulative Timesteps: 116,887,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.44638
Policy Entropy: 1.23644
Value Function Loss: 4.81481

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.09070

Collected Steps per Second: 10,374.61393
Overall Steps per Second: 8,868.12884

Timestep Collection Time: 4.82254
Timestep Consumption Time: 0.81924
PPO Batch Consumption Time: 0.04161
Total Iteration Time: 5.64178

Cumulative Model Updates: 7,007
Cumulative Timesteps: 116,937,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 116937336...
Checkpoint 116937336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.17747
Policy Entropy: 1.22726
Value Function Loss: 4.94293

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.07393
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.07119

Collected Steps per Second: 10,594.79946
Overall Steps per Second: 9,130.95797

Timestep Collection Time: 4.71930
Timestep Consumption Time: 0.75658
PPO Batch Consumption Time: 0.04478
Total Iteration Time: 5.47588

Cumulative Model Updates: 7,010
Cumulative Timesteps: 116,987,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.82735
Policy Entropy: 1.22320
Value Function Loss: 4.93550

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.05544

Collected Steps per Second: 10,750.55673
Overall Steps per Second: 9,126.24774

Timestep Collection Time: 4.65129
Timestep Consumption Time: 0.82785
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 5.47914

Cumulative Model Updates: 7,013
Cumulative Timesteps: 117,037,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 117037340...
Checkpoint 117037340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.64090
Policy Entropy: 1.23237
Value Function Loss: 4.74201

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06547
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.04696

Collected Steps per Second: 10,821.65326
Overall Steps per Second: 9,265.24317

Timestep Collection Time: 4.62147
Timestep Consumption Time: 0.77633
PPO Batch Consumption Time: 0.03911
Total Iteration Time: 5.39781

Cumulative Model Updates: 7,016
Cumulative Timesteps: 117,087,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.55886
Policy Entropy: 1.23158
Value Function Loss: 4.83427

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06297
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.05253

Collected Steps per Second: 11,013.79609
Overall Steps per Second: 9,312.36697

Timestep Collection Time: 4.54212
Timestep Consumption Time: 0.82987
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 5.37200

Cumulative Model Updates: 7,019
Cumulative Timesteps: 117,137,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 117137378...
Checkpoint 117137378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.98956
Policy Entropy: 1.22521
Value Function Loss: 5.09822

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06027
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.04994

Collected Steps per Second: 10,867.51092
Overall Steps per Second: 9,023.34728

Timestep Collection Time: 4.60381
Timestep Consumption Time: 0.94091
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 5.54473

Cumulative Model Updates: 7,022
Cumulative Timesteps: 117,187,410

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.95025
Policy Entropy: 1.20976
Value Function Loss: 5.19852

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07285
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.04390

Collected Steps per Second: 10,650.19344
Overall Steps per Second: 9,109.99410

Timestep Collection Time: 4.69494
Timestep Consumption Time: 0.79376
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 5.48870

Cumulative Model Updates: 7,025
Cumulative Timesteps: 117,237,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 117237412...
Checkpoint 117237412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.68369
Policy Entropy: 1.21950
Value Function Loss: 5.30795

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.04693

Collected Steps per Second: 10,711.19140
Overall Steps per Second: 9,127.72519

Timestep Collection Time: 4.66801
Timestep Consumption Time: 0.80980
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 5.47782

Cumulative Model Updates: 7,028
Cumulative Timesteps: 117,287,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.34450
Policy Entropy: 1.22432
Value Function Loss: 5.18933

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.06585
Policy Update Magnitude: 0.04097
Value Function Update Magnitude: 0.04460

Collected Steps per Second: 10,779.74843
Overall Steps per Second: 9,153.50168

Timestep Collection Time: 4.63963
Timestep Consumption Time: 0.82429
PPO Batch Consumption Time: 0.04022
Total Iteration Time: 5.46392

Cumulative Model Updates: 7,031
Cumulative Timesteps: 117,337,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 117337426...
Checkpoint 117337426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.17008
Policy Entropy: 1.22691
Value Function Loss: 5.22476

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.05265
Policy Update Magnitude: 0.06136
Value Function Update Magnitude: 0.04147

Collected Steps per Second: 10,817.46145
Overall Steps per Second: 9,192.01578

Timestep Collection Time: 4.62382
Timestep Consumption Time: 0.81764
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.44146

Cumulative Model Updates: 7,034
Cumulative Timesteps: 117,387,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.21645
Policy Entropy: 1.21751
Value Function Loss: 5.12463

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.04770

Collected Steps per Second: 10,550.30937
Overall Steps per Second: 8,987.45519

Timestep Collection Time: 4.74109
Timestep Consumption Time: 0.82444
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.56554

Cumulative Model Updates: 7,037
Cumulative Timesteps: 117,437,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 117437464...
Checkpoint 117437464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.09291
Policy Entropy: 1.22892
Value Function Loss: 5.03058

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.04417

Collected Steps per Second: 10,197.45206
Overall Steps per Second: 8,864.93093

Timestep Collection Time: 4.90397
Timestep Consumption Time: 0.73713
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 5.64110

Cumulative Model Updates: 7,040
Cumulative Timesteps: 117,487,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.20972
Policy Entropy: 1.23035
Value Function Loss: 4.87089

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.04144

Collected Steps per Second: 10,827.97052
Overall Steps per Second: 9,191.36694

Timestep Collection Time: 4.62044
Timestep Consumption Time: 0.82271
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 5.44315

Cumulative Model Updates: 7,043
Cumulative Timesteps: 117,537,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 117537502...
Checkpoint 117537502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.61844
Policy Entropy: 1.22366
Value Function Loss: 4.99427

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.04171

Collected Steps per Second: 10,670.08669
Overall Steps per Second: 9,003.98857

Timestep Collection Time: 4.68862
Timestep Consumption Time: 0.86758
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 5.55620

Cumulative Model Updates: 7,046
Cumulative Timesteps: 117,587,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.30507
Policy Entropy: 1.22196
Value Function Loss: 5.01032

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.06402
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.03988

Collected Steps per Second: 11,134.90637
Overall Steps per Second: 9,459.64412

Timestep Collection Time: 4.49254
Timestep Consumption Time: 0.79561
PPO Batch Consumption Time: 0.03961
Total Iteration Time: 5.28815

Cumulative Model Updates: 7,049
Cumulative Timesteps: 117,637,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 117637554...
Checkpoint 117637554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.40583
Policy Entropy: 1.23148
Value Function Loss: 4.88809

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.04158

Collected Steps per Second: 10,767.59101
Overall Steps per Second: 9,127.12423

Timestep Collection Time: 4.64579
Timestep Consumption Time: 0.83501
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 5.48081

Cumulative Model Updates: 7,052
Cumulative Timesteps: 117,687,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.14776
Policy Entropy: 1.22644
Value Function Loss: 4.74713

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.04181

Collected Steps per Second: 10,605.17916
Overall Steps per Second: 9,034.62814

Timestep Collection Time: 4.71524
Timestep Consumption Time: 0.81968
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.53493

Cumulative Model Updates: 7,055
Cumulative Timesteps: 117,737,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 117737584...
Checkpoint 117737584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.46286
Policy Entropy: 1.22114
Value Function Loss: 4.45376

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.04343

Collected Steps per Second: 10,669.70755
Overall Steps per Second: 8,992.46924

Timestep Collection Time: 4.68916
Timestep Consumption Time: 0.87460
PPO Batch Consumption Time: 0.03992
Total Iteration Time: 5.56377

Cumulative Model Updates: 7,058
Cumulative Timesteps: 117,787,616

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.36304
Policy Entropy: 1.22328
Value Function Loss: 4.69041

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.04915

Collected Steps per Second: 11,132.62161
Overall Steps per Second: 9,380.03142

Timestep Collection Time: 4.49274
Timestep Consumption Time: 0.83944
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 5.33218

Cumulative Model Updates: 7,061
Cumulative Timesteps: 117,837,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 117837632...
Checkpoint 117837632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.76879
Policy Entropy: 1.22825
Value Function Loss: 4.81633

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05310
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.05239

Collected Steps per Second: 11,058.40834
Overall Steps per Second: 9,309.86897

Timestep Collection Time: 4.52380
Timestep Consumption Time: 0.84964
PPO Batch Consumption Time: 0.04002
Total Iteration Time: 5.37344

Cumulative Model Updates: 7,064
Cumulative Timesteps: 117,887,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.79466
Policy Entropy: 1.23623
Value Function Loss: 5.16645

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04853
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.04201

Collected Steps per Second: 10,845.68365
Overall Steps per Second: 9,168.20672

Timestep Collection Time: 4.61253
Timestep Consumption Time: 0.84394
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 5.45647

Cumulative Model Updates: 7,067
Cumulative Timesteps: 117,937,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 117937684...
Checkpoint 117937684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.21701
Policy Entropy: 1.23372
Value Function Loss: 5.04614

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06816
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.06997

Collected Steps per Second: 10,791.55010
Overall Steps per Second: 9,215.54022

Timestep Collection Time: 4.63400
Timestep Consumption Time: 0.79249
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 5.42649

Cumulative Model Updates: 7,070
Cumulative Timesteps: 117,987,692

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.90793
Policy Entropy: 1.23620
Value Function Loss: 5.24107

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.07186

Collected Steps per Second: 10,069.80835
Overall Steps per Second: 8,600.14157

Timestep Collection Time: 4.96832
Timestep Consumption Time: 0.84903
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 5.81735

Cumulative Model Updates: 7,073
Cumulative Timesteps: 118,037,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 118037722...
Checkpoint 118037722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.31470
Policy Entropy: 1.23498
Value Function Loss: 5.17232

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06937
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.05215

Collected Steps per Second: 10,633.51759
Overall Steps per Second: 9,011.15031

Timestep Collection Time: 4.70305
Timestep Consumption Time: 0.84674
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 5.54979

Cumulative Model Updates: 7,076
Cumulative Timesteps: 118,087,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.19389
Policy Entropy: 1.23750
Value Function Loss: 5.31746

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.04837
Policy Update Magnitude: 0.06029
Value Function Update Magnitude: 0.05069

Collected Steps per Second: 10,987.65166
Overall Steps per Second: 9,234.10146

Timestep Collection Time: 4.55056
Timestep Consumption Time: 0.86415
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 5.41471

Cumulative Model Updates: 7,079
Cumulative Timesteps: 118,137,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 118137732...
Checkpoint 118137732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.63927
Policy Entropy: 1.24103
Value Function Loss: 4.94387

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.05533
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.04564

Collected Steps per Second: 10,893.29909
Overall Steps per Second: 9,271.85020

Timestep Collection Time: 4.59181
Timestep Consumption Time: 0.80301
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 5.39482

Cumulative Model Updates: 7,082
Cumulative Timesteps: 118,187,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.66829
Policy Entropy: 1.23794
Value Function Loss: 4.95086

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.04250
Policy Update Magnitude: 0.06897
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 11,137.68955
Overall Steps per Second: 9,521.04252

Timestep Collection Time: 4.48998
Timestep Consumption Time: 0.76239
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 5.25237

Cumulative Model Updates: 7,085
Cumulative Timesteps: 118,237,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 118237760...
Checkpoint 118237760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.99466
Policy Entropy: 1.23715
Value Function Loss: 4.82730

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06086
Policy Update Magnitude: 0.06488
Value Function Update Magnitude: 0.07431

Collected Steps per Second: 10,363.02633
Overall Steps per Second: 8,781.20194

Timestep Collection Time: 4.82504
Timestep Consumption Time: 0.86917
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.69421

Cumulative Model Updates: 7,088
Cumulative Timesteps: 118,287,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.43994
Policy Entropy: 1.23454
Value Function Loss: 4.86375

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.06978
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.07061

Collected Steps per Second: 10,541.35303
Overall Steps per Second: 8,888.15152

Timestep Collection Time: 4.74569
Timestep Consumption Time: 0.88270
PPO Batch Consumption Time: 0.04452
Total Iteration Time: 5.62839

Cumulative Model Updates: 7,091
Cumulative Timesteps: 118,337,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 118337788...
Checkpoint 118337788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.83983
Policy Entropy: 1.24592
Value Function Loss: 4.83740

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.06040

Collected Steps per Second: 11,250.15681
Overall Steps per Second: 9,448.29754

Timestep Collection Time: 4.44652
Timestep Consumption Time: 0.84798
PPO Batch Consumption Time: 0.04709
Total Iteration Time: 5.29450

Cumulative Model Updates: 7,094
Cumulative Timesteps: 118,387,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.18072
Policy Entropy: 1.24367
Value Function Loss: 4.92106

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.05979
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.05553

Collected Steps per Second: 11,072.36906
Overall Steps per Second: 9,319.72458

Timestep Collection Time: 4.51737
Timestep Consumption Time: 0.84953
PPO Batch Consumption Time: 0.04145
Total Iteration Time: 5.36690

Cumulative Model Updates: 7,097
Cumulative Timesteps: 118,437,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 118437830...
Checkpoint 118437830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.40272
Policy Entropy: 1.23784
Value Function Loss: 4.80816

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.06922
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.07270

Collected Steps per Second: 10,471.15859
Overall Steps per Second: 9,088.19540

Timestep Collection Time: 4.77598
Timestep Consumption Time: 0.72677
PPO Batch Consumption Time: 0.04156
Total Iteration Time: 5.50274

Cumulative Model Updates: 7,100
Cumulative Timesteps: 118,487,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.69136
Policy Entropy: 1.23774
Value Function Loss: 4.72004

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.08276
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.04635

Collected Steps per Second: 10,737.04624
Overall Steps per Second: 9,137.31862

Timestep Collection Time: 4.65938
Timestep Consumption Time: 0.81575
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 5.47513

Cumulative Model Updates: 7,103
Cumulative Timesteps: 118,537,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 118537868...
Checkpoint 118537868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.25699
Policy Entropy: 1.23942
Value Function Loss: 4.49287

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.05817
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.04106

Collected Steps per Second: 10,073.08668
Overall Steps per Second: 8,612.25975

Timestep Collection Time: 4.96452
Timestep Consumption Time: 0.84209
PPO Batch Consumption Time: 0.04159
Total Iteration Time: 5.80661

Cumulative Model Updates: 7,106
Cumulative Timesteps: 118,587,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.88378
Policy Entropy: 1.24361
Value Function Loss: 4.67659

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.04399
Value Function Update Magnitude: 0.05242

Collected Steps per Second: 10,968.03655
Overall Steps per Second: 9,343.93967

Timestep Collection Time: 4.56107
Timestep Consumption Time: 0.79277
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.35384

Cumulative Model Updates: 7,109
Cumulative Timesteps: 118,637,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 118637902...
Checkpoint 118637902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.33744
Policy Entropy: 1.22471
Value Function Loss: 4.69884

Mean KL Divergence: 0.03122
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.05204

Collected Steps per Second: 10,530.63261
Overall Steps per Second: 8,970.31912

Timestep Collection Time: 4.75033
Timestep Consumption Time: 0.82628
PPO Batch Consumption Time: 0.04421
Total Iteration Time: 5.57661

Cumulative Model Updates: 7,112
Cumulative Timesteps: 118,687,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.17684
Policy Entropy: 1.23900
Value Function Loss: 4.81296

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.06548

Collected Steps per Second: 10,941.71418
Overall Steps per Second: 9,196.05916

Timestep Collection Time: 4.57095
Timestep Consumption Time: 0.86769
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 5.43863

Cumulative Model Updates: 7,115
Cumulative Timesteps: 118,737,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 118737940...
Checkpoint 118737940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.44976
Policy Entropy: 1.22636
Value Function Loss: 4.88380

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.04364
Value Function Update Magnitude: 0.09030

Collected Steps per Second: 10,804.42836
Overall Steps per Second: 9,017.46531

Timestep Collection Time: 4.62958
Timestep Consumption Time: 0.91743
PPO Batch Consumption Time: 0.03972
Total Iteration Time: 5.54701

Cumulative Model Updates: 7,118
Cumulative Timesteps: 118,787,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.42358
Policy Entropy: 1.23662
Value Function Loss: 4.87720

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.10120

Collected Steps per Second: 10,439.30736
Overall Steps per Second: 8,995.11701

Timestep Collection Time: 4.79189
Timestep Consumption Time: 0.76935
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 5.56124

Cumulative Model Updates: 7,121
Cumulative Timesteps: 118,837,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 118837984...
Checkpoint 118837984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.97049
Policy Entropy: 1.23157
Value Function Loss: 4.76255

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.08630

Collected Steps per Second: 10,638.15328
Overall Steps per Second: 9,101.13011

Timestep Collection Time: 4.70138
Timestep Consumption Time: 0.79398
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 5.49536

Cumulative Model Updates: 7,124
Cumulative Timesteps: 118,887,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.18388
Policy Entropy: 1.24435
Value Function Loss: 4.53586

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.08902

Collected Steps per Second: 10,547.10326
Overall Steps per Second: 8,987.85711

Timestep Collection Time: 4.74405
Timestep Consumption Time: 0.82302
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 5.56707

Cumulative Model Updates: 7,127
Cumulative Timesteps: 118,938,034

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 118938034...
Checkpoint 118938034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.53652
Policy Entropy: 1.24359
Value Function Loss: 4.42519

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.10793

Collected Steps per Second: 11,160.91623
Overall Steps per Second: 9,467.80396

Timestep Collection Time: 4.48207
Timestep Consumption Time: 0.80152
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 5.28359

Cumulative Model Updates: 7,130
Cumulative Timesteps: 118,988,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.22309
Policy Entropy: 1.23576
Value Function Loss: 4.51891

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.06726
Value Function Update Magnitude: 0.09398

Collected Steps per Second: 10,785.01904
Overall Steps per Second: 9,197.09328

Timestep Collection Time: 4.63680
Timestep Consumption Time: 0.80057
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 5.43737

Cumulative Model Updates: 7,133
Cumulative Timesteps: 119,038,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 119038066...
Checkpoint 119038066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.08903
Policy Entropy: 1.22499
Value Function Loss: 4.60730

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.07564

Collected Steps per Second: 10,774.02816
Overall Steps per Second: 9,291.00162

Timestep Collection Time: 4.64079
Timestep Consumption Time: 0.74076
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 5.38155

Cumulative Model Updates: 7,136
Cumulative Timesteps: 119,088,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.27161
Policy Entropy: 1.23180
Value Function Loss: 4.72912

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06434
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.09294

Collected Steps per Second: 9,799.69115
Overall Steps per Second: 8,148.94330

Timestep Collection Time: 5.10241
Timestep Consumption Time: 1.03360
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 6.13601

Cumulative Model Updates: 7,139
Cumulative Timesteps: 119,138,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 119138068...
Checkpoint 119138068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.76886
Policy Entropy: 1.23164
Value Function Loss: 4.63640

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.06447
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.08897

Collected Steps per Second: 10,581.43796
Overall Steps per Second: 9,111.00606

Timestep Collection Time: 4.72715
Timestep Consumption Time: 0.76292
PPO Batch Consumption Time: 0.04305
Total Iteration Time: 5.49006

Cumulative Model Updates: 7,142
Cumulative Timesteps: 119,188,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.72468
Policy Entropy: 1.21630
Value Function Loss: 4.56448

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.07275

Collected Steps per Second: 11,018.75995
Overall Steps per Second: 9,334.08582

Timestep Collection Time: 4.53989
Timestep Consumption Time: 0.81939
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 5.35928

Cumulative Model Updates: 7,145
Cumulative Timesteps: 119,238,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 119238112...
Checkpoint 119238112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.58766
Policy Entropy: 1.21471
Value Function Loss: 4.70434

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.06406

Collected Steps per Second: 10,804.73715
Overall Steps per Second: 9,097.58358

Timestep Collection Time: 4.63001
Timestep Consumption Time: 0.86882
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 5.49882

Cumulative Model Updates: 7,148
Cumulative Timesteps: 119,288,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.15819
Policy Entropy: 1.21649
Value Function Loss: 4.81374

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06027
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.05752

Collected Steps per Second: 11,093.27454
Overall Steps per Second: 9,249.96152

Timestep Collection Time: 4.50940
Timestep Consumption Time: 0.89862
PPO Batch Consumption Time: 0.04485
Total Iteration Time: 5.40802

Cumulative Model Updates: 7,151
Cumulative Timesteps: 119,338,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 119338162...
Checkpoint 119338162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.14794
Policy Entropy: 1.22180
Value Function Loss: 4.92368

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 10,604.44757
Overall Steps per Second: 8,997.02963

Timestep Collection Time: 4.71595
Timestep Consumption Time: 0.84256
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.55850

Cumulative Model Updates: 7,154
Cumulative Timesteps: 119,388,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.04116
Policy Entropy: 1.21120
Value Function Loss: 4.77763

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06990
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.06465

Collected Steps per Second: 11,005.64039
Overall Steps per Second: 9,445.87064

Timestep Collection Time: 4.54531
Timestep Consumption Time: 0.75055
PPO Batch Consumption Time: 0.03929
Total Iteration Time: 5.29586

Cumulative Model Updates: 7,157
Cumulative Timesteps: 119,438,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 119438196...
Checkpoint 119438196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.10752
Policy Entropy: 1.20905
Value Function Loss: 4.97153

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.06633

Collected Steps per Second: 10,928.15310
Overall Steps per Second: 9,112.23839

Timestep Collection Time: 4.57753
Timestep Consumption Time: 0.91223
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 5.48976

Cumulative Model Updates: 7,160
Cumulative Timesteps: 119,488,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.61600
Policy Entropy: 1.21457
Value Function Loss: 4.99038

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06319
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.06315

Collected Steps per Second: 10,910.38984
Overall Steps per Second: 9,244.66813

Timestep Collection Time: 4.58334
Timestep Consumption Time: 0.82583
PPO Batch Consumption Time: 0.04034
Total Iteration Time: 5.40917

Cumulative Model Updates: 7,163
Cumulative Timesteps: 119,538,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 119538226...
Checkpoint 119538226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.57628
Policy Entropy: 1.21922
Value Function Loss: 5.15020

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.06266

Collected Steps per Second: 10,986.67026
Overall Steps per Second: 9,298.55955

Timestep Collection Time: 4.55152
Timestep Consumption Time: 0.82631
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 5.37782

Cumulative Model Updates: 7,166
Cumulative Timesteps: 119,588,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.18950
Policy Entropy: 1.21262
Value Function Loss: 4.97920

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.06827
Value Function Update Magnitude: 0.06067

Collected Steps per Second: 10,815.23201
Overall Steps per Second: 9,063.90190

Timestep Collection Time: 4.62366
Timestep Consumption Time: 0.89339
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 5.51705

Cumulative Model Updates: 7,169
Cumulative Timesteps: 119,638,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 119638238...
Checkpoint 119638238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.07757
Policy Entropy: 1.20900
Value Function Loss: 5.09716

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.05751
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.05481

Collected Steps per Second: 10,367.82630
Overall Steps per Second: 9,023.91375

Timestep Collection Time: 4.82435
Timestep Consumption Time: 0.71848
PPO Batch Consumption Time: 0.03896
Total Iteration Time: 5.54283

Cumulative Model Updates: 7,172
Cumulative Timesteps: 119,688,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.14378
Policy Entropy: 1.21560
Value Function Loss: 5.03986

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07181
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.06113

Collected Steps per Second: 10,668.91011
Overall Steps per Second: 9,081.15495

Timestep Collection Time: 4.68708
Timestep Consumption Time: 0.81949
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.50657

Cumulative Model Updates: 7,175
Cumulative Timesteps: 119,738,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 119738262...
Checkpoint 119738262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.34065
Policy Entropy: 1.20999
Value Function Loss: 5.11668

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.06835
Value Function Update Magnitude: 0.06504

Collected Steps per Second: 10,659.54939
Overall Steps per Second: 9,231.48343

Timestep Collection Time: 4.69138
Timestep Consumption Time: 0.72573
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 5.41711

Cumulative Model Updates: 7,178
Cumulative Timesteps: 119,788,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.64454
Policy Entropy: 1.20651
Value Function Loss: 4.87143

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.06160
Value Function Update Magnitude: 0.06262

Collected Steps per Second: 10,873.94214
Overall Steps per Second: 9,239.12630

Timestep Collection Time: 4.60146
Timestep Consumption Time: 0.81420
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.41566

Cumulative Model Updates: 7,181
Cumulative Timesteps: 119,838,306

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 119838306...
Checkpoint 119838306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.11625
Policy Entropy: 1.20676
Value Function Loss: 4.72746

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.05626
Policy Update Magnitude: 0.07641
Value Function Update Magnitude: 0.09241

Collected Steps per Second: 10,985.02071
Overall Steps per Second: 9,296.42570

Timestep Collection Time: 4.55420
Timestep Consumption Time: 0.82722
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.38142

Cumulative Model Updates: 7,184
Cumulative Timesteps: 119,888,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.09516
Policy Entropy: 1.21123
Value Function Loss: 4.61628

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.06653
Value Function Update Magnitude: 0.11609

Collected Steps per Second: 10,385.55587
Overall Steps per Second: 8,819.95743

Timestep Collection Time: 4.81438
Timestep Consumption Time: 0.85458
PPO Batch Consumption Time: 0.04121
Total Iteration Time: 5.66896

Cumulative Model Updates: 7,187
Cumulative Timesteps: 119,938,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 119938334...
Checkpoint 119938334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.20078
Policy Entropy: 1.20803
Value Function Loss: 4.73515

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06625
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.10646

Collected Steps per Second: 10,448.31982
Overall Steps per Second: 8,894.78033

Timestep Collection Time: 4.78737
Timestep Consumption Time: 0.83615
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 5.62352

Cumulative Model Updates: 7,190
Cumulative Timesteps: 119,988,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.97205
Policy Entropy: 1.20762
Value Function Loss: 4.78664

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.06437
Value Function Update Magnitude: 0.10113

Collected Steps per Second: 10,759.43426
Overall Steps per Second: 9,300.78103

Timestep Collection Time: 4.64913
Timestep Consumption Time: 0.72913
PPO Batch Consumption Time: 0.04356
Total Iteration Time: 5.37826

Cumulative Model Updates: 7,193
Cumulative Timesteps: 120,038,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 120038376...
Checkpoint 120038376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.55043
Policy Entropy: 1.21102
Value Function Loss: 4.89831

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07215
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.08586

Collected Steps per Second: 10,720.81818
Overall Steps per Second: 9,025.60603

Timestep Collection Time: 4.66401
Timestep Consumption Time: 0.87601
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 5.54002

Cumulative Model Updates: 7,196
Cumulative Timesteps: 120,088,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.35975
Policy Entropy: 1.21073
Value Function Loss: 5.02921

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.08452

Collected Steps per Second: 10,826.02647
Overall Steps per Second: 9,177.47087

Timestep Collection Time: 4.61942
Timestep Consumption Time: 0.82979
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 5.44921

Cumulative Model Updates: 7,199
Cumulative Timesteps: 120,138,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 120138388...
Checkpoint 120138388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.51811
Policy Entropy: 1.20424
Value Function Loss: 4.75073

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07478
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.07728

Collected Steps per Second: 10,559.75196
Overall Steps per Second: 9,022.89242

Timestep Collection Time: 4.73534
Timestep Consumption Time: 0.80657
PPO Batch Consumption Time: 0.04704
Total Iteration Time: 5.54190

Cumulative Model Updates: 7,202
Cumulative Timesteps: 120,188,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.41181
Policy Entropy: 1.20791
Value Function Loss: 4.75705

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.07727

Collected Steps per Second: 10,780.27442
Overall Steps per Second: 9,126.47372

Timestep Collection Time: 4.63921
Timestep Consumption Time: 0.84067
PPO Batch Consumption Time: 0.03846
Total Iteration Time: 5.47988

Cumulative Model Updates: 7,205
Cumulative Timesteps: 120,238,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 120238404...
Checkpoint 120238404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.10336
Policy Entropy: 1.21333
Value Function Loss: 4.55709

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06441
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.06501

Collected Steps per Second: 10,831.76028
Overall Steps per Second: 9,307.94715

Timestep Collection Time: 4.61698
Timestep Consumption Time: 0.75585
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 5.37283

Cumulative Model Updates: 7,208
Cumulative Timesteps: 120,288,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.97612
Policy Entropy: 1.22253
Value Function Loss: 4.85352

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08163
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.06280

Collected Steps per Second: 10,779.78035
Overall Steps per Second: 9,088.21341

Timestep Collection Time: 4.63868
Timestep Consumption Time: 0.86339
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 5.50207

Cumulative Model Updates: 7,211
Cumulative Timesteps: 120,338,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 120338418...
Checkpoint 120338418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.08190
Policy Entropy: 1.21420
Value Function Loss: 4.62516

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.05870

Collected Steps per Second: 10,797.00981
Overall Steps per Second: 9,189.47163

Timestep Collection Time: 4.63351
Timestep Consumption Time: 0.81055
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.44406

Cumulative Model Updates: 7,214
Cumulative Timesteps: 120,388,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.49321
Policy Entropy: 1.21061
Value Function Loss: 4.70585

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.06131

Collected Steps per Second: 11,040.92466
Overall Steps per Second: 9,381.04466

Timestep Collection Time: 4.52897
Timestep Consumption Time: 0.80135
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 5.33032

Cumulative Model Updates: 7,217
Cumulative Timesteps: 120,438,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 120438450...
Checkpoint 120438450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.09082
Policy Entropy: 1.20883
Value Function Loss: 4.70148

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06250
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.07436

Collected Steps per Second: 10,466.90909
Overall Steps per Second: 8,871.71882

Timestep Collection Time: 4.77715
Timestep Consumption Time: 0.85896
PPO Batch Consumption Time: 0.04644
Total Iteration Time: 5.63611

Cumulative Model Updates: 7,220
Cumulative Timesteps: 120,488,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.72155
Policy Entropy: 1.21992
Value Function Loss: 4.87788

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07323
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.06976

Collected Steps per Second: 10,930.86687
Overall Steps per Second: 9,406.86625

Timestep Collection Time: 4.57439
Timestep Consumption Time: 0.74109
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 5.31548

Cumulative Model Updates: 7,223
Cumulative Timesteps: 120,538,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 120538454...
Checkpoint 120538454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.53239
Policy Entropy: 1.20909
Value Function Loss: 4.87194

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.06385

Collected Steps per Second: 10,771.81468
Overall Steps per Second: 9,085.41214

Timestep Collection Time: 4.64193
Timestep Consumption Time: 0.86162
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.50355

Cumulative Model Updates: 7,226
Cumulative Timesteps: 120,588,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.22339
Policy Entropy: 1.19871
Value Function Loss: 4.82236

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.06690

Collected Steps per Second: 10,782.89702
Overall Steps per Second: 9,211.33659

Timestep Collection Time: 4.63771
Timestep Consumption Time: 0.79125
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 5.42896

Cumulative Model Updates: 7,229
Cumulative Timesteps: 120,638,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 120638464...
Checkpoint 120638464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.64628
Policy Entropy: 1.20688
Value Function Loss: 4.86110

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05410
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.06335

Collected Steps per Second: 10,804.66919
Overall Steps per Second: 9,190.18078

Timestep Collection Time: 4.62929
Timestep Consumption Time: 0.81325
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 5.44255

Cumulative Model Updates: 7,232
Cumulative Timesteps: 120,688,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.11941
Policy Entropy: 1.21213
Value Function Loss: 4.70297

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06299
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 10,453.35737
Overall Steps per Second: 8,838.11605

Timestep Collection Time: 4.78487
Timestep Consumption Time: 0.87448
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 5.65935

Cumulative Model Updates: 7,235
Cumulative Timesteps: 120,738,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 120738500...
Checkpoint 120738500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.65011
Policy Entropy: 1.20606
Value Function Loss: 4.61247

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06561
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.09252

Collected Steps per Second: 10,617.05414
Overall Steps per Second: 9,033.03787

Timestep Collection Time: 4.71148
Timestep Consumption Time: 0.82620
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 5.53767

Cumulative Model Updates: 7,238
Cumulative Timesteps: 120,788,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.80413
Policy Entropy: 1.20415
Value Function Loss: 4.67567

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.07854

Collected Steps per Second: 10,792.69034
Overall Steps per Second: 9,165.55591

Timestep Collection Time: 4.63314
Timestep Consumption Time: 0.82251
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 5.45564

Cumulative Model Updates: 7,241
Cumulative Timesteps: 120,838,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 120838526...
Checkpoint 120838526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.47895
Policy Entropy: 1.20855
Value Function Loss: 4.95166

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06358
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.07906

Collected Steps per Second: 10,640.93895
Overall Steps per Second: 9,097.42220

Timestep Collection Time: 4.70109
Timestep Consumption Time: 0.79761
PPO Batch Consumption Time: 0.03971
Total Iteration Time: 5.49870

Cumulative Model Updates: 7,244
Cumulative Timesteps: 120,888,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.67588
Policy Entropy: 1.20862
Value Function Loss: 4.82486

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05604
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 10,945.24620
Overall Steps per Second: 9,310.64730

Timestep Collection Time: 4.57039
Timestep Consumption Time: 0.80239
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 5.37277

Cumulative Model Updates: 7,247
Cumulative Timesteps: 120,938,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 120938574...
Checkpoint 120938574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.59968
Policy Entropy: 1.20300
Value Function Loss: 4.76155

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.05941
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.06007

Collected Steps per Second: 10,822.69229
Overall Steps per Second: 9,169.30231

Timestep Collection Time: 4.62196
Timestep Consumption Time: 0.83342
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 5.45538

Cumulative Model Updates: 7,250
Cumulative Timesteps: 120,988,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.39607
Policy Entropy: 1.20502
Value Function Loss: 4.47688

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07304
Policy Update Magnitude: 0.04411
Value Function Update Magnitude: 0.05276

Collected Steps per Second: 10,335.43358
Overall Steps per Second: 8,924.76160

Timestep Collection Time: 4.83966
Timestep Consumption Time: 0.76497
PPO Batch Consumption Time: 0.04918
Total Iteration Time: 5.60463

Cumulative Model Updates: 7,253
Cumulative Timesteps: 121,038,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 121038616...
Checkpoint 121038616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.36069
Policy Entropy: 1.21250
Value Function Loss: 4.82775

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.04504
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.04667

Collected Steps per Second: 10,572.70168
Overall Steps per Second: 8,969.99374

Timestep Collection Time: 4.72916
Timestep Consumption Time: 0.84498
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.57414

Cumulative Model Updates: 7,256
Cumulative Timesteps: 121,088,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.53550
Policy Entropy: 1.21800
Value Function Loss: 4.93297

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07159
Policy Update Magnitude: 0.06610
Value Function Update Magnitude: 0.05415

Collected Steps per Second: 10,811.10880
Overall Steps per Second: 9,301.58313

Timestep Collection Time: 4.62561
Timestep Consumption Time: 0.75068
PPO Batch Consumption Time: 0.03771
Total Iteration Time: 5.37629

Cumulative Model Updates: 7,259
Cumulative Timesteps: 121,138,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 121138624...
Checkpoint 121138624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.24088
Policy Entropy: 1.20193
Value Function Loss: 5.21656

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.06408
Value Function Update Magnitude: 0.06832

Collected Steps per Second: 10,846.58432
Overall Steps per Second: 9,185.20133

Timestep Collection Time: 4.61011
Timestep Consumption Time: 0.83386
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 5.44397

Cumulative Model Updates: 7,262
Cumulative Timesteps: 121,188,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.78488
Policy Entropy: 1.19573
Value Function Loss: 4.93156

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.08270
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.05737

Collected Steps per Second: 10,743.41774
Overall Steps per Second: 9,110.60957

Timestep Collection Time: 4.65569
Timestep Consumption Time: 0.83439
PPO Batch Consumption Time: 0.04684
Total Iteration Time: 5.49008

Cumulative Model Updates: 7,265
Cumulative Timesteps: 121,238,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 121238646...
Checkpoint 121238646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.03148
Policy Entropy: 1.20364
Value Function Loss: 4.95925

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.06149

Collected Steps per Second: 10,384.31434
Overall Steps per Second: 8,837.37602

Timestep Collection Time: 4.81495
Timestep Consumption Time: 0.84283
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 5.65779

Cumulative Model Updates: 7,268
Cumulative Timesteps: 121,288,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.11521
Policy Entropy: 1.20918
Value Function Loss: 4.80194

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.07105

Collected Steps per Second: 10,705.47024
Overall Steps per Second: 9,131.34536

Timestep Collection Time: 4.67275
Timestep Consumption Time: 0.80552
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.47827

Cumulative Model Updates: 7,271
Cumulative Timesteps: 121,338,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 121338670...
Checkpoint 121338670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.11626
Policy Entropy: 1.20252
Value Function Loss: 4.82874

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06747
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.07120

Collected Steps per Second: 10,793.73334
Overall Steps per Second: 9,259.75204

Timestep Collection Time: 4.63269
Timestep Consumption Time: 0.76746
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 5.40014

Cumulative Model Updates: 7,274
Cumulative Timesteps: 121,388,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.84630
Policy Entropy: 1.20135
Value Function Loss: 4.65030

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.07273

Collected Steps per Second: 10,862.26267
Overall Steps per Second: 9,262.47265

Timestep Collection Time: 4.60530
Timestep Consumption Time: 0.79542
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.40072

Cumulative Model Updates: 7,277
Cumulative Timesteps: 121,438,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 121438698...
Checkpoint 121438698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.82120
Policy Entropy: 1.21361
Value Function Loss: 4.59476

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.05335
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 10,780.03239
Overall Steps per Second: 9,188.63450

Timestep Collection Time: 4.64025
Timestep Consumption Time: 0.80365
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.44390

Cumulative Model Updates: 7,280
Cumulative Timesteps: 121,488,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.82098
Policy Entropy: 1.22005
Value Function Loss: 4.66323

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06015
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.07863

Collected Steps per Second: 10,973.95797
Overall Steps per Second: 9,297.78661

Timestep Collection Time: 4.55788
Timestep Consumption Time: 0.82168
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.37956

Cumulative Model Updates: 7,283
Cumulative Timesteps: 121,538,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 121538738...
Checkpoint 121538738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.06481
Policy Entropy: 1.20823
Value Function Loss: 4.55025

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05101
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.08030

Collected Steps per Second: 10,269.71143
Overall Steps per Second: 8,811.76538

Timestep Collection Time: 4.87044
Timestep Consumption Time: 0.80584
PPO Batch Consumption Time: 0.04080
Total Iteration Time: 5.67627

Cumulative Model Updates: 7,286
Cumulative Timesteps: 121,588,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.78459
Policy Entropy: 1.20465
Value Function Loss: 4.64215

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.04640
Value Function Update Magnitude: 0.08059

Collected Steps per Second: 10,778.57028
Overall Steps per Second: 9,140.82695

Timestep Collection Time: 4.64106
Timestep Consumption Time: 0.83153
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 5.47259

Cumulative Model Updates: 7,289
Cumulative Timesteps: 121,638,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 121638780...
Checkpoint 121638780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.32079
Policy Entropy: 1.20935
Value Function Loss: 4.79478

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06222
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.08034

Collected Steps per Second: 11,033.58662
Overall Steps per Second: 9,371.05170

Timestep Collection Time: 4.53379
Timestep Consumption Time: 0.80435
PPO Batch Consumption Time: 0.04070
Total Iteration Time: 5.33814

Cumulative Model Updates: 7,292
Cumulative Timesteps: 121,688,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.81465
Policy Entropy: 1.21450
Value Function Loss: 5.06472

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.04429
Value Function Update Magnitude: 0.08581

Collected Steps per Second: 10,877.16991
Overall Steps per Second: 9,225.29419

Timestep Collection Time: 4.59899
Timestep Consumption Time: 0.82349
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.42248

Cumulative Model Updates: 7,295
Cumulative Timesteps: 121,738,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 121738828...
Checkpoint 121738828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.86723
Policy Entropy: 1.20885
Value Function Loss: 5.08070

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06255
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.07665

Collected Steps per Second: 11,066.76009
Overall Steps per Second: 9,252.19958

Timestep Collection Time: 4.51930
Timestep Consumption Time: 0.88633
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 5.40563

Cumulative Model Updates: 7,298
Cumulative Timesteps: 121,788,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.79108
Policy Entropy: 1.20970
Value Function Loss: 4.87710

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07492
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.08355

Collected Steps per Second: 10,345.48705
Overall Steps per Second: 8,788.68259

Timestep Collection Time: 4.83361
Timestep Consumption Time: 0.85621
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 5.68982

Cumulative Model Updates: 7,301
Cumulative Timesteps: 121,838,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 121838848...
Checkpoint 121838848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.35961
Policy Entropy: 1.21445
Value Function Loss: 4.80329

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.05909
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.07089

Collected Steps per Second: 10,664.33775
Overall Steps per Second: 9,220.63358

Timestep Collection Time: 4.69002
Timestep Consumption Time: 0.73433
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 5.42436

Cumulative Model Updates: 7,304
Cumulative Timesteps: 121,888,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.39811
Policy Entropy: 1.22115
Value Function Loss: 4.74732

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07155
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.06810

Collected Steps per Second: 10,750.47604
Overall Steps per Second: 9,065.61667

Timestep Collection Time: 4.65226
Timestep Consumption Time: 0.86463
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 5.51689

Cumulative Model Updates: 7,307
Cumulative Timesteps: 121,938,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 121938878...
Checkpoint 121938878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.31953
Policy Entropy: 1.19922
Value Function Loss: 4.55262

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.09366
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 10,835.04705
Overall Steps per Second: 9,170.62714

Timestep Collection Time: 4.61502
Timestep Consumption Time: 0.83760
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.45263

Cumulative Model Updates: 7,310
Cumulative Timesteps: 121,988,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.33222
Policy Entropy: 1.20358
Value Function Loss: 4.36287

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.06711
Policy Update Magnitude: 0.07218
Value Function Update Magnitude: 0.07501

Collected Steps per Second: 10,971.91554
Overall Steps per Second: 9,323.75901

Timestep Collection Time: 4.55818
Timestep Consumption Time: 0.80575
PPO Batch Consumption Time: 0.04135
Total Iteration Time: 5.36393

Cumulative Model Updates: 7,313
Cumulative Timesteps: 122,038,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 122038894...
Checkpoint 122038894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.30590
Policy Entropy: 1.20744
Value Function Loss: 4.41442

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.06482
Value Function Update Magnitude: 0.07534

Collected Steps per Second: 10,778.30844
Overall Steps per Second: 9,123.32278

Timestep Collection Time: 4.64006
Timestep Consumption Time: 0.84171
PPO Batch Consumption Time: 0.04050
Total Iteration Time: 5.48177

Cumulative Model Updates: 7,316
Cumulative Timesteps: 122,088,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.02463
Policy Entropy: 1.19762
Value Function Loss: 4.72259

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07007
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.07446

Collected Steps per Second: 10,151.25895
Overall Steps per Second: 8,828.05793

Timestep Collection Time: 4.92806
Timestep Consumption Time: 0.73865
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 5.66670

Cumulative Model Updates: 7,319
Cumulative Timesteps: 122,138,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 122138932...
Checkpoint 122138932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.41179
Policy Entropy: 1.20024
Value Function Loss: 4.82622

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.07536

Collected Steps per Second: 10,732.87240
Overall Steps per Second: 9,060.29607

Timestep Collection Time: 4.66008
Timestep Consumption Time: 0.86027
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.52035

Cumulative Model Updates: 7,322
Cumulative Timesteps: 122,188,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.18796
Policy Entropy: 1.20796
Value Function Loss: 4.87939

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06107
Policy Update Magnitude: 0.06259
Value Function Update Magnitude: 0.08548

Collected Steps per Second: 10,768.36031
Overall Steps per Second: 9,190.99156

Timestep Collection Time: 4.64546
Timestep Consumption Time: 0.79726
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 5.44272

Cumulative Model Updates: 7,325
Cumulative Timesteps: 122,238,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 122238972...
Checkpoint 122238972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.87126
Policy Entropy: 1.21621
Value Function Loss: 4.88803

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.06876
Value Function Update Magnitude: 0.08561

Collected Steps per Second: 10,692.16318
Overall Steps per Second: 9,142.45445

Timestep Collection Time: 4.67670
Timestep Consumption Time: 0.79273
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 5.46943

Cumulative Model Updates: 7,328
Cumulative Timesteps: 122,288,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.68456
Policy Entropy: 1.20837
Value Function Loss: 4.83825

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07199
Policy Update Magnitude: 0.06030
Value Function Update Magnitude: 0.08185

Collected Steps per Second: 10,809.68144
Overall Steps per Second: 9,165.62409

Timestep Collection Time: 4.62826
Timestep Consumption Time: 0.83018
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.45844

Cumulative Model Updates: 7,331
Cumulative Timesteps: 122,339,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 122339006...
Checkpoint 122339006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.88661
Policy Entropy: 1.21521
Value Function Loss: 4.71875

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.07201

Collected Steps per Second: 10,126.68807
Overall Steps per Second: 8,755.77310

Timestep Collection Time: 4.93923
Timestep Consumption Time: 0.77335
PPO Batch Consumption Time: 0.04625
Total Iteration Time: 5.71257

Cumulative Model Updates: 7,334
Cumulative Timesteps: 122,389,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.87141
Policy Entropy: 1.21239
Value Function Loss: 4.71661

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.06755

Collected Steps per Second: 10,762.59770
Overall Steps per Second: 9,009.14289

Timestep Collection Time: 4.64721
Timestep Consumption Time: 0.90449
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 5.55169

Cumulative Model Updates: 7,337
Cumulative Timesteps: 122,439,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 122439040...
Checkpoint 122439040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.64125
Policy Entropy: 1.19627
Value Function Loss: 4.68123

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.06515

Collected Steps per Second: 10,919.73141
Overall Steps per Second: 9,253.83446

Timestep Collection Time: 4.57887
Timestep Consumption Time: 0.82430
PPO Batch Consumption Time: 0.04178
Total Iteration Time: 5.40317

Cumulative Model Updates: 7,340
Cumulative Timesteps: 122,489,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.64773
Policy Entropy: 1.19756
Value Function Loss: 4.48236

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.06189

Collected Steps per Second: 10,456.70589
Overall Steps per Second: 9,028.42540

Timestep Collection Time: 4.78200
Timestep Consumption Time: 0.75650
PPO Batch Consumption Time: 0.04027
Total Iteration Time: 5.53851

Cumulative Model Updates: 7,343
Cumulative Timesteps: 122,539,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 122539044...
Checkpoint 122539044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.71175
Policy Entropy: 1.20024
Value Function Loss: 4.56231

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06402
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.07170

Collected Steps per Second: 11,105.25759
Overall Steps per Second: 9,435.70396

Timestep Collection Time: 4.50327
Timestep Consumption Time: 0.79681
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 5.30008

Cumulative Model Updates: 7,346
Cumulative Timesteps: 122,589,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.52288
Policy Entropy: 1.20279
Value Function Loss: 4.63180

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.06914

Collected Steps per Second: 11,114.79476
Overall Steps per Second: 9,527.36506

Timestep Collection Time: 4.50067
Timestep Consumption Time: 0.74989
PPO Batch Consumption Time: 0.03823
Total Iteration Time: 5.25056

Cumulative Model Updates: 7,349
Cumulative Timesteps: 122,639,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 122639078...
Checkpoint 122639078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.80068
Policy Entropy: 1.19247
Value Function Loss: 4.76104

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06039
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.07266

Collected Steps per Second: 10,388.54116
Overall Steps per Second: 8,769.96944

Timestep Collection Time: 4.81473
Timestep Consumption Time: 0.88860
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 5.70333

Cumulative Model Updates: 7,352
Cumulative Timesteps: 122,689,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.91286
Policy Entropy: 1.18861
Value Function Loss: 4.76162

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.06099

Collected Steps per Second: 10,597.44422
Overall Steps per Second: 8,915.77993

Timestep Collection Time: 4.71868
Timestep Consumption Time: 0.89002
PPO Batch Consumption Time: 0.04833
Total Iteration Time: 5.60871

Cumulative Model Updates: 7,355
Cumulative Timesteps: 122,739,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 122739102...
Checkpoint 122739102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.03996
Policy Entropy: 1.20288
Value Function Loss: 4.72253

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.05244

Collected Steps per Second: 11,203.63505
Overall Steps per Second: 9,423.90050

Timestep Collection Time: 4.46462
Timestep Consumption Time: 0.84316
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 5.30778

Cumulative Model Updates: 7,358
Cumulative Timesteps: 122,789,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.76979
Policy Entropy: 1.20179
Value Function Loss: 5.05534

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.05285

Collected Steps per Second: 10,824.77542
Overall Steps per Second: 9,179.75930

Timestep Collection Time: 4.62033
Timestep Consumption Time: 0.82796
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 5.44829

Cumulative Model Updates: 7,361
Cumulative Timesteps: 122,839,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 122839136...
Checkpoint 122839136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.77351
Policy Entropy: 1.19444
Value Function Loss: 5.02283

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.06921

Collected Steps per Second: 10,698.12230
Overall Steps per Second: 9,211.98544

Timestep Collection Time: 4.67652
Timestep Consumption Time: 0.75445
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 5.43097

Cumulative Model Updates: 7,364
Cumulative Timesteps: 122,889,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.91091
Policy Entropy: 1.19824
Value Function Loss: 5.04330

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06118
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.06095

Collected Steps per Second: 10,188.73911
Overall Steps per Second: 8,642.41766

Timestep Collection Time: 4.91032
Timestep Consumption Time: 0.87857
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 5.78889

Cumulative Model Updates: 7,367
Cumulative Timesteps: 122,939,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 122939196...
Checkpoint 122939196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.69796
Policy Entropy: 1.20417
Value Function Loss: 4.79569

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.05453

Collected Steps per Second: 10,626.65548
Overall Steps per Second: 9,068.88014

Timestep Collection Time: 4.70684
Timestep Consumption Time: 0.80850
PPO Batch Consumption Time: 0.03919
Total Iteration Time: 5.51534

Cumulative Model Updates: 7,370
Cumulative Timesteps: 122,989,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.28217
Policy Entropy: 1.19770
Value Function Loss: 4.75126

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.07896
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.08224

Collected Steps per Second: 10,932.75527
Overall Steps per Second: 9,315.36586

Timestep Collection Time: 4.57524
Timestep Consumption Time: 0.79438
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 5.36962

Cumulative Model Updates: 7,373
Cumulative Timesteps: 123,039,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 123039234...
Checkpoint 123039234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.10714
Policy Entropy: 1.19980
Value Function Loss: 4.70630

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.08459
Policy Update Magnitude: 0.05683
Value Function Update Magnitude: 0.07361

Collected Steps per Second: 10,676.01123
Overall Steps per Second: 8,982.01319

Timestep Collection Time: 4.68602
Timestep Consumption Time: 0.88378
PPO Batch Consumption Time: 0.03916
Total Iteration Time: 5.56980

Cumulative Model Updates: 7,376
Cumulative Timesteps: 123,089,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.49973
Policy Entropy: 1.20337
Value Function Loss: 4.87488

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 10,743.60374
Overall Steps per Second: 9,268.76439

Timestep Collection Time: 4.65561
Timestep Consumption Time: 0.74080
PPO Batch Consumption Time: 0.04646
Total Iteration Time: 5.39640

Cumulative Model Updates: 7,379
Cumulative Timesteps: 123,139,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 123139280...
Checkpoint 123139280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.01101
Policy Entropy: 1.21087
Value Function Loss: 4.75051

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.08517

Collected Steps per Second: 10,444.13196
Overall Steps per Second: 8,720.71123

Timestep Collection Time: 4.79025
Timestep Consumption Time: 0.94667
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 5.73692

Cumulative Model Updates: 7,382
Cumulative Timesteps: 123,189,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.27696
Policy Entropy: 1.19729
Value Function Loss: 4.64473

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 10,794.47137
Overall Steps per Second: 9,369.23819

Timestep Collection Time: 4.63293
Timestep Consumption Time: 0.70475
PPO Batch Consumption Time: 0.03956
Total Iteration Time: 5.33768

Cumulative Model Updates: 7,385
Cumulative Timesteps: 123,239,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 123239320...
Checkpoint 123239320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.22225
Policy Entropy: 1.19529
Value Function Loss: 4.49979

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.10279

Collected Steps per Second: 10,887.74108
Overall Steps per Second: 9,236.49381

Timestep Collection Time: 4.59269
Timestep Consumption Time: 0.82105
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.41374

Cumulative Model Updates: 7,388
Cumulative Timesteps: 123,289,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.42817
Policy Entropy: 1.20042
Value Function Loss: 4.64239

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05219
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.10659

Collected Steps per Second: 10,650.11738
Overall Steps per Second: 9,104.04645

Timestep Collection Time: 4.69554
Timestep Consumption Time: 0.79741
PPO Batch Consumption Time: 0.04824
Total Iteration Time: 5.49294

Cumulative Model Updates: 7,391
Cumulative Timesteps: 123,339,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 123339332...
Checkpoint 123339332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.28131
Policy Entropy: 1.20733
Value Function Loss: 4.75089

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.09932

Collected Steps per Second: 10,781.47152
Overall Steps per Second: 9,083.86986

Timestep Collection Time: 4.63907
Timestep Consumption Time: 0.86695
PPO Batch Consumption Time: 0.04449
Total Iteration Time: 5.50602

Cumulative Model Updates: 7,394
Cumulative Timesteps: 123,389,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.80977
Policy Entropy: 1.20626
Value Function Loss: 4.84390

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.08549

Collected Steps per Second: 10,554.34670
Overall Steps per Second: 9,037.65392

Timestep Collection Time: 4.73928
Timestep Consumption Time: 0.79534
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 5.53462

Cumulative Model Updates: 7,397
Cumulative Timesteps: 123,439,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 123439368...
Checkpoint 123439368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.55229
Policy Entropy: 1.19857
Value Function Loss: 4.75120

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06417
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.09202

Collected Steps per Second: 10,197.55708
Overall Steps per Second: 8,769.70780

Timestep Collection Time: 4.90470
Timestep Consumption Time: 0.79856
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 5.70327

Cumulative Model Updates: 7,400
Cumulative Timesteps: 123,489,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.31627
Policy Entropy: 1.20194
Value Function Loss: 4.73723

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06076
Policy Update Magnitude: 0.06576
Value Function Update Magnitude: 0.09997

Collected Steps per Second: 10,734.82692
Overall Steps per Second: 9,065.26076

Timestep Collection Time: 4.66072
Timestep Consumption Time: 0.85837
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 5.51909

Cumulative Model Updates: 7,403
Cumulative Timesteps: 123,539,416

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 123539416...
Checkpoint 123539416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.88450
Policy Entropy: 1.20447
Value Function Loss: 4.64095

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.07121
Value Function Update Magnitude: 0.09864

Collected Steps per Second: 10,827.71781
Overall Steps per Second: 9,209.61071

Timestep Collection Time: 4.61999
Timestep Consumption Time: 0.81172
PPO Batch Consumption Time: 0.04101
Total Iteration Time: 5.43172

Cumulative Model Updates: 7,406
Cumulative Timesteps: 123,589,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.97290
Policy Entropy: 1.21440
Value Function Loss: 4.78684

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.08440

Collected Steps per Second: 10,904.41893
Overall Steps per Second: 9,259.01153

Timestep Collection Time: 4.58603
Timestep Consumption Time: 0.81498
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 5.40101

Cumulative Model Updates: 7,409
Cumulative Timesteps: 123,639,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 123639448...
Checkpoint 123639448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.82104
Policy Entropy: 1.21613
Value Function Loss: 5.07224

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.07240

Collected Steps per Second: 10,754.59070
Overall Steps per Second: 9,105.39926

Timestep Collection Time: 4.65029
Timestep Consumption Time: 0.84227
PPO Batch Consumption Time: 0.04054
Total Iteration Time: 5.49257

Cumulative Model Updates: 7,412
Cumulative Timesteps: 123,689,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.19934
Policy Entropy: 1.20800
Value Function Loss: 5.03606

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.06379

Collected Steps per Second: 10,725.85282
Overall Steps per Second: 9,179.03410

Timestep Collection Time: 4.66369
Timestep Consumption Time: 0.78591
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.44959

Cumulative Model Updates: 7,415
Cumulative Timesteps: 123,739,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 123739482...
Checkpoint 123739482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.62019
Policy Entropy: 1.20962
Value Function Loss: 4.92401

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.07751
Policy Update Magnitude: 0.04313
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 10,503.57005
Overall Steps per Second: 8,887.44317

Timestep Collection Time: 4.76124
Timestep Consumption Time: 0.86580
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 5.62704

Cumulative Model Updates: 7,418
Cumulative Timesteps: 123,789,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.78700
Policy Entropy: 1.21147
Value Function Loss: 4.59192

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07018
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.08303

Collected Steps per Second: 10,559.41533
Overall Steps per Second: 9,093.06055

Timestep Collection Time: 4.73719
Timestep Consumption Time: 0.76392
PPO Batch Consumption Time: 0.03858
Total Iteration Time: 5.50112

Cumulative Model Updates: 7,421
Cumulative Timesteps: 123,839,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 123839514...
Checkpoint 123839514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.52178
Policy Entropy: 1.21007
Value Function Loss: 4.49985

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.04122
Value Function Update Magnitude: 0.07627

Collected Steps per Second: 11,068.38313
Overall Steps per Second: 9,253.82262

Timestep Collection Time: 4.51864
Timestep Consumption Time: 0.88605
PPO Batch Consumption Time: 0.04114
Total Iteration Time: 5.40469

Cumulative Model Updates: 7,424
Cumulative Timesteps: 123,889,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.84576
Policy Entropy: 1.21088
Value Function Loss: 4.45754

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.05571
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.07042

Collected Steps per Second: 10,914.59671
Overall Steps per Second: 9,305.36787

Timestep Collection Time: 4.58102
Timestep Consumption Time: 0.79222
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 5.37324

Cumulative Model Updates: 7,427
Cumulative Timesteps: 123,939,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 123939528...
Checkpoint 123939528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.61798
Policy Entropy: 1.20097
Value Function Loss: 4.58944

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.09739
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.07394

Collected Steps per Second: 10,667.97830
Overall Steps per Second: 9,182.34172

Timestep Collection Time: 4.68749
Timestep Consumption Time: 0.75840
PPO Batch Consumption Time: 0.04363
Total Iteration Time: 5.44589

Cumulative Model Updates: 7,430
Cumulative Timesteps: 123,989,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.71350
Policy Entropy: 1.21398
Value Function Loss: 4.57483

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.06890

Collected Steps per Second: 9,937.89185
Overall Steps per Second: 8,440.65976

Timestep Collection Time: 5.03185
Timestep Consumption Time: 0.89257
PPO Batch Consumption Time: 0.04808
Total Iteration Time: 5.92442

Cumulative Model Updates: 7,433
Cumulative Timesteps: 124,039,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 124039540...
Checkpoint 124039540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.96539
Policy Entropy: 1.20540
Value Function Loss: 4.65164

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.08459
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 10,728.97762
Overall Steps per Second: 9,093.86408

Timestep Collection Time: 4.66214
Timestep Consumption Time: 0.83827
PPO Batch Consumption Time: 0.04114
Total Iteration Time: 5.50041

Cumulative Model Updates: 7,436
Cumulative Timesteps: 124,089,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.33870
Policy Entropy: 1.20079
Value Function Loss: 4.64761

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.04321
Value Function Update Magnitude: 0.06238

Collected Steps per Second: 10,959.85569
Overall Steps per Second: 9,284.75611

Timestep Collection Time: 4.56283
Timestep Consumption Time: 0.82320
PPO Batch Consumption Time: 0.04032
Total Iteration Time: 5.38603

Cumulative Model Updates: 7,439
Cumulative Timesteps: 124,139,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 124139568...
Checkpoint 124139568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.69116
Policy Entropy: 1.19170
Value Function Loss: 4.77114

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07391
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.06143

Collected Steps per Second: 10,766.09861
Overall Steps per Second: 9,122.46580

Timestep Collection Time: 4.64644
Timestep Consumption Time: 0.83717
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.48361

Cumulative Model Updates: 7,442
Cumulative Timesteps: 124,189,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.88678
Policy Entropy: 1.21170
Value Function Loss: 4.97244

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.06062

Collected Steps per Second: 10,747.03288
Overall Steps per Second: 9,241.01136

Timestep Collection Time: 4.65394
Timestep Consumption Time: 0.75846
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 5.41239

Cumulative Model Updates: 7,445
Cumulative Timesteps: 124,239,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 124239608...
Checkpoint 124239608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.75354
Policy Entropy: 1.18404
Value Function Loss: 4.72882

Mean KL Divergence: 0.03493
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.04575
Value Function Update Magnitude: 0.07215

Collected Steps per Second: 10,243.64723
Overall Steps per Second: 8,753.71376

Timestep Collection Time: 4.88205
Timestep Consumption Time: 0.83095
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.71300

Cumulative Model Updates: 7,448
Cumulative Timesteps: 124,289,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.87271
Policy Entropy: 1.21384
Value Function Loss: 4.74905

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.06871

Collected Steps per Second: 10,933.79582
Overall Steps per Second: 9,435.65424

Timestep Collection Time: 4.57499
Timestep Consumption Time: 0.72639
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 5.30138

Cumulative Model Updates: 7,451
Cumulative Timesteps: 124,339,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 124339640...
Checkpoint 124339640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.60610
Policy Entropy: 1.19881
Value Function Loss: 4.58456

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.07333

Collected Steps per Second: 10,460.73485
Overall Steps per Second: 8,856.71932

Timestep Collection Time: 4.78035
Timestep Consumption Time: 0.86576
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 5.64611

Cumulative Model Updates: 7,454
Cumulative Timesteps: 124,389,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.18811
Policy Entropy: 1.19360
Value Function Loss: 4.88405

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.06893

Collected Steps per Second: 10,961.43883
Overall Steps per Second: 9,219.98006

Timestep Collection Time: 4.56217
Timestep Consumption Time: 0.86170
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 5.42387

Cumulative Model Updates: 7,457
Cumulative Timesteps: 124,439,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 124439654...
Checkpoint 124439654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.62151
Policy Entropy: 1.20054
Value Function Loss: 4.71733

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.07667

Collected Steps per Second: 11,133.89596
Overall Steps per Second: 9,337.18789

Timestep Collection Time: 4.49295
Timestep Consumption Time: 0.86456
PPO Batch Consumption Time: 0.03876
Total Iteration Time: 5.35750

Cumulative Model Updates: 7,460
Cumulative Timesteps: 124,489,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.06083
Policy Entropy: 1.21012
Value Function Loss: 4.68205

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.06715

Collected Steps per Second: 10,855.39676
Overall Steps per Second: 9,173.48049

Timestep Collection Time: 4.60729
Timestep Consumption Time: 0.84473
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 5.45202

Cumulative Model Updates: 7,463
Cumulative Timesteps: 124,539,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 124539692...
Checkpoint 124539692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.44963
Policy Entropy: 1.19935
Value Function Loss: 4.56689

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05950
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.06437

Collected Steps per Second: 10,197.98232
Overall Steps per Second: 8,845.84997

Timestep Collection Time: 4.90587
Timestep Consumption Time: 0.74989
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 5.65576

Cumulative Model Updates: 7,466
Cumulative Timesteps: 124,589,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.28190
Policy Entropy: 1.19383
Value Function Loss: 4.62067

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.05951

Collected Steps per Second: 10,728.36807
Overall Steps per Second: 9,021.73652

Timestep Collection Time: 4.66166
Timestep Consumption Time: 0.88184
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 5.54350

Cumulative Model Updates: 7,469
Cumulative Timesteps: 124,639,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 124639734...
Checkpoint 124639734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.68790
Policy Entropy: 1.19990
Value Function Loss: 4.56102

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06556
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.07121

Collected Steps per Second: 10,672.19144
Overall Steps per Second: 9,100.75683

Timestep Collection Time: 4.68639
Timestep Consumption Time: 0.80920
PPO Batch Consumption Time: 0.04718
Total Iteration Time: 5.49559

Cumulative Model Updates: 7,472
Cumulative Timesteps: 124,689,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.32200
Policy Entropy: 1.20633
Value Function Loss: 4.47437

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.04335
Value Function Update Magnitude: 0.06626

Collected Steps per Second: 10,875.81503
Overall Steps per Second: 9,199.89625

Timestep Collection Time: 4.59736
Timestep Consumption Time: 0.83749
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 5.43484

Cumulative Model Updates: 7,475
Cumulative Timesteps: 124,739,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 124739748...
Checkpoint 124739748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.62338
Policy Entropy: 1.18717
Value Function Loss: 4.51754

Mean KL Divergence: 0.02874
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.06663

Collected Steps per Second: 11,278.73873
Overall Steps per Second: 9,582.70581

Timestep Collection Time: 4.43383
Timestep Consumption Time: 0.78474
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 5.21857

Cumulative Model Updates: 7,478
Cumulative Timesteps: 124,789,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.50048
Policy Entropy: 1.20470
Value Function Loss: 4.39552

Mean KL Divergence: 0.02549
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.05365

Collected Steps per Second: 10,586.82629
Overall Steps per Second: 8,857.52750

Timestep Collection Time: 4.72550
Timestep Consumption Time: 0.92258
PPO Batch Consumption Time: 0.04567
Total Iteration Time: 5.64808

Cumulative Model Updates: 7,481
Cumulative Timesteps: 124,839,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 124839784...
Checkpoint 124839784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.41024
Policy Entropy: 1.19483
Value Function Loss: 4.52321

Mean KL Divergence: 0.02509
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.05848

Collected Steps per Second: 11,125.39543
Overall Steps per Second: 9,371.33601

Timestep Collection Time: 4.49584
Timestep Consumption Time: 0.84150
PPO Batch Consumption Time: 0.04121
Total Iteration Time: 5.33734

Cumulative Model Updates: 7,484
Cumulative Timesteps: 124,889,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.78768
Policy Entropy: 1.21457
Value Function Loss: 4.80152

Mean KL Divergence: 0.02334
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.04744

Collected Steps per Second: 11,208.07964
Overall Steps per Second: 9,480.54253

Timestep Collection Time: 4.46142
Timestep Consumption Time: 0.81296
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 5.27438

Cumulative Model Updates: 7,487
Cumulative Timesteps: 124,939,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 124939806...
Checkpoint 124939806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.63626
Policy Entropy: 1.20248
Value Function Loss: 4.90382

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.04321
Value Function Update Magnitude: 0.05492

Collected Steps per Second: 11,054.51875
Overall Steps per Second: 9,319.71293

Timestep Collection Time: 4.52521
Timestep Consumption Time: 0.84234
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 5.36755

Cumulative Model Updates: 7,490
Cumulative Timesteps: 124,989,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.85066
Policy Entropy: 1.21474
Value Function Loss: 4.84730

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.04002
Value Function Update Magnitude: 0.06237

Collected Steps per Second: 10,815.84853
Overall Steps per Second: 9,243.23823

Timestep Collection Time: 4.62543
Timestep Consumption Time: 0.78695
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.41239

Cumulative Model Updates: 7,493
Cumulative Timesteps: 125,039,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 125039858...
Checkpoint 125039858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.28091
Policy Entropy: 1.20176
Value Function Loss: 4.56651

Mean KL Divergence: 0.02766
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.04147
Value Function Update Magnitude: 0.05813

Collected Steps per Second: 10,737.72840
Overall Steps per Second: 9,019.28274

Timestep Collection Time: 4.65815
Timestep Consumption Time: 0.88752
PPO Batch Consumption Time: 0.04682
Total Iteration Time: 5.54567

Cumulative Model Updates: 7,496
Cumulative Timesteps: 125,089,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.99373
Policy Entropy: 1.21875
Value Function Loss: 4.51373

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.05386

Collected Steps per Second: 10,068.93443
Overall Steps per Second: 8,669.66281

Timestep Collection Time: 4.96736
Timestep Consumption Time: 0.80172
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 5.76908

Cumulative Model Updates: 7,499
Cumulative Timesteps: 125,139,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 125139892...
Checkpoint 125139892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.12769
Policy Entropy: 1.20572
Value Function Loss: 4.45433

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.04057
Value Function Update Magnitude: 0.05922

Collected Steps per Second: 11,072.74674
Overall Steps per Second: 9,334.82380

Timestep Collection Time: 4.51631
Timestep Consumption Time: 0.84083
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 5.35714

Cumulative Model Updates: 7,502
Cumulative Timesteps: 125,189,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.15399
Policy Entropy: 1.20942
Value Function Loss: 4.49729

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.06901

Collected Steps per Second: 10,787.96662
Overall Steps per Second: 9,142.74657

Timestep Collection Time: 4.63535
Timestep Consumption Time: 0.83412
PPO Batch Consumption Time: 0.04738
Total Iteration Time: 5.46947

Cumulative Model Updates: 7,505
Cumulative Timesteps: 125,239,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 125239906...
Checkpoint 125239906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.52750
Policy Entropy: 1.19842
Value Function Loss: 4.62878

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.03999
Value Function Update Magnitude: 0.07285

Collected Steps per Second: 10,916.78996
Overall Steps per Second: 9,436.76786

Timestep Collection Time: 4.58267
Timestep Consumption Time: 0.71873
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 5.30139

Cumulative Model Updates: 7,508
Cumulative Timesteps: 125,289,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.56949
Policy Entropy: 1.19594
Value Function Loss: 4.75985

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.03733
Value Function Update Magnitude: 0.06841

Collected Steps per Second: 10,670.37636
Overall Steps per Second: 8,961.45285

Timestep Collection Time: 4.68625
Timestep Consumption Time: 0.89365
PPO Batch Consumption Time: 0.04656
Total Iteration Time: 5.57990

Cumulative Model Updates: 7,511
Cumulative Timesteps: 125,339,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 125339938...
Checkpoint 125339938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.14564
Policy Entropy: 1.21049
Value Function Loss: 4.84142

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06011
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.06059

Collected Steps per Second: 10,157.82512
Overall Steps per Second: 8,876.36772

Timestep Collection Time: 4.92310
Timestep Consumption Time: 0.71073
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 5.63384

Cumulative Model Updates: 7,514
Cumulative Timesteps: 125,389,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.22291
Policy Entropy: 1.21308
Value Function Loss: 4.77902

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07201
Policy Update Magnitude: 0.03774
Value Function Update Magnitude: 0.06780

Collected Steps per Second: 10,917.70255
Overall Steps per Second: 9,264.81014

Timestep Collection Time: 4.58137
Timestep Consumption Time: 0.81734
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.39871

Cumulative Model Updates: 7,517
Cumulative Timesteps: 125,439,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 125439964...
Checkpoint 125439964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.14125
Policy Entropy: 1.20993
Value Function Loss: 4.89499

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.03946
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 10,888.33420
Overall Steps per Second: 9,161.35428

Timestep Collection Time: 4.59483
Timestep Consumption Time: 0.86616
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 5.46098

Cumulative Model Updates: 7,520
Cumulative Timesteps: 125,489,994

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.20601
Policy Entropy: 1.19901
Value Function Loss: 4.73925

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07578
Policy Update Magnitude: 0.03894
Value Function Update Magnitude: 0.05710

Collected Steps per Second: 10,987.83473
Overall Steps per Second: 9,365.05728

Timestep Collection Time: 4.55158
Timestep Consumption Time: 0.78870
PPO Batch Consumption Time: 0.03966
Total Iteration Time: 5.34028

Cumulative Model Updates: 7,523
Cumulative Timesteps: 125,540,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 125540006...
Checkpoint 125540006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.52286
Policy Entropy: 1.19902
Value Function Loss: 4.82768

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.06704
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.06400

Collected Steps per Second: 10,811.15219
Overall Steps per Second: 9,128.62060

Timestep Collection Time: 4.62670
Timestep Consumption Time: 0.85277
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.47947

Cumulative Model Updates: 7,526
Cumulative Timesteps: 125,590,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.77508
Policy Entropy: 1.19637
Value Function Loss: 4.91556

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.08423

Collected Steps per Second: 10,565.57070
Overall Steps per Second: 9,045.43397

Timestep Collection Time: 4.73349
Timestep Consumption Time: 0.79549
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 5.52898

Cumulative Model Updates: 7,529
Cumulative Timesteps: 125,640,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 125640038...
Checkpoint 125640038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.82333
Policy Entropy: 1.19548
Value Function Loss: 4.92469

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.06543
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.07478

Collected Steps per Second: 10,234.75588
Overall Steps per Second: 8,819.53293

Timestep Collection Time: 4.88571
Timestep Consumption Time: 0.78398
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 5.66969

Cumulative Model Updates: 7,532
Cumulative Timesteps: 125,690,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.09649
Policy Entropy: 1.19255
Value Function Loss: 5.10099

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.06272

Collected Steps per Second: 11,005.49518
Overall Steps per Second: 9,497.72146

Timestep Collection Time: 4.54355
Timestep Consumption Time: 0.72129
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 5.26484

Cumulative Model Updates: 7,535
Cumulative Timesteps: 125,740,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 125740046...
Checkpoint 125740046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.33341
Policy Entropy: 1.19780
Value Function Loss: 4.77437

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05463
Policy Update Magnitude: 0.06005
Value Function Update Magnitude: 0.06031

Collected Steps per Second: 10,570.46264
Overall Steps per Second: 8,954.40623

Timestep Collection Time: 4.73205
Timestep Consumption Time: 0.85402
PPO Batch Consumption Time: 0.04032
Total Iteration Time: 5.58608

Cumulative Model Updates: 7,538
Cumulative Timesteps: 125,790,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.89546
Policy Entropy: 1.21194
Value Function Loss: 4.91973

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.06558

Collected Steps per Second: 10,741.50220
Overall Steps per Second: 9,102.01498

Timestep Collection Time: 4.65521
Timestep Consumption Time: 0.83851
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 5.49373

Cumulative Model Updates: 7,541
Cumulative Timesteps: 125,840,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 125840070...
Checkpoint 125840070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.65688
Policy Entropy: 1.19027
Value Function Loss: 4.67753

Mean KL Divergence: 0.02905
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.05766

Collected Steps per Second: 11,338.44803
Overall Steps per Second: 9,558.54065

Timestep Collection Time: 4.41154
Timestep Consumption Time: 0.82148
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.23302

Cumulative Model Updates: 7,544
Cumulative Timesteps: 125,890,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.78253
Policy Entropy: 1.21077
Value Function Loss: 4.85941

Mean KL Divergence: 0.02291
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.06127

Collected Steps per Second: 10,314.22208
Overall Steps per Second: 8,844.55346

Timestep Collection Time: 4.84942
Timestep Consumption Time: 0.80581
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.65523

Cumulative Model Updates: 7,547
Cumulative Timesteps: 125,940,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 125940108...
Checkpoint 125940108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.35146
Policy Entropy: 1.19053
Value Function Loss: 4.87802

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.03750
Value Function Update Magnitude: 0.06049

Collected Steps per Second: 10,616.35982
Overall Steps per Second: 9,028.29762

Timestep Collection Time: 4.71235
Timestep Consumption Time: 0.82889
PPO Batch Consumption Time: 0.04558
Total Iteration Time: 5.54124

Cumulative Model Updates: 7,550
Cumulative Timesteps: 125,990,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.80007
Policy Entropy: 1.20872
Value Function Loss: 4.96261

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.04017
Value Function Update Magnitude: 0.07148

Collected Steps per Second: 10,924.48367
Overall Steps per Second: 9,151.18296

Timestep Collection Time: 4.57944
Timestep Consumption Time: 0.88740
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 5.46683

Cumulative Model Updates: 7,553
Cumulative Timesteps: 126,040,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 126040164...
Checkpoint 126040164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.87739
Policy Entropy: 1.19717
Value Function Loss: 4.95211

Mean KL Divergence: 0.02921
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.03466
Value Function Update Magnitude: 0.07197

Collected Steps per Second: 10,889.39531
Overall Steps per Second: 9,402.28553

Timestep Collection Time: 4.59364
Timestep Consumption Time: 0.72655
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 5.32020

Cumulative Model Updates: 7,556
Cumulative Timesteps: 126,090,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.42618
Policy Entropy: 1.21898
Value Function Loss: 4.78191

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.03674
Value Function Update Magnitude: 0.06928

Collected Steps per Second: 10,843.11884
Overall Steps per Second: 9,183.43172

Timestep Collection Time: 4.61196
Timestep Consumption Time: 0.83350
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 5.44546

Cumulative Model Updates: 7,559
Cumulative Timesteps: 126,140,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 126140194...
Checkpoint 126140194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.58631
Policy Entropy: 1.20866
Value Function Loss: 4.63727

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.04009
Value Function Update Magnitude: 0.07230

Collected Steps per Second: 10,668.09022
Overall Steps per Second: 8,786.18598

Timestep Collection Time: 4.68762
Timestep Consumption Time: 1.00404
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 5.69166

Cumulative Model Updates: 7,562
Cumulative Timesteps: 126,190,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.44919
Policy Entropy: 1.21653
Value Function Loss: 4.58765

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.06564

Collected Steps per Second: 10,803.63319
Overall Steps per Second: 9,082.11678

Timestep Collection Time: 4.62955
Timestep Consumption Time: 0.87753
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.50709

Cumulative Model Updates: 7,565
Cumulative Timesteps: 126,240,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 126240218...
Checkpoint 126240218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.37881
Policy Entropy: 1.22080
Value Function Loss: 4.67129

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.04008
Value Function Update Magnitude: 0.07660

Collected Steps per Second: 10,778.02282
Overall Steps per Second: 9,116.40008

Timestep Collection Time: 4.64000
Timestep Consumption Time: 0.84572
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.48572

Cumulative Model Updates: 7,568
Cumulative Timesteps: 126,290,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.59220
Policy Entropy: 1.21015
Value Function Loss: 4.73980

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 10,832.52331
Overall Steps per Second: 9,297.62404

Timestep Collection Time: 4.61610
Timestep Consumption Time: 0.76205
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 5.37815

Cumulative Model Updates: 7,571
Cumulative Timesteps: 126,340,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 126340232...
Checkpoint 126340232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.75695
Policy Entropy: 1.19604
Value Function Loss: 4.63384

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.06643

Collected Steps per Second: 10,987.17631
Overall Steps per Second: 9,264.35009

Timestep Collection Time: 4.55331
Timestep Consumption Time: 0.84675
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 5.40006

Cumulative Model Updates: 7,574
Cumulative Timesteps: 126,390,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.27199
Policy Entropy: 1.19798
Value Function Loss: 4.73242

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06715
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.07030

Collected Steps per Second: 10,666.87939
Overall Steps per Second: 9,210.18968

Timestep Collection Time: 4.68834
Timestep Consumption Time: 0.74151
PPO Batch Consumption Time: 0.04438
Total Iteration Time: 5.42986

Cumulative Model Updates: 7,577
Cumulative Timesteps: 126,440,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 126440270...
Checkpoint 126440270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.17990
Policy Entropy: 1.19588
Value Function Loss: 4.69166

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.05994
Policy Update Magnitude: 0.07109
Value Function Update Magnitude: 0.06721

Collected Steps per Second: 10,303.90079
Overall Steps per Second: 8,800.33090

Timestep Collection Time: 4.85331
Timestep Consumption Time: 0.82921
PPO Batch Consumption Time: 0.04515
Total Iteration Time: 5.68251

Cumulative Model Updates: 7,580
Cumulative Timesteps: 126,490,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.30219
Policy Entropy: 1.19685
Value Function Loss: 4.82791

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05595
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.06493

Collected Steps per Second: 10,329.26323
Overall Steps per Second: 8,844.96118

Timestep Collection Time: 4.84217
Timestep Consumption Time: 0.81258
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 5.65474

Cumulative Model Updates: 7,583
Cumulative Timesteps: 126,540,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 126540294...
Checkpoint 126540294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.89534
Policy Entropy: 1.20563
Value Function Loss: 4.89604

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04677
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.06397

Collected Steps per Second: 11,071.35724
Overall Steps per Second: 9,404.96733

Timestep Collection Time: 4.51760
Timestep Consumption Time: 0.80044
PPO Batch Consumption Time: 0.04050
Total Iteration Time: 5.31804

Cumulative Model Updates: 7,586
Cumulative Timesteps: 126,590,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.19593
Policy Entropy: 1.20405
Value Function Loss: 4.90953

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.05513
Policy Update Magnitude: 0.06398
Value Function Update Magnitude: 0.06537

Collected Steps per Second: 10,810.74115
Overall Steps per Second: 9,120.12932

Timestep Collection Time: 4.62503
Timestep Consumption Time: 0.85735
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 5.48238

Cumulative Model Updates: 7,589
Cumulative Timesteps: 126,640,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 126640310...
Checkpoint 126640310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.70389
Policy Entropy: 1.21377
Value Function Loss: 4.78659

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.07235
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.07359

Collected Steps per Second: 10,714.88740
Overall Steps per Second: 9,141.05426

Timestep Collection Time: 4.66902
Timestep Consumption Time: 0.80387
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 5.47289

Cumulative Model Updates: 7,592
Cumulative Timesteps: 126,690,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.78264
Policy Entropy: 1.21543
Value Function Loss: 4.68642

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.07005

Collected Steps per Second: 10,569.10710
Overall Steps per Second: 8,797.76516

Timestep Collection Time: 4.73077
Timestep Consumption Time: 0.95249
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 5.68326

Cumulative Model Updates: 7,595
Cumulative Timesteps: 126,740,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 126740338...
Checkpoint 126740338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.01180
Policy Entropy: 1.20958
Value Function Loss: 4.70792

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07062
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.07105

Collected Steps per Second: 10,765.76121
Overall Steps per Second: 9,246.15768

Timestep Collection Time: 4.64528
Timestep Consumption Time: 0.76345
PPO Batch Consumption Time: 0.04559
Total Iteration Time: 5.40873

Cumulative Model Updates: 7,598
Cumulative Timesteps: 126,790,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.18550
Policy Entropy: 1.20411
Value Function Loss: 4.71368

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.04431
Value Function Update Magnitude: 0.06800

Collected Steps per Second: 10,835.28779
Overall Steps per Second: 9,118.47255

Timestep Collection Time: 4.61658
Timestep Consumption Time: 0.86920
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 5.48579

Cumulative Model Updates: 7,601
Cumulative Timesteps: 126,840,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 126840370...
Checkpoint 126840370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.72113
Policy Entropy: 1.20593
Value Function Loss: 4.67259

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06533
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.06301

Collected Steps per Second: 10,597.87637
Overall Steps per Second: 9,068.77805

Timestep Collection Time: 4.71868
Timestep Consumption Time: 0.79562
PPO Batch Consumption Time: 0.04024
Total Iteration Time: 5.51430

Cumulative Model Updates: 7,604
Cumulative Timesteps: 126,890,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.30634
Policy Entropy: 1.21213
Value Function Loss: 4.61019

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07390
Policy Update Magnitude: 0.04367
Value Function Update Magnitude: 0.05422

Collected Steps per Second: 11,327.50130
Overall Steps per Second: 9,542.32828

Timestep Collection Time: 4.41510
Timestep Consumption Time: 0.82597
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 5.24107

Cumulative Model Updates: 7,607
Cumulative Timesteps: 126,940,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 126940390...
Checkpoint 126940390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.11848
Policy Entropy: 1.20792
Value Function Loss: 4.72122

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.07055
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.04491

Collected Steps per Second: 11,048.07131
Overall Steps per Second: 9,352.27648

Timestep Collection Time: 4.52568
Timestep Consumption Time: 0.82062
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 5.34629

Cumulative Model Updates: 7,610
Cumulative Timesteps: 126,990,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.30893
Policy Entropy: 1.21069
Value Function Loss: 4.81351

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.06987
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.04118

Collected Steps per Second: 10,647.79870
Overall Steps per Second: 9,073.55354

Timestep Collection Time: 4.69768
Timestep Consumption Time: 0.81504
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.51272

Cumulative Model Updates: 7,613
Cumulative Timesteps: 127,040,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 127040410...
Checkpoint 127040410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.88172
Policy Entropy: 1.21051
Value Function Loss: 4.93532

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08102
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.04051

Collected Steps per Second: 10,961.80865
Overall Steps per Second: 9,260.26249

Timestep Collection Time: 4.56348
Timestep Consumption Time: 0.83853
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 5.40201

Cumulative Model Updates: 7,616
Cumulative Timesteps: 127,090,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.90451
Policy Entropy: 1.21074
Value Function Loss: 4.72594

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.03838

Collected Steps per Second: 11,034.07108
Overall Steps per Second: 9,472.40815

Timestep Collection Time: 4.53251
Timestep Consumption Time: 0.74725
PPO Batch Consumption Time: 0.04028
Total Iteration Time: 5.27976

Cumulative Model Updates: 7,619
Cumulative Timesteps: 127,140,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 127140446...
Checkpoint 127140446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.47472
Policy Entropy: 1.20273
Value Function Loss: 4.83149

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.04590

Collected Steps per Second: 11,239.38566
Overall Steps per Second: 9,487.96932

Timestep Collection Time: 4.44971
Timestep Consumption Time: 0.82139
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 5.27110

Cumulative Model Updates: 7,622
Cumulative Timesteps: 127,190,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.79553
Policy Entropy: 1.20040
Value Function Loss: 4.59587

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08087
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.04214

Collected Steps per Second: 10,754.54414
Overall Steps per Second: 9,172.10333

Timestep Collection Time: 4.65050
Timestep Consumption Time: 0.80234
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 5.45284

Cumulative Model Updates: 7,625
Cumulative Timesteps: 127,240,472

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 127240472...
Checkpoint 127240472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.32866
Policy Entropy: 1.20430
Value Function Loss: 4.48190

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06735
Policy Update Magnitude: 0.04190
Value Function Update Magnitude: 0.06085

Collected Steps per Second: 11,034.30874
Overall Steps per Second: 9,165.15106

Timestep Collection Time: 4.53386
Timestep Consumption Time: 0.92464
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 5.45850

Cumulative Model Updates: 7,628
Cumulative Timesteps: 127,290,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.18846
Policy Entropy: 1.20654
Value Function Loss: 4.20993

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07731
Policy Update Magnitude: 0.03680
Value Function Update Magnitude: 0.06476

Collected Steps per Second: 10,402.95059
Overall Steps per Second: 8,814.28225

Timestep Collection Time: 4.80921
Timestep Consumption Time: 0.86680
PPO Batch Consumption Time: 0.04405
Total Iteration Time: 5.67602

Cumulative Model Updates: 7,631
Cumulative Timesteps: 127,340,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 127340530...
Checkpoint 127340530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.01714
Policy Entropy: 1.19534
Value Function Loss: 4.49798

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.05879
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.06027

Collected Steps per Second: 10,199.32214
Overall Steps per Second: 8,700.27527

Timestep Collection Time: 4.90405
Timestep Consumption Time: 0.84496
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 5.74901

Cumulative Model Updates: 7,634
Cumulative Timesteps: 127,390,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.65940
Policy Entropy: 1.19884
Value Function Loss: 4.83392

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.05993
Value Function Update Magnitude: 0.05419

Collected Steps per Second: 10,579.33426
Overall Steps per Second: 8,961.77532

Timestep Collection Time: 4.72733
Timestep Consumption Time: 0.85326
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 5.58059

Cumulative Model Updates: 7,637
Cumulative Timesteps: 127,440,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 127440560...
Checkpoint 127440560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.24599
Policy Entropy: 1.20307
Value Function Loss: 5.01816

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.04950

Collected Steps per Second: 10,477.13663
Overall Steps per Second: 9,074.77732

Timestep Collection Time: 4.77382
Timestep Consumption Time: 0.73772
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 5.51154

Cumulative Model Updates: 7,640
Cumulative Timesteps: 127,490,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.17641
Policy Entropy: 1.20656
Value Function Loss: 5.06173

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.05686

Collected Steps per Second: 10,723.96729
Overall Steps per Second: 9,146.73786

Timestep Collection Time: 4.66357
Timestep Consumption Time: 0.80417
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.46774

Cumulative Model Updates: 7,643
Cumulative Timesteps: 127,540,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 127540588...
Checkpoint 127540588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.66043
Policy Entropy: 1.20398
Value Function Loss: 4.97581

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06841
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.05766

Collected Steps per Second: 10,258.36535
Overall Steps per Second: 8,777.94711

Timestep Collection Time: 4.87563
Timestep Consumption Time: 0.82228
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 5.69792

Cumulative Model Updates: 7,646
Cumulative Timesteps: 127,590,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.09283
Policy Entropy: 1.19010
Value Function Loss: 4.91115

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 10,888.20394
Overall Steps per Second: 9,260.13183

Timestep Collection Time: 4.59451
Timestep Consumption Time: 0.80779
PPO Batch Consumption Time: 0.03971
Total Iteration Time: 5.40230

Cumulative Model Updates: 7,649
Cumulative Timesteps: 127,640,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 127640630...
Checkpoint 127640630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.49619
Policy Entropy: 1.19432
Value Function Loss: 4.69135

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.03883
Value Function Update Magnitude: 0.04902

Collected Steps per Second: 10,948.89408
Overall Steps per Second: 9,339.56105

Timestep Collection Time: 4.56813
Timestep Consumption Time: 0.78715
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 5.35528

Cumulative Model Updates: 7,652
Cumulative Timesteps: 127,690,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.46578
Policy Entropy: 1.20533
Value Function Loss: 4.66176

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.06695
Policy Update Magnitude: 0.04326
Value Function Update Magnitude: 0.04552

Collected Steps per Second: 10,704.98188
Overall Steps per Second: 9,254.14551

Timestep Collection Time: 4.67184
Timestep Consumption Time: 0.73244
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.40428

Cumulative Model Updates: 7,655
Cumulative Timesteps: 127,740,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 127740658...
Checkpoint 127740658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.98683
Policy Entropy: 1.20919
Value Function Loss: 4.36493

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.04012
Value Function Update Magnitude: 0.04602

Collected Steps per Second: 10,882.17127
Overall Steps per Second: 9,267.62617

Timestep Collection Time: 4.59743
Timestep Consumption Time: 0.80093
PPO Batch Consumption Time: 0.03983
Total Iteration Time: 5.39836

Cumulative Model Updates: 7,658
Cumulative Timesteps: 127,790,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.04723
Policy Entropy: 1.19924
Value Function Loss: 4.41194

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05558
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.04617

Collected Steps per Second: 10,546.30572
Overall Steps per Second: 8,954.21393

Timestep Collection Time: 4.74365
Timestep Consumption Time: 0.84344
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 5.58709

Cumulative Model Updates: 7,661
Cumulative Timesteps: 127,840,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 127840716...
Checkpoint 127840716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.22528
Policy Entropy: 1.18965
Value Function Loss: 4.32708

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.04892

Collected Steps per Second: 11,039.13764
Overall Steps per Second: 9,371.78441

Timestep Collection Time: 4.53006
Timestep Consumption Time: 0.80595
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.33602

Cumulative Model Updates: 7,664
Cumulative Timesteps: 127,890,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.66046
Policy Entropy: 1.21028
Value Function Loss: 4.69986

Mean KL Divergence: 0.02414
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.05481

Collected Steps per Second: 10,693.71203
Overall Steps per Second: 9,127.75759

Timestep Collection Time: 4.67789
Timestep Consumption Time: 0.80254
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 5.48043

Cumulative Model Updates: 7,667
Cumulative Timesteps: 127,940,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 127940748...
Checkpoint 127940748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.65974
Policy Entropy: 1.20593
Value Function Loss: 4.69459

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.05557

Collected Steps per Second: 10,544.33856
Overall Steps per Second: 9,106.09828

Timestep Collection Time: 4.74207
Timestep Consumption Time: 0.74897
PPO Batch Consumption Time: 0.04941
Total Iteration Time: 5.49105

Cumulative Model Updates: 7,670
Cumulative Timesteps: 127,990,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.55103
Policy Entropy: 1.21380
Value Function Loss: 4.80152

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.05612

Collected Steps per Second: 10,679.35211
Overall Steps per Second: 9,014.01386

Timestep Collection Time: 4.68493
Timestep Consumption Time: 0.86554
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.55047

Cumulative Model Updates: 7,673
Cumulative Timesteps: 128,040,782

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 128040782...
Checkpoint 128040782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.72808
Policy Entropy: 1.19465
Value Function Loss: 4.72890

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.06044

Collected Steps per Second: 10,866.94683
Overall Steps per Second: 9,397.92451

Timestep Collection Time: 4.60332
Timestep Consumption Time: 0.71956
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.32288

Cumulative Model Updates: 7,676
Cumulative Timesteps: 128,090,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.62472
Policy Entropy: 1.19534
Value Function Loss: 4.73594

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.06279

Collected Steps per Second: 10,342.19642
Overall Steps per Second: 8,784.78787

Timestep Collection Time: 4.83553
Timestep Consumption Time: 0.85727
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 5.69280

Cumulative Model Updates: 7,679
Cumulative Timesteps: 128,140,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 128140816...
Checkpoint 128140816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.31712
Policy Entropy: 1.19128
Value Function Loss: 4.66873

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.07468

Collected Steps per Second: 10,841.77186
Overall Steps per Second: 9,229.90440

Timestep Collection Time: 4.61179
Timestep Consumption Time: 0.80538
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 5.41717

Cumulative Model Updates: 7,682
Cumulative Timesteps: 128,190,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.26159
Policy Entropy: 1.19495
Value Function Loss: 4.89229

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.08064

Collected Steps per Second: 10,696.16766
Overall Steps per Second: 9,259.70357

Timestep Collection Time: 4.67625
Timestep Consumption Time: 0.72543
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.40168

Cumulative Model Updates: 7,685
Cumulative Timesteps: 128,240,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 128240834...
Checkpoint 128240834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.74117
Policy Entropy: 1.19960
Value Function Loss: 4.96997

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.06791
Value Function Update Magnitude: 0.08552

Collected Steps per Second: 10,811.37631
Overall Steps per Second: 9,114.87291

Timestep Collection Time: 4.62642
Timestep Consumption Time: 0.86109
PPO Batch Consumption Time: 0.04082
Total Iteration Time: 5.48751

Cumulative Model Updates: 7,688
Cumulative Timesteps: 128,290,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.23209
Policy Entropy: 1.20144
Value Function Loss: 4.91017

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.07184

Collected Steps per Second: 10,733.09268
Overall Steps per Second: 9,255.19940

Timestep Collection Time: 4.66017
Timestep Consumption Time: 0.74415
PPO Batch Consumption Time: 0.04671
Total Iteration Time: 5.40431

Cumulative Model Updates: 7,691
Cumulative Timesteps: 128,340,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 128340870...
Checkpoint 128340870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.70420
Policy Entropy: 1.20420
Value Function Loss: 4.81783

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.06474
Value Function Update Magnitude: 0.06724

Collected Steps per Second: 10,377.11771
Overall Steps per Second: 8,799.21811

Timestep Collection Time: 4.82003
Timestep Consumption Time: 0.86434
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 5.68437

Cumulative Model Updates: 7,694
Cumulative Timesteps: 128,390,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.81794
Policy Entropy: 1.19842
Value Function Loss: 4.84132

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 10,469.19033
Overall Steps per Second: 8,880.99089

Timestep Collection Time: 4.77840
Timestep Consumption Time: 0.85453
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 5.63293

Cumulative Model Updates: 7,697
Cumulative Timesteps: 128,440,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 128440914...
Checkpoint 128440914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.31801
Policy Entropy: 1.19412
Value Function Loss: 4.73708

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.06231

Collected Steps per Second: 10,971.62530
Overall Steps per Second: 9,225.53304

Timestep Collection Time: 4.55958
Timestep Consumption Time: 0.86298
PPO Batch Consumption Time: 0.04584
Total Iteration Time: 5.42256

Cumulative Model Updates: 7,700
Cumulative Timesteps: 128,490,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.87634
Policy Entropy: 1.19194
Value Function Loss: 4.56858

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.08247

Collected Steps per Second: 10,814.90429
Overall Steps per Second: 9,150.56052

Timestep Collection Time: 4.62621
Timestep Consumption Time: 0.84143
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 5.46764

Cumulative Model Updates: 7,703
Cumulative Timesteps: 128,540,972

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 128540972...
Checkpoint 128540972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.63487
Policy Entropy: 1.19781
Value Function Loss: 4.45917

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.06607
Policy Update Magnitude: 0.06953
Value Function Update Magnitude: 0.09099

Collected Steps per Second: 10,615.77997
Overall Steps per Second: 9,163.49708

Timestep Collection Time: 4.71148
Timestep Consumption Time: 0.74670
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 5.45818

Cumulative Model Updates: 7,706
Cumulative Timesteps: 128,590,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.67711
Policy Entropy: 1.20647
Value Function Loss: 4.40844

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.07373

Collected Steps per Second: 10,831.81163
Overall Steps per Second: 9,100.21332

Timestep Collection Time: 4.61825
Timestep Consumption Time: 0.87877
PPO Batch Consumption Time: 0.03960
Total Iteration Time: 5.49701

Cumulative Model Updates: 7,709
Cumulative Timesteps: 128,641,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 128641012...
Checkpoint 128641012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.54494
Policy Entropy: 1.17912
Value Function Loss: 4.50141

Mean KL Divergence: 0.02842
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.06652
Value Function Update Magnitude: 0.06822

Collected Steps per Second: 10,159.63829
Overall Steps per Second: 8,667.05176

Timestep Collection Time: 4.92399
Timestep Consumption Time: 0.84798
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 5.77197

Cumulative Model Updates: 7,712
Cumulative Timesteps: 128,691,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.10650
Policy Entropy: 1.19723
Value Function Loss: 4.54127

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.06714

Collected Steps per Second: 11,090.61377
Overall Steps per Second: 9,368.02760

Timestep Collection Time: 4.50850
Timestep Consumption Time: 0.82902
PPO Batch Consumption Time: 0.03824
Total Iteration Time: 5.33752

Cumulative Model Updates: 7,715
Cumulative Timesteps: 128,741,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 128741040...
Checkpoint 128741040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.94584
Policy Entropy: 1.17852
Value Function Loss: 4.86289

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.06987

Collected Steps per Second: 10,604.87243
Overall Steps per Second: 8,964.10124

Timestep Collection Time: 4.71745
Timestep Consumption Time: 0.86347
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.58093

Cumulative Model Updates: 7,718
Cumulative Timesteps: 128,791,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.91069
Policy Entropy: 1.20166
Value Function Loss: 4.68322

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.07363

Collected Steps per Second: 10,709.18513
Overall Steps per Second: 9,277.06676

Timestep Collection Time: 4.67020
Timestep Consumption Time: 0.72095
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.39114

Cumulative Model Updates: 7,721
Cumulative Timesteps: 128,841,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 128841082...
Checkpoint 128841082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.86022
Policy Entropy: 1.18905
Value Function Loss: 4.72578

Mean KL Divergence: 0.03372
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.04002
Value Function Update Magnitude: 0.06586

Collected Steps per Second: 10,851.69272
Overall Steps per Second: 9,149.78446

Timestep Collection Time: 4.60758
Timestep Consumption Time: 0.85703
PPO Batch Consumption Time: 0.03930
Total Iteration Time: 5.46461

Cumulative Model Updates: 7,724
Cumulative Timesteps: 128,891,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.44943
Policy Entropy: 1.20515
Value Function Loss: 4.64142

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.03870
Value Function Update Magnitude: 0.06442

Collected Steps per Second: 10,313.98855
Overall Steps per Second: 8,864.73017

Timestep Collection Time: 4.84779
Timestep Consumption Time: 0.79254
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 5.64033

Cumulative Model Updates: 7,727
Cumulative Timesteps: 128,941,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 128941082...
Checkpoint 128941082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.65791
Policy Entropy: 1.19121
Value Function Loss: 4.91235

Mean KL Divergence: 0.02811
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.03808
Value Function Update Magnitude: 0.06438

Collected Steps per Second: 10,551.48878
Overall Steps per Second: 8,925.37070

Timestep Collection Time: 4.74075
Timestep Consumption Time: 0.86372
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 5.60447

Cumulative Model Updates: 7,730
Cumulative Timesteps: 128,991,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.04983
Policy Entropy: 1.21199
Value Function Loss: 5.09714

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.04178
Value Function Update Magnitude: 0.06770

Collected Steps per Second: 10,781.42951
Overall Steps per Second: 9,165.55120

Timestep Collection Time: 4.64020
Timestep Consumption Time: 0.81806
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 5.45826

Cumulative Model Updates: 7,733
Cumulative Timesteps: 129,041,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 129041132...
Checkpoint 129041132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.22425
Policy Entropy: 1.19683
Value Function Loss: 5.03242

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.06913

Collected Steps per Second: 11,016.57773
Overall Steps per Second: 9,254.85588

Timestep Collection Time: 4.54043
Timestep Consumption Time: 0.86430
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 5.40473

Cumulative Model Updates: 7,736
Cumulative Timesteps: 129,091,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.41254
Policy Entropy: 1.20631
Value Function Loss: 4.91673

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 11,130.74487
Overall Steps per Second: 9,382.65856

Timestep Collection Time: 4.49260
Timestep Consumption Time: 0.83702
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 5.32962

Cumulative Model Updates: 7,739
Cumulative Timesteps: 129,141,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 129141158...
Checkpoint 129141158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.45896
Policy Entropy: 1.19598
Value Function Loss: 4.73676

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.07093

Collected Steps per Second: 10,477.61685
Overall Steps per Second: 8,942.69141

Timestep Collection Time: 4.77360
Timestep Consumption Time: 0.81934
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 5.59295

Cumulative Model Updates: 7,742
Cumulative Timesteps: 129,191,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.03324
Policy Entropy: 1.19760
Value Function Loss: 4.67289

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.08919

Collected Steps per Second: 10,356.40688
Overall Steps per Second: 8,638.19240

Timestep Collection Time: 4.83044
Timestep Consumption Time: 0.96082
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.79126

Cumulative Model Updates: 7,745
Cumulative Timesteps: 129,241,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 129241200...
Checkpoint 129241200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.14864
Policy Entropy: 1.19921
Value Function Loss: 4.77821

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.07906
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.11005

Collected Steps per Second: 11,126.61270
Overall Steps per Second: 9,422.39302

Timestep Collection Time: 4.49409
Timestep Consumption Time: 0.81284
PPO Batch Consumption Time: 0.04147
Total Iteration Time: 5.30693

Cumulative Model Updates: 7,748
Cumulative Timesteps: 129,291,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.99706
Policy Entropy: 1.20128
Value Function Loss: 4.73511

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.10722

Collected Steps per Second: 11,146.86804
Overall Steps per Second: 9,372.13936

Timestep Collection Time: 4.48718
Timestep Consumption Time: 0.84970
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 5.33688

Cumulative Model Updates: 7,751
Cumulative Timesteps: 129,341,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 129341222...
Checkpoint 129341222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.82956
Policy Entropy: 1.18842
Value Function Loss: 4.94004

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.09321

Collected Steps per Second: 10,850.77599
Overall Steps per Second: 9,230.30728

Timestep Collection Time: 4.60926
Timestep Consumption Time: 0.80920
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 5.41845

Cumulative Model Updates: 7,754
Cumulative Timesteps: 129,391,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.74665
Policy Entropy: 1.19372
Value Function Loss: 4.59641

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.08535

Collected Steps per Second: 10,541.66188
Overall Steps per Second: 8,985.69147

Timestep Collection Time: 4.74422
Timestep Consumption Time: 0.82151
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 5.56574

Cumulative Model Updates: 7,757
Cumulative Timesteps: 129,441,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 129441248...
Checkpoint 129441248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.00104
Policy Entropy: 1.18811
Value Function Loss: 4.66744

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.08138

Collected Steps per Second: 10,369.40170
Overall Steps per Second: 8,872.51477

Timestep Collection Time: 4.82477
Timestep Consumption Time: 0.81399
PPO Batch Consumption Time: 0.04159
Total Iteration Time: 5.63876

Cumulative Model Updates: 7,760
Cumulative Timesteps: 129,491,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.43448
Policy Entropy: 1.17996
Value Function Loss: 4.45947

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.07397

Collected Steps per Second: 10,634.05845
Overall Steps per Second: 8,995.49028

Timestep Collection Time: 4.70281
Timestep Consumption Time: 0.85664
PPO Batch Consumption Time: 0.04722
Total Iteration Time: 5.55945

Cumulative Model Updates: 7,763
Cumulative Timesteps: 129,541,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 129541288...
Checkpoint 129541288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.44369
Policy Entropy: 1.19406
Value Function Loss: 4.71198

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.04272
Value Function Update Magnitude: 0.07745

Collected Steps per Second: 10,789.74010
Overall Steps per Second: 9,316.74652

Timestep Collection Time: 4.63459
Timestep Consumption Time: 0.73274
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 5.36732

Cumulative Model Updates: 7,766
Cumulative Timesteps: 129,591,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.17055
Policy Entropy: 1.19500
Value Function Loss: 4.73223

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.07106

Collected Steps per Second: 10,782.78719
Overall Steps per Second: 9,099.52593

Timestep Collection Time: 4.63813
Timestep Consumption Time: 0.85798
PPO Batch Consumption Time: 0.04310
Total Iteration Time: 5.49611

Cumulative Model Updates: 7,769
Cumulative Timesteps: 129,641,306

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 129641306...
Checkpoint 129641306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.26429
Policy Entropy: 1.19218
Value Function Loss: 4.68868

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.07093

Collected Steps per Second: 10,711.48974
Overall Steps per Second: 9,176.90527

Timestep Collection Time: 4.66807
Timestep Consumption Time: 0.78061
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 5.44868

Cumulative Model Updates: 7,772
Cumulative Timesteps: 129,691,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.01974
Policy Entropy: 1.19048
Value Function Loss: 4.65201

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.07180

Collected Steps per Second: 10,757.56124
Overall Steps per Second: 8,906.02229

Timestep Collection Time: 4.65031
Timestep Consumption Time: 0.96679
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 5.61710

Cumulative Model Updates: 7,775
Cumulative Timesteps: 129,741,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 129741334...
Checkpoint 129741334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.07897
Policy Entropy: 1.19002
Value Function Loss: 5.10853

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.07958

Collected Steps per Second: 10,793.47236
Overall Steps per Second: 9,186.92061

Timestep Collection Time: 4.63373
Timestep Consumption Time: 0.81032
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 5.44404

Cumulative Model Updates: 7,778
Cumulative Timesteps: 129,791,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.04007
Policy Entropy: 1.19782
Value Function Loss: 5.14393

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.09077

Collected Steps per Second: 10,845.13897
Overall Steps per Second: 9,385.59050

Timestep Collection Time: 4.61073
Timestep Consumption Time: 0.71701
PPO Batch Consumption Time: 0.04027
Total Iteration Time: 5.32774

Cumulative Model Updates: 7,781
Cumulative Timesteps: 129,841,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 129841352...
Checkpoint 129841352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.23104
Policy Entropy: 1.18446
Value Function Loss: 5.12957

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.07818

Collected Steps per Second: 10,641.68505
Overall Steps per Second: 9,015.23552

Timestep Collection Time: 4.69888
Timestep Consumption Time: 0.84773
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 5.54661

Cumulative Model Updates: 7,784
Cumulative Timesteps: 129,891,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.03298
Policy Entropy: 1.19728
Value Function Loss: 4.93541

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.07271

Collected Steps per Second: 10,410.20756
Overall Steps per Second: 8,973.24428

Timestep Collection Time: 4.80394
Timestep Consumption Time: 0.76930
PPO Batch Consumption Time: 0.04708
Total Iteration Time: 5.57324

Cumulative Model Updates: 7,787
Cumulative Timesteps: 129,941,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 129941366...
Checkpoint 129941366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.20081
Policy Entropy: 1.18869
Value Function Loss: 4.93170

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.06530

Collected Steps per Second: 10,673.87365
Overall Steps per Second: 9,035.91170

Timestep Collection Time: 4.68508
Timestep Consumption Time: 0.84928
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 5.53436

Cumulative Model Updates: 7,790
Cumulative Timesteps: 129,991,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.47561
Policy Entropy: 1.18516
Value Function Loss: 5.11761

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 10,286.58177
Overall Steps per Second: 8,835.03110

Timestep Collection Time: 4.86303
Timestep Consumption Time: 0.79897
PPO Batch Consumption Time: 0.03967
Total Iteration Time: 5.66201

Cumulative Model Updates: 7,793
Cumulative Timesteps: 130,041,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 130041398...
Checkpoint 130041398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.67572
Policy Entropy: 1.18361
Value Function Loss: 4.66888

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.04101
Value Function Update Magnitude: 0.05511

Collected Steps per Second: 10,605.21748
Overall Steps per Second: 9,022.08758

Timestep Collection Time: 4.71749
Timestep Consumption Time: 0.82779
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 5.54528

Cumulative Model Updates: 7,796
Cumulative Timesteps: 130,091,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.75736
Policy Entropy: 1.19095
Value Function Loss: 4.87121

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06150
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.05146

Collected Steps per Second: 10,809.79113
Overall Steps per Second: 9,199.41801

Timestep Collection Time: 4.62784
Timestep Consumption Time: 0.81011
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 5.43795

Cumulative Model Updates: 7,799
Cumulative Timesteps: 130,141,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 130141454...
Checkpoint 130141454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.02218
Policy Entropy: 1.19326
Value Function Loss: 4.62152

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.05712

Collected Steps per Second: 10,593.80976
Overall Steps per Second: 9,172.94908

Timestep Collection Time: 4.72314
Timestep Consumption Time: 0.73160
PPO Batch Consumption Time: 0.04158
Total Iteration Time: 5.45473

Cumulative Model Updates: 7,802
Cumulative Timesteps: 130,191,490

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.56739
Policy Entropy: 1.17219
Value Function Loss: 4.92281

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.05780

Collected Steps per Second: 10,890.26548
Overall Steps per Second: 9,084.08770

Timestep Collection Time: 4.59199
Timestep Consumption Time: 0.91302
PPO Batch Consumption Time: 0.04052
Total Iteration Time: 5.50501

Cumulative Model Updates: 7,805
Cumulative Timesteps: 130,241,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 130241498...
Checkpoint 130241498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.38177
Policy Entropy: 1.19472
Value Function Loss: 4.55199

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.06434

Collected Steps per Second: 10,408.29140
Overall Steps per Second: 8,802.53813

Timestep Collection Time: 4.80694
Timestep Consumption Time: 0.87688
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 5.68382

Cumulative Model Updates: 7,808
Cumulative Timesteps: 130,291,530

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.90450
Policy Entropy: 1.17834
Value Function Loss: 4.66564

Mean KL Divergence: 0.03880
SB3 Clip Fraction: 0.15567
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 11,041.22164
Overall Steps per Second: 9,369.64540

Timestep Collection Time: 4.53030
Timestep Consumption Time: 0.80822
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 5.33852

Cumulative Model Updates: 7,811
Cumulative Timesteps: 130,341,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 130341550...
Checkpoint 130341550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.95070
Policy Entropy: 1.18860
Value Function Loss: 4.56179

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.03985
Value Function Update Magnitude: 0.06865

Collected Steps per Second: 10,824.81934
Overall Steps per Second: 9,178.79375

Timestep Collection Time: 4.62105
Timestep Consumption Time: 0.82869
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 5.44974

Cumulative Model Updates: 7,814
Cumulative Timesteps: 130,391,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.70738
Policy Entropy: 1.18750
Value Function Loss: 4.62112

Mean KL Divergence: 0.03047
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.03853
Value Function Update Magnitude: 0.07355

Collected Steps per Second: 10,716.29799
Overall Steps per Second: 9,251.47214

Timestep Collection Time: 4.66654
Timestep Consumption Time: 0.73887
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.40541

Cumulative Model Updates: 7,817
Cumulative Timesteps: 130,441,580

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 130441580...
Checkpoint 130441580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.49356
Policy Entropy: 1.20064
Value Function Loss: 4.69355

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.06383

Collected Steps per Second: 10,955.01398
Overall Steps per Second: 9,224.82954

Timestep Collection Time: 4.56540
Timestep Consumption Time: 0.85627
PPO Batch Consumption Time: 0.04653
Total Iteration Time: 5.42167

Cumulative Model Updates: 7,820
Cumulative Timesteps: 130,491,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.33587
Policy Entropy: 1.19023
Value Function Loss: 4.71536

Mean KL Divergence: 0.02959
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.04478
Value Function Update Magnitude: 0.05992

Collected Steps per Second: 10,696.98448
Overall Steps per Second: 9,087.90688

Timestep Collection Time: 4.67721
Timestep Consumption Time: 0.82813
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 5.50534

Cumulative Model Updates: 7,823
Cumulative Timesteps: 130,541,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 130541626...
Checkpoint 130541626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.23703
Policy Entropy: 1.19015
Value Function Loss: 4.91716

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.06875

Collected Steps per Second: 10,321.19387
Overall Steps per Second: 8,766.65835

Timestep Collection Time: 4.84614
Timestep Consumption Time: 0.85934
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 5.70548

Cumulative Model Updates: 7,826
Cumulative Timesteps: 130,591,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.36803
Policy Entropy: 1.18412
Value Function Loss: 4.79063

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.06796

Collected Steps per Second: 10,566.73389
Overall Steps per Second: 9,065.38199

Timestep Collection Time: 4.73391
Timestep Consumption Time: 0.78400
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.51791

Cumulative Model Updates: 7,829
Cumulative Timesteps: 130,641,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 130641666...
Checkpoint 130641666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.07923
Policy Entropy: 1.17815
Value Function Loss: 4.84618

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.04180
Value Function Update Magnitude: 0.06697

Collected Steps per Second: 10,955.72344
Overall Steps per Second: 9,467.40812

Timestep Collection Time: 4.56455
Timestep Consumption Time: 0.71757
PPO Batch Consumption Time: 0.03819
Total Iteration Time: 5.28212

Cumulative Model Updates: 7,832
Cumulative Timesteps: 130,691,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.84971
Policy Entropy: 1.18083
Value Function Loss: 4.82831

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.04319
Value Function Update Magnitude: 0.08180

Collected Steps per Second: 10,827.63913
Overall Steps per Second: 9,170.00222

Timestep Collection Time: 4.61892
Timestep Consumption Time: 0.83495
PPO Batch Consumption Time: 0.04476
Total Iteration Time: 5.45387

Cumulative Model Updates: 7,835
Cumulative Timesteps: 130,741,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 130741686...
Checkpoint 130741686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.91668
Policy Entropy: 1.18476
Value Function Loss: 4.92763

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.04633
Value Function Update Magnitude: 0.08184

Collected Steps per Second: 10,756.75471
Overall Steps per Second: 9,152.10004

Timestep Collection Time: 4.64954
Timestep Consumption Time: 0.81521
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 5.46476

Cumulative Model Updates: 7,838
Cumulative Timesteps: 130,791,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.02356
Policy Entropy: 1.15738
Value Function Loss: 4.94454

Mean KL Divergence: 0.03815
SB3 Clip Fraction: 0.16335
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.07017

Collected Steps per Second: 10,511.69402
Overall Steps per Second: 8,887.14718

Timestep Collection Time: 4.75794
Timestep Consumption Time: 0.86974
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.62768

Cumulative Model Updates: 7,841
Cumulative Timesteps: 130,841,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 130841714...
Checkpoint 130841714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.84185
Policy Entropy: 1.18200
Value Function Loss: 5.20533

Mean KL Divergence: 0.03029
SB3 Clip Fraction: 0.15989
Policy Update Magnitude: 0.04443
Value Function Update Magnitude: 0.06557

Collected Steps per Second: 10,765.54048
Overall Steps per Second: 9,121.99902

Timestep Collection Time: 4.64742
Timestep Consumption Time: 0.83734
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 5.48476

Cumulative Model Updates: 7,844
Cumulative Timesteps: 130,891,746

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.41095
Policy Entropy: 1.17816
Value Function Loss: 5.08408

Mean KL Divergence: 0.03320
SB3 Clip Fraction: 0.14701
Policy Update Magnitude: 0.03663
Value Function Update Magnitude: 0.07695

Collected Steps per Second: 10,815.93306
Overall Steps per Second: 9,267.66047

Timestep Collection Time: 4.62466
Timestep Consumption Time: 0.77260
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 5.39726

Cumulative Model Updates: 7,847
Cumulative Timesteps: 130,941,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 130941766...
Checkpoint 130941766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.38161
Policy Entropy: 1.18800
Value Function Loss: 4.87965

Mean KL Divergence: 0.02657
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.03684
Value Function Update Magnitude: 0.07543

Collected Steps per Second: 10,741.98990
Overall Steps per Second: 9,088.72438

Timestep Collection Time: 4.65687
Timestep Consumption Time: 0.84710
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 5.50396

Cumulative Model Updates: 7,850
Cumulative Timesteps: 130,991,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.32404
Policy Entropy: 1.17566
Value Function Loss: 4.75304

Mean KL Divergence: 0.02715
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.03677
Value Function Update Magnitude: 0.06586

Collected Steps per Second: 10,728.64827
Overall Steps per Second: 9,075.39888

Timestep Collection Time: 4.66210
Timestep Consumption Time: 0.84929
PPO Batch Consumption Time: 0.04019
Total Iteration Time: 5.51138

Cumulative Model Updates: 7,853
Cumulative Timesteps: 131,041,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 131041808...
Checkpoint 131041808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.09981
Policy Entropy: 1.17977
Value Function Loss: 4.56850

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.04348
Value Function Update Magnitude: 0.07192

Collected Steps per Second: 11,053.44771
Overall Steps per Second: 9,309.97281

Timestep Collection Time: 4.52528
Timestep Consumption Time: 0.84745
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 5.37273

Cumulative Model Updates: 7,856
Cumulative Timesteps: 131,091,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.12595
Policy Entropy: 1.18099
Value Function Loss: 4.68374

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.06745

Collected Steps per Second: 10,142.42519
Overall Steps per Second: 8,741.77299

Timestep Collection Time: 4.92998
Timestep Consumption Time: 0.78991
PPO Batch Consumption Time: 0.04405
Total Iteration Time: 5.71989

Cumulative Model Updates: 7,859
Cumulative Timesteps: 131,141,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 131141830...
Checkpoint 131141830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.92692
Policy Entropy: 1.18345
Value Function Loss: 4.62283

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.06383

Collected Steps per Second: 10,843.71460
Overall Steps per Second: 9,359.20323

Timestep Collection Time: 4.61115
Timestep Consumption Time: 0.73140
PPO Batch Consumption Time: 0.04325
Total Iteration Time: 5.34255

Cumulative Model Updates: 7,862
Cumulative Timesteps: 131,191,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.86332
Policy Entropy: 1.19065
Value Function Loss: 4.90669

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.08119

Collected Steps per Second: 10,976.99202
Overall Steps per Second: 9,236.78727

Timestep Collection Time: 4.55608
Timestep Consumption Time: 0.85836
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 5.41444

Cumulative Model Updates: 7,865
Cumulative Timesteps: 131,241,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 131241844...
Checkpoint 131241844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.00192
Policy Entropy: 1.18734
Value Function Loss: 4.82808

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.09807

Collected Steps per Second: 10,899.93308
Overall Steps per Second: 9,209.66695

Timestep Collection Time: 4.58755
Timestep Consumption Time: 0.84196
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 5.42951

Cumulative Model Updates: 7,868
Cumulative Timesteps: 131,291,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.13399
Policy Entropy: 1.18269
Value Function Loss: 4.75067

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.10484

Collected Steps per Second: 11,473.39134
Overall Steps per Second: 9,576.59409

Timestep Collection Time: 4.36000
Timestep Consumption Time: 0.86357
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 5.22357

Cumulative Model Updates: 7,871
Cumulative Timesteps: 131,341,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 131341872...
Checkpoint 131341872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.61289
Policy Entropy: 1.17654
Value Function Loss: 4.72212

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.10727

Collected Steps per Second: 10,424.36801
Overall Steps per Second: 8,810.39611

Timestep Collection Time: 4.79895
Timestep Consumption Time: 0.87912
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 5.67806

Cumulative Model Updates: 7,874
Cumulative Timesteps: 131,391,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.47817
Policy Entropy: 1.20161
Value Function Loss: 4.72343

Mean KL Divergence: 0.02835
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.11881

Collected Steps per Second: 10,818.28534
Overall Steps per Second: 9,254.07044

Timestep Collection Time: 4.62254
Timestep Consumption Time: 0.78135
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 5.40389

Cumulative Model Updates: 7,877
Cumulative Timesteps: 131,441,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 131441906...
Checkpoint 131441906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.60337
Policy Entropy: 1.18432
Value Function Loss: 4.99416

Mean KL Divergence: 0.03025
SB3 Clip Fraction: 0.14266
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.10771

Collected Steps per Second: 11,101.73126
Overall Steps per Second: 9,282.95305

Timestep Collection Time: 4.50398
Timestep Consumption Time: 0.88245
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.38643

Cumulative Model Updates: 7,880
Cumulative Timesteps: 131,491,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.16076
Policy Entropy: 1.19710
Value Function Loss: 5.03993

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.04238
Value Function Update Magnitude: 0.11138

Collected Steps per Second: 11,086.50202
Overall Steps per Second: 9,308.77264

Timestep Collection Time: 4.51215
Timestep Consumption Time: 0.86170
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 5.37386

Cumulative Model Updates: 7,883
Cumulative Timesteps: 131,541,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 131541932...
Checkpoint 131541932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.29782
Policy Entropy: 1.18800
Value Function Loss: 5.25677

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.04262
Value Function Update Magnitude: 0.09612

Collected Steps per Second: 10,336.27428
Overall Steps per Second: 8,990.11072

Timestep Collection Time: 4.83830
Timestep Consumption Time: 0.72448
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 5.56278

Cumulative Model Updates: 7,886
Cumulative Timesteps: 131,591,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.67751
Policy Entropy: 1.20684
Value Function Loss: 4.90566

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.09544

Collected Steps per Second: 10,668.55928
Overall Steps per Second: 9,093.45615

Timestep Collection Time: 4.68686
Timestep Consumption Time: 0.81182
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 5.49868

Cumulative Model Updates: 7,889
Cumulative Timesteps: 131,641,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 131641944...
Checkpoint 131641944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.19191
Policy Entropy: 1.18583
Value Function Loss: 4.89190

Mean KL Divergence: 0.03401
SB3 Clip Fraction: 0.15900
Policy Update Magnitude: 0.03782
Value Function Update Magnitude: 0.10308

Collected Steps per Second: 10,083.54749
Overall Steps per Second: 8,818.81803

Timestep Collection Time: 4.95917
Timestep Consumption Time: 0.71121
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 5.67037

Cumulative Model Updates: 7,892
Cumulative Timesteps: 131,691,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.14750
Policy Entropy: 1.19530
Value Function Loss: 4.68997

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.03359
Value Function Update Magnitude: 0.08670

Collected Steps per Second: 10,706.91827
Overall Steps per Second: 9,128.15029

Timestep Collection Time: 4.67006
Timestep Consumption Time: 0.80772
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 5.47778

Cumulative Model Updates: 7,895
Cumulative Timesteps: 131,741,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 131741952...
Checkpoint 131741952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.58510
Policy Entropy: 1.18607
Value Function Loss: 4.87062

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.03508
Value Function Update Magnitude: 0.07436

Collected Steps per Second: 10,730.74895
Overall Steps per Second: 9,156.17063

Timestep Collection Time: 4.66249
Timestep Consumption Time: 0.80180
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 5.46429

Cumulative Model Updates: 7,898
Cumulative Timesteps: 131,791,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.36077
Policy Entropy: 1.20191
Value Function Loss: 4.65154

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 10,697.83871
Overall Steps per Second: 9,222.13146

Timestep Collection Time: 4.67571
Timestep Consumption Time: 0.74820
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 5.42391

Cumulative Model Updates: 7,901
Cumulative Timesteps: 131,842,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 131842004...
Checkpoint 131842004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.25146
Policy Entropy: 1.18695
Value Function Loss: 4.66082

Mean KL Divergence: 0.02784
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.03807
Value Function Update Magnitude: 0.06733

Collected Steps per Second: 10,913.68792
Overall Steps per Second: 9,074.55094

Timestep Collection Time: 4.58250
Timestep Consumption Time: 0.92873
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 5.51124

Cumulative Model Updates: 7,904
Cumulative Timesteps: 131,892,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.45474
Policy Entropy: 1.19582
Value Function Loss: 4.67051

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.06891

Collected Steps per Second: 10,053.37541
Overall Steps per Second: 8,659.84462

Timestep Collection Time: 4.97405
Timestep Consumption Time: 0.80042
PPO Batch Consumption Time: 0.04653
Total Iteration Time: 5.77447

Cumulative Model Updates: 7,907
Cumulative Timesteps: 131,942,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 131942022...
Checkpoint 131942022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.65146
Policy Entropy: 1.17137
Value Function Loss: 4.82302

Mean KL Divergence: 0.02950
SB3 Clip Fraction: 0.15018
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.06698

Collected Steps per Second: 10,041.43321
Overall Steps per Second: 8,549.76446

Timestep Collection Time: 4.97997
Timestep Consumption Time: 0.86885
PPO Batch Consumption Time: 0.04716
Total Iteration Time: 5.84882

Cumulative Model Updates: 7,910
Cumulative Timesteps: 131,992,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.55899
Policy Entropy: 1.19251
Value Function Loss: 4.91355

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.04350
Value Function Update Magnitude: 0.06636

Collected Steps per Second: 10,005.76623
Overall Steps per Second: 8,604.10294

Timestep Collection Time: 4.99772
Timestep Consumption Time: 0.81416
PPO Batch Consumption Time: 0.04579
Total Iteration Time: 5.81188

Cumulative Model Updates: 7,913
Cumulative Timesteps: 132,042,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 132042034...
Checkpoint 132042034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.65161
Policy Entropy: 1.18075
Value Function Loss: 4.75458

Mean KL Divergence: 0.02456
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.04287
Value Function Update Magnitude: 0.06647

Collected Steps per Second: 10,506.65841
Overall Steps per Second: 8,847.44180

Timestep Collection Time: 4.76098
Timestep Consumption Time: 0.89286
PPO Batch Consumption Time: 0.04408
Total Iteration Time: 5.65384

Cumulative Model Updates: 7,916
Cumulative Timesteps: 132,092,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.32943
Policy Entropy: 1.20561
Value Function Loss: 4.91998

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.08084

Collected Steps per Second: 10,144.10414
Overall Steps per Second: 8,691.57094

Timestep Collection Time: 4.92937
Timestep Consumption Time: 0.82379
PPO Batch Consumption Time: 0.04772
Total Iteration Time: 5.75316

Cumulative Model Updates: 7,919
Cumulative Timesteps: 132,142,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 132142060...
Checkpoint 132142060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.67376
Policy Entropy: 1.19333
Value Function Loss: 4.93113

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.08909

Collected Steps per Second: 9,938.29610
Overall Steps per Second: 8,560.61026

Timestep Collection Time: 5.03104
Timestep Consumption Time: 0.80966
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 5.84071

Cumulative Model Updates: 7,922
Cumulative Timesteps: 132,192,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.39512
Policy Entropy: 1.19948
Value Function Loss: 5.04754

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.07374

Collected Steps per Second: 9,797.30093
Overall Steps per Second: 8,400.31725

Timestep Collection Time: 5.10569
Timestep Consumption Time: 0.84908
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 5.95478

Cumulative Model Updates: 7,925
Cumulative Timesteps: 132,242,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 132242082...
Checkpoint 132242082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.33362
Policy Entropy: 1.20242
Value Function Loss: 4.76584

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.05214

Collected Steps per Second: 10,277.86043
Overall Steps per Second: 8,661.33501

Timestep Collection Time: 4.86599
Timestep Consumption Time: 0.90817
PPO Batch Consumption Time: 0.03823
Total Iteration Time: 5.77417

Cumulative Model Updates: 7,928
Cumulative Timesteps: 132,292,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.81903
Policy Entropy: 1.18964
Value Function Loss: 4.45590

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.05271

Collected Steps per Second: 10,443.27874
Overall Steps per Second: 8,736.85585

Timestep Collection Time: 4.78949
Timestep Consumption Time: 0.93545
PPO Batch Consumption Time: 0.03933
Total Iteration Time: 5.72494

Cumulative Model Updates: 7,931
Cumulative Timesteps: 132,342,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 132342112...
Checkpoint 132342112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.53664
Policy Entropy: 1.18507
Value Function Loss: 4.32339

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.08075

Collected Steps per Second: 10,325.13480
Overall Steps per Second: 8,709.14031

Timestep Collection Time: 4.84352
Timestep Consumption Time: 0.89872
PPO Batch Consumption Time: 0.03955
Total Iteration Time: 5.74224

Cumulative Model Updates: 7,934
Cumulative Timesteps: 132,392,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.30947
Policy Entropy: 1.19213
Value Function Loss: 4.37679

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.04538
Value Function Update Magnitude: 0.09188

Collected Steps per Second: 9,951.55571
Overall Steps per Second: 8,482.21807

Timestep Collection Time: 5.02555
Timestep Consumption Time: 0.87055
PPO Batch Consumption Time: 0.05269
Total Iteration Time: 5.89610

Cumulative Model Updates: 7,937
Cumulative Timesteps: 132,442,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 132442134...
Checkpoint 132442134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.28780
Policy Entropy: 1.19752
Value Function Loss: 4.39421

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.08625

Collected Steps per Second: 10,356.41525
Overall Steps per Second: 8,816.91772

Timestep Collection Time: 4.83044
Timestep Consumption Time: 0.84343
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 5.67386

Cumulative Model Updates: 7,940
Cumulative Timesteps: 132,492,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.29519
Policy Entropy: 1.19912
Value Function Loss: 4.39860

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.07394

Collected Steps per Second: 10,335.90770
Overall Steps per Second: 8,874.64278

Timestep Collection Time: 4.83944
Timestep Consumption Time: 0.79684
PPO Batch Consumption Time: 0.03969
Total Iteration Time: 5.63628

Cumulative Model Updates: 7,943
Cumulative Timesteps: 132,542,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 132542180...
Checkpoint 132542180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.29818
Policy Entropy: 1.18504
Value Function Loss: 4.39632

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.07118

Collected Steps per Second: 10,264.39707
Overall Steps per Second: 8,775.57117

Timestep Collection Time: 4.87354
Timestep Consumption Time: 0.82682
PPO Batch Consumption Time: 0.03952
Total Iteration Time: 5.70037

Cumulative Model Updates: 7,946
Cumulative Timesteps: 132,592,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.70817
Policy Entropy: 1.19254
Value Function Loss: 4.52498

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06364
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.08071

Collected Steps per Second: 9,957.62632
Overall Steps per Second: 8,440.22712

Timestep Collection Time: 5.02128
Timestep Consumption Time: 0.90273
PPO Batch Consumption Time: 0.04311
Total Iteration Time: 5.92401

Cumulative Model Updates: 7,949
Cumulative Timesteps: 132,642,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 132642204...
Checkpoint 132642204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.16910
Policy Entropy: 1.18196
Value Function Loss: 4.72776

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06391
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.07895

Collected Steps per Second: 10,021.97267
Overall Steps per Second: 8,504.46280

Timestep Collection Time: 4.98984
Timestep Consumption Time: 0.89037
PPO Batch Consumption Time: 0.04329
Total Iteration Time: 5.88021

Cumulative Model Updates: 7,952
Cumulative Timesteps: 132,692,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.66017
Policy Entropy: 1.17652
Value Function Loss: 4.77583

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.10636

Collected Steps per Second: 9,733.11104
Overall Steps per Second: 8,241.84951

Timestep Collection Time: 5.13875
Timestep Consumption Time: 0.92979
PPO Batch Consumption Time: 0.04678
Total Iteration Time: 6.06854

Cumulative Model Updates: 7,955
Cumulative Timesteps: 132,742,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 132742228...
Checkpoint 132742228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.75081
Policy Entropy: 1.18159
Value Function Loss: 4.82074

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06571
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.10205

Collected Steps per Second: 10,281.67890
Overall Steps per Second: 8,848.50934

Timestep Collection Time: 4.86380
Timestep Consumption Time: 0.78778
PPO Batch Consumption Time: 0.03884
Total Iteration Time: 5.65157

Cumulative Model Updates: 7,958
Cumulative Timesteps: 132,792,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.25488
Policy Entropy: 1.18830
Value Function Loss: 4.81562

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.09673

Collected Steps per Second: 9,795.48823
Overall Steps per Second: 8,293.04856

Timestep Collection Time: 5.10521
Timestep Consumption Time: 0.92490
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 6.03011

Cumulative Model Updates: 7,961
Cumulative Timesteps: 132,842,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 132842244...
Checkpoint 132842244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.97062
Policy Entropy: 1.19460
Value Function Loss: 4.78380

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05553
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.07992

Collected Steps per Second: 9,633.18935
Overall Steps per Second: 8,244.89008

Timestep Collection Time: 5.19309
Timestep Consumption Time: 0.87443
PPO Batch Consumption Time: 0.04809
Total Iteration Time: 6.06752

Cumulative Model Updates: 7,964
Cumulative Timesteps: 132,892,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.53136
Policy Entropy: 1.19086
Value Function Loss: 4.81867

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06148
Policy Update Magnitude: 0.06236
Value Function Update Magnitude: 0.08473

Collected Steps per Second: 10,334.94947
Overall Steps per Second: 8,840.83128

Timestep Collection Time: 4.83989
Timestep Consumption Time: 0.81795
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.65784

Cumulative Model Updates: 7,967
Cumulative Timesteps: 132,942,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 132942290...
Checkpoint 132942290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.40102
Policy Entropy: 1.19037
Value Function Loss: 4.63740

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06792
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.06916

Collected Steps per Second: 9,557.12758
Overall Steps per Second: 8,274.52611

Timestep Collection Time: 5.23463
Timestep Consumption Time: 0.81140
PPO Batch Consumption Time: 0.04035
Total Iteration Time: 6.04603

Cumulative Model Updates: 7,970
Cumulative Timesteps: 132,992,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.42437
Policy Entropy: 1.18226
Value Function Loss: 4.99013

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.06089

Collected Steps per Second: 10,111.23102
Overall Steps per Second: 8,704.47948

Timestep Collection Time: 4.94599
Timestep Consumption Time: 0.79933
PPO Batch Consumption Time: 0.04692
Total Iteration Time: 5.74532

Cumulative Model Updates: 7,973
Cumulative Timesteps: 133,042,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 133042328...
Checkpoint 133042328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.29196
Policy Entropy: 1.18249
Value Function Loss: 4.86763

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.06505
Value Function Update Magnitude: 0.05665

Collected Steps per Second: 10,143.15419
Overall Steps per Second: 8,644.58119

Timestep Collection Time: 4.92943
Timestep Consumption Time: 0.85454
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.78397

Cumulative Model Updates: 7,976
Cumulative Timesteps: 133,092,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.35263
Policy Entropy: 1.17519
Value Function Loss: 5.00655

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.04750

Collected Steps per Second: 10,111.83373
Overall Steps per Second: 8,679.34566

Timestep Collection Time: 4.94569
Timestep Consumption Time: 0.81626
PPO Batch Consumption Time: 0.03888
Total Iteration Time: 5.76196

Cumulative Model Updates: 7,979
Cumulative Timesteps: 133,142,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 133142338...
Checkpoint 133142338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.35906
Policy Entropy: 1.18641
Value Function Loss: 4.79539

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.05719

Collected Steps per Second: 10,248.14972
Overall Steps per Second: 8,872.88470

Timestep Collection Time: 4.88166
Timestep Consumption Time: 0.75664
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 5.63830

Cumulative Model Updates: 7,982
Cumulative Timesteps: 133,192,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.19861
Policy Entropy: 1.19094
Value Function Loss: 4.88205

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.04829

Collected Steps per Second: 9,792.86591
Overall Steps per Second: 8,360.59680

Timestep Collection Time: 5.10678
Timestep Consumption Time: 0.87485
PPO Batch Consumption Time: 0.04749
Total Iteration Time: 5.98163

Cumulative Model Updates: 7,985
Cumulative Timesteps: 133,242,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 133242376...
Checkpoint 133242376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.14453
Policy Entropy: 1.18575
Value Function Loss: 4.63700

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.06325
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.04376

Collected Steps per Second: 10,135.64957
Overall Steps per Second: 8,754.79210

Timestep Collection Time: 4.93525
Timestep Consumption Time: 0.77842
PPO Batch Consumption Time: 0.03933
Total Iteration Time: 5.71367

Cumulative Model Updates: 7,988
Cumulative Timesteps: 133,292,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.23765
Policy Entropy: 1.18753
Value Function Loss: 4.75454

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.04868

Collected Steps per Second: 10,383.09653
Overall Steps per Second: 8,625.42142

Timestep Collection Time: 4.81706
Timestep Consumption Time: 0.98161
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 5.79867

Cumulative Model Updates: 7,991
Cumulative Timesteps: 133,342,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 133342414...
Checkpoint 133342414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.19565
Policy Entropy: 1.19611
Value Function Loss: 4.60669

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.04335

Collected Steps per Second: 10,281.19779
Overall Steps per Second: 8,730.64126

Timestep Collection Time: 4.86402
Timestep Consumption Time: 0.86385
PPO Batch Consumption Time: 0.04865
Total Iteration Time: 5.72787

Cumulative Model Updates: 7,994
Cumulative Timesteps: 133,392,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.17661
Policy Entropy: 1.19580
Value Function Loss: 4.64486

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.07671
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.04522

Collected Steps per Second: 10,323.77507
Overall Steps per Second: 8,812.32243

Timestep Collection Time: 4.84532
Timestep Consumption Time: 0.83105
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.67637

Cumulative Model Updates: 7,997
Cumulative Timesteps: 133,442,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 133442444...
Checkpoint 133442444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.72315
Policy Entropy: 1.19198
Value Function Loss: 4.63394

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.03918
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 10,074.91559
Overall Steps per Second: 8,612.92814

Timestep Collection Time: 4.96381
Timestep Consumption Time: 0.84257
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 5.80639

Cumulative Model Updates: 8,000
Cumulative Timesteps: 133,492,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.31170
Policy Entropy: 1.18210
Value Function Loss: 4.77782

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.05523
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.04312

Collected Steps per Second: 10,669.84292
Overall Steps per Second: 9,065.98446

Timestep Collection Time: 4.68779
Timestep Consumption Time: 0.82931
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 5.51711

Cumulative Model Updates: 8,003
Cumulative Timesteps: 133,542,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 133542472...
Checkpoint 133542472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.99104
Policy Entropy: 1.18601
Value Function Loss: 4.98009

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.04169

Collected Steps per Second: 10,623.87421
Overall Steps per Second: 8,922.03750

Timestep Collection Time: 4.70732
Timestep Consumption Time: 0.89790
PPO Batch Consumption Time: 0.04563
Total Iteration Time: 5.60522

Cumulative Model Updates: 8,006
Cumulative Timesteps: 133,592,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.87433
Policy Entropy: 1.16026
Value Function Loss: 4.94078

Mean KL Divergence: 0.04456
SB3 Clip Fraction: 0.16216
Policy Update Magnitude: 0.06998
Value Function Update Magnitude: 0.04083

Collected Steps per Second: 10,594.17553
Overall Steps per Second: 8,982.50287

Timestep Collection Time: 4.71995
Timestep Consumption Time: 0.84687
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 5.56682

Cumulative Model Updates: 8,009
Cumulative Timesteps: 133,642,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 133642486...
Checkpoint 133642486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.30314
Policy Entropy: 1.18239
Value Function Loss: 5.05181

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.04179

Collected Steps per Second: 10,358.92717
Overall Steps per Second: 8,819.79473

Timestep Collection Time: 4.82714
Timestep Consumption Time: 0.84238
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 5.66952

Cumulative Model Updates: 8,012
Cumulative Timesteps: 133,692,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.22707
Policy Entropy: 1.18074
Value Function Loss: 4.78538

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.03713

Collected Steps per Second: 9,882.03189
Overall Steps per Second: 8,382.12477

Timestep Collection Time: 5.06272
Timestep Consumption Time: 0.90593
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 5.96865

Cumulative Model Updates: 8,015
Cumulative Timesteps: 133,742,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 133742520...
Checkpoint 133742520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.25532
Policy Entropy: 1.18751
Value Function Loss: 4.74398

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.03731

Collected Steps per Second: 10,331.38818
Overall Steps per Second: 8,984.95550

Timestep Collection Time: 4.84078
Timestep Consumption Time: 0.72541
PPO Batch Consumption Time: 0.03927
Total Iteration Time: 5.56619

Cumulative Model Updates: 8,018
Cumulative Timesteps: 133,792,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.10328
Policy Entropy: 1.18910
Value Function Loss: 4.72567

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.05064

Collected Steps per Second: 10,282.96178
Overall Steps per Second: 8,732.77069

Timestep Collection Time: 4.86319
Timestep Consumption Time: 0.86329
PPO Batch Consumption Time: 0.03953
Total Iteration Time: 5.72648

Cumulative Model Updates: 8,021
Cumulative Timesteps: 133,842,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 133842540...
Checkpoint 133842540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.81163
Policy Entropy: 1.16772
Value Function Loss: 4.88203

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.04797

Collected Steps per Second: 10,235.89742
Overall Steps per Second: 8,766.27148

Timestep Collection Time: 4.88575
Timestep Consumption Time: 0.81907
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 5.70482

Cumulative Model Updates: 8,024
Cumulative Timesteps: 133,892,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.89276
Policy Entropy: 1.17894
Value Function Loss: 4.78112

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.05365

Collected Steps per Second: 10,220.13369
Overall Steps per Second: 8,735.34950

Timestep Collection Time: 4.89504
Timestep Consumption Time: 0.83203
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 5.72707

Cumulative Model Updates: 8,027
Cumulative Timesteps: 133,942,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 133942578...
Checkpoint 133942578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.58364
Policy Entropy: 1.18481
Value Function Loss: 4.64445

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.05022

Collected Steps per Second: 10,298.68598
Overall Steps per Second: 8,757.31431

Timestep Collection Time: 4.85712
Timestep Consumption Time: 0.85490
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 5.71203

Cumulative Model Updates: 8,030
Cumulative Timesteps: 133,992,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.33301
Policy Entropy: 1.18070
Value Function Loss: 4.63188

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.06712
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.04424

Collected Steps per Second: 10,013.08367
Overall Steps per Second: 8,674.17190

Timestep Collection Time: 4.99546
Timestep Consumption Time: 0.77108
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 5.76654

Cumulative Model Updates: 8,033
Cumulative Timesteps: 134,042,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 134042620...
Checkpoint 134042620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.30294
Policy Entropy: 1.17577
Value Function Loss: 4.67626

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.04582

Collected Steps per Second: 10,156.10685
Overall Steps per Second: 8,670.00522

Timestep Collection Time: 4.92531
Timestep Consumption Time: 0.84423
PPO Batch Consumption Time: 0.03955
Total Iteration Time: 5.76955

Cumulative Model Updates: 8,036
Cumulative Timesteps: 134,092,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.11274
Policy Entropy: 1.18084
Value Function Loss: 4.69887

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.06881
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 10,107.91427
Overall Steps per Second: 8,661.34471

Timestep Collection Time: 4.94899
Timestep Consumption Time: 0.82655
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 5.77555

Cumulative Model Updates: 8,039
Cumulative Timesteps: 134,142,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 134142666...
Checkpoint 134142666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.63425
Policy Entropy: 1.18048
Value Function Loss: 4.57409

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.04354

Collected Steps per Second: 10,329.36003
Overall Steps per Second: 8,823.59173

Timestep Collection Time: 4.84193
Timestep Consumption Time: 0.82629
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 5.66821

Cumulative Model Updates: 8,042
Cumulative Timesteps: 134,192,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.48214
Policy Entropy: 1.18250
Value Function Loss: 4.49844

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.07621
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.07031

Collected Steps per Second: 10,291.54459
Overall Steps per Second: 8,795.38559

Timestep Collection Time: 4.86049
Timestep Consumption Time: 0.82681
PPO Batch Consumption Time: 0.04711
Total Iteration Time: 5.68730

Cumulative Model Updates: 8,045
Cumulative Timesteps: 134,242,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 134242702...
Checkpoint 134242702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.67316
Policy Entropy: 1.17311
Value Function Loss: 4.69374

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.08795

Collected Steps per Second: 9,574.27014
Overall Steps per Second: 8,344.54688

Timestep Collection Time: 5.22505
Timestep Consumption Time: 0.77001
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 5.99505

Cumulative Model Updates: 8,048
Cumulative Timesteps: 134,292,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.44432
Policy Entropy: 1.19103
Value Function Loss: 4.74638

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.09447

Collected Steps per Second: 9,994.14753
Overall Steps per Second: 8,484.38578

Timestep Collection Time: 5.00353
Timestep Consumption Time: 0.89036
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 5.89389

Cumulative Model Updates: 8,051
Cumulative Timesteps: 134,342,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 134342734...
Checkpoint 134342734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.42319
Policy Entropy: 1.16658
Value Function Loss: 5.02345

Mean KL Divergence: 0.02834
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.09498

Collected Steps per Second: 10,000.96298
Overall Steps per Second: 8,565.73751

Timestep Collection Time: 5.00112
Timestep Consumption Time: 0.83796
PPO Batch Consumption Time: 0.04163
Total Iteration Time: 5.83908

Cumulative Model Updates: 8,054
Cumulative Timesteps: 134,392,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.66826
Policy Entropy: 1.18125
Value Function Loss: 5.05242

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.08345

Collected Steps per Second: 10,241.81441
Overall Steps per Second: 8,692.61753

Timestep Collection Time: 4.88351
Timestep Consumption Time: 0.87034
PPO Batch Consumption Time: 0.03969
Total Iteration Time: 5.75385

Cumulative Model Updates: 8,057
Cumulative Timesteps: 134,442,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 134442766...
Checkpoint 134442766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.00170
Policy Entropy: 1.16830
Value Function Loss: 4.91849

Mean KL Divergence: 0.03071
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.07175

Collected Steps per Second: 9,788.52757
Overall Steps per Second: 8,241.87061

Timestep Collection Time: 5.10945
Timestep Consumption Time: 0.95883
PPO Batch Consumption Time: 0.04912
Total Iteration Time: 6.06828

Cumulative Model Updates: 8,060
Cumulative Timesteps: 134,492,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.45418
Policy Entropy: 1.18514
Value Function Loss: 4.72503

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.07648

Collected Steps per Second: 9,717.09233
Overall Steps per Second: 8,401.61910

Timestep Collection Time: 5.14660
Timestep Consumption Time: 0.80582
PPO Batch Consumption Time: 0.04863
Total Iteration Time: 5.95242

Cumulative Model Updates: 8,063
Cumulative Timesteps: 134,542,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 134542790...
Checkpoint 134542790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.09339
Policy Entropy: 1.15605
Value Function Loss: 4.69454

Mean KL Divergence: 0.03543
SB3 Clip Fraction: 0.15142
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.07116

Collected Steps per Second: 10,122.10364
Overall Steps per Second: 8,601.40285

Timestep Collection Time: 4.94206
Timestep Consumption Time: 0.87374
PPO Batch Consumption Time: 0.04638
Total Iteration Time: 5.81580

Cumulative Model Updates: 8,066
Cumulative Timesteps: 134,592,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.29564
Policy Entropy: 1.17298
Value Function Loss: 4.62362

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.07471

Collected Steps per Second: 10,260.59781
Overall Steps per Second: 8,709.09649

Timestep Collection Time: 4.87574
Timestep Consumption Time: 0.86860
PPO Batch Consumption Time: 0.03931
Total Iteration Time: 5.74434

Cumulative Model Updates: 8,069
Cumulative Timesteps: 134,642,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 134642842...
Checkpoint 134642842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.57445
Policy Entropy: 1.16048
Value Function Loss: 4.41680

Mean KL Divergence: 0.03002
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.06279

Collected Steps per Second: 10,228.88255
Overall Steps per Second: 8,807.60150

Timestep Collection Time: 4.88831
Timestep Consumption Time: 0.78883
PPO Batch Consumption Time: 0.04424
Total Iteration Time: 5.67714

Cumulative Model Updates: 8,072
Cumulative Timesteps: 134,692,844

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.72532
Policy Entropy: 1.17796
Value Function Loss: 4.29368

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.06183

Collected Steps per Second: 10,222.62548
Overall Steps per Second: 8,697.56564

Timestep Collection Time: 4.89111
Timestep Consumption Time: 0.85762
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 5.74874

Cumulative Model Updates: 8,075
Cumulative Timesteps: 134,742,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 134742844...
Checkpoint 134742844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.74659
Policy Entropy: 1.16950
Value Function Loss: 4.34451

Mean KL Divergence: 0.02645
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.06122

Collected Steps per Second: 9,660.90572
Overall Steps per Second: 8,369.50575

Timestep Collection Time: 5.17674
Timestep Consumption Time: 0.79876
PPO Batch Consumption Time: 0.04172
Total Iteration Time: 5.97550

Cumulative Model Updates: 8,078
Cumulative Timesteps: 134,792,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.80083
Policy Entropy: 1.18073
Value Function Loss: 4.61859

Mean KL Divergence: 0.02319
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.08147

Collected Steps per Second: 10,483.88387
Overall Steps per Second: 8,923.45574

Timestep Collection Time: 4.76922
Timestep Consumption Time: 0.83399
PPO Batch Consumption Time: 0.04192
Total Iteration Time: 5.60321

Cumulative Model Updates: 8,081
Cumulative Timesteps: 134,842,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 134842856...
Checkpoint 134842856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.80360
Policy Entropy: 1.17082
Value Function Loss: 4.48114

Mean KL Divergence: 0.02553
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.07798

Collected Steps per Second: 10,026.80027
Overall Steps per Second: 8,561.79329

Timestep Collection Time: 4.98943
Timestep Consumption Time: 0.85374
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 5.84317

Cumulative Model Updates: 8,084
Cumulative Timesteps: 134,892,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.69961
Policy Entropy: 1.18443
Value Function Loss: 4.54799

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 10,460.56611
Overall Steps per Second: 9,081.22961

Timestep Collection Time: 4.78081
Timestep Consumption Time: 0.72615
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 5.50696

Cumulative Model Updates: 8,087
Cumulative Timesteps: 134,942,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 134942894...
Checkpoint 134942894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.33108
Policy Entropy: 1.17890
Value Function Loss: 4.64138

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.08914

Collected Steps per Second: 10,360.76550
Overall Steps per Second: 8,776.77436

Timestep Collection Time: 4.82783
Timestep Consumption Time: 0.87130
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 5.69913

Cumulative Model Updates: 8,090
Cumulative Timesteps: 134,992,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.01430
Policy Entropy: 1.17966
Value Function Loss: 4.86432

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.06325
Value Function Update Magnitude: 0.08048

Collected Steps per Second: 9,899.55199
Overall Steps per Second: 8,448.58724

Timestep Collection Time: 5.05134
Timestep Consumption Time: 0.86752
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 5.91886

Cumulative Model Updates: 8,093
Cumulative Timesteps: 135,042,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 135042920...
Checkpoint 135042920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.08551
Policy Entropy: 1.18983
Value Function Loss: 4.90717

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.06603
Value Function Update Magnitude: 0.07504

Collected Steps per Second: 10,302.74388
Overall Steps per Second: 8,787.16684

Timestep Collection Time: 4.85482
Timestep Consumption Time: 0.83734
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 5.69216

Cumulative Model Updates: 8,096
Cumulative Timesteps: 135,092,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.18722
Policy Entropy: 1.18410
Value Function Loss: 4.80261

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.06888
Policy Update Magnitude: 0.06855
Value Function Update Magnitude: 0.08181

Collected Steps per Second: 10,441.17078
Overall Steps per Second: 8,770.93618

Timestep Collection Time: 4.79065
Timestep Consumption Time: 0.91228
PPO Batch Consumption Time: 0.04638
Total Iteration Time: 5.70293

Cumulative Model Updates: 8,099
Cumulative Timesteps: 135,142,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 135142958...
Checkpoint 135142958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.44649
Policy Entropy: 1.18358
Value Function Loss: 4.84157

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06221
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.07535

Collected Steps per Second: 10,426.30220
Overall Steps per Second: 8,969.67498

Timestep Collection Time: 4.79767
Timestep Consumption Time: 0.77912
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 5.57679

Cumulative Model Updates: 8,102
Cumulative Timesteps: 135,192,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.11881
Policy Entropy: 1.18956
Value Function Loss: 4.91605

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.06977
Value Function Update Magnitude: 0.07653

Collected Steps per Second: 10,469.88607
Overall Steps per Second: 8,905.26519

Timestep Collection Time: 4.77598
Timestep Consumption Time: 0.83912
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.61511

Cumulative Model Updates: 8,105
Cumulative Timesteps: 135,242,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 135242984...
Checkpoint 135242984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.99715
Policy Entropy: 1.18401
Value Function Loss: 4.64998

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.07152
Policy Update Magnitude: 0.06071
Value Function Update Magnitude: 0.06974

Collected Steps per Second: 10,333.50634
Overall Steps per Second: 8,650.55059

Timestep Collection Time: 4.84134
Timestep Consumption Time: 0.94188
PPO Batch Consumption Time: 0.04655
Total Iteration Time: 5.78322

Cumulative Model Updates: 8,108
Cumulative Timesteps: 135,293,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.50867
Policy Entropy: 1.18074
Value Function Loss: 4.45017

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.06766

Collected Steps per Second: 9,944.72396
Overall Steps per Second: 8,486.99458

Timestep Collection Time: 5.02880
Timestep Consumption Time: 0.86375
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 5.89255

Cumulative Model Updates: 8,111
Cumulative Timesteps: 135,343,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 135343022...
Checkpoint 135343022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.63245
Policy Entropy: 1.16953
Value Function Loss: 4.38243

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.09137

Collected Steps per Second: 10,131.58688
Overall Steps per Second: 8,655.75250

Timestep Collection Time: 4.93743
Timestep Consumption Time: 0.84185
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 5.77928

Cumulative Model Updates: 8,114
Cumulative Timesteps: 135,393,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.32981
Policy Entropy: 1.17534
Value Function Loss: 4.76434

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.08578

Collected Steps per Second: 9,545.34375
Overall Steps per Second: 8,352.56731

Timestep Collection Time: 5.24025
Timestep Consumption Time: 0.74833
PPO Batch Consumption Time: 0.04206
Total Iteration Time: 5.98858

Cumulative Model Updates: 8,117
Cumulative Timesteps: 135,443,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 135443066...
Checkpoint 135443066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.36337
Policy Entropy: 1.17665
Value Function Loss: 4.77836

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.08643

Collected Steps per Second: 10,269.66157
Overall Steps per Second: 8,555.44722

Timestep Collection Time: 4.87027
Timestep Consumption Time: 0.97583
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 5.84610

Cumulative Model Updates: 8,120
Cumulative Timesteps: 135,493,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.64910
Policy Entropy: 1.17423
Value Function Loss: 4.70955

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.10119

Collected Steps per Second: 10,380.22638
Overall Steps per Second: 8,804.44385

Timestep Collection Time: 4.81781
Timestep Consumption Time: 0.86227
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 5.68009

Cumulative Model Updates: 8,123
Cumulative Timesteps: 135,543,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 135543092...
Checkpoint 135543092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.50199
Policy Entropy: 1.18227
Value Function Loss: 4.57584

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.06286
Value Function Update Magnitude: 0.09196

Collected Steps per Second: 10,192.85982
Overall Steps per Second: 8,644.97349

Timestep Collection Time: 4.90853
Timestep Consumption Time: 0.87888
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.78741

Cumulative Model Updates: 8,126
Cumulative Timesteps: 135,593,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.99737
Policy Entropy: 1.18712
Value Function Loss: 4.85615

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.07542

Collected Steps per Second: 10,767.73392
Overall Steps per Second: 9,110.90275

Timestep Collection Time: 4.64369
Timestep Consumption Time: 0.84446
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 5.48815

Cumulative Model Updates: 8,129
Cumulative Timesteps: 135,643,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 135643126...
Checkpoint 135643126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.08568
Policy Entropy: 1.16591
Value Function Loss: 4.73104

Mean KL Divergence: 0.04335
SB3 Clip Fraction: 0.15733
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.07196

Collected Steps per Second: 10,309.47510
Overall Steps per Second: 8,771.76939

Timestep Collection Time: 4.85204
Timestep Consumption Time: 0.85057
PPO Batch Consumption Time: 0.05311
Total Iteration Time: 5.70261

Cumulative Model Updates: 8,132
Cumulative Timesteps: 135,693,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.20463
Policy Entropy: 1.18251
Value Function Loss: 4.88860

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 10,499.17758
Overall Steps per Second: 8,911.61757

Timestep Collection Time: 4.76380
Timestep Consumption Time: 0.84865
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 5.61245

Cumulative Model Updates: 8,135
Cumulative Timesteps: 135,743,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 135743164...
Checkpoint 135743164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.87983
Policy Entropy: 1.16735
Value Function Loss: 4.65634

Mean KL Divergence: 0.03277
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.04380
Value Function Update Magnitude: 0.07375

Collected Steps per Second: 10,283.08533
Overall Steps per Second: 8,942.37889

Timestep Collection Time: 4.86547
Timestep Consumption Time: 0.72947
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 5.59493

Cumulative Model Updates: 8,138
Cumulative Timesteps: 135,793,196

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.41061
Policy Entropy: 1.18720
Value Function Loss: 4.89373

Mean KL Divergence: 0.02415
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.06596

Collected Steps per Second: 9,993.52922
Overall Steps per Second: 8,598.68608

Timestep Collection Time: 5.00604
Timestep Consumption Time: 0.81206
PPO Batch Consumption Time: 0.04032
Total Iteration Time: 5.81810

Cumulative Model Updates: 8,141
Cumulative Timesteps: 135,843,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 135843224...
Checkpoint 135843224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.60011
Policy Entropy: 1.16738
Value Function Loss: 4.77501

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.06235

Collected Steps per Second: 10,405.43821
Overall Steps per Second: 8,895.66631

Timestep Collection Time: 4.80633
Timestep Consumption Time: 0.81573
PPO Batch Consumption Time: 0.05079
Total Iteration Time: 5.62206

Cumulative Model Updates: 8,144
Cumulative Timesteps: 135,893,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.08627
Policy Entropy: 1.18655
Value Function Loss: 4.86121

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 10,420.82381
Overall Steps per Second: 8,838.90116

Timestep Collection Time: 4.79847
Timestep Consumption Time: 0.85880
PPO Batch Consumption Time: 0.04741
Total Iteration Time: 5.65726

Cumulative Model Updates: 8,147
Cumulative Timesteps: 135,943,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 135943240...
Checkpoint 135943240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.53157
Policy Entropy: 1.18123
Value Function Loss: 4.61818

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.07397

Collected Steps per Second: 10,351.42594
Overall Steps per Second: 8,843.42785

Timestep Collection Time: 4.83025
Timestep Consumption Time: 0.82366
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.65392

Cumulative Model Updates: 8,150
Cumulative Timesteps: 135,993,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.33380
Policy Entropy: 1.18672
Value Function Loss: 4.62928

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.06907

Collected Steps per Second: 10,399.27873
Overall Steps per Second: 8,976.52226

Timestep Collection Time: 4.80841
Timestep Consumption Time: 0.76212
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 5.57053

Cumulative Model Updates: 8,153
Cumulative Timesteps: 136,043,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 136043244...
Checkpoint 136043244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.15299
Policy Entropy: 1.18089
Value Function Loss: 4.51687

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.06609

Collected Steps per Second: 10,096.84699
Overall Steps per Second: 8,630.35649

Timestep Collection Time: 4.95283
Timestep Consumption Time: 0.84160
PPO Batch Consumption Time: 0.04418
Total Iteration Time: 5.79443

Cumulative Model Updates: 8,156
Cumulative Timesteps: 136,093,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.20205
Policy Entropy: 1.17776
Value Function Loss: 4.53232

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.07637

Collected Steps per Second: 10,359.70429
Overall Steps per Second: 8,896.74446

Timestep Collection Time: 4.82852
Timestep Consumption Time: 0.79399
PPO Batch Consumption Time: 0.04452
Total Iteration Time: 5.62251

Cumulative Model Updates: 8,159
Cumulative Timesteps: 136,143,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 136143274...
Checkpoint 136143274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.94771
Policy Entropy: 1.17405
Value Function Loss: 4.44523

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.06300
Value Function Update Magnitude: 0.08669

Collected Steps per Second: 10,582.17154
Overall Steps per Second: 9,025.43995

Timestep Collection Time: 4.72701
Timestep Consumption Time: 0.81533
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 5.54233

Cumulative Model Updates: 8,162
Cumulative Timesteps: 136,193,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.15524
Policy Entropy: 1.18869
Value Function Loss: 4.48317

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.09466

Collected Steps per Second: 10,293.54340
Overall Steps per Second: 8,733.21163

Timestep Collection Time: 4.85877
Timestep Consumption Time: 0.86810
PPO Batch Consumption Time: 0.03919
Total Iteration Time: 5.72687

Cumulative Model Updates: 8,165
Cumulative Timesteps: 136,243,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 136243310...
Checkpoint 136243310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.53130
Policy Entropy: 1.19172
Value Function Loss: 4.49904

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.10491

Collected Steps per Second: 10,483.53278
Overall Steps per Second: 9,071.75380

Timestep Collection Time: 4.77110
Timestep Consumption Time: 0.74250
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.51360

Cumulative Model Updates: 8,168
Cumulative Timesteps: 136,293,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.17638
Policy Entropy: 1.17238
Value Function Loss: 4.47929

Mean KL Divergence: 0.03478
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.07703
Value Function Update Magnitude: 0.09939

Collected Steps per Second: 10,448.81615
Overall Steps per Second: 8,740.78992

Timestep Collection Time: 4.78523
Timestep Consumption Time: 0.93508
PPO Batch Consumption Time: 0.04094
Total Iteration Time: 5.72031

Cumulative Model Updates: 8,171
Cumulative Timesteps: 136,343,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 136343328...
Checkpoint 136343328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.54701
Policy Entropy: 1.18956
Value Function Loss: 4.60758

Mean KL Divergence: 0.02810
SB3 Clip Fraction: 0.15617
Policy Update Magnitude: 0.06268
Value Function Update Magnitude: 0.09235

Collected Steps per Second: 10,316.88765
Overall Steps per Second: 8,864.49122

Timestep Collection Time: 4.84797
Timestep Consumption Time: 0.79431
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 5.64229

Cumulative Model Updates: 8,174
Cumulative Timesteps: 136,393,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.83566
Policy Entropy: 1.17387
Value Function Loss: 4.73385

Mean KL Divergence: 0.03140
SB3 Clip Fraction: 0.14892
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.08625

Collected Steps per Second: 10,690.98208
Overall Steps per Second: 9,004.83228

Timestep Collection Time: 4.67908
Timestep Consumption Time: 0.87616
PPO Batch Consumption Time: 0.03983
Total Iteration Time: 5.55524

Cumulative Model Updates: 8,177
Cumulative Timesteps: 136,443,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 136443368...
Checkpoint 136443368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.09229
Policy Entropy: 1.19402
Value Function Loss: 4.63839

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.07733

Collected Steps per Second: 10,527.66229
Overall Steps per Second: 8,913.01551

Timestep Collection Time: 4.75148
Timestep Consumption Time: 0.86076
PPO Batch Consumption Time: 0.04686
Total Iteration Time: 5.61224

Cumulative Model Updates: 8,180
Cumulative Timesteps: 136,493,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.25923
Policy Entropy: 1.18062
Value Function Loss: 4.67978

Mean KL Divergence: 0.02940
SB3 Clip Fraction: 0.15145
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.07926

Collected Steps per Second: 10,483.49031
Overall Steps per Second: 8,951.37566

Timestep Collection Time: 4.77055
Timestep Consumption Time: 0.81653
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 5.58707

Cumulative Model Updates: 8,183
Cumulative Timesteps: 136,543,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 136543402...
Checkpoint 136543402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.47666
Policy Entropy: 1.18979
Value Function Loss: 4.63151

Mean KL Divergence: 0.02630
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.07312

Collected Steps per Second: 10,495.56538
Overall Steps per Second: 8,920.51513

Timestep Collection Time: 4.76601
Timestep Consumption Time: 0.84151
PPO Batch Consumption Time: 0.03940
Total Iteration Time: 5.60752

Cumulative Model Updates: 8,186
Cumulative Timesteps: 136,593,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.62229
Policy Entropy: 1.17530
Value Function Loss: 4.66139

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.09217

Collected Steps per Second: 9,920.82160
Overall Steps per Second: 8,609.33409

Timestep Collection Time: 5.04313
Timestep Consumption Time: 0.76824
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.81137

Cumulative Model Updates: 8,189
Cumulative Timesteps: 136,643,456

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 136643456...
Checkpoint 136643456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.13994
Policy Entropy: 1.19152
Value Function Loss: 4.53907

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.10564

Collected Steps per Second: 10,565.12879
Overall Steps per Second: 8,946.76505

Timestep Collection Time: 4.73482
Timestep Consumption Time: 0.85647
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 5.59129

Cumulative Model Updates: 8,192
Cumulative Timesteps: 136,693,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.43657
Policy Entropy: 1.17816
Value Function Loss: 4.75049

Mean KL Divergence: 0.02895
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.10583

Collected Steps per Second: 10,483.42494
Overall Steps per Second: 8,878.49751

Timestep Collection Time: 4.77096
Timestep Consumption Time: 0.86243
PPO Batch Consumption Time: 0.04326
Total Iteration Time: 5.63339

Cumulative Model Updates: 8,195
Cumulative Timesteps: 136,743,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 136743496...
Checkpoint 136743496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.79999
Policy Entropy: 1.20000
Value Function Loss: 5.08279

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.10286

Collected Steps per Second: 10,580.12475
Overall Steps per Second: 9,016.81317

Timestep Collection Time: 4.72811
Timestep Consumption Time: 0.81975
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.54786

Cumulative Model Updates: 8,198
Cumulative Timesteps: 136,793,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.87309
Policy Entropy: 1.19047
Value Function Loss: 4.95063

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 10,320.19725
Overall Steps per Second: 8,716.02165

Timestep Collection Time: 4.84623
Timestep Consumption Time: 0.89194
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.73817

Cumulative Model Updates: 8,201
Cumulative Timesteps: 136,843,534

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 136843534...
Checkpoint 136843534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.55184
Policy Entropy: 1.17882
Value Function Loss: 4.90899

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.10771

Collected Steps per Second: 9,801.70567
Overall Steps per Second: 8,505.18492

Timestep Collection Time: 5.10217
Timestep Consumption Time: 0.77777
PPO Batch Consumption Time: 0.04434
Total Iteration Time: 5.87994

Cumulative Model Updates: 8,204
Cumulative Timesteps: 136,893,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.91600
Policy Entropy: 1.19090
Value Function Loss: 4.67282

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.10318

Collected Steps per Second: 10,250.90388
Overall Steps per Second: 8,723.09106

Timestep Collection Time: 4.87937
Timestep Consumption Time: 0.85460
PPO Batch Consumption Time: 0.04526
Total Iteration Time: 5.73398

Cumulative Model Updates: 8,207
Cumulative Timesteps: 136,943,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 136943562...
Checkpoint 136943562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.80856
Policy Entropy: 1.17789
Value Function Loss: 4.88369

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.10950

Collected Steps per Second: 10,153.93780
Overall Steps per Second: 8,727.85070

Timestep Collection Time: 4.92774
Timestep Consumption Time: 0.80517
PPO Batch Consumption Time: 0.03886
Total Iteration Time: 5.73291

Cumulative Model Updates: 8,210
Cumulative Timesteps: 136,993,598

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.39241
Policy Entropy: 1.18470
Value Function Loss: 4.87721

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.10754

Collected Steps per Second: 10,430.55241
Overall Steps per Second: 8,860.93815

Timestep Collection Time: 4.79419
Timestep Consumption Time: 0.84924
PPO Batch Consumption Time: 0.03989
Total Iteration Time: 5.64342

Cumulative Model Updates: 8,213
Cumulative Timesteps: 137,043,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 137043604...
Checkpoint 137043604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.92839
Policy Entropy: 1.18118
Value Function Loss: 4.87583

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.11494

Collected Steps per Second: 10,181.16970
Overall Steps per Second: 8,428.90905

Timestep Collection Time: 4.91260
Timestep Consumption Time: 1.02127
PPO Batch Consumption Time: 0.05219
Total Iteration Time: 5.93386

Cumulative Model Updates: 8,216
Cumulative Timesteps: 137,093,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.68440
Policy Entropy: 1.18416
Value Function Loss: 4.84698

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.10576

Collected Steps per Second: 8,866.74277
Overall Steps per Second: 6,466.81722

Timestep Collection Time: 5.64108
Timestep Consumption Time: 2.09348
PPO Batch Consumption Time: 0.42663
Total Iteration Time: 7.73456

Cumulative Model Updates: 8,219
Cumulative Timesteps: 137,143,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 137143638...
Checkpoint 137143638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.41974
Policy Entropy: 1.15989
Value Function Loss: 4.74736

Mean KL Divergence: 0.03624
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.06171
Value Function Update Magnitude: 0.09225

Collected Steps per Second: 9,190.24671
Overall Steps per Second: 7,928.01410

Timestep Collection Time: 5.44294
Timestep Consumption Time: 0.86658
PPO Batch Consumption Time: 0.04705
Total Iteration Time: 6.30952

Cumulative Model Updates: 8,222
Cumulative Timesteps: 137,193,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.35316
Policy Entropy: 1.17294
Value Function Loss: 4.86799

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 10,097.54779
Overall Steps per Second: 8,593.14063

Timestep Collection Time: 4.95348
Timestep Consumption Time: 0.86721
PPO Batch Consumption Time: 0.04604
Total Iteration Time: 5.82069

Cumulative Model Updates: 8,225
Cumulative Timesteps: 137,243,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 137243678...
Checkpoint 137243678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.64575
Policy Entropy: 1.16856
Value Function Loss: 4.78271

Mean KL Divergence: 0.02825
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.04101
Value Function Update Magnitude: 0.11612

Collected Steps per Second: 10,493.16468
Overall Steps per Second: 8,878.65203

Timestep Collection Time: 4.76634
Timestep Consumption Time: 0.86672
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 5.63306

Cumulative Model Updates: 8,228
Cumulative Timesteps: 137,293,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.48160
Policy Entropy: 1.18258
Value Function Loss: 4.62727

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.10992

Collected Steps per Second: 10,374.73004
Overall Steps per Second: 8,806.53712

Timestep Collection Time: 4.82191
Timestep Consumption Time: 0.85864
PPO Batch Consumption Time: 0.04178
Total Iteration Time: 5.68055

Cumulative Model Updates: 8,231
Cumulative Timesteps: 137,343,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 137343718...
Checkpoint 137343718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.84082
Policy Entropy: 1.17465
Value Function Loss: 4.67464

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.10311

Collected Steps per Second: 9,663.10933
Overall Steps per Second: 8,454.28312

Timestep Collection Time: 5.17618
Timestep Consumption Time: 0.74011
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.91629

Cumulative Model Updates: 8,234
Cumulative Timesteps: 137,393,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.15018
Policy Entropy: 1.18437
Value Function Loss: 4.63057

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.09842

Collected Steps per Second: 10,383.89587
Overall Steps per Second: 8,740.70625

Timestep Collection Time: 4.81707
Timestep Consumption Time: 0.90558
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 5.72265

Cumulative Model Updates: 8,237
Cumulative Timesteps: 137,443,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 137443756...
Checkpoint 137443756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.31219
Policy Entropy: 1.17233
Value Function Loss: 4.73195

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.09029

Collected Steps per Second: 10,279.27571
Overall Steps per Second: 8,920.56508

Timestep Collection Time: 4.86610
Timestep Consumption Time: 0.74117
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 5.60727

Cumulative Model Updates: 8,240
Cumulative Timesteps: 137,493,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.49527
Policy Entropy: 1.18209
Value Function Loss: 4.58239

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.07547

Collected Steps per Second: 10,450.74054
Overall Steps per Second: 8,805.95780

Timestep Collection Time: 4.78473
Timestep Consumption Time: 0.89370
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 5.67843

Cumulative Model Updates: 8,243
Cumulative Timesteps: 137,543,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 137543780...
Checkpoint 137543780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.95342
Policy Entropy: 1.17591
Value Function Loss: 4.71277

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.06668

Collected Steps per Second: 9,877.00943
Overall Steps per Second: 8,323.63106

Timestep Collection Time: 5.06307
Timestep Consumption Time: 0.94488
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 6.00795

Cumulative Model Updates: 8,246
Cumulative Timesteps: 137,593,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.17757
Policy Entropy: 1.17463
Value Function Loss: 4.55099

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.06613

Collected Steps per Second: 9,271.53354
Overall Steps per Second: 8,070.95288

Timestep Collection Time: 5.39566
Timestep Consumption Time: 0.80262
PPO Batch Consumption Time: 0.04791
Total Iteration Time: 6.19828

Cumulative Model Updates: 8,249
Cumulative Timesteps: 137,643,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 137643814...
Checkpoint 137643814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.63915
Policy Entropy: 1.16247
Value Function Loss: 4.56899

Mean KL Divergence: 0.02651
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.07021

Collected Steps per Second: 10,171.16085
Overall Steps per Second: 8,674.53681

Timestep Collection Time: 4.91743
Timestep Consumption Time: 0.84841
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.76584

Cumulative Model Updates: 8,252
Cumulative Timesteps: 137,693,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.21094
Policy Entropy: 1.19074
Value Function Loss: 4.58190

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.06739

Collected Steps per Second: 9,946.42272
Overall Steps per Second: 8,559.66223

Timestep Collection Time: 5.02995
Timestep Consumption Time: 0.81491
PPO Batch Consumption Time: 0.04683
Total Iteration Time: 5.84486

Cumulative Model Updates: 8,255
Cumulative Timesteps: 137,743,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 137743860...
Checkpoint 137743860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.99575
Policy Entropy: 1.17191
Value Function Loss: 4.79204

Mean KL Divergence: 0.02924
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.08198

Collected Steps per Second: 10,438.68955
Overall Steps per Second: 8,911.41871

Timestep Collection Time: 4.79236
Timestep Consumption Time: 0.82133
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 5.61370

Cumulative Model Updates: 8,258
Cumulative Timesteps: 137,793,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.80620
Policy Entropy: 1.18512
Value Function Loss: 4.84916

Mean KL Divergence: 0.02375
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.03891
Value Function Update Magnitude: 0.09129

Collected Steps per Second: 10,317.68546
Overall Steps per Second: 8,779.78396

Timestep Collection Time: 4.84837
Timestep Consumption Time: 0.84926
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 5.69763

Cumulative Model Updates: 8,261
Cumulative Timesteps: 137,843,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 137843910...
Checkpoint 137843910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.69470
Policy Entropy: 1.16232
Value Function Loss: 4.80649

Mean KL Divergence: 0.02813
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.08925

Collected Steps per Second: 10,155.06676
Overall Steps per Second: 8,555.68497

Timestep Collection Time: 4.92601
Timestep Consumption Time: 0.92086
PPO Batch Consumption Time: 0.04703
Total Iteration Time: 5.84687

Cumulative Model Updates: 8,264
Cumulative Timesteps: 137,893,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.75364
Policy Entropy: 1.17565
Value Function Loss: 4.83628

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.07652

Collected Steps per Second: 10,293.75573
Overall Steps per Second: 8,816.10536

Timestep Collection Time: 4.85809
Timestep Consumption Time: 0.81426
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 5.67235

Cumulative Model Updates: 8,267
Cumulative Timesteps: 137,943,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 137943942...
Checkpoint 137943942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.83376
Policy Entropy: 1.17690
Value Function Loss: 4.78389

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.04344
Value Function Update Magnitude: 0.06689

Collected Steps per Second: 10,193.53203
Overall Steps per Second: 8,830.36903

Timestep Collection Time: 4.90762
Timestep Consumption Time: 0.75760
PPO Batch Consumption Time: 0.03919
Total Iteration Time: 5.66522

Cumulative Model Updates: 8,270
Cumulative Timesteps: 137,993,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.63544
Policy Entropy: 1.17876
Value Function Loss: 4.81129

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 8,490.06257
Overall Steps per Second: 7,210.11015

Timestep Collection Time: 5.89159
Timestep Consumption Time: 1.04589
PPO Batch Consumption Time: 0.04326
Total Iteration Time: 6.93748

Cumulative Model Updates: 8,273
Cumulative Timesteps: 138,043,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 138043988...
Checkpoint 138043988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.38274
Policy Entropy: 1.18833
Value Function Loss: 4.65893

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.07525

Collected Steps per Second: 6,277.87105
Overall Steps per Second: 4,717.40321

Timestep Collection Time: 7.97117
Timestep Consumption Time: 2.63678
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 10.60795

Cumulative Model Updates: 8,276
Cumulative Timesteps: 138,094,030

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.49098
Policy Entropy: 1.18759
Value Function Loss: 4.78163

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.04265
Value Function Update Magnitude: 0.07168

Collected Steps per Second: 4,364.59671
Overall Steps per Second: 3,578.98223

Timestep Collection Time: 11.46223
Timestep Consumption Time: 2.51605
PPO Batch Consumption Time: 0.06328
Total Iteration Time: 13.97828

Cumulative Model Updates: 8,279
Cumulative Timesteps: 138,144,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 138144058...
Checkpoint 138144058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.22745
Policy Entropy: 1.16942
Value Function Loss: 4.72808

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.08912

Collected Steps per Second: 4,310.80607
Overall Steps per Second: 3,499.51960

Timestep Collection Time: 11.60015
Timestep Consumption Time: 2.68924
PPO Batch Consumption Time: 0.05915
Total Iteration Time: 14.28939

Cumulative Model Updates: 8,282
Cumulative Timesteps: 138,194,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.74119
Policy Entropy: 1.17827
Value Function Loss: 4.78698

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.10577
Policy Update Magnitude: 0.04264
Value Function Update Magnitude: 0.08334

Collected Steps per Second: 4,181.81695
Overall Steps per Second: 3,454.83562

Timestep Collection Time: 11.95987
Timestep Consumption Time: 2.51665
PPO Batch Consumption Time: 0.06262
Total Iteration Time: 14.47652

Cumulative Model Updates: 8,285
Cumulative Timesteps: 138,244,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 138244078...
Checkpoint 138244078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.15369
Policy Entropy: 1.17441
Value Function Loss: 4.63261

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.08153

Collected Steps per Second: 4,127.22107
Overall Steps per Second: 3,344.41999

Timestep Collection Time: 12.11808
Timestep Consumption Time: 2.83638
PPO Batch Consumption Time: 0.06976
Total Iteration Time: 14.95446

Cumulative Model Updates: 8,288
Cumulative Timesteps: 138,294,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.54815
Policy Entropy: 1.16647
Value Function Loss: 4.75793

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.07894

Collected Steps per Second: 4,249.06624
Overall Steps per Second: 3,389.11480

Timestep Collection Time: 11.77529
Timestep Consumption Time: 2.98785
PPO Batch Consumption Time: 0.06203
Total Iteration Time: 14.76315

Cumulative Model Updates: 8,291
Cumulative Timesteps: 138,344,126

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 138344126...
Checkpoint 138344126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.06144
Policy Entropy: 1.16777
Value Function Loss: 4.89196

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07353
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.07697

Collected Steps per Second: 4,257.02639
Overall Steps per Second: 3,435.05990

Timestep Collection Time: 11.75515
Timestep Consumption Time: 2.81286
PPO Batch Consumption Time: 0.06263
Total Iteration Time: 14.56801

Cumulative Model Updates: 8,294
Cumulative Timesteps: 138,394,168

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.76144
Policy Entropy: 1.17375
Value Function Loss: 5.01450

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 4,257.17317
Overall Steps per Second: 3,371.65820

Timestep Collection Time: 11.74582
Timestep Consumption Time: 3.08486
PPO Batch Consumption Time: 0.05762
Total Iteration Time: 14.83068

Cumulative Model Updates: 8,297
Cumulative Timesteps: 138,444,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 138444172...
Checkpoint 138444172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.18062
Policy Entropy: 1.17270
Value Function Loss: 4.83659

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07149
Policy Update Magnitude: 0.04155
Value Function Update Magnitude: 0.06758

Collected Steps per Second: 4,284.40556
Overall Steps per Second: 3,403.62739

Timestep Collection Time: 11.67070
Timestep Consumption Time: 3.02010
PPO Batch Consumption Time: 0.06086
Total Iteration Time: 14.69080

Cumulative Model Updates: 8,300
Cumulative Timesteps: 138,494,174

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.89336
Policy Entropy: 1.16787
Value Function Loss: 4.86648

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06287
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.06830

Collected Steps per Second: 4,212.91294
Overall Steps per Second: 3,257.12471

Timestep Collection Time: 11.87919
Timestep Consumption Time: 3.48589
PPO Batch Consumption Time: 0.06818
Total Iteration Time: 15.36509

Cumulative Model Updates: 8,303
Cumulative Timesteps: 138,544,220

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 138544220...
Checkpoint 138544220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.84119
Policy Entropy: 1.15566
Value Function Loss: 4.78482

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.09395

Collected Steps per Second: 4,145.86079
Overall Steps per Second: 3,374.56276

Timestep Collection Time: 12.06939
Timestep Consumption Time: 2.75861
PPO Batch Consumption Time: 0.06177
Total Iteration Time: 14.82800

Cumulative Model Updates: 8,306
Cumulative Timesteps: 138,594,258

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.43838
Policy Entropy: 1.18324
Value Function Loss: 4.77453

Mean KL Divergence: 0.03133
SB3 Clip Fraction: 0.15733
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.09425

Collected Steps per Second: 4,256.13291
Overall Steps per Second: 3,461.16865

Timestep Collection Time: 11.75997
Timestep Consumption Time: 2.70104
PPO Batch Consumption Time: 0.05896
Total Iteration Time: 14.46101

Cumulative Model Updates: 8,309
Cumulative Timesteps: 138,644,310

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 138644310...
Checkpoint 138644310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.42430
Policy Entropy: 1.17506
Value Function Loss: 4.82864

Mean KL Divergence: 0.02830
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.09120

Collected Steps per Second: 4,247.30260
Overall Steps per Second: 3,450.04137

Timestep Collection Time: 11.77877
Timestep Consumption Time: 2.72193
PPO Batch Consumption Time: 0.05988
Total Iteration Time: 14.50070

Cumulative Model Updates: 8,312
Cumulative Timesteps: 138,694,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.32193
Policy Entropy: 1.18344
Value Function Loss: 4.76510

Mean KL Divergence: 0.02693
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.10449

Collected Steps per Second: 4,341.10033
Overall Steps per Second: 3,534.00116

Timestep Collection Time: 11.52150
Timestep Consumption Time: 2.63129
PPO Batch Consumption Time: 0.05822
Total Iteration Time: 14.15280

Cumulative Model Updates: 8,315
Cumulative Timesteps: 138,744,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 138744354...
Checkpoint 138744354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.98750
Policy Entropy: 1.16269
Value Function Loss: 4.99205

Mean KL Divergence: 0.03374
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.08676

Collected Steps per Second: 4,231.47656
Overall Steps per Second: 3,474.17229

Timestep Collection Time: 11.82897
Timestep Consumption Time: 2.57849
PPO Batch Consumption Time: 0.05821
Total Iteration Time: 14.40746

Cumulative Model Updates: 8,318
Cumulative Timesteps: 138,794,408

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.13489
Policy Entropy: 1.17128
Value Function Loss: 4.95281

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.04196
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 4,111.44165
Overall Steps per Second: 3,337.29708

Timestep Collection Time: 12.16654
Timestep Consumption Time: 2.82224
PPO Batch Consumption Time: 0.16534
Total Iteration Time: 14.98878

Cumulative Model Updates: 8,321
Cumulative Timesteps: 138,844,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 138844430...
Checkpoint 138844430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.94751
Policy Entropy: 1.15886
Value Function Loss: 4.99528

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.05676

Collected Steps per Second: 4,562.02545
Overall Steps per Second: 3,619.33993

Timestep Collection Time: 10.96574
Timestep Consumption Time: 2.85611
PPO Batch Consumption Time: 0.06316
Total Iteration Time: 13.82186

Cumulative Model Updates: 8,324
Cumulative Timesteps: 138,894,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.28635
Policy Entropy: 1.18384
Value Function Loss: 4.72576

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.04106
Value Function Update Magnitude: 0.05085

Collected Steps per Second: 4,456.69021
Overall Steps per Second: 3,633.96216

Timestep Collection Time: 11.21999
Timestep Consumption Time: 2.54020
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 13.76019

Cumulative Model Updates: 8,327
Cumulative Timesteps: 138,944,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 138944460...
Checkpoint 138944460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.93035
Policy Entropy: 1.17749
Value Function Loss: 4.84920

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.05369

Collected Steps per Second: 4,102.43623
Overall Steps per Second: 3,374.42122

Timestep Collection Time: 12.19178
Timestep Consumption Time: 2.63032
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 14.82210

Cumulative Model Updates: 8,330
Cumulative Timesteps: 138,994,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.89762
Policy Entropy: 1.19606
Value Function Loss: 4.70331

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.04204
Value Function Update Magnitude: 0.04784

Collected Steps per Second: 4,108.66921
Overall Steps per Second: 3,381.28473

Timestep Collection Time: 12.17913
Timestep Consumption Time: 2.61998
PPO Batch Consumption Time: 0.06077
Total Iteration Time: 14.79911

Cumulative Model Updates: 8,333
Cumulative Timesteps: 139,044,516

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 139044516...
Checkpoint 139044516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.15455
Policy Entropy: 1.17557
Value Function Loss: 4.77681

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.04022
Value Function Update Magnitude: 0.06666

Collected Steps per Second: 4,150.98615
Overall Steps per Second: 3,442.11784

Timestep Collection Time: 12.04629
Timestep Consumption Time: 2.48081
PPO Batch Consumption Time: 0.06167
Total Iteration Time: 14.52710

Cumulative Model Updates: 8,336
Cumulative Timesteps: 139,094,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.05485
Policy Entropy: 1.18551
Value Function Loss: 4.82063

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.07582

Collected Steps per Second: 4,454.27871
Overall Steps per Second: 3,615.58681

Timestep Collection Time: 11.22651
Timestep Consumption Time: 2.60416
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 13.83067

Cumulative Model Updates: 8,339
Cumulative Timesteps: 139,144,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 139144526...
Checkpoint 139144526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.39156
Policy Entropy: 1.17255
Value Function Loss: 4.82157

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.09232

Collected Steps per Second: 4,152.35258
Overall Steps per Second: 3,435.65956

Timestep Collection Time: 12.05293
Timestep Consumption Time: 2.51429
PPO Batch Consumption Time: 0.06414
Total Iteration Time: 14.56722

Cumulative Model Updates: 8,342
Cumulative Timesteps: 139,194,574

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.26302
Policy Entropy: 1.18902
Value Function Loss: 4.92182

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.09343

Collected Steps per Second: 4,166.48502
Overall Steps per Second: 3,412.47192

Timestep Collection Time: 12.00820
Timestep Consumption Time: 2.65331
PPO Batch Consumption Time: 0.06587
Total Iteration Time: 14.66151

Cumulative Model Updates: 8,345
Cumulative Timesteps: 139,244,606

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 139244606...
Checkpoint 139244606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.58035
Policy Entropy: 1.18868
Value Function Loss: 4.74316

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.08200

Collected Steps per Second: 4,449.47933
Overall Steps per Second: 3,668.61446

Timestep Collection Time: 11.23997
Timestep Consumption Time: 2.39243
PPO Batch Consumption Time: 0.05967
Total Iteration Time: 13.63239

Cumulative Model Updates: 8,348
Cumulative Timesteps: 139,294,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.46643
Policy Entropy: 1.18214
Value Function Loss: 4.78811

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.07048

Collected Steps per Second: 4,524.06384
Overall Steps per Second: 3,695.03613

Timestep Collection Time: 11.05599
Timestep Consumption Time: 2.48055
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 13.53654

Cumulative Model Updates: 8,351
Cumulative Timesteps: 139,344,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 139344636...
Checkpoint 139344636 saved!
