Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 367,609.56234
Policy Entropy: 1.09581
Value Function Loss: 100.71889

Mean KL Divergence: -0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.03092
Value Function Update Magnitude: 0.03965

Collected Steps per Second: 8,668.86920
Overall Steps per Second: 7,020.19475

Timestep Collection Time: 5.76869
Timestep Consumption Time: 1.35476
PPO Batch Consumption Time: 0.55742
Total Iteration Time: 7.12345

Cumulative Model Updates: 32,470
Cumulative Timesteps: 541,675,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375,174.15741
Policy Entropy: 1.09862
Value Function Loss: 95.80096

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.04078
Policy Update Magnitude: 0.02865
Value Function Update Magnitude: 0.03916

Collected Steps per Second: 10,814.33981
Overall Steps per Second: 9,389.97073

Timestep Collection Time: 4.62423
Timestep Consumption Time: 0.70145
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 5.32568

Cumulative Model Updates: 32,471
Cumulative Timesteps: 541,725,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 541725050...
Checkpoint 541725050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339,476.14062
Policy Entropy: 1.10960
Value Function Loss: 97.84751

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.07059

Collected Steps per Second: 11,549.30343
Overall Steps per Second: 9,697.17714

Timestep Collection Time: 4.33117
Timestep Consumption Time: 0.82724
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 5.15841

Cumulative Model Updates: 32,473
Cumulative Timesteps: 541,775,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,222.19804
Policy Entropy: 1.12346
Value Function Loss: 92.26040

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.08954
Value Function Update Magnitude: 0.09924

Collected Steps per Second: 10,665.66807
Overall Steps per Second: 9,122.46348

Timestep Collection Time: 4.68925
Timestep Consumption Time: 0.79326
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 5.48251

Cumulative Model Updates: 32,476
Cumulative Timesteps: 541,825,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 541825086...
Checkpoint 541825086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407,331.15100
Policy Entropy: 1.12001
Value Function Loss: 86.21090

Mean KL Divergence: 0.02270
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.08756
Value Function Update Magnitude: 0.11740

Collected Steps per Second: 11,201.26086
Overall Steps per Second: 9,640.76041

Timestep Collection Time: 4.46450
Timestep Consumption Time: 0.72265
PPO Batch Consumption Time: 0.03341
Total Iteration Time: 5.18714

Cumulative Model Updates: 32,479
Cumulative Timesteps: 541,875,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,426.69966
Policy Entropy: 1.12344
Value Function Loss: 81.29486

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.08615
Value Function Update Magnitude: 0.09951

Collected Steps per Second: 11,309.19773
Overall Steps per Second: 9,614.05410

Timestep Collection Time: 4.42153
Timestep Consumption Time: 0.77960
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.20114

Cumulative Model Updates: 32,482
Cumulative Timesteps: 541,925,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 541925098...
Checkpoint 541925098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254,473.71329
Policy Entropy: 1.11726
Value Function Loss: 73.93564

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.08638
Value Function Update Magnitude: 0.08078

Collected Steps per Second: 11,220.29742
Overall Steps per Second: 9,543.86238

Timestep Collection Time: 4.45746
Timestep Consumption Time: 0.78298
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.24044

Cumulative Model Updates: 32,485
Cumulative Timesteps: 541,975,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305,826.33153
Policy Entropy: 1.13490
Value Function Loss: 70.01684

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.07186
Value Function Update Magnitude: 0.06615

Collected Steps per Second: 12,126.00957
Overall Steps per Second: 10,172.86241

Timestep Collection Time: 4.12568
Timestep Consumption Time: 0.79211
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.91779

Cumulative Model Updates: 32,488
Cumulative Timesteps: 542,025,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 542025140...
Checkpoint 542025140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,463.67758
Policy Entropy: 1.13800
Value Function Loss: 62.51293

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.06665
Value Function Update Magnitude: 0.06671

Collected Steps per Second: 11,806.95891
Overall Steps per Second: 10,044.89886

Timestep Collection Time: 4.23716
Timestep Consumption Time: 0.74328
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 4.98044

Cumulative Model Updates: 32,491
Cumulative Timesteps: 542,075,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258,167.31408
Policy Entropy: 1.12500
Value Function Loss: 62.12473

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.06518
Value Function Update Magnitude: 0.08143

Collected Steps per Second: 11,369.06651
Overall Steps per Second: 9,785.34890

Timestep Collection Time: 4.39843
Timestep Consumption Time: 0.71187
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.11029

Cumulative Model Updates: 32,494
Cumulative Timesteps: 542,125,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 542125174...
Checkpoint 542125174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305,372.86869
Policy Entropy: 1.09746
Value Function Loss: 60.23694

Mean KL Divergence: 0.04555
SB3 Clip Fraction: 0.19361
Policy Update Magnitude: 0.06742
Value Function Update Magnitude: 0.10003

Collected Steps per Second: 12,308.42579
Overall Steps per Second: 10,225.94426

Timestep Collection Time: 4.06405
Timestep Consumption Time: 0.82763
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 4.89168

Cumulative Model Updates: 32,497
Cumulative Timesteps: 542,175,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,840.65155
Policy Entropy: 1.13751
Value Function Loss: 60.64557

Mean KL Divergence: 0.03699
SB3 Clip Fraction: 0.19973
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.11005

Collected Steps per Second: 12,181.06604
Overall Steps per Second: 10,198.46168

Timestep Collection Time: 4.10703
Timestep Consumption Time: 0.79842
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.90545

Cumulative Model Updates: 32,500
Cumulative Timesteps: 542,225,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 542225224...
Checkpoint 542225224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,018.40624
Policy Entropy: 1.10858
Value Function Loss: 59.62599

Mean KL Divergence: 0.05226
SB3 Clip Fraction: 0.22207
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.10106

Collected Steps per Second: 12,728.48542
Overall Steps per Second: 10,544.08876

Timestep Collection Time: 3.93024
Timestep Consumption Time: 0.81422
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 4.74446

Cumulative Model Updates: 32,503
Cumulative Timesteps: 542,275,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356,931.72015
Policy Entropy: 1.13423
Value Function Loss: 60.88531

Mean KL Divergence: 0.03910
SB3 Clip Fraction: 0.19649
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.08546

Collected Steps per Second: 12,225.61505
Overall Steps per Second: 10,226.57109

Timestep Collection Time: 4.09141
Timestep Consumption Time: 0.79977
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 4.89118

Cumulative Model Updates: 32,506
Cumulative Timesteps: 542,325,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 542325270...
Checkpoint 542325270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372,608.89525
Policy Entropy: 1.11343
Value Function Loss: 60.33927

Mean KL Divergence: 0.04341
SB3 Clip Fraction: 0.19311
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.07434

Collected Steps per Second: 11,780.21145
Overall Steps per Second: 10,105.28452

Timestep Collection Time: 4.24644
Timestep Consumption Time: 0.70384
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.95028

Cumulative Model Updates: 32,509
Cumulative Timesteps: 542,375,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325,518.48802
Policy Entropy: 1.12934
Value Function Loss: 58.63177

Mean KL Divergence: 0.02558
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 11,669.29465
Overall Steps per Second: 9,831.74724

Timestep Collection Time: 4.28509
Timestep Consumption Time: 0.80088
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.08597

Cumulative Model Updates: 32,512
Cumulative Timesteps: 542,425,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 542425298...
Checkpoint 542425298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286,551.80396
Policy Entropy: 1.12279
Value Function Loss: 58.58412

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.09539

Collected Steps per Second: 12,321.46950
Overall Steps per Second: 10,495.55170

Timestep Collection Time: 4.05942
Timestep Consumption Time: 0.70622
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.76564

Cumulative Model Updates: 32,515
Cumulative Timesteps: 542,475,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,351.26168
Policy Entropy: 1.11208
Value Function Loss: 58.38287

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.06978
Value Function Update Magnitude: 0.08578

Collected Steps per Second: 12,163.61144
Overall Steps per Second: 10,228.02698

Timestep Collection Time: 4.11276
Timestep Consumption Time: 0.77831
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.89107

Cumulative Model Updates: 32,518
Cumulative Timesteps: 542,525,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 542525342...
Checkpoint 542525342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,634.89766
Policy Entropy: 1.12024
Value Function Loss: 59.40622

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.08517

Collected Steps per Second: 12,001.53163
Overall Steps per Second: 10,027.32029

Timestep Collection Time: 4.16863
Timestep Consumption Time: 0.82073
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 4.98937

Cumulative Model Updates: 32,521
Cumulative Timesteps: 542,575,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417,150.00884
Policy Entropy: 1.12328
Value Function Loss: 57.59213

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.10366

Collected Steps per Second: 12,012.58417
Overall Steps per Second: 10,221.31800

Timestep Collection Time: 4.16313
Timestep Consumption Time: 0.72958
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.89272

Cumulative Model Updates: 32,524
Cumulative Timesteps: 542,625,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 542625382...
Checkpoint 542625382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303,133.29795
Policy Entropy: 1.11096
Value Function Loss: 57.43696

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.10834

Collected Steps per Second: 12,188.42929
Overall Steps per Second: 10,194.39851

Timestep Collection Time: 4.10406
Timestep Consumption Time: 0.80276
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.90681

Cumulative Model Updates: 32,527
Cumulative Timesteps: 542,675,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318,819.09122
Policy Entropy: 1.11459
Value Function Loss: 57.80581

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 11,683.10336
Overall Steps per Second: 9,976.19337

Timestep Collection Time: 4.27986
Timestep Consumption Time: 0.73228
PPO Batch Consumption Time: 0.03778
Total Iteration Time: 5.01213

Cumulative Model Updates: 32,530
Cumulative Timesteps: 542,725,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 542725406...
Checkpoint 542725406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375,146.45741
Policy Entropy: 1.12778
Value Function Loss: 60.33013

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.10428

Collected Steps per Second: 12,151.41388
Overall Steps per Second: 10,240.97148

Timestep Collection Time: 4.11491
Timestep Consumption Time: 0.76763
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 4.88254

Cumulative Model Updates: 32,533
Cumulative Timesteps: 542,775,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,278.99967
Policy Entropy: 1.12701
Value Function Loss: 61.64198

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.09897

Collected Steps per Second: 11,854.86325
Overall Steps per Second: 10,100.10587

Timestep Collection Time: 4.21903
Timestep Consumption Time: 0.73300
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 4.95203

Cumulative Model Updates: 32,536
Cumulative Timesteps: 542,825,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 542825424...
Checkpoint 542825424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378,911.16964
Policy Entropy: 1.10597
Value Function Loss: 61.05448

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.09776

Collected Steps per Second: 11,909.58941
Overall Steps per Second: 10,057.58761

Timestep Collection Time: 4.19964
Timestep Consumption Time: 0.77332
PPO Batch Consumption Time: 0.03346
Total Iteration Time: 4.97296

Cumulative Model Updates: 32,539
Cumulative Timesteps: 542,875,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350,047.29755
Policy Entropy: 1.08801
Value Function Loss: 57.71391

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.16249
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.08592

Collected Steps per Second: 11,872.16693
Overall Steps per Second: 10,041.81398

Timestep Collection Time: 4.21187
Timestep Consumption Time: 0.76771
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.97958

Cumulative Model Updates: 32,542
Cumulative Timesteps: 542,925,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 542925444...
Checkpoint 542925444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375,592.50085
Policy Entropy: 1.10913
Value Function Loss: 56.39807

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.08459

Collected Steps per Second: 11,635.42439
Overall Steps per Second: 10,036.84651

Timestep Collection Time: 4.29963
Timestep Consumption Time: 0.68481
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.98443

Cumulative Model Updates: 32,545
Cumulative Timesteps: 542,975,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399,035.04153
Policy Entropy: 1.09791
Value Function Loss: 55.97040

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.07572

Collected Steps per Second: 11,295.02777
Overall Steps per Second: 9,597.32966

Timestep Collection Time: 4.42850
Timestep Consumption Time: 0.78337
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.21187

Cumulative Model Updates: 32,548
Cumulative Timesteps: 543,025,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 543025492...
Checkpoint 543025492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397,769.60578
Policy Entropy: 1.07356
Value Function Loss: 56.69229

Mean KL Divergence: 0.03401
SB3 Clip Fraction: 0.17583
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.08665

Collected Steps per Second: 11,604.49010
Overall Steps per Second: 9,869.06366

Timestep Collection Time: 4.31075
Timestep Consumption Time: 0.75802
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.06877

Cumulative Model Updates: 32,551
Cumulative Timesteps: 543,075,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345,299.24703
Policy Entropy: 1.09691
Value Function Loss: 57.84254

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.07582

Collected Steps per Second: 11,885.01159
Overall Steps per Second: 9,950.82410

Timestep Collection Time: 4.20934
Timestep Consumption Time: 0.81819
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.02752

Cumulative Model Updates: 32,554
Cumulative Timesteps: 543,125,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 543125544...
Checkpoint 543125544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447,708.62756
Policy Entropy: 1.07930
Value Function Loss: 57.65854

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.06307

Collected Steps per Second: 11,844.75581
Overall Steps per Second: 9,986.73389

Timestep Collection Time: 4.22162
Timestep Consumption Time: 0.78543
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.00704

Cumulative Model Updates: 32,557
Cumulative Timesteps: 543,175,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370,526.42606
Policy Entropy: 1.08074
Value Function Loss: 62.21390

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.05178

Collected Steps per Second: 11,078.03747
Overall Steps per Second: 9,578.04780

Timestep Collection Time: 4.51578
Timestep Consumption Time: 0.70720
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.22298

Cumulative Model Updates: 32,560
Cumulative Timesteps: 543,225,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 543225574...
Checkpoint 543225574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407,459.81929
Policy Entropy: 1.10449
Value Function Loss: 63.93489

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.05539

Collected Steps per Second: 11,244.38674
Overall Steps per Second: 9,514.23340

Timestep Collection Time: 4.44898
Timestep Consumption Time: 0.80904
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.25802

Cumulative Model Updates: 32,563
Cumulative Timesteps: 543,275,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,783.99174
Policy Entropy: 1.09741
Value Function Loss: 63.25045

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 10,754.17055
Overall Steps per Second: 9,277.09551

Timestep Collection Time: 4.65178
Timestep Consumption Time: 0.74064
PPO Batch Consumption Time: 0.03761
Total Iteration Time: 5.39242

Cumulative Model Updates: 32,566
Cumulative Timesteps: 543,325,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 543325626...
Checkpoint 543325626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,902.69961
Policy Entropy: 1.07918
Value Function Loss: 60.35293

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.07322

Collected Steps per Second: 12,359.95268
Overall Steps per Second: 10,428.27621

Timestep Collection Time: 4.04743
Timestep Consumption Time: 0.74972
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.79715

Cumulative Model Updates: 32,569
Cumulative Timesteps: 543,375,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375,906.19460
Policy Entropy: 1.06492
Value Function Loss: 59.42642

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.15292
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.06882

Collected Steps per Second: 12,093.32349
Overall Steps per Second: 10,123.80683

Timestep Collection Time: 4.13567
Timestep Consumption Time: 0.80457
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 4.94024

Cumulative Model Updates: 32,572
Cumulative Timesteps: 543,425,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 543425666...
Checkpoint 543425666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,158.77586
Policy Entropy: 1.07713
Value Function Loss: 59.48827

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.06838

Collected Steps per Second: 11,038.16249
Overall Steps per Second: 9,571.90915

Timestep Collection Time: 4.53046
Timestep Consumption Time: 0.69399
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.22445

Cumulative Model Updates: 32,575
Cumulative Timesteps: 543,475,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,955.76713
Policy Entropy: 1.08817
Value Function Loss: 58.31503

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.06535

Collected Steps per Second: 11,089.20713
Overall Steps per Second: 9,399.76654

Timestep Collection Time: 4.51105
Timestep Consumption Time: 0.81078
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 5.32183

Cumulative Model Updates: 32,578
Cumulative Timesteps: 543,525,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 543525698...
Checkpoint 543525698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396,173.97338
Policy Entropy: 1.07086
Value Function Loss: 59.02761

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.06610
Value Function Update Magnitude: 0.06969

Collected Steps per Second: 11,124.48510
Overall Steps per Second: 9,561.00045

Timestep Collection Time: 4.49621
Timestep Consumption Time: 0.73525
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.23146

Cumulative Model Updates: 32,581
Cumulative Timesteps: 543,575,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,448.76861
Policy Entropy: 1.08698
Value Function Loss: 59.13656

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.06581

Collected Steps per Second: 11,021.96662
Overall Steps per Second: 9,427.66975

Timestep Collection Time: 4.53730
Timestep Consumption Time: 0.76730
PPO Batch Consumption Time: 0.03390
Total Iteration Time: 5.30460

Cumulative Model Updates: 32,584
Cumulative Timesteps: 543,625,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 543625726...
Checkpoint 543625726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,910.01825
Policy Entropy: 1.09543
Value Function Loss: 59.35934

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.08022

Collected Steps per Second: 10,765.86451
Overall Steps per Second: 9,184.30104

Timestep Collection Time: 4.64542
Timestep Consumption Time: 0.79996
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.44538

Cumulative Model Updates: 32,587
Cumulative Timesteps: 543,675,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,056.59320
Policy Entropy: 1.08505
Value Function Loss: 56.53499

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.07395

Collected Steps per Second: 10,332.40873
Overall Steps per Second: 8,906.72022

Timestep Collection Time: 4.84069
Timestep Consumption Time: 0.77484
PPO Batch Consumption Time: 0.04068
Total Iteration Time: 5.61554

Cumulative Model Updates: 32,590
Cumulative Timesteps: 543,725,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 543725754...
Checkpoint 543725754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,182.43121
Policy Entropy: 1.07637
Value Function Loss: 55.74891

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.07695

Collected Steps per Second: 11,184.19858
Overall Steps per Second: 9,495.69661

Timestep Collection Time: 4.47202
Timestep Consumption Time: 0.79520
PPO Batch Consumption Time: 0.03984
Total Iteration Time: 5.26723

Cumulative Model Updates: 32,593
Cumulative Timesteps: 543,775,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317,730.97736
Policy Entropy: 1.07837
Value Function Loss: 55.89391

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.07600

Collected Steps per Second: 10,801.85084
Overall Steps per Second: 9,362.68422

Timestep Collection Time: 4.63069
Timestep Consumption Time: 0.71180
PPO Batch Consumption Time: 0.03908
Total Iteration Time: 5.34248

Cumulative Model Updates: 32,596
Cumulative Timesteps: 543,825,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 543825790...
Checkpoint 543825790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,363.14339
Policy Entropy: 1.09336
Value Function Loss: 56.39703

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.15380
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.07934

Collected Steps per Second: 10,911.36342
Overall Steps per Second: 9,199.61544

Timestep Collection Time: 4.58476
Timestep Consumption Time: 0.85307
PPO Batch Consumption Time: 0.03922
Total Iteration Time: 5.43784

Cumulative Model Updates: 32,599
Cumulative Timesteps: 543,875,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349,508.04414
Policy Entropy: 1.05066
Value Function Loss: 56.38263

Mean KL Divergence: 0.06914
SB3 Clip Fraction: 0.23903
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.08724

Collected Steps per Second: 11,201.09946
Overall Steps per Second: 9,634.68112

Timestep Collection Time: 4.46545
Timestep Consumption Time: 0.72600
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.19145

Cumulative Model Updates: 32,602
Cumulative Timesteps: 543,925,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 543925834...
Checkpoint 543925834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296,355.97866
Policy Entropy: 1.08735
Value Function Loss: 55.70083

Mean KL Divergence: 0.04221
SB3 Clip Fraction: 0.20510
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.08704

Collected Steps per Second: 11,210.78520
Overall Steps per Second: 9,530.48443

Timestep Collection Time: 4.46088
Timestep Consumption Time: 0.78649
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 5.24737

Cumulative Model Updates: 32,605
Cumulative Timesteps: 543,975,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375,428.96331
Policy Entropy: 1.06441
Value Function Loss: 53.75353

Mean KL Divergence: 0.05349
SB3 Clip Fraction: 0.20380
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.07069

Collected Steps per Second: 10,979.63722
Overall Steps per Second: 9,345.25285

Timestep Collection Time: 4.55643
Timestep Consumption Time: 0.79687
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.35331

Cumulative Model Updates: 32,608
Cumulative Timesteps: 544,025,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 544025872...
Checkpoint 544025872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383,184.48447
Policy Entropy: 1.09162
Value Function Loss: 53.82324

Mean KL Divergence: 0.04470
SB3 Clip Fraction: 0.20001
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.07708

Collected Steps per Second: 10,917.19377
Overall Steps per Second: 9,465.74315

Timestep Collection Time: 4.58213
Timestep Consumption Time: 0.70261
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.28474

Cumulative Model Updates: 32,611
Cumulative Timesteps: 544,075,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405,429.02127
Policy Entropy: 1.06109
Value Function Loss: 53.41899

Mean KL Divergence: 0.04379
SB3 Clip Fraction: 0.18402
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.07113

Collected Steps per Second: 11,614.26022
Overall Steps per Second: 9,822.37666

Timestep Collection Time: 4.30505
Timestep Consumption Time: 0.78537
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.09042

Cumulative Model Updates: 32,614
Cumulative Timesteps: 544,125,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 544125896...
Checkpoint 544125896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,014.62727
Policy Entropy: 1.07640
Value Function Loss: 52.08564

Mean KL Divergence: 0.02456
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.06548

Collected Steps per Second: 11,448.50380
Overall Steps per Second: 9,826.80555

Timestep Collection Time: 4.36826
Timestep Consumption Time: 0.72088
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.08914

Cumulative Model Updates: 32,617
Cumulative Timesteps: 544,175,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,547.29021
Policy Entropy: 1.07698
Value Function Loss: 52.43041

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.07506

Collected Steps per Second: 12,140.55510
Overall Steps per Second: 10,177.72501

Timestep Collection Time: 4.12008
Timestep Consumption Time: 0.79458
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 4.91465

Cumulative Model Updates: 32,620
Cumulative Timesteps: 544,225,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 544225926...
Checkpoint 544225926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386,251.70943
Policy Entropy: 1.07791
Value Function Loss: 54.31014

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.06665
Value Function Update Magnitude: 0.07125

Collected Steps per Second: 11,873.72612
Overall Steps per Second: 10,039.36286

Timestep Collection Time: 4.21165
Timestep Consumption Time: 0.76954
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 4.98119

Cumulative Model Updates: 32,623
Cumulative Timesteps: 544,275,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,529.62141
Policy Entropy: 1.08179
Value Function Loss: 57.29144

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.06243
Value Function Update Magnitude: 0.06255

Collected Steps per Second: 11,811.08944
Overall Steps per Second: 10,176.05230

Timestep Collection Time: 4.23517
Timestep Consumption Time: 0.68049
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.91566

Cumulative Model Updates: 32,626
Cumulative Timesteps: 544,325,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 544325956...
Checkpoint 544325956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,413.09354
Policy Entropy: 1.08609
Value Function Loss: 56.11919

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.07342

Collected Steps per Second: 11,926.31404
Overall Steps per Second: 10,036.47063

Timestep Collection Time: 4.19459
Timestep Consumption Time: 0.78983
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.98442

Cumulative Model Updates: 32,629
Cumulative Timesteps: 544,375,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,924.12444
Policy Entropy: 1.08902
Value Function Loss: 56.08477

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.09696

Collected Steps per Second: 11,769.71422
Overall Steps per Second: 9,981.99433

Timestep Collection Time: 4.24938
Timestep Consumption Time: 0.76104
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 5.01042

Cumulative Model Updates: 32,632
Cumulative Timesteps: 544,425,996

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 544425996...
Checkpoint 544425996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,930.34980
Policy Entropy: 1.07996
Value Function Loss: 55.08005

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.09442

Collected Steps per Second: 11,410.00433
Overall Steps per Second: 9,886.51379

Timestep Collection Time: 4.38422
Timestep Consumption Time: 0.67560
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.05982

Cumulative Model Updates: 32,635
Cumulative Timesteps: 544,476,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377,077.74140
Policy Entropy: 1.07457
Value Function Loss: 52.00340

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.15332
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.10811

Collected Steps per Second: 11,967.78839
Overall Steps per Second: 10,147.84616

Timestep Collection Time: 4.18056
Timestep Consumption Time: 0.74975
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.93031

Cumulative Model Updates: 32,638
Cumulative Timesteps: 544,526,052

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 544526052...
Checkpoint 544526052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,794.96324
Policy Entropy: 1.08620
Value Function Loss: 51.48021

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.10347

Collected Steps per Second: 12,760.67683
Overall Steps per Second: 10,647.70971

Timestep Collection Time: 3.92048
Timestep Consumption Time: 0.77799
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 4.69848

Cumulative Model Updates: 32,641
Cumulative Timesteps: 544,576,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,984.28458
Policy Entropy: 1.09997
Value Function Loss: 51.04758

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.09280

Collected Steps per Second: 12,702.57732
Overall Steps per Second: 10,619.68217

Timestep Collection Time: 3.93763
Timestep Consumption Time: 0.77231
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 4.70993

Cumulative Model Updates: 32,644
Cumulative Timesteps: 544,626,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 544626098...
Checkpoint 544626098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,451.99264
Policy Entropy: 1.08947
Value Function Loss: 54.89081

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.09804

Collected Steps per Second: 12,463.31533
Overall Steps per Second: 10,382.43254

Timestep Collection Time: 4.01370
Timestep Consumption Time: 0.80444
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 4.81814

Cumulative Model Updates: 32,647
Cumulative Timesteps: 544,676,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300,094.05302
Policy Entropy: 1.09873
Value Function Loss: 54.42432

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.05910
Value Function Update Magnitude: 0.10249

Collected Steps per Second: 12,428.63827
Overall Steps per Second: 10,585.98599

Timestep Collection Time: 4.02409
Timestep Consumption Time: 0.70045
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 4.72455

Cumulative Model Updates: 32,650
Cumulative Timesteps: 544,726,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 544726136...
Checkpoint 544726136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,430.56097
Policy Entropy: 1.09985
Value Function Loss: 52.54974

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.10422

Collected Steps per Second: 12,087.82531
Overall Steps per Second: 10,129.57699

Timestep Collection Time: 4.13689
Timestep Consumption Time: 0.79974
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 4.93663

Cumulative Model Updates: 32,653
Cumulative Timesteps: 544,776,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358,719.96362
Policy Entropy: 1.10134
Value Function Loss: 50.71378

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.07641
Value Function Update Magnitude: 0.08537

Collected Steps per Second: 12,560.20240
Overall Steps per Second: 10,510.01696

Timestep Collection Time: 3.98242
Timestep Consumption Time: 0.77685
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 4.75927

Cumulative Model Updates: 32,656
Cumulative Timesteps: 544,826,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 544826162...
Checkpoint 544826162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,035.55104
Policy Entropy: 1.09609
Value Function Loss: 50.87315

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.07346
Value Function Update Magnitude: 0.08741

Collected Steps per Second: 12,172.96386
Overall Steps per Second: 10,241.03241

Timestep Collection Time: 4.10878
Timestep Consumption Time: 0.77511
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 4.88388

Cumulative Model Updates: 32,659
Cumulative Timesteps: 544,876,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367,950.26766
Policy Entropy: 1.08093
Value Function Loss: 51.64470

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 11,810.83843
Overall Steps per Second: 10,040.55730

Timestep Collection Time: 4.23475
Timestep Consumption Time: 0.74664
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 4.98140

Cumulative Model Updates: 32,662
Cumulative Timesteps: 544,926,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 544926194...
Checkpoint 544926194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313,787.72261
Policy Entropy: 1.10002
Value Function Loss: 52.57275

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.07929

Collected Steps per Second: 11,755.15250
Overall Steps per Second: 10,146.29811

Timestep Collection Time: 4.25584
Timestep Consumption Time: 0.67483
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.93067

Cumulative Model Updates: 32,665
Cumulative Timesteps: 544,976,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368,790.26666
Policy Entropy: 1.10204
Value Function Loss: 54.62416

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.07382

Collected Steps per Second: 11,934.28682
Overall Steps per Second: 10,040.48195

Timestep Collection Time: 4.19045
Timestep Consumption Time: 0.79039
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.98084

Cumulative Model Updates: 32,668
Cumulative Timesteps: 545,026,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 545026232...
Checkpoint 545026232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,092.25394
Policy Entropy: 1.10351
Value Function Loss: 55.88180

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.08038

Collected Steps per Second: 11,536.26077
Overall Steps per Second: 9,797.46811

Timestep Collection Time: 4.33416
Timestep Consumption Time: 0.76920
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.10336

Cumulative Model Updates: 32,671
Cumulative Timesteps: 545,076,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,609.87279
Policy Entropy: 1.09775
Value Function Loss: 56.21856

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 12,150.75213
Overall Steps per Second: 10,227.86074

Timestep Collection Time: 4.11563
Timestep Consumption Time: 0.77376
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.88939

Cumulative Model Updates: 32,674
Cumulative Timesteps: 545,126,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 545126240...
Checkpoint 545126240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425,542.82633
Policy Entropy: 1.10692
Value Function Loss: 52.94600

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.06205

Collected Steps per Second: 11,807.32818
Overall Steps per Second: 10,029.19786

Timestep Collection Time: 4.23686
Timestep Consumption Time: 0.75118
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 4.98804

Cumulative Model Updates: 32,677
Cumulative Timesteps: 545,176,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379,144.64603
Policy Entropy: 1.10970
Value Function Loss: 51.65916

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.05415

Collected Steps per Second: 11,911.32453
Overall Steps per Second: 10,276.61517

Timestep Collection Time: 4.20037
Timestep Consumption Time: 0.66816
PPO Batch Consumption Time: 0.03344
Total Iteration Time: 4.86853

Cumulative Model Updates: 32,680
Cumulative Timesteps: 545,226,298

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 545226298...
Checkpoint 545226298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360,891.76736
Policy Entropy: 1.07656
Value Function Loss: 48.82259

Mean KL Divergence: 0.04737
SB3 Clip Fraction: 0.19428
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.05285

Collected Steps per Second: 11,470.47888
Overall Steps per Second: 9,782.12782

Timestep Collection Time: 4.36041
Timestep Consumption Time: 0.75259
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.11300

Cumulative Model Updates: 32,683
Cumulative Timesteps: 545,276,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339,531.89305
Policy Entropy: 1.10829
Value Function Loss: 47.96995

Mean KL Divergence: 0.03143
SB3 Clip Fraction: 0.17811
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.04656

Collected Steps per Second: 11,767.79793
Overall Steps per Second: 10,141.74190

Timestep Collection Time: 4.25075
Timestep Consumption Time: 0.68154
PPO Batch Consumption Time: 0.03303
Total Iteration Time: 4.93229

Cumulative Model Updates: 32,686
Cumulative Timesteps: 545,326,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 545326336...
Checkpoint 545326336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,796.68052
Policy Entropy: 1.08580
Value Function Loss: 50.64060

Mean KL Divergence: 0.02953
SB3 Clip Fraction: 0.17267
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.05142

Collected Steps per Second: 11,731.79303
Overall Steps per Second: 9,843.42117

Timestep Collection Time: 4.26431
Timestep Consumption Time: 0.81807
PPO Batch Consumption Time: 0.03308
Total Iteration Time: 5.08238

Cumulative Model Updates: 32,689
Cumulative Timesteps: 545,376,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,632.71099
Policy Entropy: 1.10349
Value Function Loss: 51.21991

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.04661

Collected Steps per Second: 11,538.96711
Overall Steps per Second: 9,943.95178

Timestep Collection Time: 4.33401
Timestep Consumption Time: 0.69518
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.02919

Cumulative Model Updates: 32,692
Cumulative Timesteps: 545,426,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 545426374...
Checkpoint 545426374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385,940.11840
Policy Entropy: 1.10997
Value Function Loss: 52.37039

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.14938
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.06224

Collected Steps per Second: 11,759.01564
Overall Steps per Second: 10,024.78118

Timestep Collection Time: 4.25393
Timestep Consumption Time: 0.73591
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.98983

Cumulative Model Updates: 32,695
Cumulative Timesteps: 545,476,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,949.96438
Policy Entropy: 1.08743
Value Function Loss: 48.54435

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.05888

Collected Steps per Second: 11,924.06833
Overall Steps per Second: 10,108.89250

Timestep Collection Time: 4.19488
Timestep Consumption Time: 0.75324
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 4.94812

Cumulative Model Updates: 32,698
Cumulative Timesteps: 545,526,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 545526416...
Checkpoint 545526416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,778.69280
Policy Entropy: 1.07447
Value Function Loss: 47.73581

Mean KL Divergence: 0.03315
SB3 Clip Fraction: 0.17749
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.06810

Collected Steps per Second: 11,902.92917
Overall Steps per Second: 10,230.80942

Timestep Collection Time: 4.20266
Timestep Consumption Time: 0.68688
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 4.88954

Cumulative Model Updates: 32,701
Cumulative Timesteps: 545,576,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375,913.09525
Policy Entropy: 1.10332
Value Function Loss: 46.42852

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.16404
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.06778

Collected Steps per Second: 11,874.88166
Overall Steps per Second: 9,974.55871

Timestep Collection Time: 4.21074
Timestep Consumption Time: 0.80222
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.01295

Cumulative Model Updates: 32,704
Cumulative Timesteps: 545,626,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 545626442...
Checkpoint 545626442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342,565.63568
Policy Entropy: 1.09045
Value Function Loss: 47.13132

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.06445

Collected Steps per Second: 11,455.85355
Overall Steps per Second: 9,854.94412

Timestep Collection Time: 4.36703
Timestep Consumption Time: 0.70941
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.07644

Cumulative Model Updates: 32,707
Cumulative Timesteps: 545,676,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,077.97552
Policy Entropy: 1.10091
Value Function Loss: 48.69999

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.08098

Collected Steps per Second: 12,033.46335
Overall Steps per Second: 10,162.60906

Timestep Collection Time: 4.15724
Timestep Consumption Time: 0.76531
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 4.92255

Cumulative Model Updates: 32,710
Cumulative Timesteps: 545,726,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 545726496...
Checkpoint 545726496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,920.97016
Policy Entropy: 1.11027
Value Function Loss: 47.43018

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.07362

Collected Steps per Second: 12,006.50972
Overall Steps per Second: 10,214.91502

Timestep Collection Time: 4.16491
Timestep Consumption Time: 0.73048
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 4.89539

Cumulative Model Updates: 32,713
Cumulative Timesteps: 545,776,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405,132.92485
Policy Entropy: 1.09012
Value Function Loss: 48.74814

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.14497
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.07375

Collected Steps per Second: 12,249.29491
Overall Steps per Second: 10,302.77486

Timestep Collection Time: 4.08187
Timestep Consumption Time: 0.77119
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.85306

Cumulative Model Updates: 32,716
Cumulative Timesteps: 545,826,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 545826502...
Checkpoint 545826502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,942.25640
Policy Entropy: 1.09350
Value Function Loss: 47.72378

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.06643

Collected Steps per Second: 12,029.16260
Overall Steps per Second: 9,997.11710

Timestep Collection Time: 4.15839
Timestep Consumption Time: 0.84525
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 5.00364

Cumulative Model Updates: 32,719
Cumulative Timesteps: 545,876,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,763.03435
Policy Entropy: 1.09316
Value Function Loss: 47.37046

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.05200

Collected Steps per Second: 12,134.59957
Overall Steps per Second: 10,408.24028

Timestep Collection Time: 4.12127
Timestep Consumption Time: 0.68357
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.80485

Cumulative Model Updates: 32,722
Cumulative Timesteps: 545,926,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 545926534...
Checkpoint 545926534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,162.30371
Policy Entropy: 1.09859
Value Function Loss: 47.14423

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.04448

Collected Steps per Second: 12,160.70977
Overall Steps per Second: 10,042.35592

Timestep Collection Time: 4.11259
Timestep Consumption Time: 0.86752
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 4.98011

Cumulative Model Updates: 32,725
Cumulative Timesteps: 545,976,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,727.91274
Policy Entropy: 1.09196
Value Function Loss: 46.67166

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.05119

Collected Steps per Second: 12,014.50717
Overall Steps per Second: 10,326.88404

Timestep Collection Time: 4.16230
Timestep Consumption Time: 0.68020
PPO Batch Consumption Time: 0.03336
Total Iteration Time: 4.84251

Cumulative Model Updates: 32,728
Cumulative Timesteps: 546,026,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 546026554...
Checkpoint 546026554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,155.59515
Policy Entropy: 1.07842
Value Function Loss: 47.36701

Mean KL Divergence: 0.03051
SB3 Clip Fraction: 0.16313
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.05843

Collected Steps per Second: 11,805.11174
Overall Steps per Second: 10,028.89761

Timestep Collection Time: 4.23596
Timestep Consumption Time: 0.75023
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.98619

Cumulative Model Updates: 32,731
Cumulative Timesteps: 546,076,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373,379.53450
Policy Entropy: 1.10283
Value Function Loss: 47.14776

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.06094
Value Function Update Magnitude: 0.06063

Collected Steps per Second: 11,836.29182
Overall Steps per Second: 10,026.99585

Timestep Collection Time: 4.22480
Timestep Consumption Time: 0.76233
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 4.98714

Cumulative Model Updates: 32,734
Cumulative Timesteps: 546,126,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 546126566...
Checkpoint 546126566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,531.09780
Policy Entropy: 1.09659
Value Function Loss: 47.64949

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.07186

Collected Steps per Second: 11,480.18664
Overall Steps per Second: 9,869.46516

Timestep Collection Time: 4.35550
Timestep Consumption Time: 0.71083
PPO Batch Consumption Time: 0.03838
Total Iteration Time: 5.06633

Cumulative Model Updates: 32,737
Cumulative Timesteps: 546,176,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,538.56066
Policy Entropy: 1.09191
Value Function Loss: 49.21024

Mean KL Divergence: 0.02697
SB3 Clip Fraction: 0.16698
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.09500

Collected Steps per Second: 11,288.69650
Overall Steps per Second: 9,589.57306

Timestep Collection Time: 4.43169
Timestep Consumption Time: 0.78523
PPO Batch Consumption Time: 0.04335
Total Iteration Time: 5.21692

Cumulative Model Updates: 32,740
Cumulative Timesteps: 546,226,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 546226596...
Checkpoint 546226596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361,284.97407
Policy Entropy: 1.09357
Value Function Loss: 49.49016

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11590
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.09875

Collected Steps per Second: 11,720.77201
Overall Steps per Second: 9,987.58700

Timestep Collection Time: 4.26730
Timestep Consumption Time: 0.74052
PPO Batch Consumption Time: 0.03322
Total Iteration Time: 5.00782

Cumulative Model Updates: 32,743
Cumulative Timesteps: 546,276,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,824.10129
Policy Entropy: 1.09958
Value Function Loss: 46.56727

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.10646

Collected Steps per Second: 11,978.42294
Overall Steps per Second: 10,130.74437

Timestep Collection Time: 4.17517
Timestep Consumption Time: 0.76148
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 4.93666

Cumulative Model Updates: 32,746
Cumulative Timesteps: 546,326,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 546326624...
Checkpoint 546326624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,549.49990
Policy Entropy: 1.07902
Value Function Loss: 45.44123

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.09270

Collected Steps per Second: 11,811.69641
Overall Steps per Second: 10,151.96110

Timestep Collection Time: 4.23377
Timestep Consumption Time: 0.69218
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 4.92594

Cumulative Model Updates: 32,749
Cumulative Timesteps: 546,376,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,843.34789
Policy Entropy: 1.10497
Value Function Loss: 44.68064

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.08184

Collected Steps per Second: 11,308.84072
Overall Steps per Second: 9,624.67519

Timestep Collection Time: 4.42273
Timestep Consumption Time: 0.77391
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.19664

Cumulative Model Updates: 32,752
Cumulative Timesteps: 546,426,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 546426648...
Checkpoint 546426648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421,243.82766
Policy Entropy: 1.09849
Value Function Loss: 45.74212

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.10863

Collected Steps per Second: 11,743.49299
Overall Steps per Second: 10,004.68660

Timestep Collection Time: 4.25768
Timestep Consumption Time: 0.73998
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.99766

Cumulative Model Updates: 32,755
Cumulative Timesteps: 546,476,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,734.55168
Policy Entropy: 1.08462
Value Function Loss: 44.36512

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.12953

Collected Steps per Second: 11,598.73873
Overall Steps per Second: 10,053.04959

Timestep Collection Time: 4.31323
Timestep Consumption Time: 0.66317
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 4.97640

Cumulative Model Updates: 32,758
Cumulative Timesteps: 546,526,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 546526676...
Checkpoint 546526676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404,369.55030
Policy Entropy: 1.06204
Value Function Loss: 44.66230

Mean KL Divergence: 0.03288
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.12264

Collected Steps per Second: 10,173.62172
Overall Steps per Second: 8,724.04548

Timestep Collection Time: 4.91683
Timestep Consumption Time: 0.81697
PPO Batch Consumption Time: 0.04039
Total Iteration Time: 5.73381

Cumulative Model Updates: 32,761
Cumulative Timesteps: 546,576,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,952.77793
Policy Entropy: 1.09117
Value Function Loss: 45.29054

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.11281

Collected Steps per Second: 10,392.13026
Overall Steps per Second: 8,978.15393

Timestep Collection Time: 4.81287
Timestep Consumption Time: 0.75798
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.57086

Cumulative Model Updates: 32,764
Cumulative Timesteps: 546,626,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 546626714...
Checkpoint 546626714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,529.77064
Policy Entropy: 1.08869
Value Function Loss: 47.14011

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.09337

Collected Steps per Second: 10,643.36798
Overall Steps per Second: 9,084.54321

Timestep Collection Time: 4.69964
Timestep Consumption Time: 0.80642
PPO Batch Consumption Time: 0.03816
Total Iteration Time: 5.50606

Cumulative Model Updates: 32,767
Cumulative Timesteps: 546,676,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,538.63628
Policy Entropy: 1.08572
Value Function Loss: 46.35115

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.08272

Collected Steps per Second: 10,799.87967
Overall Steps per Second: 9,236.61455

Timestep Collection Time: 4.62987
Timestep Consumption Time: 0.78359
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.41346

Cumulative Model Updates: 32,770
Cumulative Timesteps: 546,726,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 546726736...
Checkpoint 546726736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347,397.09803
Policy Entropy: 1.09782
Value Function Loss: 44.73317

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.07759

Collected Steps per Second: 10,497.78795
Overall Steps per Second: 9,034.05855

Timestep Collection Time: 4.76558
Timestep Consumption Time: 0.77214
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 5.53771

Cumulative Model Updates: 32,773
Cumulative Timesteps: 546,776,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,989.13276
Policy Entropy: 1.09969
Value Function Loss: 43.79069

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.09935

Collected Steps per Second: 10,643.24899
Overall Steps per Second: 9,071.48999

Timestep Collection Time: 4.69913
Timestep Consumption Time: 0.81419
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.51332

Cumulative Model Updates: 32,776
Cumulative Timesteps: 546,826,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 546826778...
Checkpoint 546826778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,334.59929
Policy Entropy: 1.07406
Value Function Loss: 43.69953

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.10831

Collected Steps per Second: 10,456.64408
Overall Steps per Second: 9,002.53649

Timestep Collection Time: 4.78241
Timestep Consumption Time: 0.77247
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.55488

Cumulative Model Updates: 32,779
Cumulative Timesteps: 546,876,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360,393.88859
Policy Entropy: 1.06968
Value Function Loss: 45.22583

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.08789

Collected Steps per Second: 11,879.89521
Overall Steps per Second: 10,054.61617

Timestep Collection Time: 4.21064
Timestep Consumption Time: 0.76439
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 4.97503

Cumulative Model Updates: 32,782
Cumulative Timesteps: 546,926,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 546926808...
Checkpoint 546926808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,566.90996
Policy Entropy: 1.07761
Value Function Loss: 43.05871

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.06953

Collected Steps per Second: 11,641.27559
Overall Steps per Second: 10,045.77930

Timestep Collection Time: 4.29747
Timestep Consumption Time: 0.68253
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.98000

Cumulative Model Updates: 32,785
Cumulative Timesteps: 546,976,836

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407,387.69038
Policy Entropy: 1.09093
Value Function Loss: 42.40005

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.06227

Collected Steps per Second: 11,709.54594
Overall Steps per Second: 9,961.05532

Timestep Collection Time: 4.27070
Timestep Consumption Time: 0.74965
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.02035

Cumulative Model Updates: 32,788
Cumulative Timesteps: 547,026,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 547026844...
Checkpoint 547026844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362,494.07463
Policy Entropy: 1.07633
Value Function Loss: 40.00275

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 11,521.98460
Overall Steps per Second: 9,895.42659

Timestep Collection Time: 4.34127
Timestep Consumption Time: 0.71359
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.05486

Cumulative Model Updates: 32,791
Cumulative Timesteps: 547,076,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,571.45675
Policy Entropy: 1.08116
Value Function Loss: 40.92774

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.04937

Collected Steps per Second: 11,688.35543
Overall Steps per Second: 9,831.20664

Timestep Collection Time: 4.27828
Timestep Consumption Time: 0.80818
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 5.08646

Cumulative Model Updates: 32,794
Cumulative Timesteps: 547,126,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 547126870...
Checkpoint 547126870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385,838.96947
Policy Entropy: 1.09288
Value Function Loss: 41.64307

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.05264

Collected Steps per Second: 11,328.25538
Overall Steps per Second: 9,455.90439

Timestep Collection Time: 4.41551
Timestep Consumption Time: 0.87431
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.28982

Cumulative Model Updates: 32,797
Cumulative Timesteps: 547,176,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,007.10959
Policy Entropy: 1.08998
Value Function Loss: 42.89181

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.04973

Collected Steps per Second: 11,141.40839
Overall Steps per Second: 9,514.22794

Timestep Collection Time: 4.48830
Timestep Consumption Time: 0.76762
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.25592

Cumulative Model Updates: 32,800
Cumulative Timesteps: 547,226,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 547226896...
Checkpoint 547226896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412,545.44812
Policy Entropy: 1.08284
Value Function Loss: 41.93139

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.06552
Value Function Update Magnitude: 0.04824

Collected Steps per Second: 11,014.92901
Overall Steps per Second: 9,370.50327

Timestep Collection Time: 4.54184
Timestep Consumption Time: 0.79704
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.33888

Cumulative Model Updates: 32,803
Cumulative Timesteps: 547,276,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,988.88440
Policy Entropy: 1.09040
Value Function Loss: 42.47956

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.04869

Collected Steps per Second: 11,153.49907
Overall Steps per Second: 9,673.87231

Timestep Collection Time: 4.48379
Timestep Consumption Time: 0.68580
PPO Batch Consumption Time: 0.03804
Total Iteration Time: 5.16959

Cumulative Model Updates: 32,806
Cumulative Timesteps: 547,326,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 547326934...
Checkpoint 547326934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,444.46691
Policy Entropy: 1.09241
Value Function Loss: 42.56288

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.04137

Collected Steps per Second: 11,042.80871
Overall Steps per Second: 9,335.22689

Timestep Collection Time: 4.52820
Timestep Consumption Time: 0.82829
PPO Batch Consumption Time: 0.03992
Total Iteration Time: 5.35648

Cumulative Model Updates: 32,809
Cumulative Timesteps: 547,376,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,636.83040
Policy Entropy: 1.09923
Value Function Loss: 42.58718

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.05017

Collected Steps per Second: 10,630.90626
Overall Steps per Second: 9,105.62894

Timestep Collection Time: 4.70458
Timestep Consumption Time: 0.78806
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.49265

Cumulative Model Updates: 32,812
Cumulative Timesteps: 547,426,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 547426952...
Checkpoint 547426952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427,030.88655
Policy Entropy: 1.09365
Value Function Loss: 40.63709

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.04466

Collected Steps per Second: 11,047.48004
Overall Steps per Second: 9,383.48021

Timestep Collection Time: 4.52682
Timestep Consumption Time: 0.80275
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.32958

Cumulative Model Updates: 32,815
Cumulative Timesteps: 547,476,962

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,811.91313
Policy Entropy: 1.10546
Value Function Loss: 40.76887

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.04395

Collected Steps per Second: 10,763.15494
Overall Steps per Second: 9,226.90692

Timestep Collection Time: 4.64696
Timestep Consumption Time: 0.77370
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.42067

Cumulative Model Updates: 32,818
Cumulative Timesteps: 547,526,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 547526978...
Checkpoint 547526978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355,464.04828
Policy Entropy: 1.09965
Value Function Loss: 40.63072

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.04017

Collected Steps per Second: 10,866.46397
Overall Steps per Second: 9,430.98481

Timestep Collection Time: 4.60334
Timestep Consumption Time: 0.70067
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.30401

Cumulative Model Updates: 32,821
Cumulative Timesteps: 547,577,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368,792.50963
Policy Entropy: 1.10781
Value Function Loss: 42.65985

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.04248

Collected Steps per Second: 10,820.52677
Overall Steps per Second: 9,261.83021

Timestep Collection Time: 4.62343
Timestep Consumption Time: 0.77809
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.40152

Cumulative Model Updates: 32,824
Cumulative Timesteps: 547,627,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 547627028...
Checkpoint 547627028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,421.77044
Policy Entropy: 1.09236
Value Function Loss: 42.24188

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.04360

Collected Steps per Second: 10,932.48998
Overall Steps per Second: 9,446.09246

Timestep Collection Time: 4.57480
Timestep Consumption Time: 0.71987
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.29468

Cumulative Model Updates: 32,827
Cumulative Timesteps: 547,677,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,722.70469
Policy Entropy: 1.10251
Value Function Loss: 42.66795

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.05773
Value Function Update Magnitude: 0.04180

Collected Steps per Second: 10,610.90174
Overall Steps per Second: 9,129.93401

Timestep Collection Time: 4.71421
Timestep Consumption Time: 0.76469
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.47890

Cumulative Model Updates: 32,830
Cumulative Timesteps: 547,727,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 547727064...
Checkpoint 547727064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,726.30388
Policy Entropy: 1.11324
Value Function Loss: 42.74632

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.04649

Collected Steps per Second: 10,852.32708
Overall Steps per Second: 9,163.20491

Timestep Collection Time: 4.60897
Timestep Consumption Time: 0.84961
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.45857

Cumulative Model Updates: 32,833
Cumulative Timesteps: 547,777,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,381.78915
Policy Entropy: 1.10555
Value Function Loss: 43.90834

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.04570

Collected Steps per Second: 10,696.53119
Overall Steps per Second: 9,328.93838

Timestep Collection Time: 4.67666
Timestep Consumption Time: 0.68558
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.36224

Cumulative Model Updates: 32,836
Cumulative Timesteps: 547,827,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 547827106...
Checkpoint 547827106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,519.81273
Policy Entropy: 1.10263
Value Function Loss: 44.78982

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.05111

Collected Steps per Second: 10,814.26428
Overall Steps per Second: 9,286.30060

Timestep Collection Time: 4.62426
Timestep Consumption Time: 0.76087
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.38514

Cumulative Model Updates: 32,839
Cumulative Timesteps: 547,877,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396,783.14818
Policy Entropy: 1.11179
Value Function Loss: 45.17270

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.04685

Collected Steps per Second: 10,943.03843
Overall Steps per Second: 9,397.21541

Timestep Collection Time: 4.56966
Timestep Consumption Time: 0.75170
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 5.32136

Cumulative Model Updates: 32,842
Cumulative Timesteps: 547,927,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 547927120...
Checkpoint 547927120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,123.57252
Policy Entropy: 1.11304
Value Function Loss: 44.83168

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.04996

Collected Steps per Second: 10,705.95288
Overall Steps per Second: 9,158.64071

Timestep Collection Time: 4.67179
Timestep Consumption Time: 0.78928
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.46107

Cumulative Model Updates: 32,845
Cumulative Timesteps: 547,977,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,244.40752
Policy Entropy: 1.10222
Value Function Loss: 44.62456

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.11741
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.04834

Collected Steps per Second: 10,392.78372
Overall Steps per Second: 8,875.06131

Timestep Collection Time: 4.81219
Timestep Consumption Time: 0.82293
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 5.63512

Cumulative Model Updates: 32,848
Cumulative Timesteps: 548,027,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 548027148...
Checkpoint 548027148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337,013.81907
Policy Entropy: 1.10650
Value Function Loss: 42.01425

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.04867

Collected Steps per Second: 10,572.08431
Overall Steps per Second: 9,188.25347

Timestep Collection Time: 4.73000
Timestep Consumption Time: 0.71238
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.44238

Cumulative Model Updates: 32,851
Cumulative Timesteps: 548,077,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394,921.78162
Policy Entropy: 1.11297
Value Function Loss: 41.38918

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.05061

Collected Steps per Second: 11,375.64609
Overall Steps per Second: 9,621.04096

Timestep Collection Time: 4.39729
Timestep Consumption Time: 0.80194
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.19923

Cumulative Model Updates: 32,854
Cumulative Timesteps: 548,127,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 548127176...
Checkpoint 548127176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371,154.23333
Policy Entropy: 1.12350
Value Function Loss: 38.66441

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.04538

Collected Steps per Second: 10,731.62567
Overall Steps per Second: 9,278.63070

Timestep Collection Time: 4.66155
Timestep Consumption Time: 0.72998
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.39153

Cumulative Model Updates: 32,857
Cumulative Timesteps: 548,177,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,157.72596
Policy Entropy: 1.10801
Value Function Loss: 38.43695

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.05141

Collected Steps per Second: 11,392.53242
Overall Steps per Second: 9,718.26079

Timestep Collection Time: 4.39007
Timestep Consumption Time: 0.75633
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.14639

Cumulative Model Updates: 32,860
Cumulative Timesteps: 548,227,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 548227216...
Checkpoint 548227216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,023.37301
Policy Entropy: 1.11535
Value Function Loss: 38.18198

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.04817

Collected Steps per Second: 10,653.38383
Overall Steps per Second: 9,124.54630

Timestep Collection Time: 4.69522
Timestep Consumption Time: 0.78669
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.48192

Cumulative Model Updates: 32,863
Cumulative Timesteps: 548,277,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,426.08869
Policy Entropy: 1.11626
Value Function Loss: 40.29827

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.04768

Collected Steps per Second: 11,229.14027
Overall Steps per Second: 9,405.22183

Timestep Collection Time: 4.45413
Timestep Consumption Time: 0.86377
PPO Batch Consumption Time: 0.05124
Total Iteration Time: 5.31790

Cumulative Model Updates: 32,866
Cumulative Timesteps: 548,327,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 548327252...
Checkpoint 548327252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,906.87982
Policy Entropy: 1.12099
Value Function Loss: 41.43376

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07173
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.04506

Collected Steps per Second: 11,226.83054
Overall Steps per Second: 9,494.10275

Timestep Collection Time: 4.45362
Timestep Consumption Time: 0.81281
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.26643

Cumulative Model Updates: 32,869
Cumulative Timesteps: 548,377,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445,356.22831
Policy Entropy: 1.12239
Value Function Loss: 43.34193

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.06254
Value Function Update Magnitude: 0.04241

Collected Steps per Second: 10,988.79324
Overall Steps per Second: 9,489.60578

Timestep Collection Time: 4.55209
Timestep Consumption Time: 0.71915
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.27124

Cumulative Model Updates: 32,872
Cumulative Timesteps: 548,427,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 548427274...
Checkpoint 548427274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404,623.99995
Policy Entropy: 1.12215
Value Function Loss: 42.65494

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.04694

Collected Steps per Second: 11,206.30421
Overall Steps per Second: 9,548.83036

Timestep Collection Time: 4.46356
Timestep Consumption Time: 0.77478
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.23834

Cumulative Model Updates: 32,875
Cumulative Timesteps: 548,477,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388,561.82300
Policy Entropy: 1.10957
Value Function Loss: 42.31975

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.04423

Collected Steps per Second: 11,451.89611
Overall Steps per Second: 9,867.90934

Timestep Collection Time: 4.36766
Timestep Consumption Time: 0.70109
PPO Batch Consumption Time: 0.03758
Total Iteration Time: 5.06875

Cumulative Model Updates: 32,878
Cumulative Timesteps: 548,527,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 548527312...
Checkpoint 548527312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,337.47885
Policy Entropy: 1.12234
Value Function Loss: 39.15592

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.05187

Collected Steps per Second: 10,929.22524
Overall Steps per Second: 9,251.17750

Timestep Collection Time: 4.57489
Timestep Consumption Time: 0.82983
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.40472

Cumulative Model Updates: 32,881
Cumulative Timesteps: 548,577,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,748.80972
Policy Entropy: 1.13153
Value Function Loss: 38.61133

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.04803

Collected Steps per Second: 10,758.12723
Overall Steps per Second: 9,132.22881

Timestep Collection Time: 4.64858
Timestep Consumption Time: 0.82763
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 5.47621

Cumulative Model Updates: 32,884
Cumulative Timesteps: 548,627,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 548627322...
Checkpoint 548627322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,080.37762
Policy Entropy: 1.12024
Value Function Loss: 39.49178

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.05132

Collected Steps per Second: 10,877.37320
Overall Steps per Second: 9,474.43866

Timestep Collection Time: 4.59688
Timestep Consumption Time: 0.68069
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.27757

Cumulative Model Updates: 32,887
Cumulative Timesteps: 548,677,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327,172.16783
Policy Entropy: 1.13539
Value Function Loss: 40.92465

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.04913

Collected Steps per Second: 10,886.53571
Overall Steps per Second: 9,336.36997

Timestep Collection Time: 4.59448
Timestep Consumption Time: 0.76285
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.35733

Cumulative Model Updates: 32,890
Cumulative Timesteps: 548,727,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 548727342...
Checkpoint 548727342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331,477.70829
Policy Entropy: 1.13068
Value Function Loss: 40.21880

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 10,831.21016
Overall Steps per Second: 9,375.80311

Timestep Collection Time: 4.61758
Timestep Consumption Time: 0.71679
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.33437

Cumulative Model Updates: 32,893
Cumulative Timesteps: 548,777,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378,873.68657
Policy Entropy: 1.12178
Value Function Loss: 40.03450

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.04889

Collected Steps per Second: 10,597.96015
Overall Steps per Second: 9,103.31874

Timestep Collection Time: 4.71864
Timestep Consumption Time: 0.77474
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 5.49338

Cumulative Model Updates: 32,896
Cumulative Timesteps: 548,827,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 548827364...
Checkpoint 548827364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,631.66938
Policy Entropy: 1.10958
Value Function Loss: 37.86196

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.04647

Collected Steps per Second: 10,794.66194
Overall Steps per Second: 9,270.46835

Timestep Collection Time: 4.63210
Timestep Consumption Time: 0.76158
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 5.39369

Cumulative Model Updates: 32,899
Cumulative Timesteps: 548,877,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420,964.04972
Policy Entropy: 1.12159
Value Function Loss: 38.21659

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.04765

Collected Steps per Second: 10,563.85946
Overall Steps per Second: 9,093.51589

Timestep Collection Time: 4.73444
Timestep Consumption Time: 0.76552
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 5.49996

Cumulative Model Updates: 32,902
Cumulative Timesteps: 548,927,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 548927380...
Checkpoint 548927380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375,069.11265
Policy Entropy: 1.12729
Value Function Loss: 36.05661

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.04655

Collected Steps per Second: 10,962.83073
Overall Steps per Second: 9,208.57579

Timestep Collection Time: 4.56233
Timestep Consumption Time: 0.86913
PPO Batch Consumption Time: 0.03873
Total Iteration Time: 5.43146

Cumulative Model Updates: 32,905
Cumulative Timesteps: 548,977,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,902.61969
Policy Entropy: 1.10484
Value Function Loss: 37.19974

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.04437

Collected Steps per Second: 10,323.41053
Overall Steps per Second: 8,939.78809

Timestep Collection Time: 4.84607
Timestep Consumption Time: 0.75003
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.59611

Cumulative Model Updates: 32,908
Cumulative Timesteps: 549,027,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 549027424...
Checkpoint 549027424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440,927.87989
Policy Entropy: 1.12339
Value Function Loss: 38.47188

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.05346

Collected Steps per Second: 11,060.21754
Overall Steps per Second: 9,394.68852

Timestep Collection Time: 4.52107
Timestep Consumption Time: 0.80151
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 5.32258

Cumulative Model Updates: 32,911
Cumulative Timesteps: 549,077,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,094.84623
Policy Entropy: 1.13045
Value Function Loss: 38.17466

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.04990

Collected Steps per Second: 10,439.43525
Overall Steps per Second: 8,944.77152

Timestep Collection Time: 4.78972
Timestep Consumption Time: 0.80036
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.59008

Cumulative Model Updates: 32,914
Cumulative Timesteps: 549,127,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 549127430...
Checkpoint 549127430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340,085.70616
Policy Entropy: 1.12015
Value Function Loss: 39.24541

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.06227

Collected Steps per Second: 12,005.72032
Overall Steps per Second: 10,213.61939

Timestep Collection Time: 4.16718
Timestep Consumption Time: 0.73118
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.89836

Cumulative Model Updates: 32,917
Cumulative Timesteps: 549,177,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,690.69614
Policy Entropy: 1.12579
Value Function Loss: 38.61036

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.05473

Collected Steps per Second: 11,337.78035
Overall Steps per Second: 9,486.29126

Timestep Collection Time: 4.41268
Timestep Consumption Time: 0.86125
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.27393

Cumulative Model Updates: 32,920
Cumulative Timesteps: 549,227,490

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 549227490...
Checkpoint 549227490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335,746.96462
Policy Entropy: 1.13517
Value Function Loss: 37.11344

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.04666

Collected Steps per Second: 11,603.99735
Overall Steps per Second: 9,760.28125

Timestep Collection Time: 4.30886
Timestep Consumption Time: 0.81394
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 5.12280

Cumulative Model Updates: 32,923
Cumulative Timesteps: 549,277,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342,698.67058
Policy Entropy: 1.14298
Value Function Loss: 38.41743

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 11,277.48622
Overall Steps per Second: 9,707.54718

Timestep Collection Time: 4.43379
Timestep Consumption Time: 0.71705
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 5.15084

Cumulative Model Updates: 32,926
Cumulative Timesteps: 549,327,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 549327492...
Checkpoint 549327492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374,300.76753
Policy Entropy: 1.12562
Value Function Loss: 38.70028

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.04121

Collected Steps per Second: 12,014.95077
Overall Steps per Second: 9,962.33796

Timestep Collection Time: 4.16265
Timestep Consumption Time: 0.85766
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.02031

Cumulative Model Updates: 32,929
Cumulative Timesteps: 549,377,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364,690.22483
Policy Entropy: 1.12032
Value Function Loss: 40.77209

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.04803

Collected Steps per Second: 11,982.24897
Overall Steps per Second: 10,017.20860

Timestep Collection Time: 4.17468
Timestep Consumption Time: 0.81893
PPO Batch Consumption Time: 0.04049
Total Iteration Time: 4.99361

Cumulative Model Updates: 32,932
Cumulative Timesteps: 549,427,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 549427528...
Checkpoint 549427528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,476.55527
Policy Entropy: 1.12660
Value Function Loss: 39.21796

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.04503

Collected Steps per Second: 11,051.01058
Overall Steps per Second: 9,357.26174

Timestep Collection Time: 4.52610
Timestep Consumption Time: 0.81927
PPO Batch Consumption Time: 0.03924
Total Iteration Time: 5.34537

Cumulative Model Updates: 32,935
Cumulative Timesteps: 549,477,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437,785.89589
Policy Entropy: 1.12653
Value Function Loss: 38.07015

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.04784

Collected Steps per Second: 11,209.47050
Overall Steps per Second: 9,434.67745

Timestep Collection Time: 4.46319
Timestep Consumption Time: 0.83959
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.30278

Cumulative Model Updates: 32,938
Cumulative Timesteps: 549,527,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 549527576...
Checkpoint 549527576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,431.90051
Policy Entropy: 1.11197
Value Function Loss: 36.85837

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.04888

Collected Steps per Second: 11,017.31497
Overall Steps per Second: 9,531.54592

Timestep Collection Time: 4.54031
Timestep Consumption Time: 0.70774
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 5.24805

Cumulative Model Updates: 32,941
Cumulative Timesteps: 549,577,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,152.66529
Policy Entropy: 1.10315
Value Function Loss: 37.10848

Mean KL Divergence: 0.03352
SB3 Clip Fraction: 0.17295
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.05018

Collected Steps per Second: 10,892.04911
Overall Steps per Second: 9,269.58972

Timestep Collection Time: 4.59271
Timestep Consumption Time: 0.80386
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 5.39657

Cumulative Model Updates: 32,944
Cumulative Timesteps: 549,627,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 549627622...
Checkpoint 549627622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,438.79885
Policy Entropy: 1.10468
Value Function Loss: 37.04655

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.04991

Collected Steps per Second: 10,448.85025
Overall Steps per Second: 8,970.10176

Timestep Collection Time: 4.78560
Timestep Consumption Time: 0.78892
PPO Batch Consumption Time: 0.03896
Total Iteration Time: 5.57452

Cumulative Model Updates: 32,947
Cumulative Timesteps: 549,677,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,903.00132
Policy Entropy: 1.12001
Value Function Loss: 36.97778

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.05000

Collected Steps per Second: 11,081.65691
Overall Steps per Second: 9,473.33959

Timestep Collection Time: 4.51413
Timestep Consumption Time: 0.76638
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.28050

Cumulative Model Updates: 32,950
Cumulative Timesteps: 549,727,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 549727650...
Checkpoint 549727650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,323.03549
Policy Entropy: 1.08888
Value Function Loss: 35.33375

Mean KL Divergence: 0.04418
SB3 Clip Fraction: 0.18241
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.04492

Collected Steps per Second: 10,877.22300
Overall Steps per Second: 9,342.95982

Timestep Collection Time: 4.59805
Timestep Consumption Time: 0.75507
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 5.35312

Cumulative Model Updates: 32,953
Cumulative Timesteps: 549,777,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362,161.72391
Policy Entropy: 1.11632
Value Function Loss: 36.42347

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.04547

Collected Steps per Second: 10,975.64562
Overall Steps per Second: 9,510.06109

Timestep Collection Time: 4.55663
Timestep Consumption Time: 0.70222
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 5.25885

Cumulative Model Updates: 32,956
Cumulative Timesteps: 549,827,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 549827676...
Checkpoint 549827676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422,661.54672
Policy Entropy: 1.09335
Value Function Loss: 35.88258

Mean KL Divergence: 0.02905
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.04455

Collected Steps per Second: 10,926.22070
Overall Steps per Second: 9,353.99124

Timestep Collection Time: 4.57725
Timestep Consumption Time: 0.76935
PPO Batch Consumption Time: 0.03400
Total Iteration Time: 5.34659

Cumulative Model Updates: 32,959
Cumulative Timesteps: 549,877,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,129.35393
Policy Entropy: 1.09012
Value Function Loss: 36.66864

Mean KL Divergence: 0.02809
SB3 Clip Fraction: 0.15529
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.05090

Collected Steps per Second: 10,826.66464
Overall Steps per Second: 9,309.82508

Timestep Collection Time: 4.61971
Timestep Consumption Time: 0.75268
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.37239

Cumulative Model Updates: 32,962
Cumulative Timesteps: 549,927,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 549927704...
Checkpoint 549927704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331,724.55348
Policy Entropy: 1.09487
Value Function Loss: 35.87915

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.04727
Value Function Update Magnitude: 0.04951

Collected Steps per Second: 10,542.57056
Overall Steps per Second: 9,061.19606

Timestep Collection Time: 4.74419
Timestep Consumption Time: 0.77561
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.51980

Cumulative Model Updates: 32,965
Cumulative Timesteps: 549,977,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,046.88241
Policy Entropy: 1.09987
Value Function Loss: 35.31072

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.04467

Collected Steps per Second: 10,534.27607
Overall Steps per Second: 9,032.51344

Timestep Collection Time: 4.74831
Timestep Consumption Time: 0.78946
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.53777

Cumulative Model Updates: 32,968
Cumulative Timesteps: 550,027,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 550027740...
Checkpoint 550027740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,248.31267
Policy Entropy: 1.08654
Value Function Loss: 36.10118

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.05075

Collected Steps per Second: 10,441.06483
Overall Steps per Second: 9,136.13916

Timestep Collection Time: 4.78917
Timestep Consumption Time: 0.68404
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.47321

Cumulative Model Updates: 32,971
Cumulative Timesteps: 550,077,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,900.01663
Policy Entropy: 1.09194
Value Function Loss: 35.26574

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.06527

Collected Steps per Second: 10,813.69475
Overall Steps per Second: 9,292.83589

Timestep Collection Time: 4.62506
Timestep Consumption Time: 0.75693
PPO Batch Consumption Time: 0.03844
Total Iteration Time: 5.38200

Cumulative Model Updates: 32,974
Cumulative Timesteps: 550,127,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 550127758...
Checkpoint 550127758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327,613.28023
Policy Entropy: 1.09570
Value Function Loss: 35.58586

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.07640

Collected Steps per Second: 10,688.15590
Overall Steps per Second: 9,216.39076

Timestep Collection Time: 4.67826
Timestep Consumption Time: 0.74707
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.42533

Cumulative Model Updates: 32,977
Cumulative Timesteps: 550,177,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,899.24935
Policy Entropy: 1.09702
Value Function Loss: 33.54738

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.06785

Collected Steps per Second: 10,567.55290
Overall Steps per Second: 9,001.54265

Timestep Collection Time: 4.73222
Timestep Consumption Time: 0.82327
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.55549

Cumulative Model Updates: 32,980
Cumulative Timesteps: 550,227,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 550227768...
Checkpoint 550227768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410,606.71176
Policy Entropy: 1.09707
Value Function Loss: 32.97455

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.06263

Collected Steps per Second: 10,896.66529
Overall Steps per Second: 9,352.54052

Timestep Collection Time: 4.58911
Timestep Consumption Time: 0.75767
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.34678

Cumulative Model Updates: 32,983
Cumulative Timesteps: 550,277,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,144.74464
Policy Entropy: 1.09419
Value Function Loss: 33.50340

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.06721

Collected Steps per Second: 11,261.89540
Overall Steps per Second: 9,684.44167

Timestep Collection Time: 4.44135
Timestep Consumption Time: 0.72343
PPO Batch Consumption Time: 0.04573
Total Iteration Time: 5.16478

Cumulative Model Updates: 32,986
Cumulative Timesteps: 550,327,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 550327792...
Checkpoint 550327792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,350.35648
Policy Entropy: 1.09704
Value Function Loss: 34.36644

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.08896

Collected Steps per Second: 11,703.02919
Overall Steps per Second: 9,955.92214

Timestep Collection Time: 4.27359
Timestep Consumption Time: 0.74995
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.02354

Cumulative Model Updates: 32,989
Cumulative Timesteps: 550,377,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347,836.40652
Policy Entropy: 1.09676
Value Function Loss: 35.90710

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.09189

Collected Steps per Second: 11,282.44914
Overall Steps per Second: 9,631.89335

Timestep Collection Time: 4.43379
Timestep Consumption Time: 0.75979
PPO Batch Consumption Time: 0.03915
Total Iteration Time: 5.19358

Cumulative Model Updates: 32,992
Cumulative Timesteps: 550,427,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 550427830...
Checkpoint 550427830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,884.87068
Policy Entropy: 1.09721
Value Function Loss: 34.93259

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.10093

Collected Steps per Second: 11,472.17897
Overall Steps per Second: 9,705.02030

Timestep Collection Time: 4.36116
Timestep Consumption Time: 0.79411
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 5.15527

Cumulative Model Updates: 32,995
Cumulative Timesteps: 550,477,862

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,622.02951
Policy Entropy: 1.08953
Value Function Loss: 33.83949

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.10669

Collected Steps per Second: 11,067.13662
Overall Steps per Second: 9,524.63082

Timestep Collection Time: 4.51987
Timestep Consumption Time: 0.73199
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.25186

Cumulative Model Updates: 32,998
Cumulative Timesteps: 550,527,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 550527884...
Checkpoint 550527884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313,954.66292
Policy Entropy: 1.11323
Value Function Loss: 33.96773

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.09336

Collected Steps per Second: 11,030.15815
Overall Steps per Second: 9,539.63243

Timestep Collection Time: 4.53411
Timestep Consumption Time: 0.70844
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.24255

Cumulative Model Updates: 33,001
Cumulative Timesteps: 550,577,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,783.43475
Policy Entropy: 1.11612
Value Function Loss: 33.92120

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.08780

Collected Steps per Second: 11,393.16802
Overall Steps per Second: 9,703.05565

Timestep Collection Time: 4.38947
Timestep Consumption Time: 0.76457
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.15405

Cumulative Model Updates: 33,004
Cumulative Timesteps: 550,627,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 550627906...
Checkpoint 550627906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,409.05248
Policy Entropy: 1.09886
Value Function Loss: 33.78241

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.09799

Collected Steps per Second: 11,048.43848
Overall Steps per Second: 9,425.56195

Timestep Collection Time: 4.52553
Timestep Consumption Time: 0.77920
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.30472

Cumulative Model Updates: 33,007
Cumulative Timesteps: 550,677,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356,782.01239
Policy Entropy: 1.08561
Value Function Loss: 32.79330

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.07929

Collected Steps per Second: 11,256.23361
Overall Steps per Second: 9,512.80369

Timestep Collection Time: 4.44412
Timestep Consumption Time: 0.81448
PPO Batch Consumption Time: 0.03888
Total Iteration Time: 5.25860

Cumulative Model Updates: 33,010
Cumulative Timesteps: 550,727,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 550727930...
Checkpoint 550727930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427,129.26056
Policy Entropy: 1.09199
Value Function Loss: 33.10311

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.07946

Collected Steps per Second: 10,981.69284
Overall Steps per Second: 9,350.99792

Timestep Collection Time: 4.55303
Timestep Consumption Time: 0.79399
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.34702

Cumulative Model Updates: 33,013
Cumulative Timesteps: 550,777,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350,303.71902
Policy Entropy: 1.11042
Value Function Loss: 34.92754

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.07029

Collected Steps per Second: 10,771.58995
Overall Steps per Second: 9,372.87191

Timestep Collection Time: 4.64444
Timestep Consumption Time: 0.69309
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.33753

Cumulative Model Updates: 33,016
Cumulative Timesteps: 550,827,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 550827958...
Checkpoint 550827958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,550.67177
Policy Entropy: 1.09223
Value Function Loss: 33.97860

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.06451

Collected Steps per Second: 10,938.13352
Overall Steps per Second: 9,351.15891

Timestep Collection Time: 4.57391
Timestep Consumption Time: 0.77623
PPO Batch Consumption Time: 0.03908
Total Iteration Time: 5.35014

Cumulative Model Updates: 33,019
Cumulative Timesteps: 550,877,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396,590.33144
Policy Entropy: 1.09237
Value Function Loss: 35.10618

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 10,865.23454
Overall Steps per Second: 9,320.22634

Timestep Collection Time: 4.60441
Timestep Consumption Time: 0.76327
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.36768

Cumulative Model Updates: 33,022
Cumulative Timesteps: 550,928,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 550928016...
Checkpoint 550928016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,470.24585
Policy Entropy: 1.10253
Value Function Loss: 34.48929

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.06504

Collected Steps per Second: 10,860.90076
Overall Steps per Second: 9,405.68894

Timestep Collection Time: 4.60514
Timestep Consumption Time: 0.71249
PPO Batch Consumption Time: 0.04082
Total Iteration Time: 5.31763

Cumulative Model Updates: 33,025
Cumulative Timesteps: 550,978,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,470.55587
Policy Entropy: 1.10274
Value Function Loss: 35.57181

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.04299
Value Function Update Magnitude: 0.06156

Collected Steps per Second: 10,980.91281
Overall Steps per Second: 9,363.73967

Timestep Collection Time: 4.55536
Timestep Consumption Time: 0.78674
PPO Batch Consumption Time: 0.03889
Total Iteration Time: 5.34210

Cumulative Model Updates: 33,028
Cumulative Timesteps: 551,028,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 551028054...
Checkpoint 551028054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,523.70424
Policy Entropy: 1.08736
Value Function Loss: 35.07868

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 10,379.42601
Overall Steps per Second: 8,970.56371

Timestep Collection Time: 4.82011
Timestep Consumption Time: 0.75702
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.57713

Cumulative Model Updates: 33,031
Cumulative Timesteps: 551,078,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379,977.96286
Policy Entropy: 1.06684
Value Function Loss: 33.50206

Mean KL Divergence: 0.03069
SB3 Clip Fraction: 0.18585
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.07801

Collected Steps per Second: 11,051.05858
Overall Steps per Second: 9,404.23207

Timestep Collection Time: 4.52644
Timestep Consumption Time: 0.79265
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.31909

Cumulative Model Updates: 33,034
Cumulative Timesteps: 551,128,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 551128106...
Checkpoint 551128106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,750.02080
Policy Entropy: 1.08126
Value Function Loss: 32.52045

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07656

Collected Steps per Second: 10,721.33212
Overall Steps per Second: 9,147.41262

Timestep Collection Time: 4.66621
Timestep Consumption Time: 0.80288
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.46909

Cumulative Model Updates: 33,037
Cumulative Timesteps: 551,178,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,715.97654
Policy Entropy: 1.08105
Value Function Loss: 30.42221

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 10,712.31450
Overall Steps per Second: 9,290.70464

Timestep Collection Time: 4.66827
Timestep Consumption Time: 0.71431
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.38258

Cumulative Model Updates: 33,040
Cumulative Timesteps: 551,228,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 551228142...
Checkpoint 551228142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,162.82008
Policy Entropy: 1.08942
Value Function Loss: 31.02682

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.07481

Collected Steps per Second: 10,985.54498
Overall Steps per Second: 9,334.35625

Timestep Collection Time: 4.55380
Timestep Consumption Time: 0.80554
PPO Batch Consumption Time: 0.03778
Total Iteration Time: 5.35934

Cumulative Model Updates: 33,043
Cumulative Timesteps: 551,278,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439,386.65640
Policy Entropy: 1.07979
Value Function Loss: 32.36227

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.06888

Collected Steps per Second: 10,657.30398
Overall Steps per Second: 9,160.91295

Timestep Collection Time: 4.69256
Timestep Consumption Time: 0.76651
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 5.45906

Cumulative Model Updates: 33,046
Cumulative Timesteps: 551,328,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 551328178...
Checkpoint 551328178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,046.48928
Policy Entropy: 1.09025
Value Function Loss: 34.05870

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 10,136.05867
Overall Steps per Second: 8,857.35655

Timestep Collection Time: 4.93367
Timestep Consumption Time: 0.71226
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.64593

Cumulative Model Updates: 33,049
Cumulative Timesteps: 551,378,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,279.89698
Policy Entropy: 1.09555
Value Function Loss: 34.68526

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.07648

Collected Steps per Second: 11,701.48816
Overall Steps per Second: 9,869.32432

Timestep Collection Time: 4.27313
Timestep Consumption Time: 0.79327
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 5.06641

Cumulative Model Updates: 33,052
Cumulative Timesteps: 551,428,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 551428188...
Checkpoint 551428188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,366.87129
Policy Entropy: 1.08351
Value Function Loss: 32.84333

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.07330

Collected Steps per Second: 11,665.64297
Overall Steps per Second: 9,868.70416

Timestep Collection Time: 4.28660
Timestep Consumption Time: 0.78052
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.06713

Cumulative Model Updates: 33,055
Cumulative Timesteps: 551,478,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427,300.76962
Policy Entropy: 1.07001
Value Function Loss: 30.60596

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.06762

Collected Steps per Second: 11,504.39038
Overall Steps per Second: 9,738.52060

Timestep Collection Time: 4.34825
Timestep Consumption Time: 0.78846
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 5.13671

Cumulative Model Updates: 33,058
Cumulative Timesteps: 551,528,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 551528218...
Checkpoint 551528218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,589.31003
Policy Entropy: 1.07157
Value Function Loss: 32.00189

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 11,928.33514
Overall Steps per Second: 10,086.54030

Timestep Collection Time: 4.19170
Timestep Consumption Time: 0.76540
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 4.95710

Cumulative Model Updates: 33,061
Cumulative Timesteps: 551,578,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,047.01619
Policy Entropy: 1.08280
Value Function Loss: 34.05847

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.15075
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.07124

Collected Steps per Second: 11,527.27842
Overall Steps per Second: 9,787.73508

Timestep Collection Time: 4.33875
Timestep Consumption Time: 0.77111
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.10986

Cumulative Model Updates: 33,064
Cumulative Timesteps: 551,628,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 551628232...
Checkpoint 551628232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,117.67391
Policy Entropy: 1.07547
Value Function Loss: 36.50215

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.07336

Collected Steps per Second: 11,851.54038
Overall Steps per Second: 9,954.84531

Timestep Collection Time: 4.21987
Timestep Consumption Time: 0.80401
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.02389

Cumulative Model Updates: 33,067
Cumulative Timesteps: 551,678,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,970.89898
Policy Entropy: 1.05747
Value Function Loss: 36.12741

Mean KL Divergence: 0.03966
SB3 Clip Fraction: 0.19213
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.06993

Collected Steps per Second: 10,600.60180
Overall Steps per Second: 9,108.30708

Timestep Collection Time: 4.71879
Timestep Consumption Time: 0.77312
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 5.49191

Cumulative Model Updates: 33,070
Cumulative Timesteps: 551,728,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 551728266...
Checkpoint 551728266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,038.40937
Policy Entropy: 1.08667
Value Function Loss: 34.09737

Mean KL Divergence: 0.03922
SB3 Clip Fraction: 0.18973
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.06647

Collected Steps per Second: 11,041.86325
Overall Steps per Second: 9,573.36380

Timestep Collection Time: 4.53094
Timestep Consumption Time: 0.69502
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 5.22596

Cumulative Model Updates: 33,073
Cumulative Timesteps: 551,778,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,140.52346
Policy Entropy: 1.05163
Value Function Loss: 33.40545

Mean KL Divergence: 0.06109
SB3 Clip Fraction: 0.23153
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.07854

Collected Steps per Second: 11,009.32198
Overall Steps per Second: 9,398.99344

Timestep Collection Time: 4.54288
Timestep Consumption Time: 0.77833
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.32121

Cumulative Model Updates: 33,076
Cumulative Timesteps: 551,828,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 551828310...
Checkpoint 551828310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410,881.18375
Policy Entropy: 1.08725
Value Function Loss: 32.05935

Mean KL Divergence: 0.05305
SB3 Clip Fraction: 0.22360
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.08444

Collected Steps per Second: 11,218.69181
Overall Steps per Second: 9,567.44804

Timestep Collection Time: 4.45774
Timestep Consumption Time: 0.76936
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 5.22710

Cumulative Model Updates: 33,079
Cumulative Timesteps: 551,878,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340,114.67283
Policy Entropy: 1.06233
Value Function Loss: 31.87232

Mean KL Divergence: 0.06748
SB3 Clip Fraction: 0.22457
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.08185

Collected Steps per Second: 9,948.16430
Overall Steps per Second: 8,541.88485

Timestep Collection Time: 5.02847
Timestep Consumption Time: 0.82785
PPO Batch Consumption Time: 0.04767
Total Iteration Time: 5.85632

Cumulative Model Updates: 33,082
Cumulative Timesteps: 551,928,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 551928344...
Checkpoint 551928344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,549.33276
Policy Entropy: 1.08498
Value Function Loss: 31.43951

Mean KL Divergence: 0.04609
SB3 Clip Fraction: 0.20770
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.07872

Collected Steps per Second: 11,119.35277
Overall Steps per Second: 9,431.43341

Timestep Collection Time: 4.49828
Timestep Consumption Time: 0.80505
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.30333

Cumulative Model Updates: 33,085
Cumulative Timesteps: 551,978,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,227.00837
Policy Entropy: 1.07159
Value Function Loss: 31.48069

Mean KL Divergence: 0.03429
SB3 Clip Fraction: 0.17144
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.07277

Collected Steps per Second: 11,235.62545
Overall Steps per Second: 9,726.60788

Timestep Collection Time: 4.45209
Timestep Consumption Time: 0.69071
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.14280

Cumulative Model Updates: 33,088
Cumulative Timesteps: 552,028,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 552028384...
Checkpoint 552028384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,577.95027
Policy Entropy: 1.07036
Value Function Loss: 31.07184

Mean KL Divergence: 0.02617
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.06708

Collected Steps per Second: 10,827.51415
Overall Steps per Second: 9,291.61261

Timestep Collection Time: 4.62008
Timestep Consumption Time: 0.76370
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.38378

Cumulative Model Updates: 33,091
Cumulative Timesteps: 552,078,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416,186.45707
Policy Entropy: 1.07707
Value Function Loss: 30.54567

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.06740

Collected Steps per Second: 10,672.93923
Overall Steps per Second: 9,221.73593

Timestep Collection Time: 4.68699
Timestep Consumption Time: 0.73758
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 5.42458

Cumulative Model Updates: 33,094
Cumulative Timesteps: 552,128,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 552128432...
Checkpoint 552128432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,524.38524
Policy Entropy: 1.07878
Value Function Loss: 30.18149

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.07172

Collected Steps per Second: 10,895.16508
Overall Steps per Second: 9,319.35502

Timestep Collection Time: 4.59029
Timestep Consumption Time: 0.77617
PPO Batch Consumption Time: 0.03896
Total Iteration Time: 5.36647

Cumulative Model Updates: 33,097
Cumulative Timesteps: 552,178,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,002.44702
Policy Entropy: 1.08470
Value Function Loss: 30.98895

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.08166

Collected Steps per Second: 10,334.35644
Overall Steps per Second: 8,972.21874

Timestep Collection Time: 4.83862
Timestep Consumption Time: 0.73459
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 5.57320

Cumulative Model Updates: 33,100
Cumulative Timesteps: 552,228,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 552228448...
Checkpoint 552228448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,828.67174
Policy Entropy: 1.08450
Value Function Loss: 32.71493

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.07276

Collected Steps per Second: 10,593.39426
Overall Steps per Second: 9,265.33264

Timestep Collection Time: 4.72049
Timestep Consumption Time: 0.67662
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.39711

Cumulative Model Updates: 33,103
Cumulative Timesteps: 552,278,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420,125.98063
Policy Entropy: 1.08733
Value Function Loss: 34.33952

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.06839

Collected Steps per Second: 10,755.49884
Overall Steps per Second: 9,118.14387

Timestep Collection Time: 4.64934
Timestep Consumption Time: 0.83489
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.48423

Cumulative Model Updates: 33,106
Cumulative Timesteps: 552,328,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 552328460...
Checkpoint 552328460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432,959.64132
Policy Entropy: 1.09197
Value Function Loss: 35.14860

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.07205

Collected Steps per Second: 10,990.48512
Overall Steps per Second: 9,558.88438

Timestep Collection Time: 4.55103
Timestep Consumption Time: 0.68159
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.23262

Cumulative Model Updates: 33,109
Cumulative Timesteps: 552,378,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,365.23447
Policy Entropy: 1.10070
Value Function Loss: 34.32340

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.08438

Collected Steps per Second: 10,925.01234
Overall Steps per Second: 9,340.06302

Timestep Collection Time: 4.57702
Timestep Consumption Time: 0.77669
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.35371

Cumulative Model Updates: 33,112
Cumulative Timesteps: 552,428,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 552428482...
Checkpoint 552428482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,402.26886
Policy Entropy: 1.08766
Value Function Loss: 32.80952

Mean KL Divergence: 0.02363
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 10,475.66768
Overall Steps per Second: 9,179.43829

Timestep Collection Time: 4.77545
Timestep Consumption Time: 0.67434
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.44979

Cumulative Model Updates: 33,115
Cumulative Timesteps: 552,478,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399,157.08319
Policy Entropy: 1.08451
Value Function Loss: 31.71895

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.16162
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.05965

Collected Steps per Second: 11,181.00237
Overall Steps per Second: 9,599.70162

Timestep Collection Time: 4.47312
Timestep Consumption Time: 0.73683
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.20995

Cumulative Model Updates: 33,118
Cumulative Timesteps: 552,528,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 552528522...
Checkpoint 552528522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,834.02988
Policy Entropy: 1.08900
Value Function Loss: 32.39228

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.04725

Collected Steps per Second: 11,153.87864
Overall Steps per Second: 9,499.27966

Timestep Collection Time: 4.48526
Timestep Consumption Time: 0.78125
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.26650

Cumulative Model Updates: 33,121
Cumulative Timesteps: 552,578,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,508.03612
Policy Entropy: 1.10313
Value Function Loss: 33.17544

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.04812

Collected Steps per Second: 11,373.52820
Overall Steps per Second: 9,865.76168

Timestep Collection Time: 4.39688
Timestep Consumption Time: 0.67197
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 5.06884

Cumulative Model Updates: 33,124
Cumulative Timesteps: 552,628,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 552628558...
Checkpoint 552628558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380,606.11029
Policy Entropy: 1.08044
Value Function Loss: 32.73398

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.15081
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.04792

Collected Steps per Second: 11,230.19102
Overall Steps per Second: 9,600.83332

Timestep Collection Time: 4.45264
Timestep Consumption Time: 0.75566
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.20830

Cumulative Model Updates: 33,127
Cumulative Timesteps: 552,678,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,609.07359
Policy Entropy: 1.10096
Value Function Loss: 32.06083

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.04410

Collected Steps per Second: 11,121.14730
Overall Steps per Second: 9,444.11065

Timestep Collection Time: 4.49828
Timestep Consumption Time: 0.79878
PPO Batch Consumption Time: 0.04151
Total Iteration Time: 5.29706

Cumulative Model Updates: 33,130
Cumulative Timesteps: 552,728,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 552728588...
Checkpoint 552728588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414,617.90768
Policy Entropy: 1.09853
Value Function Loss: 31.59814

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.04467

Collected Steps per Second: 10,930.08823
Overall Steps per Second: 9,342.75179

Timestep Collection Time: 4.57636
Timestep Consumption Time: 0.77752
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.35388

Cumulative Model Updates: 33,133
Cumulative Timesteps: 552,778,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,274.46608
Policy Entropy: 1.08484
Value Function Loss: 31.94021

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.04391

Collected Steps per Second: 11,245.37756
Overall Steps per Second: 9,550.77351

Timestep Collection Time: 4.44716
Timestep Consumption Time: 0.78906
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.23623

Cumulative Model Updates: 33,136
Cumulative Timesteps: 552,828,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 552828618...
Checkpoint 552828618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,773.18825
Policy Entropy: 1.07357
Value Function Loss: 31.85851

Mean KL Divergence: 0.03045
SB3 Clip Fraction: 0.16865
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.04445

Collected Steps per Second: 10,952.31637
Overall Steps per Second: 9,538.32617

Timestep Collection Time: 4.56689
Timestep Consumption Time: 0.67701
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.24390

Cumulative Model Updates: 33,139
Cumulative Timesteps: 552,878,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,111.46838
Policy Entropy: 1.08754
Value Function Loss: 31.30690

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.04182

Collected Steps per Second: 11,113.67804
Overall Steps per Second: 9,471.17332

Timestep Collection Time: 4.50040
Timestep Consumption Time: 0.78047
PPO Batch Consumption Time: 0.03332
Total Iteration Time: 5.28087

Cumulative Model Updates: 33,142
Cumulative Timesteps: 552,928,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 552928652...
Checkpoint 552928652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,146.24147
Policy Entropy: 1.09346
Value Function Loss: 32.02403

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.04669

Collected Steps per Second: 11,100.22480
Overall Steps per Second: 9,470.47307

Timestep Collection Time: 4.50658
Timestep Consumption Time: 0.77553
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 5.28210

Cumulative Model Updates: 33,145
Cumulative Timesteps: 552,978,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403,695.06989
Policy Entropy: 1.07962
Value Function Loss: 32.34288

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.11257
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.05391

Collected Steps per Second: 11,036.41788
Overall Steps per Second: 9,566.62657

Timestep Collection Time: 4.53154
Timestep Consumption Time: 0.69621
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.22776

Cumulative Model Updates: 33,148
Cumulative Timesteps: 553,028,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 553028688...
Checkpoint 553028688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,578.37632
Policy Entropy: 1.07665
Value Function Loss: 33.60486

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.05858

Collected Steps per Second: 10,975.54937
Overall Steps per Second: 9,374.57226

Timestep Collection Time: 4.55777
Timestep Consumption Time: 0.77837
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.33614

Cumulative Model Updates: 33,151
Cumulative Timesteps: 553,078,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,728.93948
Policy Entropy: 1.07014
Value Function Loss: 32.35457

Mean KL Divergence: 0.03601
SB3 Clip Fraction: 0.16087
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.05797

Collected Steps per Second: 10,797.68922
Overall Steps per Second: 9,330.63602

Timestep Collection Time: 4.63136
Timestep Consumption Time: 0.72819
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 5.35955

Cumulative Model Updates: 33,154
Cumulative Timesteps: 553,128,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 553128720...
Checkpoint 553128720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,284.85464
Policy Entropy: 1.08041
Value Function Loss: 31.27439

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.05625

Collected Steps per Second: 11,176.21260
Overall Steps per Second: 9,534.16273

Timestep Collection Time: 4.47629
Timestep Consumption Time: 0.77094
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.24724

Cumulative Model Updates: 33,157
Cumulative Timesteps: 553,178,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,858.42867
Policy Entropy: 1.08118
Value Function Loss: 29.85678

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.06193

Collected Steps per Second: 10,665.98890
Overall Steps per Second: 9,139.19447

Timestep Collection Time: 4.68836
Timestep Consumption Time: 0.78324
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.47160

Cumulative Model Updates: 33,160
Cumulative Timesteps: 553,228,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 553228754...
Checkpoint 553228754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,179.37422
Policy Entropy: 1.08022
Value Function Loss: 29.84817

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.06071
Value Function Update Magnitude: 0.05734

Collected Steps per Second: 10,818.47905
Overall Steps per Second: 9,449.69714

Timestep Collection Time: 4.62265
Timestep Consumption Time: 0.66959
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.29223

Cumulative Model Updates: 33,163
Cumulative Timesteps: 553,278,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,621.95705
Policy Entropy: 1.08271
Value Function Loss: 29.00737

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.06666

Collected Steps per Second: 10,558.96628
Overall Steps per Second: 9,045.91073

Timestep Collection Time: 4.73645
Timestep Consumption Time: 0.79224
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.52869

Cumulative Model Updates: 33,166
Cumulative Timesteps: 553,328,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 553328776...
Checkpoint 553328776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,228.29092
Policy Entropy: 1.08525
Value Function Loss: 29.51102

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.06524

Collected Steps per Second: 10,807.57191
Overall Steps per Second: 9,244.62627

Timestep Collection Time: 4.62787
Timestep Consumption Time: 0.78241
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.41028

Cumulative Model Updates: 33,169
Cumulative Timesteps: 553,378,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,540.67010
Policy Entropy: 1.09203
Value Function Loss: 31.28995

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.06242

Collected Steps per Second: 11,216.19565
Overall Steps per Second: 9,533.07058

Timestep Collection Time: 4.45784
Timestep Consumption Time: 0.78706
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.24490

Cumulative Model Updates: 33,172
Cumulative Timesteps: 553,428,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 553428792...
Checkpoint 553428792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419,773.14286
Policy Entropy: 1.10506
Value Function Loss: 31.75241

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.05123

Collected Steps per Second: 10,771.34084
Overall Steps per Second: 9,246.42197

Timestep Collection Time: 4.64380
Timestep Consumption Time: 0.76586
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.40966

Cumulative Model Updates: 33,175
Cumulative Timesteps: 553,478,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,706.01511
Policy Entropy: 1.09752
Value Function Loss: 31.95926

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.06732
Value Function Update Magnitude: 0.04759

Collected Steps per Second: 11,055.60536
Overall Steps per Second: 9,589.45018

Timestep Collection Time: 4.52295
Timestep Consumption Time: 0.69153
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.21448

Cumulative Model Updates: 33,178
Cumulative Timesteps: 553,528,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 553528816...
Checkpoint 553528816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364,953.68559
Policy Entropy: 1.09906
Value Function Loss: 31.45997

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.06005
Value Function Update Magnitude: 0.04725

Collected Steps per Second: 10,667.06604
Overall Steps per Second: 9,128.21844

Timestep Collection Time: 4.68732
Timestep Consumption Time: 0.79020
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.47752

Cumulative Model Updates: 33,181
Cumulative Timesteps: 553,578,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,507.01436
Policy Entropy: 1.08996
Value Function Loss: 31.99878

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.11866
Policy Update Magnitude: 0.06734
Value Function Update Magnitude: 0.04448

Collected Steps per Second: 10,480.76775
Overall Steps per Second: 8,998.31020

Timestep Collection Time: 4.77083
Timestep Consumption Time: 0.78599
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 5.55682

Cumulative Model Updates: 33,184
Cumulative Timesteps: 553,628,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 553628818...
Checkpoint 553628818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,766.58187
Policy Entropy: 1.08004
Value Function Loss: 32.37431

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.04354

Collected Steps per Second: 11,751.99840
Overall Steps per Second: 10,112.37940

Timestep Collection Time: 4.25715
Timestep Consumption Time: 0.69025
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.94740

Cumulative Model Updates: 33,187
Cumulative Timesteps: 553,678,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,459.77002
Policy Entropy: 1.06863
Value Function Loss: 32.19836

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.16191
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 12,034.49018
Overall Steps per Second: 10,102.91201

Timestep Collection Time: 4.15672
Timestep Consumption Time: 0.79472
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.95144

Cumulative Model Updates: 33,190
Cumulative Timesteps: 553,728,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 553728872...
Checkpoint 553728872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329,747.12964
Policy Entropy: 1.08233
Value Function Loss: 32.18401

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.05811

Collected Steps per Second: 11,867.57111
Overall Steps per Second: 10,129.90487

Timestep Collection Time: 4.21552
Timestep Consumption Time: 0.72312
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.93864

Cumulative Model Updates: 33,193
Cumulative Timesteps: 553,778,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377,542.27817
Policy Entropy: 1.08757
Value Function Loss: 31.41079

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.04675

Collected Steps per Second: 11,711.80128
Overall Steps per Second: 9,941.02697

Timestep Collection Time: 4.27091
Timestep Consumption Time: 0.76077
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.03167

Cumulative Model Updates: 33,196
Cumulative Timesteps: 553,828,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 553828920...
Checkpoint 553828920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,906.43675
Policy Entropy: 1.07406
Value Function Loss: 31.42153

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.04194

Collected Steps per Second: 11,847.77671
Overall Steps per Second: 10,032.95370

Timestep Collection Time: 4.22071
Timestep Consumption Time: 0.76347
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.98418

Cumulative Model Updates: 33,199
Cumulative Timesteps: 553,878,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,186.32781
Policy Entropy: 1.05461
Value Function Loss: 31.36685

Mean KL Divergence: 0.04106
SB3 Clip Fraction: 0.19665
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.04671

Collected Steps per Second: 11,059.92993
Overall Steps per Second: 9,633.31729

Timestep Collection Time: 4.52137
Timestep Consumption Time: 0.66958
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.19094

Cumulative Model Updates: 33,202
Cumulative Timesteps: 553,928,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 553928932...
Checkpoint 553928932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,108.19577
Policy Entropy: 1.07847
Value Function Loss: 31.31379

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.04357

Collected Steps per Second: 11,182.04720
Overall Steps per Second: 9,470.21085

Timestep Collection Time: 4.47288
Timestep Consumption Time: 0.80852
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 5.28140

Cumulative Model Updates: 33,205
Cumulative Timesteps: 553,978,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,926.22482
Policy Entropy: 1.06931
Value Function Loss: 31.43839

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 11,071.28690
Overall Steps per Second: 9,477.66140

Timestep Collection Time: 4.51763
Timestep Consumption Time: 0.75962
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.27725

Cumulative Model Updates: 33,208
Cumulative Timesteps: 554,028,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 554028964...
Checkpoint 554028964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432,782.82903
Policy Entropy: 1.06558
Value Function Loss: 31.51330

Mean KL Divergence: 0.03244
SB3 Clip Fraction: 0.17050
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.04196

Collected Steps per Second: 11,028.12277
Overall Steps per Second: 9,405.61445

Timestep Collection Time: 4.53386
Timestep Consumption Time: 0.78211
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.31597

Cumulative Model Updates: 33,211
Cumulative Timesteps: 554,078,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,721.43361
Policy Entropy: 1.07659
Value Function Loss: 30.98350

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.04449

Collected Steps per Second: 11,154.02694
Overall Steps per Second: 9,443.72191

Timestep Collection Time: 4.48358
Timestep Consumption Time: 0.81200
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 5.29558

Cumulative Model Updates: 33,214
Cumulative Timesteps: 554,128,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 554128974...
Checkpoint 554128974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354,435.54280
Policy Entropy: 1.09065
Value Function Loss: 31.42053

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.04304

Collected Steps per Second: 10,815.89329
Overall Steps per Second: 9,395.38895

Timestep Collection Time: 4.62320
Timestep Consumption Time: 0.69899
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.32219

Cumulative Model Updates: 33,217
Cumulative Timesteps: 554,178,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,222.71030
Policy Entropy: 1.06307
Value Function Loss: 31.05806

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.05454

Collected Steps per Second: 11,309.90438
Overall Steps per Second: 9,646.04134

Timestep Collection Time: 4.42303
Timestep Consumption Time: 0.76294
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.18596

Cumulative Model Updates: 33,220
Cumulative Timesteps: 554,229,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 554229002...
Checkpoint 554229002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,184.31310
Policy Entropy: 1.05289
Value Function Loss: 31.93207

Mean KL Divergence: 0.02912
SB3 Clip Fraction: 0.16464
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.04637

Collected Steps per Second: 10,813.92081
Overall Steps per Second: 9,442.50272

Timestep Collection Time: 4.62570
Timestep Consumption Time: 0.67183
PPO Batch Consumption Time: 0.04043
Total Iteration Time: 5.29754

Cumulative Model Updates: 33,223
Cumulative Timesteps: 554,279,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,126.96808
Policy Entropy: 1.06202
Value Function Loss: 32.04782

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.04443

Collected Steps per Second: 11,035.81319
Overall Steps per Second: 9,414.64450

Timestep Collection Time: 4.53179
Timestep Consumption Time: 0.78036
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.31215

Cumulative Model Updates: 33,226
Cumulative Timesteps: 554,329,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 554329036...
Checkpoint 554329036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419,299.01045
Policy Entropy: 1.07141
Value Function Loss: 31.27761

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.04318

Collected Steps per Second: 10,906.18100
Overall Steps per Second: 9,388.53448

Timestep Collection Time: 4.58584
Timestep Consumption Time: 0.74130
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.32714

Cumulative Model Updates: 33,229
Cumulative Timesteps: 554,379,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,347.26866
Policy Entropy: 1.06220
Value Function Loss: 30.93502

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.03998

Collected Steps per Second: 11,291.20542
Overall Steps per Second: 9,657.76250

Timestep Collection Time: 4.42964
Timestep Consumption Time: 0.74920
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.17884

Cumulative Model Updates: 33,232
Cumulative Timesteps: 554,429,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 554429066...
Checkpoint 554429066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,852.28475
Policy Entropy: 1.04796
Value Function Loss: 30.47394

Mean KL Divergence: 0.03351
SB3 Clip Fraction: 0.18371
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.03856

Collected Steps per Second: 10,317.42199
Overall Steps per Second: 8,845.38470

Timestep Collection Time: 4.84927
Timestep Consumption Time: 0.80701
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 5.65628

Cumulative Model Updates: 33,235
Cumulative Timesteps: 554,479,098

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,460.63658
Policy Entropy: 1.06880
Value Function Loss: 31.96510

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.03729

Collected Steps per Second: 11,184.69342
Overall Steps per Second: 9,697.33702

Timestep Collection Time: 4.47129
Timestep Consumption Time: 0.68580
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.15709

Cumulative Model Updates: 33,238
Cumulative Timesteps: 554,529,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 554529108...
Checkpoint 554529108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,000.15164
Policy Entropy: 1.07538
Value Function Loss: 32.28279

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.05788
Value Function Update Magnitude: 0.04195

Collected Steps per Second: 10,529.75389
Overall Steps per Second: 9,011.97472

Timestep Collection Time: 4.74864
Timestep Consumption Time: 0.79976
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 5.54840

Cumulative Model Updates: 33,241
Cumulative Timesteps: 554,579,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398,045.68438
Policy Entropy: 1.06193
Value Function Loss: 31.12166

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.04550

Collected Steps per Second: 10,700.80335
Overall Steps per Second: 9,246.46231

Timestep Collection Time: 4.67423
Timestep Consumption Time: 0.73519
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 5.40942

Cumulative Model Updates: 33,244
Cumulative Timesteps: 554,629,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 554629128...
Checkpoint 554629128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,784.58958
Policy Entropy: 1.05398
Value Function Loss: 30.87671

Mean KL Divergence: 0.02579
SB3 Clip Fraction: 0.16572
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.03987

Collected Steps per Second: 10,651.67300
Overall Steps per Second: 9,122.67453

Timestep Collection Time: 4.69560
Timestep Consumption Time: 0.78700
PPO Batch Consumption Time: 0.03826
Total Iteration Time: 5.48260

Cumulative Model Updates: 33,247
Cumulative Timesteps: 554,679,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,768.41469
Policy Entropy: 1.06390
Value Function Loss: 29.10326

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.04126

Collected Steps per Second: 10,715.68130
Overall Steps per Second: 9,068.04288

Timestep Collection Time: 4.66830
Timestep Consumption Time: 0.84822
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.51652

Cumulative Model Updates: 33,250
Cumulative Timesteps: 554,729,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 554729168...
Checkpoint 554729168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,473.62000
Policy Entropy: 1.07281
Value Function Loss: 32.27088

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.04183
Value Function Update Magnitude: 0.05035

Collected Steps per Second: 10,559.26256
Overall Steps per Second: 9,294.12468

Timestep Collection Time: 4.73632
Timestep Consumption Time: 0.64472
PPO Batch Consumption Time: 0.03379
Total Iteration Time: 5.38103

Cumulative Model Updates: 33,253
Cumulative Timesteps: 554,779,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345,698.41436
Policy Entropy: 1.05220
Value Function Loss: 32.05572

Mean KL Divergence: 0.02891
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.04485

Collected Steps per Second: 11,193.42790
Overall Steps per Second: 9,510.09725

Timestep Collection Time: 4.46744
Timestep Consumption Time: 0.79076
PPO Batch Consumption Time: 0.04488
Total Iteration Time: 5.25820

Cumulative Model Updates: 33,256
Cumulative Timesteps: 554,829,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 554829186...
Checkpoint 554829186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,548.10904
Policy Entropy: 1.06249
Value Function Loss: 31.97911

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.04719

Collected Steps per Second: 11,429.78818
Overall Steps per Second: 9,894.34306

Timestep Collection Time: 4.37698
Timestep Consumption Time: 0.67924
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.05622

Cumulative Model Updates: 33,259
Cumulative Timesteps: 554,879,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,370.09995
Policy Entropy: 1.07511
Value Function Loss: 30.26079

Mean KL Divergence: 0.03404
SB3 Clip Fraction: 0.18663
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.04001

Collected Steps per Second: 11,515.80708
Overall Steps per Second: 9,768.27753

Timestep Collection Time: 4.34307
Timestep Consumption Time: 0.77697
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.12004

Cumulative Model Updates: 33,262
Cumulative Timesteps: 554,929,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 554929228...
Checkpoint 554929228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,664.55025
Policy Entropy: 1.04361
Value Function Loss: 29.40730

Mean KL Divergence: 0.04225
SB3 Clip Fraction: 0.19791
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.03754

Collected Steps per Second: 11,061.45172
Overall Steps per Second: 9,500.91691

Timestep Collection Time: 4.52147
Timestep Consumption Time: 0.74266
PPO Batch Consumption Time: 0.04029
Total Iteration Time: 5.26412

Cumulative Model Updates: 33,265
Cumulative Timesteps: 554,979,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,592.10471
Policy Entropy: 1.07338
Value Function Loss: 31.01661

Mean KL Divergence: 0.02347
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.04444

Collected Steps per Second: 11,090.57203
Overall Steps per Second: 9,438.73642

Timestep Collection Time: 4.50924
Timestep Consumption Time: 0.78914
PPO Batch Consumption Time: 0.03849
Total Iteration Time: 5.29838

Cumulative Model Updates: 33,268
Cumulative Timesteps: 555,029,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 555029252...
Checkpoint 555029252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,682.63732
Policy Entropy: 1.07349
Value Function Loss: 28.66781

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.05591

Collected Steps per Second: 11,428.97476
Overall Steps per Second: 9,649.41898

Timestep Collection Time: 4.37502
Timestep Consumption Time: 0.80685
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.18187

Cumulative Model Updates: 33,271
Cumulative Timesteps: 555,079,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,119.87824
Policy Entropy: 1.06618
Value Function Loss: 28.38554

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.06750

Collected Steps per Second: 11,266.27184
Overall Steps per Second: 9,646.26232

Timestep Collection Time: 4.44016
Timestep Consumption Time: 0.74569
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 5.18584

Cumulative Model Updates: 33,274
Cumulative Timesteps: 555,129,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 555129278...
Checkpoint 555129278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361,094.43521
Policy Entropy: 1.06041
Value Function Loss: 27.67102

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.09898

Collected Steps per Second: 10,870.89799
Overall Steps per Second: 9,275.92273

Timestep Collection Time: 4.60220
Timestep Consumption Time: 0.79134
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 5.39353

Cumulative Model Updates: 33,277
Cumulative Timesteps: 555,179,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,630.23529
Policy Entropy: 1.05398
Value Function Loss: 30.44301

Mean KL Divergence: 0.02582
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.09841

Collected Steps per Second: 11,233.37751
Overall Steps per Second: 9,595.60094

Timestep Collection Time: 4.45245
Timestep Consumption Time: 0.75994
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.21239

Cumulative Model Updates: 33,280
Cumulative Timesteps: 555,229,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 555229324...
Checkpoint 555229324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,104.07794
Policy Entropy: 1.06709
Value Function Loss: 32.20749

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.08311

Collected Steps per Second: 11,215.15239
Overall Steps per Second: 9,553.92742

Timestep Collection Time: 4.45897
Timestep Consumption Time: 0.77532
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.23429

Cumulative Model Updates: 33,283
Cumulative Timesteps: 555,279,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,462.47829
Policy Entropy: 1.06617
Value Function Loss: 31.40716

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.07014

Collected Steps per Second: 10,669.52405
Overall Steps per Second: 9,135.23518

Timestep Collection Time: 4.68718
Timestep Consumption Time: 0.78723
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.47441

Cumulative Model Updates: 33,286
Cumulative Timesteps: 555,329,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 555329342...
Checkpoint 555329342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356,662.29823
Policy Entropy: 1.04998
Value Function Loss: 32.28645

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.07308

Collected Steps per Second: 11,011.93141
Overall Steps per Second: 9,567.19124

Timestep Collection Time: 4.54180
Timestep Consumption Time: 0.68586
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 5.22766

Cumulative Model Updates: 33,289
Cumulative Timesteps: 555,379,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,373.06847
Policy Entropy: 1.03055
Value Function Loss: 30.17261

Mean KL Divergence: 0.03800
SB3 Clip Fraction: 0.20281
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.07924

Collected Steps per Second: 10,843.36973
Overall Steps per Second: 9,337.48873

Timestep Collection Time: 4.61314
Timestep Consumption Time: 0.74397
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.35711

Cumulative Model Updates: 33,292
Cumulative Timesteps: 555,429,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 555429378...
Checkpoint 555429378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,363.43094
Policy Entropy: 1.06437
Value Function Loss: 29.72266

Mean KL Divergence: 0.03569
SB3 Clip Fraction: 0.18647
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.07601

Collected Steps per Second: 10,943.54531
Overall Steps per Second: 9,538.72243

Timestep Collection Time: 4.56963
Timestep Consumption Time: 0.67300
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.24263

Cumulative Model Updates: 33,295
Cumulative Timesteps: 555,479,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,931.78608
Policy Entropy: 1.03739
Value Function Loss: 28.32005

Mean KL Divergence: 0.03394
SB3 Clip Fraction: 0.18481
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.06763

Collected Steps per Second: 10,945.91671
Overall Steps per Second: 9,395.53024

Timestep Collection Time: 4.56864
Timestep Consumption Time: 0.75389
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.32253

Cumulative Model Updates: 33,298
Cumulative Timesteps: 555,529,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 555529394...
Checkpoint 555529394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388,686.30262
Policy Entropy: 1.06215
Value Function Loss: 28.94157

Mean KL Divergence: 0.02558
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.07843

Collected Steps per Second: 11,209.54530
Overall Steps per Second: 9,588.91142

Timestep Collection Time: 4.46209
Timestep Consumption Time: 0.75414
PPO Batch Consumption Time: 0.03829
Total Iteration Time: 5.21623

Cumulative Model Updates: 33,301
Cumulative Timesteps: 555,579,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398,430.02501
Policy Entropy: 1.06463
Value Function Loss: 30.48501

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.06770

Collected Steps per Second: 10,866.65105
Overall Steps per Second: 9,339.21140

Timestep Collection Time: 4.60344
Timestep Consumption Time: 0.75290
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.35634

Cumulative Model Updates: 33,304
Cumulative Timesteps: 555,629,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 555629436...
Checkpoint 555629436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,400.13697
Policy Entropy: 1.05695
Value Function Loss: 29.64651

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.10118

Collected Steps per Second: 10,852.07724
Overall Steps per Second: 9,240.71992

Timestep Collection Time: 4.60944
Timestep Consumption Time: 0.80377
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 5.41321

Cumulative Model Updates: 33,307
Cumulative Timesteps: 555,679,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367,322.33135
Policy Entropy: 1.04400
Value Function Loss: 27.90368

Mean KL Divergence: 0.03388
SB3 Clip Fraction: 0.19026
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.10336

Collected Steps per Second: 10,886.16438
Overall Steps per Second: 9,468.76510

Timestep Collection Time: 4.59537
Timestep Consumption Time: 0.68789
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.28327

Cumulative Model Updates: 33,310
Cumulative Timesteps: 555,729,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 555729484...
Checkpoint 555729484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,335.55453
Policy Entropy: 1.05901
Value Function Loss: 26.75342

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.10675

Collected Steps per Second: 10,890.45860
Overall Steps per Second: 9,312.24521

Timestep Collection Time: 4.59319
Timestep Consumption Time: 0.77844
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 5.37164

Cumulative Model Updates: 33,313
Cumulative Timesteps: 555,779,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,599.81390
Policy Entropy: 1.07004
Value Function Loss: 27.85693

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.16305
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.09788

Collected Steps per Second: 10,934.65830
Overall Steps per Second: 9,285.11159

Timestep Collection Time: 4.57280
Timestep Consumption Time: 0.81238
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.38518

Cumulative Model Updates: 33,316
Cumulative Timesteps: 555,829,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 555829508...
Checkpoint 555829508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,944.17155
Policy Entropy: 1.05627
Value Function Loss: 29.26594

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.08208

Collected Steps per Second: 10,766.72987
Overall Steps per Second: 9,219.42412

Timestep Collection Time: 4.64431
Timestep Consumption Time: 0.77946
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.42377

Cumulative Model Updates: 33,319
Cumulative Timesteps: 555,879,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,264.10902
Policy Entropy: 1.04422
Value Function Loss: 28.98882

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.15601
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 11,278.42285
Overall Steps per Second: 9,554.85870

Timestep Collection Time: 4.43466
Timestep Consumption Time: 0.79995
PPO Batch Consumption Time: 0.03981
Total Iteration Time: 5.23461

Cumulative Model Updates: 33,322
Cumulative Timesteps: 555,929,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 555929528...
Checkpoint 555929528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,597.15357
Policy Entropy: 1.05259
Value Function Loss: 28.08142

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.06816

Collected Steps per Second: 11,769.55051
Overall Steps per Second: 10,197.27298

Timestep Collection Time: 4.24825
Timestep Consumption Time: 0.65502
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.90327

Cumulative Model Updates: 33,325
Cumulative Timesteps: 555,979,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402,334.18732
Policy Entropy: 1.05341
Value Function Loss: 27.98010

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.06921

Collected Steps per Second: 11,806.47301
Overall Steps per Second: 9,911.87934

Timestep Collection Time: 4.23530
Timestep Consumption Time: 0.80955
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 5.04486

Cumulative Model Updates: 33,328
Cumulative Timesteps: 556,029,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 556029532...
Checkpoint 556029532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422,729.86344
Policy Entropy: 1.03973
Value Function Loss: 28.27680

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.06441
Value Function Update Magnitude: 0.06937

Collected Steps per Second: 11,664.01116
Overall Steps per Second: 9,902.34113

Timestep Collection Time: 4.28669
Timestep Consumption Time: 0.76262
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.04931

Cumulative Model Updates: 33,331
Cumulative Timesteps: 556,079,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420,808.09586
Policy Entropy: 1.03610
Value Function Loss: 30.00882

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.16157
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.06929

Collected Steps per Second: 11,875.90748
Overall Steps per Second: 10,251.41342

Timestep Collection Time: 4.21071
Timestep Consumption Time: 0.66725
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 4.87796

Cumulative Model Updates: 33,334
Cumulative Timesteps: 556,129,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 556129538...
Checkpoint 556129538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419,851.35734
Policy Entropy: 1.05069
Value Function Loss: 29.89843

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.06151
Value Function Update Magnitude: 0.06602

Collected Steps per Second: 11,138.13239
Overall Steps per Second: 9,496.45637

Timestep Collection Time: 4.49070
Timestep Consumption Time: 0.77632
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.26702

Cumulative Model Updates: 33,337
Cumulative Timesteps: 556,179,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365,778.33174
Policy Entropy: 1.06472
Value Function Loss: 29.08942

Mean KL Divergence: 0.02449
SB3 Clip Fraction: 0.16267
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.08296

Collected Steps per Second: 11,568.20023
Overall Steps per Second: 9,863.79453

Timestep Collection Time: 4.32237
Timestep Consumption Time: 0.74688
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.06925

Cumulative Model Updates: 33,340
Cumulative Timesteps: 556,229,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 556229558...
Checkpoint 556229558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,853.81157
Policy Entropy: 1.02485
Value Function Loss: 28.12123

Mean KL Divergence: 0.06489
SB3 Clip Fraction: 0.22035
Policy Update Magnitude: 0.06676
Value Function Update Magnitude: 0.08625

Collected Steps per Second: 11,263.43867
Overall Steps per Second: 9,613.02223

Timestep Collection Time: 4.44056
Timestep Consumption Time: 0.76238
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.20294

Cumulative Model Updates: 33,343
Cumulative Timesteps: 556,279,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,974.42415
Policy Entropy: 1.06713
Value Function Loss: 27.80135

Mean KL Divergence: 0.05037
SB3 Clip Fraction: 0.20815
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.09742

Collected Steps per Second: 10,878.26292
Overall Steps per Second: 9,341.64803

Timestep Collection Time: 4.59779
Timestep Consumption Time: 0.75629
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 5.35409

Cumulative Model Updates: 33,346
Cumulative Timesteps: 556,329,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 556329590...
Checkpoint 556329590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,292.64856
Policy Entropy: 1.04012
Value Function Loss: 29.14720

Mean KL Divergence: 0.04992
SB3 Clip Fraction: 0.20040
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.09090

Collected Steps per Second: 11,205.20141
Overall Steps per Second: 9,710.31049

Timestep Collection Time: 4.46239
Timestep Consumption Time: 0.68698
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.14937

Cumulative Model Updates: 33,349
Cumulative Timesteps: 556,379,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,676.78976
Policy Entropy: 1.06388
Value Function Loss: 28.93631

Mean KL Divergence: 0.03110
SB3 Clip Fraction: 0.15693
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.08772

Collected Steps per Second: 11,142.76123
Overall Steps per Second: 9,418.55182

Timestep Collection Time: 4.48740
Timestep Consumption Time: 0.82149
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.30888

Cumulative Model Updates: 33,352
Cumulative Timesteps: 556,429,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 556429594...
Checkpoint 556429594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428,651.25315
Policy Entropy: 1.06241
Value Function Loss: 29.61884

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.09340

Collected Steps per Second: 10,492.54275
Overall Steps per Second: 9,043.92835

Timestep Collection Time: 4.76796
Timestep Consumption Time: 0.76371
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.53167

Cumulative Model Updates: 33,355
Cumulative Timesteps: 556,479,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,294.52124
Policy Entropy: 1.06865
Value Function Loss: 29.20329

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.08771

Collected Steps per Second: 10,959.73660
Overall Steps per Second: 9,372.70607

Timestep Collection Time: 4.56398
Timestep Consumption Time: 0.77279
PPO Batch Consumption Time: 0.03984
Total Iteration Time: 5.33677

Cumulative Model Updates: 33,358
Cumulative Timesteps: 556,529,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 556529642...
Checkpoint 556529642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,173.77266
Policy Entropy: 1.05544
Value Function Loss: 29.62891

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.07902

Collected Steps per Second: 10,988.46249
Overall Steps per Second: 9,408.77286

Timestep Collection Time: 4.55187
Timestep Consumption Time: 0.76424
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 5.31610

Cumulative Model Updates: 33,361
Cumulative Timesteps: 556,579,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,160.93708
Policy Entropy: 1.07428
Value Function Loss: 29.32535

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.07892

Collected Steps per Second: 10,793.60978
Overall Steps per Second: 9,396.20409

Timestep Collection Time: 4.63385
Timestep Consumption Time: 0.68915
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.32300

Cumulative Model Updates: 33,364
Cumulative Timesteps: 556,629,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 556629676...
Checkpoint 556629676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,648.53176
Policy Entropy: 1.07933
Value Function Loss: 28.81184

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.07660

Collected Steps per Second: 10,760.65782
Overall Steps per Second: 9,226.63684

Timestep Collection Time: 4.64841
Timestep Consumption Time: 0.77285
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.42126

Cumulative Model Updates: 33,367
Cumulative Timesteps: 556,679,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,563.26216
Policy Entropy: 1.07232
Value Function Loss: 28.50665

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.07780
Value Function Update Magnitude: 0.07030

Collected Steps per Second: 10,883.53848
Overall Steps per Second: 9,248.38582

Timestep Collection Time: 4.59667
Timestep Consumption Time: 0.81271
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.40938

Cumulative Model Updates: 33,370
Cumulative Timesteps: 556,729,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 556729724...
Checkpoint 556729724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,137.45139
Policy Entropy: 1.06120
Value Function Loss: 29.57339

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.07507
Value Function Update Magnitude: 0.06960

Collected Steps per Second: 10,884.34948
Overall Steps per Second: 9,303.34144

Timestep Collection Time: 4.59522
Timestep Consumption Time: 0.78091
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.37613

Cumulative Model Updates: 33,373
Cumulative Timesteps: 556,779,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,131.94494
Policy Entropy: 1.06065
Value Function Loss: 29.31363

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.11472
Policy Update Magnitude: 0.07120
Value Function Update Magnitude: 0.07012

Collected Steps per Second: 10,919.79175
Overall Steps per Second: 9,340.56821

Timestep Collection Time: 4.57884
Timestep Consumption Time: 0.77415
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.35299

Cumulative Model Updates: 33,376
Cumulative Timesteps: 556,829,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 556829740...
Checkpoint 556829740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336,545.33733
Policy Entropy: 1.06975
Value Function Loss: 29.75145

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.06526
Value Function Update Magnitude: 0.06517

Collected Steps per Second: 10,784.10474
Overall Steps per Second: 9,385.17477

Timestep Collection Time: 4.63682
Timestep Consumption Time: 0.69115
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.32798

Cumulative Model Updates: 33,379
Cumulative Timesteps: 556,879,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,696.11509
Policy Entropy: 1.08198
Value Function Loss: 28.32091

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.05850

Collected Steps per Second: 10,966.00545
Overall Steps per Second: 9,350.86132

Timestep Collection Time: 4.56082
Timestep Consumption Time: 0.78778
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.34860

Cumulative Model Updates: 33,382
Cumulative Timesteps: 556,929,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 556929758...
Checkpoint 556929758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,953.68893
Policy Entropy: 1.08384
Value Function Loss: 28.65484

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.05958

Collected Steps per Second: 10,509.86706
Overall Steps per Second: 9,143.15930

Timestep Collection Time: 4.75800
Timestep Consumption Time: 0.71122
PPO Batch Consumption Time: 0.03907
Total Iteration Time: 5.46923

Cumulative Model Updates: 33,385
Cumulative Timesteps: 556,979,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356,109.77177
Policy Entropy: 1.09271
Value Function Loss: 27.57842

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.12321
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.08045

Collected Steps per Second: 10,718.08467
Overall Steps per Second: 9,177.10587

Timestep Collection Time: 4.66632
Timestep Consumption Time: 0.78355
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.44987

Cumulative Model Updates: 33,388
Cumulative Timesteps: 557,029,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 557029778...
Checkpoint 557029778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,545.87109
Policy Entropy: 1.09841
Value Function Loss: 28.49458

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.08524

Collected Steps per Second: 11,166.46883
Overall Steps per Second: 9,589.41492

Timestep Collection Time: 4.47841
Timestep Consumption Time: 0.73651
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 5.21492

Cumulative Model Updates: 33,391
Cumulative Timesteps: 557,079,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410,718.25331
Policy Entropy: 1.09599
Value Function Loss: 27.77638

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.09399

Collected Steps per Second: 11,192.05601
Overall Steps per Second: 9,660.43458

Timestep Collection Time: 4.46871
Timestep Consumption Time: 0.70849
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.17720

Cumulative Model Updates: 33,394
Cumulative Timesteps: 557,129,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 557129800...
Checkpoint 557129800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,215.03794
Policy Entropy: 1.09141
Value Function Loss: 28.37167

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.06477
Value Function Update Magnitude: 0.08106

Collected Steps per Second: 11,326.87784
Overall Steps per Second: 9,615.98131

Timestep Collection Time: 4.41604
Timestep Consumption Time: 0.78571
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.20176

Cumulative Model Updates: 33,397
Cumulative Timesteps: 557,179,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,143.11027
Policy Entropy: 1.08657
Value Function Loss: 27.01747

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.06867
Value Function Update Magnitude: 0.07647

Collected Steps per Second: 11,314.90149
Overall Steps per Second: 9,779.98762

Timestep Collection Time: 4.42072
Timestep Consumption Time: 0.69381
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.11453

Cumulative Model Updates: 33,400
Cumulative Timesteps: 557,229,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 557229840...
Checkpoint 557229840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403,771.39914
Policy Entropy: 1.08133
Value Function Loss: 27.35109

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.07278

Collected Steps per Second: 11,629.46587
Overall Steps per Second: 9,817.92312

Timestep Collection Time: 4.30166
Timestep Consumption Time: 0.79372
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.09537

Cumulative Model Updates: 33,403
Cumulative Timesteps: 557,279,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404,508.05398
Policy Entropy: 1.09665
Value Function Loss: 26.43936

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.06461

Collected Steps per Second: 10,662.31516
Overall Steps per Second: 9,125.81668

Timestep Collection Time: 4.69073
Timestep Consumption Time: 0.78977
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.48050

Cumulative Model Updates: 33,406
Cumulative Timesteps: 557,329,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 557329880...
Checkpoint 557329880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,071.70773
Policy Entropy: 1.10552
Value Function Loss: 26.94570

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.07075

Collected Steps per Second: 11,016.36232
Overall Steps per Second: 9,500.65056

Timestep Collection Time: 4.53870
Timestep Consumption Time: 0.72409
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.26280

Cumulative Model Updates: 33,409
Cumulative Timesteps: 557,379,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354,965.79772
Policy Entropy: 1.09058
Value Function Loss: 27.11276

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.08777

Collected Steps per Second: 10,733.29245
Overall Steps per Second: 9,093.77728

Timestep Collection Time: 4.66027
Timestep Consumption Time: 0.84020
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.50046

Cumulative Model Updates: 33,412
Cumulative Timesteps: 557,429,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 557429900...
Checkpoint 557429900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427,554.67913
Policy Entropy: 1.08780
Value Function Loss: 27.91618

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.08916

Collected Steps per Second: 10,750.46931
Overall Steps per Second: 9,267.07376

Timestep Collection Time: 4.65170
Timestep Consumption Time: 0.74461
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 5.39631

Cumulative Model Updates: 33,415
Cumulative Timesteps: 557,479,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,890.48248
Policy Entropy: 1.10401
Value Function Loss: 28.11971

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.09288

Collected Steps per Second: 11,324.03665
Overall Steps per Second: 9,604.15178

Timestep Collection Time: 4.41733
Timestep Consumption Time: 0.79104
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 5.20837

Cumulative Model Updates: 33,418
Cumulative Timesteps: 557,529,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 557529930...
Checkpoint 557529930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342,562.37569
Policy Entropy: 1.11118
Value Function Loss: 28.77644

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.08373

Collected Steps per Second: 10,569.19325
Overall Steps per Second: 9,068.40591

Timestep Collection Time: 4.73111
Timestep Consumption Time: 0.78298
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.51409

Cumulative Model Updates: 33,421
Cumulative Timesteps: 557,579,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408,711.53341
Policy Entropy: 1.09261
Value Function Loss: 28.45999

Mean KL Divergence: 0.03494
SB3 Clip Fraction: 0.16437
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.07917

Collected Steps per Second: 11,149.53195
Overall Steps per Second: 9,640.12525

Timestep Collection Time: 4.48611
Timestep Consumption Time: 0.70241
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 5.18852

Cumulative Model Updates: 33,424
Cumulative Timesteps: 557,629,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 557629952...
Checkpoint 557629952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397,052.61202
Policy Entropy: 1.11123
Value Function Loss: 28.03157

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.06646

Collected Steps per Second: 10,801.23157
Overall Steps per Second: 9,286.96035

Timestep Collection Time: 4.63040
Timestep Consumption Time: 0.75500
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.38540

Cumulative Model Updates: 33,427
Cumulative Timesteps: 557,679,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325,494.86077
Policy Entropy: 1.10631
Value Function Loss: 26.22135

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.04495
Value Function Update Magnitude: 0.07206

Collected Steps per Second: 10,953.64468
Overall Steps per Second: 9,391.94412

Timestep Collection Time: 4.56469
Timestep Consumption Time: 0.75902
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.32371

Cumulative Model Updates: 33,430
Cumulative Timesteps: 557,729,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 557729966...
Checkpoint 557729966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380,554.71308
Policy Entropy: 1.09540
Value Function Loss: 25.59910

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.06382

Collected Steps per Second: 11,128.13548
Overall Steps per Second: 9,478.28848

Timestep Collection Time: 4.49545
Timestep Consumption Time: 0.78251
PPO Batch Consumption Time: 0.03858
Total Iteration Time: 5.27796

Cumulative Model Updates: 33,433
Cumulative Timesteps: 557,779,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,830.38494
Policy Entropy: 1.06984
Value Function Loss: 24.65314

Mean KL Divergence: 0.04634
SB3 Clip Fraction: 0.18965
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 11,253.22923
Overall Steps per Second: 9,645.18208

Timestep Collection Time: 4.44406
Timestep Consumption Time: 0.74091
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.18497

Cumulative Model Updates: 33,436
Cumulative Timesteps: 557,830,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 557830002...
Checkpoint 557830002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380,778.49708
Policy Entropy: 1.10886
Value Function Loss: 25.63417

Mean KL Divergence: 0.03612
SB3 Clip Fraction: 0.19114
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.06069

Collected Steps per Second: 10,574.98796
Overall Steps per Second: 9,253.08406

Timestep Collection Time: 4.72908
Timestep Consumption Time: 0.67560
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.40468

Cumulative Model Updates: 33,439
Cumulative Timesteps: 557,880,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,483.46941
Policy Entropy: 1.08153
Value Function Loss: 26.35139

Mean KL Divergence: 0.06394
SB3 Clip Fraction: 0.23234
Policy Update Magnitude: 0.04429
Value Function Update Magnitude: 0.05719

Collected Steps per Second: 11,039.27988
Overall Steps per Second: 9,432.72290

Timestep Collection Time: 4.53145
Timestep Consumption Time: 0.77179
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.30324

Cumulative Model Updates: 33,442
Cumulative Timesteps: 557,930,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 557930036...
Checkpoint 557930036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,834.34848
Policy Entropy: 1.11358
Value Function Loss: 26.57196

Mean KL Divergence: 0.04896
SB3 Clip Fraction: 0.21146
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.05856

Collected Steps per Second: 10,775.58935
Overall Steps per Second: 9,258.37369

Timestep Collection Time: 4.64272
Timestep Consumption Time: 0.76082
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 5.40354

Cumulative Model Updates: 33,445
Cumulative Timesteps: 557,980,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416,455.56974
Policy Entropy: 1.08206
Value Function Loss: 26.04223

Mean KL Divergence: 0.05971
SB3 Clip Fraction: 0.21949
Policy Update Magnitude: 0.03858
Value Function Update Magnitude: 0.05544

Collected Steps per Second: 11,126.71643
Overall Steps per Second: 9,412.95272

Timestep Collection Time: 4.49441
Timestep Consumption Time: 0.81827
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 5.31268

Cumulative Model Updates: 33,448
Cumulative Timesteps: 558,030,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 558030072...
Checkpoint 558030072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,976.40506
Policy Entropy: 1.09978
Value Function Loss: 24.95736

Mean KL Divergence: 0.04392
SB3 Clip Fraction: 0.19095
Policy Update Magnitude: 0.03850
Value Function Update Magnitude: 0.07379

Collected Steps per Second: 10,733.24774
Overall Steps per Second: 9,270.56653

Timestep Collection Time: 4.65973
Timestep Consumption Time: 0.73520
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.39492

Cumulative Model Updates: 33,451
Cumulative Timesteps: 558,080,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451,310.72137
Policy Entropy: 1.06974
Value Function Loss: 26.14550

Mean KL Divergence: 0.05359
SB3 Clip Fraction: 0.20468
Policy Update Magnitude: 0.04200
Value Function Update Magnitude: 0.07824

Collected Steps per Second: 10,681.63824
Overall Steps per Second: 9,185.42945

Timestep Collection Time: 4.68336
Timestep Consumption Time: 0.76287
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.44623

Cumulative Model Updates: 33,454
Cumulative Timesteps: 558,130,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 558130112...
Checkpoint 558130112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,180.02189
Policy Entropy: 1.09350
Value Function Loss: 26.52615

Mean KL Divergence: 0.02590
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.04199
Value Function Update Magnitude: 0.07659

Collected Steps per Second: 10,851.93597
Overall Steps per Second: 9,219.83432

Timestep Collection Time: 4.61024
Timestep Consumption Time: 0.81611
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 5.42634

Cumulative Model Updates: 33,457
Cumulative Timesteps: 558,180,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,197.58485
Policy Entropy: 1.09389
Value Function Loss: 26.81322

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.07283

Collected Steps per Second: 12,114.31992
Overall Steps per Second: 10,252.47467

Timestep Collection Time: 4.12834
Timestep Consumption Time: 0.74970
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.87804

Cumulative Model Updates: 33,460
Cumulative Timesteps: 558,230,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 558230154...
Checkpoint 558230154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,989.49894
Policy Entropy: 1.08645
Value Function Loss: 26.15882

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.06882

Collected Steps per Second: 12,139.68223
Overall Steps per Second: 10,227.30298

Timestep Collection Time: 4.11955
Timestep Consumption Time: 0.77030
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.88985

Cumulative Model Updates: 33,463
Cumulative Timesteps: 558,280,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,916.41827
Policy Entropy: 1.07605
Value Function Loss: 26.75648

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.06739

Collected Steps per Second: 12,041.07050
Overall Steps per Second: 10,164.77461

Timestep Collection Time: 4.15412
Timestep Consumption Time: 0.76680
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.92092

Cumulative Model Updates: 33,466
Cumulative Timesteps: 558,330,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 558330184...
Checkpoint 558330184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,681.67329
Policy Entropy: 1.08069
Value Function Loss: 26.56837

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.06863

Collected Steps per Second: 11,871.32013
Overall Steps per Second: 10,249.16502

Timestep Collection Time: 4.21368
Timestep Consumption Time: 0.66691
PPO Batch Consumption Time: 0.03353
Total Iteration Time: 4.88059

Cumulative Model Updates: 33,469
Cumulative Timesteps: 558,380,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,556.88248
Policy Entropy: 1.08685
Value Function Loss: 25.99916

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.06730

Collected Steps per Second: 11,356.31928
Overall Steps per Second: 9,522.44627

Timestep Collection Time: 4.40283
Timestep Consumption Time: 0.84792
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.25075

Cumulative Model Updates: 33,472
Cumulative Timesteps: 558,430,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 558430206...
Checkpoint 558430206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,257.28450
Policy Entropy: 1.07443
Value Function Loss: 25.05251

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.06449

Collected Steps per Second: 11,474.28614
Overall Steps per Second: 9,942.12075

Timestep Collection Time: 4.36001
Timestep Consumption Time: 0.67191
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.03192

Cumulative Model Updates: 33,475
Cumulative Timesteps: 558,480,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,159.99024
Policy Entropy: 1.07922
Value Function Loss: 26.07542

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.07968

Collected Steps per Second: 11,298.62016
Overall Steps per Second: 9,584.20406

Timestep Collection Time: 4.42762
Timestep Consumption Time: 0.79201
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.21963

Cumulative Model Updates: 33,478
Cumulative Timesteps: 558,530,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 558530260...
Checkpoint 558530260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,403.18154
Policy Entropy: 1.09307
Value Function Loss: 27.71255

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.09849

Collected Steps per Second: 10,908.16136
Overall Steps per Second: 9,349.88868

Timestep Collection Time: 4.58519
Timestep Consumption Time: 0.76418
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.34937

Cumulative Model Updates: 33,481
Cumulative Timesteps: 558,580,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,482.86333
Policy Entropy: 1.09144
Value Function Loss: 27.91930

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.08722

Collected Steps per Second: 11,206.23268
Overall Steps per Second: 9,523.58863

Timestep Collection Time: 4.46287
Timestep Consumption Time: 0.78851
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 5.25138

Cumulative Model Updates: 33,484
Cumulative Timesteps: 558,630,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 558630288...
Checkpoint 558630288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,015.40764
Policy Entropy: 1.08013
Value Function Loss: 26.72014

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.08927

Collected Steps per Second: 11,022.53587
Overall Steps per Second: 9,337.34091

Timestep Collection Time: 4.53834
Timestep Consumption Time: 0.81908
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.35741

Cumulative Model Updates: 33,487
Cumulative Timesteps: 558,680,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,246.96118
Policy Entropy: 1.07763
Value Function Loss: 25.69562

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.09701

Collected Steps per Second: 10,702.50953
Overall Steps per Second: 9,258.16501

Timestep Collection Time: 4.67442
Timestep Consumption Time: 0.72924
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.40366

Cumulative Model Updates: 33,490
Cumulative Timesteps: 558,730,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 558730340...
Checkpoint 558730340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440,783.26388
Policy Entropy: 1.09309
Value Function Loss: 25.54882

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.09687

Collected Steps per Second: 11,190.41446
Overall Steps per Second: 9,567.76641

Timestep Collection Time: 4.46918
Timestep Consumption Time: 0.75795
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.22713

Cumulative Model Updates: 33,493
Cumulative Timesteps: 558,780,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407,388.74420
Policy Entropy: 1.09152
Value Function Loss: 25.64111

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.09383

Collected Steps per Second: 10,675.55385
Overall Steps per Second: 9,251.02608

Timestep Collection Time: 4.68510
Timestep Consumption Time: 0.72144
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.40654

Cumulative Model Updates: 33,496
Cumulative Timesteps: 558,830,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 558830368...
Checkpoint 558830368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344,214.58781
Policy Entropy: 1.09668
Value Function Loss: 25.32883

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.08692

Collected Steps per Second: 10,970.84521
Overall Steps per Second: 9,501.44994

Timestep Collection Time: 4.55845
Timestep Consumption Time: 0.70496
PPO Batch Consumption Time: 0.03966
Total Iteration Time: 5.26341

Cumulative Model Updates: 33,499
Cumulative Timesteps: 558,880,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,954.02174
Policy Entropy: 1.09306
Value Function Loss: 25.38297

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.08956

Collected Steps per Second: 11,069.85375
Overall Steps per Second: 9,367.31175

Timestep Collection Time: 4.51930
Timestep Consumption Time: 0.82140
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 5.34070

Cumulative Model Updates: 33,502
Cumulative Timesteps: 558,930,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 558930406...
Checkpoint 558930406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,763.50884
Policy Entropy: 1.10485
Value Function Loss: 25.01064

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.08069

Collected Steps per Second: 10,944.47249
Overall Steps per Second: 9,418.74142

Timestep Collection Time: 4.57071
Timestep Consumption Time: 0.74040
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 5.31111

Cumulative Model Updates: 33,505
Cumulative Timesteps: 558,980,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,842.76193
Policy Entropy: 1.10221
Value Function Loss: 26.57451

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.07767

Collected Steps per Second: 10,608.26885
Overall Steps per Second: 9,160.56330

Timestep Collection Time: 4.71519
Timestep Consumption Time: 0.74517
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 5.46036

Cumulative Model Updates: 33,508
Cumulative Timesteps: 559,030,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 559030450...
Checkpoint 559030450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369,845.61194
Policy Entropy: 1.10586
Value Function Loss: 27.70611

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.06323
Value Function Update Magnitude: 0.07950

Collected Steps per Second: 10,999.06583
Overall Steps per Second: 9,418.90469

Timestep Collection Time: 4.54693
Timestep Consumption Time: 0.76282
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.30975

Cumulative Model Updates: 33,511
Cumulative Timesteps: 559,080,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,167.55241
Policy Entropy: 1.10973
Value Function Loss: 26.81075

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.08568

Collected Steps per Second: 10,840.35207
Overall Steps per Second: 9,321.63928

Timestep Collection Time: 4.61332
Timestep Consumption Time: 0.75162
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.36494

Cumulative Model Updates: 33,514
Cumulative Timesteps: 559,130,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 559130472...
Checkpoint 559130472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,440.62575
Policy Entropy: 1.10087
Value Function Loss: 27.07563

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.08007

Collected Steps per Second: 10,871.74282
Overall Steps per Second: 9,291.28362

Timestep Collection Time: 4.60018
Timestep Consumption Time: 0.78250
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.38268

Cumulative Model Updates: 33,517
Cumulative Timesteps: 559,180,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,795.87027
Policy Entropy: 1.07950
Value Function Loss: 25.99592

Mean KL Divergence: 0.03619
SB3 Clip Fraction: 0.18204
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.07535

Collected Steps per Second: 10,991.52241
Overall Steps per Second: 9,469.99504

Timestep Collection Time: 4.54932
Timestep Consumption Time: 0.73093
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.28026

Cumulative Model Updates: 33,520
Cumulative Timesteps: 559,230,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 559230488...
Checkpoint 559230488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,943.29877
Policy Entropy: 1.10648
Value Function Loss: 27.24246

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.14881
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.06873

Collected Steps per Second: 10,564.12731
Overall Steps per Second: 9,176.23391

Timestep Collection Time: 4.73376
Timestep Consumption Time: 0.71597
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.44973

Cumulative Model Updates: 33,523
Cumulative Timesteps: 559,280,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,966.11061
Policy Entropy: 1.08966
Value Function Loss: 25.47222

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.15683
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.05942

Collected Steps per Second: 11,082.86701
Overall Steps per Second: 9,432.55293

Timestep Collection Time: 4.51327
Timestep Consumption Time: 0.78964
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 5.30291

Cumulative Model Updates: 33,526
Cumulative Timesteps: 559,330,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 559330516...
Checkpoint 559330516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,118.78114
Policy Entropy: 1.10139
Value Function Loss: 24.88291

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.06697
Value Function Update Magnitude: 0.06404

Collected Steps per Second: 11,370.94483
Overall Steps per Second: 9,745.85423

Timestep Collection Time: 4.39823
Timestep Consumption Time: 0.73339
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.13162

Cumulative Model Updates: 33,529
Cumulative Timesteps: 559,380,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,042.33870
Policy Entropy: 1.10173
Value Function Loss: 24.80109

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.06979
Value Function Update Magnitude: 0.06084

Collected Steps per Second: 11,462.95571
Overall Steps per Second: 9,756.13980

Timestep Collection Time: 4.36362
Timestep Consumption Time: 0.76341
PPO Batch Consumption Time: 0.03807
Total Iteration Time: 5.12703

Cumulative Model Updates: 33,532
Cumulative Timesteps: 559,430,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 559430548...
Checkpoint 559430548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,822.40084
Policy Entropy: 1.10691
Value Function Loss: 25.84113

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.07091
Value Function Update Magnitude: 0.05710

Collected Steps per Second: 11,055.10937
Overall Steps per Second: 9,503.76437

Timestep Collection Time: 4.52280
Timestep Consumption Time: 0.73828
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.26107

Cumulative Model Updates: 33,535
Cumulative Timesteps: 559,480,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451,851.33951
Policy Entropy: 1.08801
Value Function Loss: 26.50603

Mean KL Divergence: 0.04093
SB3 Clip Fraction: 0.17339
Policy Update Magnitude: 0.06758
Value Function Update Magnitude: 0.05084

Collected Steps per Second: 11,111.74008
Overall Steps per Second: 9,586.90256

Timestep Collection Time: 4.50119
Timestep Consumption Time: 0.71593
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 5.21712

Cumulative Model Updates: 33,538
Cumulative Timesteps: 559,530,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 559530564...
Checkpoint 559530564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,851.31549
Policy Entropy: 1.11879
Value Function Loss: 26.20424

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.05679

Collected Steps per Second: 10,975.79960
Overall Steps per Second: 9,382.73592

Timestep Collection Time: 4.55584
Timestep Consumption Time: 0.77352
PPO Batch Consumption Time: 0.03358
Total Iteration Time: 5.32936

Cumulative Model Updates: 33,541
Cumulative Timesteps: 559,580,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,097.95242
Policy Entropy: 1.10263
Value Function Loss: 25.16186

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.15272
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.07776

Collected Steps per Second: 11,168.06801
Overall Steps per Second: 9,577.63642

Timestep Collection Time: 4.47902
Timestep Consumption Time: 0.74377
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.22279

Cumulative Model Updates: 33,544
Cumulative Timesteps: 559,630,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 559630590...
Checkpoint 559630590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,576.69031
Policy Entropy: 1.11065
Value Function Loss: 26.04789

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.08394

Collected Steps per Second: 11,420.13036
Overall Steps per Second: 9,722.35974

Timestep Collection Time: 4.37981
Timestep Consumption Time: 0.76483
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.14464

Cumulative Model Updates: 33,547
Cumulative Timesteps: 559,680,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,999.77672
Policy Entropy: 1.11197
Value Function Loss: 26.26843

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.06635
Value Function Update Magnitude: 0.07558

Collected Steps per Second: 11,265.58698
Overall Steps per Second: 9,631.45029

Timestep Collection Time: 4.43972
Timestep Consumption Time: 0.75327
PPO Batch Consumption Time: 0.03748
Total Iteration Time: 5.19299

Cumulative Model Updates: 33,550
Cumulative Timesteps: 559,730,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 559730624...
Checkpoint 559730624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,549.36250
Policy Entropy: 1.12240
Value Function Loss: 27.72481

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.06247
Value Function Update Magnitude: 0.06352

Collected Steps per Second: 11,122.34405
Overall Steps per Second: 9,617.98526

Timestep Collection Time: 4.49689
Timestep Consumption Time: 0.70336
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.20026

Cumulative Model Updates: 33,553
Cumulative Timesteps: 559,780,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,903.02423
Policy Entropy: 1.10943
Value Function Loss: 26.82214

Mean KL Divergence: 0.02334
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.07229

Collected Steps per Second: 11,216.24834
Overall Steps per Second: 9,448.69914

Timestep Collection Time: 4.45978
Timestep Consumption Time: 0.83428
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 5.29406

Cumulative Model Updates: 33,556
Cumulative Timesteps: 559,830,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 559830662...
Checkpoint 559830662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337,394.98712
Policy Entropy: 1.10388
Value Function Loss: 27.18438

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 10,727.56274
Overall Steps per Second: 9,343.42752

Timestep Collection Time: 4.66276
Timestep Consumption Time: 0.69074
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 5.35350

Cumulative Model Updates: 33,559
Cumulative Timesteps: 559,880,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347,920.75966
Policy Entropy: 1.11192
Value Function Loss: 27.51238

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.07441

Collected Steps per Second: 10,767.69553
Overall Steps per Second: 9,239.34600

Timestep Collection Time: 4.64482
Timestep Consumption Time: 0.76833
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.41315

Cumulative Model Updates: 33,562
Cumulative Timesteps: 559,930,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 559930696...
Checkpoint 559930696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,472.10389
Policy Entropy: 1.11905
Value Function Loss: 27.00939

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.06685

Collected Steps per Second: 11,005.39090
Overall Steps per Second: 9,438.28436

Timestep Collection Time: 4.54577
Timestep Consumption Time: 0.75477
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.30054

Cumulative Model Updates: 33,565
Cumulative Timesteps: 559,980,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,325.78985
Policy Entropy: 1.10328
Value Function Loss: 26.56442

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.05948
Value Function Update Magnitude: 0.06864

Collected Steps per Second: 11,052.37164
Overall Steps per Second: 9,569.40125

Timestep Collection Time: 4.52482
Timestep Consumption Time: 0.70121
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.22603

Cumulative Model Updates: 33,568
Cumulative Timesteps: 560,030,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 560030734...
Checkpoint 560030734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,509.42878
Policy Entropy: 1.09222
Value Function Loss: 25.16900

Mean KL Divergence: 0.02964
SB3 Clip Fraction: 0.16203
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.06338

Collected Steps per Second: 11,058.03523
Overall Steps per Second: 9,404.15644

Timestep Collection Time: 4.52214
Timestep Consumption Time: 0.79529
PPO Batch Consumption Time: 0.03932
Total Iteration Time: 5.31744

Cumulative Model Updates: 33,571
Cumulative Timesteps: 560,080,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,586.25709
Policy Entropy: 1.11146
Value Function Loss: 25.34969

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.06463

Collected Steps per Second: 10,870.02376
Overall Steps per Second: 9,465.44570

Timestep Collection Time: 4.60109
Timestep Consumption Time: 0.68276
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.28385

Cumulative Model Updates: 33,574
Cumulative Timesteps: 560,130,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 560130754...
Checkpoint 560130754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,883.81015
Policy Entropy: 1.10452
Value Function Loss: 25.96587

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.05886

Collected Steps per Second: 10,904.98773
Overall Steps per Second: 9,353.27954

Timestep Collection Time: 4.58597
Timestep Consumption Time: 0.76081
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.34679

Cumulative Model Updates: 33,577
Cumulative Timesteps: 560,180,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,186.05998
Policy Entropy: 1.11013
Value Function Loss: 26.38927

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.06843

Collected Steps per Second: 10,778.75073
Overall Steps per Second: 9,252.10248

Timestep Collection Time: 4.64024
Timestep Consumption Time: 0.76567
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.40591

Cumulative Model Updates: 33,580
Cumulative Timesteps: 560,230,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 560230780...
Checkpoint 560230780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,976.97423
Policy Entropy: 1.10539
Value Function Loss: 26.36946

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.07518
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 11,134.36241
Overall Steps per Second: 9,429.49394

Timestep Collection Time: 4.49294
Timestep Consumption Time: 0.81233
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 5.30527

Cumulative Model Updates: 33,583
Cumulative Timesteps: 560,280,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,210.90026
Policy Entropy: 1.10418
Value Function Loss: 25.51517

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.07241
Value Function Update Magnitude: 0.06782

Collected Steps per Second: 10,688.73763
Overall Steps per Second: 9,098.86444

Timestep Collection Time: 4.67969
Timestep Consumption Time: 0.81770
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.49739

Cumulative Model Updates: 33,586
Cumulative Timesteps: 560,330,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 560330826...
Checkpoint 560330826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,845.32311
Policy Entropy: 1.09317
Value Function Loss: 24.44341

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.06234
Value Function Update Magnitude: 0.06620

Collected Steps per Second: 10,819.61375
Overall Steps per Second: 9,411.40648

Timestep Collection Time: 4.62327
Timestep Consumption Time: 0.69177
PPO Batch Consumption Time: 0.03908
Total Iteration Time: 5.31504

Cumulative Model Updates: 33,589
Cumulative Timesteps: 560,380,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,749.10230
Policy Entropy: 1.09965
Value Function Loss: 24.15507

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.07642

Collected Steps per Second: 10,659.13418
Overall Steps per Second: 8,928.30374

Timestep Collection Time: 4.69363
Timestep Consumption Time: 0.90990
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 5.60353

Cumulative Model Updates: 33,592
Cumulative Timesteps: 560,430,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 560430878...
Checkpoint 560430878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,045.56944
Policy Entropy: 1.11365
Value Function Loss: 23.73686

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.07789

Collected Steps per Second: 11,060.75063
Overall Steps per Second: 9,265.35915

Timestep Collection Time: 4.52085
Timestep Consumption Time: 0.87603
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.39688

Cumulative Model Updates: 33,595
Cumulative Timesteps: 560,480,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,394.31948
Policy Entropy: 1.09307
Value Function Loss: 24.95088

Mean KL Divergence: 0.03296
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.06570

Collected Steps per Second: 12,283.24026
Overall Steps per Second: 10,360.38471

Timestep Collection Time: 4.07091
Timestep Consumption Time: 0.75555
PPO Batch Consumption Time: 0.03400
Total Iteration Time: 4.82646

Cumulative Model Updates: 33,598
Cumulative Timesteps: 560,530,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 560530886...
Checkpoint 560530886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,328.99523
Policy Entropy: 1.10839
Value Function Loss: 25.70805

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.06187

Collected Steps per Second: 12,056.61401
Overall Steps per Second: 10,143.29216

Timestep Collection Time: 4.14743
Timestep Consumption Time: 0.78233
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 4.92976

Cumulative Model Updates: 33,601
Cumulative Timesteps: 560,580,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373,329.10521
Policy Entropy: 1.10516
Value Function Loss: 26.32095

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.06100

Collected Steps per Second: 12,054.21684
Overall Steps per Second: 10,268.12877

Timestep Collection Time: 4.14942
Timestep Consumption Time: 0.72177
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 4.87119

Cumulative Model Updates: 33,604
Cumulative Timesteps: 560,630,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 560630908...
Checkpoint 560630908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,149.84741
Policy Entropy: 1.08943
Value Function Loss: 25.41870

Mean KL Divergence: 0.03063
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.08786

Collected Steps per Second: 11,764.30813
Overall Steps per Second: 9,970.94762

Timestep Collection Time: 4.25031
Timestep Consumption Time: 0.76446
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.01477

Cumulative Model Updates: 33,607
Cumulative Timesteps: 560,680,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,701.94734
Policy Entropy: 1.08808
Value Function Loss: 24.53898

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.16362
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.08875

Collected Steps per Second: 11,473.19335
Overall Steps per Second: 9,734.57538

Timestep Collection Time: 4.35973
Timestep Consumption Time: 0.77866
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.13839

Cumulative Model Updates: 33,610
Cumulative Timesteps: 560,730,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 560730930...
Checkpoint 560730930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,993.85201
Policy Entropy: 1.09484
Value Function Loss: 23.97874

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.07490

Collected Steps per Second: 10,967.79305
Overall Steps per Second: 9,494.69184

Timestep Collection Time: 4.56026
Timestep Consumption Time: 0.70752
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.26779

Cumulative Model Updates: 33,613
Cumulative Timesteps: 560,780,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,751.35643
Policy Entropy: 1.10161
Value Function Loss: 22.99884

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.04323
Value Function Update Magnitude: 0.06587

Collected Steps per Second: 11,132.75442
Overall Steps per Second: 9,476.85286

Timestep Collection Time: 4.49161
Timestep Consumption Time: 0.78482
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.27644

Cumulative Model Updates: 33,616
Cumulative Timesteps: 560,830,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 560830950...
Checkpoint 560830950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,234.50443
Policy Entropy: 1.08746
Value Function Loss: 22.73317

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 10,881.72026
Overall Steps per Second: 9,335.00641

Timestep Collection Time: 4.59596
Timestep Consumption Time: 0.76150
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 5.35747

Cumulative Model Updates: 33,619
Cumulative Timesteps: 560,880,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,505.16557
Policy Entropy: 1.09102
Value Function Loss: 22.84843

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.06104

Collected Steps per Second: 11,356.58571
Overall Steps per Second: 9,613.30675

Timestep Collection Time: 4.40449
Timestep Consumption Time: 0.79871
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.20320

Cumulative Model Updates: 33,622
Cumulative Timesteps: 560,930,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 560930982...
Checkpoint 560930982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398,316.71026
Policy Entropy: 1.09926
Value Function Loss: 25.12659

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.05852

Collected Steps per Second: 11,218.85306
Overall Steps per Second: 9,418.36663

Timestep Collection Time: 4.45910
Timestep Consumption Time: 0.85244
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.31154

Cumulative Model Updates: 33,625
Cumulative Timesteps: 560,981,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,433.46691
Policy Entropy: 1.10243
Value Function Loss: 24.94379

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.04120
Value Function Update Magnitude: 0.06150

Collected Steps per Second: 11,096.61791
Overall Steps per Second: 9,635.12256

Timestep Collection Time: 4.50786
Timestep Consumption Time: 0.68377
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.19163

Cumulative Model Updates: 33,628
Cumulative Timesteps: 561,031,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 561031030...
Checkpoint 561031030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,682.47603
Policy Entropy: 1.08422
Value Function Loss: 24.83000

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.06007

Collected Steps per Second: 10,851.15991
Overall Steps per Second: 9,327.59458

Timestep Collection Time: 4.60872
Timestep Consumption Time: 0.75279
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.36151

Cumulative Model Updates: 33,631
Cumulative Timesteps: 561,081,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,701.95358
Policy Entropy: 1.07026
Value Function Loss: 23.22699

Mean KL Divergence: 0.03563
SB3 Clip Fraction: 0.17848
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.06605

Collected Steps per Second: 11,087.75919
Overall Steps per Second: 9,492.93323

Timestep Collection Time: 4.51074
Timestep Consumption Time: 0.75781
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.26855

Cumulative Model Updates: 33,634
Cumulative Timesteps: 561,131,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 561131054...
Checkpoint 561131054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,280.72445
Policy Entropy: 1.10058
Value Function Loss: 23.40726

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.06408

Collected Steps per Second: 10,866.18334
Overall Steps per Second: 9,452.63333

Timestep Collection Time: 4.60254
Timestep Consumption Time: 0.68826
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 5.29080

Cumulative Model Updates: 33,637
Cumulative Timesteps: 561,181,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,346.57044
Policy Entropy: 1.07246
Value Function Loss: 23.26423

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.15946
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.06661

Collected Steps per Second: 11,053.91591
Overall Steps per Second: 9,448.29385

Timestep Collection Time: 4.52437
Timestep Consumption Time: 0.76886
PPO Batch Consumption Time: 0.04563
Total Iteration Time: 5.29323

Cumulative Model Updates: 33,640
Cumulative Timesteps: 561,231,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 561231078...
Checkpoint 561231078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328,333.71981
Policy Entropy: 1.08926
Value Function Loss: 23.42885

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.06598

Collected Steps per Second: 10,139.27606
Overall Steps per Second: 8,760.60969

Timestep Collection Time: 4.93230
Timestep Consumption Time: 0.77620
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.70851

Cumulative Model Updates: 33,643
Cumulative Timesteps: 561,281,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,737.51567
Policy Entropy: 1.09185
Value Function Loss: 23.01106

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.15211
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 10,962.49035
Overall Steps per Second: 9,299.38395

Timestep Collection Time: 4.56356
Timestep Consumption Time: 0.81615
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.37971

Cumulative Model Updates: 33,646
Cumulative Timesteps: 561,331,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 561331116...
Checkpoint 561331116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415,612.20231
Policy Entropy: 1.07956
Value Function Loss: 22.87038

Mean KL Divergence: 0.02538
SB3 Clip Fraction: 0.15487
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.10272

Collected Steps per Second: 10,775.86509
Overall Steps per Second: 9,331.64386

Timestep Collection Time: 4.64260
Timestep Consumption Time: 0.71852
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.36111

Cumulative Model Updates: 33,649
Cumulative Timesteps: 561,381,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404,243.31883
Policy Entropy: 1.07076
Value Function Loss: 23.87465

Mean KL Divergence: 0.02841
SB3 Clip Fraction: 0.16567
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.09116

Collected Steps per Second: 10,827.30238
Overall Steps per Second: 9,382.40523

Timestep Collection Time: 4.61851
Timestep Consumption Time: 0.71125
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.32976

Cumulative Model Updates: 33,652
Cumulative Timesteps: 561,431,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 561431150...
Checkpoint 561431150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,133.41338
Policy Entropy: 1.08497
Value Function Loss: 24.79746

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.08520

Collected Steps per Second: 10,971.01200
Overall Steps per Second: 9,398.68328

Timestep Collection Time: 4.55874
Timestep Consumption Time: 0.76264
PPO Batch Consumption Time: 0.03811
Total Iteration Time: 5.32138

Cumulative Model Updates: 33,655
Cumulative Timesteps: 561,481,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,191.51914
Policy Entropy: 1.08985
Value Function Loss: 23.96271

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.09866

Collected Steps per Second: 10,806.86443
Overall Steps per Second: 9,314.91530

Timestep Collection Time: 4.62798
Timestep Consumption Time: 0.74125
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 5.36924

Cumulative Model Updates: 33,658
Cumulative Timesteps: 561,531,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 561531178...
Checkpoint 561531178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,404.07067
Policy Entropy: 1.07137
Value Function Loss: 22.65830

Mean KL Divergence: 0.02521
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.09744

Collected Steps per Second: 10,719.06634
Overall Steps per Second: 9,198.25106

Timestep Collection Time: 4.66533
Timestep Consumption Time: 0.77135
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 5.43669

Cumulative Model Updates: 33,661
Cumulative Timesteps: 561,581,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,128.69730
Policy Entropy: 1.06333
Value Function Loss: 21.26978

Mean KL Divergence: 0.03007
SB3 Clip Fraction: 0.16874
Policy Update Magnitude: 0.04479
Value Function Update Magnitude: 0.07858

Collected Steps per Second: 11,425.93113
Overall Steps per Second: 9,760.63575

Timestep Collection Time: 4.37829
Timestep Consumption Time: 0.74699
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.12528

Cumulative Model Updates: 33,664
Cumulative Timesteps: 561,631,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 561631212...
Checkpoint 561631212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,530.73925
Policy Entropy: 1.06853
Value Function Loss: 21.85686

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.07760

Collected Steps per Second: 11,469.95896
Overall Steps per Second: 9,936.10780

Timestep Collection Time: 4.36200
Timestep Consumption Time: 0.67337
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 5.03537

Cumulative Model Updates: 33,667
Cumulative Timesteps: 561,681,244

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,197.19433
Policy Entropy: 1.07854
Value Function Loss: 23.53079

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.06609

Collected Steps per Second: 11,327.21824
Overall Steps per Second: 9,632.71744

Timestep Collection Time: 4.41432
Timestep Consumption Time: 0.77653
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.19085

Cumulative Model Updates: 33,670
Cumulative Timesteps: 561,731,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 561731246...
Checkpoint 561731246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,852.75633
Policy Entropy: 1.06220
Value Function Loss: 24.66360

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.05790

Collected Steps per Second: 11,558.17934
Overall Steps per Second: 10,027.58558

Timestep Collection Time: 4.32854
Timestep Consumption Time: 0.66070
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 4.98924

Cumulative Model Updates: 33,673
Cumulative Timesteps: 561,781,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,360.99696
Policy Entropy: 1.06129
Value Function Loss: 25.78085

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.15719
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.06068

Collected Steps per Second: 11,400.37249
Overall Steps per Second: 9,525.90277

Timestep Collection Time: 4.38793
Timestep Consumption Time: 0.86344
PPO Batch Consumption Time: 0.03823
Total Iteration Time: 5.25137

Cumulative Model Updates: 33,676
Cumulative Timesteps: 561,831,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 561831300...
Checkpoint 561831300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,769.76560
Policy Entropy: 1.07548
Value Function Loss: 24.91506

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.08551

Collected Steps per Second: 11,391.66738
Overall Steps per Second: 9,701.83121

Timestep Collection Time: 4.39128
Timestep Consumption Time: 0.76486
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.15614

Cumulative Model Updates: 33,679
Cumulative Timesteps: 561,881,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,323.08875
Policy Entropy: 1.08099
Value Function Loss: 25.29918

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.15359
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.09528

Collected Steps per Second: 11,359.00235
Overall Steps per Second: 9,766.89470

Timestep Collection Time: 4.40444
Timestep Consumption Time: 0.71797
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.12241

Cumulative Model Updates: 33,682
Cumulative Timesteps: 561,931,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 561931354...
Checkpoint 561931354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,862.14909
Policy Entropy: 1.06064
Value Function Loss: 23.42865

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.11908
Policy Update Magnitude: 0.04994
Value Function Update Magnitude: 0.10205

Collected Steps per Second: 11,289.32800
Overall Steps per Second: 9,510.34751

Timestep Collection Time: 4.43144
Timestep Consumption Time: 0.82893
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 5.26038

Cumulative Model Updates: 33,685
Cumulative Timesteps: 561,981,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,070.99578
Policy Entropy: 1.04018
Value Function Loss: 22.66146

Mean KL Divergence: 0.03694
SB3 Clip Fraction: 0.18475
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.08691

Collected Steps per Second: 11,101.13372
Overall Steps per Second: 9,509.19443

Timestep Collection Time: 4.50440
Timestep Consumption Time: 0.75408
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 5.25849

Cumulative Model Updates: 33,688
Cumulative Timesteps: 562,031,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 562031386...
Checkpoint 562031386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,920.55952
Policy Entropy: 1.07118
Value Function Loss: 22.03194

Mean KL Divergence: 0.02693
SB3 Clip Fraction: 0.16191
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.07298

Collected Steps per Second: 11,384.78700
Overall Steps per Second: 9,570.63602

Timestep Collection Time: 4.39306
Timestep Consumption Time: 0.83272
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.22578

Cumulative Model Updates: 33,691
Cumulative Timesteps: 562,081,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,278.93474
Policy Entropy: 1.04590
Value Function Loss: 22.93678

Mean KL Divergence: 0.03564
SB3 Clip Fraction: 0.17964
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.06384

Collected Steps per Second: 10,800.12017
Overall Steps per Second: 9,301.62647

Timestep Collection Time: 4.63087
Timestep Consumption Time: 0.74603
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 5.37691

Cumulative Model Updates: 33,694
Cumulative Timesteps: 562,131,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 562131414...
Checkpoint 562131414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,834.00110
Policy Entropy: 1.06074
Value Function Loss: 23.65240

Mean KL Divergence: 0.02863
SB3 Clip Fraction: 0.16239
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.05537

Collected Steps per Second: 10,843.59670
Overall Steps per Second: 9,468.18541

Timestep Collection Time: 4.61194
Timestep Consumption Time: 0.66996
PPO Batch Consumption Time: 0.03876
Total Iteration Time: 5.28190

Cumulative Model Updates: 33,697
Cumulative Timesteps: 562,181,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,754.34961
Policy Entropy: 1.06410
Value Function Loss: 22.44053

Mean KL Divergence: 0.02634
SB3 Clip Fraction: 0.15843
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.06477

Collected Steps per Second: 10,975.41945
Overall Steps per Second: 9,351.07575

Timestep Collection Time: 4.55819
Timestep Consumption Time: 0.79179
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.34997

Cumulative Model Updates: 33,700
Cumulative Timesteps: 562,231,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 562231452...
Checkpoint 562231452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,667.62332
Policy Entropy: 1.05622
Value Function Loss: 22.53869

Mean KL Divergence: 0.03204
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.05866

Collected Steps per Second: 10,973.83085
Overall Steps per Second: 9,467.03876

Timestep Collection Time: 4.55830
Timestep Consumption Time: 0.72551
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.28381

Cumulative Model Updates: 33,703
Cumulative Timesteps: 562,281,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,413.64701
Policy Entropy: 1.05142
Value Function Loss: 22.25446

Mean KL Divergence: 0.02969
SB3 Clip Fraction: 0.17336
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.07537

Collected Steps per Second: 11,062.77878
Overall Steps per Second: 9,488.05382

Timestep Collection Time: 4.51984
Timestep Consumption Time: 0.75015
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.27000

Cumulative Model Updates: 33,706
Cumulative Timesteps: 562,331,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 562331476...
Checkpoint 562331476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,054.01499
Policy Entropy: 1.06635
Value Function Loss: 22.84255

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.07037

Collected Steps per Second: 11,296.61670
Overall Steps per Second: 9,618.83385

Timestep Collection Time: 4.42664
Timestep Consumption Time: 0.77212
PPO Batch Consumption Time: 0.03926
Total Iteration Time: 5.19876

Cumulative Model Updates: 33,709
Cumulative Timesteps: 562,381,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,071.42458
Policy Entropy: 1.08148
Value Function Loss: 21.97155

Mean KL Divergence: 0.02848
SB3 Clip Fraction: 0.15725
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.08812

Collected Steps per Second: 10,515.08524
Overall Steps per Second: 9,232.10456

Timestep Collection Time: 4.75507
Timestep Consumption Time: 0.66081
PPO Batch Consumption Time: 0.03822
Total Iteration Time: 5.41588

Cumulative Model Updates: 33,712
Cumulative Timesteps: 562,431,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 562431482...
Checkpoint 562431482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,148.57472
Policy Entropy: 1.06256
Value Function Loss: 21.13530

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 10,876.80283
Overall Steps per Second: 9,242.77371

Timestep Collection Time: 4.59841
Timestep Consumption Time: 0.81295
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 5.41136

Cumulative Model Updates: 33,715
Cumulative Timesteps: 562,481,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420,284.29381
Policy Entropy: 1.05085
Value Function Loss: 21.24006

Mean KL Divergence: 0.03347
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.08592

Collected Steps per Second: 11,196.39019
Overall Steps per Second: 9,547.22271

Timestep Collection Time: 4.46733
Timestep Consumption Time: 0.77168
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.23901

Cumulative Model Updates: 33,718
Cumulative Timesteps: 562,531,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 562531516...
Checkpoint 562531516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,127.76613
Policy Entropy: 1.06905
Value Function Loss: 22.36412

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.07681

Collected Steps per Second: 11,391.94130
Overall Steps per Second: 9,650.83278

Timestep Collection Time: 4.39030
Timestep Consumption Time: 0.79205
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.18235

Cumulative Model Updates: 33,721
Cumulative Timesteps: 562,581,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,343.65461
Policy Entropy: 1.07457
Value Function Loss: 23.21019

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.07438

Collected Steps per Second: 10,860.27291
Overall Steps per Second: 9,315.80092

Timestep Collection Time: 4.60467
Timestep Consumption Time: 0.76341
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.36808

Cumulative Model Updates: 33,724
Cumulative Timesteps: 562,631,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 562631538...
Checkpoint 562631538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,034.68692
Policy Entropy: 1.05860
Value Function Loss: 22.72110

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.07697

Collected Steps per Second: 10,802.70804
Overall Steps per Second: 9,301.74910

Timestep Collection Time: 4.62958
Timestep Consumption Time: 0.74704
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.37662

Cumulative Model Updates: 33,727
Cumulative Timesteps: 562,681,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420,278.99831
Policy Entropy: 1.05937
Value Function Loss: 21.81620

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.08003

Collected Steps per Second: 10,994.03096
Overall Steps per Second: 9,389.91637

Timestep Collection Time: 4.54974
Timestep Consumption Time: 0.77725
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.32699

Cumulative Model Updates: 33,730
Cumulative Timesteps: 562,731,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 562731570...
Checkpoint 562731570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,832.14864
Policy Entropy: 1.07298
Value Function Loss: 22.50259

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.07236

Collected Steps per Second: 11,624.73790
Overall Steps per Second: 9,727.17007

Timestep Collection Time: 4.30358
Timestep Consumption Time: 0.83954
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.14312

Cumulative Model Updates: 33,733
Cumulative Timesteps: 562,781,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337,727.30312
Policy Entropy: 1.07948
Value Function Loss: 23.17623

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.07043
Value Function Update Magnitude: 0.08591

Collected Steps per Second: 12,508.94630
Overall Steps per Second: 10,430.35636

Timestep Collection Time: 3.99858
Timestep Consumption Time: 0.79685
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 4.79543

Cumulative Model Updates: 33,736
Cumulative Timesteps: 562,831,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 562831616...
Checkpoint 562831616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,671.27974
Policy Entropy: 1.08196
Value Function Loss: 23.17353

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.12216
Policy Update Magnitude: 0.07065
Value Function Update Magnitude: 0.09743

Collected Steps per Second: 11,845.19340
Overall Steps per Second: 10,003.70703

Timestep Collection Time: 4.22129
Timestep Consumption Time: 0.77706
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 4.99835

Cumulative Model Updates: 33,739
Cumulative Timesteps: 562,881,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,060.09916
Policy Entropy: 1.07102
Value Function Loss: 22.96191

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.07118
Value Function Update Magnitude: 0.08791

Collected Steps per Second: 11,973.58592
Overall Steps per Second: 10,208.70433

Timestep Collection Time: 4.17753
Timestep Consumption Time: 0.72221
PPO Batch Consumption Time: 0.04329
Total Iteration Time: 4.89974

Cumulative Model Updates: 33,742
Cumulative Timesteps: 562,931,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 562931638...
Checkpoint 562931638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,244.89622
Policy Entropy: 1.06238
Value Function Loss: 22.10599

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.06565
Value Function Update Magnitude: 0.09502

Collected Steps per Second: 11,709.21961
Overall Steps per Second: 9,795.29940

Timestep Collection Time: 4.27014
Timestep Consumption Time: 0.83435
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.10449

Cumulative Model Updates: 33,745
Cumulative Timesteps: 562,981,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,583.55975
Policy Entropy: 1.08885
Value Function Loss: 22.96294

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.09255

Collected Steps per Second: 11,933.20299
Overall Steps per Second: 9,996.77842

Timestep Collection Time: 4.19049
Timestep Consumption Time: 0.81172
PPO Batch Consumption Time: 0.03984
Total Iteration Time: 5.00221

Cumulative Model Updates: 33,748
Cumulative Timesteps: 563,031,644

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 563031644...
Checkpoint 563031644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,571.87793
Policy Entropy: 1.09114
Value Function Loss: 22.14437

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.14540
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.08884

Collected Steps per Second: 11,507.38747
Overall Steps per Second: 9,738.70407

Timestep Collection Time: 4.34677
Timestep Consumption Time: 0.78943
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.13621

Cumulative Model Updates: 33,751
Cumulative Timesteps: 563,081,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398,958.65498
Policy Entropy: 1.07903
Value Function Loss: 22.54083

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.07593

Collected Steps per Second: 11,123.26443
Overall Steps per Second: 9,582.02887

Timestep Collection Time: 4.49598
Timestep Consumption Time: 0.72316
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 5.21915

Cumulative Model Updates: 33,754
Cumulative Timesteps: 563,131,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 563131674...
Checkpoint 563131674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,359.87442
Policy Entropy: 1.06026
Value Function Loss: 23.17395

Mean KL Divergence: 0.02747
SB3 Clip Fraction: 0.15914
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.07398

Collected Steps per Second: 11,165.86979
Overall Steps per Second: 9,685.57703

Timestep Collection Time: 4.47901
Timestep Consumption Time: 0.68455
PPO Batch Consumption Time: 0.03860
Total Iteration Time: 5.16355

Cumulative Model Updates: 33,757
Cumulative Timesteps: 563,181,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,299.34262
Policy Entropy: 1.07340
Value Function Loss: 23.34189

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.06336

Collected Steps per Second: 11,384.96722
Overall Steps per Second: 9,634.19899

Timestep Collection Time: 4.39334
Timestep Consumption Time: 0.79838
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.19171

Cumulative Model Updates: 33,760
Cumulative Timesteps: 563,231,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 563231704...
Checkpoint 563231704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,400.11683
Policy Entropy: 1.07409
Value Function Loss: 23.56698

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 10,922.13055
Overall Steps per Second: 9,369.77590

Timestep Collection Time: 4.58024
Timestep Consumption Time: 0.75884
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.33908

Cumulative Model Updates: 33,763
Cumulative Timesteps: 563,281,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,167.13162
Policy Entropy: 1.07760
Value Function Loss: 23.45657

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.04681

Collected Steps per Second: 11,165.75158
Overall Steps per Second: 9,517.44643

Timestep Collection Time: 4.47798
Timestep Consumption Time: 0.77553
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.25351

Cumulative Model Updates: 33,766
Cumulative Timesteps: 563,331,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 563331730...
Checkpoint 563331730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,803.60050
Policy Entropy: 1.08320
Value Function Loss: 24.89203

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.06127
Value Function Update Magnitude: 0.04978

Collected Steps per Second: 10,737.95567
Overall Steps per Second: 9,241.24166

Timestep Collection Time: 4.65768
Timestep Consumption Time: 0.75436
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.41204

Cumulative Model Updates: 33,769
Cumulative Timesteps: 563,381,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,929.59220
Policy Entropy: 1.07233
Value Function Loss: 24.86338

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.04529

Collected Steps per Second: 10,951.73565
Overall Steps per Second: 9,482.06882

Timestep Collection Time: 4.56658
Timestep Consumption Time: 0.70779
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.27438

Cumulative Model Updates: 33,772
Cumulative Timesteps: 563,431,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 563431756...
Checkpoint 563431756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,720.05762
Policy Entropy: 1.08489
Value Function Loss: 24.77088

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.04392

Collected Steps per Second: 10,982.33661
Overall Steps per Second: 9,391.44760

Timestep Collection Time: 4.55440
Timestep Consumption Time: 0.77151
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 5.32591

Cumulative Model Updates: 33,775
Cumulative Timesteps: 563,481,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,063.24518
Policy Entropy: 1.08278
Value Function Loss: 23.19132

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.04429

Collected Steps per Second: 11,014.84830
Overall Steps per Second: 9,572.03010

Timestep Collection Time: 4.53969
Timestep Consumption Time: 0.68428
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.22397

Cumulative Model Updates: 33,778
Cumulative Timesteps: 563,531,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 563531778...
Checkpoint 563531778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,757.82732
Policy Entropy: 1.06686
Value Function Loss: 22.39992

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.03949

Collected Steps per Second: 10,713.55236
Overall Steps per Second: 9,158.90340

Timestep Collection Time: 4.66885
Timestep Consumption Time: 0.79250
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.46135

Cumulative Model Updates: 33,781
Cumulative Timesteps: 563,581,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,548.31626
Policy Entropy: 1.04534
Value Function Loss: 21.95496

Mean KL Divergence: 0.03269
SB3 Clip Fraction: 0.18890
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.03985

Collected Steps per Second: 10,821.13659
Overall Steps per Second: 9,207.23962

Timestep Collection Time: 4.62280
Timestep Consumption Time: 0.81031
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.43312

Cumulative Model Updates: 33,784
Cumulative Timesteps: 563,631,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 563631822...
Checkpoint 563631822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,175.19112
Policy Entropy: 1.06422
Value Function Loss: 22.63706

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.04647

Collected Steps per Second: 10,729.40836
Overall Steps per Second: 9,338.40705

Timestep Collection Time: 4.66028
Timestep Consumption Time: 0.69417
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.35445

Cumulative Model Updates: 33,787
Cumulative Timesteps: 563,681,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,569.07797
Policy Entropy: 1.05798
Value Function Loss: 22.51112

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.04252

Collected Steps per Second: 11,208.27072
Overall Steps per Second: 9,469.98208

Timestep Collection Time: 4.46206
Timestep Consumption Time: 0.81905
PPO Batch Consumption Time: 0.04681
Total Iteration Time: 5.28111

Cumulative Model Updates: 33,790
Cumulative Timesteps: 563,731,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 563731836...
Checkpoint 563731836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435,242.77298
Policy Entropy: 1.04494
Value Function Loss: 22.19247

Mean KL Divergence: 0.04521
SB3 Clip Fraction: 0.20562
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.04390

Collected Steps per Second: 10,887.69284
Overall Steps per Second: 9,259.54619

Timestep Collection Time: 4.59418
Timestep Consumption Time: 0.80781
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.40199

Cumulative Model Updates: 33,793
Cumulative Timesteps: 563,781,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,280.75000
Policy Entropy: 1.06825
Value Function Loss: 22.34824

Mean KL Divergence: 0.03105
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.04448

Collected Steps per Second: 10,903.58422
Overall Steps per Second: 9,232.55295

Timestep Collection Time: 4.58583
Timestep Consumption Time: 0.83001
PPO Batch Consumption Time: 0.03974
Total Iteration Time: 5.41584

Cumulative Model Updates: 33,796
Cumulative Timesteps: 563,831,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 563831858...
Checkpoint 563831858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344,209.83887
Policy Entropy: 1.05621
Value Function Loss: 23.13690

Mean KL Divergence: 0.03453
SB3 Clip Fraction: 0.16012
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.05586

Collected Steps per Second: 11,123.03599
Overall Steps per Second: 9,547.50315

Timestep Collection Time: 4.49518
Timestep Consumption Time: 0.74180
PPO Batch Consumption Time: 0.03389
Total Iteration Time: 5.23697

Cumulative Model Updates: 33,799
Cumulative Timesteps: 563,881,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,954.47599
Policy Entropy: 1.05300
Value Function Loss: 24.24338

Mean KL Divergence: 0.02839
SB3 Clip Fraction: 0.16895
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.06273

Collected Steps per Second: 11,433.62381
Overall Steps per Second: 9,898.76517

Timestep Collection Time: 4.37429
Timestep Consumption Time: 0.67826
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.05255

Cumulative Model Updates: 33,802
Cumulative Timesteps: 563,931,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 563931872...
Checkpoint 563931872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,067.67588
Policy Entropy: 1.07109
Value Function Loss: 24.59910

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.06512

Collected Steps per Second: 11,303.59540
Overall Steps per Second: 9,628.27387

Timestep Collection Time: 4.42567
Timestep Consumption Time: 0.77007
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.19574

Cumulative Model Updates: 33,805
Cumulative Timesteps: 563,981,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,863.86280
Policy Entropy: 1.08440
Value Function Loss: 24.80703

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.06665

Collected Steps per Second: 11,547.29454
Overall Steps per Second: 9,840.60250

Timestep Collection Time: 4.33262
Timestep Consumption Time: 0.75142
PPO Batch Consumption Time: 0.04024
Total Iteration Time: 5.08404

Cumulative Model Updates: 33,808
Cumulative Timesteps: 564,031,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 564031928...
Checkpoint 564031928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,317.24893
Policy Entropy: 1.06676
Value Function Loss: 23.97943

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.05220

Collected Steps per Second: 11,716.60734
Overall Steps per Second: 9,942.24906

Timestep Collection Time: 4.26967
Timestep Consumption Time: 0.76199
PPO Batch Consumption Time: 0.04028
Total Iteration Time: 5.03166

Cumulative Model Updates: 33,811
Cumulative Timesteps: 564,081,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,512.26289
Policy Entropy: 1.06947
Value Function Loss: 23.31253

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.05827

Collected Steps per Second: 11,069.23930
Overall Steps per Second: 9,415.80611

Timestep Collection Time: 4.51919
Timestep Consumption Time: 0.79358
PPO Batch Consumption Time: 0.04400
Total Iteration Time: 5.31277

Cumulative Model Updates: 33,814
Cumulative Timesteps: 564,131,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 564131978...
Checkpoint 564131978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380,586.57405
Policy Entropy: 1.06733
Value Function Loss: 22.26871

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.10848
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.05900

Collected Steps per Second: 11,283.29290
Overall Steps per Second: 9,783.16953

Timestep Collection Time: 4.43399
Timestep Consumption Time: 0.67990
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.11388

Cumulative Model Updates: 33,817
Cumulative Timesteps: 564,182,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,929.81744
Policy Entropy: 1.07444
Value Function Loss: 22.36031

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.04866

Collected Steps per Second: 11,284.94884
Overall Steps per Second: 9,619.61202

Timestep Collection Time: 4.43228
Timestep Consumption Time: 0.76731
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.19959

Cumulative Model Updates: 33,820
Cumulative Timesteps: 564,232,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 564232026...
Checkpoint 564232026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,196.19629
Policy Entropy: 1.07070
Value Function Loss: 22.34733

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.06277
Value Function Update Magnitude: 0.04553

Collected Steps per Second: 11,003.82825
Overall Steps per Second: 9,532.49849

Timestep Collection Time: 4.54660
Timestep Consumption Time: 0.70176
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.24836

Cumulative Model Updates: 33,823
Cumulative Timesteps: 564,282,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,068.94917
Policy Entropy: 1.07014
Value Function Loss: 21.76805

Mean KL Divergence: 0.02743
SB3 Clip Fraction: 0.15825
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.04230

Collected Steps per Second: 10,958.25121
Overall Steps per Second: 9,338.36656

Timestep Collection Time: 4.56551
Timestep Consumption Time: 0.79196
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.35747

Cumulative Model Updates: 33,826
Cumulative Timesteps: 564,332,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 564332086...
Checkpoint 564332086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,641.74836
Policy Entropy: 1.07499
Value Function Loss: 21.13850

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.04176

Collected Steps per Second: 11,088.77223
Overall Steps per Second: 9,535.93227

Timestep Collection Time: 4.50943
Timestep Consumption Time: 0.73432
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 5.24375

Cumulative Model Updates: 33,829
Cumulative Timesteps: 564,382,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,865.54168
Policy Entropy: 1.07647
Value Function Loss: 20.99496

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.03848

Collected Steps per Second: 10,788.55993
Overall Steps per Second: 9,372.50582

Timestep Collection Time: 4.63491
Timestep Consumption Time: 0.70027
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.33518

Cumulative Model Updates: 33,832
Cumulative Timesteps: 564,432,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 564432094...
Checkpoint 564432094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442,063.04907
Policy Entropy: 1.06961
Value Function Loss: 21.55332

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.06005
Value Function Update Magnitude: 0.03885

Collected Steps per Second: 10,901.67777
Overall Steps per Second: 9,326.92820

Timestep Collection Time: 4.58645
Timestep Consumption Time: 0.77437
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.36082

Cumulative Model Updates: 33,835
Cumulative Timesteps: 564,482,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,780.00239
Policy Entropy: 1.06996
Value Function Loss: 22.64725

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.06246
Value Function Update Magnitude: 0.03829

Collected Steps per Second: 11,240.46145
Overall Steps per Second: 9,646.82634

Timestep Collection Time: 4.45035
Timestep Consumption Time: 0.73519
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.18554

Cumulative Model Updates: 33,838
Cumulative Timesteps: 564,532,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 564532118...
Checkpoint 564532118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385,841.21693
Policy Entropy: 1.05518
Value Function Loss: 23.88766

Mean KL Divergence: 0.03253
SB3 Clip Fraction: 0.16082
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.04211

Collected Steps per Second: 11,214.82695
Overall Steps per Second: 9,563.61398

Timestep Collection Time: 4.45963
Timestep Consumption Time: 0.76998
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.22961

Cumulative Model Updates: 33,841
Cumulative Timesteps: 564,582,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,315.31796
Policy Entropy: 1.06635
Value Function Loss: 24.02791

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.04698

Collected Steps per Second: 11,114.79589
Overall Steps per Second: 9,517.04236

Timestep Collection Time: 4.49869
Timestep Consumption Time: 0.75526
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.25394

Cumulative Model Updates: 33,844
Cumulative Timesteps: 564,632,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 564632134...
Checkpoint 564632134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,792.36762
Policy Entropy: 1.07914
Value Function Loss: 22.99208

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.15567
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.04285

Collected Steps per Second: 11,113.88805
Overall Steps per Second: 9,600.38604

Timestep Collection Time: 4.50175
Timestep Consumption Time: 0.70970
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 5.21146

Cumulative Model Updates: 33,847
Cumulative Timesteps: 564,682,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,365.19668
Policy Entropy: 1.06330
Value Function Loss: 21.53318

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.04166

Collected Steps per Second: 10,750.58062
Overall Steps per Second: 9,127.65578

Timestep Collection Time: 4.65147
Timestep Consumption Time: 0.82705
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 5.47852

Cumulative Model Updates: 33,850
Cumulative Timesteps: 564,732,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 564732172...
Checkpoint 564732172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,773.28292
Policy Entropy: 1.05970
Value Function Loss: 22.51114

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.15269
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.04267

Collected Steps per Second: 10,878.55466
Overall Steps per Second: 9,356.23869

Timestep Collection Time: 4.59730
Timestep Consumption Time: 0.74801
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.34531

Cumulative Model Updates: 33,853
Cumulative Timesteps: 564,782,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,709.20233
Policy Entropy: 1.06353
Value Function Loss: 22.37349

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.04384
Value Function Update Magnitude: 0.04120

Collected Steps per Second: 11,103.59962
Overall Steps per Second: 9,507.47323

Timestep Collection Time: 4.50376
Timestep Consumption Time: 0.75610
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.25986

Cumulative Model Updates: 33,856
Cumulative Timesteps: 564,832,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 564832192...
Checkpoint 564832192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,814.49204
Policy Entropy: 1.07266
Value Function Loss: 23.72751

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.04549

Collected Steps per Second: 10,903.60053
Overall Steps per Second: 9,282.23637

Timestep Collection Time: 4.58839
Timestep Consumption Time: 0.80147
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.38986

Cumulative Model Updates: 33,859
Cumulative Timesteps: 564,882,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,270.67184
Policy Entropy: 1.05534
Value Function Loss: 23.07186

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.04223
Value Function Update Magnitude: 0.04671

Collected Steps per Second: 10,919.52270
Overall Steps per Second: 9,481.89608

Timestep Collection Time: 4.58079
Timestep Consumption Time: 0.69453
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.27532

Cumulative Model Updates: 33,862
Cumulative Timesteps: 564,932,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 564932242...
Checkpoint 564932242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,049.99291
Policy Entropy: 1.04878
Value Function Loss: 23.55200

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.04101
Value Function Update Magnitude: 0.04508

Collected Steps per Second: 10,562.99732
Overall Steps per Second: 9,046.36599

Timestep Collection Time: 4.73426
Timestep Consumption Time: 0.79370
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 5.52797

Cumulative Model Updates: 33,865
Cumulative Timesteps: 564,982,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,906.88618
Policy Entropy: 1.06064
Value Function Loss: 21.46360

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.04041
Value Function Update Magnitude: 0.04884

Collected Steps per Second: 10,934.68161
Overall Steps per Second: 9,404.66500

Timestep Collection Time: 4.57480
Timestep Consumption Time: 0.74426
PPO Batch Consumption Time: 0.03366
Total Iteration Time: 5.31906

Cumulative Model Updates: 33,868
Cumulative Timesteps: 565,032,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 565032274...
Checkpoint 565032274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,418.79562
Policy Entropy: 1.07498
Value Function Loss: 20.40003

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14967
Policy Update Magnitude: 0.03989
Value Function Update Magnitude: 0.04612

Collected Steps per Second: 11,212.39452
Overall Steps per Second: 9,498.07100

Timestep Collection Time: 4.46113
Timestep Consumption Time: 0.80520
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.26633

Cumulative Model Updates: 33,871
Cumulative Timesteps: 565,082,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,172.76355
Policy Entropy: 1.05972
Value Function Loss: 20.40918

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.05177

Collected Steps per Second: 10,963.25062
Overall Steps per Second: 9,276.03586

Timestep Collection Time: 4.56106
Timestep Consumption Time: 0.82961
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.39066

Cumulative Model Updates: 33,874
Cumulative Timesteps: 565,132,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 565132298...
Checkpoint 565132298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,949.41140
Policy Entropy: 1.05791
Value Function Loss: 21.05558

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.04845

Collected Steps per Second: 10,884.04944
Overall Steps per Second: 9,458.26531

Timestep Collection Time: 4.59443
Timestep Consumption Time: 0.69259
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.28702

Cumulative Model Updates: 33,877
Cumulative Timesteps: 565,182,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,742.55156
Policy Entropy: 1.07987
Value Function Loss: 23.11023

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.04373

Collected Steps per Second: 11,863.72806
Overall Steps per Second: 10,026.05125

Timestep Collection Time: 4.21554
Timestep Consumption Time: 0.77267
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 4.98821

Cumulative Model Updates: 33,880
Cumulative Timesteps: 565,232,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 565232316...
Checkpoint 565232316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,384.90022
Policy Entropy: 1.08530
Value Function Loss: 23.17789

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.04040
Value Function Update Magnitude: 0.04716

Collected Steps per Second: 11,080.50422
Overall Steps per Second: 9,416.62943

Timestep Collection Time: 4.51442
Timestep Consumption Time: 0.79768
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.31209

Cumulative Model Updates: 33,883
Cumulative Timesteps: 565,282,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,550.45469
Policy Entropy: 1.06340
Value Function Loss: 23.37115

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.04588

Collected Steps per Second: 10,392.65238
Overall Steps per Second: 9,027.38190

Timestep Collection Time: 4.81263
Timestep Consumption Time: 0.72785
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 5.54048

Cumulative Model Updates: 33,886
Cumulative Timesteps: 565,332,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 565332354...
Checkpoint 565332354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,442.74931
Policy Entropy: 1.06951
Value Function Loss: 23.17634

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.04811
Value Function Update Magnitude: 0.04519

Collected Steps per Second: 10,925.81695
Overall Steps per Second: 9,283.92455

Timestep Collection Time: 4.57760
Timestep Consumption Time: 0.80956
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.38716

Cumulative Model Updates: 33,889
Cumulative Timesteps: 565,382,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,277.05910
Policy Entropy: 1.07187
Value Function Loss: 23.70805

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.04756

Collected Steps per Second: 11,343.76456
Overall Steps per Second: 9,674.05716

Timestep Collection Time: 4.40894
Timestep Consumption Time: 0.76097
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.16991

Cumulative Model Updates: 33,892
Cumulative Timesteps: 565,432,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 565432382...
Checkpoint 565432382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,383.27599
Policy Entropy: 1.07726
Value Function Loss: 23.61831

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 11,320.35481
Overall Steps per Second: 9,633.44189

Timestep Collection Time: 4.41806
Timestep Consumption Time: 0.77365
PPO Batch Consumption Time: 0.03778
Total Iteration Time: 5.19171

Cumulative Model Updates: 33,895
Cumulative Timesteps: 565,482,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,093.15281
Policy Entropy: 1.06865
Value Function Loss: 23.27769

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.04524

Collected Steps per Second: 10,994.11365
Overall Steps per Second: 9,286.10587

Timestep Collection Time: 4.54880
Timestep Consumption Time: 0.83667
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.38547

Cumulative Model Updates: 33,898
Cumulative Timesteps: 565,532,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 565532406...
Checkpoint 565532406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,713.64014
Policy Entropy: 1.04724
Value Function Loss: 23.02775

Mean KL Divergence: 0.03934
SB3 Clip Fraction: 0.19355
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.04601

Collected Steps per Second: 11,231.96337
Overall Steps per Second: 9,755.83079

Timestep Collection Time: 4.45336
Timestep Consumption Time: 0.67383
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.12719

Cumulative Model Updates: 33,901
Cumulative Timesteps: 565,582,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,783.10014
Policy Entropy: 1.07923
Value Function Loss: 22.32423

Mean KL Divergence: 0.02782
SB3 Clip Fraction: 0.17459
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.04501

Collected Steps per Second: 10,770.77315
Overall Steps per Second: 9,193.59240

Timestep Collection Time: 4.64498
Timestep Consumption Time: 0.79686
PPO Batch Consumption Time: 0.04651
Total Iteration Time: 5.44183

Cumulative Model Updates: 33,904
Cumulative Timesteps: 565,632,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 565632456...
Checkpoint 565632456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,452.38054
Policy Entropy: 1.05229
Value Function Loss: 21.47403

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.16494
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.04272

Collected Steps per Second: 10,805.51291
Overall Steps per Second: 9,269.69765

Timestep Collection Time: 4.62764
Timestep Consumption Time: 0.76671
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.39435

Cumulative Model Updates: 33,907
Cumulative Timesteps: 565,682,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,179.25283
Policy Entropy: 1.05604
Value Function Loss: 20.39319

Mean KL Divergence: 0.02547
SB3 Clip Fraction: 0.16355
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.04067

Collected Steps per Second: 11,236.55569
Overall Steps per Second: 9,550.39202

Timestep Collection Time: 4.45225
Timestep Consumption Time: 0.78607
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 5.23832

Cumulative Model Updates: 33,910
Cumulative Timesteps: 565,732,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 565732488...
Checkpoint 565732488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377,664.85554
Policy Entropy: 1.07128
Value Function Loss: 19.83453

Mean KL Divergence: 0.02796
SB3 Clip Fraction: 0.16911
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.03900

Collected Steps per Second: 11,039.58327
Overall Steps per Second: 9,458.63298

Timestep Collection Time: 4.53169
Timestep Consumption Time: 0.75744
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.28914

Cumulative Model Updates: 33,913
Cumulative Timesteps: 565,782,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,417.53541
Policy Entropy: 1.08254
Value Function Loss: 19.88016

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.15657
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.04187

Collected Steps per Second: 10,300.52499
Overall Steps per Second: 8,977.33672

Timestep Collection Time: 4.85587
Timestep Consumption Time: 0.71572
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.57159

Cumulative Model Updates: 33,916
Cumulative Timesteps: 565,832,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 565832534...
Checkpoint 565832534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,538.62327
Policy Entropy: 1.07665
Value Function Loss: 19.73662

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 11,135.37733
Overall Steps per Second: 9,426.24831

Timestep Collection Time: 4.49253
Timestep Consumption Time: 0.81457
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 5.30710

Cumulative Model Updates: 33,919
Cumulative Timesteps: 565,882,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,270.17743
Policy Entropy: 1.06935
Value Function Loss: 20.98864

Mean KL Divergence: 0.02864
SB3 Clip Fraction: 0.16579
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.04000

Collected Steps per Second: 10,732.87345
Overall Steps per Second: 9,213.95312

Timestep Collection Time: 4.65989
Timestep Consumption Time: 0.76818
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.42807

Cumulative Model Updates: 33,922
Cumulative Timesteps: 565,932,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 565932574...
Checkpoint 565932574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,933.37207
Policy Entropy: 1.08245
Value Function Loss: 21.71085

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.04452

Collected Steps per Second: 11,059.52779
Overall Steps per Second: 9,425.59509

Timestep Collection Time: 4.52334
Timestep Consumption Time: 0.78412
PPO Batch Consumption Time: 0.03771
Total Iteration Time: 5.30746

Cumulative Model Updates: 33,925
Cumulative Timesteps: 565,982,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,953.75784
Policy Entropy: 1.08974
Value Function Loss: 22.79822

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.14762
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.04414

Collected Steps per Second: 10,876.58424
Overall Steps per Second: 9,222.43045

Timestep Collection Time: 4.59869
Timestep Consumption Time: 0.82483
PPO Batch Consumption Time: 0.03827
Total Iteration Time: 5.42352

Cumulative Model Updates: 33,928
Cumulative Timesteps: 566,032,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 566032618...
Checkpoint 566032618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,644.65964
Policy Entropy: 1.06666
Value Function Loss: 22.50714

Mean KL Divergence: 0.02629
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.04298

Collected Steps per Second: 10,962.47858
Overall Steps per Second: 9,501.82105

Timestep Collection Time: 4.56357
Timestep Consumption Time: 0.70153
PPO Batch Consumption Time: 0.03984
Total Iteration Time: 5.26510

Cumulative Model Updates: 33,931
Cumulative Timesteps: 566,082,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,927.55522
Policy Entropy: 1.07826
Value Function Loss: 22.60926

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.04191

Collected Steps per Second: 10,724.74651
Overall Steps per Second: 9,151.57876

Timestep Collection Time: 4.66398
Timestep Consumption Time: 0.80174
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 5.46572

Cumulative Model Updates: 33,934
Cumulative Timesteps: 566,132,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 566132666...
Checkpoint 566132666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,307.92181
Policy Entropy: 1.07903
Value Function Loss: 22.19536

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.04237
Value Function Update Magnitude: 0.04959

Collected Steps per Second: 11,264.57287
Overall Steps per Second: 9,597.72228

Timestep Collection Time: 4.43940
Timestep Consumption Time: 0.77100
PPO Batch Consumption Time: 0.03890
Total Iteration Time: 5.21040

Cumulative Model Updates: 33,937
Cumulative Timesteps: 566,182,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,890.35611
Policy Entropy: 1.06930
Value Function Loss: 22.55111

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.04908

Collected Steps per Second: 10,985.67311
Overall Steps per Second: 9,366.12942

Timestep Collection Time: 4.55247
Timestep Consumption Time: 0.78719
PPO Batch Consumption Time: 0.03400
Total Iteration Time: 5.33967

Cumulative Model Updates: 33,940
Cumulative Timesteps: 566,232,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 566232686...
Checkpoint 566232686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,525.10094
Policy Entropy: 1.05704
Value Function Loss: 22.91018

Mean KL Divergence: 0.03228
SB3 Clip Fraction: 0.18041
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.04351

Collected Steps per Second: 11,272.01578
Overall Steps per Second: 9,563.44398

Timestep Collection Time: 4.43843
Timestep Consumption Time: 0.79295
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.23138

Cumulative Model Updates: 33,943
Cumulative Timesteps: 566,282,716

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,242.49353
Policy Entropy: 1.08348
Value Function Loss: 23.53963

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.04961

Collected Steps per Second: 11,458.02458
Overall Steps per Second: 9,948.45492

Timestep Collection Time: 4.36532
Timestep Consumption Time: 0.66239
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.02772

Cumulative Model Updates: 33,946
Cumulative Timesteps: 566,332,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 566332734...
Checkpoint 566332734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428,869.02130
Policy Entropy: 1.07627
Value Function Loss: 22.81093

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.04161

Collected Steps per Second: 10,936.45190
Overall Steps per Second: 9,336.97490

Timestep Collection Time: 4.57315
Timestep Consumption Time: 0.78341
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.35655

Cumulative Model Updates: 33,949
Cumulative Timesteps: 566,382,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376,791.94140
Policy Entropy: 1.06322
Value Function Loss: 22.30594

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.17645
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.04642

Collected Steps per Second: 11,125.04306
Overall Steps per Second: 9,445.06031

Timestep Collection Time: 4.49598
Timestep Consumption Time: 0.79970
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 5.29568

Cumulative Model Updates: 33,952
Cumulative Timesteps: 566,432,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 566432766...
Checkpoint 566432766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,563.84448
Policy Entropy: 1.07009
Value Function Loss: 22.11382

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.04473

Collected Steps per Second: 11,146.32163
Overall Steps per Second: 9,655.77453

Timestep Collection Time: 4.48758
Timestep Consumption Time: 0.69274
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 5.18032

Cumulative Model Updates: 33,955
Cumulative Timesteps: 566,482,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,786.57161
Policy Entropy: 1.06738
Value Function Loss: 21.74867

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.04280

Collected Steps per Second: 11,012.40815
Overall Steps per Second: 9,416.32097

Timestep Collection Time: 4.54324
Timestep Consumption Time: 0.77009
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 5.31333

Cumulative Model Updates: 33,958
Cumulative Timesteps: 566,532,818

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 566532818...
Checkpoint 566532818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428,985.01026
Policy Entropy: 1.06869
Value Function Loss: 21.68371

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.04028

Collected Steps per Second: 11,139.32947
Overall Steps per Second: 9,572.26745

Timestep Collection Time: 4.49058
Timestep Consumption Time: 0.73515
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.22572

Cumulative Model Updates: 33,961
Cumulative Timesteps: 566,582,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364,717.59758
Policy Entropy: 1.06598
Value Function Loss: 20.46185

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.04024

Collected Steps per Second: 11,115.37163
Overall Steps per Second: 9,509.50456

Timestep Collection Time: 4.49971
Timestep Consumption Time: 0.75987
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 5.25958

Cumulative Model Updates: 33,964
Cumulative Timesteps: 566,632,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 566632856...
Checkpoint 566632856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,058.43267
Policy Entropy: 1.07899
Value Function Loss: 20.76652

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.04286

Collected Steps per Second: 10,788.98684
Overall Steps per Second: 9,253.47414

Timestep Collection Time: 4.63547
Timestep Consumption Time: 0.76921
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 5.40467

Cumulative Model Updates: 33,967
Cumulative Timesteps: 566,682,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,429.65465
Policy Entropy: 1.08414
Value Function Loss: 20.99944

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.04626

Collected Steps per Second: 11,244.19242
Overall Steps per Second: 9,760.85743

Timestep Collection Time: 4.44781
Timestep Consumption Time: 0.67592
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 5.12373

Cumulative Model Updates: 33,970
Cumulative Timesteps: 566,732,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 566732880...
Checkpoint 566732880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,399.95040
Policy Entropy: 1.08587
Value Function Loss: 22.29715

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.06113
Value Function Update Magnitude: 0.04674

Collected Steps per Second: 10,862.91992
Overall Steps per Second: 9,338.68014

Timestep Collection Time: 4.60410
Timestep Consumption Time: 0.75147
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.35557

Cumulative Model Updates: 33,973
Cumulative Timesteps: 566,782,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,314.95175
Policy Entropy: 1.08435
Value Function Loss: 22.13718

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11594
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.04704

Collected Steps per Second: 11,127.84218
Overall Steps per Second: 9,683.29658

Timestep Collection Time: 4.49503
Timestep Consumption Time: 0.67056
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.16560

Cumulative Model Updates: 33,976
Cumulative Timesteps: 566,832,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 566832914...
Checkpoint 566832914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,893.88740
Policy Entropy: 1.09300
Value Function Loss: 22.08277

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.04192

Collected Steps per Second: 11,064.82835
Overall Steps per Second: 9,454.41479

Timestep Collection Time: 4.52045
Timestep Consumption Time: 0.76999
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.29044

Cumulative Model Updates: 33,979
Cumulative Timesteps: 566,882,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,516.29886
Policy Entropy: 1.09857
Value Function Loss: 22.33626

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.04377

Collected Steps per Second: 10,806.53553
Overall Steps per Second: 9,311.65640

Timestep Collection Time: 4.62850
Timestep Consumption Time: 0.74305
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.37155

Cumulative Model Updates: 33,982
Cumulative Timesteps: 566,932,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 566932950...
Checkpoint 566932950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369,059.45046
Policy Entropy: 1.10087
Value Function Loss: 21.95127

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.04239

Collected Steps per Second: 10,472.50757
Overall Steps per Second: 9,185.60261

Timestep Collection Time: 4.77612
Timestep Consumption Time: 0.66914
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.44526

Cumulative Model Updates: 33,985
Cumulative Timesteps: 566,982,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,821.72364
Policy Entropy: 1.09483
Value Function Loss: 22.84538

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.06040

Collected Steps per Second: 11,119.19115
Overall Steps per Second: 9,376.77894

Timestep Collection Time: 4.49943
Timestep Consumption Time: 0.83609
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 5.33552

Cumulative Model Updates: 33,988
Cumulative Timesteps: 567,032,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 567032998...
Checkpoint 567032998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,862.93531
Policy Entropy: 1.09170
Value Function Loss: 23.14915

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 11,006.98871
Overall Steps per Second: 9,481.76051

Timestep Collection Time: 4.54366
Timestep Consumption Time: 0.73089
PPO Batch Consumption Time: 0.04620
Total Iteration Time: 5.27455

Cumulative Model Updates: 33,991
Cumulative Timesteps: 567,083,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,145.87039
Policy Entropy: 1.09684
Value Function Loss: 22.46813

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.05077

Collected Steps per Second: 11,071.24559
Overall Steps per Second: 9,396.44351

Timestep Collection Time: 4.51855
Timestep Consumption Time: 0.80538
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.32393

Cumulative Model Updates: 33,994
Cumulative Timesteps: 567,133,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 567133036...
Checkpoint 567133036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,882.16066
Policy Entropy: 1.10346
Value Function Loss: 22.17440

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.05049

Collected Steps per Second: 10,531.18593
Overall Steps per Second: 9,036.92865

Timestep Collection Time: 4.74989
Timestep Consumption Time: 0.78540
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.53529

Cumulative Model Updates: 33,997
Cumulative Timesteps: 567,183,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,858.89639
Policy Entropy: 1.10349
Value Function Loss: 21.65087

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.05110

Collected Steps per Second: 10,538.65414
Overall Steps per Second: 9,181.08569

Timestep Collection Time: 4.74729
Timestep Consumption Time: 0.70196
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 5.44925

Cumulative Model Updates: 34,000
Cumulative Timesteps: 567,233,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 567233088...
Checkpoint 567233088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432,455.54970
Policy Entropy: 1.10641
Value Function Loss: 22.21484

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.04392

Collected Steps per Second: 11,131.70403
Overall Steps per Second: 9,433.33203

Timestep Collection Time: 4.49437
Timestep Consumption Time: 0.80916
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.30353

Cumulative Model Updates: 34,003
Cumulative Timesteps: 567,283,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,918.99027
Policy Entropy: 1.10572
Value Function Loss: 22.04490

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.04541

Collected Steps per Second: 11,952.99080
Overall Steps per Second: 10,023.62247

Timestep Collection Time: 4.18305
Timestep Consumption Time: 0.80516
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.98822

Cumulative Model Updates: 34,006
Cumulative Timesteps: 567,333,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 567333118...
Checkpoint 567333118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,831.63573
Policy Entropy: 1.12117
Value Function Loss: 21.99832

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.04996

Collected Steps per Second: 12,068.89575
Overall Steps per Second: 10,146.68486

Timestep Collection Time: 4.14404
Timestep Consumption Time: 0.78506
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 4.92910

Cumulative Model Updates: 34,009
Cumulative Timesteps: 567,383,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,238.08835
Policy Entropy: 1.12484
Value Function Loss: 21.72761

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.04370

Collected Steps per Second: 12,147.59036
Overall Steps per Second: 10,189.48776

Timestep Collection Time: 4.11703
Timestep Consumption Time: 0.79117
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 4.90820

Cumulative Model Updates: 34,012
Cumulative Timesteps: 567,433,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 567433144...
Checkpoint 567433144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380,289.94969
Policy Entropy: 1.09961
Value Function Loss: 22.12577

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.05781

Collected Steps per Second: 12,159.42862
Overall Steps per Second: 10,324.63254

Timestep Collection Time: 4.11401
Timestep Consumption Time: 0.73110
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 4.84511

Cumulative Model Updates: 34,015
Cumulative Timesteps: 567,483,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,557.97899
Policy Entropy: 1.10834
Value Function Loss: 21.62908

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 11,345.60036
Overall Steps per Second: 9,650.30039

Timestep Collection Time: 4.40823
Timestep Consumption Time: 0.77441
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.18264

Cumulative Model Updates: 34,018
Cumulative Timesteps: 567,533,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 567533182...
Checkpoint 567533182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,717.37781
Policy Entropy: 1.09695
Value Function Loss: 21.46244

Mean KL Divergence: 0.02437
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.04387
Value Function Update Magnitude: 0.04812

Collected Steps per Second: 11,506.95794
Overall Steps per Second: 9,761.06701

Timestep Collection Time: 4.34572
Timestep Consumption Time: 0.77729
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.12301

Cumulative Model Updates: 34,021
Cumulative Timesteps: 567,583,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,604.92228
Policy Entropy: 1.08783
Value Function Loss: 20.84472

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.04891

Collected Steps per Second: 11,082.54176
Overall Steps per Second: 9,397.74690

Timestep Collection Time: 4.51268
Timestep Consumption Time: 0.80902
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.32170

Cumulative Model Updates: 34,024
Cumulative Timesteps: 567,633,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 567633200...
Checkpoint 567633200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,753.30696
Policy Entropy: 1.07572
Value Function Loss: 21.27535

Mean KL Divergence: 0.02268
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.04899

Collected Steps per Second: 11,146.07735
Overall Steps per Second: 9,455.62796

Timestep Collection Time: 4.48588
Timestep Consumption Time: 0.80197
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.28786

Cumulative Model Updates: 34,027
Cumulative Timesteps: 567,683,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376,081.31321
Policy Entropy: 1.09684
Value Function Loss: 20.58271

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.04661

Collected Steps per Second: 11,335.12940
Overall Steps per Second: 9,827.85104

Timestep Collection Time: 4.41124
Timestep Consumption Time: 0.67654
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.08779

Cumulative Model Updates: 34,030
Cumulative Timesteps: 567,733,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 567733202...
Checkpoint 567733202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,373.03433
Policy Entropy: 1.10176
Value Function Loss: 19.96609

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.04587

Collected Steps per Second: 11,098.69417
Overall Steps per Second: 9,407.18858

Timestep Collection Time: 4.50684
Timestep Consumption Time: 0.81037
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.31721

Cumulative Model Updates: 34,033
Cumulative Timesteps: 567,783,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,241.76898
Policy Entropy: 1.08941
Value Function Loss: 19.80462

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.04464

Collected Steps per Second: 10,589.44658
Overall Steps per Second: 9,093.33950

Timestep Collection Time: 4.72263
Timestep Consumption Time: 0.77700
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.49963

Cumulative Model Updates: 34,036
Cumulative Timesteps: 567,833,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 567833232...
Checkpoint 567833232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,445.36470
Policy Entropy: 1.07634
Value Function Loss: 20.45742

Mean KL Divergence: 0.03319
SB3 Clip Fraction: 0.15421
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.04924

Collected Steps per Second: 11,072.31097
Overall Steps per Second: 9,481.83887

Timestep Collection Time: 4.51739
Timestep Consumption Time: 0.75774
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.27514

Cumulative Model Updates: 34,039
Cumulative Timesteps: 567,883,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,606.60664
Policy Entropy: 1.08694
Value Function Loss: 20.63985

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.04628

Collected Steps per Second: 11,018.76351
Overall Steps per Second: 9,363.01420

Timestep Collection Time: 4.53917
Timestep Consumption Time: 0.80270
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 5.34187

Cumulative Model Updates: 34,042
Cumulative Timesteps: 567,933,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 567933266...
Checkpoint 567933266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,056.06925
Policy Entropy: 1.09420
Value Function Loss: 21.06012

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.05115

Collected Steps per Second: 11,207.10626
Overall Steps per Second: 9,625.91583

Timestep Collection Time: 4.46306
Timestep Consumption Time: 0.73312
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 5.19618

Cumulative Model Updates: 34,045
Cumulative Timesteps: 567,983,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,631.51762
Policy Entropy: 1.07286
Value Function Loss: 19.91652

Mean KL Divergence: 0.02511
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.04431

Collected Steps per Second: 10,812.19703
Overall Steps per Second: 9,265.60522

Timestep Collection Time: 4.62700
Timestep Consumption Time: 0.77233
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.39932

Cumulative Model Updates: 34,048
Cumulative Timesteps: 568,033,312

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 568033312...
Checkpoint 568033312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,853.30815
Policy Entropy: 1.07242
Value Function Loss: 20.06270

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.04313
Value Function Update Magnitude: 0.04382

Collected Steps per Second: 11,167.20096
Overall Steps per Second: 9,525.07853

Timestep Collection Time: 4.47776
Timestep Consumption Time: 0.77196
PPO Batch Consumption Time: 0.03746
Total Iteration Time: 5.24972

Cumulative Model Updates: 34,051
Cumulative Timesteps: 568,083,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,847.88948
Policy Entropy: 1.07428
Value Function Loss: 20.14717

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.04274

Collected Steps per Second: 10,864.84435
Overall Steps per Second: 9,281.80653

Timestep Collection Time: 4.60329
Timestep Consumption Time: 0.78510
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 5.38839

Cumulative Model Updates: 34,054
Cumulative Timesteps: 568,133,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 568133330...
Checkpoint 568133330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,045.04256
Policy Entropy: 1.07373
Value Function Loss: 20.91127

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.04447

Collected Steps per Second: 10,827.57081
Overall Steps per Second: 9,263.95575

Timestep Collection Time: 4.61969
Timestep Consumption Time: 0.77973
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.39942

Cumulative Model Updates: 34,057
Cumulative Timesteps: 568,183,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,066.72632
Policy Entropy: 1.07244
Value Function Loss: 20.79282

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.04173

Collected Steps per Second: 10,851.00384
Overall Steps per Second: 9,402.96776

Timestep Collection Time: 4.60897
Timestep Consumption Time: 0.70977
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.31875

Cumulative Model Updates: 34,060
Cumulative Timesteps: 568,233,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 568233362...
Checkpoint 568233362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,811.20751
Policy Entropy: 1.06887
Value Function Loss: 20.31522

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.07057

Collected Steps per Second: 10,895.51530
Overall Steps per Second: 9,317.82233

Timestep Collection Time: 4.59088
Timestep Consumption Time: 0.77733
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.36821

Cumulative Model Updates: 34,063
Cumulative Timesteps: 568,283,382

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408,021.43635
Policy Entropy: 1.07943
Value Function Loss: 20.08868

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.07334

Collected Steps per Second: 10,986.18263
Overall Steps per Second: 9,425.45109

Timestep Collection Time: 4.55317
Timestep Consumption Time: 0.75395
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.30712

Cumulative Model Updates: 34,066
Cumulative Timesteps: 568,333,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 568333404...
Checkpoint 568333404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,519.31256
Policy Entropy: 1.08541
Value Function Loss: 19.93822

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.06330

Collected Steps per Second: 10,785.80736
Overall Steps per Second: 9,259.18228

Timestep Collection Time: 4.63646
Timestep Consumption Time: 0.76445
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 5.40091

Cumulative Model Updates: 34,069
Cumulative Timesteps: 568,383,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,422.83587
Policy Entropy: 1.07600
Value Function Loss: 19.66223

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.05519

Collected Steps per Second: 11,206.87994
Overall Steps per Second: 9,502.81980

Timestep Collection Time: 4.46422
Timestep Consumption Time: 0.80053
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.26475

Cumulative Model Updates: 34,072
Cumulative Timesteps: 568,433,442

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 568433442...
Checkpoint 568433442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422,498.90901
Policy Entropy: 1.06155
Value Function Loss: 20.31048

Mean KL Divergence: 0.03324
SB3 Clip Fraction: 0.18459
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.06193

Collected Steps per Second: 11,411.67940
Overall Steps per Second: 9,894.76854

Timestep Collection Time: 4.38340
Timestep Consumption Time: 0.67199
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.05540

Cumulative Model Updates: 34,075
Cumulative Timesteps: 568,483,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,275.29365
Policy Entropy: 1.08443
Value Function Loss: 20.10738

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.05772

Collected Steps per Second: 11,279.24574
Overall Steps per Second: 9,517.62467

Timestep Collection Time: 4.43576
Timestep Consumption Time: 0.82102
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.25677

Cumulative Model Updates: 34,078
Cumulative Timesteps: 568,533,496

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 568533496...
Checkpoint 568533496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,310.41893
Policy Entropy: 1.07695
Value Function Loss: 20.14450

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.05084

Collected Steps per Second: 11,459.79478
Overall Steps per Second: 9,824.74144

Timestep Collection Time: 4.36552
Timestep Consumption Time: 0.72652
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.09204

Cumulative Model Updates: 34,081
Cumulative Timesteps: 568,583,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,291.27412
Policy Entropy: 1.06334
Value Function Loss: 21.04393

Mean KL Divergence: 0.03111
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.05224

Collected Steps per Second: 11,729.59590
Overall Steps per Second: 9,933.39588

Timestep Collection Time: 4.26374
Timestep Consumption Time: 0.77099
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.03473

Cumulative Model Updates: 34,084
Cumulative Timesteps: 568,633,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 568633536...
Checkpoint 568633536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,322.59918
Policy Entropy: 1.07384
Value Function Loss: 21.42797

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.05697

Collected Steps per Second: 10,777.29709
Overall Steps per Second: 9,273.81679

Timestep Collection Time: 4.64068
Timestep Consumption Time: 0.75235
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.39303

Cumulative Model Updates: 34,087
Cumulative Timesteps: 568,683,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,958.66028
Policy Entropy: 1.07771
Value Function Loss: 21.68967

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.16561
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.06125

Collected Steps per Second: 11,439.83620
Overall Steps per Second: 9,794.87053

Timestep Collection Time: 4.37227
Timestep Consumption Time: 0.73429
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 5.10655

Cumulative Model Updates: 34,090
Cumulative Timesteps: 568,733,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 568733568...
Checkpoint 568733568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,292.34402
Policy Entropy: 1.06420
Value Function Loss: 20.20939

Mean KL Divergence: 0.02455
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.06836

Collected Steps per Second: 10,299.30902
Overall Steps per Second: 8,885.43532

Timestep Collection Time: 4.85644
Timestep Consumption Time: 0.77277
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.62921

Cumulative Model Updates: 34,093
Cumulative Timesteps: 568,783,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,010.93439
Policy Entropy: 1.04686
Value Function Loss: 20.30977

Mean KL Divergence: 0.03491
SB3 Clip Fraction: 0.18579
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.10335

Collected Steps per Second: 11,300.13883
Overall Steps per Second: 9,624.25133

Timestep Collection Time: 4.42472
Timestep Consumption Time: 0.77048
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.19521

Cumulative Model Updates: 34,096
Cumulative Timesteps: 568,833,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 568833586...
Checkpoint 568833586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,515.87963
Policy Entropy: 1.07895
Value Function Loss: 20.06683

Mean KL Divergence: 0.03715
SB3 Clip Fraction: 0.19818
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.10916

Collected Steps per Second: 11,402.40792
Overall Steps per Second: 9,588.66613

Timestep Collection Time: 4.38521
Timestep Consumption Time: 0.82948
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 5.21470

Cumulative Model Updates: 34,099
Cumulative Timesteps: 568,883,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378,927.36055
Policy Entropy: 1.05984
Value Function Loss: 19.91560

Mean KL Divergence: 0.03601
SB3 Clip Fraction: 0.18459
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.11924

Collected Steps per Second: 11,025.44168
Overall Steps per Second: 9,305.51640

Timestep Collection Time: 4.53678
Timestep Consumption Time: 0.83853
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.37531

Cumulative Model Updates: 34,102
Cumulative Timesteps: 568,933,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 568933608...
Checkpoint 568933608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,089.58177
Policy Entropy: 1.08711
Value Function Loss: 19.16144

Mean KL Divergence: 0.03546
SB3 Clip Fraction: 0.17756
Policy Update Magnitude: 0.04412
Value Function Update Magnitude: 0.09922

Collected Steps per Second: 11,033.84927
Overall Steps per Second: 9,593.74917

Timestep Collection Time: 4.53405
Timestep Consumption Time: 0.68060
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.21465

Cumulative Model Updates: 34,105
Cumulative Timesteps: 568,983,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,448.71959
Policy Entropy: 1.08984
Value Function Loss: 19.53566

Mean KL Divergence: 0.03337
SB3 Clip Fraction: 0.17965
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 10,424.63979
Overall Steps per Second: 8,904.82448

Timestep Collection Time: 4.79671
Timestep Consumption Time: 0.81867
PPO Batch Consumption Time: 0.04343
Total Iteration Time: 5.61538

Cumulative Model Updates: 34,108
Cumulative Timesteps: 569,033,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 569033640...
Checkpoint 569033640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,377.04254
Policy Entropy: 1.07864
Value Function Loss: 19.51750

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.07656

Collected Steps per Second: 10,740.13452
Overall Steps per Second: 9,098.86663

Timestep Collection Time: 4.65786
Timestep Consumption Time: 0.84019
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.49805

Cumulative Model Updates: 34,111
Cumulative Timesteps: 569,083,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437,363.86348
Policy Entropy: 1.06889
Value Function Loss: 20.10492

Mean KL Divergence: 0.03278
SB3 Clip Fraction: 0.16030
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.08360

Collected Steps per Second: 11,076.45159
Overall Steps per Second: 9,624.65223

Timestep Collection Time: 4.51571
Timestep Consumption Time: 0.68116
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.19686

Cumulative Model Updates: 34,114
Cumulative Timesteps: 569,133,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 569133684...
Checkpoint 569133684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,805.88404
Policy Entropy: 1.09310
Value Function Loss: 19.93156

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.07841

Collected Steps per Second: 11,070.48490
Overall Steps per Second: 9,494.26296

Timestep Collection Time: 4.51742
Timestep Consumption Time: 0.74997
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.26739

Cumulative Model Updates: 34,117
Cumulative Timesteps: 569,183,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,647.84661
Policy Entropy: 1.09893
Value Function Loss: 19.97511

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11908
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 10,435.71957
Overall Steps per Second: 8,970.44073

Timestep Collection Time: 4.79143
Timestep Consumption Time: 0.78266
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.57409

Cumulative Model Updates: 34,120
Cumulative Timesteps: 569,233,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 569233696...
Checkpoint 569233696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,903.49580
Policy Entropy: 1.08096
Value Function Loss: 19.84565

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.07353

Collected Steps per Second: 10,987.02084
Overall Steps per Second: 9,313.44298

Timestep Collection Time: 4.55210
Timestep Consumption Time: 0.81799
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.37009

Cumulative Model Updates: 34,123
Cumulative Timesteps: 569,283,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,591.27664
Policy Entropy: 1.05840
Value Function Loss: 19.39515

Mean KL Divergence: 0.03283
SB3 Clip Fraction: 0.17373
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.06969

Collected Steps per Second: 10,793.51449
Overall Steps per Second: 9,290.02167

Timestep Collection Time: 4.63445
Timestep Consumption Time: 0.75004
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.38449

Cumulative Model Updates: 34,126
Cumulative Timesteps: 569,333,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 569333732...
Checkpoint 569333732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,094.94346
Policy Entropy: 1.07438
Value Function Loss: 19.74648

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.07843

Collected Steps per Second: 10,870.82890
Overall Steps per Second: 9,433.90265

Timestep Collection Time: 4.60094
Timestep Consumption Time: 0.70079
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.30173

Cumulative Model Updates: 34,129
Cumulative Timesteps: 569,383,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399,238.25464
Policy Entropy: 1.07928
Value Function Loss: 19.20670

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.07301

Collected Steps per Second: 10,739.00646
Overall Steps per Second: 9,132.13483

Timestep Collection Time: 4.65797
Timestep Consumption Time: 0.81961
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.47758

Cumulative Model Updates: 34,132
Cumulative Timesteps: 569,433,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 569433770...
Checkpoint 569433770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,296.31093
Policy Entropy: 1.07042
Value Function Loss: 18.51786

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.06384

Collected Steps per Second: 10,931.25190
Overall Steps per Second: 9,142.64259

Timestep Collection Time: 4.57459
Timestep Consumption Time: 0.89494
PPO Batch Consumption Time: 0.03945
Total Iteration Time: 5.46953

Cumulative Model Updates: 34,135
Cumulative Timesteps: 569,483,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,734.30807
Policy Entropy: 1.05259
Value Function Loss: 18.04154

Mean KL Divergence: 0.03280
SB3 Clip Fraction: 0.17461
Policy Update Magnitude: 0.04038
Value Function Update Magnitude: 0.07300

Collected Steps per Second: 11,076.14629
Overall Steps per Second: 9,451.26467

Timestep Collection Time: 4.51565
Timestep Consumption Time: 0.77634
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.29199

Cumulative Model Updates: 34,138
Cumulative Timesteps: 569,533,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 569533792...
Checkpoint 569533792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,060.53929
Policy Entropy: 1.06405
Value Function Loss: 18.92834

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.07185

Collected Steps per Second: 12,303.84369
Overall Steps per Second: 10,435.00421

Timestep Collection Time: 4.06556
Timestep Consumption Time: 0.72811
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.79367

Cumulative Model Updates: 34,141
Cumulative Timesteps: 569,583,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,870.48424
Policy Entropy: 1.07635
Value Function Loss: 19.85448

Mean KL Divergence: 0.02450
SB3 Clip Fraction: 0.15616
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.06540

Collected Steps per Second: 12,005.82152
Overall Steps per Second: 10,261.96596

Timestep Collection Time: 4.16565
Timestep Consumption Time: 0.70788
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 4.87353

Cumulative Model Updates: 34,144
Cumulative Timesteps: 569,633,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 569633826...
Checkpoint 569633826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,867.55734
Policy Entropy: 1.04356
Value Function Loss: 19.18227

Mean KL Divergence: 0.04286
SB3 Clip Fraction: 0.18175
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.05734

Collected Steps per Second: 11,974.86428
Overall Steps per Second: 10,077.06240

Timestep Collection Time: 4.17575
Timestep Consumption Time: 0.78641
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 4.96216

Cumulative Model Updates: 34,147
Cumulative Timesteps: 569,683,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,761.25692
Policy Entropy: 1.07105
Value Function Loss: 19.60412

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.06462

Collected Steps per Second: 11,872.72034
Overall Steps per Second: 10,010.15466

Timestep Collection Time: 4.21268
Timestep Consumption Time: 0.78384
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 4.99653

Cumulative Model Updates: 34,150
Cumulative Timesteps: 569,733,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 569733846...
Checkpoint 569733846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,653.07955
Policy Entropy: 1.06184
Value Function Loss: 19.90189

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.05783

Collected Steps per Second: 12,243.27869
Overall Steps per Second: 10,116.80700

Timestep Collection Time: 4.08600
Timestep Consumption Time: 0.85884
PPO Batch Consumption Time: 0.04022
Total Iteration Time: 4.94484

Cumulative Model Updates: 34,153
Cumulative Timesteps: 569,783,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,610.33282
Policy Entropy: 1.06318
Value Function Loss: 20.50808

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.04972

Collected Steps per Second: 11,478.68178
Overall Steps per Second: 9,808.07793

Timestep Collection Time: 4.35747
Timestep Consumption Time: 0.74220
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.09967

Cumulative Model Updates: 34,156
Cumulative Timesteps: 569,833,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 569833890...
Checkpoint 569833890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,523.74830
Policy Entropy: 1.05212
Value Function Loss: 19.25229

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.14749
Policy Update Magnitude: 0.06477
Value Function Update Magnitude: 0.04304

Collected Steps per Second: 11,230.77951
Overall Steps per Second: 9,712.89689

Timestep Collection Time: 4.45223
Timestep Consumption Time: 0.69577
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.14800

Cumulative Model Updates: 34,159
Cumulative Timesteps: 569,883,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,328.97525
Policy Entropy: 1.06651
Value Function Loss: 18.36484

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.05228

Collected Steps per Second: 11,049.77233
Overall Steps per Second: 9,342.12484

Timestep Collection Time: 4.52679
Timestep Consumption Time: 0.82745
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.35424

Cumulative Model Updates: 34,162
Cumulative Timesteps: 569,933,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 569933912...
Checkpoint 569933912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,132.75598
Policy Entropy: 1.06823
Value Function Loss: 17.39415

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.04762

Collected Steps per Second: 11,078.04229
Overall Steps per Second: 9,504.04733

Timestep Collection Time: 4.51560
Timestep Consumption Time: 0.74784
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.26344

Cumulative Model Updates: 34,165
Cumulative Timesteps: 569,983,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,926.41369
Policy Entropy: 1.04634
Value Function Loss: 17.08197

Mean KL Divergence: 0.02619
SB3 Clip Fraction: 0.16269
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.04491

Collected Steps per Second: 11,475.28871
Overall Steps per Second: 9,712.82207

Timestep Collection Time: 4.35789
Timestep Consumption Time: 0.79077
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.14866

Cumulative Model Updates: 34,168
Cumulative Timesteps: 570,033,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 570033944...
Checkpoint 570033944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,631.05306
Policy Entropy: 1.04602
Value Function Loss: 17.52447

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.04059
Value Function Update Magnitude: 0.04578

Collected Steps per Second: 10,554.15518
Overall Steps per Second: 9,072.60401

Timestep Collection Time: 4.73956
Timestep Consumption Time: 0.77397
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.51352

Cumulative Model Updates: 34,171
Cumulative Timesteps: 570,083,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,594.57042
Policy Entropy: 1.05606
Value Function Loss: 18.57483

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.04147
Value Function Update Magnitude: 0.04325

Collected Steps per Second: 11,041.98479
Overall Steps per Second: 9,616.19525

Timestep Collection Time: 4.53071
Timestep Consumption Time: 0.67177
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.20247

Cumulative Model Updates: 34,174
Cumulative Timesteps: 570,133,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 570133994...
Checkpoint 570133994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,457.82918
Policy Entropy: 1.06323
Value Function Loss: 19.77700

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.03881
Value Function Update Magnitude: 0.05219

Collected Steps per Second: 10,953.71652
Overall Steps per Second: 9,411.42721

Timestep Collection Time: 4.56685
Timestep Consumption Time: 0.74839
PPO Batch Consumption Time: 0.03272
Total Iteration Time: 5.31524

Cumulative Model Updates: 34,177
Cumulative Timesteps: 570,184,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,954.59030
Policy Entropy: 1.06095
Value Function Loss: 20.08682

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.04763

Collected Steps per Second: 11,029.70812
Overall Steps per Second: 9,450.21148

Timestep Collection Time: 4.53430
Timestep Consumption Time: 0.75786
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.29216

Cumulative Model Updates: 34,180
Cumulative Timesteps: 570,234,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 570234030...
Checkpoint 570234030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,359.69591
Policy Entropy: 1.04657
Value Function Loss: 19.27526

Mean KL Divergence: 0.03029
SB3 Clip Fraction: 0.16509
Policy Update Magnitude: 0.04279
Value Function Update Magnitude: 0.04946

Collected Steps per Second: 11,228.15014
Overall Steps per Second: 9,607.82210

Timestep Collection Time: 4.45470
Timestep Consumption Time: 0.75127
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 5.20597

Cumulative Model Updates: 34,183
Cumulative Timesteps: 570,284,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,813.77147
Policy Entropy: 1.07365
Value Function Loss: 19.11742

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.06062

Collected Steps per Second: 11,591.54758
Overall Steps per Second: 9,857.85030

Timestep Collection Time: 4.31401
Timestep Consumption Time: 0.75870
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.07271

Cumulative Model Updates: 34,186
Cumulative Timesteps: 570,334,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 570334054...
Checkpoint 570334054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,889.59354
Policy Entropy: 1.05704
Value Function Loss: 18.52069

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.06794

Collected Steps per Second: 10,411.44791
Overall Steps per Second: 9,145.06315

Timestep Collection Time: 4.80279
Timestep Consumption Time: 0.66508
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.46787

Cumulative Model Updates: 34,189
Cumulative Timesteps: 570,384,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,036.39344
Policy Entropy: 1.04848
Value Function Loss: 18.83928

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.15871
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.06807

Collected Steps per Second: 10,906.22476
Overall Steps per Second: 9,311.81179

Timestep Collection Time: 4.58582
Timestep Consumption Time: 0.78521
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.37103

Cumulative Model Updates: 34,192
Cumulative Timesteps: 570,434,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 570434072...
Checkpoint 570434072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,585.16408
Policy Entropy: 1.06358
Value Function Loss: 18.24442

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.08065

Collected Steps per Second: 10,876.78472
Overall Steps per Second: 9,344.00531

Timestep Collection Time: 4.59805
Timestep Consumption Time: 0.75426
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.35231

Cumulative Model Updates: 34,195
Cumulative Timesteps: 570,484,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419,949.52733
Policy Entropy: 1.06267
Value Function Loss: 18.93860

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.14741
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.08028

Collected Steps per Second: 11,006.90419
Overall Steps per Second: 9,350.51374

Timestep Collection Time: 4.54424
Timestep Consumption Time: 0.80499
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 5.34922

Cumulative Model Updates: 34,198
Cumulative Timesteps: 570,534,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 570534102...
Checkpoint 570534102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,512.58334
Policy Entropy: 1.04535
Value Function Loss: 17.59611

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.04500
Value Function Update Magnitude: 0.08498

Collected Steps per Second: 10,970.63230
Overall Steps per Second: 9,350.73378

Timestep Collection Time: 4.55963
Timestep Consumption Time: 0.78990
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.34953

Cumulative Model Updates: 34,201
Cumulative Timesteps: 570,584,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,447.77426
Policy Entropy: 1.03234
Value Function Loss: 17.99395

Mean KL Divergence: 0.03283
SB3 Clip Fraction: 0.17108
Policy Update Magnitude: 0.04265
Value Function Update Magnitude: 0.08613

Collected Steps per Second: 10,783.83270
Overall Steps per Second: 9,340.48182

Timestep Collection Time: 4.63731
Timestep Consumption Time: 0.71659
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 5.35390

Cumulative Model Updates: 34,204
Cumulative Timesteps: 570,634,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 570634132...
Checkpoint 570634132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,196.82280
Policy Entropy: 1.05753
Value Function Loss: 17.09014

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.07434

Collected Steps per Second: 10,831.88782
Overall Steps per Second: 9,269.39688

Timestep Collection Time: 4.61859
Timestep Consumption Time: 0.77853
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.39711

Cumulative Model Updates: 34,207
Cumulative Timesteps: 570,684,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,207.29274
Policy Entropy: 1.04601
Value Function Loss: 18.84517

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.06891

Collected Steps per Second: 11,141.17602
Overall Steps per Second: 9,637.94727

Timestep Collection Time: 4.48947
Timestep Consumption Time: 0.70022
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 5.18969

Cumulative Model Updates: 34,210
Cumulative Timesteps: 570,734,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 570734178...
Checkpoint 570734178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,331.02080
Policy Entropy: 1.04744
Value Function Loss: 18.49622

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.06936

Collected Steps per Second: 11,420.95367
Overall Steps per Second: 9,649.27314

Timestep Collection Time: 4.37879
Timestep Consumption Time: 0.80398
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 5.18277

Cumulative Model Updates: 34,213
Cumulative Timesteps: 570,784,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,522.93105
Policy Entropy: 1.02965
Value Function Loss: 19.32107

Mean KL Divergence: 0.03544
SB3 Clip Fraction: 0.18126
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.06603

Collected Steps per Second: 11,050.27901
Overall Steps per Second: 9,442.72460

Timestep Collection Time: 4.52532
Timestep Consumption Time: 0.77040
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.29572

Cumulative Model Updates: 34,216
Cumulative Timesteps: 570,834,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 570834194...
Checkpoint 570834194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,346.05928
Policy Entropy: 1.05085
Value Function Loss: 19.00392

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.06667

Collected Steps per Second: 11,651.54638
Overall Steps per Second: 9,915.63662

Timestep Collection Time: 4.29368
Timestep Consumption Time: 0.75169
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.04536

Cumulative Model Updates: 34,219
Cumulative Timesteps: 570,884,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402,477.56368
Policy Entropy: 1.04967
Value Function Loss: 18.52891

Mean KL Divergence: 0.02437
SB3 Clip Fraction: 0.15833
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.06589

Collected Steps per Second: 10,754.67482
Overall Steps per Second: 9,236.12216

Timestep Collection Time: 4.64933
Timestep Consumption Time: 0.76442
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 5.41374

Cumulative Model Updates: 34,222
Cumulative Timesteps: 570,934,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 570934224...
Checkpoint 570934224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,387.20882
Policy Entropy: 1.02978
Value Function Loss: 18.68506

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.06733

Collected Steps per Second: 11,305.44631
Overall Steps per Second: 9,771.45265

Timestep Collection Time: 4.42389
Timestep Consumption Time: 0.69449
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.11838

Cumulative Model Updates: 34,225
Cumulative Timesteps: 570,984,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,047.56022
Policy Entropy: 1.01045
Value Function Loss: 19.35931

Mean KL Divergence: 0.03742
SB3 Clip Fraction: 0.19384
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.06310

Collected Steps per Second: 11,186.92340
Overall Steps per Second: 9,514.49955

Timestep Collection Time: 4.47129
Timestep Consumption Time: 0.78595
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.25724

Cumulative Model Updates: 34,228
Cumulative Timesteps: 571,034,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 571034258...
Checkpoint 571034258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,066.10340
Policy Entropy: 1.03885
Value Function Loss: 19.92761

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.07703

Collected Steps per Second: 10,961.50967
Overall Steps per Second: 9,462.70712

Timestep Collection Time: 4.56306
Timestep Consumption Time: 0.72274
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.28580

Cumulative Model Updates: 34,231
Cumulative Timesteps: 571,084,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,093.20536
Policy Entropy: 1.03771
Value Function Loss: 19.80642

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.07569

Collected Steps per Second: 11,473.90781
Overall Steps per Second: 9,696.82916

Timestep Collection Time: 4.35893
Timestep Consumption Time: 0.79884
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.15777

Cumulative Model Updates: 34,234
Cumulative Timesteps: 571,134,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 571134290...
Checkpoint 571134290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,837.44638
Policy Entropy: 1.02248
Value Function Loss: 18.21418

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.07516

Collected Steps per Second: 11,011.62509
Overall Steps per Second: 9,361.62743

Timestep Collection Time: 4.54302
Timestep Consumption Time: 0.80071
PPO Batch Consumption Time: 0.03953
Total Iteration Time: 5.34373

Cumulative Model Updates: 34,237
Cumulative Timesteps: 571,184,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,217.67785
Policy Entropy: 1.04190
Value Function Loss: 18.20435

Mean KL Divergence: 0.02630
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.06921

Collected Steps per Second: 10,815.47000
Overall Steps per Second: 9,396.54063

Timestep Collection Time: 4.62301
Timestep Consumption Time: 0.69810
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.32111

Cumulative Model Updates: 34,240
Cumulative Timesteps: 571,234,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 571234316...
Checkpoint 571234316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,070.00856
Policy Entropy: 1.03835
Value Function Loss: 17.69965

Mean KL Divergence: 0.02388
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.07681

Collected Steps per Second: 10,917.65086
Overall Steps per Second: 9,325.73740

Timestep Collection Time: 4.58121
Timestep Consumption Time: 0.78202
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.36322

Cumulative Model Updates: 34,243
Cumulative Timesteps: 571,284,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,639.32481
Policy Entropy: 1.03646
Value Function Loss: 17.27909

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.08330

Collected Steps per Second: 10,966.60803
Overall Steps per Second: 9,536.62538

Timestep Collection Time: 4.56185
Timestep Consumption Time: 0.68403
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.24588

Cumulative Model Updates: 34,246
Cumulative Timesteps: 571,334,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 571334360...
Checkpoint 571334360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,571.91533
Policy Entropy: 1.01531
Value Function Loss: 17.03373

Mean KL Divergence: 0.04151
SB3 Clip Fraction: 0.19681
Policy Update Magnitude: 0.04633
Value Function Update Magnitude: 0.09394

Collected Steps per Second: 11,130.29739
Overall Steps per Second: 9,501.02375

Timestep Collection Time: 4.49314
Timestep Consumption Time: 0.77050
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.26364

Cumulative Model Updates: 34,249
Cumulative Timesteps: 571,384,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,374.05592
Policy Entropy: 1.04239
Value Function Loss: 17.05860

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.11823

Collected Steps per Second: 11,212.36895
Overall Steps per Second: 9,579.29698

Timestep Collection Time: 4.45954
Timestep Consumption Time: 0.76026
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 5.21980

Cumulative Model Updates: 34,252
Cumulative Timesteps: 571,434,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 571434372...
Checkpoint 571434372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,925.60745
Policy Entropy: 1.02916
Value Function Loss: 18.00872

Mean KL Divergence: 0.02616
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.11229

Collected Steps per Second: 11,161.34019
Overall Steps per Second: 9,694.38948

Timestep Collection Time: 4.48100
Timestep Consumption Time: 0.67806
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.15907

Cumulative Model Updates: 34,255
Cumulative Timesteps: 571,484,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,966.09555
Policy Entropy: 1.02792
Value Function Loss: 18.01306

Mean KL Divergence: 0.03118
SB3 Clip Fraction: 0.16801
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.09747

Collected Steps per Second: 10,652.64675
Overall Steps per Second: 9,160.02679

Timestep Collection Time: 4.69404
Timestep Consumption Time: 0.76489
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 5.45894

Cumulative Model Updates: 34,258
Cumulative Timesteps: 571,534,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 571534390...
Checkpoint 571534390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,909.78809
Policy Entropy: 1.04246
Value Function Loss: 17.95455

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.07961

Collected Steps per Second: 10,833.41310
Overall Steps per Second: 9,285.26598

Timestep Collection Time: 4.61757
Timestep Consumption Time: 0.76989
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.38746

Cumulative Model Updates: 34,261
Cumulative Timesteps: 571,584,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,390.20325
Policy Entropy: 1.05413
Value Function Loss: 17.85916

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.16168
Policy Update Magnitude: 0.03964
Value Function Update Magnitude: 0.07264

Collected Steps per Second: 11,001.94126
Overall Steps per Second: 9,439.48325

Timestep Collection Time: 4.54483
Timestep Consumption Time: 0.75228
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 5.29711

Cumulative Model Updates: 34,264
Cumulative Timesteps: 571,634,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 571634416...
Checkpoint 571634416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407,331.20634
Policy Entropy: 1.02687
Value Function Loss: 17.45410

Mean KL Divergence: 0.02578
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.07742

Collected Steps per Second: 10,893.00792
Overall Steps per Second: 9,335.17637

Timestep Collection Time: 4.59010
Timestep Consumption Time: 0.76598
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.35609

Cumulative Model Updates: 34,267
Cumulative Timesteps: 571,684,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,443.92350
Policy Entropy: 1.04141
Value Function Loss: 17.23964

Mean KL Divergence: 0.02602
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.07834

Collected Steps per Second: 11,013.81136
Overall Steps per Second: 9,587.37418

Timestep Collection Time: 4.54212
Timestep Consumption Time: 0.67579
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.21790

Cumulative Model Updates: 34,270
Cumulative Timesteps: 571,734,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 571734442...
Checkpoint 571734442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,058.41950
Policy Entropy: 1.03305
Value Function Loss: 16.94520

Mean KL Divergence: 0.02607
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.04126
Value Function Update Magnitude: 0.07253

Collected Steps per Second: 10,325.18212
Overall Steps per Second: 8,908.00947

Timestep Collection Time: 4.84330
Timestep Consumption Time: 0.77052
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.61382

Cumulative Model Updates: 34,273
Cumulative Timesteps: 571,784,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,683.04553
Policy Entropy: 1.02354
Value Function Loss: 16.84336

Mean KL Divergence: 0.02773
SB3 Clip Fraction: 0.14956
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.06724

Collected Steps per Second: 11,334.96058
Overall Steps per Second: 9,652.91420

Timestep Collection Time: 4.41131
Timestep Consumption Time: 0.76868
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.17999

Cumulative Model Updates: 34,276
Cumulative Timesteps: 571,834,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 571834452...
Checkpoint 571834452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,532.26356
Policy Entropy: 1.01129
Value Function Loss: 17.27851

Mean KL Divergence: 0.02936
SB3 Clip Fraction: 0.17528
Policy Update Magnitude: 0.03963
Value Function Update Magnitude: 0.05759

Collected Steps per Second: 12,061.15060
Overall Steps per Second: 10,184.89312

Timestep Collection Time: 4.14654
Timestep Consumption Time: 0.76387
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 4.91041

Cumulative Model Updates: 34,279
Cumulative Timesteps: 571,884,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,243.52839
Policy Entropy: 1.02203
Value Function Loss: 17.75489

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.04950

Collected Steps per Second: 11,738.58578
Overall Steps per Second: 9,961.00640

Timestep Collection Time: 4.26167
Timestep Consumption Time: 0.76051
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.02218

Cumulative Model Updates: 34,282
Cumulative Timesteps: 571,934,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 571934490...
Checkpoint 571934490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396,560.73147
Policy Entropy: 1.04308
Value Function Loss: 18.61305

Mean KL Divergence: 0.02549
SB3 Clip Fraction: 0.15793
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.05136

Collected Steps per Second: 12,055.92472
Overall Steps per Second: 10,338.18807

Timestep Collection Time: 4.14833
Timestep Consumption Time: 0.68926
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 4.83760

Cumulative Model Updates: 34,285
Cumulative Timesteps: 571,984,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,705.30098
Policy Entropy: 1.00124
Value Function Loss: 19.13526

Mean KL Divergence: 0.07201
SB3 Clip Fraction: 0.22705
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.05458

Collected Steps per Second: 11,897.01726
Overall Steps per Second: 10,102.39642

Timestep Collection Time: 4.20290
Timestep Consumption Time: 0.74662
PPO Batch Consumption Time: 0.03965
Total Iteration Time: 4.94952

Cumulative Model Updates: 34,288
Cumulative Timesteps: 572,034,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 572034504...
Checkpoint 572034504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,607.97842
Policy Entropy: 1.03792
Value Function Loss: 18.99268

Mean KL Divergence: 0.04657
SB3 Clip Fraction: 0.19004
Policy Update Magnitude: 0.04125
Value Function Update Magnitude: 0.04583

Collected Steps per Second: 11,349.90418
Overall Steps per Second: 9,659.26382

Timestep Collection Time: 4.40620
Timestep Consumption Time: 0.77121
PPO Batch Consumption Time: 0.04000
Total Iteration Time: 5.17741

Cumulative Model Updates: 34,291
Cumulative Timesteps: 572,084,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,213.49923
Policy Entropy: 1.02019
Value Function Loss: 19.08323

Mean KL Divergence: 0.03999
SB3 Clip Fraction: 0.18779
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.04930

Collected Steps per Second: 12,067.77518
Overall Steps per Second: 10,135.10796

Timestep Collection Time: 4.14443
Timestep Consumption Time: 0.79030
PPO Batch Consumption Time: 0.04715
Total Iteration Time: 4.93473

Cumulative Model Updates: 34,294
Cumulative Timesteps: 572,134,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 572134528...
Checkpoint 572134528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,291.17299
Policy Entropy: 1.04754
Value Function Loss: 19.09488

Mean KL Divergence: 0.04197
SB3 Clip Fraction: 0.17015
Policy Update Magnitude: 0.04280
Value Function Update Magnitude: 0.05024

Collected Steps per Second: 11,053.61678
Overall Steps per Second: 9,426.27481

Timestep Collection Time: 4.52431
Timestep Consumption Time: 0.78107
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.30538

Cumulative Model Updates: 34,297
Cumulative Timesteps: 572,184,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,385.06233
Policy Entropy: 1.03258
Value Function Loss: 19.00693

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.04486

Collected Steps per Second: 11,059.30435
Overall Steps per Second: 9,633.82286

Timestep Collection Time: 4.52307
Timestep Consumption Time: 0.66926
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.19233

Cumulative Model Updates: 34,300
Cumulative Timesteps: 572,234,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 572234560...
Checkpoint 572234560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,395.47533
Policy Entropy: 1.03155
Value Function Loss: 18.98459

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.04352

Collected Steps per Second: 11,119.62086
Overall Steps per Second: 9,458.02151

Timestep Collection Time: 4.49746
Timestep Consumption Time: 0.79012
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.28758

Cumulative Model Updates: 34,303
Cumulative Timesteps: 572,284,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,022.11377
Policy Entropy: 1.02644
Value Function Loss: 18.99637

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.04255

Collected Steps per Second: 11,103.52524
Overall Steps per Second: 9,475.92283

Timestep Collection Time: 4.50560
Timestep Consumption Time: 0.77389
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 5.27949

Cumulative Model Updates: 34,306
Cumulative Timesteps: 572,334,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 572334598...
Checkpoint 572334598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,418.55646
Policy Entropy: 1.02104
Value Function Loss: 19.01442

Mean KL Divergence: 0.03738
SB3 Clip Fraction: 0.16509
Policy Update Magnitude: 0.06371
Value Function Update Magnitude: 0.04116

Collected Steps per Second: 10,948.63699
Overall Steps per Second: 9,324.17972

Timestep Collection Time: 4.56678
Timestep Consumption Time: 0.79562
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.36240

Cumulative Model Updates: 34,309
Cumulative Timesteps: 572,384,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,844.83608
Policy Entropy: 1.04746
Value Function Loss: 18.17853

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.15515
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.04358

Collected Steps per Second: 10,952.39964
Overall Steps per Second: 9,355.81823

Timestep Collection Time: 4.56521
Timestep Consumption Time: 0.77906
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 5.34427

Cumulative Model Updates: 34,312
Cumulative Timesteps: 572,434,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 572434598...
Checkpoint 572434598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,940.19370
Policy Entropy: 1.04440
Value Function Loss: 17.85356

Mean KL Divergence: 0.02610
SB3 Clip Fraction: 0.16827
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.06148

Collected Steps per Second: 11,084.38445
Overall Steps per Second: 9,595.44086

Timestep Collection Time: 4.51139
Timestep Consumption Time: 0.70004
PPO Batch Consumption Time: 0.03992
Total Iteration Time: 5.21143

Cumulative Model Updates: 34,315
Cumulative Timesteps: 572,484,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,445.25958
Policy Entropy: 1.02913
Value Function Loss: 17.00015

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.16451
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.06692

Collected Steps per Second: 10,880.28363
Overall Steps per Second: 9,302.16905

Timestep Collection Time: 4.59804
Timestep Consumption Time: 0.78006
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 5.37810

Cumulative Model Updates: 34,318
Cumulative Timesteps: 572,534,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 572534632...
Checkpoint 572534632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,787.82446
Policy Entropy: 1.03290
Value Function Loss: 17.84842

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.14834
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.07105

Collected Steps per Second: 11,020.14132
Overall Steps per Second: 9,619.52387

Timestep Collection Time: 4.53969
Timestep Consumption Time: 0.66099
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.20067

Cumulative Model Updates: 34,321
Cumulative Timesteps: 572,584,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,522.43045
Policy Entropy: 1.04173
Value Function Loss: 17.86553

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.07059

Collected Steps per Second: 11,216.29643
Overall Steps per Second: 9,459.44811

Timestep Collection Time: 4.46012
Timestep Consumption Time: 0.82835
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.28847

Cumulative Model Updates: 34,324
Cumulative Timesteps: 572,634,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 572634686...
Checkpoint 572634686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,556.18250
Policy Entropy: 1.05041
Value Function Loss: 17.69107

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.08065

Collected Steps per Second: 10,725.21227
Overall Steps per Second: 9,249.80370

Timestep Collection Time: 4.66266
Timestep Consumption Time: 0.74373
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 5.40639

Cumulative Model Updates: 34,327
Cumulative Timesteps: 572,684,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,998.82552
Policy Entropy: 1.05099
Value Function Loss: 17.55473

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.09000

Collected Steps per Second: 11,090.94636
Overall Steps per Second: 9,414.10941

Timestep Collection Time: 4.50836
Timestep Consumption Time: 0.80303
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.31139

Cumulative Model Updates: 34,330
Cumulative Timesteps: 572,734,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 572734696...
Checkpoint 572734696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,014.36669
Policy Entropy: 1.03356
Value Function Loss: 17.05193

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.10490

Collected Steps per Second: 10,902.88755
Overall Steps per Second: 9,317.75393

Timestep Collection Time: 4.58649
Timestep Consumption Time: 0.78025
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.36674

Cumulative Model Updates: 34,333
Cumulative Timesteps: 572,784,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,611.51899
Policy Entropy: 1.02876
Value Function Loss: 17.63626

Mean KL Divergence: 0.02422
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.10888

Collected Steps per Second: 11,004.14108
Overall Steps per Second: 9,544.23091

Timestep Collection Time: 4.54447
Timestep Consumption Time: 0.69513
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.23960

Cumulative Model Updates: 34,336
Cumulative Timesteps: 572,834,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 572834710...
Checkpoint 572834710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421,424.80636
Policy Entropy: 1.04258
Value Function Loss: 18.21411

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.10815

Collected Steps per Second: 11,006.62039
Overall Steps per Second: 9,408.41359

Timestep Collection Time: 4.54290
Timestep Consumption Time: 0.77170
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.31460

Cumulative Model Updates: 34,339
Cumulative Timesteps: 572,884,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,466.39541
Policy Entropy: 1.04416
Value Function Loss: 18.35374

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.09496

Collected Steps per Second: 10,561.95645
Overall Steps per Second: 9,062.28362

Timestep Collection Time: 4.73454
Timestep Consumption Time: 0.78350
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.51804

Cumulative Model Updates: 34,342
Cumulative Timesteps: 572,934,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 572934718...
Checkpoint 572934718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,585.36197
Policy Entropy: 1.04932
Value Function Loss: 17.93601

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.08077

Collected Steps per Second: 11,127.96490
Overall Steps per Second: 9,467.30321

Timestep Collection Time: 4.49480
Timestep Consumption Time: 0.78843
PPO Batch Consumption Time: 0.03792
Total Iteration Time: 5.28324

Cumulative Model Updates: 34,345
Cumulative Timesteps: 572,984,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,463.99677
Policy Entropy: 1.03694
Value Function Loss: 16.78571

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.15653
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.06944

Collected Steps per Second: 11,375.57145
Overall Steps per Second: 9,700.11565

Timestep Collection Time: 4.39556
Timestep Consumption Time: 0.75922
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.15478

Cumulative Model Updates: 34,348
Cumulative Timesteps: 573,034,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 573034738...
Checkpoint 573034738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,616.48284
Policy Entropy: 1.03724
Value Function Loss: 17.21538

Mean KL Divergence: 0.02672
SB3 Clip Fraction: 0.15601
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.06037

Collected Steps per Second: 11,322.57378
Overall Steps per Second: 9,867.19025

Timestep Collection Time: 4.41737
Timestep Consumption Time: 0.65155
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.06892

Cumulative Model Updates: 34,351
Cumulative Timesteps: 573,084,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,679.11391
Policy Entropy: 1.04316
Value Function Loss: 16.70338

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.04292
Value Function Update Magnitude: 0.06153

Collected Steps per Second: 11,168.41620
Overall Steps per Second: 9,479.51578

Timestep Collection Time: 4.47709
Timestep Consumption Time: 0.79765
PPO Batch Consumption Time: 0.04440
Total Iteration Time: 5.27474

Cumulative Model Updates: 34,354
Cumulative Timesteps: 573,134,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 573134756...
Checkpoint 573134756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,887.01150
Policy Entropy: 1.04962
Value Function Loss: 17.31069

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.05949

Collected Steps per Second: 11,313.84355
Overall Steps per Second: 9,659.62297

Timestep Collection Time: 4.42025
Timestep Consumption Time: 0.75697
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.17722

Cumulative Model Updates: 34,357
Cumulative Timesteps: 573,184,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,857.54457
Policy Entropy: 1.04888
Value Function Loss: 16.79272

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 10,882.58845
Overall Steps per Second: 9,352.80832

Timestep Collection Time: 4.59688
Timestep Consumption Time: 0.75188
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 5.34877

Cumulative Model Updates: 34,360
Cumulative Timesteps: 573,234,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 573234792...
Checkpoint 573234792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,500.93420
Policy Entropy: 1.05189
Value Function Loss: 17.07070

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.06737

Collected Steps per Second: 11,156.56469
Overall Steps per Second: 9,524.06803

Timestep Collection Time: 4.48167
Timestep Consumption Time: 0.76819
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.24986

Cumulative Model Updates: 34,363
Cumulative Timesteps: 573,284,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,745.35822
Policy Entropy: 1.04842
Value Function Loss: 17.35269

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.15914
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.06712

Collected Steps per Second: 11,179.34990
Overall Steps per Second: 9,716.48960

Timestep Collection Time: 4.47468
Timestep Consumption Time: 0.67368
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.14836

Cumulative Model Updates: 34,366
Cumulative Timesteps: 573,334,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 573334816...
Checkpoint 573334816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,109.83658
Policy Entropy: 1.05529
Value Function Loss: 17.61240

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 11,291.42807
Overall Steps per Second: 9,611.85255

Timestep Collection Time: 4.42920
Timestep Consumption Time: 0.77396
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.20316

Cumulative Model Updates: 34,369
Cumulative Timesteps: 573,384,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,241.39834
Policy Entropy: 1.06323
Value Function Loss: 18.24003

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.07029

Collected Steps per Second: 11,177.60817
Overall Steps per Second: 9,599.59498

Timestep Collection Time: 4.47502
Timestep Consumption Time: 0.73562
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.21064

Cumulative Model Updates: 34,372
Cumulative Timesteps: 573,434,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 573434848...
Checkpoint 573434848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,793.02588
Policy Entropy: 1.06163
Value Function Loss: 17.72747

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.09024

Collected Steps per Second: 11,418.25344
Overall Steps per Second: 9,705.95664

Timestep Collection Time: 4.37948
Timestep Consumption Time: 0.77261
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 5.15209

Cumulative Model Updates: 34,375
Cumulative Timesteps: 573,484,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,577.67709
Policy Entropy: 1.06688
Value Function Loss: 17.26139

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.05783
Value Function Update Magnitude: 0.09051

Collected Steps per Second: 10,637.49579
Overall Steps per Second: 9,146.86822

Timestep Collection Time: 4.70054
Timestep Consumption Time: 0.76603
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.46657

Cumulative Model Updates: 34,378
Cumulative Timesteps: 573,534,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 573534856...
Checkpoint 573534856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,235.67185
Policy Entropy: 1.06477
Value Function Loss: 16.65623

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.07916

Collected Steps per Second: 10,846.85893
Overall Steps per Second: 9,450.69409

Timestep Collection Time: 4.61110
Timestep Consumption Time: 0.68121
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 5.29231

Cumulative Model Updates: 34,381
Cumulative Timesteps: 573,584,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,235.64937
Policy Entropy: 1.06083
Value Function Loss: 16.80713

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.06143
Value Function Update Magnitude: 0.08222

Collected Steps per Second: 11,055.84466
Overall Steps per Second: 9,466.42247

Timestep Collection Time: 4.52376
Timestep Consumption Time: 0.75954
PPO Batch Consumption Time: 0.03911
Total Iteration Time: 5.28331

Cumulative Model Updates: 34,384
Cumulative Timesteps: 573,634,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 573634886...
Checkpoint 573634886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,855.40225
Policy Entropy: 1.06668
Value Function Loss: 17.77446

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.08743

Collected Steps per Second: 10,800.73431
Overall Steps per Second: 9,290.19045

Timestep Collection Time: 4.63117
Timestep Consumption Time: 0.75301
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.38417

Cumulative Model Updates: 34,387
Cumulative Timesteps: 573,684,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,508.07451
Policy Entropy: 1.05611
Value Function Loss: 18.40904

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.07997

Collected Steps per Second: 11,188.35870
Overall Steps per Second: 9,596.67574

Timestep Collection Time: 4.46947
Timestep Consumption Time: 0.74130
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.21076

Cumulative Model Updates: 34,390
Cumulative Timesteps: 573,734,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 573734912...
Checkpoint 573734912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,294.19899
Policy Entropy: 1.05854
Value Function Loss: 18.39293

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.06910
Value Function Update Magnitude: 0.07519

Collected Steps per Second: 10,478.89405
Overall Steps per Second: 9,057.94689

Timestep Collection Time: 4.77150
Timestep Consumption Time: 0.74852
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 5.52001

Cumulative Model Updates: 34,393
Cumulative Timesteps: 573,784,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,606.21770
Policy Entropy: 1.04678
Value Function Loss: 18.58541

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.08857

Collected Steps per Second: 11,033.71436
Overall Steps per Second: 9,590.17946

Timestep Collection Time: 4.53283
Timestep Consumption Time: 0.68229
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.21513

Cumulative Model Updates: 34,396
Cumulative Timesteps: 573,834,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 573834926...
Checkpoint 573834926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,402.16947
Policy Entropy: 1.05410
Value Function Loss: 17.82545

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.08140

Collected Steps per Second: 10,970.27312
Overall Steps per Second: 9,374.82870

Timestep Collection Time: 4.55832
Timestep Consumption Time: 0.77575
PPO Batch Consumption Time: 0.03357
Total Iteration Time: 5.33407

Cumulative Model Updates: 34,399
Cumulative Timesteps: 573,884,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,313.32116
Policy Entropy: 1.05632
Value Function Loss: 18.14961

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.08167

Collected Steps per Second: 11,056.36384
Overall Steps per Second: 9,469.37026

Timestep Collection Time: 4.52301
Timestep Consumption Time: 0.75802
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.28103

Cumulative Model Updates: 34,402
Cumulative Timesteps: 573,934,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 573934940...
Checkpoint 573934940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,607.67659
Policy Entropy: 1.05195
Value Function Loss: 17.25320

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.07353

Collected Steps per Second: 11,054.09458
Overall Steps per Second: 9,450.89131

Timestep Collection Time: 4.52321
Timestep Consumption Time: 0.76730
PPO Batch Consumption Time: 0.04208
Total Iteration Time: 5.29051

Cumulative Model Updates: 34,405
Cumulative Timesteps: 573,984,940

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,244.49399
Policy Entropy: 1.06285
Value Function Loss: 17.45680

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.07600

Collected Steps per Second: 11,228.33276
Overall Steps per Second: 9,640.94684

Timestep Collection Time: 4.45338
Timestep Consumption Time: 0.73325
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 5.18663

Cumulative Model Updates: 34,408
Cumulative Timesteps: 574,034,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 574034944...
Checkpoint 574034944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,671.98966
Policy Entropy: 1.06078
Value Function Loss: 17.58563

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.06701

Collected Steps per Second: 10,576.88081
Overall Steps per Second: 9,202.46076

Timestep Collection Time: 4.72994
Timestep Consumption Time: 0.70643
PPO Batch Consumption Time: 0.03896
Total Iteration Time: 5.43637

Cumulative Model Updates: 34,411
Cumulative Timesteps: 574,084,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,949.35324
Policy Entropy: 1.06826
Value Function Loss: 17.33420

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.06512
Value Function Update Magnitude: 0.07189

Collected Steps per Second: 11,702.24324
Overall Steps per Second: 9,858.21561

Timestep Collection Time: 4.27337
Timestep Consumption Time: 0.79935
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.07272

Cumulative Model Updates: 34,414
Cumulative Timesteps: 574,134,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 574134980...
Checkpoint 574134980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,603.20384
Policy Entropy: 1.06317
Value Function Loss: 17.52249

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.06767
Value Function Update Magnitude: 0.08793

Collected Steps per Second: 12,051.63396
Overall Steps per Second: 10,394.20817

Timestep Collection Time: 4.15064
Timestep Consumption Time: 0.66185
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.81249

Cumulative Model Updates: 34,417
Cumulative Timesteps: 574,185,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551,089.45402
Policy Entropy: 1.06300
Value Function Loss: 16.94002

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.08593

Collected Steps per Second: 12,058.99327
Overall Steps per Second: 10,168.79302

Timestep Collection Time: 4.14628
Timestep Consumption Time: 0.77072
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.91700

Cumulative Model Updates: 34,420
Cumulative Timesteps: 574,235,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 574235002...
Checkpoint 574235002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,883.46949
Policy Entropy: 1.06029
Value Function Loss: 17.35033

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.05993
Value Function Update Magnitude: 0.07482

Collected Steps per Second: 11,789.76886
Overall Steps per Second: 10,035.18697

Timestep Collection Time: 4.24164
Timestep Consumption Time: 0.74162
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 4.98327

Cumulative Model Updates: 34,423
Cumulative Timesteps: 574,285,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,426.89354
Policy Entropy: 1.05297
Value Function Loss: 17.12800

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.07165

Collected Steps per Second: 12,134.66058
Overall Steps per Second: 10,370.14562

Timestep Collection Time: 4.12241
Timestep Consumption Time: 0.70144
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.82385

Cumulative Model Updates: 34,426
Cumulative Timesteps: 574,335,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 574335034...
Checkpoint 574335034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,532.56329
Policy Entropy: 1.07200
Value Function Loss: 17.13047

Mean KL Divergence: 0.02567
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.07752

Collected Steps per Second: 11,472.67300
Overall Steps per Second: 9,715.11536

Timestep Collection Time: 4.35905
Timestep Consumption Time: 0.78859
PPO Batch Consumption Time: 0.03873
Total Iteration Time: 5.14765

Cumulative Model Updates: 34,429
Cumulative Timesteps: 574,385,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,617.55409
Policy Entropy: 1.07310
Value Function Loss: 17.69632

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.08278

Collected Steps per Second: 11,564.89092
Overall Steps per Second: 9,980.67529

Timestep Collection Time: 4.32568
Timestep Consumption Time: 0.68661
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.01229

Cumulative Model Updates: 34,432
Cumulative Timesteps: 574,435,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 574435070...
Checkpoint 574435070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,142.49810
Policy Entropy: 1.06170
Value Function Loss: 18.51786

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.08768

Collected Steps per Second: 11,153.27722
Overall Steps per Second: 9,458.64370

Timestep Collection Time: 4.48586
Timestep Consumption Time: 0.80370
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.28955

Cumulative Model Updates: 34,435
Cumulative Timesteps: 574,485,102

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,653.21317
Policy Entropy: 1.05247
Value Function Loss: 18.84104

Mean KL Divergence: 0.03245
SB3 Clip Fraction: 0.16811
Policy Update Magnitude: 0.04387
Value Function Update Magnitude: 0.10182

Collected Steps per Second: 11,261.30742
Overall Steps per Second: 9,761.07845

Timestep Collection Time: 4.44051
Timestep Consumption Time: 0.68248
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.12300

Cumulative Model Updates: 34,438
Cumulative Timesteps: 574,535,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 574535108...
Checkpoint 574535108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,576.90205
Policy Entropy: 1.08045
Value Function Loss: 18.29876

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.10041

Collected Steps per Second: 11,398.97452
Overall Steps per Second: 9,629.72782

Timestep Collection Time: 4.38899
Timestep Consumption Time: 0.80638
PPO Batch Consumption Time: 0.03401
Total Iteration Time: 5.19537

Cumulative Model Updates: 34,441
Cumulative Timesteps: 574,585,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,173.11033
Policy Entropy: 1.09525
Value Function Loss: 17.48090

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.10045

Collected Steps per Second: 11,293.12794
Overall Steps per Second: 9,620.10767

Timestep Collection Time: 4.42960
Timestep Consumption Time: 0.77035
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.19994

Cumulative Model Updates: 34,444
Cumulative Timesteps: 574,635,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 574635162...
Checkpoint 574635162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,396.65836
Policy Entropy: 1.08141
Value Function Loss: 17.54707

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.10240

Collected Steps per Second: 10,480.84407
Overall Steps per Second: 9,189.07438

Timestep Collection Time: 4.77347
Timestep Consumption Time: 0.67104
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.44451

Cumulative Model Updates: 34,447
Cumulative Timesteps: 574,685,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407,603.28916
Policy Entropy: 1.05855
Value Function Loss: 17.60502

Mean KL Divergence: 0.02862
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.08770

Collected Steps per Second: 11,135.23681
Overall Steps per Second: 9,510.56429

Timestep Collection Time: 4.49276
Timestep Consumption Time: 0.76749
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.26026

Cumulative Model Updates: 34,450
Cumulative Timesteps: 574,735,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 574735220...
Checkpoint 574735220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,247.31560
Policy Entropy: 1.07674
Value Function Loss: 17.56491

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.07394

Collected Steps per Second: 11,018.53190
Overall Steps per Second: 9,407.63430

Timestep Collection Time: 4.53908
Timestep Consumption Time: 0.77724
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 5.31632

Cumulative Model Updates: 34,453
Cumulative Timesteps: 574,785,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,607.30502
Policy Entropy: 1.08281
Value Function Loss: 17.14883

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.14767
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.09266

Collected Steps per Second: 11,121.82738
Overall Steps per Second: 9,513.81383

Timestep Collection Time: 4.49638
Timestep Consumption Time: 0.75997
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.25636

Cumulative Model Updates: 34,456
Cumulative Timesteps: 574,835,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 574835242...
Checkpoint 574835242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364,954.65186
Policy Entropy: 1.07392
Value Function Loss: 17.59702

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.08776

Collected Steps per Second: 11,038.82054
Overall Steps per Second: 9,474.09546

Timestep Collection Time: 4.53128
Timestep Consumption Time: 0.74838
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.27966

Cumulative Model Updates: 34,459
Cumulative Timesteps: 574,885,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,106.00876
Policy Entropy: 1.06071
Value Function Loss: 17.50955

Mean KL Divergence: 0.02947
SB3 Clip Fraction: 0.15141
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.07391

Collected Steps per Second: 10,525.52506
Overall Steps per Second: 9,189.06012

Timestep Collection Time: 4.75112
Timestep Consumption Time: 0.69101
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.44212

Cumulative Model Updates: 34,462
Cumulative Timesteps: 574,935,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 574935270...
Checkpoint 574935270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440,002.46729
Policy Entropy: 1.07199
Value Function Loss: 17.28177

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.06584

Collected Steps per Second: 11,094.94568
Overall Steps per Second: 9,465.23988

Timestep Collection Time: 4.50674
Timestep Consumption Time: 0.77596
PPO Batch Consumption Time: 0.03788
Total Iteration Time: 5.28270

Cumulative Model Updates: 34,465
Cumulative Timesteps: 574,985,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,437.45199
Policy Entropy: 1.08723
Value Function Loss: 17.29471

Mean KL Divergence: 0.02651
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.06464

Collected Steps per Second: 10,792.54456
Overall Steps per Second: 9,265.07843

Timestep Collection Time: 4.63487
Timestep Consumption Time: 0.76412
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.39898

Cumulative Model Updates: 34,468
Cumulative Timesteps: 575,035,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 575035294...
Checkpoint 575035294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,625.71989
Policy Entropy: 1.04831
Value Function Loss: 17.69340

Mean KL Divergence: 0.07827
SB3 Clip Fraction: 0.22305
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.06191

Collected Steps per Second: 11,151.94961
Overall Steps per Second: 9,499.90340

Timestep Collection Time: 4.48406
Timestep Consumption Time: 0.77978
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 5.26384

Cumulative Model Updates: 34,471
Cumulative Timesteps: 575,085,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,887.61632
Policy Entropy: 1.09521
Value Function Loss: 18.23274

Mean KL Divergence: 0.05477
SB3 Clip Fraction: 0.21547
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 10,945.33439
Overall Steps per Second: 9,386.71181

Timestep Collection Time: 4.57053
Timestep Consumption Time: 0.75892
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 5.32945

Cumulative Model Updates: 34,474
Cumulative Timesteps: 575,135,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 575135326...
Checkpoint 575135326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,722.43162
Policy Entropy: 1.06922
Value Function Loss: 17.68229

Mean KL Divergence: 0.06887
SB3 Clip Fraction: 0.22427
Policy Update Magnitude: 0.04141
Value Function Update Magnitude: 0.06205

Collected Steps per Second: 10,900.54554
Overall Steps per Second: 9,525.59624

Timestep Collection Time: 4.58766
Timestep Consumption Time: 0.66219
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.24986

Cumulative Model Updates: 34,477
Cumulative Timesteps: 575,185,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,371.29149
Policy Entropy: 1.09093
Value Function Loss: 17.32994

Mean KL Divergence: 0.04924
SB3 Clip Fraction: 0.19854
Policy Update Magnitude: 0.04207
Value Function Update Magnitude: 0.05496

Collected Steps per Second: 10,383.27798
Overall Steps per Second: 8,880.77227

Timestep Collection Time: 4.81563
Timestep Consumption Time: 0.81474
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 5.63037

Cumulative Model Updates: 34,480
Cumulative Timesteps: 575,235,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 575235336...
Checkpoint 575235336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,801.75011
Policy Entropy: 1.05076
Value Function Loss: 17.01726

Mean KL Divergence: 0.08000
SB3 Clip Fraction: 0.23528
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.05012

Collected Steps per Second: 11,500.02202
Overall Steps per Second: 9,792.38004

Timestep Collection Time: 4.34834
Timestep Consumption Time: 0.75828
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.10662

Cumulative Model Updates: 34,483
Cumulative Timesteps: 575,285,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,782.53672
Policy Entropy: 1.08419
Value Function Loss: 16.52095

Mean KL Divergence: 0.04978
SB3 Clip Fraction: 0.20288
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.05134

Collected Steps per Second: 11,703.04940
Overall Steps per Second: 9,930.37797

Timestep Collection Time: 4.27427
Timestep Consumption Time: 0.76300
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 5.03727

Cumulative Model Updates: 34,486
Cumulative Timesteps: 575,335,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 575335364...
Checkpoint 575335364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453,899.13838
Policy Entropy: 1.05192
Value Function Loss: 17.31845

Mean KL Divergence: 0.07669
SB3 Clip Fraction: 0.22199
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.05882

Collected Steps per Second: 11,291.62353
Overall Steps per Second: 9,644.69784

Timestep Collection Time: 4.42966
Timestep Consumption Time: 0.75641
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.18606

Cumulative Model Updates: 34,489
Cumulative Timesteps: 575,385,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420,862.62320
Policy Entropy: 1.08905
Value Function Loss: 17.31720

Mean KL Divergence: 0.05392
SB3 Clip Fraction: 0.19560
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.06351

Collected Steps per Second: 11,450.70497
Overall Steps per Second: 9,884.18705

Timestep Collection Time: 4.36829
Timestep Consumption Time: 0.69232
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 5.06061

Cumulative Model Updates: 34,492
Cumulative Timesteps: 575,435,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 575435402...
Checkpoint 575435402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,333.52184
Policy Entropy: 1.05732
Value Function Loss: 17.95451

Mean KL Divergence: 0.06356
SB3 Clip Fraction: 0.20992
Policy Update Magnitude: 0.04348
Value Function Update Magnitude: 0.06427

Collected Steps per Second: 11,526.58177
Overall Steps per Second: 9,778.10049

Timestep Collection Time: 4.34006
Timestep Consumption Time: 0.77607
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 5.11613

Cumulative Model Updates: 34,495
Cumulative Timesteps: 575,485,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,489.84354
Policy Entropy: 1.08630
Value Function Loss: 17.00652

Mean KL Divergence: 0.04123
SB3 Clip Fraction: 0.17071
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.05758

Collected Steps per Second: 10,840.77090
Overall Steps per Second: 9,471.38357

Timestep Collection Time: 4.61259
Timestep Consumption Time: 0.66690
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.27948

Cumulative Model Updates: 34,498
Cumulative Timesteps: 575,535,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 575535432...
Checkpoint 575535432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,789.54273
Policy Entropy: 1.04891
Value Function Loss: 16.74942

Mean KL Divergence: 0.06288
SB3 Clip Fraction: 0.22191
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.05609

Collected Steps per Second: 10,900.84660
Overall Steps per Second: 9,242.18516

Timestep Collection Time: 4.58882
Timestep Consumption Time: 0.82354
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.41236

Cumulative Model Updates: 34,501
Cumulative Timesteps: 575,585,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,004.40990
Policy Entropy: 1.07070
Value Function Loss: 16.57956

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.06548

Collected Steps per Second: 11,441.22664
Overall Steps per Second: 9,669.41036

Timestep Collection Time: 4.37051
Timestep Consumption Time: 0.80085
PPO Batch Consumption Time: 0.03977
Total Iteration Time: 5.17136

Cumulative Model Updates: 34,504
Cumulative Timesteps: 575,635,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 575635458...
Checkpoint 575635458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,774.86330
Policy Entropy: 1.07036
Value Function Loss: 17.59407

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.07088
Value Function Update Magnitude: 0.07697

Collected Steps per Second: 11,204.50388
Overall Steps per Second: 9,643.05153

Timestep Collection Time: 4.46463
Timestep Consumption Time: 0.72294
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.18757

Cumulative Model Updates: 34,507
Cumulative Timesteps: 575,685,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,384.13034
Policy Entropy: 1.06684
Value Function Loss: 17.97046

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.06677
Value Function Update Magnitude: 0.10011

Collected Steps per Second: 11,173.38349
Overall Steps per Second: 9,490.44091

Timestep Collection Time: 4.47761
Timestep Consumption Time: 0.79402
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.27162

Cumulative Model Updates: 34,510
Cumulative Timesteps: 575,735,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 575735512...
Checkpoint 575735512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,830.92286
Policy Entropy: 1.07488
Value Function Loss: 18.05745

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.10107

Collected Steps per Second: 10,843.32980
Overall Steps per Second: 9,254.07199

Timestep Collection Time: 4.61279
Timestep Consumption Time: 0.79218
PPO Batch Consumption Time: 0.03896
Total Iteration Time: 5.40497

Cumulative Model Updates: 34,513
Cumulative Timesteps: 575,785,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,084.55723
Policy Entropy: 1.07394
Value Function Loss: 17.60157

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.08761

Collected Steps per Second: 11,196.66551
Overall Steps per Second: 9,575.34382

Timestep Collection Time: 4.46687
Timestep Consumption Time: 0.75634
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.22321

Cumulative Model Updates: 34,516
Cumulative Timesteps: 575,835,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 575835544...
Checkpoint 575835544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354,832.33518
Policy Entropy: 1.07399
Value Function Loss: 17.97537

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.07887

Collected Steps per Second: 11,134.82127
Overall Steps per Second: 9,502.23061

Timestep Collection Time: 4.49114
Timestep Consumption Time: 0.77163
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.26276

Cumulative Model Updates: 34,519
Cumulative Timesteps: 575,885,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,617.85687
Policy Entropy: 1.06765
Value Function Loss: 18.08290

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.07295

Collected Steps per Second: 10,972.15404
Overall Steps per Second: 9,561.15550

Timestep Collection Time: 4.55918
Timestep Consumption Time: 0.67283
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.23200

Cumulative Model Updates: 34,522
Cumulative Timesteps: 575,935,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 575935576...
Checkpoint 575935576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394,254.55596
Policy Entropy: 1.07041
Value Function Loss: 18.57754

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.06377

Collected Steps per Second: 11,099.18831
Overall Steps per Second: 9,503.32950

Timestep Collection Time: 4.50537
Timestep Consumption Time: 0.75657
PPO Batch Consumption Time: 0.03839
Total Iteration Time: 5.26195

Cumulative Model Updates: 34,525
Cumulative Timesteps: 575,985,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,536.72980
Policy Entropy: 1.07738
Value Function Loss: 17.40746

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.05285

Collected Steps per Second: 11,075.45896
Overall Steps per Second: 9,453.24106

Timestep Collection Time: 4.51539
Timestep Consumption Time: 0.77486
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 5.29025

Cumulative Model Updates: 34,528
Cumulative Timesteps: 576,035,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 576035592...
Checkpoint 576035592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,997.45703
Policy Entropy: 1.06582
Value Function Loss: 16.91673

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.04344

Collected Steps per Second: 10,853.35190
Overall Steps per Second: 9,348.49846

Timestep Collection Time: 4.60927
Timestep Consumption Time: 0.74197
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 5.35123

Cumulative Model Updates: 34,531
Cumulative Timesteps: 576,085,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397,940.38255
Policy Entropy: 1.05869
Value Function Loss: 16.42363

Mean KL Divergence: 0.03555
SB3 Clip Fraction: 0.17018
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.04174

Collected Steps per Second: 10,948.58568
Overall Steps per Second: 9,354.90625

Timestep Collection Time: 4.56680
Timestep Consumption Time: 0.77799
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 5.34479

Cumulative Model Updates: 34,534
Cumulative Timesteps: 576,135,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 576135618...
Checkpoint 576135618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,827.25292
Policy Entropy: 1.06528
Value Function Loss: 16.68485

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.04348

Collected Steps per Second: 10,989.12832
Overall Steps per Second: 9,325.17357

Timestep Collection Time: 4.55195
Timestep Consumption Time: 0.81224
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 5.36419

Cumulative Model Updates: 34,537
Cumulative Timesteps: 576,185,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464,027.41948
Policy Entropy: 1.07847
Value Function Loss: 16.93967

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.05147

Collected Steps per Second: 11,019.55882
Overall Steps per Second: 9,251.12671

Timestep Collection Time: 4.53866
Timestep Consumption Time: 0.86760
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.40626

Cumulative Model Updates: 34,540
Cumulative Timesteps: 576,235,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 576235654...
Checkpoint 576235654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,610.96048
Policy Entropy: 1.05179
Value Function Loss: 16.09180

Mean KL Divergence: 0.02608
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.05797

Collected Steps per Second: 10,815.55507
Overall Steps per Second: 9,380.15297

Timestep Collection Time: 4.62556
Timestep Consumption Time: 0.70783
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.33339

Cumulative Model Updates: 34,543
Cumulative Timesteps: 576,285,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,334.09694
Policy Entropy: 1.07241
Value Function Loss: 16.82967

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.05683

Collected Steps per Second: 10,784.45885
Overall Steps per Second: 9,135.91084

Timestep Collection Time: 4.63686
Timestep Consumption Time: 0.83671
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 5.47356

Cumulative Model Updates: 34,546
Cumulative Timesteps: 576,335,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 576335688...
Checkpoint 576335688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,230.65780
Policy Entropy: 1.06750
Value Function Loss: 16.15079

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.06127

Collected Steps per Second: 10,609.12845
Overall Steps per Second: 9,279.95169

Timestep Collection Time: 4.71311
Timestep Consumption Time: 0.67506
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.38817

Cumulative Model Updates: 34,549
Cumulative Timesteps: 576,385,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,451.04054
Policy Entropy: 1.04526
Value Function Loss: 16.40673

Mean KL Divergence: 0.03205
SB3 Clip Fraction: 0.15793
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.05822

Collected Steps per Second: 11,975.15342
Overall Steps per Second: 10,086.49923

Timestep Collection Time: 4.17732
Timestep Consumption Time: 0.78218
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 4.95950

Cumulative Model Updates: 34,552
Cumulative Timesteps: 576,435,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 576435714...
Checkpoint 576435714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447,994.99455
Policy Entropy: 1.04085
Value Function Loss: 15.50858

Mean KL Divergence: 0.02626
SB3 Clip Fraction: 0.15232
Policy Update Magnitude: 0.04360
Value Function Update Magnitude: 0.06053

Collected Steps per Second: 11,904.22325
Overall Steps per Second: 10,068.54721

Timestep Collection Time: 4.20137
Timestep Consumption Time: 0.76598
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 4.96735

Cumulative Model Updates: 34,555
Cumulative Timesteps: 576,485,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,486.11224
Policy Entropy: 1.05283
Value Function Loss: 15.88203

Mean KL Divergence: 0.02391
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.04213
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 11,497.59192
Overall Steps per Second: 9,886.47296

Timestep Collection Time: 4.35082
Timestep Consumption Time: 0.70902
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.05984

Cumulative Model Updates: 34,558
Cumulative Timesteps: 576,535,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 576535752...
Checkpoint 576535752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,520.09586
Policy Entropy: 1.06735
Value Function Loss: 15.90054

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.03790
Value Function Update Magnitude: 0.07259

Collected Steps per Second: 11,904.92117
Overall Steps per Second: 9,946.71813

Timestep Collection Time: 4.20078
Timestep Consumption Time: 0.82701
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.02779

Cumulative Model Updates: 34,561
Cumulative Timesteps: 576,585,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,510.99307
Policy Entropy: 1.06341
Value Function Loss: 16.31854

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.06840

Collected Steps per Second: 11,989.50900
Overall Steps per Second: 10,145.80925

Timestep Collection Time: 4.17215
Timestep Consumption Time: 0.75816
PPO Batch Consumption Time: 0.03907
Total Iteration Time: 4.93031

Cumulative Model Updates: 34,564
Cumulative Timesteps: 576,635,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 576635784...
Checkpoint 576635784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,886.66197
Policy Entropy: 1.06229
Value Function Loss: 15.90384

Mean KL Divergence: 0.02642
SB3 Clip Fraction: 0.15176
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.06476

Collected Steps per Second: 11,911.83527
Overall Steps per Second: 9,994.18541

Timestep Collection Time: 4.19969
Timestep Consumption Time: 0.80582
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.00551

Cumulative Model Updates: 34,567
Cumulative Timesteps: 576,685,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,928.01177
Policy Entropy: 1.06991
Value Function Loss: 15.41946

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.05915

Collected Steps per Second: 11,306.54831
Overall Steps per Second: 9,588.17726

Timestep Collection Time: 4.42381
Timestep Consumption Time: 0.79282
PPO Batch Consumption Time: 0.03713
Total Iteration Time: 5.21663

Cumulative Model Updates: 34,570
Cumulative Timesteps: 576,735,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 576735828...
Checkpoint 576735828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,135.62036
Policy Entropy: 1.07787
Value Function Loss: 14.74296

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.05390

Collected Steps per Second: 11,185.37582
Overall Steps per Second: 9,474.96646

Timestep Collection Time: 4.47048
Timestep Consumption Time: 0.80701
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 5.27749

Cumulative Model Updates: 34,573
Cumulative Timesteps: 576,785,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,414.28965
Policy Entropy: 1.04916
Value Function Loss: 14.78618

Mean KL Divergence: 0.02523
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.06281

Collected Steps per Second: 11,222.78586
Overall Steps per Second: 9,551.23684

Timestep Collection Time: 4.45558
Timestep Consumption Time: 0.77976
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 5.23534

Cumulative Model Updates: 34,576
Cumulative Timesteps: 576,835,836

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 576835836...
Checkpoint 576835836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,478.23262
Policy Entropy: 1.06112
Value Function Loss: 16.06217

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.08983

Collected Steps per Second: 11,109.73833
Overall Steps per Second: 9,625.86184

Timestep Collection Time: 4.50182
Timestep Consumption Time: 0.69398
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.19579

Cumulative Model Updates: 34,579
Cumulative Timesteps: 576,885,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,053.81955
Policy Entropy: 1.05266
Value Function Loss: 16.55506

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 10,751.99116
Overall Steps per Second: 9,115.64604

Timestep Collection Time: 4.65272
Timestep Consumption Time: 0.83521
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 5.48793

Cumulative Model Updates: 34,582
Cumulative Timesteps: 576,935,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 576935876...
Checkpoint 576935876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,645.72492
Policy Entropy: 1.06285
Value Function Loss: 16.08610

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.07497

Collected Steps per Second: 10,594.82922
Overall Steps per Second: 9,140.40405

Timestep Collection Time: 4.72155
Timestep Consumption Time: 0.75129
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.47284

Cumulative Model Updates: 34,585
Cumulative Timesteps: 576,985,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,567.98808
Policy Entropy: 1.04905
Value Function Loss: 15.26459

Mean KL Divergence: 0.02591
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.08898

Collected Steps per Second: 11,178.40827
Overall Steps per Second: 9,532.59815

Timestep Collection Time: 4.47470
Timestep Consumption Time: 0.77256
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.24726

Cumulative Model Updates: 34,588
Cumulative Timesteps: 577,035,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 577035920...
Checkpoint 577035920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,583.76284
Policy Entropy: 1.05256
Value Function Loss: 15.04553

Mean KL Divergence: 0.02627
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 10,983.44800
Overall Steps per Second: 9,387.12947

Timestep Collection Time: 4.55285
Timestep Consumption Time: 0.77423
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.32708

Cumulative Model Updates: 34,591
Cumulative Timesteps: 577,085,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,234.20268
Policy Entropy: 1.06734
Value Function Loss: 16.23697

Mean KL Divergence: 0.02830
SB3 Clip Fraction: 0.16130
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.06930

Collected Steps per Second: 11,102.33825
Overall Steps per Second: 9,591.99732

Timestep Collection Time: 4.50392
Timestep Consumption Time: 0.70918
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.21310

Cumulative Model Updates: 34,594
Cumulative Timesteps: 577,135,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 577135930...
Checkpoint 577135930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,169.94560
Policy Entropy: 1.06833
Value Function Loss: 16.15354

Mean KL Divergence: 0.02758
SB3 Clip Fraction: 0.16201
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.06620

Collected Steps per Second: 11,102.60563
Overall Steps per Second: 9,514.29847

Timestep Collection Time: 4.50507
Timestep Consumption Time: 0.75207
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.25714

Cumulative Model Updates: 34,597
Cumulative Timesteps: 577,185,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,860.60747
Policy Entropy: 1.05667
Value Function Loss: 16.35131

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.08029

Collected Steps per Second: 10,476.37200
Overall Steps per Second: 9,083.08997

Timestep Collection Time: 4.77341
Timestep Consumption Time: 0.73221
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.50562

Cumulative Model Updates: 34,600
Cumulative Timesteps: 577,235,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 577235956...
Checkpoint 577235956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,229.58053
Policy Entropy: 1.05040
Value Function Loss: 15.90766

Mean KL Divergence: 0.03445
SB3 Clip Fraction: 0.17936
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.08824

Collected Steps per Second: 11,063.25864
Overall Steps per Second: 9,404.99221

Timestep Collection Time: 4.52181
Timestep Consumption Time: 0.79728
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.31909

Cumulative Model Updates: 34,603
Cumulative Timesteps: 577,285,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,782.61676
Policy Entropy: 1.06983
Value Function Loss: 16.14086

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.09189

Collected Steps per Second: 10,960.08322
Overall Steps per Second: 9,363.83972

Timestep Collection Time: 4.56438
Timestep Consumption Time: 0.77809
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.34247

Cumulative Model Updates: 34,606
Cumulative Timesteps: 577,336,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 577336008...
Checkpoint 577336008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,737.16492
Policy Entropy: 1.07888
Value Function Loss: 16.98671

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.09786

Collected Steps per Second: 10,809.92397
Overall Steps per Second: 9,296.32634

Timestep Collection Time: 4.62741
Timestep Consumption Time: 0.75342
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.38084

Cumulative Model Updates: 34,609
Cumulative Timesteps: 577,386,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,411.46227
Policy Entropy: 1.05769
Value Function Loss: 16.84039

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.09610

Collected Steps per Second: 10,847.47892
Overall Steps per Second: 9,198.89273

Timestep Collection Time: 4.61047
Timestep Consumption Time: 0.82627
PPO Batch Consumption Time: 0.03807
Total Iteration Time: 5.43674

Cumulative Model Updates: 34,612
Cumulative Timesteps: 577,436,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 577436042...
Checkpoint 577436042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,457.61581
Policy Entropy: 1.04860
Value Function Loss: 16.67641

Mean KL Divergence: 0.03554
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.09102

Collected Steps per Second: 10,784.50850
Overall Steps per Second: 9,185.52062

Timestep Collection Time: 4.63628
Timestep Consumption Time: 0.80707
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 5.44335

Cumulative Model Updates: 34,615
Cumulative Timesteps: 577,486,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,694.99503
Policy Entropy: 1.06286
Value Function Loss: 16.03183

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.08297

Collected Steps per Second: 10,915.53010
Overall Steps per Second: 9,364.96230

Timestep Collection Time: 4.58155
Timestep Consumption Time: 0.75857
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.34012

Cumulative Model Updates: 34,618
Cumulative Timesteps: 577,536,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 577536052...
Checkpoint 577536052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,390.50342
Policy Entropy: 1.07301
Value Function Loss: 16.41639

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.08980

Collected Steps per Second: 11,370.09251
Overall Steps per Second: 9,664.57214

Timestep Collection Time: 4.39891
Timestep Consumption Time: 0.77628
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 5.17519

Cumulative Model Updates: 34,621
Cumulative Timesteps: 577,586,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,447.89237
Policy Entropy: 1.05152
Value Function Loss: 16.72296

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.08086

Collected Steps per Second: 10,692.57132
Overall Steps per Second: 9,240.32339

Timestep Collection Time: 4.67820
Timestep Consumption Time: 0.73525
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 5.41345

Cumulative Model Updates: 34,624
Cumulative Timesteps: 577,636,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 577636090...
Checkpoint 577636090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,453.10019
Policy Entropy: 1.03673
Value Function Loss: 16.04314

Mean KL Divergence: 0.02815
SB3 Clip Fraction: 0.16389
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.08566

Collected Steps per Second: 11,377.22744
Overall Steps per Second: 9,598.07034

Timestep Collection Time: 4.39510
Timestep Consumption Time: 0.81470
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 5.20980

Cumulative Model Updates: 34,627
Cumulative Timesteps: 577,686,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,564.08681
Policy Entropy: 1.03916
Value Function Loss: 15.81474

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.09240

Collected Steps per Second: 11,110.12646
Overall Steps per Second: 9,498.29641

Timestep Collection Time: 4.50130
Timestep Consumption Time: 0.76386
PPO Batch Consumption Time: 0.03943
Total Iteration Time: 5.26515

Cumulative Model Updates: 34,630
Cumulative Timesteps: 577,736,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 577736104...
Checkpoint 577736104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,383.95136
Policy Entropy: 1.05034
Value Function Loss: 15.67872

Mean KL Divergence: 0.02807
SB3 Clip Fraction: 0.16206
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.08490

Collected Steps per Second: 10,997.00241
Overall Steps per Second: 9,425.41912

Timestep Collection Time: 4.54869
Timestep Consumption Time: 0.75844
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.30714

Cumulative Model Updates: 34,633
Cumulative Timesteps: 577,786,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,189.44518
Policy Entropy: 1.01358
Value Function Loss: 16.18755

Mean KL Divergence: 0.08739
SB3 Clip Fraction: 0.22170
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.08810

Collected Steps per Second: 11,284.04161
Overall Steps per Second: 9,659.14102

Timestep Collection Time: 4.43370
Timestep Consumption Time: 0.74585
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 5.17955

Cumulative Model Updates: 34,636
Cumulative Timesteps: 577,836,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 577836156...
Checkpoint 577836156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,583.47189
Policy Entropy: 1.06113
Value Function Loss: 16.20570

Mean KL Divergence: 0.04613
SB3 Clip Fraction: 0.21797
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.07367

Collected Steps per Second: 11,072.69059
Overall Steps per Second: 9,626.42195

Timestep Collection Time: 4.51634
Timestep Consumption Time: 0.67853
PPO Batch Consumption Time: 0.03789
Total Iteration Time: 5.19487

Cumulative Model Updates: 34,639
Cumulative Timesteps: 577,886,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418,317.38425
Policy Entropy: 1.02792
Value Function Loss: 16.65540

Mean KL Divergence: 0.06207
SB3 Clip Fraction: 0.23107
Policy Update Magnitude: 0.04128
Value Function Update Magnitude: 0.06074

Collected Steps per Second: 11,191.93780
Overall Steps per Second: 9,531.69122

Timestep Collection Time: 4.46947
Timestep Consumption Time: 0.77850
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.24797

Cumulative Model Updates: 34,642
Cumulative Timesteps: 577,936,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 577936186...
Checkpoint 577936186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442,350.76533
Policy Entropy: 1.07295
Value Function Loss: 16.43157

Mean KL Divergence: 0.05013
SB3 Clip Fraction: 0.20733
Policy Update Magnitude: 0.04078
Value Function Update Magnitude: 0.05231

Collected Steps per Second: 10,991.30381
Overall Steps per Second: 9,564.25438

Timestep Collection Time: 4.55123
Timestep Consumption Time: 0.67907
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.23031

Cumulative Model Updates: 34,645
Cumulative Timesteps: 577,986,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481,017.39846
Policy Entropy: 1.02828
Value Function Loss: 16.36406

Mean KL Divergence: 0.06640
SB3 Clip Fraction: 0.24773
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.05921

Collected Steps per Second: 11,274.07431
Overall Steps per Second: 9,558.36041

Timestep Collection Time: 4.43637
Timestep Consumption Time: 0.79632
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.23270

Cumulative Model Updates: 34,648
Cumulative Timesteps: 578,036,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 578036226...
Checkpoint 578036226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,822.68668
Policy Entropy: 1.07266
Value Function Loss: 15.74805

Mean KL Divergence: 0.05479
SB3 Clip Fraction: 0.23857
Policy Update Magnitude: 0.03939
Value Function Update Magnitude: 0.05172

Collected Steps per Second: 10,915.19031
Overall Steps per Second: 9,295.66203

Timestep Collection Time: 4.58096
Timestep Consumption Time: 0.79811
PPO Batch Consumption Time: 0.04301
Total Iteration Time: 5.37907

Cumulative Model Updates: 34,651
Cumulative Timesteps: 578,086,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,821.88194
Policy Entropy: 1.04105
Value Function Loss: 15.64051

Mean KL Divergence: 0.07436
SB3 Clip Fraction: 0.24435
Policy Update Magnitude: 0.03823
Value Function Update Magnitude: 0.04905

Collected Steps per Second: 10,841.19357
Overall Steps per Second: 9,450.32160

Timestep Collection Time: 4.61407
Timestep Consumption Time: 0.67909
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.29315

Cumulative Model Updates: 34,654
Cumulative Timesteps: 578,136,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 578136250...
Checkpoint 578136250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,120.81138
Policy Entropy: 1.06461
Value Function Loss: 16.44362

Mean KL Divergence: 0.04655
SB3 Clip Fraction: 0.20966
Policy Update Magnitude: 0.03657
Value Function Update Magnitude: 0.04779

Collected Steps per Second: 11,106.41829
Overall Steps per Second: 9,507.23355

Timestep Collection Time: 4.50262
Timestep Consumption Time: 0.75737
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 5.25999

Cumulative Model Updates: 34,657
Cumulative Timesteps: 578,186,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,688.34815
Policy Entropy: 1.04532
Value Function Loss: 16.11693

Mean KL Divergence: 0.03691
SB3 Clip Fraction: 0.17903
Policy Update Magnitude: 0.03959
Value Function Update Magnitude: 0.04436

Collected Steps per Second: 11,127.45586
Overall Steps per Second: 9,709.77728

Timestep Collection Time: 4.49339
Timestep Consumption Time: 0.65606
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.14945

Cumulative Model Updates: 34,660
Cumulative Timesteps: 578,236,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 578236258...
Checkpoint 578236258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,313.06025
Policy Entropy: 1.05626
Value Function Loss: 16.76967

Mean KL Divergence: 0.03246
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.03994
Value Function Update Magnitude: 0.05167

Collected Steps per Second: 11,383.24763
Overall Steps per Second: 9,738.71704

Timestep Collection Time: 4.39242
Timestep Consumption Time: 0.74173
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.13415

Cumulative Model Updates: 34,663
Cumulative Timesteps: 578,286,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,492.23915
Policy Entropy: 1.05117
Value Function Loss: 16.46954

Mean KL Divergence: 0.02340
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.04139
Value Function Update Magnitude: 0.04604

Collected Steps per Second: 11,158.81012
Overall Steps per Second: 9,472.22877

Timestep Collection Time: 4.48148
Timestep Consumption Time: 0.79795
PPO Batch Consumption Time: 0.04042
Total Iteration Time: 5.27943

Cumulative Model Updates: 34,666
Cumulative Timesteps: 578,336,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 578336266...
Checkpoint 578336266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,369.53331
Policy Entropy: 1.04133
Value Function Loss: 16.93437

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.04443

Collected Steps per Second: 11,160.09343
Overall Steps per Second: 9,490.74327

Timestep Collection Time: 4.48150
Timestep Consumption Time: 0.78826
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.26977

Cumulative Model Updates: 34,669
Cumulative Timesteps: 578,386,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,220.31980
Policy Entropy: 1.03364
Value Function Loss: 16.52129

Mean KL Divergence: 0.02859
SB3 Clip Fraction: 0.15946
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.04301

Collected Steps per Second: 11,034.03853
Overall Steps per Second: 9,401.41192

Timestep Collection Time: 4.53198
Timestep Consumption Time: 0.78701
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.31899

Cumulative Model Updates: 34,672
Cumulative Timesteps: 578,436,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 578436286...
Checkpoint 578436286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396,525.66876
Policy Entropy: 1.04422
Value Function Loss: 16.42872

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.04500
Value Function Update Magnitude: 0.04319

Collected Steps per Second: 10,950.96849
Overall Steps per Second: 9,517.93459

Timestep Collection Time: 4.56855
Timestep Consumption Time: 0.68785
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.25639

Cumulative Model Updates: 34,675
Cumulative Timesteps: 578,486,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,867.30600
Policy Entropy: 1.05658
Value Function Loss: 15.32625

Mean KL Divergence: 0.02733
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.03960

Collected Steps per Second: 10,895.30975
Overall Steps per Second: 9,314.60052

Timestep Collection Time: 4.59207
Timestep Consumption Time: 0.77928
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.37135

Cumulative Model Updates: 34,678
Cumulative Timesteps: 578,536,348

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 578536348...
Checkpoint 578536348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,951.89823
Policy Entropy: 1.05497
Value Function Loss: 14.82836

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.05671

Collected Steps per Second: 10,983.57313
Overall Steps per Second: 9,381.88107

Timestep Collection Time: 4.55335
Timestep Consumption Time: 0.77736
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.33070

Cumulative Model Updates: 34,681
Cumulative Timesteps: 578,586,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,520.49968
Policy Entropy: 1.04064
Value Function Loss: 14.48128

Mean KL Divergence: 0.03327
SB3 Clip Fraction: 0.16829
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.06083

Collected Steps per Second: 10,669.73360
Overall Steps per Second: 9,120.97930

Timestep Collection Time: 4.68690
Timestep Consumption Time: 0.79584
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.48274

Cumulative Model Updates: 34,684
Cumulative Timesteps: 578,636,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 578636368...
Checkpoint 578636368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,321.25206
Policy Entropy: 1.05618
Value Function Loss: 14.44671

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.06022

Collected Steps per Second: 11,484.35086
Overall Steps per Second: 9,758.99098

Timestep Collection Time: 4.35462
Timestep Consumption Time: 0.76988
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.12451

Cumulative Model Updates: 34,687
Cumulative Timesteps: 578,686,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,417.91100
Policy Entropy: 1.04338
Value Function Loss: 15.49008

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.07151

Collected Steps per Second: 12,074.01325
Overall Steps per Second: 10,334.81711

Timestep Collection Time: 4.14129
Timestep Consumption Time: 0.69692
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 4.83821

Cumulative Model Updates: 34,690
Cumulative Timesteps: 578,736,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 578736380...
Checkpoint 578736380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,762.48419
Policy Entropy: 1.03005
Value Function Loss: 15.76309

Mean KL Divergence: 0.03304
SB3 Clip Fraction: 0.16483
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.07863

Collected Steps per Second: 11,752.06199
Overall Steps per Second: 9,958.99000

Timestep Collection Time: 4.25576
Timestep Consumption Time: 0.76623
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.02200

Cumulative Model Updates: 34,693
Cumulative Timesteps: 578,786,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,208.14370
Policy Entropy: 1.04770
Value Function Loss: 16.61593

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.07957

Collected Steps per Second: 11,737.31177
Overall Steps per Second: 9,971.85660

Timestep Collection Time: 4.26094
Timestep Consumption Time: 0.75437
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.01531

Cumulative Model Updates: 34,696
Cumulative Timesteps: 578,836,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 578836406...
Checkpoint 578836406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,601.03784
Policy Entropy: 1.05205
Value Function Loss: 15.73420

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.03955
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 12,020.48813
Overall Steps per Second: 10,300.22527

Timestep Collection Time: 4.16106
Timestep Consumption Time: 0.69495
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.85601

Cumulative Model Updates: 34,699
Cumulative Timesteps: 578,886,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,875.74778
Policy Entropy: 1.04222
Value Function Loss: 15.07513

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.06441

Collected Steps per Second: 11,192.30614
Overall Steps per Second: 9,497.36671

Timestep Collection Time: 4.46950
Timestep Consumption Time: 0.79765
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.26714

Cumulative Model Updates: 34,702
Cumulative Timesteps: 578,936,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 578936448...
Checkpoint 578936448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,100.48215
Policy Entropy: 1.02629
Value Function Loss: 14.80017

Mean KL Divergence: 0.03084
SB3 Clip Fraction: 0.18721
Policy Update Magnitude: 0.03868
Value Function Update Magnitude: 0.06164

Collected Steps per Second: 11,762.42940
Overall Steps per Second: 9,998.28005

Timestep Collection Time: 4.25218
Timestep Consumption Time: 0.75028
PPO Batch Consumption Time: 0.03807
Total Iteration Time: 5.00246

Cumulative Model Updates: 34,705
Cumulative Timesteps: 578,986,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,483.71965
Policy Entropy: 1.04177
Value Function Loss: 15.23171

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.04246
Value Function Update Magnitude: 0.07548

Collected Steps per Second: 11,304.27259
Overall Steps per Second: 9,620.47266

Timestep Collection Time: 4.42558
Timestep Consumption Time: 0.77458
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.20016

Cumulative Model Updates: 34,708
Cumulative Timesteps: 579,036,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 579036492...
Checkpoint 579036492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,924.44117
Policy Entropy: 1.04709
Value Function Loss: 15.27193

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.08519

Collected Steps per Second: 11,000.01891
Overall Steps per Second: 9,312.05504

Timestep Collection Time: 4.54817
Timestep Consumption Time: 0.82443
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 5.37261

Cumulative Model Updates: 34,711
Cumulative Timesteps: 579,086,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,451.64456
Policy Entropy: 1.04432
Value Function Loss: 15.20403

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.07506

Collected Steps per Second: 11,084.27015
Overall Steps per Second: 9,613.13808

Timestep Collection Time: 4.51234
Timestep Consumption Time: 0.69054
PPO Batch Consumption Time: 0.03915
Total Iteration Time: 5.20288

Cumulative Model Updates: 34,714
Cumulative Timesteps: 579,136,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 579136538...
Checkpoint 579136538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389,704.38070
Policy Entropy: 1.04550
Value Function Loss: 15.10725

Mean KL Divergence: 0.02340
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.06728

Collected Steps per Second: 11,375.59139
Overall Steps per Second: 9,700.45407

Timestep Collection Time: 4.39678
Timestep Consumption Time: 0.75926
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 5.15605

Cumulative Model Updates: 34,717
Cumulative Timesteps: 579,186,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,817.44078
Policy Entropy: 1.05161
Value Function Loss: 14.90066

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.06094

Collected Steps per Second: 10,606.95067
Overall Steps per Second: 9,168.73072

Timestep Collection Time: 4.71483
Timestep Consumption Time: 0.73958
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.45441

Cumulative Model Updates: 34,720
Cumulative Timesteps: 579,236,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 579236564...
Checkpoint 579236564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,141.55051
Policy Entropy: 1.04308
Value Function Loss: 15.19947

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.05856
Value Function Update Magnitude: 0.05821

Collected Steps per Second: 10,764.51975
Overall Steps per Second: 9,330.05849

Timestep Collection Time: 4.64730
Timestep Consumption Time: 0.71451
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.36181

Cumulative Model Updates: 34,723
Cumulative Timesteps: 579,286,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,403.13834
Policy Entropy: 1.05303
Value Function Loss: 15.76007

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.06134
Value Function Update Magnitude: 0.05673

Collected Steps per Second: 11,129.40548
Overall Steps per Second: 9,513.69426

Timestep Collection Time: 4.49440
Timestep Consumption Time: 0.76328
PPO Batch Consumption Time: 0.03778
Total Iteration Time: 5.25768

Cumulative Model Updates: 34,726
Cumulative Timesteps: 579,336,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 579336610...
Checkpoint 579336610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,679.09897
Policy Entropy: 1.04711
Value Function Loss: 16.19123

Mean KL Divergence: 0.02227
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.06419
Value Function Update Magnitude: 0.06698

Collected Steps per Second: 10,760.17143
Overall Steps per Second: 9,250.23316

Timestep Collection Time: 4.64751
Timestep Consumption Time: 0.75862
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.40613

Cumulative Model Updates: 34,729
Cumulative Timesteps: 579,386,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,066.99907
Policy Entropy: 1.03864
Value Function Loss: 16.14542

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.07031

Collected Steps per Second: 11,294.60305
Overall Steps per Second: 9,650.39446

Timestep Collection Time: 4.42742
Timestep Consumption Time: 0.75433
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.18176

Cumulative Model Updates: 34,732
Cumulative Timesteps: 579,436,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 579436624...
Checkpoint 579436624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,314.40849
Policy Entropy: 1.05862
Value Function Loss: 15.74981

Mean KL Divergence: 0.02520
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.07526

Collected Steps per Second: 10,815.85948
Overall Steps per Second: 9,245.31277

Timestep Collection Time: 4.62525
Timestep Consumption Time: 0.78571
PPO Batch Consumption Time: 0.03800
Total Iteration Time: 5.41096

Cumulative Model Updates: 34,735
Cumulative Timesteps: 579,486,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,504.08989
Policy Entropy: 1.06135
Value Function Loss: 15.32661

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.15389
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.06549

Collected Steps per Second: 10,954.39672
Overall Steps per Second: 9,500.88165

Timestep Collection Time: 4.56456
Timestep Consumption Time: 0.69832
PPO Batch Consumption Time: 0.03869
Total Iteration Time: 5.26288

Cumulative Model Updates: 34,738
Cumulative Timesteps: 579,536,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 579536652...
Checkpoint 579536652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379,668.02867
Policy Entropy: 1.05560
Value Function Loss: 14.80456

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.06523

Collected Steps per Second: 10,921.36766
Overall Steps per Second: 9,303.77051

Timestep Collection Time: 4.57891
Timestep Consumption Time: 0.79611
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.37503

Cumulative Model Updates: 34,741
Cumulative Timesteps: 579,586,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,973.04807
Policy Entropy: 1.04507
Value Function Loss: 15.49636

Mean KL Divergence: 0.03086
SB3 Clip Fraction: 0.16556
Policy Update Magnitude: 0.04134
Value Function Update Magnitude: 0.06977

Collected Steps per Second: 10,892.48871
Overall Steps per Second: 9,375.41928

Timestep Collection Time: 4.59326
Timestep Consumption Time: 0.74325
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.33651

Cumulative Model Updates: 34,744
Cumulative Timesteps: 579,636,692

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 579636692...
Checkpoint 579636692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,146.68587
Policy Entropy: 1.04967
Value Function Loss: 15.83925

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.06729

Collected Steps per Second: 11,265.26868
Overall Steps per Second: 9,537.41588

Timestep Collection Time: 4.44108
Timestep Consumption Time: 0.80457
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 5.24566

Cumulative Model Updates: 34,747
Cumulative Timesteps: 579,686,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,105.37606
Policy Entropy: 1.04276
Value Function Loss: 16.07644

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.08217

Collected Steps per Second: 10,958.16172
Overall Steps per Second: 9,410.40376

Timestep Collection Time: 4.56281
Timestep Consumption Time: 0.75046
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.31327

Cumulative Model Updates: 34,750
Cumulative Timesteps: 579,736,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 579736722...
Checkpoint 579736722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,545.87509
Policy Entropy: 1.03326
Value Function Loss: 15.09298

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.09066

Collected Steps per Second: 10,609.87700
Overall Steps per Second: 9,278.80406

Timestep Collection Time: 4.71391
Timestep Consumption Time: 0.67622
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.39013

Cumulative Model Updates: 34,753
Cumulative Timesteps: 579,786,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,754.13461
Policy Entropy: 1.03074
Value Function Loss: 14.60619

Mean KL Divergence: 0.02735
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 11,155.66902
Overall Steps per Second: 9,518.85376

Timestep Collection Time: 4.48418
Timestep Consumption Time: 0.77108
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.25525

Cumulative Model Updates: 34,756
Cumulative Timesteps: 579,836,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 579836760...
Checkpoint 579836760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,096.24810
Policy Entropy: 1.05499
Value Function Loss: 14.63271

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07447

Collected Steps per Second: 11,335.28615
Overall Steps per Second: 9,720.99848

Timestep Collection Time: 4.41295
Timestep Consumption Time: 0.73282
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.14577

Cumulative Model Updates: 34,759
Cumulative Timesteps: 579,886,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,689.47087
Policy Entropy: 1.06097
Value Function Loss: 15.13476

Mean KL Divergence: 0.02961
SB3 Clip Fraction: 0.15768
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.06107

Collected Steps per Second: 11,423.59568
Overall Steps per Second: 9,784.23690

Timestep Collection Time: 4.37918
Timestep Consumption Time: 0.73374
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.11292

Cumulative Model Updates: 34,762
Cumulative Timesteps: 579,936,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 579936808...
Checkpoint 579936808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,905.67017
Policy Entropy: 1.04440
Value Function Loss: 15.67146

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.06389

Collected Steps per Second: 11,239.82879
Overall Steps per Second: 9,548.33679

Timestep Collection Time: 4.45060
Timestep Consumption Time: 0.78843
PPO Batch Consumption Time: 0.03847
Total Iteration Time: 5.23903

Cumulative Model Updates: 34,765
Cumulative Timesteps: 579,986,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,060.20098
Policy Entropy: 1.02255
Value Function Loss: 15.60959

Mean KL Divergence: 0.03834
SB3 Clip Fraction: 0.19081
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.06155

Collected Steps per Second: 11,372.15973
Overall Steps per Second: 9,849.89352

Timestep Collection Time: 4.39741
Timestep Consumption Time: 0.67960
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.07701

Cumulative Model Updates: 34,768
Cumulative Timesteps: 580,036,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 580036840...
Checkpoint 580036840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,423.50059
Policy Entropy: 1.04547
Value Function Loss: 14.53534

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.07251

Collected Steps per Second: 10,844.68432
Overall Steps per Second: 9,301.60487

Timestep Collection Time: 4.61092
Timestep Consumption Time: 0.76492
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.37585

Cumulative Model Updates: 34,771
Cumulative Timesteps: 580,086,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,662.04272
Policy Entropy: 1.05267
Value Function Loss: 14.07652

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.06912

Collected Steps per Second: 11,238.42264
Overall Steps per Second: 9,632.30854

Timestep Collection Time: 4.45098
Timestep Consumption Time: 0.74217
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.19315

Cumulative Model Updates: 34,774
Cumulative Timesteps: 580,136,866

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 580136866...
Checkpoint 580136866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,553.28227
Policy Entropy: 1.04975
Value Function Loss: 13.67500

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 11,509.70541
Overall Steps per Second: 9,708.92985

Timestep Collection Time: 4.34694
Timestep Consumption Time: 0.80625
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 5.15319

Cumulative Model Updates: 34,777
Cumulative Timesteps: 580,186,898

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,120.69124
Policy Entropy: 1.05222
Value Function Loss: 13.89191

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.06436
Value Function Update Magnitude: 0.06139

Collected Steps per Second: 11,254.52222
Overall Steps per Second: 9,601.76825

Timestep Collection Time: 4.44532
Timestep Consumption Time: 0.76517
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.21050

Cumulative Model Updates: 34,780
Cumulative Timesteps: 580,236,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 580236928...
Checkpoint 580236928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,230.15361
Policy Entropy: 1.03703
Value Function Loss: 13.84632

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.06552
Value Function Update Magnitude: 0.06398

Collected Steps per Second: 11,076.41112
Overall Steps per Second: 9,613.08274

Timestep Collection Time: 4.51572
Timestep Consumption Time: 0.68739
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.20312

Cumulative Model Updates: 34,783
Cumulative Timesteps: 580,286,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,036.00899
Policy Entropy: 1.05351
Value Function Loss: 14.35753

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.06056

Collected Steps per Second: 11,352.09206
Overall Steps per Second: 9,570.21467

Timestep Collection Time: 4.40447
Timestep Consumption Time: 0.82007
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.22454

Cumulative Model Updates: 34,786
Cumulative Timesteps: 580,336,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 580336946...
Checkpoint 580336946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,460.21151
Policy Entropy: 1.04767
Value Function Loss: 15.44278

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.06671

Collected Steps per Second: 11,311.24245
Overall Steps per Second: 9,682.11799

Timestep Collection Time: 4.42162
Timestep Consumption Time: 0.74399
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.16561

Cumulative Model Updates: 34,789
Cumulative Timesteps: 580,386,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404,015.53629
Policy Entropy: 1.05537
Value Function Loss: 16.34594

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.11103
Policy Update Magnitude: 0.06160
Value Function Update Magnitude: 0.06417

Collected Steps per Second: 11,182.18875
Overall Steps per Second: 9,516.96212

Timestep Collection Time: 4.47193
Timestep Consumption Time: 0.78247
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.25441

Cumulative Model Updates: 34,792
Cumulative Timesteps: 580,436,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 580436966...
Checkpoint 580436966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374,497.72441
Policy Entropy: 1.05021
Value Function Loss: 16.37127

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.08276

Collected Steps per Second: 11,042.49054
Overall Steps per Second: 9,453.91729

Timestep Collection Time: 4.52959
Timestep Consumption Time: 0.76112
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.29072

Cumulative Model Updates: 34,795
Cumulative Timesteps: 580,486,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414,759.18165
Policy Entropy: 1.06573
Value Function Loss: 15.76374

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.10533

Collected Steps per Second: 11,199.23500
Overall Steps per Second: 9,566.84896

Timestep Collection Time: 4.46638
Timestep Consumption Time: 0.76210
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.22847

Cumulative Model Updates: 34,798
Cumulative Timesteps: 580,537,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 580537004...
Checkpoint 580537004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,128.24263
Policy Entropy: 1.06927
Value Function Loss: 15.41887

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.08784

Collected Steps per Second: 11,250.73176
Overall Steps per Second: 9,571.01634

Timestep Collection Time: 4.44611
Timestep Consumption Time: 0.78029
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.22640

Cumulative Model Updates: 34,801
Cumulative Timesteps: 580,587,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398,388.34369
Policy Entropy: 1.06708
Value Function Loss: 15.48248

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.09179

Collected Steps per Second: 10,587.28862
Overall Steps per Second: 9,282.67245

Timestep Collection Time: 4.72378
Timestep Consumption Time: 0.66389
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.38767

Cumulative Model Updates: 34,804
Cumulative Timesteps: 580,637,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 580637038...
Checkpoint 580637038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,500.71598
Policy Entropy: 1.06782
Value Function Loss: 15.05641

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.06509
Value Function Update Magnitude: 0.09322

Collected Steps per Second: 10,812.10642
Overall Steps per Second: 9,290.10832

Timestep Collection Time: 4.62519
Timestep Consumption Time: 0.75774
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 5.38293

Cumulative Model Updates: 34,807
Cumulative Timesteps: 580,687,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,407.54912
Policy Entropy: 1.06991
Value Function Loss: 15.13722

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.09530

Collected Steps per Second: 10,895.51444
Overall Steps per Second: 9,529.05352

Timestep Collection Time: 4.59070
Timestep Consumption Time: 0.65830
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.24900

Cumulative Model Updates: 34,810
Cumulative Timesteps: 580,737,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 580737064...
Checkpoint 580737064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,820.10098
Policy Entropy: 1.06094
Value Function Loss: 15.13544

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.08611

Collected Steps per Second: 11,072.29326
Overall Steps per Second: 9,487.54634

Timestep Collection Time: 4.51668
Timestep Consumption Time: 0.75444
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.27112

Cumulative Model Updates: 34,813
Cumulative Timesteps: 580,787,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387,081.75956
Policy Entropy: 1.08134
Value Function Loss: 15.61243

Mean KL Divergence: 0.02683
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.08573

Collected Steps per Second: 10,842.45380
Overall Steps per Second: 9,294.94518

Timestep Collection Time: 4.61261
Timestep Consumption Time: 0.76795
PPO Batch Consumption Time: 0.03930
Total Iteration Time: 5.38056

Cumulative Model Updates: 34,816
Cumulative Timesteps: 580,837,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 580837086...
Checkpoint 580837086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,753.41013
Policy Entropy: 1.08403
Value Function Loss: 15.62651

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.09269

Collected Steps per Second: 11,112.77195
Overall Steps per Second: 9,455.75648

Timestep Collection Time: 4.50041
Timestep Consumption Time: 0.78865
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.28905

Cumulative Model Updates: 34,819
Cumulative Timesteps: 580,887,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,717.27424
Policy Entropy: 1.08911
Value Function Loss: 15.55460

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.07965

Collected Steps per Second: 10,688.97910
Overall Steps per Second: 9,159.78535

Timestep Collection Time: 4.67772
Timestep Consumption Time: 0.78093
PPO Batch Consumption Time: 0.03843
Total Iteration Time: 5.45864

Cumulative Model Updates: 34,822
Cumulative Timesteps: 580,937,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 580937098...
Checkpoint 580937098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,844.94822
Policy Entropy: 1.07774
Value Function Loss: 14.78580

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.06745

Collected Steps per Second: 11,878.74653
Overall Steps per Second: 10,156.04497

Timestep Collection Time: 4.21038
Timestep Consumption Time: 0.71418
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.92455

Cumulative Model Updates: 34,825
Cumulative Timesteps: 580,987,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,702.86206
Policy Entropy: 1.06385
Value Function Loss: 14.10532

Mean KL Divergence: 0.02976
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.06616

Collected Steps per Second: 12,154.57893
Overall Steps per Second: 10,167.92319

Timestep Collection Time: 4.11532
Timestep Consumption Time: 0.80407
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 4.91939

Cumulative Model Updates: 34,828
Cumulative Timesteps: 581,037,132

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 581037132...
Checkpoint 581037132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,023.31451
Policy Entropy: 1.08903
Value Function Loss: 13.76926

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.06347

Collected Steps per Second: 11,887.96784
Overall Steps per Second: 10,251.67949

Timestep Collection Time: 4.20812
Timestep Consumption Time: 0.67167
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.87979

Cumulative Model Updates: 34,831
Cumulative Timesteps: 581,087,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290,626.03764
Policy Entropy: 1.10048
Value Function Loss: 14.53978

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.07021

Collected Steps per Second: 11,957.65059
Overall Steps per Second: 10,067.32848

Timestep Collection Time: 4.18142
Timestep Consumption Time: 0.78514
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.96656

Cumulative Model Updates: 34,834
Cumulative Timesteps: 581,137,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 581137158...
Checkpoint 581137158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,770.01287
Policy Entropy: 1.08004
Value Function Loss: 14.35214

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.07226

Collected Steps per Second: 11,808.61256
Overall Steps per Second: 9,997.00817

Timestep Collection Time: 4.23572
Timestep Consumption Time: 0.76757
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.00330

Cumulative Model Updates: 34,837
Cumulative Timesteps: 581,187,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,663.58323
Policy Entropy: 1.06826
Value Function Loss: 14.85383

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.06859

Collected Steps per Second: 11,330.41561
Overall Steps per Second: 9,800.02722

Timestep Collection Time: 4.41520
Timestep Consumption Time: 0.68948
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 5.10468

Cumulative Model Updates: 34,840
Cumulative Timesteps: 581,237,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 581237202...
Checkpoint 581237202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369,307.51786
Policy Entropy: 1.07898
Value Function Loss: 14.90208

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.06425

Collected Steps per Second: 11,369.20874
Overall Steps per Second: 9,679.99887

Timestep Collection Time: 4.39995
Timestep Consumption Time: 0.76781
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 5.16777

Cumulative Model Updates: 34,843
Cumulative Timesteps: 581,287,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,533.55871
Policy Entropy: 1.09528
Value Function Loss: 15.54807

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.03900
Value Function Update Magnitude: 0.08052

Collected Steps per Second: 11,309.30992
Overall Steps per Second: 9,661.91955

Timestep Collection Time: 4.42290
Timestep Consumption Time: 0.75412
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.17703

Cumulative Model Updates: 34,846
Cumulative Timesteps: 581,337,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 581337246...
Checkpoint 581337246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,409.14748
Policy Entropy: 1.06295
Value Function Loss: 15.18912

Mean KL Divergence: 0.03672
SB3 Clip Fraction: 0.17233
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.09006

Collected Steps per Second: 11,428.17500
Overall Steps per Second: 9,671.70506

Timestep Collection Time: 4.37620
Timestep Consumption Time: 0.79476
PPO Batch Consumption Time: 0.04034
Total Iteration Time: 5.17096

Cumulative Model Updates: 34,849
Cumulative Timesteps: 581,387,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,892.42471
Policy Entropy: 1.07312
Value Function Loss: 15.17310

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.08715

Collected Steps per Second: 11,014.51467
Overall Steps per Second: 9,459.67396

Timestep Collection Time: 4.54074
Timestep Consumption Time: 0.74634
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.28707

Cumulative Model Updates: 34,852
Cumulative Timesteps: 581,437,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 581437272...
Checkpoint 581437272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,287.87184
Policy Entropy: 1.07132
Value Function Loss: 15.54817

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.04235
Value Function Update Magnitude: 0.07876

Collected Steps per Second: 11,143.73414
Overall Steps per Second: 9,576.14394

Timestep Collection Time: 4.48916
Timestep Consumption Time: 0.73486
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.22402

Cumulative Model Updates: 34,855
Cumulative Timesteps: 581,487,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,111.33665
Policy Entropy: 1.05306
Value Function Loss: 14.82398

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.04474
Value Function Update Magnitude: 0.08838

Collected Steps per Second: 10,811.58505
Overall Steps per Second: 9,281.06641

Timestep Collection Time: 4.62596
Timestep Consumption Time: 0.76286
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.38882

Cumulative Model Updates: 34,858
Cumulative Timesteps: 581,537,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 581537312...
Checkpoint 581537312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,591.10131
Policy Entropy: 1.04866
Value Function Loss: 13.85597

Mean KL Divergence: 0.03014
SB3 Clip Fraction: 0.17247
Policy Update Magnitude: 0.04115
Value Function Update Magnitude: 0.09200

Collected Steps per Second: 10,825.92142
Overall Steps per Second: 9,311.81629

Timestep Collection Time: 4.61891
Timestep Consumption Time: 0.75104
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.36995

Cumulative Model Updates: 34,861
Cumulative Timesteps: 581,587,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,397.45169
Policy Entropy: 1.06191
Value Function Loss: 13.22327

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.08409

Collected Steps per Second: 11,233.75397
Overall Steps per Second: 9,570.06152

Timestep Collection Time: 4.45336
Timestep Consumption Time: 0.77419
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.22755

Cumulative Model Updates: 34,864
Cumulative Timesteps: 581,637,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 581637344...
Checkpoint 581637344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,944.75495
Policy Entropy: 1.07249
Value Function Loss: 12.72340

Mean KL Divergence: 0.02561
SB3 Clip Fraction: 0.16445
Policy Update Magnitude: 0.03987
Value Function Update Magnitude: 0.06829

Collected Steps per Second: 11,039.53559
Overall Steps per Second: 9,505.03926

Timestep Collection Time: 4.52990
Timestep Consumption Time: 0.73131
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.26121

Cumulative Model Updates: 34,867
Cumulative Timesteps: 581,687,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,911.17619
Policy Entropy: 1.05486
Value Function Loss: 12.74663

Mean KL Divergence: 0.02566
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.06403

Collected Steps per Second: 11,132.14408
Overall Steps per Second: 9,657.65065

Timestep Collection Time: 4.49258
Timestep Consumption Time: 0.68591
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.17849

Cumulative Model Updates: 34,870
Cumulative Timesteps: 581,737,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 581737364...
Checkpoint 581737364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425,619.67059
Policy Entropy: 1.06416
Value Function Loss: 13.09629

Mean KL Divergence: 0.02926
SB3 Clip Fraction: 0.16384
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.06274

Collected Steps per Second: 10,842.62762
Overall Steps per Second: 9,322.16508

Timestep Collection Time: 4.61235
Timestep Consumption Time: 0.75228
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.36463

Cumulative Model Updates: 34,873
Cumulative Timesteps: 581,787,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,444.10660
Policy Entropy: 1.06381
Value Function Loss: 13.94011

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.04200
Value Function Update Magnitude: 0.07501

Collected Steps per Second: 10,883.83399
Overall Steps per Second: 9,353.42456

Timestep Collection Time: 4.59562
Timestep Consumption Time: 0.75194
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.34756

Cumulative Model Updates: 34,876
Cumulative Timesteps: 581,837,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 581837392...
Checkpoint 581837392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,832.70073
Policy Entropy: 1.05816
Value Function Loss: 14.58650

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.06715

Collected Steps per Second: 11,023.85351
Overall Steps per Second: 9,378.31702

Timestep Collection Time: 4.53598
Timestep Consumption Time: 0.79589
PPO Batch Consumption Time: 0.03890
Total Iteration Time: 5.33187

Cumulative Model Updates: 34,879
Cumulative Timesteps: 581,887,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,990.72607
Policy Entropy: 1.03410
Value Function Loss: 13.66188

Mean KL Divergence: 0.03730
SB3 Clip Fraction: 0.18003
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.06516

Collected Steps per Second: 11,131.70650
Overall Steps per Second: 9,522.66894

Timestep Collection Time: 4.49221
Timestep Consumption Time: 0.75905
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.25126

Cumulative Model Updates: 34,882
Cumulative Timesteps: 581,937,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 581937402...
Checkpoint 581937402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,245.58463
Policy Entropy: 1.06014
Value Function Loss: 13.75800

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.06291

Collected Steps per Second: 10,841.78748
Overall Steps per Second: 9,399.98533

Timestep Collection Time: 4.61474
Timestep Consumption Time: 0.70782
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.32256

Cumulative Model Updates: 34,885
Cumulative Timesteps: 581,987,434

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,508.72512
Policy Entropy: 1.06088
Value Function Loss: 13.61090

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.06590

Collected Steps per Second: 11,061.21211
Overall Steps per Second: 9,451.10737

Timestep Collection Time: 4.52084
Timestep Consumption Time: 0.77018
PPO Batch Consumption Time: 0.03923
Total Iteration Time: 5.29102

Cumulative Model Updates: 34,888
Cumulative Timesteps: 582,037,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 582037440...
Checkpoint 582037440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,694.48539
Policy Entropy: 1.04957
Value Function Loss: 14.27385

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 10,672.59205
Overall Steps per Second: 9,103.41817

Timestep Collection Time: 4.68565
Timestep Consumption Time: 0.80767
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 5.49332

Cumulative Model Updates: 34,891
Cumulative Timesteps: 582,087,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,376.80363
Policy Entropy: 1.03151
Value Function Loss: 14.42347

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.08230

Collected Steps per Second: 11,624.19619
Overall Steps per Second: 9,870.11056

Timestep Collection Time: 4.30361
Timestep Consumption Time: 0.76482
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.06843

Cumulative Model Updates: 34,894
Cumulative Timesteps: 582,137,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 582137474...
Checkpoint 582137474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,893.61191
Policy Entropy: 1.04384
Value Function Loss: 13.80792

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.04211
Value Function Update Magnitude: 0.06938

Collected Steps per Second: 11,463.17762
Overall Steps per Second: 9,691.70621

Timestep Collection Time: 4.36371
Timestep Consumption Time: 0.79761
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.16132

Cumulative Model Updates: 34,897
Cumulative Timesteps: 582,187,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,696.92965
Policy Entropy: 1.05468
Value Function Loss: 14.08412

Mean KL Divergence: 0.02813
SB3 Clip Fraction: 0.15565
Policy Update Magnitude: 0.03905
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 11,250.90172
Overall Steps per Second: 9,671.00480

Timestep Collection Time: 4.44427
Timestep Consumption Time: 0.72603
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.17030

Cumulative Model Updates: 34,900
Cumulative Timesteps: 582,237,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 582237498...
Checkpoint 582237498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,173.38113
Policy Entropy: 1.03067
Value Function Loss: 13.27721

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.15559
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.06189

Collected Steps per Second: 11,307.50113
Overall Steps per Second: 9,619.67055

Timestep Collection Time: 4.42432
Timestep Consumption Time: 0.77627
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.20059

Cumulative Model Updates: 34,903
Cumulative Timesteps: 582,287,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,544.41682
Policy Entropy: 1.04333
Value Function Loss: 13.41302

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.06509

Collected Steps per Second: 11,660.81019
Overall Steps per Second: 9,934.85785

Timestep Collection Time: 4.28872
Timestep Consumption Time: 0.74507
PPO Batch Consumption Time: 0.03856
Total Iteration Time: 5.03379

Cumulative Model Updates: 34,906
Cumulative Timesteps: 582,337,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 582337536...
Checkpoint 582337536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,947.29542
Policy Entropy: 1.04230
Value Function Loss: 13.16591

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.07104

Collected Steps per Second: 11,176.80216
Overall Steps per Second: 9,584.96603

Timestep Collection Time: 4.47570
Timestep Consumption Time: 0.74331
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.21901

Cumulative Model Updates: 34,909
Cumulative Timesteps: 582,387,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,810.99892
Policy Entropy: 1.05880
Value Function Loss: 13.97709

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.17908
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.06296

Collected Steps per Second: 11,567.41288
Overall Steps per Second: 9,782.00615

Timestep Collection Time: 4.32508
Timestep Consumption Time: 0.78941
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.11449

Cumulative Model Updates: 34,912
Cumulative Timesteps: 582,437,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 582437590...
Checkpoint 582437590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,059.48251
Policy Entropy: 1.03993
Value Function Loss: 13.72951

Mean KL Divergence: 0.03890
SB3 Clip Fraction: 0.18907
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.05862

Collected Steps per Second: 11,340.90848
Overall Steps per Second: 9,839.85914

Timestep Collection Time: 4.41058
Timestep Consumption Time: 0.67282
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.08341

Cumulative Model Updates: 34,915
Cumulative Timesteps: 582,487,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,120.09909
Policy Entropy: 1.07320
Value Function Loss: 13.59998

Mean KL Divergence: 0.03691
SB3 Clip Fraction: 0.17856
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.06636

Collected Steps per Second: 10,993.14647
Overall Steps per Second: 9,389.65391

Timestep Collection Time: 4.54974
Timestep Consumption Time: 0.77697
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.32671

Cumulative Model Updates: 34,918
Cumulative Timesteps: 582,537,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 582537626...
Checkpoint 582537626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,603.50150
Policy Entropy: 1.07670
Value Function Loss: 12.73253

Mean KL Divergence: 0.02968
SB3 Clip Fraction: 0.15887
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.06189

Collected Steps per Second: 10,956.96308
Overall Steps per Second: 9,519.82829

Timestep Collection Time: 4.56586
Timestep Consumption Time: 0.68927
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.25514

Cumulative Model Updates: 34,921
Cumulative Timesteps: 582,587,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,614.94134
Policy Entropy: 1.06175
Value Function Loss: 12.89100

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.05944

Collected Steps per Second: 11,219.98711
Overall Steps per Second: 9,507.39273

Timestep Collection Time: 4.45865
Timestep Consumption Time: 0.80315
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.26180

Cumulative Model Updates: 34,924
Cumulative Timesteps: 582,637,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 582637680...
Checkpoint 582637680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,380.95089
Policy Entropy: 1.04869
Value Function Loss: 12.14364

Mean KL Divergence: 0.03457
SB3 Clip Fraction: 0.17335
Policy Update Magnitude: 0.04045
Value Function Update Magnitude: 0.05439

Collected Steps per Second: 11,197.15340
Overall Steps per Second: 9,713.32804

Timestep Collection Time: 4.46596
Timestep Consumption Time: 0.68223
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.14818

Cumulative Model Updates: 34,927
Cumulative Timesteps: 582,687,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,084.17576
Policy Entropy: 1.06252
Value Function Loss: 12.35351

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.06395

Collected Steps per Second: 10,912.23077
Overall Steps per Second: 9,326.96199

Timestep Collection Time: 4.58330
Timestep Consumption Time: 0.77901
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.36230

Cumulative Model Updates: 34,930
Cumulative Timesteps: 582,737,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 582737700...
Checkpoint 582737700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,304.75903
Policy Entropy: 1.06981
Value Function Loss: 12.75451

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.06382

Collected Steps per Second: 10,897.88901
Overall Steps per Second: 9,402.16845

Timestep Collection Time: 4.58951
Timestep Consumption Time: 0.73011
PPO Batch Consumption Time: 0.03897
Total Iteration Time: 5.31962

Cumulative Model Updates: 34,933
Cumulative Timesteps: 582,787,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,813.61461
Policy Entropy: 1.05799
Value Function Loss: 13.44383

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.14558
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.06885

Collected Steps per Second: 11,011.56042
Overall Steps per Second: 9,603.40159

Timestep Collection Time: 4.54250
Timestep Consumption Time: 0.66607
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.20857

Cumulative Model Updates: 34,936
Cumulative Timesteps: 582,837,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 582837736...
Checkpoint 582837736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,841.98456
Policy Entropy: 1.04010
Value Function Loss: 13.79483

Mean KL Divergence: 0.03509
SB3 Clip Fraction: 0.16549
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.07069

Collected Steps per Second: 11,009.95346
Overall Steps per Second: 9,403.50797

Timestep Collection Time: 4.54316
Timestep Consumption Time: 0.77613
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.31929

Cumulative Model Updates: 34,939
Cumulative Timesteps: 582,887,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,470.37976
Policy Entropy: 1.06061
Value Function Loss: 13.11942

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.06279

Collected Steps per Second: 10,667.65266
Overall Steps per Second: 9,333.14294

Timestep Collection Time: 4.68969
Timestep Consumption Time: 0.67056
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.36025

Cumulative Model Updates: 34,942
Cumulative Timesteps: 582,937,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 582937784...
Checkpoint 582937784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,935.15824
Policy Entropy: 1.07010
Value Function Loss: 13.57908

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.05551

Collected Steps per Second: 10,946.76203
Overall Steps per Second: 9,328.34011

Timestep Collection Time: 4.56793
Timestep Consumption Time: 0.79251
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.36044

Cumulative Model Updates: 34,945
Cumulative Timesteps: 582,987,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,688.54714
Policy Entropy: 1.05591
Value Function Loss: 13.18564

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.04386
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 10,772.11942
Overall Steps per Second: 9,273.36427

Timestep Collection Time: 4.64273
Timestep Consumption Time: 0.75035
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.39308

Cumulative Model Updates: 34,948
Cumulative Timesteps: 583,037,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 583037800...
Checkpoint 583037800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575,211.37883
Policy Entropy: 1.04177
Value Function Loss: 13.86942

Mean KL Divergence: 0.02825
SB3 Clip Fraction: 0.16491
Policy Update Magnitude: 0.04416
Value Function Update Magnitude: 0.06479

Collected Steps per Second: 11,149.58012
Overall Steps per Second: 9,485.85454

Timestep Collection Time: 4.48537
Timestep Consumption Time: 0.78669
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.27206

Cumulative Model Updates: 34,951
Cumulative Timesteps: 583,087,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445,190.19057
Policy Entropy: 1.06228
Value Function Loss: 12.79724

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.04387
Value Function Update Magnitude: 0.06364

Collected Steps per Second: 10,977.63496
Overall Steps per Second: 9,319.31185

Timestep Collection Time: 4.55672
Timestep Consumption Time: 0.81084
PPO Batch Consumption Time: 0.04161
Total Iteration Time: 5.36756

Cumulative Model Updates: 34,954
Cumulative Timesteps: 583,137,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 583137832...
Checkpoint 583137832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,142.23049
Policy Entropy: 1.07286
Value Function Loss: 13.07593

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.14958
Policy Update Magnitude: 0.04144
Value Function Update Magnitude: 0.06838

Collected Steps per Second: 10,835.00152
Overall Steps per Second: 9,409.60424

Timestep Collection Time: 4.61634
Timestep Consumption Time: 0.69930
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.31563

Cumulative Model Updates: 34,957
Cumulative Timesteps: 583,187,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408,918.68084
Policy Entropy: 1.06156
Value Function Loss: 13.61637

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.04268
Value Function Update Magnitude: 0.06679

Collected Steps per Second: 10,432.29721
Overall Steps per Second: 8,989.21871

Timestep Collection Time: 4.79377
Timestep Consumption Time: 0.76956
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.56333

Cumulative Model Updates: 34,960
Cumulative Timesteps: 583,237,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 583237860...
Checkpoint 583237860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,357.11965
Policy Entropy: 1.06685
Value Function Loss: 13.70005

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.04102
Value Function Update Magnitude: 0.06600

Collected Steps per Second: 11,913.39900
Overall Steps per Second: 10,072.50982

Timestep Collection Time: 4.19729
Timestep Consumption Time: 0.76711
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 4.96440

Cumulative Model Updates: 34,963
Cumulative Timesteps: 583,287,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,837.98874
Policy Entropy: 1.07914
Value Function Loss: 14.20713

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.04294
Value Function Update Magnitude: 0.06671

Collected Steps per Second: 12,293.31456
Overall Steps per Second: 10,374.56374

Timestep Collection Time: 4.06774
Timestep Consumption Time: 0.75232
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 4.82006

Cumulative Model Updates: 34,966
Cumulative Timesteps: 583,337,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 583337870...
Checkpoint 583337870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,221.27703
Policy Entropy: 1.07121
Value Function Loss: 13.60396

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.05961

Collected Steps per Second: 11,655.30381
Overall Steps per Second: 9,824.28820

Timestep Collection Time: 4.29247
Timestep Consumption Time: 0.80001
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.09248

Cumulative Model Updates: 34,969
Cumulative Timesteps: 583,387,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,857.16383
Policy Entropy: 1.08302
Value Function Loss: 13.90350

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.15698
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.06180

Collected Steps per Second: 11,965.15050
Overall Steps per Second: 10,022.05120

Timestep Collection Time: 4.18031
Timestep Consumption Time: 0.81049
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 4.99079

Cumulative Model Updates: 34,972
Cumulative Timesteps: 583,437,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 583437918...
Checkpoint 583437918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,413.33994
Policy Entropy: 1.05421
Value Function Loss: 14.10824

Mean KL Divergence: 0.03067
SB3 Clip Fraction: 0.16556
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.05783

Collected Steps per Second: 11,980.76677
Overall Steps per Second: 9,995.07480

Timestep Collection Time: 4.17486
Timestep Consumption Time: 0.82941
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.00426

Cumulative Model Updates: 34,975
Cumulative Timesteps: 583,487,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,123.21659
Policy Entropy: 1.08063
Value Function Loss: 13.85065

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.04443
Value Function Update Magnitude: 0.06391

Collected Steps per Second: 11,951.28367
Overall Steps per Second: 10,305.01315

Timestep Collection Time: 4.18616
Timestep Consumption Time: 0.66876
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.85492

Cumulative Model Updates: 34,978
Cumulative Timesteps: 583,537,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 583537966...
Checkpoint 583537966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,590.60765
Policy Entropy: 1.08565
Value Function Loss: 14.22620

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.06140

Collected Steps per Second: 11,113.65665
Overall Steps per Second: 9,448.04004

Timestep Collection Time: 4.50113
Timestep Consumption Time: 0.79351
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.29464

Cumulative Model Updates: 34,981
Cumulative Timesteps: 583,587,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,217.08268
Policy Entropy: 1.06728
Value Function Loss: 13.11641

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.05583

Collected Steps per Second: 11,124.20987
Overall Steps per Second: 9,652.00980

Timestep Collection Time: 4.49542
Timestep Consumption Time: 0.68568
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.18110

Cumulative Model Updates: 34,984
Cumulative Timesteps: 583,637,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 583637998...
Checkpoint 583637998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,804.11591
Policy Entropy: 1.05757
Value Function Loss: 13.46340

Mean KL Divergence: 0.03278
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.04088
Value Function Update Magnitude: 0.05560

Collected Steps per Second: 11,366.70036
Overall Steps per Second: 9,589.09282

Timestep Collection Time: 4.39934
Timestep Consumption Time: 0.81554
PPO Batch Consumption Time: 0.03966
Total Iteration Time: 5.21488

Cumulative Model Updates: 34,987
Cumulative Timesteps: 583,688,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,375.42137
Policy Entropy: 1.07287
Value Function Loss: 14.11345

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.04177
Value Function Update Magnitude: 0.06254

Collected Steps per Second: 11,198.64185
Overall Steps per Second: 9,567.78411

Timestep Collection Time: 4.46572
Timestep Consumption Time: 0.76120
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.22692

Cumulative Model Updates: 34,990
Cumulative Timesteps: 583,738,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 583738014...
Checkpoint 583738014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,574.80173
Policy Entropy: 1.07966
Value Function Loss: 14.88146

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.06014

Collected Steps per Second: 11,060.03678
Overall Steps per Second: 9,432.16194

Timestep Collection Time: 4.52295
Timestep Consumption Time: 0.78061
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.30356

Cumulative Model Updates: 34,993
Cumulative Timesteps: 583,788,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,651.99019
Policy Entropy: 1.06457
Value Function Loss: 15.01861

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.07201

Collected Steps per Second: 11,095.64738
Overall Steps per Second: 9,543.74682

Timestep Collection Time: 4.50825
Timestep Consumption Time: 0.73308
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.24134

Cumulative Model Updates: 34,996
Cumulative Timesteps: 583,838,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 583838060...
Checkpoint 583838060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,382.78990
Policy Entropy: 1.04818
Value Function Loss: 14.19780

Mean KL Divergence: 0.03642
SB3 Clip Fraction: 0.16738
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.06778

Collected Steps per Second: 10,814.62173
Overall Steps per Second: 9,433.45379

Timestep Collection Time: 4.62540
Timestep Consumption Time: 0.67721
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.30262

Cumulative Model Updates: 34,999
Cumulative Timesteps: 583,888,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,856.69748
Policy Entropy: 1.05926
Value Function Loss: 14.28861

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.06956

Collected Steps per Second: 11,098.34928
Overall Steps per Second: 9,505.20652

Timestep Collection Time: 4.50553
Timestep Consumption Time: 0.75516
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.26070

Cumulative Model Updates: 35,002
Cumulative Timesteps: 583,938,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 583938086...
Checkpoint 583938086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,226.84598
Policy Entropy: 1.06109
Value Function Loss: 14.50403

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.06861

Collected Steps per Second: 10,948.59586
Overall Steps per Second: 9,385.77322

Timestep Collection Time: 4.56844
Timestep Consumption Time: 0.76069
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.32913

Cumulative Model Updates: 35,005
Cumulative Timesteps: 583,988,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,684.85496
Policy Entropy: 1.05803
Value Function Loss: 14.94381

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.06086

Collected Steps per Second: 11,122.54609
Overall Steps per Second: 9,492.78404

Timestep Collection Time: 4.49663
Timestep Consumption Time: 0.77200
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.26863

Cumulative Model Updates: 35,008
Cumulative Timesteps: 584,038,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 584038118...
Checkpoint 584038118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,304.01545
Policy Entropy: 1.05789
Value Function Loss: 14.60561

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.06551

Collected Steps per Second: 10,665.83128
Overall Steps per Second: 9,180.57646

Timestep Collection Time: 4.68862
Timestep Consumption Time: 0.75854
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.44715

Cumulative Model Updates: 35,011
Cumulative Timesteps: 584,088,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,068.22962
Policy Entropy: 1.07170
Value Function Loss: 13.87683

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.06254

Collected Steps per Second: 10,753.61500
Overall Steps per Second: 9,355.36913

Timestep Collection Time: 4.65109
Timestep Consumption Time: 0.69515
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.34623

Cumulative Model Updates: 35,014
Cumulative Timesteps: 584,138,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 584138142...
Checkpoint 584138142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,331.52643
Policy Entropy: 1.08236
Value Function Loss: 13.84969

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.07356

Collected Steps per Second: 10,954.10754
Overall Steps per Second: 9,368.59734

Timestep Collection Time: 4.56559
Timestep Consumption Time: 0.77267
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.33826

Cumulative Model Updates: 35,017
Cumulative Timesteps: 584,188,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,331.57654
Policy Entropy: 1.08521
Value Function Loss: 13.83383

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.11048

Collected Steps per Second: 11,034.38893
Overall Steps per Second: 9,498.43404

Timestep Collection Time: 4.53364
Timestep Consumption Time: 0.73312
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.26676

Cumulative Model Updates: 35,020
Cumulative Timesteps: 584,238,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 584238180...
Checkpoint 584238180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,810.03179
Policy Entropy: 1.08034
Value Function Loss: 13.71895

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.11442

Collected Steps per Second: 10,945.65682
Overall Steps per Second: 9,315.36518

Timestep Collection Time: 4.56894
Timestep Consumption Time: 0.79961
PPO Batch Consumption Time: 0.03870
Total Iteration Time: 5.36855

Cumulative Model Updates: 35,023
Cumulative Timesteps: 584,288,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,011.82369
Policy Entropy: 1.06817
Value Function Loss: 13.66941

Mean KL Divergence: 0.02697
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.09567

Collected Steps per Second: 11,091.60328
Overall Steps per Second: 9,398.87641

Timestep Collection Time: 4.50828
Timestep Consumption Time: 0.81194
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 5.32021

Cumulative Model Updates: 35,026
Cumulative Timesteps: 584,338,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 584338194...
Checkpoint 584338194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,798.26809
Policy Entropy: 1.09112
Value Function Loss: 13.86489

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.07528

Collected Steps per Second: 10,700.08223
Overall Steps per Second: 9,072.20456

Timestep Collection Time: 4.67436
Timestep Consumption Time: 0.83875
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 5.51310

Cumulative Model Updates: 35,029
Cumulative Timesteps: 584,388,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,152.68816
Policy Entropy: 1.09685
Value Function Loss: 14.57584

Mean KL Divergence: 0.02883
SB3 Clip Fraction: 0.15481
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.06136

Collected Steps per Second: 11,429.38925
Overall Steps per Second: 9,554.86077

Timestep Collection Time: 4.37539
Timestep Consumption Time: 0.85839
PPO Batch Consumption Time: 0.05006
Total Iteration Time: 5.23378

Cumulative Model Updates: 35,032
Cumulative Timesteps: 584,438,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 584438218...
Checkpoint 584438218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,417.23294
Policy Entropy: 1.08321
Value Function Loss: 13.73273

Mean KL Divergence: 0.02766
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.08676

Collected Steps per Second: 11,512.20598
Overall Steps per Second: 9,872.07338

Timestep Collection Time: 4.34478
Timestep Consumption Time: 0.72184
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.06662

Cumulative Model Updates: 35,035
Cumulative Timesteps: 584,488,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,632.83931
Policy Entropy: 1.09062
Value Function Loss: 13.68647

Mean KL Divergence: 0.02911
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.10093

Collected Steps per Second: 11,670.64461
Overall Steps per Second: 9,830.19488

Timestep Collection Time: 4.28597
Timestep Consumption Time: 0.80244
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 5.08840

Cumulative Model Updates: 35,038
Cumulative Timesteps: 584,538,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 584538256...
Checkpoint 584538256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,506.66418
Policy Entropy: 1.10142
Value Function Loss: 13.70698

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.10790

Collected Steps per Second: 11,399.71996
Overall Steps per Second: 9,720.02869

Timestep Collection Time: 4.38625
Timestep Consumption Time: 0.75798
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.14422

Cumulative Model Updates: 35,041
Cumulative Timesteps: 584,588,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,725.93820
Policy Entropy: 1.10918
Value Function Loss: 14.04545

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.10187

Collected Steps per Second: 10,970.73477
Overall Steps per Second: 9,498.68621

Timestep Collection Time: 4.55904
Timestep Consumption Time: 0.70653
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.26557

Cumulative Model Updates: 35,044
Cumulative Timesteps: 584,638,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 584638274...
Checkpoint 584638274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,548.30438
Policy Entropy: 1.10432
Value Function Loss: 14.15715

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.08471

Collected Steps per Second: 11,412.88989
Overall Steps per Second: 9,688.12538

Timestep Collection Time: 4.38259
Timestep Consumption Time: 0.78023
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.16282

Cumulative Model Updates: 35,047
Cumulative Timesteps: 584,688,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,262.47378
Policy Entropy: 1.10093
Value Function Loss: 14.05399

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.08554

Collected Steps per Second: 11,223.37302
Overall Steps per Second: 9,648.88836

Timestep Collection Time: 4.45570
Timestep Consumption Time: 0.72707
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.18277

Cumulative Model Updates: 35,050
Cumulative Timesteps: 584,738,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 584738300...
Checkpoint 584738300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396,399.79816
Policy Entropy: 1.11546
Value Function Loss: 14.84053

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 11,623.58562
Overall Steps per Second: 9,823.53611

Timestep Collection Time: 4.30366
Timestep Consumption Time: 0.78860
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.09226

Cumulative Model Updates: 35,053
Cumulative Timesteps: 584,788,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,801.92150
Policy Entropy: 1.12258
Value Function Loss: 14.40428

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.07437

Collected Steps per Second: 11,086.25924
Overall Steps per Second: 9,453.12904

Timestep Collection Time: 4.51153
Timestep Consumption Time: 0.77942
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.29095

Cumulative Model Updates: 35,056
Cumulative Timesteps: 584,838,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 584838340...
Checkpoint 584838340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418,008.71890
Policy Entropy: 1.11672
Value Function Loss: 13.85957

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.06671

Collected Steps per Second: 11,254.48085
Overall Steps per Second: 9,772.04609

Timestep Collection Time: 4.44427
Timestep Consumption Time: 0.67420
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.11848

Cumulative Model Updates: 35,059
Cumulative Timesteps: 584,888,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,358.35430
Policy Entropy: 1.10871
Value Function Loss: 13.45638

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.15227
Policy Update Magnitude: 0.04358
Value Function Update Magnitude: 0.06523

Collected Steps per Second: 10,842.89730
Overall Steps per Second: 9,237.52676

Timestep Collection Time: 4.61334
Timestep Consumption Time: 0.80174
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.41509

Cumulative Model Updates: 35,062
Cumulative Timesteps: 584,938,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 584938380...
Checkpoint 584938380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,796.79953
Policy Entropy: 1.11680
Value Function Loss: 13.98953

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.07043

Collected Steps per Second: 11,010.10794
Overall Steps per Second: 9,581.06602

Timestep Collection Time: 4.54219
Timestep Consumption Time: 0.67748
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.21967

Cumulative Model Updates: 35,065
Cumulative Timesteps: 584,988,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,017.53230
Policy Entropy: 1.11634
Value Function Loss: 14.23480

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.05926
Value Function Update Magnitude: 0.06628

Collected Steps per Second: 11,089.21328
Overall Steps per Second: 9,496.79642

Timestep Collection Time: 4.51105
Timestep Consumption Time: 0.75641
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.26746

Cumulative Model Updates: 35,068
Cumulative Timesteps: 585,038,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 585038414...
Checkpoint 585038414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,810.03011
Policy Entropy: 1.10645
Value Function Loss: 13.78441

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.05933
Value Function Update Magnitude: 0.06803

Collected Steps per Second: 10,969.04997
Overall Steps per Second: 9,501.58468

Timestep Collection Time: 4.55828
Timestep Consumption Time: 0.70400
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 5.26228

Cumulative Model Updates: 35,071
Cumulative Timesteps: 585,088,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,818.94766
Policy Entropy: 1.09993
Value Function Loss: 12.98729

Mean KL Divergence: 0.02833
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 10,791.03822
Overall Steps per Second: 9,245.14352

Timestep Collection Time: 4.63366
Timestep Consumption Time: 0.77480
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.40846

Cumulative Model Updates: 35,074
Cumulative Timesteps: 585,138,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 585138416...
Checkpoint 585138416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,154.84615
Policy Entropy: 1.11406
Value Function Loss: 12.58045

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.06889

Collected Steps per Second: 11,064.14855
Overall Steps per Second: 9,482.41349

Timestep Collection Time: 4.52145
Timestep Consumption Time: 0.75421
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.27566

Cumulative Model Updates: 35,077
Cumulative Timesteps: 585,188,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,352.41491
Policy Entropy: 1.12512
Value Function Loss: 12.41519

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.06983

Collected Steps per Second: 10,892.65791
Overall Steps per Second: 9,261.52756

Timestep Collection Time: 4.59043
Timestep Consumption Time: 0.80846
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.39889

Cumulative Model Updates: 35,080
Cumulative Timesteps: 585,238,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 585238444...
Checkpoint 585238444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,644.86198
Policy Entropy: 1.11394
Value Function Loss: 12.82377

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.06985

Collected Steps per Second: 10,806.46717
Overall Steps per Second: 9,239.45843

Timestep Collection Time: 4.62982
Timestep Consumption Time: 0.78522
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.41504

Cumulative Model Updates: 35,083
Cumulative Timesteps: 585,288,476

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,015.94218
Policy Entropy: 1.12424
Value Function Loss: 13.22436

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.04298
Value Function Update Magnitude: 0.06073

Collected Steps per Second: 11,062.05578
Overall Steps per Second: 9,550.87531

Timestep Collection Time: 4.52122
Timestep Consumption Time: 0.71537
PPO Batch Consumption Time: 0.03825
Total Iteration Time: 5.23659

Cumulative Model Updates: 35,086
Cumulative Timesteps: 585,338,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 585338490...
Checkpoint 585338490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,141.06712
Policy Entropy: 1.12266
Value Function Loss: 13.43822

Mean KL Divergence: 0.02402
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.05436

Collected Steps per Second: 11,008.19448
Overall Steps per Second: 9,424.14465

Timestep Collection Time: 4.54225
Timestep Consumption Time: 0.76348
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 5.30573

Cumulative Model Updates: 35,089
Cumulative Timesteps: 585,388,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,501.16695
Policy Entropy: 1.10696
Value Function Loss: 13.06156

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.04414

Collected Steps per Second: 10,888.89901
Overall Steps per Second: 9,312.15130

Timestep Collection Time: 4.59367
Timestep Consumption Time: 0.77781
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.37148

Cumulative Model Updates: 35,092
Cumulative Timesteps: 585,438,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 585438512...
Checkpoint 585438512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,425.77168
Policy Entropy: 1.08939
Value Function Loss: 13.16937

Mean KL Divergence: 0.02990
SB3 Clip Fraction: 0.15603
Policy Update Magnitude: 0.04365
Value Function Update Magnitude: 0.05327

Collected Steps per Second: 10,681.72625
Overall Steps per Second: 9,301.78683

Timestep Collection Time: 4.68220
Timestep Consumption Time: 0.69461
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 5.37682

Cumulative Model Updates: 35,095
Cumulative Timesteps: 585,488,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,102.24968
Policy Entropy: 1.10183
Value Function Loss: 13.19668

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.05463

Collected Steps per Second: 11,194.96858
Overall Steps per Second: 9,563.46957

Timestep Collection Time: 4.46897
Timestep Consumption Time: 0.76239
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.23137

Cumulative Model Updates: 35,098
Cumulative Timesteps: 585,538,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 585538556...
Checkpoint 585538556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,578.16220
Policy Entropy: 1.09705
Value Function Loss: 13.49599

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.07295

Collected Steps per Second: 12,061.30936
Overall Steps per Second: 10,130.17005

Timestep Collection Time: 4.14715
Timestep Consumption Time: 0.79058
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 4.93773

Cumulative Model Updates: 35,101
Cumulative Timesteps: 585,588,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,682.12264
Policy Entropy: 1.08762
Value Function Loss: 13.42515

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.15750
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.08985

Collected Steps per Second: 11,984.02035
Overall Steps per Second: 10,105.40906

Timestep Collection Time: 4.17306
Timestep Consumption Time: 0.77578
PPO Batch Consumption Time: 0.03918
Total Iteration Time: 4.94883

Cumulative Model Updates: 35,104
Cumulative Timesteps: 585,638,586

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 585638586...
Checkpoint 585638586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,955.59700
Policy Entropy: 1.09548
Value Function Loss: 12.86630

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.08266

Collected Steps per Second: 11,972.08534
Overall Steps per Second: 9,997.39271

Timestep Collection Time: 4.17772
Timestep Consumption Time: 0.82519
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.00290

Cumulative Model Updates: 35,107
Cumulative Timesteps: 585,688,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,957.23708
Policy Entropy: 1.10865
Value Function Loss: 12.82070

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.04352
Value Function Update Magnitude: 0.07812

Collected Steps per Second: 11,766.70087
Overall Steps per Second: 10,127.02319

Timestep Collection Time: 4.25183
Timestep Consumption Time: 0.68842
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.94025

Cumulative Model Updates: 35,110
Cumulative Timesteps: 585,738,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 585738632...
Checkpoint 585738632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,563.28940
Policy Entropy: 1.08721
Value Function Loss: 13.08002

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.07406

Collected Steps per Second: 11,154.69714
Overall Steps per Second: 9,492.54725

Timestep Collection Time: 4.48421
Timestep Consumption Time: 0.78519
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.26940

Cumulative Model Updates: 35,113
Cumulative Timesteps: 585,788,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367,297.77642
Policy Entropy: 1.09653
Value Function Loss: 13.28982

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.04040
Value Function Update Magnitude: 0.06529

Collected Steps per Second: 11,841.77294
Overall Steps per Second: 10,031.34283

Timestep Collection Time: 4.22268
Timestep Consumption Time: 0.76210
PPO Batch Consumption Time: 0.03824
Total Iteration Time: 4.98478

Cumulative Model Updates: 35,116
Cumulative Timesteps: 585,838,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 585838656...
Checkpoint 585838656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,244.17193
Policy Entropy: 1.09025
Value Function Loss: 13.26274

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.06218

Collected Steps per Second: 11,366.50580
Overall Steps per Second: 9,611.62181

Timestep Collection Time: 4.40100
Timestep Consumption Time: 0.80353
PPO Batch Consumption Time: 0.03870
Total Iteration Time: 5.20453

Cumulative Model Updates: 35,119
Cumulative Timesteps: 585,888,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,224.86105
Policy Entropy: 1.10003
Value Function Loss: 12.95853

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.05811

Collected Steps per Second: 11,109.23354
Overall Steps per Second: 9,483.03760

Timestep Collection Time: 4.50346
Timestep Consumption Time: 0.77227
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 5.27574

Cumulative Model Updates: 35,122
Cumulative Timesteps: 585,938,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 585938710...
Checkpoint 585938710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387,085.95851
Policy Entropy: 1.10350
Value Function Loss: 12.95364

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.05637

Collected Steps per Second: 11,302.65519
Overall Steps per Second: 9,762.40463

Timestep Collection Time: 4.42515
Timestep Consumption Time: 0.69817
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.12333

Cumulative Model Updates: 35,125
Cumulative Timesteps: 585,988,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,896.23517
Policy Entropy: 1.10755
Value Function Loss: 12.25525

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.05504

Collected Steps per Second: 11,163.96763
Overall Steps per Second: 9,505.18435

Timestep Collection Time: 4.47959
Timestep Consumption Time: 0.78175
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.26134

Cumulative Model Updates: 35,128
Cumulative Timesteps: 586,038,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 586038736...
Checkpoint 586038736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,048.83082
Policy Entropy: 1.11324
Value Function Loss: 11.37983

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.06145

Collected Steps per Second: 10,677.00065
Overall Steps per Second: 9,237.48889

Timestep Collection Time: 4.68502
Timestep Consumption Time: 0.73008
PPO Batch Consumption Time: 0.03821
Total Iteration Time: 5.41511

Cumulative Model Updates: 35,131
Cumulative Timesteps: 586,088,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,033.42882
Policy Entropy: 1.10749
Value Function Loss: 11.81674

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.06007
Value Function Update Magnitude: 0.05859

Collected Steps per Second: 11,343.14686
Overall Steps per Second: 9,650.98957

Timestep Collection Time: 4.41024
Timestep Consumption Time: 0.77327
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.18351

Cumulative Model Updates: 35,134
Cumulative Timesteps: 586,138,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 586138784...
Checkpoint 586138784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440,007.22737
Policy Entropy: 1.10695
Value Function Loss: 12.45210

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.06892

Collected Steps per Second: 10,852.01561
Overall Steps per Second: 9,328.28286

Timestep Collection Time: 4.60781
Timestep Consumption Time: 0.75266
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 5.36047

Cumulative Model Updates: 35,137
Cumulative Timesteps: 586,188,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373,805.97246
Policy Entropy: 1.12010
Value Function Loss: 14.13417

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 10,671.00993
Overall Steps per Second: 9,241.09400

Timestep Collection Time: 4.68784
Timestep Consumption Time: 0.72537
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.41321

Cumulative Model Updates: 35,140
Cumulative Timesteps: 586,238,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 586238812...
Checkpoint 586238812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428,305.60404
Policy Entropy: 1.11465
Value Function Loss: 13.92474

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.10306
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.04837

Collected Steps per Second: 10,441.66541
Overall Steps per Second: 8,968.03777

Timestep Collection Time: 4.79062
Timestep Consumption Time: 0.78719
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 5.57781

Cumulative Model Updates: 35,143
Cumulative Timesteps: 586,288,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,981.52880
Policy Entropy: 1.12526
Value Function Loss: 13.93561

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.04490

Collected Steps per Second: 11,094.72879
Overall Steps per Second: 9,482.06118

Timestep Collection Time: 4.50737
Timestep Consumption Time: 0.76659
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 5.27396

Cumulative Model Updates: 35,146
Cumulative Timesteps: 586,338,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 586338842...
Checkpoint 586338842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,757.50086
Policy Entropy: 1.11991
Value Function Loss: 13.92098

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.04515

Collected Steps per Second: 10,931.65426
Overall Steps per Second: 9,337.77380

Timestep Collection Time: 4.57534
Timestep Consumption Time: 0.78097
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 5.35631

Cumulative Model Updates: 35,149
Cumulative Timesteps: 586,388,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,341.05904
Policy Entropy: 1.12291
Value Function Loss: 14.71983

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.06106
Value Function Update Magnitude: 0.04371

Collected Steps per Second: 10,785.13715
Overall Steps per Second: 9,247.24586

Timestep Collection Time: 4.63712
Timestep Consumption Time: 0.77119
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.40831

Cumulative Model Updates: 35,152
Cumulative Timesteps: 586,438,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 586438870...
Checkpoint 586438870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,517.09327
Policy Entropy: 1.12506
Value Function Loss: 14.88662

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.04211

Collected Steps per Second: 10,904.29376
Overall Steps per Second: 9,443.16748

Timestep Collection Time: 4.58682
Timestep Consumption Time: 0.70971
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.29653

Cumulative Model Updates: 35,155
Cumulative Timesteps: 586,488,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439,495.55133
Policy Entropy: 1.12932
Value Function Loss: 14.85934

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.05290

Collected Steps per Second: 10,806.01449
Overall Steps per Second: 9,239.79411

Timestep Collection Time: 4.62742
Timestep Consumption Time: 0.78439
PPO Batch Consumption Time: 0.03980
Total Iteration Time: 5.41181

Cumulative Model Updates: 35,158
Cumulative Timesteps: 586,538,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 586538890...
Checkpoint 586538890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440,736.51669
Policy Entropy: 1.11945
Value Function Loss: 14.04902

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.04736

Collected Steps per Second: 10,588.20028
Overall Steps per Second: 9,252.11383

Timestep Collection Time: 4.72469
Timestep Consumption Time: 0.68229
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 5.40698

Cumulative Model Updates: 35,161
Cumulative Timesteps: 586,588,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,509.13470
Policy Entropy: 1.11820
Value Function Loss: 14.27347

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 10,607.27723
Overall Steps per Second: 9,088.44969

Timestep Collection Time: 4.71488
Timestep Consumption Time: 0.78793
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.50281

Cumulative Model Updates: 35,164
Cumulative Timesteps: 586,638,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 586638928...
Checkpoint 586638928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,138.93900
Policy Entropy: 1.12138
Value Function Loss: 14.24980

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.03981

Collected Steps per Second: 10,900.22394
Overall Steps per Second: 9,328.37735

Timestep Collection Time: 4.58835
Timestep Consumption Time: 0.77314
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.36149

Cumulative Model Updates: 35,167
Cumulative Timesteps: 586,688,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,943.95504
Policy Entropy: 1.12485
Value Function Loss: 14.04783

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.03875

Collected Steps per Second: 11,620.22149
Overall Steps per Second: 9,767.72604

Timestep Collection Time: 4.30319
Timestep Consumption Time: 0.81612
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.11931

Cumulative Model Updates: 35,170
Cumulative Timesteps: 586,738,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 586738946...
Checkpoint 586738946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,981.81561
Policy Entropy: 1.11631
Value Function Loss: 13.61474

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.03896

Collected Steps per Second: 11,258.12444
Overall Steps per Second: 9,567.84567

Timestep Collection Time: 4.44337
Timestep Consumption Time: 0.78498
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.22835

Cumulative Model Updates: 35,173
Cumulative Timesteps: 586,788,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,333.48045
Policy Entropy: 1.13000
Value Function Loss: 13.76005

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.03613

Collected Steps per Second: 11,208.20546
Overall Steps per Second: 9,744.20450

Timestep Collection Time: 4.46173
Timestep Consumption Time: 0.67034
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.13208

Cumulative Model Updates: 35,176
Cumulative Timesteps: 586,838,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 586838978...
Checkpoint 586838978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,002.23751
Policy Entropy: 1.13656
Value Function Loss: 14.69769

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.04337

Collected Steps per Second: 11,368.20690
Overall Steps per Second: 9,623.35071

Timestep Collection Time: 4.39823
Timestep Consumption Time: 0.79746
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.19570

Cumulative Model Updates: 35,179
Cumulative Timesteps: 586,888,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,875.75645
Policy Entropy: 1.12975
Value Function Loss: 15.06471

Mean KL Divergence: 0.02576
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.04098

Collected Steps per Second: 10,947.03496
Overall Steps per Second: 9,403.03811

Timestep Collection Time: 4.56909
Timestep Consumption Time: 0.75025
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.31934

Cumulative Model Updates: 35,182
Cumulative Timesteps: 586,938,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 586938996...
Checkpoint 586938996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385,151.45720
Policy Entropy: 1.13850
Value Function Loss: 14.66146

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.03718

Collected Steps per Second: 11,655.55232
Overall Steps per Second: 9,766.40192

Timestep Collection Time: 4.28980
Timestep Consumption Time: 0.82979
PPO Batch Consumption Time: 0.03870
Total Iteration Time: 5.11959

Cumulative Model Updates: 35,185
Cumulative Timesteps: 586,988,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407,237.41303
Policy Entropy: 1.13753
Value Function Loss: 14.05675

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.04136

Collected Steps per Second: 11,324.18354
Overall Steps per Second: 9,599.73286

Timestep Collection Time: 4.41727
Timestep Consumption Time: 0.79350
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.21077

Cumulative Model Updates: 35,188
Cumulative Timesteps: 587,039,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 587039018...
Checkpoint 587039018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,071.08446
Policy Entropy: 1.12415
Value Function Loss: 13.98836

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.04262

Collected Steps per Second: 11,327.13315
Overall Steps per Second: 9,792.49250

Timestep Collection Time: 4.41630
Timestep Consumption Time: 0.69210
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.10840

Cumulative Model Updates: 35,191
Cumulative Timesteps: 587,089,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,546.05496
Policy Entropy: 1.12936
Value Function Loss: 14.16814

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.04502
Value Function Update Magnitude: 0.03936

Collected Steps per Second: 11,506.59623
Overall Steps per Second: 9,788.46428

Timestep Collection Time: 4.34707
Timestep Consumption Time: 0.76303
PPO Batch Consumption Time: 0.04068
Total Iteration Time: 5.11010

Cumulative Model Updates: 35,194
Cumulative Timesteps: 587,139,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 587139062...
Checkpoint 587139062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,931.00643
Policy Entropy: 1.13763
Value Function Loss: 14.56912

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.04166

Collected Steps per Second: 11,362.49245
Overall Steps per Second: 9,598.60851

Timestep Collection Time: 4.40273
Timestep Consumption Time: 0.80907
PPO Batch Consumption Time: 0.05210
Total Iteration Time: 5.21180

Cumulative Model Updates: 35,197
Cumulative Timesteps: 587,189,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,323.01591
Policy Entropy: 1.13488
Value Function Loss: 15.05933

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.04917

Collected Steps per Second: 11,018.60160
Overall Steps per Second: 9,376.06589

Timestep Collection Time: 4.53923
Timestep Consumption Time: 0.79520
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 5.33443

Cumulative Model Updates: 35,200
Cumulative Timesteps: 587,239,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 587239104...
Checkpoint 587239104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,347.98013
Policy Entropy: 1.12040
Value Function Loss: 14.80400

Mean KL Divergence: 0.03696
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.04436

Collected Steps per Second: 10,976.64894
Overall Steps per Second: 9,394.42953

Timestep Collection Time: 4.55622
Timestep Consumption Time: 0.76736
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.32358

Cumulative Model Updates: 35,203
Cumulative Timesteps: 587,289,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,337.99619
Policy Entropy: 1.13014
Value Function Loss: 14.73193

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.04495

Collected Steps per Second: 10,908.20037
Overall Steps per Second: 9,478.47665

Timestep Collection Time: 4.58517
Timestep Consumption Time: 0.69162
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.27680

Cumulative Model Updates: 35,206
Cumulative Timesteps: 587,339,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 587339132...
Checkpoint 587339132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,515.38129
Policy Entropy: 1.13563
Value Function Loss: 14.56019

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.05077

Collected Steps per Second: 11,345.22108
Overall Steps per Second: 9,684.78738

Timestep Collection Time: 4.40802
Timestep Consumption Time: 0.75575
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.16377

Cumulative Model Updates: 35,209
Cumulative Timesteps: 587,389,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,482.32111
Policy Entropy: 1.12324
Value Function Loss: 14.41398

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.04671

Collected Steps per Second: 11,270.29741
Overall Steps per Second: 9,711.56844

Timestep Collection Time: 4.43750
Timestep Consumption Time: 0.71223
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.14973

Cumulative Model Updates: 35,212
Cumulative Timesteps: 587,439,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 587439154...
Checkpoint 587439154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,266.80074
Policy Entropy: 1.10812
Value Function Loss: 14.43488

Mean KL Divergence: 0.03167
SB3 Clip Fraction: 0.17575
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.04709

Collected Steps per Second: 10,842.31521
Overall Steps per Second: 9,223.20129

Timestep Collection Time: 4.61396
Timestep Consumption Time: 0.80997
PPO Batch Consumption Time: 0.03837
Total Iteration Time: 5.42393

Cumulative Model Updates: 35,215
Cumulative Timesteps: 587,489,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352,202.59839
Policy Entropy: 1.12398
Value Function Loss: 14.24046

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.08275
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.04792

Collected Steps per Second: 11,126.99538
Overall Steps per Second: 9,541.33835

Timestep Collection Time: 4.49627
Timestep Consumption Time: 0.74723
PPO Batch Consumption Time: 0.03356
Total Iteration Time: 5.24350

Cumulative Model Updates: 35,218
Cumulative Timesteps: 587,539,210

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 587539210...
Checkpoint 587539210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,105.91927
Policy Entropy: 1.11542
Value Function Loss: 13.67953

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.04655

Collected Steps per Second: 11,085.12696
Overall Steps per Second: 9,343.48637

Timestep Collection Time: 4.51343
Timestep Consumption Time: 0.84131
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 5.35475

Cumulative Model Updates: 35,221
Cumulative Timesteps: 587,589,242

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,646.44344
Policy Entropy: 1.11086
Value Function Loss: 13.47182

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.04595

Collected Steps per Second: 10,993.24807
Overall Steps per Second: 9,280.88003

Timestep Collection Time: 4.55061
Timestep Consumption Time: 0.83961
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.39022

Cumulative Model Updates: 35,224
Cumulative Timesteps: 587,639,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 587639268...
Checkpoint 587639268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,940.47667
Policy Entropy: 1.11016
Value Function Loss: 13.47714

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.04411

Collected Steps per Second: 10,798.85180
Overall Steps per Second: 9,369.22755

Timestep Collection Time: 4.63086
Timestep Consumption Time: 0.70661
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.33747

Cumulative Model Updates: 35,227
Cumulative Timesteps: 587,689,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400,446.01353
Policy Entropy: 1.12082
Value Function Loss: 13.49142

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.04084

Collected Steps per Second: 11,295.00849
Overall Steps per Second: 9,653.18319

Timestep Collection Time: 4.42886
Timestep Consumption Time: 0.75327
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.18212

Cumulative Model Updates: 35,230
Cumulative Timesteps: 587,739,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 587739300...
Checkpoint 587739300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,153.22811
Policy Entropy: 1.12821
Value Function Loss: 13.50070

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.07191

Collected Steps per Second: 10,518.74924
Overall Steps per Second: 9,224.36095

Timestep Collection Time: 4.75570
Timestep Consumption Time: 0.66733
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.42303

Cumulative Model Updates: 35,233
Cumulative Timesteps: 587,789,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,426.52073
Policy Entropy: 1.12694
Value Function Loss: 12.93320

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.06987

Collected Steps per Second: 11,810.79201
Overall Steps per Second: 9,960.21588

Timestep Collection Time: 4.23596
Timestep Consumption Time: 0.78703
PPO Batch Consumption Time: 0.03374
Total Iteration Time: 5.02298

Cumulative Model Updates: 35,236
Cumulative Timesteps: 587,839,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 587839354...
Checkpoint 587839354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,086.67772
Policy Entropy: 1.12019
Value Function Loss: 12.73165

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 11,987.22111
Overall Steps per Second: 10,051.42034

Timestep Collection Time: 4.17294
Timestep Consumption Time: 0.80367
PPO Batch Consumption Time: 0.04533
Total Iteration Time: 4.97661

Cumulative Model Updates: 35,239
Cumulative Timesteps: 587,889,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,245.74527
Policy Entropy: 1.10909
Value Function Loss: 13.34207

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.07466

Collected Steps per Second: 11,976.88177
Overall Steps per Second: 10,187.37443

Timestep Collection Time: 4.17504
Timestep Consumption Time: 0.73339
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 4.90843

Cumulative Model Updates: 35,242
Cumulative Timesteps: 587,939,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 587939380...
Checkpoint 587939380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,317.85899
Policy Entropy: 1.12298
Value Function Loss: 13.29420

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.06941

Collected Steps per Second: 11,484.45767
Overall Steps per Second: 9,694.58679

Timestep Collection Time: 4.35458
Timestep Consumption Time: 0.80397
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 5.15855

Cumulative Model Updates: 35,245
Cumulative Timesteps: 587,989,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,118.99707
Policy Entropy: 1.12239
Value Function Loss: 13.77699

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.04477
Value Function Update Magnitude: 0.06777

Collected Steps per Second: 12,030.63321
Overall Steps per Second: 10,224.34629

Timestep Collection Time: 4.15755
Timestep Consumption Time: 0.73450
PPO Batch Consumption Time: 0.03300
Total Iteration Time: 4.89205

Cumulative Model Updates: 35,248
Cumulative Timesteps: 588,039,408

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 588039408...
Checkpoint 588039408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,402.71338
Policy Entropy: 1.11832
Value Function Loss: 12.47870

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.05929

Collected Steps per Second: 11,369.62133
Overall Steps per Second: 9,654.97517

Timestep Collection Time: 4.39909
Timestep Consumption Time: 0.78124
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.18033

Cumulative Model Updates: 35,251
Cumulative Timesteps: 588,089,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310,304.29813
Policy Entropy: 1.10824
Value Function Loss: 12.74008

Mean KL Divergence: 0.02638
SB3 Clip Fraction: 0.15012
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.06818

Collected Steps per Second: 11,092.71618
Overall Steps per Second: 9,411.20900

Timestep Collection Time: 4.50764
Timestep Consumption Time: 0.80538
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.31303

Cumulative Model Updates: 35,254
Cumulative Timesteps: 588,139,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 588139426...
Checkpoint 588139426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,573.84036
Policy Entropy: 1.11419
Value Function Loss: 12.53829

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.06455

Collected Steps per Second: 11,225.52128
Overall Steps per Second: 9,703.72156

Timestep Collection Time: 4.45485
Timestep Consumption Time: 0.69864
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 5.15349

Cumulative Model Updates: 35,257
Cumulative Timesteps: 588,189,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,251.65349
Policy Entropy: 1.11855
Value Function Loss: 12.85665

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.06332

Collected Steps per Second: 10,800.14283
Overall Steps per Second: 9,198.07777

Timestep Collection Time: 4.63068
Timestep Consumption Time: 0.80654
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.43722

Cumulative Model Updates: 35,260
Cumulative Timesteps: 588,239,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 588239446...
Checkpoint 588239446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,830.66187
Policy Entropy: 1.10774
Value Function Loss: 12.70641

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.05791

Collected Steps per Second: 11,252.86689
Overall Steps per Second: 9,599.84445

Timestep Collection Time: 4.44367
Timestep Consumption Time: 0.76517
PPO Batch Consumption Time: 0.03713
Total Iteration Time: 5.20883

Cumulative Model Updates: 35,263
Cumulative Timesteps: 588,289,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,983.32398
Policy Entropy: 1.10153
Value Function Loss: 12.81936

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.06452

Collected Steps per Second: 11,295.76861
Overall Steps per Second: 9,608.64846

Timestep Collection Time: 4.42927
Timestep Consumption Time: 0.77771
PPO Batch Consumption Time: 0.04526
Total Iteration Time: 5.20698

Cumulative Model Updates: 35,266
Cumulative Timesteps: 588,339,482

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 588339482...
Checkpoint 588339482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388,442.12330
Policy Entropy: 1.11718
Value Function Loss: 13.17038

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.07937

Collected Steps per Second: 10,984.88097
Overall Steps per Second: 9,424.43784

Timestep Collection Time: 4.55390
Timestep Consumption Time: 0.75401
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.30790

Cumulative Model Updates: 35,269
Cumulative Timesteps: 588,389,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,795.53268
Policy Entropy: 1.11834
Value Function Loss: 13.55035

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.04410
Value Function Update Magnitude: 0.07267

Collected Steps per Second: 10,984.98284
Overall Steps per Second: 9,477.63787

Timestep Collection Time: 4.55313
Timestep Consumption Time: 0.72414
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 5.27726

Cumulative Model Updates: 35,272
Cumulative Timesteps: 588,439,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 588439522...
Checkpoint 588439522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,557.12535
Policy Entropy: 1.10355
Value Function Loss: 13.16133

Mean KL Divergence: 0.02626
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.08589

Collected Steps per Second: 11,007.23385
Overall Steps per Second: 9,360.95772

Timestep Collection Time: 4.54447
Timestep Consumption Time: 0.79922
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 5.34368

Cumulative Model Updates: 35,275
Cumulative Timesteps: 588,489,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,094.42153
Policy Entropy: 1.08617
Value Function Loss: 12.46315

Mean KL Divergence: 0.02748
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.04119
Value Function Update Magnitude: 0.09282

Collected Steps per Second: 11,059.01569
Overall Steps per Second: 9,438.18680

Timestep Collection Time: 4.52409
Timestep Consumption Time: 0.77693
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.30102

Cumulative Model Updates: 35,278
Cumulative Timesteps: 588,539,576

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 588539576...
Checkpoint 588539576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,148.31936
Policy Entropy: 1.09358
Value Function Loss: 12.40934

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.08174

Collected Steps per Second: 11,468.60147
Overall Steps per Second: 9,943.49172

Timestep Collection Time: 4.36112
Timestep Consumption Time: 0.66890
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 5.03002

Cumulative Model Updates: 35,281
Cumulative Timesteps: 588,589,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,694.17783
Policy Entropy: 1.10327
Value Function Loss: 12.62275

Mean KL Divergence: 0.02270
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.07288

Collected Steps per Second: 10,734.13856
Overall Steps per Second: 9,206.95154

Timestep Collection Time: 4.66027
Timestep Consumption Time: 0.77301
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 5.43329

Cumulative Model Updates: 35,284
Cumulative Timesteps: 588,639,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 588639616...
Checkpoint 588639616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,210.37089
Policy Entropy: 1.09156
Value Function Loss: 12.82021

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.07081

Collected Steps per Second: 11,056.20123
Overall Steps per Second: 9,449.86326

Timestep Collection Time: 4.52380
Timestep Consumption Time: 0.76898
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.29278

Cumulative Model Updates: 35,287
Cumulative Timesteps: 588,689,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,401.36461
Policy Entropy: 1.08004
Value Function Loss: 13.06001

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.06654

Collected Steps per Second: 11,042.27322
Overall Steps per Second: 9,431.27297

Timestep Collection Time: 4.52932
Timestep Consumption Time: 0.77367
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.30300

Cumulative Model Updates: 35,290
Cumulative Timesteps: 588,739,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 588739646...
Checkpoint 588739646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387,555.78817
Policy Entropy: 1.09572
Value Function Loss: 12.84200

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.06603

Collected Steps per Second: 11,048.94729
Overall Steps per Second: 9,472.26091

Timestep Collection Time: 4.52821
Timestep Consumption Time: 0.75373
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.28195

Cumulative Model Updates: 35,293
Cumulative Timesteps: 588,789,678

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,845.12608
Policy Entropy: 1.10047
Value Function Loss: 13.64538

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.04231
Value Function Update Magnitude: 0.06440

Collected Steps per Second: 10,756.90149
Overall Steps per Second: 9,326.36649

Timestep Collection Time: 4.64911
Timestep Consumption Time: 0.71311
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.36222

Cumulative Model Updates: 35,296
Cumulative Timesteps: 588,839,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 588839688...
Checkpoint 588839688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,405.12987
Policy Entropy: 1.08686
Value Function Loss: 13.12974

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.06436

Collected Steps per Second: 10,956.68341
Overall Steps per Second: 9,423.72057

Timestep Collection Time: 4.56379
Timestep Consumption Time: 0.74239
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.30618

Cumulative Model Updates: 35,299
Cumulative Timesteps: 588,889,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398,726.90691
Policy Entropy: 1.08279
Value Function Loss: 13.02699

Mean KL Divergence: 0.02756
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.06490

Collected Steps per Second: 10,563.81489
Overall Steps per Second: 9,118.35584

Timestep Collection Time: 4.73314
Timestep Consumption Time: 0.75031
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 5.48344

Cumulative Model Updates: 35,302
Cumulative Timesteps: 588,939,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 588939692...
Checkpoint 588939692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,853.10635
Policy Entropy: 1.09111
Value Function Loss: 12.45527

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.04261
Value Function Update Magnitude: 0.07123

Collected Steps per Second: 11,605.58046
Overall Steps per Second: 9,888.45853

Timestep Collection Time: 4.31034
Timestep Consumption Time: 0.74849
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 5.05883

Cumulative Model Updates: 35,305
Cumulative Timesteps: 588,989,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,356.40814
Policy Entropy: 1.09816
Value Function Loss: 12.39583

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.06674

Collected Steps per Second: 11,837.15651
Overall Steps per Second: 9,985.80901

Timestep Collection Time: 4.22483
Timestep Consumption Time: 0.78327
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.00811

Cumulative Model Updates: 35,308
Cumulative Timesteps: 589,039,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 589039726...
Checkpoint 589039726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,806.30353
Policy Entropy: 1.08406
Value Function Loss: 12.52636

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.06758

Collected Steps per Second: 11,423.78221
Overall Steps per Second: 9,746.59553

Timestep Collection Time: 4.37841
Timestep Consumption Time: 0.75343
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.13184

Cumulative Model Updates: 35,311
Cumulative Timesteps: 589,089,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,722.31080
Policy Entropy: 1.07965
Value Function Loss: 12.32438

Mean KL Divergence: 0.02866
SB3 Clip Fraction: 0.16542
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.06400

Collected Steps per Second: 11,688.14903
Overall Steps per Second: 9,885.38990

Timestep Collection Time: 4.28023
Timestep Consumption Time: 0.78057
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 5.06080

Cumulative Model Updates: 35,314
Cumulative Timesteps: 589,139,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 589139772...
Checkpoint 589139772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,910.07066
Policy Entropy: 1.08250
Value Function Loss: 11.72363

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.07712

Collected Steps per Second: 11,672.39451
Overall Steps per Second: 9,929.19659

Timestep Collection Time: 4.28395
Timestep Consumption Time: 0.75210
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.03606

Cumulative Model Updates: 35,317
Cumulative Timesteps: 589,189,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417,193.59948
Policy Entropy: 1.08899
Value Function Loss: 12.27439

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 11,227.10231
Overall Steps per Second: 9,583.36443

Timestep Collection Time: 4.45618
Timestep Consumption Time: 0.76432
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.22050

Cumulative Model Updates: 35,320
Cumulative Timesteps: 589,239,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 589239806...
Checkpoint 589239806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,341.20523
Policy Entropy: 1.06666
Value Function Loss: 12.45777

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 11,058.72050
Overall Steps per Second: 9,420.29729

Timestep Collection Time: 4.52331
Timestep Consumption Time: 0.78672
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 5.31002

Cumulative Model Updates: 35,323
Cumulative Timesteps: 589,289,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,572.43857
Policy Entropy: 1.07494
Value Function Loss: 13.21615

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.06212

Collected Steps per Second: 11,300.46924
Overall Steps per Second: 9,728.77094

Timestep Collection Time: 4.42707
Timestep Consumption Time: 0.71520
PPO Batch Consumption Time: 0.03925
Total Iteration Time: 5.14227

Cumulative Model Updates: 35,326
Cumulative Timesteps: 589,339,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 589339856...
Checkpoint 589339856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,230.54216
Policy Entropy: 1.08383
Value Function Loss: 12.38780

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.05438

Collected Steps per Second: 11,392.06263
Overall Steps per Second: 9,638.49738

Timestep Collection Time: 4.39043
Timestep Consumption Time: 0.79877
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.18919

Cumulative Model Updates: 35,329
Cumulative Timesteps: 589,389,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,285.62954
Policy Entropy: 1.09399
Value Function Loss: 12.34109

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.05633

Collected Steps per Second: 11,302.04691
Overall Steps per Second: 9,673.95612

Timestep Collection Time: 4.42610
Timestep Consumption Time: 0.74490
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.17100

Cumulative Model Updates: 35,332
Cumulative Timesteps: 589,439,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 589439896...
Checkpoint 589439896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,434.40870
Policy Entropy: 1.08280
Value Function Loss: 12.18457

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.06122

Collected Steps per Second: 11,229.84669
Overall Steps per Second: 9,513.53779

Timestep Collection Time: 4.45438
Timestep Consumption Time: 0.80360
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.25798

Cumulative Model Updates: 35,335
Cumulative Timesteps: 589,489,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,063.35369
Policy Entropy: 1.07711
Value Function Loss: 12.32702

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.07215

Collected Steps per Second: 11,142.82573
Overall Steps per Second: 9,440.79658

Timestep Collection Time: 4.48773
Timestep Consumption Time: 0.80907
PPO Batch Consumption Time: 0.03912
Total Iteration Time: 5.29680

Cumulative Model Updates: 35,338
Cumulative Timesteps: 589,539,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 589539924...
Checkpoint 589539924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,057.95438
Policy Entropy: 1.08525
Value Function Loss: 12.38258

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 11,064.47552
Overall Steps per Second: 9,473.46976

Timestep Collection Time: 4.51951
Timestep Consumption Time: 0.75902
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.27853

Cumulative Model Updates: 35,341
Cumulative Timesteps: 589,589,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,235.44486
Policy Entropy: 1.09075
Value Function Loss: 12.39401

Mean KL Divergence: 0.02227
SB3 Clip Fraction: 0.14870
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.09891

Collected Steps per Second: 11,219.55238
Overall Steps per Second: 9,469.32404

Timestep Collection Time: 4.45775
Timestep Consumption Time: 0.82393
PPO Batch Consumption Time: 0.04085
Total Iteration Time: 5.28169

Cumulative Model Updates: 35,344
Cumulative Timesteps: 589,639,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 589639944...
Checkpoint 589639944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,422.37212
Policy Entropy: 1.07489
Value Function Loss: 12.22349

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.09647

Collected Steps per Second: 11,175.67388
Overall Steps per Second: 9,557.87902

Timestep Collection Time: 4.47597
Timestep Consumption Time: 0.75762
PPO Batch Consumption Time: 0.03800
Total Iteration Time: 5.23359

Cumulative Model Updates: 35,347
Cumulative Timesteps: 589,689,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,315.86753
Policy Entropy: 1.06844
Value Function Loss: 12.51485

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.08520

Collected Steps per Second: 11,156.35337
Overall Steps per Second: 9,703.22615

Timestep Collection Time: 4.48229
Timestep Consumption Time: 0.67125
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.15354

Cumulative Model Updates: 35,350
Cumulative Timesteps: 589,739,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 589739972...
Checkpoint 589739972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407,521.36330
Policy Entropy: 1.07929
Value Function Loss: 12.25723

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.08022

Collected Steps per Second: 10,555.69389
Overall Steps per Second: 9,037.93070

Timestep Collection Time: 4.73697
Timestep Consumption Time: 0.79549
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 5.53246

Cumulative Model Updates: 35,353
Cumulative Timesteps: 589,789,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,349.59236
Policy Entropy: 1.09428
Value Function Loss: 11.98085

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.07477

Collected Steps per Second: 10,965.71150
Overall Steps per Second: 9,407.97025

Timestep Collection Time: 4.56040
Timestep Consumption Time: 0.75510
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.31549

Cumulative Model Updates: 35,356
Cumulative Timesteps: 589,839,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 589839982...
Checkpoint 589839982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,786.13657
Policy Entropy: 1.07874
Value Function Loss: 12.09641

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.07381

Collected Steps per Second: 11,282.35817
Overall Steps per Second: 9,597.11115

Timestep Collection Time: 4.43187
Timestep Consumption Time: 0.77823
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 5.21011

Cumulative Model Updates: 35,359
Cumulative Timesteps: 589,889,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356,091.73700
Policy Entropy: 1.09189
Value Function Loss: 12.07767

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.08305

Collected Steps per Second: 11,148.16864
Overall Steps per Second: 9,518.00307

Timestep Collection Time: 4.48594
Timestep Consumption Time: 0.76831
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 5.25425

Cumulative Model Updates: 35,362
Cumulative Timesteps: 589,939,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 589939994...
Checkpoint 589939994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,767.08692
Policy Entropy: 1.09387
Value Function Loss: 12.64001

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.07396

Collected Steps per Second: 10,987.98388
Overall Steps per Second: 9,480.51067

Timestep Collection Time: 4.55134
Timestep Consumption Time: 0.72370
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 5.27503

Cumulative Model Updates: 35,365
Cumulative Timesteps: 589,990,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,339.10842
Policy Entropy: 1.08191
Value Function Loss: 12.04508

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.06631

Collected Steps per Second: 11,084.40623
Overall Steps per Second: 9,443.90822

Timestep Collection Time: 4.51120
Timestep Consumption Time: 0.78364
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.29484

Cumulative Model Updates: 35,368
Cumulative Timesteps: 590,040,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 590040008...
Checkpoint 590040008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386,809.38291
Policy Entropy: 1.07646
Value Function Loss: 11.89823

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.06385
Value Function Update Magnitude: 0.06124

Collected Steps per Second: 10,651.71856
Overall Steps per Second: 9,150.54586

Timestep Collection Time: 4.69464
Timestep Consumption Time: 0.77017
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.46481

Cumulative Model Updates: 35,371
Cumulative Timesteps: 590,090,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,137.72232
Policy Entropy: 1.07403
Value Function Loss: 11.69868

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.06307

Collected Steps per Second: 12,172.99881
Overall Steps per Second: 10,232.47070

Timestep Collection Time: 4.10893
Timestep Consumption Time: 0.77923
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 4.88816

Cumulative Model Updates: 35,374
Cumulative Timesteps: 590,140,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 590140032...
Checkpoint 590140032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425,136.96278
Policy Entropy: 1.07741
Value Function Loss: 11.47264

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.05950

Collected Steps per Second: 11,863.46631
Overall Steps per Second: 10,090.49353

Timestep Collection Time: 4.21681
Timestep Consumption Time: 0.74092
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 4.95774

Cumulative Model Updates: 35,377
Cumulative Timesteps: 590,190,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386,941.79657
Policy Entropy: 1.08963
Value Function Loss: 11.61612

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.06051

Collected Steps per Second: 11,682.29674
Overall Steps per Second: 9,946.82262

Timestep Collection Time: 4.28186
Timestep Consumption Time: 0.74708
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 5.02894

Cumulative Model Updates: 35,380
Cumulative Timesteps: 590,240,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 590240080...
Checkpoint 590240080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,670.50157
Policy Entropy: 1.10275
Value Function Loss: 11.55187

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.05554

Collected Steps per Second: 12,197.91300
Overall Steps per Second: 10,214.41489

Timestep Collection Time: 4.10021
Timestep Consumption Time: 0.79620
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.89641

Cumulative Model Updates: 35,383
Cumulative Timesteps: 590,290,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,521.58170
Policy Entropy: 1.09291
Value Function Loss: 12.55464

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.05646

Collected Steps per Second: 12,057.37000
Overall Steps per Second: 10,195.06334

Timestep Collection Time: 4.14817
Timestep Consumption Time: 0.75774
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.90590

Cumulative Model Updates: 35,386
Cumulative Timesteps: 590,340,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 590340110...
Checkpoint 590340110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,589.18821
Policy Entropy: 1.08581
Value Function Loss: 12.81812

Mean KL Divergence: 0.02796
SB3 Clip Fraction: 0.15076
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.05414

Collected Steps per Second: 11,733.79368
Overall Steps per Second: 9,914.79074

Timestep Collection Time: 4.26137
Timestep Consumption Time: 0.78181
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.04317

Cumulative Model Updates: 35,389
Cumulative Timesteps: 590,390,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,320.61980
Policy Entropy: 1.09907
Value Function Loss: 12.11508

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.08124

Collected Steps per Second: 11,170.39311
Overall Steps per Second: 9,449.38135

Timestep Collection Time: 4.47648
Timestep Consumption Time: 0.81530
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 5.29178

Cumulative Model Updates: 35,392
Cumulative Timesteps: 590,440,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 590440116...
Checkpoint 590440116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,385.12760
Policy Entropy: 1.11316
Value Function Loss: 11.88399

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.10463

Collected Steps per Second: 11,391.05919
Overall Steps per Second: 9,817.51133

Timestep Collection Time: 4.39046
Timestep Consumption Time: 0.70370
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.09416

Cumulative Model Updates: 35,395
Cumulative Timesteps: 590,490,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,137.46067
Policy Entropy: 1.09213
Value Function Loss: 11.81941

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.10494

Collected Steps per Second: 11,319.49581
Overall Steps per Second: 9,602.37729

Timestep Collection Time: 4.41804
Timestep Consumption Time: 0.79004
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.20809

Cumulative Model Updates: 35,398
Cumulative Timesteps: 590,540,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 590540138...
Checkpoint 590540138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,356.20082
Policy Entropy: 1.09279
Value Function Loss: 12.11035

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.10668

Collected Steps per Second: 11,117.43095
Overall Steps per Second: 9,635.16572

Timestep Collection Time: 4.49906
Timestep Consumption Time: 0.69213
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.19119

Cumulative Model Updates: 35,401
Cumulative Timesteps: 590,590,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,205.37320
Policy Entropy: 1.10127
Value Function Loss: 12.01163

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.10472

Collected Steps per Second: 11,105.88905
Overall Steps per Second: 9,386.65023

Timestep Collection Time: 4.50482
Timestep Consumption Time: 0.82509
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.32991

Cumulative Model Updates: 35,404
Cumulative Timesteps: 590,640,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 590640186...
Checkpoint 590640186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,731.88524
Policy Entropy: 1.10304
Value Function Loss: 11.65655

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.04399
Value Function Update Magnitude: 0.09663

Collected Steps per Second: 10,900.73345
Overall Steps per Second: 9,402.99460

Timestep Collection Time: 4.58978
Timestep Consumption Time: 0.73108
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.32086

Cumulative Model Updates: 35,407
Cumulative Timesteps: 590,690,218

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,689.92573
Policy Entropy: 1.08269
Value Function Loss: 11.69616

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.10565

Collected Steps per Second: 11,175.09069
Overall Steps per Second: 9,504.66404

Timestep Collection Time: 4.47495
Timestep Consumption Time: 0.78646
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 5.26142

Cumulative Model Updates: 35,410
Cumulative Timesteps: 590,740,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 590740226...
Checkpoint 590740226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,288.91142
Policy Entropy: 1.09974
Value Function Loss: 11.80567

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.16233
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.11182

Collected Steps per Second: 11,284.61896
Overall Steps per Second: 9,605.34772

Timestep Collection Time: 4.43258
Timestep Consumption Time: 0.77493
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.20752

Cumulative Model Updates: 35,413
Cumulative Timesteps: 590,790,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,749.68825
Policy Entropy: 1.10353
Value Function Loss: 11.95781

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.15276
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.10008

Collected Steps per Second: 10,632.93456
Overall Steps per Second: 9,307.45738

Timestep Collection Time: 4.70256
Timestep Consumption Time: 0.66969
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.37225

Cumulative Model Updates: 35,416
Cumulative Timesteps: 590,840,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 590840248...
Checkpoint 590840248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416,209.08250
Policy Entropy: 1.09636
Value Function Loss: 12.22509

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.08109

Collected Steps per Second: 11,173.82846
Overall Steps per Second: 9,505.76917

Timestep Collection Time: 4.47725
Timestep Consumption Time: 0.78566
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.26291

Cumulative Model Updates: 35,419
Cumulative Timesteps: 590,890,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,584.16411
Policy Entropy: 1.08042
Value Function Loss: 11.37122

Mean KL Divergence: 0.03653
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.06918

Collected Steps per Second: 10,750.54747
Overall Steps per Second: 9,373.51542

Timestep Collection Time: 4.65279
Timestep Consumption Time: 0.68353
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.33631

Cumulative Model Updates: 35,422
Cumulative Timesteps: 590,940,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 590940296...
Checkpoint 590940296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,338.54513
Policy Entropy: 1.09173
Value Function Loss: 10.99517

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.07725

Collected Steps per Second: 10,940.04083
Overall Steps per Second: 9,246.49085

Timestep Collection Time: 4.57220
Timestep Consumption Time: 0.83742
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.40962

Cumulative Model Updates: 35,425
Cumulative Timesteps: 590,990,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,206.86038
Policy Entropy: 1.08762
Value Function Loss: 10.92119

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.08611

Collected Steps per Second: 11,016.49706
Overall Steps per Second: 9,404.14854

Timestep Collection Time: 4.54028
Timestep Consumption Time: 0.77843
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.31872

Cumulative Model Updates: 35,428
Cumulative Timesteps: 591,040,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 591040334...
Checkpoint 591040334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,261.20198
Policy Entropy: 1.08622
Value Function Loss: 11.61618

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.06610
Value Function Update Magnitude: 0.07160

Collected Steps per Second: 11,007.73399
Overall Steps per Second: 9,604.59386

Timestep Collection Time: 4.54281
Timestep Consumption Time: 0.66366
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.20647

Cumulative Model Updates: 35,431
Cumulative Timesteps: 591,090,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,545.14404
Policy Entropy: 1.07199
Value Function Loss: 12.24425

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.15594
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.06707

Collected Steps per Second: 11,035.89737
Overall Steps per Second: 9,418.59262

Timestep Collection Time: 4.53085
Timestep Consumption Time: 0.77801
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 5.30886

Cumulative Model Updates: 35,434
Cumulative Timesteps: 591,140,342

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 591140342...
Checkpoint 591140342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,160.38381
Policy Entropy: 1.09284
Value Function Loss: 12.38144

Mean KL Divergence: 0.02363
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.06677

Collected Steps per Second: 10,903.49180
Overall Steps per Second: 9,369.20169

Timestep Collection Time: 4.58605
Timestep Consumption Time: 0.75101
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.33706

Cumulative Model Updates: 35,437
Cumulative Timesteps: 591,190,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,437.34098
Policy Entropy: 1.09421
Value Function Loss: 12.46046

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.06094

Collected Steps per Second: 10,901.42759
Overall Steps per Second: 9,274.64280

Timestep Collection Time: 4.58876
Timestep Consumption Time: 0.80487
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.39363

Cumulative Model Updates: 35,440
Cumulative Timesteps: 591,240,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 591240370...
Checkpoint 591240370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,349.14138
Policy Entropy: 1.07581
Value Function Loss: 12.84528

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.06809

Collected Steps per Second: 11,413.94708
Overall Steps per Second: 9,776.94368

Timestep Collection Time: 4.38166
Timestep Consumption Time: 0.73364
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.11530

Cumulative Model Updates: 35,443
Cumulative Timesteps: 591,290,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,919.39540
Policy Entropy: 1.06965
Value Function Loss: 12.87503

Mean KL Divergence: 0.02428
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.06670

Collected Steps per Second: 11,449.79799
Overall Steps per Second: 9,924.73442

Timestep Collection Time: 4.36811
Timestep Consumption Time: 0.67122
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 5.03933

Cumulative Model Updates: 35,446
Cumulative Timesteps: 591,340,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 591340396...
Checkpoint 591340396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,439.10721
Policy Entropy: 1.08007
Value Function Loss: 13.27417

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.08612

Collected Steps per Second: 10,969.37029
Overall Steps per Second: 9,401.11040

Timestep Collection Time: 4.55961
Timestep Consumption Time: 0.76062
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.32022

Cumulative Model Updates: 35,449
Cumulative Timesteps: 591,390,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,693.53350
Policy Entropy: 1.09013
Value Function Loss: 13.07732

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.08206

Collected Steps per Second: 11,296.96606
Overall Steps per Second: 9,671.96125

Timestep Collection Time: 4.42738
Timestep Consumption Time: 0.74385
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.17124

Cumulative Model Updates: 35,452
Cumulative Timesteps: 591,440,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 591440428...
Checkpoint 591440428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,825.10873
Policy Entropy: 1.06392
Value Function Loss: 13.58713

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.14984
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.08014

Collected Steps per Second: 11,604.73343
Overall Steps per Second: 9,716.08590

Timestep Collection Time: 4.31100
Timestep Consumption Time: 0.83799
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.14899

Cumulative Model Updates: 35,455
Cumulative Timesteps: 591,490,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,782.38248
Policy Entropy: 1.08685
Value Function Loss: 13.26586

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.15204
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.06844

Collected Steps per Second: 11,389.56651
Overall Steps per Second: 9,747.45843

Timestep Collection Time: 4.39156
Timestep Consumption Time: 0.73983
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.13139

Cumulative Model Updates: 35,458
Cumulative Timesteps: 591,540,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 591540474...
Checkpoint 591540474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,869.32912
Policy Entropy: 1.08699
Value Function Loss: 13.12255

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.06149

Collected Steps per Second: 11,114.89318
Overall Steps per Second: 9,633.24529

Timestep Collection Time: 4.49901
Timestep Consumption Time: 0.69197
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.19098

Cumulative Model Updates: 35,461
Cumulative Timesteps: 591,590,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,253.34807
Policy Entropy: 1.07939
Value Function Loss: 12.30091

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.05787

Collected Steps per Second: 11,507.23291
Overall Steps per Second: 9,713.83562

Timestep Collection Time: 4.34753
Timestep Consumption Time: 0.80265
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 5.15018

Cumulative Model Updates: 35,464
Cumulative Timesteps: 591,640,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 591640508...
Checkpoint 591640508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,701.38457
Policy Entropy: 1.05829
Value Function Loss: 12.24085

Mean KL Divergence: 0.03328
SB3 Clip Fraction: 0.17653
Policy Update Magnitude: 0.04302
Value Function Update Magnitude: 0.06596

Collected Steps per Second: 10,863.12748
Overall Steps per Second: 9,236.90329

Timestep Collection Time: 4.60549
Timestep Consumption Time: 0.81083
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 5.41632

Cumulative Model Updates: 35,467
Cumulative Timesteps: 591,690,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,438.37157
Policy Entropy: 1.07995
Value Function Loss: 11.95444

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.07495

Collected Steps per Second: 11,417.22248
Overall Steps per Second: 9,685.51223

Timestep Collection Time: 4.38163
Timestep Consumption Time: 0.78341
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.16503

Cumulative Model Updates: 35,470
Cumulative Timesteps: 591,740,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 591740564...
Checkpoint 591740564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,368.79019
Policy Entropy: 1.06940
Value Function Loss: 12.90058

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.05965

Collected Steps per Second: 10,782.98643
Overall Steps per Second: 9,212.43465

Timestep Collection Time: 4.63805
Timestep Consumption Time: 0.79070
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.42875

Cumulative Model Updates: 35,473
Cumulative Timesteps: 591,790,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,437.71067
Policy Entropy: 1.05658
Value Function Loss: 12.55809

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.05653

Collected Steps per Second: 10,962.66568
Overall Steps per Second: 9,445.51689

Timestep Collection Time: 4.56294
Timestep Consumption Time: 0.73290
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.29585

Cumulative Model Updates: 35,476
Cumulative Timesteps: 591,840,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 591840598...
Checkpoint 591840598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,113.87847
Policy Entropy: 1.05047
Value Function Loss: 12.78409

Mean KL Divergence: 0.02920
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.06981

Collected Steps per Second: 11,008.40561
Overall Steps per Second: 9,400.42697

Timestep Collection Time: 4.54380
Timestep Consumption Time: 0.77723
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.32103

Cumulative Model Updates: 35,479
Cumulative Timesteps: 591,890,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,170.70401
Policy Entropy: 1.05911
Value Function Loss: 11.56357

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.06996

Collected Steps per Second: 10,993.00496
Overall Steps per Second: 9,537.49318

Timestep Collection Time: 4.54944
Timestep Consumption Time: 0.69429
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.24373

Cumulative Model Updates: 35,482
Cumulative Timesteps: 591,940,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 591940630...
Checkpoint 591940630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,345.57067
Policy Entropy: 1.07349
Value Function Loss: 12.11567

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.15980
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.05705

Collected Steps per Second: 11,171.87487
Overall Steps per Second: 9,448.32035

Timestep Collection Time: 4.47785
Timestep Consumption Time: 0.81685
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.29470

Cumulative Model Updates: 35,485
Cumulative Timesteps: 591,990,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,873.64008
Policy Entropy: 1.05200
Value Function Loss: 11.99108

Mean KL Divergence: 0.02445
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.05011

Collected Steps per Second: 11,123.84571
Overall Steps per Second: 9,561.60016

Timestep Collection Time: 4.49755
Timestep Consumption Time: 0.73484
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 5.23239

Cumulative Model Updates: 35,488
Cumulative Timesteps: 592,040,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 592040686...
Checkpoint 592040686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,595.71847
Policy Entropy: 1.08120
Value Function Loss: 12.80835

Mean KL Divergence: 0.03090
SB3 Clip Fraction: 0.16928
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.05822

Collected Steps per Second: 10,847.93162
Overall Steps per Second: 9,307.64741

Timestep Collection Time: 4.61028
Timestep Consumption Time: 0.76294
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.37322

Cumulative Model Updates: 35,491
Cumulative Timesteps: 592,090,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,821.94648
Policy Entropy: 1.06872
Value Function Loss: 12.68989

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.06169

Collected Steps per Second: 11,120.95679
Overall Steps per Second: 9,470.79285

Timestep Collection Time: 4.49853
Timestep Consumption Time: 0.78381
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.28235

Cumulative Model Updates: 35,494
Cumulative Timesteps: 592,140,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 592140726...
Checkpoint 592140726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,563.16988
Policy Entropy: 1.06074
Value Function Loss: 11.68995

Mean KL Divergence: 0.03218
SB3 Clip Fraction: 0.15963
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.06689

Collected Steps per Second: 10,839.63278
Overall Steps per Second: 9,409.50698

Timestep Collection Time: 4.61529
Timestep Consumption Time: 0.70146
PPO Batch Consumption Time: 0.03371
Total Iteration Time: 5.31675

Cumulative Model Updates: 35,497
Cumulative Timesteps: 592,190,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,127.92195
Policy Entropy: 1.05955
Value Function Loss: 11.76435

Mean KL Divergence: 0.02897
SB3 Clip Fraction: 0.17230
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.07073

Collected Steps per Second: 11,040.79230
Overall Steps per Second: 9,402.65320

Timestep Collection Time: 4.52866
Timestep Consumption Time: 0.78899
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.31765

Cumulative Model Updates: 35,500
Cumulative Timesteps: 592,240,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 592240754...
Checkpoint 592240754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,665.46248
Policy Entropy: 1.07078
Value Function Loss: 11.84642

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.06785

Collected Steps per Second: 10,788.99464
Overall Steps per Second: 9,266.69133

Timestep Collection Time: 4.63509
Timestep Consumption Time: 0.76144
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.39653

Cumulative Model Updates: 35,503
Cumulative Timesteps: 592,290,762

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,936.98343
Policy Entropy: 1.07780
Value Function Loss: 13.17132

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.06807
Value Function Update Magnitude: 0.06880

Collected Steps per Second: 11,014.06791
Overall Steps per Second: 9,255.47916

Timestep Collection Time: 4.54201
Timestep Consumption Time: 0.86301
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 5.40501

Cumulative Model Updates: 35,506
Cumulative Timesteps: 592,340,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 592340788...
Checkpoint 592340788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,188.29140
Policy Entropy: 1.07244
Value Function Loss: 13.02706

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.07367
Value Function Update Magnitude: 0.06567

Collected Steps per Second: 10,923.26204
Overall Steps per Second: 9,344.27469

Timestep Collection Time: 4.57794
Timestep Consumption Time: 0.77358
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.35151

Cumulative Model Updates: 35,509
Cumulative Timesteps: 592,390,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,156.11324
Policy Entropy: 1.07107
Value Function Loss: 12.32054

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.07309
Value Function Update Magnitude: 0.06524

Collected Steps per Second: 11,966.55060
Overall Steps per Second: 10,227.12737

Timestep Collection Time: 4.17982
Timestep Consumption Time: 0.71090
PPO Batch Consumption Time: 0.04307
Total Iteration Time: 4.89072

Cumulative Model Updates: 35,512
Cumulative Timesteps: 592,440,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 592440812...
Checkpoint 592440812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,478.07822
Policy Entropy: 1.08396
Value Function Loss: 11.64518

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.06243
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 11,829.51660
Overall Steps per Second: 10,001.51243

Timestep Collection Time: 4.22672
Timestep Consumption Time: 0.77253
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.99924

Cumulative Model Updates: 35,515
Cumulative Timesteps: 592,490,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389,575.21683
Policy Entropy: 1.08347
Value Function Loss: 11.38098

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.05827

Collected Steps per Second: 11,906.67798
Overall Steps per Second: 10,095.70085

Timestep Collection Time: 4.20067
Timestep Consumption Time: 0.75352
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.95419

Cumulative Model Updates: 35,518
Cumulative Timesteps: 592,540,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 592540828...
Checkpoint 592540828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,271.87042
Policy Entropy: 1.08298
Value Function Loss: 11.40927

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.06863

Collected Steps per Second: 12,379.50717
Overall Steps per Second: 10,338.62339

Timestep Collection Time: 4.04119
Timestep Consumption Time: 0.79775
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 4.83894

Cumulative Model Updates: 35,521
Cumulative Timesteps: 592,590,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,276.99856
Policy Entropy: 1.07966
Value Function Loss: 11.11499

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.06401
Value Function Update Magnitude: 0.06370

Collected Steps per Second: 12,091.27406
Overall Steps per Second: 9,885.31177

Timestep Collection Time: 4.13670
Timestep Consumption Time: 0.92313
PPO Batch Consumption Time: 0.03823
Total Iteration Time: 5.05983

Cumulative Model Updates: 35,524
Cumulative Timesteps: 592,640,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 592640874...
Checkpoint 592640874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,021.97523
Policy Entropy: 1.07633
Value Function Loss: 11.07952

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.07009
Value Function Update Magnitude: 0.07290

Collected Steps per Second: 12,004.05837
Overall Steps per Second: 10,280.02347

Timestep Collection Time: 4.16709
Timestep Consumption Time: 0.69885
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 4.86594

Cumulative Model Updates: 35,527
Cumulative Timesteps: 592,690,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,907.92241
Policy Entropy: 1.08732
Value Function Loss: 10.81951

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.06373
Value Function Update Magnitude: 0.09222

Collected Steps per Second: 11,214.12516
Overall Steps per Second: 9,544.91616

Timestep Collection Time: 4.45920
Timestep Consumption Time: 0.77982
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 5.23902

Cumulative Model Updates: 35,530
Cumulative Timesteps: 592,740,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 592740902...
Checkpoint 592740902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,024.41090
Policy Entropy: 1.09412
Value Function Loss: 11.51732

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.08977

Collected Steps per Second: 11,306.26525
Overall Steps per Second: 9,653.51704

Timestep Collection Time: 4.42268
Timestep Consumption Time: 0.75719
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 5.17987

Cumulative Model Updates: 35,533
Cumulative Timesteps: 592,790,906

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,764.77035
Policy Entropy: 1.09120
Value Function Loss: 11.42628

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.10074

Collected Steps per Second: 11,488.78165
Overall Steps per Second: 9,608.58427

Timestep Collection Time: 4.35381
Timestep Consumption Time: 0.85195
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.20576

Cumulative Model Updates: 35,536
Cumulative Timesteps: 592,840,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 592840926...
Checkpoint 592840926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,744.63641
Policy Entropy: 1.08925
Value Function Loss: 11.51269

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.10385

Collected Steps per Second: 11,274.45033
Overall Steps per Second: 9,665.29235

Timestep Collection Time: 4.43711
Timestep Consumption Time: 0.73873
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.17584

Cumulative Model Updates: 35,539
Cumulative Timesteps: 592,890,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,923.63125
Policy Entropy: 1.10156
Value Function Loss: 11.17075

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.10314

Collected Steps per Second: 10,814.57355
Overall Steps per Second: 9,396.58239

Timestep Collection Time: 4.62487
Timestep Consumption Time: 0.69792
PPO Batch Consumption Time: 0.03849
Total Iteration Time: 5.32279

Cumulative Model Updates: 35,542
Cumulative Timesteps: 592,940,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 592940968...
Checkpoint 592940968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,436.71253
Policy Entropy: 1.09895
Value Function Loss: 11.11366

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.05989
Value Function Update Magnitude: 0.09353

Collected Steps per Second: 11,190.44261
Overall Steps per Second: 9,505.01473

Timestep Collection Time: 4.47024
Timestep Consumption Time: 0.79266
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.26291

Cumulative Model Updates: 35,545
Cumulative Timesteps: 592,990,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,683.08653
Policy Entropy: 1.09830
Value Function Loss: 11.56121

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.09263

Collected Steps per Second: 11,128.50982
Overall Steps per Second: 9,512.10260

Timestep Collection Time: 4.49548
Timestep Consumption Time: 0.76392
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 5.25940

Cumulative Model Updates: 35,548
Cumulative Timesteps: 593,041,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 593041020...
Checkpoint 593041020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,859.46548
Policy Entropy: 1.09549
Value Function Loss: 12.16369

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.08669

Collected Steps per Second: 11,335.98279
Overall Steps per Second: 9,638.24491

Timestep Collection Time: 4.41144
Timestep Consumption Time: 0.77706
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.18850

Cumulative Model Updates: 35,551
Cumulative Timesteps: 593,091,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,338.30860
Policy Entropy: 1.09028
Value Function Loss: 12.52200

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.07328
Value Function Update Magnitude: 0.10120

Collected Steps per Second: 11,300.59353
Overall Steps per Second: 9,611.80809

Timestep Collection Time: 4.42614
Timestep Consumption Time: 0.77767
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.20381

Cumulative Model Updates: 35,554
Cumulative Timesteps: 593,141,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 593141046...
Checkpoint 593141046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,148.78819
Policy Entropy: 1.10767
Value Function Loss: 12.59606

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.14598
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.11530

Collected Steps per Second: 10,993.85340
Overall Steps per Second: 9,560.78212

Timestep Collection Time: 4.54909
Timestep Consumption Time: 0.68187
PPO Batch Consumption Time: 0.03732
Total Iteration Time: 5.23095

Cumulative Model Updates: 35,557
Cumulative Timesteps: 593,191,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,377.02263
Policy Entropy: 1.10540
Value Function Loss: 12.02470

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.10894

Collected Steps per Second: 10,679.85520
Overall Steps per Second: 9,179.83446

Timestep Collection Time: 4.68358
Timestep Consumption Time: 0.76532
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.44890

Cumulative Model Updates: 35,560
Cumulative Timesteps: 593,241,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 593241078...
Checkpoint 593241078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,713.18517
Policy Entropy: 1.09310
Value Function Loss: 12.23284

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.08832

Collected Steps per Second: 10,775.92660
Overall Steps per Second: 9,281.45977

Timestep Collection Time: 4.64257
Timestep Consumption Time: 0.74753
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.39010

Cumulative Model Updates: 35,563
Cumulative Timesteps: 593,291,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445,911.00491
Policy Entropy: 1.09169
Value Function Loss: 12.35846

Mean KL Divergence: 0.03328
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.04303
Value Function Update Magnitude: 0.07443

Collected Steps per Second: 11,320.91267
Overall Steps per Second: 9,557.06625

Timestep Collection Time: 4.41731
Timestep Consumption Time: 0.81526
PPO Batch Consumption Time: 0.04018
Total Iteration Time: 5.23257

Cumulative Model Updates: 35,566
Cumulative Timesteps: 593,341,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 593341114...
Checkpoint 593341114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,466.68262
Policy Entropy: 1.11430
Value Function Loss: 12.50290

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.06345

Collected Steps per Second: 10,975.47942
Overall Steps per Second: 9,400.73757

Timestep Collection Time: 4.55670
Timestep Consumption Time: 0.76331
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.32001

Cumulative Model Updates: 35,569
Cumulative Timesteps: 593,391,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,498.16045
Policy Entropy: 1.10417
Value Function Loss: 12.15534

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.06085

Collected Steps per Second: 10,797.99814
Overall Steps per Second: 9,400.52139

Timestep Collection Time: 4.63215
Timestep Consumption Time: 0.68861
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 5.32077

Cumulative Model Updates: 35,572
Cumulative Timesteps: 593,441,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 593441144...
Checkpoint 593441144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336,460.30492
Policy Entropy: 1.09465
Value Function Loss: 12.11323

Mean KL Divergence: 0.03058
SB3 Clip Fraction: 0.17217
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.05772

Collected Steps per Second: 10,937.00675
Overall Steps per Second: 9,176.24621

Timestep Collection Time: 4.57237
Timestep Consumption Time: 0.87736
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.44972

Cumulative Model Updates: 35,575
Cumulative Timesteps: 593,491,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,024.13326
Policy Entropy: 1.10961
Value Function Loss: 12.53297

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.06563

Collected Steps per Second: 10,621.80156
Overall Steps per Second: 9,286.90453

Timestep Collection Time: 4.70937
Timestep Consumption Time: 0.67692
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.38629

Cumulative Model Updates: 35,578
Cumulative Timesteps: 593,541,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 593541174...
Checkpoint 593541174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417,614.30084
Policy Entropy: 1.11678
Value Function Loss: 12.23159

Mean KL Divergence: 0.02517
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 11,531.92862
Overall Steps per Second: 9,724.47332

Timestep Collection Time: 4.33856
Timestep Consumption Time: 0.80639
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 5.14496

Cumulative Model Updates: 35,581
Cumulative Timesteps: 593,591,206

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417,464.92579
Policy Entropy: 1.08957
Value Function Loss: 11.75006

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.15588
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.06815

Collected Steps per Second: 11,395.69043
Overall Steps per Second: 9,706.34643

Timestep Collection Time: 4.38850
Timestep Consumption Time: 0.76380
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.15230

Cumulative Model Updates: 35,584
Cumulative Timesteps: 593,641,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 593641216...
Checkpoint 593641216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425,607.43417
Policy Entropy: 1.10011
Value Function Loss: 11.09586

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.05814

Collected Steps per Second: 10,869.74150
Overall Steps per Second: 9,458.13905

Timestep Collection Time: 4.59993
Timestep Consumption Time: 0.68653
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.28645

Cumulative Model Updates: 35,587
Cumulative Timesteps: 593,691,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,225.05998
Policy Entropy: 1.10262
Value Function Loss: 10.83780

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.06003

Collected Steps per Second: 11,475.86552
Overall Steps per Second: 9,734.17264

Timestep Collection Time: 4.35732
Timestep Consumption Time: 0.77964
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.13695

Cumulative Model Updates: 35,590
Cumulative Timesteps: 593,741,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 593741220...
Checkpoint 593741220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389,677.06845
Policy Entropy: 1.09186
Value Function Loss: 10.78840

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.05821

Collected Steps per Second: 11,106.05996
Overall Steps per Second: 9,627.93024

Timestep Collection Time: 4.50349
Timestep Consumption Time: 0.69140
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.19489

Cumulative Model Updates: 35,593
Cumulative Timesteps: 593,791,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,275.80918
Policy Entropy: 1.08482
Value Function Loss: 11.47389

Mean KL Divergence: 0.03509
SB3 Clip Fraction: 0.17337
Policy Update Magnitude: 0.04444
Value Function Update Magnitude: 0.07259

Collected Steps per Second: 11,553.21836
Overall Steps per Second: 9,819.58939

Timestep Collection Time: 4.32918
Timestep Consumption Time: 0.76431
PPO Batch Consumption Time: 0.03780
Total Iteration Time: 5.09349

Cumulative Model Updates: 35,596
Cumulative Timesteps: 593,841,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 593841252...
Checkpoint 593841252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364,736.89515
Policy Entropy: 1.10328
Value Function Loss: 11.35261

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.08787

Collected Steps per Second: 11,019.71524
Overall Steps per Second: 9,467.23158

Timestep Collection Time: 4.53805
Timestep Consumption Time: 0.74417
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 5.28222

Cumulative Model Updates: 35,599
Cumulative Timesteps: 593,891,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,258.09791
Policy Entropy: 1.09604
Value Function Loss: 11.46261

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.07981

Collected Steps per Second: 11,367.89005
Overall Steps per Second: 9,797.19033

Timestep Collection Time: 4.40099
Timestep Consumption Time: 0.70557
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.10657

Cumulative Model Updates: 35,602
Cumulative Timesteps: 593,941,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 593941290...
Checkpoint 593941290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,836.86426
Policy Entropy: 1.08424
Value Function Loss: 11.00347

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.07656

Collected Steps per Second: 11,300.70715
Overall Steps per Second: 9,547.37033

Timestep Collection Time: 4.42698
Timestep Consumption Time: 0.81300
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.23998

Cumulative Model Updates: 35,605
Cumulative Timesteps: 593,991,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,623.26264
Policy Entropy: 1.09955
Value Function Loss: 11.32618

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.06657

Collected Steps per Second: 11,434.24625
Overall Steps per Second: 9,856.07804

Timestep Collection Time: 4.37300
Timestep Consumption Time: 0.70021
PPO Batch Consumption Time: 0.03822
Total Iteration Time: 5.07321

Cumulative Model Updates: 35,608
Cumulative Timesteps: 594,041,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 594041320...
Checkpoint 594041320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,029.84326
Policy Entropy: 1.10030
Value Function Loss: 11.39981

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 10,727.55256
Overall Steps per Second: 9,203.64704

Timestep Collection Time: 4.66369
Timestep Consumption Time: 0.77220
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.43589

Cumulative Model Updates: 35,611
Cumulative Timesteps: 594,091,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,923.44586
Policy Entropy: 1.08815
Value Function Loss: 11.75782

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 11,116.11338
Overall Steps per Second: 9,574.51537

Timestep Collection Time: 4.49995
Timestep Consumption Time: 0.72454
PPO Batch Consumption Time: 0.03784
Total Iteration Time: 5.22449

Cumulative Model Updates: 35,614
Cumulative Timesteps: 594,141,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 594141372...
Checkpoint 594141372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403,360.06751
Policy Entropy: 1.07328
Value Function Loss: 12.15268

Mean KL Divergence: 0.03299
SB3 Clip Fraction: 0.18132
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.05750

Collected Steps per Second: 11,575.67104
Overall Steps per Second: 9,706.52691

Timestep Collection Time: 4.32027
Timestep Consumption Time: 0.83194
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.15220

Cumulative Model Updates: 35,617
Cumulative Timesteps: 594,191,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,440.88602
Policy Entropy: 1.09095
Value Function Loss: 12.05079

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 11,033.60637
Overall Steps per Second: 9,477.25811

Timestep Collection Time: 4.53270
Timestep Consumption Time: 0.74436
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.27705

Cumulative Model Updates: 35,620
Cumulative Timesteps: 594,241,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 594241394...
Checkpoint 594241394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,217.60929
Policy Entropy: 1.09385
Value Function Loss: 11.83015

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.07536

Collected Steps per Second: 11,109.14865
Overall Steps per Second: 9,657.14098

Timestep Collection Time: 4.50115
Timestep Consumption Time: 0.67677
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.17793

Cumulative Model Updates: 35,623
Cumulative Timesteps: 594,291,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405,692.19835
Policy Entropy: 1.09317
Value Function Loss: 11.48487

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.07364

Collected Steps per Second: 11,308.46869
Overall Steps per Second: 9,556.20123

Timestep Collection Time: 4.42288
Timestep Consumption Time: 0.81100
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.23388

Cumulative Model Updates: 35,626
Cumulative Timesteps: 594,341,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 594341414...
Checkpoint 594341414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,413.36475
Policy Entropy: 1.09336
Value Function Loss: 11.85427

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.08064

Collected Steps per Second: 10,615.59880
Overall Steps per Second: 9,283.57639

Timestep Collection Time: 4.71062
Timestep Consumption Time: 0.67589
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 5.38650

Cumulative Model Updates: 35,629
Cumulative Timesteps: 594,391,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,288.51843
Policy Entropy: 1.10196
Value Function Loss: 11.37590

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.07690

Collected Steps per Second: 10,997.90725
Overall Steps per Second: 9,395.58307

Timestep Collection Time: 4.54741
Timestep Consumption Time: 0.77552
PPO Batch Consumption Time: 0.03349
Total Iteration Time: 5.32293

Cumulative Model Updates: 35,632
Cumulative Timesteps: 594,441,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 594441432...
Checkpoint 594441432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,701.54954
Policy Entropy: 1.10239
Value Function Loss: 11.22692

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.07522

Collected Steps per Second: 10,969.84341
Overall Steps per Second: 9,288.35513

Timestep Collection Time: 4.55996
Timestep Consumption Time: 0.82550
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.38545

Cumulative Model Updates: 35,635
Cumulative Timesteps: 594,491,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348,880.54778
Policy Entropy: 1.10899
Value Function Loss: 10.94510

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.06732

Collected Steps per Second: 11,287.99713
Overall Steps per Second: 9,538.94392

Timestep Collection Time: 4.43002
Timestep Consumption Time: 0.81228
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.24230

Cumulative Model Updates: 35,638
Cumulative Timesteps: 594,541,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 594541460...
Checkpoint 594541460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366,478.70035
Policy Entropy: 1.11509
Value Function Loss: 11.01238

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.07581

Collected Steps per Second: 10,823.88988
Overall Steps per Second: 9,230.73203

Timestep Collection Time: 4.61997
Timestep Consumption Time: 0.79737
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 5.41734

Cumulative Model Updates: 35,641
Cumulative Timesteps: 594,591,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,909.59931
Policy Entropy: 1.11130
Value Function Loss: 10.93068

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.08939

Collected Steps per Second: 10,810.09305
Overall Steps per Second: 9,305.62267

Timestep Collection Time: 4.62549
Timestep Consumption Time: 0.74782
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 5.37331

Cumulative Model Updates: 35,644
Cumulative Timesteps: 594,641,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 594641468...
Checkpoint 594641468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,029.52235
Policy Entropy: 1.11312
Value Function Loss: 11.30334

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.08879

Collected Steps per Second: 11,130.70209
Overall Steps per Second: 9,467.53903

Timestep Collection Time: 4.49442
Timestep Consumption Time: 0.78953
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 5.28395

Cumulative Model Updates: 35,647
Cumulative Timesteps: 594,691,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,875.93774
Policy Entropy: 1.12301
Value Function Loss: 11.58489

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.09122

Collected Steps per Second: 12,084.28415
Overall Steps per Second: 10,367.44512

Timestep Collection Time: 4.13943
Timestep Consumption Time: 0.68549
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 4.82491

Cumulative Model Updates: 35,650
Cumulative Timesteps: 594,741,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 594741516...
Checkpoint 594741516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,376.24190
Policy Entropy: 1.12267
Value Function Loss: 11.41937

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.08010

Collected Steps per Second: 11,868.79803
Overall Steps per Second: 10,071.52819

Timestep Collection Time: 4.21273
Timestep Consumption Time: 0.75176
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.96449

Cumulative Model Updates: 35,653
Cumulative Timesteps: 594,791,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,731.76603
Policy Entropy: 1.10873
Value Function Loss: 10.96827

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.07987

Collected Steps per Second: 11,954.82872
Overall Steps per Second: 10,106.52600

Timestep Collection Time: 4.18258
Timestep Consumption Time: 0.76492
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.94750

Cumulative Model Updates: 35,656
Cumulative Timesteps: 594,841,518

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 594841518...
Checkpoint 594841518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,882.58874
Policy Entropy: 1.10327
Value Function Loss: 10.84683

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 11,146.60781
Overall Steps per Second: 9,568.31123

Timestep Collection Time: 4.48621
Timestep Consumption Time: 0.74000
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.22621

Cumulative Model Updates: 35,659
Cumulative Timesteps: 594,891,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,995.68374
Policy Entropy: 1.12132
Value Function Loss: 10.86223

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.07840

Collected Steps per Second: 11,191.34814
Overall Steps per Second: 9,442.49935

Timestep Collection Time: 4.46988
Timestep Consumption Time: 0.82787
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 5.29775

Cumulative Model Updates: 35,662
Cumulative Timesteps: 594,941,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 594941548...
Checkpoint 594941548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,336.74028
Policy Entropy: 1.13690
Value Function Loss: 11.02173

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.07336

Collected Steps per Second: 11,688.74434
Overall Steps per Second: 10,026.17898

Timestep Collection Time: 4.27984
Timestep Consumption Time: 0.70969
PPO Batch Consumption Time: 0.03940
Total Iteration Time: 4.98954

Cumulative Model Updates: 35,665
Cumulative Timesteps: 594,991,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,640.20138
Policy Entropy: 1.10889
Value Function Loss: 11.36170

Mean KL Divergence: 0.03831
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.08207

Collected Steps per Second: 11,542.30457
Overall Steps per Second: 9,746.80023

Timestep Collection Time: 4.33432
Timestep Consumption Time: 0.79845
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.13276

Cumulative Model Updates: 35,668
Cumulative Timesteps: 595,041,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 595041602...
Checkpoint 595041602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,301.21268
Policy Entropy: 1.12438
Value Function Loss: 11.56075

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.09107

Collected Steps per Second: 11,319.13342
Overall Steps per Second: 9,563.47174

Timestep Collection Time: 4.41924
Timestep Consumption Time: 0.81128
PPO Batch Consumption Time: 0.04001
Total Iteration Time: 5.23053

Cumulative Model Updates: 35,671
Cumulative Timesteps: 595,091,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402,843.18875
Policy Entropy: 1.11722
Value Function Loss: 11.94048

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.08630

Collected Steps per Second: 11,092.73981
Overall Steps per Second: 9,583.19999

Timestep Collection Time: 4.50745
Timestep Consumption Time: 0.71001
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.21746

Cumulative Model Updates: 35,674
Cumulative Timesteps: 595,141,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 595141624...
Checkpoint 595141624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,727.57366
Policy Entropy: 1.11067
Value Function Loss: 11.91826

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.08186

Collected Steps per Second: 11,460.88028
Overall Steps per Second: 9,718.34027

Timestep Collection Time: 4.36441
Timestep Consumption Time: 0.78256
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.14697

Cumulative Model Updates: 35,677
Cumulative Timesteps: 595,191,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417,082.78937
Policy Entropy: 1.11479
Value Function Loss: 12.76765

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.08646

Collected Steps per Second: 10,796.78784
Overall Steps per Second: 9,393.30461

Timestep Collection Time: 4.63379
Timestep Consumption Time: 0.69235
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.32613

Cumulative Model Updates: 35,680
Cumulative Timesteps: 595,241,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 595241674...
Checkpoint 595241674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,999.48088
Policy Entropy: 1.12654
Value Function Loss: 12.97867

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.08308

Collected Steps per Second: 10,818.74654
Overall Steps per Second: 9,261.41819

Timestep Collection Time: 4.62309
Timestep Consumption Time: 0.77738
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 5.40047

Cumulative Model Updates: 35,683
Cumulative Timesteps: 595,291,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,959.20550
Policy Entropy: 1.13059
Value Function Loss: 13.03469

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.07446

Collected Steps per Second: 10,909.61804
Overall Steps per Second: 9,348.75914

Timestep Collection Time: 4.58330
Timestep Consumption Time: 0.76522
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.34852

Cumulative Model Updates: 35,686
Cumulative Timesteps: 595,341,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 595341692...
Checkpoint 595341692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,620.92437
Policy Entropy: 1.10570
Value Function Loss: 12.32099

Mean KL Divergence: 0.03441
SB3 Clip Fraction: 0.16566
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.06728

Collected Steps per Second: 11,457.83751
Overall Steps per Second: 9,761.02205

Timestep Collection Time: 4.36417
Timestep Consumption Time: 0.75865
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.12282

Cumulative Model Updates: 35,689
Cumulative Timesteps: 595,391,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,984.80060
Policy Entropy: 1.12223
Value Function Loss: 11.84113

Mean KL Divergence: 0.02586
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.05490

Collected Steps per Second: 11,154.15242
Overall Steps per Second: 9,545.95241

Timestep Collection Time: 4.48479
Timestep Consumption Time: 0.75555
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.24034

Cumulative Model Updates: 35,692
Cumulative Timesteps: 595,441,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 595441720...
Checkpoint 595441720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,598.16640
Policy Entropy: 1.12197
Value Function Loss: 11.36634

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.04945

Collected Steps per Second: 11,007.10209
Overall Steps per Second: 9,572.52543

Timestep Collection Time: 4.54470
Timestep Consumption Time: 0.68109
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.22579

Cumulative Model Updates: 35,695
Cumulative Timesteps: 595,491,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383,629.27072
Policy Entropy: 1.10576
Value Function Loss: 11.17613

Mean KL Divergence: 0.02620
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.04980

Collected Steps per Second: 10,778.41165
Overall Steps per Second: 9,230.11763

Timestep Collection Time: 4.63946
Timestep Consumption Time: 0.77824
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 5.41770

Cumulative Model Updates: 35,698
Cumulative Timesteps: 595,541,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 595541750...
Checkpoint 595541750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,295.22161
Policy Entropy: 1.10275
Value Function Loss: 10.91670

Mean KL Divergence: 0.02802
SB3 Clip Fraction: 0.15974
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 10,829.75704
Overall Steps per Second: 9,311.57440

Timestep Collection Time: 4.61728
Timestep Consumption Time: 0.75281
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.37009

Cumulative Model Updates: 35,701
Cumulative Timesteps: 595,591,754

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439,380.81349
Policy Entropy: 1.11175
Value Function Loss: 10.95618

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.04096

Collected Steps per Second: 11,085.52068
Overall Steps per Second: 9,430.62898

Timestep Collection Time: 4.51327
Timestep Consumption Time: 0.79199
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.30527

Cumulative Model Updates: 35,704
Cumulative Timesteps: 595,641,786

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 595641786...
Checkpoint 595641786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,864.62641
Policy Entropy: 1.12400
Value Function Loss: 11.68009

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.04563

Collected Steps per Second: 10,913.34673
Overall Steps per Second: 9,336.87490

Timestep Collection Time: 4.58393
Timestep Consumption Time: 0.77397
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.35790

Cumulative Model Updates: 35,707
Cumulative Timesteps: 595,691,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,620.43062
Policy Entropy: 1.10238
Value Function Loss: 11.75732

Mean KL Divergence: 0.02952
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.04762

Collected Steps per Second: 11,065.71360
Overall Steps per Second: 9,555.24924

Timestep Collection Time: 4.51882
Timestep Consumption Time: 0.71432
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.23314

Cumulative Model Updates: 35,710
Cumulative Timesteps: 595,741,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 595741816...
Checkpoint 595741816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,461.94009
Policy Entropy: 1.12347
Value Function Loss: 12.39474

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.04177

Collected Steps per Second: 10,652.35186
Overall Steps per Second: 9,140.08438

Timestep Collection Time: 4.69474
Timestep Consumption Time: 0.77677
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.47150

Cumulative Model Updates: 35,713
Cumulative Timesteps: 595,791,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379,850.55408
Policy Entropy: 1.12345
Value Function Loss: 11.67937

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.04472

Collected Steps per Second: 11,084.10296
Overall Steps per Second: 9,534.03541

Timestep Collection Time: 4.51259
Timestep Consumption Time: 0.73367
PPO Batch Consumption Time: 0.03389
Total Iteration Time: 5.24626

Cumulative Model Updates: 35,716
Cumulative Timesteps: 595,841,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 595841844...
Checkpoint 595841844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,002.83359
Policy Entropy: 1.10943
Value Function Loss: 11.76889

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.04589

Collected Steps per Second: 11,493.22755
Overall Steps per Second: 9,760.08471

Timestep Collection Time: 4.35300
Timestep Consumption Time: 0.77298
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.12598

Cumulative Model Updates: 35,719
Cumulative Timesteps: 595,891,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,265.57403
Policy Entropy: 1.10662
Value Function Loss: 11.50386

Mean KL Divergence: 0.02837
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.04220

Collected Steps per Second: 11,351.94375
Overall Steps per Second: 9,754.55172

Timestep Collection Time: 4.40682
Timestep Consumption Time: 0.72166
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.12848

Cumulative Model Updates: 35,722
Cumulative Timesteps: 595,941,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 595941900...
Checkpoint 595941900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,325.15593
Policy Entropy: 1.11348
Value Function Loss: 11.92983

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.04792

Collected Steps per Second: 11,295.76635
Overall Steps per Second: 9,817.76025

Timestep Collection Time: 4.42838
Timestep Consumption Time: 0.66667
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.09505

Cumulative Model Updates: 35,725
Cumulative Timesteps: 595,991,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,253.21116
Policy Entropy: 1.12511
Value Function Loss: 12.24019

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.14741
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.04456

Collected Steps per Second: 11,270.25299
Overall Steps per Second: 9,552.27962

Timestep Collection Time: 4.43876
Timestep Consumption Time: 0.79831
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.23707

Cumulative Model Updates: 35,728
Cumulative Timesteps: 596,041,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 596041948...
Checkpoint 596041948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,316.63699
Policy Entropy: 1.10226
Value Function Loss: 11.83521

Mean KL Divergence: 0.03485
SB3 Clip Fraction: 0.16030
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.04399

Collected Steps per Second: 10,828.16713
Overall Steps per Second: 9,345.76366

Timestep Collection Time: 4.62017
Timestep Consumption Time: 0.73284
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.35301

Cumulative Model Updates: 35,731
Cumulative Timesteps: 596,091,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,789.85247
Policy Entropy: 1.10941
Value Function Loss: 12.23925

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.05111

Collected Steps per Second: 11,308.58079
Overall Steps per Second: 9,596.00059

Timestep Collection Time: 4.42266
Timestep Consumption Time: 0.78930
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.21196

Cumulative Model Updates: 35,734
Cumulative Timesteps: 596,141,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 596141990...
Checkpoint 596141990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,801.65582
Policy Entropy: 1.10917
Value Function Loss: 12.37835

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.04429
Value Function Update Magnitude: 0.04959

Collected Steps per Second: 11,065.52439
Overall Steps per Second: 9,497.92618

Timestep Collection Time: 4.52035
Timestep Consumption Time: 0.74607
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.26641

Cumulative Model Updates: 35,737
Cumulative Timesteps: 596,192,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,650.71889
Policy Entropy: 1.09783
Value Function Loss: 12.24560

Mean KL Divergence: 0.02576
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.04398

Collected Steps per Second: 11,114.34147
Overall Steps per Second: 9,625.24513

Timestep Collection Time: 4.50139
Timestep Consumption Time: 0.69640
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.19779

Cumulative Model Updates: 35,740
Cumulative Timesteps: 596,242,040

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 596242040...
Checkpoint 596242040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435,664.42973
Policy Entropy: 1.08621
Value Function Loss: 11.57346

Mean KL Divergence: 0.02692
SB3 Clip Fraction: 0.16931
Policy Update Magnitude: 0.04019
Value Function Update Magnitude: 0.05234

Collected Steps per Second: 11,367.17671
Overall Steps per Second: 9,627.91465

Timestep Collection Time: 4.40056
Timestep Consumption Time: 0.79495
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 5.19552

Cumulative Model Updates: 35,743
Cumulative Timesteps: 596,292,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,765.90289
Policy Entropy: 1.09430
Value Function Loss: 11.54227

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.05444

Collected Steps per Second: 11,409.86201
Overall Steps per Second: 9,721.45114

Timestep Collection Time: 4.38410
Timestep Consumption Time: 0.76143
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.14553

Cumulative Model Updates: 35,746
Cumulative Timesteps: 596,342,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 596342084...
Checkpoint 596342084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,673.59548
Policy Entropy: 1.09221
Value Function Loss: 11.55300

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.04789

Collected Steps per Second: 10,867.37505
Overall Steps per Second: 9,316.39633

Timestep Collection Time: 4.60258
Timestep Consumption Time: 0.76623
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.36881

Cumulative Model Updates: 35,749
Cumulative Timesteps: 596,392,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,290.30288
Policy Entropy: 1.09602
Value Function Loss: 11.80367

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.04397

Collected Steps per Second: 10,779.22817
Overall Steps per Second: 9,260.93818

Timestep Collection Time: 4.64059
Timestep Consumption Time: 0.76080
PPO Batch Consumption Time: 0.03887
Total Iteration Time: 5.40140

Cumulative Model Updates: 35,752
Cumulative Timesteps: 596,442,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 596442124...
Checkpoint 596442124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,653.39221
Policy Entropy: 1.08951
Value Function Loss: 11.24071

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.05722

Collected Steps per Second: 10,833.49299
Overall Steps per Second: 9,440.31053

Timestep Collection Time: 4.61679
Timestep Consumption Time: 0.68134
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.29813

Cumulative Model Updates: 35,755
Cumulative Timesteps: 596,492,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,724.47464
Policy Entropy: 1.10892
Value Function Loss: 11.31547

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.06911

Collected Steps per Second: 10,876.08211
Overall Steps per Second: 9,335.65138

Timestep Collection Time: 4.59908
Timestep Consumption Time: 0.75887
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.35796

Cumulative Model Updates: 35,758
Cumulative Timesteps: 596,542,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 596542160...
Checkpoint 596542160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,791.63679
Policy Entropy: 1.11178
Value Function Loss: 11.50787

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.06594

Collected Steps per Second: 11,007.02605
Overall Steps per Second: 9,469.79305

Timestep Collection Time: 4.54510
Timestep Consumption Time: 0.73781
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.28290

Cumulative Model Updates: 35,761
Cumulative Timesteps: 596,592,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,666.96278
Policy Entropy: 1.09824
Value Function Loss: 11.89873

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.06541

Collected Steps per Second: 11,064.93997
Overall Steps per Second: 9,450.95717

Timestep Collection Time: 4.52040
Timestep Consumption Time: 0.77197
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 5.29237

Cumulative Model Updates: 35,764
Cumulative Timesteps: 596,642,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 596642206...
Checkpoint 596642206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453,298.06311
Policy Entropy: 1.08226
Value Function Loss: 11.54709

Mean KL Divergence: 0.02593
SB3 Clip Fraction: 0.14837
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.06385

Collected Steps per Second: 11,010.30621
Overall Steps per Second: 9,316.18724

Timestep Collection Time: 4.54283
Timestep Consumption Time: 0.82610
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.36893

Cumulative Model Updates: 35,767
Cumulative Timesteps: 596,692,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,442.91128
Policy Entropy: 1.09172
Value Function Loss: 10.99553

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.05373

Collected Steps per Second: 11,062.39036
Overall Steps per Second: 9,416.05897

Timestep Collection Time: 4.52000
Timestep Consumption Time: 0.79029
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.31029

Cumulative Model Updates: 35,770
Cumulative Timesteps: 596,742,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 596742226...
Checkpoint 596742226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,372.72038
Policy Entropy: 1.10577
Value Function Loss: 10.92780

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.04594

Collected Steps per Second: 10,891.45456
Overall Steps per Second: 9,290.69147

Timestep Collection Time: 4.59167
Timestep Consumption Time: 0.79113
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.38281

Cumulative Model Updates: 35,773
Cumulative Timesteps: 596,792,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,614.52710
Policy Entropy: 1.08114
Value Function Loss: 11.27906

Mean KL Divergence: 0.03899
SB3 Clip Fraction: 0.17676
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.04650

Collected Steps per Second: 10,804.79125
Overall Steps per Second: 9,214.08263

Timestep Collection Time: 4.62887
Timestep Consumption Time: 0.79912
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.42800

Cumulative Model Updates: 35,776
Cumulative Timesteps: 596,842,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 596842250...
Checkpoint 596842250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,812.41578
Policy Entropy: 1.09678
Value Function Loss: 11.61961

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.05008

Collected Steps per Second: 11,249.89717
Overall Steps per Second: 9,520.03557

Timestep Collection Time: 4.44680
Timestep Consumption Time: 0.80802
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.25481

Cumulative Model Updates: 35,779
Cumulative Timesteps: 596,892,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,932.22049
Policy Entropy: 1.10111
Value Function Loss: 11.54133

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.14893
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.04841

Collected Steps per Second: 10,482.62797
Overall Steps per Second: 8,907.52886

Timestep Collection Time: 4.77189
Timestep Consumption Time: 0.84380
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.61570

Cumulative Model Updates: 35,782
Cumulative Timesteps: 596,942,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 596942298...
Checkpoint 596942298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,059.70378
Policy Entropy: 1.08783
Value Function Loss: 11.42944

Mean KL Divergence: 0.03061
SB3 Clip Fraction: 0.15567
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.04147

Collected Steps per Second: 11,726.03344
Overall Steps per Second: 10,108.62814

Timestep Collection Time: 4.26572
Timestep Consumption Time: 0.68253
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 4.94825

Cumulative Model Updates: 35,785
Cumulative Timesteps: 596,992,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,096.93337
Policy Entropy: 1.10230
Value Function Loss: 11.53375

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.03940

Collected Steps per Second: 11,986.71409
Overall Steps per Second: 10,067.29020

Timestep Collection Time: 4.17212
Timestep Consumption Time: 0.79545
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 4.96757

Cumulative Model Updates: 35,788
Cumulative Timesteps: 597,042,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 597042328...
Checkpoint 597042328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,138.15305
Policy Entropy: 1.10280
Value Function Loss: 11.58515

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.04128

Collected Steps per Second: 11,493.02858
Overall Steps per Second: 9,739.23368

Timestep Collection Time: 4.35064
Timestep Consumption Time: 0.78344
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.13408

Cumulative Model Updates: 35,791
Cumulative Timesteps: 597,092,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,485.31476
Policy Entropy: 1.08458
Value Function Loss: 11.69014

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.04568

Collected Steps per Second: 11,998.63716
Overall Steps per Second: 10,034.55202

Timestep Collection Time: 4.16747
Timestep Consumption Time: 0.81571
PPO Batch Consumption Time: 0.03995
Total Iteration Time: 4.98318

Cumulative Model Updates: 35,794
Cumulative Timesteps: 597,142,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 597142334...
Checkpoint 597142334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,104.48083
Policy Entropy: 1.07485
Value Function Loss: 11.92131

Mean KL Divergence: 0.02650
SB3 Clip Fraction: 0.16095
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.04928

Collected Steps per Second: 11,783.11585
Overall Steps per Second: 9,914.53908

Timestep Collection Time: 4.24489
Timestep Consumption Time: 0.80003
PPO Batch Consumption Time: 0.03270
Total Iteration Time: 5.04491

Cumulative Model Updates: 35,797
Cumulative Timesteps: 597,192,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,110.50269
Policy Entropy: 1.08524
Value Function Loss: 11.96874

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.05060

Collected Steps per Second: 11,427.65393
Overall Steps per Second: 9,863.74925

Timestep Collection Time: 4.37588
Timestep Consumption Time: 0.69380
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.06967

Cumulative Model Updates: 35,800
Cumulative Timesteps: 597,242,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 597242358...
Checkpoint 597242358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,073.60773
Policy Entropy: 1.10296
Value Function Loss: 11.83229

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.05202

Collected Steps per Second: 11,200.44753
Overall Steps per Second: 9,539.54087

Timestep Collection Time: 4.46679
Timestep Consumption Time: 0.77770
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.24449

Cumulative Model Updates: 35,803
Cumulative Timesteps: 597,292,388

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,047.69352
Policy Entropy: 1.08733
Value Function Loss: 11.79656

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.04621

Collected Steps per Second: 11,100.09712
Overall Steps per Second: 9,485.63482

Timestep Collection Time: 4.50609
Timestep Consumption Time: 0.76694
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.27303

Cumulative Model Updates: 35,806
Cumulative Timesteps: 597,342,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 597342406...
Checkpoint 597342406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,726.73035
Policy Entropy: 1.08278
Value Function Loss: 11.51042

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.04274

Collected Steps per Second: 11,264.19477
Overall Steps per Second: 9,583.58444

Timestep Collection Time: 4.43884
Timestep Consumption Time: 0.77841
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 5.21725

Cumulative Model Updates: 35,809
Cumulative Timesteps: 597,392,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,261.33086
Policy Entropy: 1.09616
Value Function Loss: 11.86220

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.04321

Collected Steps per Second: 11,201.90005
Overall Steps per Second: 9,597.23612

Timestep Collection Time: 4.46531
Timestep Consumption Time: 0.74660
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 5.21192

Cumulative Model Updates: 35,812
Cumulative Timesteps: 597,442,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 597442426...
Checkpoint 597442426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,769.23208
Policy Entropy: 1.10290
Value Function Loss: 11.42806

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.04194

Collected Steps per Second: 11,130.24877
Overall Steps per Second: 9,550.32967

Timestep Collection Time: 4.49370
Timestep Consumption Time: 0.74340
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.23710

Cumulative Model Updates: 35,815
Cumulative Timesteps: 597,492,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,523.31290
Policy Entropy: 1.08507
Value Function Loss: 11.47519

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.07395

Collected Steps per Second: 11,073.89042
Overall Steps per Second: 9,491.85087

Timestep Collection Time: 4.51711
Timestep Consumption Time: 0.75288
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 5.26999

Cumulative Model Updates: 35,818
Cumulative Timesteps: 597,542,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 597542464...
Checkpoint 597542464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,851.05319
Policy Entropy: 1.07619
Value Function Loss: 11.10139

Mean KL Divergence: 0.03119
SB3 Clip Fraction: 0.15301
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.06791

Collected Steps per Second: 11,106.72683
Overall Steps per Second: 9,521.37043

Timestep Collection Time: 4.50448
Timestep Consumption Time: 0.75002
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 5.25450

Cumulative Model Updates: 35,821
Cumulative Timesteps: 597,592,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,454.60106
Policy Entropy: 1.08804
Value Function Loss: 10.89264

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.06707

Collected Steps per Second: 11,076.36642
Overall Steps per Second: 9,469.43230

Timestep Collection Time: 4.51484
Timestep Consumption Time: 0.76615
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.28099

Cumulative Model Updates: 35,824
Cumulative Timesteps: 597,642,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 597642502...
Checkpoint 597642502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,197.85872
Policy Entropy: 1.08932
Value Function Loss: 10.84256

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.07119

Collected Steps per Second: 11,042.62604
Overall Steps per Second: 9,484.04019

Timestep Collection Time: 4.53044
Timestep Consumption Time: 0.74452
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.27497

Cumulative Model Updates: 35,827
Cumulative Timesteps: 597,692,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,251.99304
Policy Entropy: 1.08616
Value Function Loss: 10.78835

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.09122

Collected Steps per Second: 11,093.11730
Overall Steps per Second: 9,670.81925

Timestep Collection Time: 4.50982
Timestep Consumption Time: 0.66326
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.17309

Cumulative Model Updates: 35,830
Cumulative Timesteps: 597,742,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 597742558...
Checkpoint 597742558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,408.75783
Policy Entropy: 1.08329
Value Function Loss: 11.33601

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.06180
Value Function Update Magnitude: 0.09392

Collected Steps per Second: 10,698.04097
Overall Steps per Second: 9,231.29276

Timestep Collection Time: 4.67487
Timestep Consumption Time: 0.74278
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.41766

Cumulative Model Updates: 35,833
Cumulative Timesteps: 597,792,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,008.96288
Policy Entropy: 1.08360
Value Function Loss: 11.58078

Mean KL Divergence: 0.02532
SB3 Clip Fraction: 0.15453
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.09027

Collected Steps per Second: 10,973.32411
Overall Steps per Second: 9,376.59885

Timestep Collection Time: 4.55760
Timestep Consumption Time: 0.77611
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.33370

Cumulative Model Updates: 35,836
Cumulative Timesteps: 597,842,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 597842582...
Checkpoint 597842582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,687.85405
Policy Entropy: 1.08838
Value Function Loss: 11.52197

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.07893

Collected Steps per Second: 10,869.95107
Overall Steps per Second: 9,281.42807

Timestep Collection Time: 4.60020
Timestep Consumption Time: 0.78733
PPO Batch Consumption Time: 0.03373
Total Iteration Time: 5.38753

Cumulative Model Updates: 35,839
Cumulative Timesteps: 597,892,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,750.00840
Policy Entropy: 1.08590
Value Function Loss: 10.95824

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 11,158.23367
Overall Steps per Second: 9,492.19634

Timestep Collection Time: 4.48297
Timestep Consumption Time: 0.78683
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.26980

Cumulative Model Updates: 35,842
Cumulative Timesteps: 597,942,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 597942608...
Checkpoint 597942608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,646.20937
Policy Entropy: 1.07145
Value Function Loss: 10.29370

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.11125

Collected Steps per Second: 10,639.82252
Overall Steps per Second: 9,283.67968

Timestep Collection Time: 4.70008
Timestep Consumption Time: 0.68658
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.38666

Cumulative Model Updates: 35,845
Cumulative Timesteps: 597,992,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,905.53638
Policy Entropy: 1.06675
Value Function Loss: 10.72876

Mean KL Divergence: 0.03544
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.10946

Collected Steps per Second: 10,966.11778
Overall Steps per Second: 9,335.92417

Timestep Collection Time: 4.56242
Timestep Consumption Time: 0.79667
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 5.35908

Cumulative Model Updates: 35,848
Cumulative Timesteps: 598,042,648

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 598042648...
Checkpoint 598042648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,669.03438
Policy Entropy: 1.08348
Value Function Loss: 10.54933

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.10268

Collected Steps per Second: 10,464.73118
Overall Steps per Second: 9,186.25504

Timestep Collection Time: 4.78006
Timestep Consumption Time: 0.66525
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.44531

Cumulative Model Updates: 35,851
Cumulative Timesteps: 598,092,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,038.16913
Policy Entropy: 1.07650
Value Function Loss: 10.57384

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.09556

Collected Steps per Second: 11,339.95221
Overall Steps per Second: 9,629.91707

Timestep Collection Time: 4.41060
Timestep Consumption Time: 0.78321
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.19381

Cumulative Model Updates: 35,854
Cumulative Timesteps: 598,142,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 598142686...
Checkpoint 598142686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,497.22709
Policy Entropy: 1.07657
Value Function Loss: 10.49810

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 11,374.39879
Overall Steps per Second: 9,867.91705

Timestep Collection Time: 4.39619
Timestep Consumption Time: 0.67114
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.06733

Cumulative Model Updates: 35,857
Cumulative Timesteps: 598,192,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,306.53894
Policy Entropy: 1.08995
Value Function Loss: 11.26388

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.11369
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.06729

Collected Steps per Second: 11,382.62274
Overall Steps per Second: 9,679.91209

Timestep Collection Time: 4.39442
Timestep Consumption Time: 0.77298
PPO Batch Consumption Time: 0.04177
Total Iteration Time: 5.16740

Cumulative Model Updates: 35,860
Cumulative Timesteps: 598,242,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 598242710...
Checkpoint 598242710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,445.03046
Policy Entropy: 1.09637
Value Function Loss: 11.41673

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.07580

Collected Steps per Second: 11,131.35666
Overall Steps per Second: 9,549.80276

Timestep Collection Time: 4.49289
Timestep Consumption Time: 0.74407
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.23697

Cumulative Model Updates: 35,863
Cumulative Timesteps: 598,292,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,203.54733
Policy Entropy: 1.09788
Value Function Loss: 11.44709

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.07497

Collected Steps per Second: 11,270.61123
Overall Steps per Second: 9,750.65856

Timestep Collection Time: 4.43791
Timestep Consumption Time: 0.69179
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 5.12970

Cumulative Model Updates: 35,866
Cumulative Timesteps: 598,342,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 598342740...
Checkpoint 598342740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,526.80477
Policy Entropy: 1.09179
Value Function Loss: 10.95788

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.06844
Value Function Update Magnitude: 0.07858

Collected Steps per Second: 11,011.44178
Overall Steps per Second: 9,407.67298

Timestep Collection Time: 4.54291
Timestep Consumption Time: 0.77445
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.31736

Cumulative Model Updates: 35,869
Cumulative Timesteps: 598,392,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,485.90857
Policy Entropy: 1.10710
Value Function Loss: 10.54658

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.08615

Collected Steps per Second: 10,969.17820
Overall Steps per Second: 9,542.63607

Timestep Collection Time: 4.55877
Timestep Consumption Time: 0.68150
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.24027

Cumulative Model Updates: 35,872
Cumulative Timesteps: 598,442,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 598442770...
Checkpoint 598442770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,156.01280
Policy Entropy: 1.11594
Value Function Loss: 10.40987

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.15181
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.07130

Collected Steps per Second: 11,236.00025
Overall Steps per Second: 9,564.66890

Timestep Collection Time: 4.45069
Timestep Consumption Time: 0.77771
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.22841

Cumulative Model Updates: 35,875
Cumulative Timesteps: 598,492,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,719.80957
Policy Entropy: 1.09569
Value Function Loss: 10.29043

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.06727

Collected Steps per Second: 11,261.73176
Overall Steps per Second: 9,754.90518

Timestep Collection Time: 4.44230
Timestep Consumption Time: 0.68620
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.12850

Cumulative Model Updates: 35,878
Cumulative Timesteps: 598,542,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 598542806...
Checkpoint 598542806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,321.87209
Policy Entropy: 1.09558
Value Function Loss: 10.77008

Mean KL Divergence: 0.02649
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.06206

Collected Steps per Second: 11,245.51488
Overall Steps per Second: 9,500.30273

Timestep Collection Time: 4.44639
Timestep Consumption Time: 0.81681
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.26320

Cumulative Model Updates: 35,881
Cumulative Timesteps: 598,592,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,198.41120
Policy Entropy: 1.10939
Value Function Loss: 10.63530

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.06064

Collected Steps per Second: 10,751.03671
Overall Steps per Second: 9,169.42501

Timestep Collection Time: 4.65276
Timestep Consumption Time: 0.80254
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.45530

Cumulative Model Updates: 35,884
Cumulative Timesteps: 598,642,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 598642830...
Checkpoint 598642830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,462.20061
Policy Entropy: 1.11655
Value Function Loss: 10.79620

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.06763

Collected Steps per Second: 10,992.27436
Overall Steps per Second: 9,554.30904

Timestep Collection Time: 4.55101
Timestep Consumption Time: 0.68495
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.23596

Cumulative Model Updates: 35,887
Cumulative Timesteps: 598,692,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,807.68842
Policy Entropy: 1.09470
Value Function Loss: 10.19371

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.06622

Collected Steps per Second: 11,094.95627
Overall Steps per Second: 9,501.16237

Timestep Collection Time: 4.50673
Timestep Consumption Time: 0.75599
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.26272

Cumulative Model Updates: 35,890
Cumulative Timesteps: 598,742,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 598742858...
Checkpoint 598742858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,388.48670
Policy Entropy: 1.10645
Value Function Loss: 10.38643

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.08435

Collected Steps per Second: 10,913.93279
Overall Steps per Second: 9,356.53843

Timestep Collection Time: 4.58387
Timestep Consumption Time: 0.76298
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.34685

Cumulative Model Updates: 35,893
Cumulative Timesteps: 598,792,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,171.78347
Policy Entropy: 1.10881
Value Function Loss: 10.41179

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.07870

Collected Steps per Second: 11,388.26965
Overall Steps per Second: 9,677.13496

Timestep Collection Time: 4.39119
Timestep Consumption Time: 0.77646
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.16765

Cumulative Model Updates: 35,896
Cumulative Timesteps: 598,842,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 598842894...
Checkpoint 598842894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,351.77602
Policy Entropy: 1.09673
Value Function Loss: 11.57301

Mean KL Divergence: 0.02493
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.07321

Collected Steps per Second: 11,012.07939
Overall Steps per Second: 9,408.68534

Timestep Collection Time: 4.54301
Timestep Consumption Time: 0.77420
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.31721

Cumulative Model Updates: 35,899
Cumulative Timesteps: 598,892,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392,008.34471
Policy Entropy: 1.09868
Value Function Loss: 10.93612

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.07040

Collected Steps per Second: 10,601.02353
Overall Steps per Second: 9,273.28416

Timestep Collection Time: 4.71898
Timestep Consumption Time: 0.67566
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.39464

Cumulative Model Updates: 35,902
Cumulative Timesteps: 598,942,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 598942948...
Checkpoint 598942948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,860.22531
Policy Entropy: 1.09978
Value Function Loss: 10.77071

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.08283

Collected Steps per Second: 10,925.10778
Overall Steps per Second: 9,292.74159

Timestep Collection Time: 4.57863
Timestep Consumption Time: 0.80428
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.38291

Cumulative Model Updates: 35,905
Cumulative Timesteps: 598,992,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,194.29602
Policy Entropy: 1.10504
Value Function Loss: 9.87995

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.09002

Collected Steps per Second: 10,874.92921
Overall Steps per Second: 9,337.71074

Timestep Collection Time: 4.60012
Timestep Consumption Time: 0.75729
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 5.35742

Cumulative Model Updates: 35,908
Cumulative Timesteps: 599,042,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 599042996...
Checkpoint 599042996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,299.20791
Policy Entropy: 1.10234
Value Function Loss: 9.90266

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.07812

Collected Steps per Second: 11,098.57835
Overall Steps per Second: 9,437.38269

Timestep Collection Time: 4.50508
Timestep Consumption Time: 0.79300
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.29808

Cumulative Model Updates: 35,911
Cumulative Timesteps: 599,092,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340,980.14230
Policy Entropy: 1.09150
Value Function Loss: 10.04330

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.07387

Collected Steps per Second: 10,927.84485
Overall Steps per Second: 9,388.51246

Timestep Collection Time: 4.57748
Timestep Consumption Time: 0.75052
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.32800

Cumulative Model Updates: 35,914
Cumulative Timesteps: 599,143,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 599143018...
Checkpoint 599143018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,517.68214
Policy Entropy: 1.10466
Value Function Loss: 10.43332

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.07779

Collected Steps per Second: 10,722.10946
Overall Steps per Second: 9,197.92301

Timestep Collection Time: 4.66401
Timestep Consumption Time: 0.77287
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.43688

Cumulative Model Updates: 35,917
Cumulative Timesteps: 599,193,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,633.90357
Policy Entropy: 1.09639
Value Function Loss: 10.95575

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.07538

Collected Steps per Second: 10,787.30359
Overall Steps per Second: 9,241.79690

Timestep Collection Time: 4.63526
Timestep Consumption Time: 0.77516
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 5.41042

Cumulative Model Updates: 35,920
Cumulative Timesteps: 599,243,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 599243028...
Checkpoint 599243028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,405.77979
Policy Entropy: 1.10613
Value Function Loss: 10.96077

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.07284

Collected Steps per Second: 11,706.94884
Overall Steps per Second: 9,912.87504

Timestep Collection Time: 4.27199
Timestep Consumption Time: 0.77316
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.04516

Cumulative Model Updates: 35,923
Cumulative Timesteps: 599,293,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,261.70004
Policy Entropy: 1.11872
Value Function Loss: 11.48928

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.06361

Collected Steps per Second: 11,860.32577
Overall Steps per Second: 9,908.61570

Timestep Collection Time: 4.21742
Timestep Consumption Time: 0.83071
PPO Batch Consumption Time: 0.04165
Total Iteration Time: 5.04813

Cumulative Model Updates: 35,926
Cumulative Timesteps: 599,343,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 599343060...
Checkpoint 599343060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,457.14455
Policy Entropy: 1.11719
Value Function Loss: 11.16544

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.06216
Value Function Update Magnitude: 0.07244

Collected Steps per Second: 11,167.27654
Overall Steps per Second: 9,467.06297

Timestep Collection Time: 4.47755
Timestep Consumption Time: 0.80413
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.28168

Cumulative Model Updates: 35,929
Cumulative Timesteps: 599,393,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,070.49710
Policy Entropy: 1.11932
Value Function Loss: 10.80227

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.06882
Value Function Update Magnitude: 0.06854

Collected Steps per Second: 11,769.50194
Overall Steps per Second: 10,099.01696

Timestep Collection Time: 4.25031
Timestep Consumption Time: 0.70305
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.95335

Cumulative Model Updates: 35,932
Cumulative Timesteps: 599,443,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 599443086...
Checkpoint 599443086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,044.70587
Policy Entropy: 1.11891
Value Function Loss: 10.22785

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.07785

Collected Steps per Second: 11,375.04429
Overall Steps per Second: 9,614.82947

Timestep Collection Time: 4.39647
Timestep Consumption Time: 0.80487
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.20134

Cumulative Model Updates: 35,935
Cumulative Timesteps: 599,493,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,477.73134
Policy Entropy: 1.11693
Value Function Loss: 10.25322

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.06744
Value Function Update Magnitude: 0.06984

Collected Steps per Second: 11,745.61754
Overall Steps per Second: 9,988.07687

Timestep Collection Time: 4.25742
Timestep Consumption Time: 0.74915
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.00657

Cumulative Model Updates: 35,938
Cumulative Timesteps: 599,543,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 599543102...
Checkpoint 599543102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,245.48265
Policy Entropy: 1.13370
Value Function Loss: 10.55773

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.08296

Collected Steps per Second: 11,087.75172
Overall Steps per Second: 9,429.27542

Timestep Collection Time: 4.51020
Timestep Consumption Time: 0.79328
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.30348

Cumulative Model Updates: 35,941
Cumulative Timesteps: 599,593,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,391.93029
Policy Entropy: 1.13158
Value Function Loss: 10.39941

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.06964

Collected Steps per Second: 11,043.75786
Overall Steps per Second: 9,477.02033

Timestep Collection Time: 4.52998
Timestep Consumption Time: 0.74889
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.27887

Cumulative Model Updates: 35,944
Cumulative Timesteps: 599,643,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 599643138...
Checkpoint 599643138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,230.16761
Policy Entropy: 1.11880
Value Function Loss: 10.26385

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.08237

Collected Steps per Second: 11,135.03558
Overall Steps per Second: 9,580.86484

Timestep Collection Time: 4.49159
Timestep Consumption Time: 0.72861
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.22020

Cumulative Model Updates: 35,947
Cumulative Timesteps: 599,693,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403,574.04503
Policy Entropy: 1.11262
Value Function Loss: 9.98011

Mean KL Divergence: 0.02879
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.07204

Collected Steps per Second: 11,255.18282
Overall Steps per Second: 9,554.02548

Timestep Collection Time: 4.44471
Timestep Consumption Time: 0.79141
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 5.23612

Cumulative Model Updates: 35,950
Cumulative Timesteps: 599,743,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 599743178...
Checkpoint 599743178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,137.84084
Policy Entropy: 1.12815
Value Function Loss: 9.94158

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.07321
Value Function Update Magnitude: 0.06998

Collected Steps per Second: 10,417.42916
Overall Steps per Second: 9,086.68529

Timestep Collection Time: 4.80061
Timestep Consumption Time: 0.70305
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.50366

Cumulative Model Updates: 35,953
Cumulative Timesteps: 599,793,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,070.61976
Policy Entropy: 1.12725
Value Function Loss: 10.19418

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.12239
Policy Update Magnitude: 0.07262
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 11,052.28132
Overall Steps per Second: 9,417.12020

Timestep Collection Time: 4.52649
Timestep Consumption Time: 0.78597
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.31245

Cumulative Model Updates: 35,956
Cumulative Timesteps: 599,843,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 599843216...
Checkpoint 599843216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,291.10413
Policy Entropy: 1.10928
Value Function Loss: 10.51985

Mean KL Divergence: 0.03692
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.07149
Value Function Update Magnitude: 0.07791

Collected Steps per Second: 10,962.66451
Overall Steps per Second: 9,426.26907

Timestep Collection Time: 4.56203
Timestep Consumption Time: 0.74357
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.30560

Cumulative Model Updates: 35,959
Cumulative Timesteps: 599,893,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,876.83889
Policy Entropy: 1.11947
Value Function Loss: 10.85254

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.07084

Collected Steps per Second: 10,813.03131
Overall Steps per Second: 9,429.47864

Timestep Collection Time: 4.62424
Timestep Consumption Time: 0.67850
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.30273

Cumulative Model Updates: 35,962
Cumulative Timesteps: 599,943,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 599943230...
Checkpoint 599943230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,364.80766
Policy Entropy: 1.12353
Value Function Loss: 10.97180

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.06899

Collected Steps per Second: 10,791.55492
Overall Steps per Second: 9,195.53363

Timestep Collection Time: 4.63566
Timestep Consumption Time: 0.80459
PPO Batch Consumption Time: 0.04330
Total Iteration Time: 5.44025

Cumulative Model Updates: 35,965
Cumulative Timesteps: 599,993,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,586.89630
Policy Entropy: 1.10849
Value Function Loss: 11.29245

Mean KL Divergence: 0.03023
SB3 Clip Fraction: 0.15281
Policy Update Magnitude: 0.06798
Value Function Update Magnitude: 0.06128

Collected Steps per Second: 11,100.61161
Overall Steps per Second: 9,580.79519

Timestep Collection Time: 4.50498
Timestep Consumption Time: 0.71463
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.21961

Cumulative Model Updates: 35,968
Cumulative Timesteps: 600,043,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 600043264...
Checkpoint 600043264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481,183.50897
Policy Entropy: 1.11699
Value Function Loss: 11.24338

Mean KL Divergence: 0.03063
SB3 Clip Fraction: 0.15973
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.08241

Collected Steps per Second: 10,599.51814
Overall Steps per Second: 9,055.97162

Timestep Collection Time: 4.71984
Timestep Consumption Time: 0.80447
PPO Batch Consumption Time: 0.03961
Total Iteration Time: 5.52431

Cumulative Model Updates: 35,971
Cumulative Timesteps: 600,093,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404,279.53521
Policy Entropy: 1.11882
Value Function Loss: 11.20534

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 10,872.54417
Overall Steps per Second: 9,497.91947

Timestep Collection Time: 4.60003
Timestep Consumption Time: 0.66576
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.26578

Cumulative Model Updates: 35,974
Cumulative Timesteps: 600,143,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 600143306...
Checkpoint 600143306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,850.70612
Policy Entropy: 1.10987
Value Function Loss: 10.64764

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.07829

Collected Steps per Second: 11,155.40767
Overall Steps per Second: 9,513.81202

Timestep Collection Time: 4.48374
Timestep Consumption Time: 0.77366
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.25741

Cumulative Model Updates: 35,977
Cumulative Timesteps: 600,193,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,021.73352
Policy Entropy: 1.10309
Value Function Loss: 10.96181

Mean KL Divergence: 0.03465
SB3 Clip Fraction: 0.17456
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 10,795.61745
Overall Steps per Second: 9,249.20133

Timestep Collection Time: 4.63225
Timestep Consumption Time: 0.77449
PPO Batch Consumption Time: 0.03922
Total Iteration Time: 5.40674

Cumulative Model Updates: 35,980
Cumulative Timesteps: 600,243,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 600243332...
Checkpoint 600243332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,105.92695
Policy Entropy: 1.10731
Value Function Loss: 10.48562

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.06929

Collected Steps per Second: 10,894.67123
Overall Steps per Second: 9,509.08082

Timestep Collection Time: 4.59032
Timestep Consumption Time: 0.66887
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.25918

Cumulative Model Updates: 35,983
Cumulative Timesteps: 600,293,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,228.15567
Policy Entropy: 1.10625
Value Function Loss: 10.11075

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.07841

Collected Steps per Second: 10,564.47380
Overall Steps per Second: 9,049.61984

Timestep Collection Time: 4.73436
Timestep Consumption Time: 0.79250
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 5.52686

Cumulative Model Updates: 35,986
Cumulative Timesteps: 600,343,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 600343358...
Checkpoint 600343358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,511.32320
Policy Entropy: 1.09322
Value Function Loss: 9.87261

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.06950

Collected Steps per Second: 10,945.83936
Overall Steps per Second: 9,608.93653

Timestep Collection Time: 4.57087
Timestep Consumption Time: 0.63595
PPO Batch Consumption Time: 0.03303
Total Iteration Time: 5.20682

Cumulative Model Updates: 35,989
Cumulative Timesteps: 600,393,390

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,163.55296
Policy Entropy: 1.10633
Value Function Loss: 9.99607

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.06861

Collected Steps per Second: 11,629.09588
Overall Steps per Second: 9,870.58169

Timestep Collection Time: 4.30042
Timestep Consumption Time: 0.76615
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.06657

Cumulative Model Updates: 35,992
Cumulative Timesteps: 600,443,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 600443400...
Checkpoint 600443400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,340.69410
Policy Entropy: 1.10877
Value Function Loss: 10.37494

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.06736
Value Function Update Magnitude: 0.06750

Collected Steps per Second: 11,329.17596
Overall Steps per Second: 9,783.73168

Timestep Collection Time: 4.41462
Timestep Consumption Time: 0.69734
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.11196

Cumulative Model Updates: 35,995
Cumulative Timesteps: 600,493,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,310.23936
Policy Entropy: 1.10270
Value Function Loss: 10.57271

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.06814
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 11,472.69573
Overall Steps per Second: 9,740.80254

Timestep Collection Time: 4.35992
Timestep Consumption Time: 0.77518
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.13510

Cumulative Model Updates: 35,998
Cumulative Timesteps: 600,543,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 600543434...
Checkpoint 600543434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,485.36369
Policy Entropy: 1.09871
Value Function Loss: 10.69363

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.06053

Collected Steps per Second: 11,266.29559
Overall Steps per Second: 9,636.41546

Timestep Collection Time: 4.43979
Timestep Consumption Time: 0.75094
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.19073

Cumulative Model Updates: 36,001
Cumulative Timesteps: 600,593,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,543.81532
Policy Entropy: 1.11914
Value Function Loss: 10.79284

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.05909

Collected Steps per Second: 10,990.06543
Overall Steps per Second: 9,381.33997

Timestep Collection Time: 4.55011
Timestep Consumption Time: 0.78026
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 5.33037

Cumulative Model Updates: 36,004
Cumulative Timesteps: 600,643,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 600643460...
Checkpoint 600643460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,955.12842
Policy Entropy: 1.12139
Value Function Loss: 10.33058

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.05757

Collected Steps per Second: 11,023.00537
Overall Steps per Second: 9,318.68897

Timestep Collection Time: 4.53815
Timestep Consumption Time: 0.82999
PPO Batch Consumption Time: 0.04018
Total Iteration Time: 5.36814

Cumulative Model Updates: 36,007
Cumulative Timesteps: 600,693,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,394.70175
Policy Entropy: 1.11111
Value Function Loss: 10.42706

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.06873

Collected Steps per Second: 11,144.84333
Overall Steps per Second: 9,661.34755

Timestep Collection Time: 4.48638
Timestep Consumption Time: 0.68888
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.17526

Cumulative Model Updates: 36,010
Cumulative Timesteps: 600,743,484

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 600743484...
Checkpoint 600743484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,841.11838
Policy Entropy: 1.10042
Value Function Loss: 10.45225

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 11,185.55749
Overall Steps per Second: 9,553.80353

Timestep Collection Time: 4.47130
Timestep Consumption Time: 0.76368
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.23498

Cumulative Model Updates: 36,013
Cumulative Timesteps: 600,793,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,116.31179
Policy Entropy: 1.10835
Value Function Loss: 10.71470

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.07066

Collected Steps per Second: 11,382.07712
Overall Steps per Second: 9,688.53995

Timestep Collection Time: 4.39516
Timestep Consumption Time: 0.76826
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 5.16342

Cumulative Model Updates: 36,016
Cumulative Timesteps: 600,843,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 600843524...
Checkpoint 600843524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,092.77945
Policy Entropy: 1.10815
Value Function Loss: 10.60453

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 11,155.45174
Overall Steps per Second: 9,642.23224

Timestep Collection Time: 4.48355
Timestep Consumption Time: 0.70363
PPO Batch Consumption Time: 0.04028
Total Iteration Time: 5.18718

Cumulative Model Updates: 36,019
Cumulative Timesteps: 600,893,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,213.27109
Policy Entropy: 1.09212
Value Function Loss: 10.67584

Mean KL Divergence: 0.02579
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.06752

Collected Steps per Second: 10,997.98767
Overall Steps per Second: 9,389.82367

Timestep Collection Time: 4.54756
Timestep Consumption Time: 0.77885
PPO Batch Consumption Time: 0.03819
Total Iteration Time: 5.32640

Cumulative Model Updates: 36,022
Cumulative Timesteps: 600,943,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 600943554...
Checkpoint 600943554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,483.90499
Policy Entropy: 1.09836
Value Function Loss: 10.77100

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.07556

Collected Steps per Second: 10,940.13265
Overall Steps per Second: 9,442.41676

Timestep Collection Time: 4.57179
Timestep Consumption Time: 0.72516
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.29695

Cumulative Model Updates: 36,025
Cumulative Timesteps: 600,993,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,006.38176
Policy Entropy: 1.11687
Value Function Loss: 10.87905

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 11,382.36230
Overall Steps per Second: 9,714.37353

Timestep Collection Time: 4.39364
Timestep Consumption Time: 0.75440
PPO Batch Consumption Time: 0.03771
Total Iteration Time: 5.14804

Cumulative Model Updates: 36,028
Cumulative Timesteps: 601,043,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 601043580...
Checkpoint 601043580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,261.15650
Policy Entropy: 1.09857
Value Function Loss: 10.80037

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.06732

Collected Steps per Second: 11,149.10515
Overall Steps per Second: 9,505.23456

Timestep Collection Time: 4.48538
Timestep Consumption Time: 0.77572
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.26110

Cumulative Model Updates: 36,031
Cumulative Timesteps: 601,093,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380,373.93092
Policy Entropy: 1.11043
Value Function Loss: 10.75242

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.06468

Collected Steps per Second: 10,913.92468
Overall Steps per Second: 9,396.30559

Timestep Collection Time: 4.58314
Timestep Consumption Time: 0.74023
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 5.32337

Cumulative Model Updates: 36,034
Cumulative Timesteps: 601,143,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 601143608...
Checkpoint 601143608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,316.36875
Policy Entropy: 1.10608
Value Function Loss: 10.63041

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.07076
Value Function Update Magnitude: 0.06403

Collected Steps per Second: 10,649.00460
Overall Steps per Second: 9,131.95187

Timestep Collection Time: 4.69659
Timestep Consumption Time: 0.78022
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.47681

Cumulative Model Updates: 36,037
Cumulative Timesteps: 601,193,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,119.14119
Policy Entropy: 1.10755
Value Function Loss: 10.67429

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.07337
Value Function Update Magnitude: 0.06708

Collected Steps per Second: 10,806.46211
Overall Steps per Second: 9,240.11995

Timestep Collection Time: 4.62816
Timestep Consumption Time: 0.78454
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 5.41270

Cumulative Model Updates: 36,040
Cumulative Timesteps: 601,243,636

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 601243636...
Checkpoint 601243636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,955.75815
Policy Entropy: 1.09541
Value Function Loss: 10.56674

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.07399
Value Function Update Magnitude: 0.06355

Collected Steps per Second: 11,197.09255
Overall Steps per Second: 9,513.28225

Timestep Collection Time: 4.46830
Timestep Consumption Time: 0.79087
PPO Batch Consumption Time: 0.03775
Total Iteration Time: 5.25917

Cumulative Model Updates: 36,043
Cumulative Timesteps: 601,293,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,820.32161
Policy Entropy: 1.08508
Value Function Loss: 10.18238

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.07149
Value Function Update Magnitude: 0.08402

Collected Steps per Second: 11,047.25763
Overall Steps per Second: 9,428.11921

Timestep Collection Time: 4.52854
Timestep Consumption Time: 0.77771
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.30625

Cumulative Model Updates: 36,046
Cumulative Timesteps: 601,343,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 601343696...
Checkpoint 601343696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,935.01631
Policy Entropy: 1.09678
Value Function Loss: 9.88055

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.12798

Collected Steps per Second: 10,854.31462
Overall Steps per Second: 9,413.47042

Timestep Collection Time: 4.60923
Timestep Consumption Time: 0.70550
PPO Batch Consumption Time: 0.03371
Total Iteration Time: 5.31472

Cumulative Model Updates: 36,049
Cumulative Timesteps: 601,393,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,511.29973
Policy Entropy: 1.10427
Value Function Loss: 9.91577

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.10950

Collected Steps per Second: 10,973.30317
Overall Steps per Second: 9,337.69324

Timestep Collection Time: 4.55943
Timestep Consumption Time: 0.79864
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.35807

Cumulative Model Updates: 36,052
Cumulative Timesteps: 601,443,758

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 601443758...
Checkpoint 601443758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,190.73942
Policy Entropy: 1.09002
Value Function Loss: 10.51164

Mean KL Divergence: 0.02375
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.08400

Collected Steps per Second: 10,546.76317
Overall Steps per Second: 9,177.77659

Timestep Collection Time: 4.74193
Timestep Consumption Time: 0.70732
PPO Batch Consumption Time: 0.03847
Total Iteration Time: 5.44925

Cumulative Model Updates: 36,055
Cumulative Timesteps: 601,493,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,906.43779
Policy Entropy: 1.08850
Value Function Loss: 10.38460

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.07473

Collected Steps per Second: 11,835.83203
Overall Steps per Second: 10,013.82488

Timestep Collection Time: 4.22514
Timestep Consumption Time: 0.76876
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 4.99390

Cumulative Model Updates: 36,058
Cumulative Timesteps: 601,543,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 601543778...
Checkpoint 601543778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,853.75644
Policy Entropy: 1.10193
Value Function Loss: 10.83818

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 11,898.64594
Overall Steps per Second: 10,001.66268

Timestep Collection Time: 4.20367
Timestep Consumption Time: 0.79730
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 5.00097

Cumulative Model Updates: 36,061
Cumulative Timesteps: 601,593,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453,644.00206
Policy Entropy: 1.10953
Value Function Loss: 11.28096

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 12,167.91588
Overall Steps per Second: 10,186.38643

Timestep Collection Time: 4.11081
Timestep Consumption Time: 0.79966
PPO Batch Consumption Time: 0.04028
Total Iteration Time: 4.91048

Cumulative Model Updates: 36,064
Cumulative Timesteps: 601,643,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 601643816...
Checkpoint 601643816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,840.50569
Policy Entropy: 1.08899
Value Function Loss: 11.39228

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.05354

Collected Steps per Second: 12,221.53152
Overall Steps per Second: 10,280.76595

Timestep Collection Time: 4.09261
Timestep Consumption Time: 0.77259
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 4.86520

Cumulative Model Updates: 36,067
Cumulative Timesteps: 601,693,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,532.14465
Policy Entropy: 1.10030
Value Function Loss: 11.08522

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.05496

Collected Steps per Second: 11,706.94569
Overall Steps per Second: 10,086.50016

Timestep Collection Time: 4.27353
Timestep Consumption Time: 0.68656
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.96010

Cumulative Model Updates: 36,070
Cumulative Timesteps: 601,743,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 601743864...
Checkpoint 601743864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,906.60072
Policy Entropy: 1.09730
Value Function Loss: 10.75527

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.05044

Collected Steps per Second: 11,549.17709
Overall Steps per Second: 9,818.97205

Timestep Collection Time: 4.32983
Timestep Consumption Time: 0.76296
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.09279

Cumulative Model Updates: 36,073
Cumulative Timesteps: 601,793,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,614.03404
Policy Entropy: 1.09689
Value Function Loss: 10.77989

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.04385

Collected Steps per Second: 11,224.92820
Overall Steps per Second: 9,671.98135

Timestep Collection Time: 4.45633
Timestep Consumption Time: 0.71551
PPO Batch Consumption Time: 0.04165
Total Iteration Time: 5.17185

Cumulative Model Updates: 36,076
Cumulative Timesteps: 601,843,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 601843892...
Checkpoint 601843892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387,374.74459
Policy Entropy: 1.10140
Value Function Loss: 11.54166

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.04575

Collected Steps per Second: 11,064.76249
Overall Steps per Second: 9,438.85752

Timestep Collection Time: 4.52012
Timestep Consumption Time: 0.77862
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.29873

Cumulative Model Updates: 36,079
Cumulative Timesteps: 601,893,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,793.56557
Policy Entropy: 1.09935
Value Function Loss: 11.18699

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.04306

Collected Steps per Second: 11,291.01611
Overall Steps per Second: 9,771.28745

Timestep Collection Time: 4.42989
Timestep Consumption Time: 0.68898
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.11888

Cumulative Model Updates: 36,082
Cumulative Timesteps: 601,943,924

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 601943924...
Checkpoint 601943924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,117.96551
Policy Entropy: 1.11079
Value Function Loss: 11.05736

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.04325

Collected Steps per Second: 11,331.73379
Overall Steps per Second: 9,621.04481

Timestep Collection Time: 4.41451
Timestep Consumption Time: 0.78493
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.19944

Cumulative Model Updates: 36,085
Cumulative Timesteps: 601,993,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,422.55080
Policy Entropy: 1.10950
Value Function Loss: 10.24411

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.04478

Collected Steps per Second: 11,474.57858
Overall Steps per Second: 9,781.05801

Timestep Collection Time: 4.35763
Timestep Consumption Time: 0.75449
PPO Batch Consumption Time: 0.03390
Total Iteration Time: 5.11213

Cumulative Model Updates: 36,088
Cumulative Timesteps: 602,043,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 602043950...
Checkpoint 602043950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412,074.25771
Policy Entropy: 1.11817
Value Function Loss: 10.19508

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.04085

Collected Steps per Second: 10,614.30480
Overall Steps per Second: 9,080.09536

Timestep Collection Time: 4.71062
Timestep Consumption Time: 0.79593
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.50655

Cumulative Model Updates: 36,091
Cumulative Timesteps: 602,093,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,850.75683
Policy Entropy: 1.12180
Value Function Loss: 9.79532

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.04421

Collected Steps per Second: 10,920.80867
Overall Steps per Second: 9,355.87275

Timestep Collection Time: 4.57878
Timestep Consumption Time: 0.76588
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.34466

Cumulative Model Updates: 36,094
Cumulative Timesteps: 602,143,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 602143954...
Checkpoint 602143954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,021.44381
Policy Entropy: 1.10629
Value Function Loss: 10.39401

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.04729

Collected Steps per Second: 11,129.56642
Overall Steps per Second: 9,649.45448

Timestep Collection Time: 4.49344
Timestep Consumption Time: 0.68924
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.18268

Cumulative Model Updates: 36,097
Cumulative Timesteps: 602,193,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373,788.24105
Policy Entropy: 1.10411
Value Function Loss: 10.65994

Mean KL Divergence: 0.03289
SB3 Clip Fraction: 0.15535
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.04485

Collected Steps per Second: 11,086.03008
Overall Steps per Second: 9,426.16266

Timestep Collection Time: 4.51271
Timestep Consumption Time: 0.79465
PPO Batch Consumption Time: 0.03869
Total Iteration Time: 5.30736

Cumulative Model Updates: 36,100
Cumulative Timesteps: 602,243,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 602243992...
Checkpoint 602243992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,830.28822
Policy Entropy: 1.11663
Value Function Loss: 11.40239

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.04588

Collected Steps per Second: 10,805.26481
Overall Steps per Second: 9,313.03719

Timestep Collection Time: 4.62978
Timestep Consumption Time: 0.74183
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.37161

Cumulative Model Updates: 36,103
Cumulative Timesteps: 602,294,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,529.99974
Policy Entropy: 1.12531
Value Function Loss: 10.95993

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07531
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.04631

Collected Steps per Second: 10,898.50829
Overall Steps per Second: 9,355.85625

Timestep Collection Time: 4.59072
Timestep Consumption Time: 0.75695
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.34767

Cumulative Model Updates: 36,106
Cumulative Timesteps: 602,344,050

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 602344050...
Checkpoint 602344050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,824.21471
Policy Entropy: 1.12107
Value Function Loss: 10.61613

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.04460

Collected Steps per Second: 11,079.28223
Overall Steps per Second: 9,489.60182

Timestep Collection Time: 4.51365
Timestep Consumption Time: 0.75612
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.26977

Cumulative Model Updates: 36,109
Cumulative Timesteps: 602,394,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,099.95383
Policy Entropy: 1.11174
Value Function Loss: 10.42414

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.04150

Collected Steps per Second: 10,785.22485
Overall Steps per Second: 9,445.49868

Timestep Collection Time: 4.63616
Timestep Consumption Time: 0.65758
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.29374

Cumulative Model Updates: 36,112
Cumulative Timesteps: 602,444,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 602444060...
Checkpoint 602444060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422,453.30073
Policy Entropy: 1.12035
Value Function Loss: 10.85585

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.04718

Collected Steps per Second: 11,116.27836
Overall Steps per Second: 9,489.62314

Timestep Collection Time: 4.49971
Timestep Consumption Time: 0.77131
PPO Batch Consumption Time: 0.03918
Total Iteration Time: 5.27102

Cumulative Model Updates: 36,115
Cumulative Timesteps: 602,494,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437,327.25943
Policy Entropy: 1.11700
Value Function Loss: 11.37746

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.04640
Value Function Update Magnitude: 0.04670

Collected Steps per Second: 11,048.20545
Overall Steps per Second: 9,420.93930

Timestep Collection Time: 4.52598
Timestep Consumption Time: 0.78177
PPO Batch Consumption Time: 0.03899
Total Iteration Time: 5.30775

Cumulative Model Updates: 36,118
Cumulative Timesteps: 602,544,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 602544084...
Checkpoint 602544084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,415.72303
Policy Entropy: 1.11365
Value Function Loss: 11.30797

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.04400

Collected Steps per Second: 11,268.51738
Overall Steps per Second: 9,590.08824

Timestep Collection Time: 4.43909
Timestep Consumption Time: 0.77692
PPO Batch Consumption Time: 0.03769
Total Iteration Time: 5.21601

Cumulative Model Updates: 36,121
Cumulative Timesteps: 602,594,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,534.80795
Policy Entropy: 1.10218
Value Function Loss: 11.25157

Mean KL Divergence: 0.04082
SB3 Clip Fraction: 0.17991
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.04122

Collected Steps per Second: 10,440.01289
Overall Steps per Second: 9,026.91538

Timestep Collection Time: 4.79003
Timestep Consumption Time: 0.74984
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.53988

Cumulative Model Updates: 36,124
Cumulative Timesteps: 602,644,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 602644114...
Checkpoint 602644114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,504.58921
Policy Entropy: 1.11141
Value Function Loss: 10.50055

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.04151

Collected Steps per Second: 11,372.50169
Overall Steps per Second: 9,822.52792

Timestep Collection Time: 4.39903
Timestep Consumption Time: 0.69416
PPO Batch Consumption Time: 0.03967
Total Iteration Time: 5.09319

Cumulative Model Updates: 36,127
Cumulative Timesteps: 602,694,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,713.72632
Policy Entropy: 1.10989
Value Function Loss: 10.67800

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.03904

Collected Steps per Second: 11,379.75554
Overall Steps per Second: 9,660.33706

Timestep Collection Time: 4.39517
Timestep Consumption Time: 0.78229
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 5.17746

Cumulative Model Updates: 36,130
Cumulative Timesteps: 602,744,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 602744158...
Checkpoint 602744158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,085.39613
Policy Entropy: 1.09056
Value Function Loss: 10.52922

Mean KL Divergence: 0.03624
SB3 Clip Fraction: 0.17504
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.04435

Collected Steps per Second: 11,172.72323
Overall Steps per Second: 9,648.90395

Timestep Collection Time: 4.47769
Timestep Consumption Time: 0.70715
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 5.18484

Cumulative Model Updates: 36,133
Cumulative Timesteps: 602,794,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,976.62450
Policy Entropy: 1.10318
Value Function Loss: 10.59855

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.04610

Collected Steps per Second: 11,584.68608
Overall Steps per Second: 9,876.94684

Timestep Collection Time: 4.31639
Timestep Consumption Time: 0.74631
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.06270

Cumulative Model Updates: 36,136
Cumulative Timesteps: 602,844,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 602844190...
Checkpoint 602844190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,600.44046
Policy Entropy: 1.10392
Value Function Loss: 10.71924

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.04629

Collected Steps per Second: 11,430.60616
Overall Steps per Second: 9,762.98706

Timestep Collection Time: 4.37545
Timestep Consumption Time: 0.74737
PPO Batch Consumption Time: 0.03781
Total Iteration Time: 5.12282

Cumulative Model Updates: 36,139
Cumulative Timesteps: 602,894,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,898.83890
Policy Entropy: 1.08603
Value Function Loss: 11.01005

Mean KL Divergence: 0.03491
SB3 Clip Fraction: 0.17731
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.04126

Collected Steps per Second: 11,083.15234
Overall Steps per Second: 9,471.17565

Timestep Collection Time: 4.51280
Timestep Consumption Time: 0.76807
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.28086

Cumulative Model Updates: 36,142
Cumulative Timesteps: 602,944,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 602944220...
Checkpoint 602944220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,291.19573
Policy Entropy: 1.09883
Value Function Loss: 11.54043

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.12237
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.03852

Collected Steps per Second: 10,961.41750
Overall Steps per Second: 9,267.03695

Timestep Collection Time: 4.56383
Timestep Consumption Time: 0.83445
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.39827

Cumulative Model Updates: 36,145
Cumulative Timesteps: 602,994,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362,975.41002
Policy Entropy: 1.09873
Value Function Loss: 10.98919

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.04101

Collected Steps per Second: 11,105.76721
Overall Steps per Second: 9,620.20686

Timestep Collection Time: 4.50379
Timestep Consumption Time: 0.69548
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.19926

Cumulative Model Updates: 36,148
Cumulative Timesteps: 603,044,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 603044264...
Checkpoint 603044264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,754.80947
Policy Entropy: 1.09462
Value Function Loss: 10.78946

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.03970

Collected Steps per Second: 11,006.65746
Overall Steps per Second: 9,388.26694

Timestep Collection Time: 4.54507
Timestep Consumption Time: 0.78350
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 5.32857

Cumulative Model Updates: 36,151
Cumulative Timesteps: 603,094,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,764.58807
Policy Entropy: 1.08657
Value Function Loss: 10.77004

Mean KL Divergence: 0.02879
SB3 Clip Fraction: 0.16683
Policy Update Magnitude: 0.04640
Value Function Update Magnitude: 0.04088

Collected Steps per Second: 11,382.10487
Overall Steps per Second: 9,870.08701

Timestep Collection Time: 4.39409
Timestep Consumption Time: 0.67314
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.06723

Cumulative Model Updates: 36,154
Cumulative Timesteps: 603,144,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 603144304...
Checkpoint 603144304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,669.79530
Policy Entropy: 1.09798
Value Function Loss: 11.34329

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.04159

Collected Steps per Second: 10,930.31816
Overall Steps per Second: 9,200.12210

Timestep Collection Time: 4.57571
Timestep Consumption Time: 0.86052
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.43623

Cumulative Model Updates: 36,157
Cumulative Timesteps: 603,194,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,128.83477
Policy Entropy: 1.10440
Value Function Loss: 11.04910

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.04433

Collected Steps per Second: 11,124.51458
Overall Steps per Second: 9,469.50285

Timestep Collection Time: 4.49710
Timestep Consumption Time: 0.78597
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.28307

Cumulative Model Updates: 36,160
Cumulative Timesteps: 603,244,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 603244346...
Checkpoint 603244346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,091.91998
Policy Entropy: 1.08908
Value Function Loss: 10.59560

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.04387

Collected Steps per Second: 11,243.04974
Overall Steps per Second: 9,755.32316

Timestep Collection Time: 4.44897
Timestep Consumption Time: 0.67849
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.12746

Cumulative Model Updates: 36,163
Cumulative Timesteps: 603,294,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,381.12416
Policy Entropy: 1.07173
Value Function Loss: 9.97507

Mean KL Divergence: 0.03344
SB3 Clip Fraction: 0.16385
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.04364

Collected Steps per Second: 11,068.32428
Overall Steps per Second: 9,482.06751

Timestep Collection Time: 4.51974
Timestep Consumption Time: 0.75611
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 5.27585

Cumulative Model Updates: 36,166
Cumulative Timesteps: 603,344,392

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 603344392...
Checkpoint 603344392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,416.52924
Policy Entropy: 1.08931
Value Function Loss: 10.10286

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.04482

Collected Steps per Second: 11,540.40926
Overall Steps per Second: 9,949.30747

Timestep Collection Time: 4.33347
Timestep Consumption Time: 0.69301
PPO Batch Consumption Time: 0.03981
Total Iteration Time: 5.02648

Cumulative Model Updates: 36,169
Cumulative Timesteps: 603,394,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,266.58458
Policy Entropy: 1.08610
Value Function Loss: 10.29170

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.05556

Collected Steps per Second: 11,278.97910
Overall Steps per Second: 9,608.41715

Timestep Collection Time: 4.43533
Timestep Consumption Time: 0.77115
PPO Batch Consumption Time: 0.03713
Total Iteration Time: 5.20648

Cumulative Model Updates: 36,172
Cumulative Timesteps: 603,444,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 603444428...
Checkpoint 603444428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,517.58531
Policy Entropy: 1.06342
Value Function Loss: 10.23963

Mean KL Divergence: 0.05066
SB3 Clip Fraction: 0.17975
Policy Update Magnitude: 0.06160
Value Function Update Magnitude: 0.06378

Collected Steps per Second: 9,670.81983
Overall Steps per Second: 8,344.92713

Timestep Collection Time: 5.17061
Timestep Consumption Time: 0.82154
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 5.99214

Cumulative Model Updates: 36,175
Cumulative Timesteps: 603,494,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,429.26986
Policy Entropy: 1.10246
Value Function Loss: 9.90610

Mean KL Divergence: 0.03636
SB3 Clip Fraction: 0.19342
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.07215

Collected Steps per Second: 11,128.15747
Overall Steps per Second: 9,428.86907

Timestep Collection Time: 4.49311
Timestep Consumption Time: 0.80976
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 5.30286

Cumulative Model Updates: 36,178
Cumulative Timesteps: 603,544,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 603544432...
Checkpoint 603544432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,904.33037
Policy Entropy: 1.07333
Value Function Loss: 9.69398

Mean KL Divergence: 0.04047
SB3 Clip Fraction: 0.17788
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.07052

Collected Steps per Second: 10,910.27204
Overall Steps per Second: 9,296.06579

Timestep Collection Time: 4.58357
Timestep Consumption Time: 0.79591
PPO Batch Consumption Time: 0.03785
Total Iteration Time: 5.37948

Cumulative Model Updates: 36,181
Cumulative Timesteps: 603,594,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407,916.50264
Policy Entropy: 1.09204
Value Function Loss: 10.22335

Mean KL Divergence: 0.03032
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.06958

Collected Steps per Second: 10,922.36813
Overall Steps per Second: 9,447.08111

Timestep Collection Time: 4.57886
Timestep Consumption Time: 0.71505
PPO Batch Consumption Time: 0.04014
Total Iteration Time: 5.29391

Cumulative Model Updates: 36,184
Cumulative Timesteps: 603,644,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 603644452...
Checkpoint 603644452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,793.93236
Policy Entropy: 1.09730
Value Function Loss: 10.54951

Mean KL Divergence: 0.02634
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.06293
Value Function Update Magnitude: 0.06352

Collected Steps per Second: 10,953.61529
Overall Steps per Second: 9,299.97025

Timestep Collection Time: 4.56543
Timestep Consumption Time: 0.81179
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.37722

Cumulative Model Updates: 36,187
Cumulative Timesteps: 603,694,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,229.33164
Policy Entropy: 1.09043
Value Function Loss: 10.80073

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.06470
Value Function Update Magnitude: 0.06629

Collected Steps per Second: 10,957.11802
Overall Steps per Second: 9,350.26292

Timestep Collection Time: 4.56434
Timestep Consumption Time: 0.78439
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.34873

Cumulative Model Updates: 36,190
Cumulative Timesteps: 603,744,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 603744472...
Checkpoint 603744472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425,785.26832
Policy Entropy: 1.07908
Value Function Loss: 10.22204

Mean KL Divergence: 0.03372
SB3 Clip Fraction: 0.18081
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.07700

Collected Steps per Second: 10,788.85354
Overall Steps per Second: 9,270.14811

Timestep Collection Time: 4.63608
Timestep Consumption Time: 0.75952
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.39560

Cumulative Model Updates: 36,193
Cumulative Timesteps: 603,794,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,800.64246
Policy Entropy: 1.08799
Value Function Loss: 10.50719

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.08180

Collected Steps per Second: 12,250.14713
Overall Steps per Second: 10,301.69606

Timestep Collection Time: 4.08305
Timestep Consumption Time: 0.77226
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 4.85532

Cumulative Model Updates: 36,196
Cumulative Timesteps: 603,844,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 603844508...
Checkpoint 603844508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,948.96411
Policy Entropy: 1.09312
Value Function Loss: 10.27651

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.06337
Value Function Update Magnitude: 0.07253

Collected Steps per Second: 11,894.73401
Overall Steps per Second: 10,232.53119

Timestep Collection Time: 4.20505
Timestep Consumption Time: 0.68308
PPO Batch Consumption Time: 0.03900
Total Iteration Time: 4.88814

Cumulative Model Updates: 36,199
Cumulative Timesteps: 603,894,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,385.88787
Policy Entropy: 1.07676
Value Function Loss: 10.09792

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.08566

Collected Steps per Second: 12,321.00953
Overall Steps per Second: 10,324.48417

Timestep Collection Time: 4.05860
Timestep Consumption Time: 0.78484
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 4.84344

Cumulative Model Updates: 36,202
Cumulative Timesteps: 603,944,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 603944532...
Checkpoint 603944532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,900.71560
Policy Entropy: 1.07085
Value Function Loss: 10.02785

Mean KL Divergence: 0.03313
SB3 Clip Fraction: 0.16201
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.08270

Collected Steps per Second: 12,076.65012
Overall Steps per Second: 10,215.15976

Timestep Collection Time: 4.14088
Timestep Consumption Time: 0.75459
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.89547

Cumulative Model Updates: 36,205
Cumulative Timesteps: 603,994,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,991.53657
Policy Entropy: 1.08270
Value Function Loss: 10.07853

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.08631

Collected Steps per Second: 11,949.29083
Overall Steps per Second: 10,079.01142

Timestep Collection Time: 4.18652
Timestep Consumption Time: 0.77686
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 4.96338

Cumulative Model Updates: 36,208
Cumulative Timesteps: 604,044,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 604044566...
Checkpoint 604044566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453,436.63562
Policy Entropy: 1.09079
Value Function Loss: 10.45980

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.07907

Collected Steps per Second: 11,552.80621
Overall Steps per Second: 9,695.01313

Timestep Collection Time: 4.32986
Timestep Consumption Time: 0.82970
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.15956

Cumulative Model Updates: 36,211
Cumulative Timesteps: 604,094,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,137.94775
Policy Entropy: 1.07382
Value Function Loss: 10.00409

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.10083

Collected Steps per Second: 11,242.02402
Overall Steps per Second: 9,719.97594

Timestep Collection Time: 4.44831
Timestep Consumption Time: 0.69656
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 5.14487

Cumulative Model Updates: 36,214
Cumulative Timesteps: 604,144,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 604144596...
Checkpoint 604144596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,286.12945
Policy Entropy: 1.08583
Value Function Loss: 10.29677

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.10297

Collected Steps per Second: 11,210.95249
Overall Steps per Second: 9,577.35169

Timestep Collection Time: 4.46278
Timestep Consumption Time: 0.76121
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 5.22399

Cumulative Model Updates: 36,217
Cumulative Timesteps: 604,194,628

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350,408.07321
Policy Entropy: 1.09443
Value Function Loss: 10.32198

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.10113

Collected Steps per Second: 11,294.09767
Overall Steps per Second: 9,731.15732

Timestep Collection Time: 4.42780
Timestep Consumption Time: 0.71116
PPO Batch Consumption Time: 0.03925
Total Iteration Time: 5.13896

Cumulative Model Updates: 36,220
Cumulative Timesteps: 604,244,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 604244636...
Checkpoint 604244636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,639.92616
Policy Entropy: 1.09899
Value Function Loss: 10.45285

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.08973

Collected Steps per Second: 11,167.89302
Overall Steps per Second: 9,456.54188

Timestep Collection Time: 4.47891
Timestep Consumption Time: 0.81055
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 5.28946

Cumulative Model Updates: 36,223
Cumulative Timesteps: 604,294,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394,091.45312
Policy Entropy: 1.09334
Value Function Loss: 10.20647

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.10056

Collected Steps per Second: 11,055.74593
Overall Steps per Second: 9,411.77161

Timestep Collection Time: 4.52380
Timestep Consumption Time: 0.79018
PPO Batch Consumption Time: 0.03912
Total Iteration Time: 5.31398

Cumulative Model Updates: 36,226
Cumulative Timesteps: 604,344,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 604344670...
Checkpoint 604344670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,214.07325
Policy Entropy: 1.07720
Value Function Loss: 10.09382

Mean KL Divergence: 0.02767
SB3 Clip Fraction: 0.15246
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.08673

Collected Steps per Second: 11,386.38636
Overall Steps per Second: 9,672.33149

Timestep Collection Time: 4.39156
Timestep Consumption Time: 0.77824
PPO Batch Consumption Time: 0.03974
Total Iteration Time: 5.16980

Cumulative Model Updates: 36,229
Cumulative Timesteps: 604,394,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,265.80590
Policy Entropy: 1.09388
Value Function Loss: 10.52560

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.07556

Collected Steps per Second: 11,076.83867
Overall Steps per Second: 9,474.89303

Timestep Collection Time: 4.51428
Timestep Consumption Time: 0.76324
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.27753

Cumulative Model Updates: 36,232
Cumulative Timesteps: 604,444,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 604444678...
Checkpoint 604444678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,814.49174
Policy Entropy: 1.09668
Value Function Loss: 10.62738

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 10,785.32750
Overall Steps per Second: 9,317.82819

Timestep Collection Time: 4.63723
Timestep Consumption Time: 0.73033
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.36756

Cumulative Model Updates: 36,235
Cumulative Timesteps: 604,494,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,355.90560
Policy Entropy: 1.08829
Value Function Loss: 10.46900

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.07703

Collected Steps per Second: 10,997.75387
Overall Steps per Second: 9,364.32482

Timestep Collection Time: 4.54675
Timestep Consumption Time: 0.79309
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.33984

Cumulative Model Updates: 36,238
Cumulative Timesteps: 604,544,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 604544696...
Checkpoint 604544696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,529.72190
Policy Entropy: 1.07409
Value Function Loss: 10.15178

Mean KL Divergence: 0.03501
SB3 Clip Fraction: 0.17736
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.07112

Collected Steps per Second: 11,222.61859
Overall Steps per Second: 9,532.69098

Timestep Collection Time: 4.45707
Timestep Consumption Time: 0.79014
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.24721

Cumulative Model Updates: 36,241
Cumulative Timesteps: 604,594,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,242.83678
Policy Entropy: 1.09002
Value Function Loss: 9.97120

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.07288

Collected Steps per Second: 10,650.94602
Overall Steps per Second: 9,158.18155

Timestep Collection Time: 4.69592
Timestep Consumption Time: 0.76543
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.46135

Cumulative Model Updates: 36,244
Cumulative Timesteps: 604,644,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 604644732...
Checkpoint 604644732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417,833.72314
Policy Entropy: 1.09327
Value Function Loss: 9.86203

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.08178

Collected Steps per Second: 11,116.30568
Overall Steps per Second: 9,450.11472

Timestep Collection Time: 4.49808
Timestep Consumption Time: 0.79308
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.29115

Cumulative Model Updates: 36,247
Cumulative Timesteps: 604,694,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,151.91509
Policy Entropy: 1.08484
Value Function Loss: 9.77905

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 10,763.66272
Overall Steps per Second: 9,349.19020

Timestep Collection Time: 4.64712
Timestep Consumption Time: 0.70308
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.35020

Cumulative Model Updates: 36,250
Cumulative Timesteps: 604,744,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 604744754...
Checkpoint 604744754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,826.98242
Policy Entropy: 1.08359
Value Function Loss: 9.67964

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.06753

Collected Steps per Second: 10,976.09293
Overall Steps per Second: 9,348.90675

Timestep Collection Time: 4.55772
Timestep Consumption Time: 0.79328
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.35100

Cumulative Model Updates: 36,253
Cumulative Timesteps: 604,794,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,047.42279
Policy Entropy: 1.06694
Value Function Loss: 9.75743

Mean KL Divergence: 0.03314
SB3 Clip Fraction: 0.15366
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.07547

Collected Steps per Second: 10,843.69353
Overall Steps per Second: 9,236.32183

Timestep Collection Time: 4.61134
Timestep Consumption Time: 0.80250
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.41384

Cumulative Model Updates: 36,256
Cumulative Timesteps: 604,844,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 604844784...
Checkpoint 604844784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481,426.25746
Policy Entropy: 1.07908
Value Function Loss: 9.89934

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.08399

Collected Steps per Second: 10,946.94177
Overall Steps per Second: 9,513.00651

Timestep Collection Time: 4.56785
Timestep Consumption Time: 0.68853
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 5.25638

Cumulative Model Updates: 36,259
Cumulative Timesteps: 604,894,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373,381.51615
Policy Entropy: 1.08193
Value Function Loss: 9.98385

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.07373

Collected Steps per Second: 10,831.36110
Overall Steps per Second: 9,228.05511

Timestep Collection Time: 4.61807
Timestep Consumption Time: 0.80236
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.42043

Cumulative Model Updates: 36,262
Cumulative Timesteps: 604,944,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 604944808...
Checkpoint 604944808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,543.30818
Policy Entropy: 1.06179
Value Function Loss: 9.85109

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.09927

Collected Steps per Second: 11,382.34042
Overall Steps per Second: 9,720.31571

Timestep Collection Time: 4.39295
Timestep Consumption Time: 0.75113
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.14407

Cumulative Model Updates: 36,265
Cumulative Timesteps: 604,994,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399,928.09339
Policy Entropy: 1.05754
Value Function Loss: 10.03293

Mean KL Divergence: 0.02910
SB3 Clip Fraction: 0.14761
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.10029

Collected Steps per Second: 11,862.01307
Overall Steps per Second: 9,992.45662

Timestep Collection Time: 4.21699
Timestep Consumption Time: 0.78899
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 5.00598

Cumulative Model Updates: 36,268
Cumulative Timesteps: 605,044,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 605044832...
Checkpoint 605044832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,809.74425
Policy Entropy: 1.06962
Value Function Loss: 9.75192

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.09003

Collected Steps per Second: 11,070.64373
Overall Steps per Second: 9,277.58679

Timestep Collection Time: 4.51645
Timestep Consumption Time: 0.87288
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 5.38933

Cumulative Model Updates: 36,271
Cumulative Timesteps: 605,094,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,044.19172
Policy Entropy: 1.06673
Value Function Loss: 9.93648

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.08644

Collected Steps per Second: 11,637.47172
Overall Steps per Second: 9,998.39372

Timestep Collection Time: 4.29715
Timestep Consumption Time: 0.70445
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.00160

Cumulative Model Updates: 36,274
Cumulative Timesteps: 605,144,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 605144840...
Checkpoint 605144840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377,381.86956
Policy Entropy: 1.05852
Value Function Loss: 9.64441

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 11,043.88584
Overall Steps per Second: 9,391.03044

Timestep Collection Time: 4.53011
Timestep Consumption Time: 0.79732
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 5.32742

Cumulative Model Updates: 36,277
Cumulative Timesteps: 605,194,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,083.12736
Policy Entropy: 1.06253
Value Function Loss: 9.27595

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.10530
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 11,425.47135
Overall Steps per Second: 9,771.97622

Timestep Collection Time: 4.37776
Timestep Consumption Time: 0.74075
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.11851

Cumulative Model Updates: 36,280
Cumulative Timesteps: 605,244,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 605244888...
Checkpoint 605244888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387,792.57301
Policy Entropy: 1.06551
Value Function Loss: 9.46349

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.10664

Collected Steps per Second: 11,123.44256
Overall Steps per Second: 9,649.83910

Timestep Collection Time: 4.49519
Timestep Consumption Time: 0.68645
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.18164

Cumulative Model Updates: 36,283
Cumulative Timesteps: 605,294,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,437.17499
Policy Entropy: 1.06147
Value Function Loss: 9.66251

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.10666

Collected Steps per Second: 11,108.98111
Overall Steps per Second: 9,509.43586

Timestep Collection Time: 4.50338
Timestep Consumption Time: 0.75750
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.26088

Cumulative Model Updates: 36,286
Cumulative Timesteps: 605,344,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 605344918...
Checkpoint 605344918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,015.63629
Policy Entropy: 1.07229
Value Function Loss: 10.40494

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.09191

Collected Steps per Second: 11,178.19658
Overall Steps per Second: 9,498.50131

Timestep Collection Time: 4.47442
Timestep Consumption Time: 0.79125
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 5.26567

Cumulative Model Updates: 36,289
Cumulative Timesteps: 605,394,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,422.00197
Policy Entropy: 1.08155
Value Function Loss: 10.23675

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.07655

Collected Steps per Second: 11,384.12740
Overall Steps per Second: 9,682.44848

Timestep Collection Time: 4.39366
Timestep Consumption Time: 0.77218
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.16584

Cumulative Model Updates: 36,292
Cumulative Timesteps: 605,444,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 605444952...
Checkpoint 605444952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,903.37200
Policy Entropy: 1.07894
Value Function Loss: 9.88047

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.06719

Collected Steps per Second: 10,614.96188
Overall Steps per Second: 9,119.13453

Timestep Collection Time: 4.71165
Timestep Consumption Time: 0.77286
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.48451

Cumulative Model Updates: 36,295
Cumulative Timesteps: 605,494,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379,809.83686
Policy Entropy: 1.06150
Value Function Loss: 9.39900

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.06603

Collected Steps per Second: 11,206.20663
Overall Steps per Second: 9,757.78091

Timestep Collection Time: 4.46467
Timestep Consumption Time: 0.66273
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.12740

Cumulative Model Updates: 36,298
Cumulative Timesteps: 605,544,998

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 605544998...
Checkpoint 605544998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,456.97264
Policy Entropy: 1.07120
Value Function Loss: 9.50440

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.06050

Collected Steps per Second: 10,928.17158
Overall Steps per Second: 9,369.06171

Timestep Collection Time: 4.57533
Timestep Consumption Time: 0.76138
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.33671

Cumulative Model Updates: 36,301
Cumulative Timesteps: 605,594,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,870.82694
Policy Entropy: 1.07992
Value Function Loss: 9.43383

Mean KL Divergence: 0.02414
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.06712

Collected Steps per Second: 10,780.30892
Overall Steps per Second: 9,305.49207

Timestep Collection Time: 4.63957
Timestep Consumption Time: 0.73532
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.37489

Cumulative Model Updates: 36,304
Cumulative Timesteps: 605,645,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 605645014...
Checkpoint 605645014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415,842.52052
Policy Entropy: 1.07076
Value Function Loss: 9.59631

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.06273

Collected Steps per Second: 11,268.22206
Overall Steps per Second: 9,643.01828

Timestep Collection Time: 4.43992
Timestep Consumption Time: 0.74829
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.18821

Cumulative Model Updates: 36,307
Cumulative Timesteps: 605,695,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,322.04017
Policy Entropy: 1.05531
Value Function Loss: 9.13055

Mean KL Divergence: 0.04539
SB3 Clip Fraction: 0.18516
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.08394

Collected Steps per Second: 11,047.99639
Overall Steps per Second: 9,485.50458

Timestep Collection Time: 4.52770
Timestep Consumption Time: 0.74582
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.27352

Cumulative Model Updates: 36,310
Cumulative Timesteps: 605,745,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 605745066...
Checkpoint 605745066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,313.51543
Policy Entropy: 1.09451
Value Function Loss: 9.46418

Mean KL Divergence: 0.04086
SB3 Clip Fraction: 0.17959
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.07541

Collected Steps per Second: 10,632.36324
Overall Steps per Second: 9,310.61424

Timestep Collection Time: 4.70319
Timestep Consumption Time: 0.66767
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 5.37086

Cumulative Model Updates: 36,313
Cumulative Timesteps: 605,795,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469,820.40659
Policy Entropy: 1.07087
Value Function Loss: 9.39027

Mean KL Divergence: 0.04267
SB3 Clip Fraction: 0.19073
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.07473

Collected Steps per Second: 11,021.57411
Overall Steps per Second: 9,377.10405

Timestep Collection Time: 4.53692
Timestep Consumption Time: 0.79564
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.33256

Cumulative Model Updates: 36,316
Cumulative Timesteps: 605,845,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 605845076...
Checkpoint 605845076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,732.46532
Policy Entropy: 1.08775
Value Function Loss: 9.96583

Mean KL Divergence: 0.02560
SB3 Clip Fraction: 0.15418
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.06560

Collected Steps per Second: 11,054.94372
Overall Steps per Second: 9,479.41544

Timestep Collection Time: 4.52449
Timestep Consumption Time: 0.75199
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.27649

Cumulative Model Updates: 36,319
Cumulative Timesteps: 605,895,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,051.13012
Policy Entropy: 1.07142
Value Function Loss: 10.21833

Mean KL Divergence: 0.02613
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 11,168.28404
Overall Steps per Second: 9,535.00925

Timestep Collection Time: 4.47696
Timestep Consumption Time: 0.76687
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.24383

Cumulative Model Updates: 36,322
Cumulative Timesteps: 605,945,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 605945094...
Checkpoint 605945094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,085.75131
Policy Entropy: 1.05745
Value Function Loss: 10.15224

Mean KL Divergence: 0.03846
SB3 Clip Fraction: 0.17829
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.05616

Collected Steps per Second: 11,027.16093
Overall Steps per Second: 9,455.58511

Timestep Collection Time: 4.53589
Timestep Consumption Time: 0.75389
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.28978

Cumulative Model Updates: 36,325
Cumulative Timesteps: 605,995,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,132.88221
Policy Entropy: 1.06719
Value Function Loss: 9.89285

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.06221

Collected Steps per Second: 10,947.92682
Overall Steps per Second: 9,393.60501

Timestep Collection Time: 4.56854
Timestep Consumption Time: 0.75594
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.32447

Cumulative Model Updates: 36,328
Cumulative Timesteps: 606,045,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 606045128...
Checkpoint 606045128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,742.41798
Policy Entropy: 1.07815
Value Function Loss: 10.00582

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.06763

Collected Steps per Second: 11,109.47985
Overall Steps per Second: 9,504.80274

Timestep Collection Time: 4.50300
Timestep Consumption Time: 0.76023
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.26323

Cumulative Model Updates: 36,331
Cumulative Timesteps: 606,095,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,765.69851
Policy Entropy: 1.04391
Value Function Loss: 10.35031

Mean KL Divergence: 0.05879
SB3 Clip Fraction: 0.21429
Policy Update Magnitude: 0.06229
Value Function Update Magnitude: 0.06433

Collected Steps per Second: 11,930.55590
Overall Steps per Second: 10,129.15031

Timestep Collection Time: 4.19159
Timestep Consumption Time: 0.74545
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 4.93704

Cumulative Model Updates: 36,334
Cumulative Timesteps: 606,145,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 606145162...
Checkpoint 606145162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,931.98720
Policy Entropy: 1.07395
Value Function Loss: 10.07768

Mean KL Divergence: 0.03148
SB3 Clip Fraction: 0.15499
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.05314

Collected Steps per Second: 12,243.68727
Overall Steps per Second: 10,229.37628

Timestep Collection Time: 4.08537
Timestep Consumption Time: 0.80447
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.88984

Cumulative Model Updates: 36,337
Cumulative Timesteps: 606,195,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,025.65404
Policy Entropy: 1.06010
Value Function Loss: 9.83404

Mean KL Divergence: 0.02941
SB3 Clip Fraction: 0.15160
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.04487

Collected Steps per Second: 12,064.17405
Overall Steps per Second: 10,242.94318

Timestep Collection Time: 4.14483
Timestep Consumption Time: 0.73697
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 4.88180

Cumulative Model Updates: 36,340
Cumulative Timesteps: 606,245,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 606245186...
Checkpoint 606245186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396,025.29380
Policy Entropy: 1.07355
Value Function Loss: 9.97262

Mean KL Divergence: 0.02810
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.04081

Collected Steps per Second: 12,069.62860
Overall Steps per Second: 10,234.02135

Timestep Collection Time: 4.14445
Timestep Consumption Time: 0.74336
PPO Batch Consumption Time: 0.03876
Total Iteration Time: 4.88781

Cumulative Model Updates: 36,343
Cumulative Timesteps: 606,295,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,929.35875
Policy Entropy: 1.08398
Value Function Loss: 10.20512

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.05566

Collected Steps per Second: 11,926.98239
Overall Steps per Second: 9,869.11106

Timestep Collection Time: 4.19368
Timestep Consumption Time: 0.87445
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.06814

Cumulative Model Updates: 36,346
Cumulative Timesteps: 606,345,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 606345226...
Checkpoint 606345226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440,915.17378
Policy Entropy: 1.09554
Value Function Loss: 10.21957

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.06638
Value Function Update Magnitude: 0.06665

Collected Steps per Second: 11,817.23486
Overall Steps per Second: 10,018.04971

Timestep Collection Time: 4.23280
Timestep Consumption Time: 0.76019
PPO Batch Consumption Time: 0.03748
Total Iteration Time: 4.99299

Cumulative Model Updates: 36,349
Cumulative Timesteps: 606,395,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,911.07885
Policy Entropy: 1.08848
Value Function Loss: 10.12408

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.07018
Value Function Update Magnitude: 0.08045

Collected Steps per Second: 11,593.04459
Overall Steps per Second: 9,837.80370

Timestep Collection Time: 4.31414
Timestep Consumption Time: 0.76972
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 5.08386

Cumulative Model Updates: 36,352
Cumulative Timesteps: 606,445,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 606445260...
Checkpoint 606445260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,682.99731
Policy Entropy: 1.07986
Value Function Loss: 9.82561

Mean KL Divergence: 0.03184
SB3 Clip Fraction: 0.15126
Policy Update Magnitude: 0.06502
Value Function Update Magnitude: 0.08165

Collected Steps per Second: 11,239.21918
Overall Steps per Second: 9,532.87666

Timestep Collection Time: 4.45084
Timestep Consumption Time: 0.79668
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 5.24752

Cumulative Model Updates: 36,355
Cumulative Timesteps: 606,495,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,491.63006
Policy Entropy: 1.09871
Value Function Loss: 9.70747

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.07673

Collected Steps per Second: 11,114.32621
Overall Steps per Second: 9,588.89469

Timestep Collection Time: 4.49960
Timestep Consumption Time: 0.71581
PPO Batch Consumption Time: 0.04692
Total Iteration Time: 5.21541

Cumulative Model Updates: 36,358
Cumulative Timesteps: 606,545,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 606545294...
Checkpoint 606545294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,505.15375
Policy Entropy: 1.10200
Value Function Loss: 9.86220

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.06534

Collected Steps per Second: 11,353.39760
Overall Steps per Second: 9,626.98763

Timestep Collection Time: 4.40450
Timestep Consumption Time: 0.78986
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.19436

Cumulative Model Updates: 36,361
Cumulative Timesteps: 606,595,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,377.81595
Policy Entropy: 1.08858
Value Function Loss: 10.11846

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.07558

Collected Steps per Second: 10,643.32615
Overall Steps per Second: 9,142.00522

Timestep Collection Time: 4.69853
Timestep Consumption Time: 0.77160
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.47013

Cumulative Model Updates: 36,364
Cumulative Timesteps: 606,645,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 606645308...
Checkpoint 606645308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410,695.91865
Policy Entropy: 1.07413
Value Function Loss: 9.85309

Mean KL Divergence: 0.03755
SB3 Clip Fraction: 0.16141
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.08196

Collected Steps per Second: 11,357.93380
Overall Steps per Second: 9,654.90378

Timestep Collection Time: 4.40432
Timestep Consumption Time: 0.77688
PPO Batch Consumption Time: 0.03971
Total Iteration Time: 5.18120

Cumulative Model Updates: 36,367
Cumulative Timesteps: 606,695,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,453.16713
Policy Entropy: 1.08757
Value Function Loss: 9.84352

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.07315

Collected Steps per Second: 11,156.28186
Overall Steps per Second: 9,503.64930

Timestep Collection Time: 4.48375
Timestep Consumption Time: 0.77970
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 5.26345

Cumulative Model Updates: 36,370
Cumulative Timesteps: 606,745,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 606745354...
Checkpoint 606745354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,641.07777
Policy Entropy: 1.07869
Value Function Loss: 9.67532

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.07064

Collected Steps per Second: 11,023.61868
Overall Steps per Second: 9,581.54238

Timestep Collection Time: 4.53717
Timestep Consumption Time: 0.68287
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.22004

Cumulative Model Updates: 36,373
Cumulative Timesteps: 606,795,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,493.96330
Policy Entropy: 1.07657
Value Function Loss: 9.86277

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.06498

Collected Steps per Second: 11,153.42739
Overall Steps per Second: 9,535.76786

Timestep Collection Time: 4.48472
Timestep Consumption Time: 0.76079
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 5.24551

Cumulative Model Updates: 36,376
Cumulative Timesteps: 606,845,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 606845390...
Checkpoint 606845390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,640.51236
Policy Entropy: 1.07639
Value Function Loss: 9.72773

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.07340

Collected Steps per Second: 11,006.07121
Overall Steps per Second: 9,440.90291

Timestep Collection Time: 4.54331
Timestep Consumption Time: 0.75322
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.29653

Cumulative Model Updates: 36,379
Cumulative Timesteps: 606,895,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,847.80980
Policy Entropy: 1.07235
Value Function Loss: 9.51436

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.06428
Value Function Update Magnitude: 0.07565

Collected Steps per Second: 10,882.11683
Overall Steps per Second: 9,333.90420

Timestep Collection Time: 4.59745
Timestep Consumption Time: 0.76258
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.36003

Cumulative Model Updates: 36,382
Cumulative Timesteps: 606,945,424

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 606945424...
Checkpoint 606945424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,843.74070
Policy Entropy: 1.08557
Value Function Loss: 9.76974

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.07037

Collected Steps per Second: 10,950.81856
Overall Steps per Second: 9,306.74276

Timestep Collection Time: 4.56678
Timestep Consumption Time: 0.80674
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.37352

Cumulative Model Updates: 36,385
Cumulative Timesteps: 606,995,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,000.19094
Policy Entropy: 1.08715
Value Function Loss: 9.87172

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.07283

Collected Steps per Second: 10,914.11960
Overall Steps per Second: 9,475.71452

Timestep Collection Time: 4.58250
Timestep Consumption Time: 0.69562
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.27812

Cumulative Model Updates: 36,388
Cumulative Timesteps: 607,045,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 607045448...
Checkpoint 607045448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,109.17302
Policy Entropy: 1.08831
Value Function Loss: 10.04144

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.07863

Collected Steps per Second: 10,980.77916
Overall Steps per Second: 9,384.51124

Timestep Collection Time: 4.55469
Timestep Consumption Time: 0.77473
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.32942

Cumulative Model Updates: 36,391
Cumulative Timesteps: 607,095,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,266.09938
Policy Entropy: 1.08027
Value Function Loss: 9.76764

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.07264

Collected Steps per Second: 11,011.23803
Overall Steps per Second: 9,405.00711

Timestep Collection Time: 4.54154
Timestep Consumption Time: 0.77563
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.31717

Cumulative Model Updates: 36,394
Cumulative Timesteps: 607,145,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 607145470...
Checkpoint 607145470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,807.09884
Policy Entropy: 1.08195
Value Function Loss: 9.90808

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.07020

Collected Steps per Second: 11,293.53081
Overall Steps per Second: 9,454.43827

Timestep Collection Time: 4.42908
Timestep Consumption Time: 0.86155
PPO Batch Consumption Time: 0.03960
Total Iteration Time: 5.29064

Cumulative Model Updates: 36,397
Cumulative Timesteps: 607,195,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,347.04637
Policy Entropy: 1.08873
Value Function Loss: 10.06850

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.06560

Collected Steps per Second: 10,830.31365
Overall Steps per Second: 9,305.43808

Timestep Collection Time: 4.61759
Timestep Consumption Time: 0.75668
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.37428

Cumulative Model Updates: 36,400
Cumulative Timesteps: 607,245,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 607245500...
Checkpoint 607245500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,623.05392
Policy Entropy: 1.09536
Value Function Loss: 10.21550

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.07405

Collected Steps per Second: 11,593.15582
Overall Steps per Second: 10,073.22854

Timestep Collection Time: 4.31513
Timestep Consumption Time: 0.65110
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.96623

Cumulative Model Updates: 36,403
Cumulative Timesteps: 607,295,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,662.56964
Policy Entropy: 1.09150
Value Function Loss: 10.28190

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.06963

Collected Steps per Second: 11,606.52915
Overall Steps per Second: 9,878.64285

Timestep Collection Time: 4.30913
Timestep Consumption Time: 0.75371
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 5.06284

Cumulative Model Updates: 36,406
Cumulative Timesteps: 607,345,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 607345540...
Checkpoint 607345540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,088.21562
Policy Entropy: 1.08364
Value Function Loss: 10.51817

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.06857

Collected Steps per Second: 11,368.13281
Overall Steps per Second: 9,728.11284

Timestep Collection Time: 4.40019
Timestep Consumption Time: 0.74181
PPO Batch Consumption Time: 0.03844
Total Iteration Time: 5.14200

Cumulative Model Updates: 36,409
Cumulative Timesteps: 607,395,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,911.97778
Policy Entropy: 1.09105
Value Function Loss: 10.32707

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.06912

Collected Steps per Second: 11,603.33297
Overall Steps per Second: 9,842.71804

Timestep Collection Time: 4.31014
Timestep Consumption Time: 0.77098
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.08112

Cumulative Model Updates: 36,412
Cumulative Timesteps: 607,445,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 607445574...
Checkpoint 607445574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,857.09713
Policy Entropy: 1.10249
Value Function Loss: 9.76342

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.06274

Collected Steps per Second: 11,171.93849
Overall Steps per Second: 9,477.28983

Timestep Collection Time: 4.47693
Timestep Consumption Time: 0.80053
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 5.27746

Cumulative Model Updates: 36,415
Cumulative Timesteps: 607,495,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419,333.69900
Policy Entropy: 1.09623
Value Function Loss: 9.62615

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.07252

Collected Steps per Second: 11,505.03196
Overall Steps per Second: 9,896.75217

Timestep Collection Time: 4.34697
Timestep Consumption Time: 0.70641
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.05337

Cumulative Model Updates: 36,418
Cumulative Timesteps: 607,545,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 607545602...
Checkpoint 607545602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388,868.39207
Policy Entropy: 1.09579
Value Function Loss: 9.59134

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 10,910.96046
Overall Steps per Second: 9,344.24128

Timestep Collection Time: 4.58291
Timestep Consumption Time: 0.76840
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.35132

Cumulative Model Updates: 36,421
Cumulative Timesteps: 607,595,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418,221.84219
Policy Entropy: 1.09263
Value Function Loss: 10.35283

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.07097

Collected Steps per Second: 11,382.32346
Overall Steps per Second: 9,647.93692

Timestep Collection Time: 4.39383
Timestep Consumption Time: 0.78987
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.18370

Cumulative Model Updates: 36,424
Cumulative Timesteps: 607,645,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 607645618...
Checkpoint 607645618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,936.45277
Policy Entropy: 1.11116
Value Function Loss: 10.42616

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 11,496.43685
Overall Steps per Second: 9,743.52594

Timestep Collection Time: 4.35039
Timestep Consumption Time: 0.78266
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 5.13305

Cumulative Model Updates: 36,427
Cumulative Timesteps: 607,695,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408,442.44410
Policy Entropy: 1.10867
Value Function Loss: 10.13200

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.07167

Collected Steps per Second: 11,146.60584
Overall Steps per Second: 9,532.07924

Timestep Collection Time: 4.48693
Timestep Consumption Time: 0.75999
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.24691

Cumulative Model Updates: 36,430
Cumulative Timesteps: 607,745,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 607745646...
Checkpoint 607745646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,142.60305
Policy Entropy: 1.09467
Value Function Loss: 9.79225

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.07142

Collected Steps per Second: 10,646.43491
Overall Steps per Second: 9,287.54223

Timestep Collection Time: 4.69772
Timestep Consumption Time: 0.68734
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.38506

Cumulative Model Updates: 36,433
Cumulative Timesteps: 607,795,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,523.39635
Policy Entropy: 1.08904
Value Function Loss: 10.16588

Mean KL Divergence: 0.03323
SB3 Clip Fraction: 0.17161
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.06313

Collected Steps per Second: 11,004.32148
Overall Steps per Second: 9,443.26203

Timestep Collection Time: 4.54440
Timestep Consumption Time: 0.75123
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.29563

Cumulative Model Updates: 36,436
Cumulative Timesteps: 607,845,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 607845668...
Checkpoint 607845668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369,644.84128
Policy Entropy: 1.09719
Value Function Loss: 10.75494

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.07226

Collected Steps per Second: 11,103.19696
Overall Steps per Second: 9,665.59253

Timestep Collection Time: 4.50501
Timestep Consumption Time: 0.67005
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.17506

Cumulative Model Updates: 36,439
Cumulative Timesteps: 607,895,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,693.13852
Policy Entropy: 1.11372
Value Function Loss: 10.94601

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.06971

Collected Steps per Second: 10,990.68220
Overall Steps per Second: 9,387.55434

Timestep Collection Time: 4.55022
Timestep Consumption Time: 0.77705
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.32727

Cumulative Model Updates: 36,442
Cumulative Timesteps: 607,945,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 607945698...
Checkpoint 607945698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,309.82390
Policy Entropy: 1.07141
Value Function Loss: 10.00555

Mean KL Divergence: 0.05439
SB3 Clip Fraction: 0.20613
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.06305

Collected Steps per Second: 10,995.89705
Overall Steps per Second: 9,425.72824

Timestep Collection Time: 4.54861
Timestep Consumption Time: 0.75772
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.30633

Cumulative Model Updates: 36,445
Cumulative Timesteps: 607,995,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,684.88288
Policy Entropy: 1.09622
Value Function Loss: 9.89896

Mean KL Divergence: 0.02734
SB3 Clip Fraction: 0.16129
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.06546

Collected Steps per Second: 11,166.26490
Overall Steps per Second: 9,465.43246

Timestep Collection Time: 4.47867
Timestep Consumption Time: 0.80477
PPO Batch Consumption Time: 0.03910
Total Iteration Time: 5.28344

Cumulative Model Updates: 36,448
Cumulative Timesteps: 608,045,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 608045724...
Checkpoint 608045724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,304.36607
Policy Entropy: 1.08689
Value Function Loss: 9.99938

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.15234
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.06702

Collected Steps per Second: 10,644.57397
Overall Steps per Second: 9,127.50406

Timestep Collection Time: 4.69817
Timestep Consumption Time: 0.78088
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.47904

Cumulative Model Updates: 36,451
Cumulative Timesteps: 608,095,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,577.04197
Policy Entropy: 1.07838
Value Function Loss: 10.19847

Mean KL Divergence: 0.03297
SB3 Clip Fraction: 0.17244
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 10,953.98210
Overall Steps per Second: 9,535.75062

Timestep Collection Time: 4.56546
Timestep Consumption Time: 0.67901
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.24447

Cumulative Model Updates: 36,454
Cumulative Timesteps: 608,145,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 608145744...
Checkpoint 608145744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366,307.35190
Policy Entropy: 1.09519
Value Function Loss: 9.94065

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.07682

Collected Steps per Second: 11,033.93111
Overall Steps per Second: 9,399.23119

Timestep Collection Time: 4.53166
Timestep Consumption Time: 0.78814
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 5.31980

Cumulative Model Updates: 36,457
Cumulative Timesteps: 608,195,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,508.13338
Policy Entropy: 1.09869
Value Function Loss: 9.30967

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 11,131.01518
Overall Steps per Second: 9,479.15093

Timestep Collection Time: 4.49249
Timestep Consumption Time: 0.78287
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 5.27537

Cumulative Model Updates: 36,460
Cumulative Timesteps: 608,245,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 608245752...
Checkpoint 608245752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,298.57946
Policy Entropy: 1.08602
Value Function Loss: 9.13002

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 11,214.54068
Overall Steps per Second: 9,570.54180

Timestep Collection Time: 4.45868
Timestep Consumption Time: 0.76590
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.22457

Cumulative Model Updates: 36,463
Cumulative Timesteps: 608,295,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,183.95702
Policy Entropy: 1.07699
Value Function Loss: 8.97464

Mean KL Divergence: 0.03471
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.04341
Value Function Update Magnitude: 0.08760

Collected Steps per Second: 10,638.94478
Overall Steps per Second: 9,063.69684

Timestep Collection Time: 4.69990
Timestep Consumption Time: 0.81683
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.51673

Cumulative Model Updates: 36,466
Cumulative Timesteps: 608,345,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 608345756...
Checkpoint 608345756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,494.35829
Policy Entropy: 1.09555
Value Function Loss: 9.31227

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.09258

Collected Steps per Second: 11,229.20500
Overall Steps per Second: 9,714.12199

Timestep Collection Time: 4.45357
Timestep Consumption Time: 0.69461
PPO Batch Consumption Time: 0.03289
Total Iteration Time: 5.14817

Cumulative Model Updates: 36,469
Cumulative Timesteps: 608,395,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,444.85329
Policy Entropy: 1.09481
Value Function Loss: 9.93940

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.09056

Collected Steps per Second: 12,219.32113
Overall Steps per Second: 10,271.83426

Timestep Collection Time: 4.09221
Timestep Consumption Time: 0.77586
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 4.86807

Cumulative Model Updates: 36,472
Cumulative Timesteps: 608,445,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 608445770...
Checkpoint 608445770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,453.42933
Policy Entropy: 1.09681
Value Function Loss: 9.79437

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.08383

Collected Steps per Second: 11,604.34124
Overall Steps per Second: 9,754.39327

Timestep Collection Time: 4.31046
Timestep Consumption Time: 0.81749
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.12795

Cumulative Model Updates: 36,475
Cumulative Timesteps: 608,495,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,537.11614
Policy Entropy: 1.08470
Value Function Loss: 9.60458

Mean KL Divergence: 0.03510
SB3 Clip Fraction: 0.16286
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.07907

Collected Steps per Second: 12,157.69945
Overall Steps per Second: 10,198.19432

Timestep Collection Time: 4.11361
Timestep Consumption Time: 0.79040
PPO Batch Consumption Time: 0.03846
Total Iteration Time: 4.90401

Cumulative Model Updates: 36,478
Cumulative Timesteps: 608,545,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 608545802...
Checkpoint 608545802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,198.35521
Policy Entropy: 1.10267
Value Function Loss: 9.80135

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.08168

Collected Steps per Second: 12,217.69634
Overall Steps per Second: 10,142.12544

Timestep Collection Time: 4.09308
Timestep Consumption Time: 0.83764
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 4.93072

Cumulative Model Updates: 36,481
Cumulative Timesteps: 608,595,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,715.77444
Policy Entropy: 1.10099
Value Function Loss: 9.70668

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.07674

Collected Steps per Second: 11,429.95731
Overall Steps per Second: 9,790.68731

Timestep Collection Time: 4.37639
Timestep Consumption Time: 0.73275
PPO Batch Consumption Time: 0.03884
Total Iteration Time: 5.10914

Cumulative Model Updates: 36,484
Cumulative Timesteps: 608,645,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 608645832...
Checkpoint 608645832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,915.83178
Policy Entropy: 1.08518
Value Function Loss: 9.63815

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.07285

Collected Steps per Second: 11,525.58639
Overall Steps per Second: 9,763.64570

Timestep Collection Time: 4.34095
Timestep Consumption Time: 0.78336
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 5.12432

Cumulative Model Updates: 36,487
Cumulative Timesteps: 608,695,864

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,256.68171
Policy Entropy: 1.07711
Value Function Loss: 8.94631

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.05939

Collected Steps per Second: 11,043.30303
Overall Steps per Second: 9,491.41797

Timestep Collection Time: 4.52781
Timestep Consumption Time: 0.74032
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.26813

Cumulative Model Updates: 36,490
Cumulative Timesteps: 608,745,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 608745866...
Checkpoint 608745866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350,565.54615
Policy Entropy: 1.09202
Value Function Loss: 9.16236

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.05059

Collected Steps per Second: 11,281.85090
Overall Steps per Second: 9,608.18720

Timestep Collection Time: 4.43261
Timestep Consumption Time: 0.77212
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.20473

Cumulative Model Updates: 36,493
Cumulative Timesteps: 608,795,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,352.30176
Policy Entropy: 1.09957
Value Function Loss: 9.19842

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.04421
Value Function Update Magnitude: 0.04440

Collected Steps per Second: 11,079.87572
Overall Steps per Second: 9,409.55565

Timestep Collection Time: 4.51521
Timestep Consumption Time: 0.80151
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 5.31672

Cumulative Model Updates: 36,496
Cumulative Timesteps: 608,845,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 608845902...
Checkpoint 608845902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,992.79840
Policy Entropy: 1.08553
Value Function Loss: 9.31916

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.04397

Collected Steps per Second: 11,266.11329
Overall Steps per Second: 9,741.85563

Timestep Collection Time: 4.43880
Timestep Consumption Time: 0.69452
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.13331

Cumulative Model Updates: 36,499
Cumulative Timesteps: 608,895,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307,378.34048
Policy Entropy: 1.07867
Value Function Loss: 9.77383

Mean KL Divergence: 0.02982
SB3 Clip Fraction: 0.14850
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.05015

Collected Steps per Second: 10,822.74665
Overall Steps per Second: 9,275.65144

Timestep Collection Time: 4.62119
Timestep Consumption Time: 0.77077
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.39197

Cumulative Model Updates: 36,502
Cumulative Timesteps: 608,945,924

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 608945924...
Checkpoint 608945924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,246.55814
Policy Entropy: 1.09040
Value Function Loss: 9.62699

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.04910

Collected Steps per Second: 10,889.98506
Overall Steps per Second: 9,491.07818

Timestep Collection Time: 4.59229
Timestep Consumption Time: 0.67687
PPO Batch Consumption Time: 0.03778
Total Iteration Time: 5.26916

Cumulative Model Updates: 36,505
Cumulative Timesteps: 608,995,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,968.96876
Policy Entropy: 1.09953
Value Function Loss: 9.68236

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.04854

Collected Steps per Second: 10,595.35828
Overall Steps per Second: 9,021.44580

Timestep Collection Time: 4.72150
Timestep Consumption Time: 0.82373
PPO Batch Consumption Time: 0.03732
Total Iteration Time: 5.54523

Cumulative Model Updates: 36,508
Cumulative Timesteps: 609,045,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 609045960...
Checkpoint 609045960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,889.16819
Policy Entropy: 1.07024
Value Function Loss: 9.46915

Mean KL Divergence: 0.02815
SB3 Clip Fraction: 0.17231
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.04712

Collected Steps per Second: 10,259.37510
Overall Steps per Second: 8,747.31459

Timestep Collection Time: 4.87457
Timestep Consumption Time: 0.84262
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.71718

Cumulative Model Updates: 36,511
Cumulative Timesteps: 609,095,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398,367.55042
Policy Entropy: 1.09534
Value Function Loss: 9.85363

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.04551

Collected Steps per Second: 10,930.36804
Overall Steps per Second: 9,493.02513

Timestep Collection Time: 4.57661
Timestep Consumption Time: 0.69295
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.26955

Cumulative Model Updates: 36,514
Cumulative Timesteps: 609,145,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 609145994...
Checkpoint 609145994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,890.59783
Policy Entropy: 1.09520
Value Function Loss: 10.06813

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.04620

Collected Steps per Second: 10,959.17913
Overall Steps per Second: 9,287.37549

Timestep Collection Time: 4.56257
Timestep Consumption Time: 0.82130
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.38387

Cumulative Model Updates: 36,517
Cumulative Timesteps: 609,195,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,405.06217
Policy Entropy: 1.08631
Value Function Loss: 9.76665

Mean KL Divergence: 0.02875
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.04189

Collected Steps per Second: 10,541.23682
Overall Steps per Second: 9,166.87794

Timestep Collection Time: 4.74441
Timestep Consumption Time: 0.71131
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.45573

Cumulative Model Updates: 36,520
Cumulative Timesteps: 609,246,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 609246008...
Checkpoint 609246008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,628.91692
Policy Entropy: 1.07246
Value Function Loss: 9.41723

Mean KL Divergence: 0.03714
SB3 Clip Fraction: 0.17815
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.04366

Collected Steps per Second: 10,801.55686
Overall Steps per Second: 9,185.17074

Timestep Collection Time: 4.63007
Timestep Consumption Time: 0.81479
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.44486

Cumulative Model Updates: 36,523
Cumulative Timesteps: 609,296,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,392.30474
Policy Entropy: 1.07991
Value Function Loss: 9.29233

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.04218

Collected Steps per Second: 10,956.84581
Overall Steps per Second: 9,438.55058

Timestep Collection Time: 4.56555
Timestep Consumption Time: 0.73442
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.29997

Cumulative Model Updates: 36,526
Cumulative Timesteps: 609,346,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 609346044...
Checkpoint 609346044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432,573.52510
Policy Entropy: 1.08918
Value Function Loss: 9.53609

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.11102
Policy Update Magnitude: 0.06649
Value Function Update Magnitude: 0.04484

Collected Steps per Second: 10,885.47431
Overall Steps per Second: 9,465.74615

Timestep Collection Time: 4.59438
Timestep Consumption Time: 0.68909
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 5.28347

Cumulative Model Updates: 36,529
Cumulative Timesteps: 609,396,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,749.81466
Policy Entropy: 1.08077
Value Function Loss: 9.50575

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.03976

Collected Steps per Second: 10,891.97788
Overall Steps per Second: 9,280.74780

Timestep Collection Time: 4.59329
Timestep Consumption Time: 0.79744
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.39073

Cumulative Model Updates: 36,532
Cumulative Timesteps: 609,446,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 609446086...
Checkpoint 609446086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,141.16476
Policy Entropy: 1.06435
Value Function Loss: 9.45259

Mean KL Divergence: 0.02618
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.06559
Value Function Update Magnitude: 0.04014

Collected Steps per Second: 10,502.68856
Overall Steps per Second: 9,004.55576

Timestep Collection Time: 4.76297
Timestep Consumption Time: 0.79244
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.55541

Cumulative Model Updates: 36,535
Cumulative Timesteps: 609,496,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,968.81521
Policy Entropy: 1.08182
Value Function Loss: 9.85084

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.04354

Collected Steps per Second: 11,729.83821
Overall Steps per Second: 9,913.21201

Timestep Collection Time: 4.26297
Timestep Consumption Time: 0.78120
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.04418

Cumulative Model Updates: 36,538
Cumulative Timesteps: 609,546,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 609546114...
Checkpoint 609546114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,111.38457
Policy Entropy: 1.08780
Value Function Loss: 9.91128

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.04223

Collected Steps per Second: 11,711.72831
Overall Steps per Second: 9,915.78640

Timestep Collection Time: 4.27042
Timestep Consumption Time: 0.77346
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.04388

Cumulative Model Updates: 36,541
Cumulative Timesteps: 609,596,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,104.39632
Policy Entropy: 1.07658
Value Function Loss: 10.08755

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.14501
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.05323

Collected Steps per Second: 11,221.90025
Overall Steps per Second: 9,761.02445

Timestep Collection Time: 4.45807
Timestep Consumption Time: 0.66721
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.12528

Cumulative Model Updates: 36,544
Cumulative Timesteps: 609,646,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 609646156...
Checkpoint 609646156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,452.39839
Policy Entropy: 1.07385
Value Function Loss: 9.86640

Mean KL Divergence: 0.03050
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.04576

Collected Steps per Second: 11,376.97569
Overall Steps per Second: 9,592.49482

Timestep Collection Time: 4.39677
Timestep Consumption Time: 0.81793
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.21470

Cumulative Model Updates: 36,547
Cumulative Timesteps: 609,696,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,408.08821
Policy Entropy: 1.08623
Value Function Loss: 9.88150

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.04367

Collected Steps per Second: 11,417.31510
Overall Steps per Second: 9,770.03169

Timestep Collection Time: 4.38001
Timestep Consumption Time: 0.73850
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.11851

Cumulative Model Updates: 36,550
Cumulative Timesteps: 609,746,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 609746186...
Checkpoint 609746186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,808.00653
Policy Entropy: 1.09794
Value Function Loss: 10.17270

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.04968

Collected Steps per Second: 10,936.56419
Overall Steps per Second: 9,477.84593

Timestep Collection Time: 4.57273
Timestep Consumption Time: 0.70378
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 5.27652

Cumulative Model Updates: 36,553
Cumulative Timesteps: 609,796,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,045.29438
Policy Entropy: 1.06848
Value Function Loss: 10.31887

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.04447

Collected Steps per Second: 11,122.10038
Overall Steps per Second: 9,323.33562

Timestep Collection Time: 4.49681
Timestep Consumption Time: 0.86758
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.36439

Cumulative Model Updates: 36,556
Cumulative Timesteps: 609,846,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 609846210...
Checkpoint 609846210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,931.95809
Policy Entropy: 1.08097
Value Function Loss: 10.04197

Mean KL Divergence: 0.02530
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.04348

Collected Steps per Second: 11,188.66230
Overall Steps per Second: 9,501.36737

Timestep Collection Time: 4.47131
Timestep Consumption Time: 0.79404
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.26535

Cumulative Model Updates: 36,559
Cumulative Timesteps: 609,896,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,548.25761
Policy Entropy: 1.09249
Value Function Loss: 9.46509

Mean KL Divergence: 0.03014
SB3 Clip Fraction: 0.15623
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.04610

Collected Steps per Second: 10,918.11267
Overall Steps per Second: 9,292.06069

Timestep Collection Time: 4.58229
Timestep Consumption Time: 0.80187
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 5.38417

Cumulative Model Updates: 36,562
Cumulative Timesteps: 609,946,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 609946268...
Checkpoint 609946268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,539.27030
Policy Entropy: 1.06979
Value Function Loss: 8.96146

Mean KL Divergence: 0.02492
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.04064

Collected Steps per Second: 11,180.55103
Overall Steps per Second: 9,546.13785

Timestep Collection Time: 4.47205
Timestep Consumption Time: 0.76567
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 5.23772

Cumulative Model Updates: 36,565
Cumulative Timesteps: 609,996,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,809.32998
Policy Entropy: 1.09640
Value Function Loss: 8.94237

Mean KL Divergence: 0.03393
SB3 Clip Fraction: 0.15820
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.05062

Collected Steps per Second: 11,298.11562
Overall Steps per Second: 9,648.28943

Timestep Collection Time: 4.42676
Timestep Consumption Time: 0.75696
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 5.18372

Cumulative Model Updates: 36,568
Cumulative Timesteps: 610,046,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 610046282...
Checkpoint 610046282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,301.57685
Policy Entropy: 1.08582
Value Function Loss: 9.06242

Mean KL Divergence: 0.02776
SB3 Clip Fraction: 0.15659
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 10,598.44921
Overall Steps per Second: 9,038.91471

Timestep Collection Time: 4.71956
Timestep Consumption Time: 0.81429
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.53385

Cumulative Model Updates: 36,571
Cumulative Timesteps: 610,096,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,516.10538
Policy Entropy: 1.08829
Value Function Loss: 8.91791

Mean KL Divergence: 0.02651
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.04396

Collected Steps per Second: 11,045.72456
Overall Steps per Second: 9,433.49509

Timestep Collection Time: 4.52881
Timestep Consumption Time: 0.77400
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.30281

Cumulative Model Updates: 36,574
Cumulative Timesteps: 610,146,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 610146326...
Checkpoint 610146326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372,383.56011
Policy Entropy: 1.07053
Value Function Loss: 8.84006

Mean KL Divergence: 0.04511
SB3 Clip Fraction: 0.18294
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.03911

Collected Steps per Second: 11,294.99064
Overall Steps per Second: 9,614.31018

Timestep Collection Time: 4.42887
Timestep Consumption Time: 0.77421
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 5.20308

Cumulative Model Updates: 36,577
Cumulative Timesteps: 610,196,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414,034.03496
Policy Entropy: 1.09781
Value Function Loss: 9.03701

Mean KL Divergence: 0.02461
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.04730

Collected Steps per Second: 11,020.87536
Overall Steps per Second: 9,401.70008

Timestep Collection Time: 4.53757
Timestep Consumption Time: 0.78147
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.31904

Cumulative Model Updates: 36,580
Cumulative Timesteps: 610,246,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 610246358...
Checkpoint 610246358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398,310.74414
Policy Entropy: 1.09111
Value Function Loss: 9.24337

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.05116

Collected Steps per Second: 10,965.78356
Overall Steps per Second: 9,570.67288

Timestep Collection Time: 4.56073
Timestep Consumption Time: 0.66481
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.22555

Cumulative Model Updates: 36,583
Cumulative Timesteps: 610,296,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,790.54214
Policy Entropy: 1.08982
Value Function Loss: 9.85768

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.05165

Collected Steps per Second: 10,766.07319
Overall Steps per Second: 9,268.83988

Timestep Collection Time: 4.64626
Timestep Consumption Time: 0.75053
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 5.39679

Cumulative Model Updates: 36,586
Cumulative Timesteps: 610,346,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 610346392...
Checkpoint 610346392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,490.04890
Policy Entropy: 1.09406
Value Function Loss: 9.91187

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.05530

Collected Steps per Second: 11,052.85749
Overall Steps per Second: 9,455.13602

Timestep Collection Time: 4.52498
Timestep Consumption Time: 0.76463
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.28961

Cumulative Model Updates: 36,589
Cumulative Timesteps: 610,396,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372,132.48996
Policy Entropy: 1.09735
Value Function Loss: 9.76694

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.08256

Collected Steps per Second: 11,102.70450
Overall Steps per Second: 9,382.08251

Timestep Collection Time: 4.50611
Timestep Consumption Time: 0.82640
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.33250

Cumulative Model Updates: 36,592
Cumulative Timesteps: 610,446,436

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 610446436...
Checkpoint 610446436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,139.85800
Policy Entropy: 1.09278
Value Function Loss: 9.52634

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.10429
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.07801

Collected Steps per Second: 10,820.94046
Overall Steps per Second: 9,317.39178

Timestep Collection Time: 4.62159
Timestep Consumption Time: 0.74579
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.36738

Cumulative Model Updates: 36,595
Cumulative Timesteps: 610,496,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379,757.04197
Policy Entropy: 1.09880
Value Function Loss: 10.31680

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.06922

Collected Steps per Second: 10,554.98025
Overall Steps per Second: 9,239.19417

Timestep Collection Time: 4.73937
Timestep Consumption Time: 0.67495
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 5.41432

Cumulative Model Updates: 36,598
Cumulative Timesteps: 610,546,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 610546470...
Checkpoint 610546470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,408.60963
Policy Entropy: 1.10099
Value Function Loss: 10.49905

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.07431

Collected Steps per Second: 10,932.54055
Overall Steps per Second: 9,357.90846

Timestep Collection Time: 4.57369
Timestep Consumption Time: 0.76960
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.34329

Cumulative Model Updates: 36,601
Cumulative Timesteps: 610,596,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,827.60171
Policy Entropy: 1.10517
Value Function Loss: 10.31138

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.09596

Collected Steps per Second: 10,383.63006
Overall Steps per Second: 9,070.77839

Timestep Collection Time: 4.81701
Timestep Consumption Time: 0.69719
PPO Batch Consumption Time: 0.03823
Total Iteration Time: 5.51419

Cumulative Model Updates: 36,604
Cumulative Timesteps: 610,646,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 610646490...
Checkpoint 610646490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,801.78518
Policy Entropy: 1.11379
Value Function Loss: 9.43439

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.10319

Collected Steps per Second: 12,106.46515
Overall Steps per Second: 10,215.13173

Timestep Collection Time: 4.13118
Timestep Consumption Time: 0.76489
PPO Batch Consumption Time: 0.03368
Total Iteration Time: 4.89607

Cumulative Model Updates: 36,607
Cumulative Timesteps: 610,696,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,107.91259
Policy Entropy: 1.10735
Value Function Loss: 9.50283

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.08782
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.08694

Collected Steps per Second: 11,760.88862
Overall Steps per Second: 9,970.34120

Timestep Collection Time: 4.25189
Timestep Consumption Time: 0.76359
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.01548

Cumulative Model Updates: 36,610
Cumulative Timesteps: 610,746,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 610746510...
Checkpoint 610746510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,281.51567
Policy Entropy: 1.11053
Value Function Loss: 9.45848

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.07363

Collected Steps per Second: 11,679.26747
Overall Steps per Second: 10,020.42500

Timestep Collection Time: 4.28143
Timestep Consumption Time: 0.70877
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 4.99021

Cumulative Model Updates: 36,613
Cumulative Timesteps: 610,796,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,577.94876
Policy Entropy: 1.11767
Value Function Loss: 9.18304

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 11,628.96105
Overall Steps per Second: 9,836.56006

Timestep Collection Time: 4.30116
Timestep Consumption Time: 0.78375
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.08491

Cumulative Model Updates: 36,616
Cumulative Timesteps: 610,846,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 610846532...
Checkpoint 610846532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410,513.71314
Policy Entropy: 1.10881
Value Function Loss: 9.04345

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.07471

Collected Steps per Second: 11,713.18006
Overall Steps per Second: 10,101.38149

Timestep Collection Time: 4.27126
Timestep Consumption Time: 0.68153
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.95279

Cumulative Model Updates: 36,619
Cumulative Timesteps: 610,896,562

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,982.48908
Policy Entropy: 1.09120
Value Function Loss: 9.19833

Mean KL Divergence: 0.03695
SB3 Clip Fraction: 0.17891
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 11,406.70958
Overall Steps per Second: 9,618.79087

Timestep Collection Time: 4.38374
Timestep Consumption Time: 0.81484
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 5.19857

Cumulative Model Updates: 36,622
Cumulative Timesteps: 610,946,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 610946566...
Checkpoint 610946566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,163.27074
Policy Entropy: 1.11290
Value Function Loss: 10.00891

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.07467

Collected Steps per Second: 11,128.38832
Overall Steps per Second: 9,404.92544

Timestep Collection Time: 4.49481
Timestep Consumption Time: 0.82368
PPO Batch Consumption Time: 0.03907
Total Iteration Time: 5.31849

Cumulative Model Updates: 36,625
Cumulative Timesteps: 610,996,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386,542.55999
Policy Entropy: 1.10976
Value Function Loss: 9.86910

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.07123

Collected Steps per Second: 11,104.24258
Overall Steps per Second: 9,425.99242

Timestep Collection Time: 4.50314
Timestep Consumption Time: 0.80176
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 5.30491

Cumulative Model Updates: 36,628
Cumulative Timesteps: 611,046,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 611046590...
Checkpoint 611046590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,503.26358
Policy Entropy: 1.08629
Value Function Loss: 10.09864

Mean KL Divergence: 0.05605
SB3 Clip Fraction: 0.19119
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.07788

Collected Steps per Second: 11,237.30986
Overall Steps per Second: 9,589.06896

Timestep Collection Time: 4.45107
Timestep Consumption Time: 0.76508
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.21615

Cumulative Model Updates: 36,631
Cumulative Timesteps: 611,096,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,303.63043
Policy Entropy: 1.12042
Value Function Loss: 9.68602

Mean KL Divergence: 0.03580
SB3 Clip Fraction: 0.18365
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.07445

Collected Steps per Second: 11,269.13881
Overall Steps per Second: 9,704.97825

Timestep Collection Time: 4.43743
Timestep Consumption Time: 0.71518
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 5.15261

Cumulative Model Updates: 36,634
Cumulative Timesteps: 611,146,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 611146614...
Checkpoint 611146614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,219.28467
Policy Entropy: 1.08295
Value Function Loss: 9.82436

Mean KL Divergence: 0.07507
SB3 Clip Fraction: 0.20706
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.06759

Collected Steps per Second: 10,808.41146
Overall Steps per Second: 9,201.14364

Timestep Collection Time: 4.62603
Timestep Consumption Time: 0.80808
PPO Batch Consumption Time: 0.04019
Total Iteration Time: 5.43411

Cumulative Model Updates: 36,637
Cumulative Timesteps: 611,196,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,116.40131
Policy Entropy: 1.11247
Value Function Loss: 9.84344

Mean KL Divergence: 0.04811
SB3 Clip Fraction: 0.18329
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.06370

Collected Steps per Second: 10,990.52170
Overall Steps per Second: 9,443.13517

Timestep Collection Time: 4.55138
Timestep Consumption Time: 0.74581
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.29718

Cumulative Model Updates: 36,640
Cumulative Timesteps: 611,246,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 611246636...
Checkpoint 611246636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417,631.88526
Policy Entropy: 1.08545
Value Function Loss: 9.68440

Mean KL Divergence: 0.07221
SB3 Clip Fraction: 0.22243
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.06379

Collected Steps per Second: 11,272.90489
Overall Steps per Second: 9,623.01429

Timestep Collection Time: 4.43772
Timestep Consumption Time: 0.76086
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.19858

Cumulative Model Updates: 36,643
Cumulative Timesteps: 611,296,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,081.80191
Policy Entropy: 1.11096
Value Function Loss: 9.55209

Mean KL Divergence: 0.04605
SB3 Clip Fraction: 0.19015
Policy Update Magnitude: 0.04262
Value Function Update Magnitude: 0.07621

Collected Steps per Second: 11,032.18937
Overall Steps per Second: 9,355.14609

Timestep Collection Time: 4.53310
Timestep Consumption Time: 0.81262
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.34572

Cumulative Model Updates: 36,646
Cumulative Timesteps: 611,346,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 611346672...
Checkpoint 611346672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,065.91265
Policy Entropy: 1.09991
Value Function Loss: 9.53380

Mean KL Divergence: 0.03172
SB3 Clip Fraction: 0.16051
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.07544

Collected Steps per Second: 11,061.46116
Overall Steps per Second: 9,646.62999

Timestep Collection Time: 4.52273
Timestep Consumption Time: 0.66333
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.18606

Cumulative Model Updates: 36,649
Cumulative Timesteps: 611,396,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,549.71769
Policy Entropy: 1.10992
Value Function Loss: 9.77540

Mean KL Divergence: 0.03147
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.08264

Collected Steps per Second: 11,003.01940
Overall Steps per Second: 9,367.60199

Timestep Collection Time: 4.54421
Timestep Consumption Time: 0.79334
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 5.33755

Cumulative Model Updates: 36,652
Cumulative Timesteps: 611,446,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 611446700...
Checkpoint 611446700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,609.77424
Policy Entropy: 1.10932
Value Function Loss: 9.70550

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.08103

Collected Steps per Second: 10,651.59204
Overall Steps per Second: 9,237.47817

Timestep Collection Time: 4.69451
Timestep Consumption Time: 0.71866
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.41317

Cumulative Model Updates: 36,655
Cumulative Timesteps: 611,496,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,409.61945
Policy Entropy: 1.10589
Value Function Loss: 9.32296

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.07643

Collected Steps per Second: 10,875.14753
Overall Steps per Second: 9,237.72188

Timestep Collection Time: 4.59837
Timestep Consumption Time: 0.81508
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.41346

Cumulative Model Updates: 36,658
Cumulative Timesteps: 611,546,712

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 611546712...
Checkpoint 611546712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,452.26163
Policy Entropy: 1.08506
Value Function Loss: 9.76247

Mean KL Divergence: 0.03399
SB3 Clip Fraction: 0.17065
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.07211

Collected Steps per Second: 11,025.11499
Overall Steps per Second: 9,484.30504

Timestep Collection Time: 4.53546
Timestep Consumption Time: 0.73683
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.27229

Cumulative Model Updates: 36,661
Cumulative Timesteps: 611,596,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,296.93360
Policy Entropy: 1.09522
Value Function Loss: 10.12170

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.07761

Collected Steps per Second: 11,082.29485
Overall Steps per Second: 9,597.37420

Timestep Collection Time: 4.51188
Timestep Consumption Time: 0.69809
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 5.20997

Cumulative Model Updates: 36,664
Cumulative Timesteps: 611,646,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 611646718...
Checkpoint 611646718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,137.65370
Policy Entropy: 1.09239
Value Function Loss: 10.11697

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.06027
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 10,886.38899
Overall Steps per Second: 9,197.53621

Timestep Collection Time: 4.59307
Timestep Consumption Time: 0.84338
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 5.43646

Cumulative Model Updates: 36,667
Cumulative Timesteps: 611,696,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,696.59755
Policy Entropy: 1.08252
Value Function Loss: 9.55161

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.15166
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.08230

Collected Steps per Second: 10,757.86328
Overall Steps per Second: 9,177.20367

Timestep Collection Time: 4.64776
Timestep Consumption Time: 0.80052
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.44828

Cumulative Model Updates: 36,670
Cumulative Timesteps: 611,746,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 611746720...
Checkpoint 611746720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,420.47862
Policy Entropy: 1.08484
Value Function Loss: 9.21444

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.08185

Collected Steps per Second: 11,098.45905
Overall Steps per Second: 9,501.15156

Timestep Collection Time: 4.50765
Timestep Consumption Time: 0.75781
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.26547

Cumulative Model Updates: 36,673
Cumulative Timesteps: 611,796,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,005.03012
Policy Entropy: 1.09288
Value Function Loss: 9.70144

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.07871

Collected Steps per Second: 11,417.58379
Overall Steps per Second: 9,581.12335

Timestep Collection Time: 4.38061
Timestep Consumption Time: 0.83965
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.22026

Cumulative Model Updates: 36,676
Cumulative Timesteps: 611,846,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 611846764...
Checkpoint 611846764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,871.18659
Policy Entropy: 1.09577
Value Function Loss: 9.27877

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.07245

Collected Steps per Second: 11,067.02252
Overall Steps per Second: 9,561.93686

Timestep Collection Time: 4.51991
Timestep Consumption Time: 0.71145
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.23137

Cumulative Model Updates: 36,679
Cumulative Timesteps: 611,896,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417,589.79590
Policy Entropy: 1.09887
Value Function Loss: 9.43230

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.06585

Collected Steps per Second: 11,418.66672
Overall Steps per Second: 9,678.82921

Timestep Collection Time: 4.38037
Timestep Consumption Time: 0.78740
PPO Batch Consumption Time: 0.04050
Total Iteration Time: 5.16777

Cumulative Model Updates: 36,682
Cumulative Timesteps: 611,946,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 611946804...
Checkpoint 611946804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,288.82357
Policy Entropy: 1.10403
Value Function Loss: 9.44295

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.06981

Collected Steps per Second: 11,345.21281
Overall Steps per Second: 9,733.09611

Timestep Collection Time: 4.40944
Timestep Consumption Time: 0.73035
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.13978

Cumulative Model Updates: 36,685
Cumulative Timesteps: 611,996,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,870.92432
Policy Entropy: 1.09345
Value Function Loss: 9.81935

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.06332

Collected Steps per Second: 11,378.39595
Overall Steps per Second: 9,640.78586

Timestep Collection Time: 4.39429
Timestep Consumption Time: 0.79201
PPO Batch Consumption Time: 0.03713
Total Iteration Time: 5.18630

Cumulative Model Updates: 36,688
Cumulative Timesteps: 612,046,830

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 612046830...
Checkpoint 612046830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,147.46025
Policy Entropy: 1.09919
Value Function Loss: 9.71782

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.07391

Collected Steps per Second: 10,546.00646
Overall Steps per Second: 8,960.55180

Timestep Collection Time: 4.74208
Timestep Consumption Time: 0.83905
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 5.58113

Cumulative Model Updates: 36,691
Cumulative Timesteps: 612,096,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,768.58945
Policy Entropy: 1.10153
Value Function Loss: 9.27805

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 11,145.57112
Overall Steps per Second: 9,664.29078

Timestep Collection Time: 4.48878
Timestep Consumption Time: 0.68801
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.17679

Cumulative Model Updates: 36,694
Cumulative Timesteps: 612,146,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 612146870...
Checkpoint 612146870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,281.00924
Policy Entropy: 1.09605
Value Function Loss: 9.03972

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.06558
Value Function Update Magnitude: 0.07290

Collected Steps per Second: 11,159.76316
Overall Steps per Second: 9,457.07054

Timestep Collection Time: 4.48128
Timestep Consumption Time: 0.80683
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.28811

Cumulative Model Updates: 36,697
Cumulative Timesteps: 612,196,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,420.12644
Policy Entropy: 1.09095
Value Function Loss: 9.20006

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.08671

Collected Steps per Second: 11,190.51481
Overall Steps per Second: 9,591.98706

Timestep Collection Time: 4.46896
Timestep Consumption Time: 0.74476
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.21373

Cumulative Model Updates: 36,700
Cumulative Timesteps: 612,246,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 612246890...
Checkpoint 612246890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398,521.62679
Policy Entropy: 1.08530
Value Function Loss: 9.29706

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.07561

Collected Steps per Second: 11,473.73660
Overall Steps per Second: 9,738.31093

Timestep Collection Time: 4.35987
Timestep Consumption Time: 0.77696
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.13683

Cumulative Model Updates: 36,703
Cumulative Timesteps: 612,296,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394,276.50193
Policy Entropy: 1.10811
Value Function Loss: 9.51152

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.07157

Collected Steps per Second: 10,494.57043
Overall Steps per Second: 8,995.58829

Timestep Collection Time: 4.76456
Timestep Consumption Time: 0.79394
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.55850

Cumulative Model Updates: 36,706
Cumulative Timesteps: 612,346,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 612346916...
Checkpoint 612346916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,140.23867
Policy Entropy: 1.11701
Value Function Loss: 9.09441

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.07968

Collected Steps per Second: 11,382.46804
Overall Steps per Second: 9,720.83777

Timestep Collection Time: 4.39395
Timestep Consumption Time: 0.75108
PPO Batch Consumption Time: 0.03976
Total Iteration Time: 5.14503

Cumulative Model Updates: 36,709
Cumulative Timesteps: 612,396,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,896.50709
Policy Entropy: 1.09992
Value Function Loss: 8.98589

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.07436

Collected Steps per Second: 11,086.19110
Overall Steps per Second: 9,431.24522

Timestep Collection Time: 4.51048
Timestep Consumption Time: 0.79147
PPO Batch Consumption Time: 0.04533
Total Iteration Time: 5.30195

Cumulative Model Updates: 36,712
Cumulative Timesteps: 612,446,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 612446934...
Checkpoint 612446934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,108.72041
Policy Entropy: 1.09034
Value Function Loss: 9.21227

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.07200

Collected Steps per Second: 10,946.51293
Overall Steps per Second: 9,527.15340

Timestep Collection Time: 4.56949
Timestep Consumption Time: 0.68076
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 5.25026

Cumulative Model Updates: 36,715
Cumulative Timesteps: 612,496,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551,942.52757
Policy Entropy: 1.10382
Value Function Loss: 9.43578

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.07393

Collected Steps per Second: 10,990.60012
Overall Steps per Second: 9,379.56126

Timestep Collection Time: 4.55153
Timestep Consumption Time: 0.78177
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.33330

Cumulative Model Updates: 36,718
Cumulative Timesteps: 612,546,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 612546978...
Checkpoint 612546978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,614.26448
Policy Entropy: 1.10815
Value Function Loss: 10.06726

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 11,077.28784
Overall Steps per Second: 9,619.43373

Timestep Collection Time: 4.51428
Timestep Consumption Time: 0.68415
PPO Batch Consumption Time: 0.03778
Total Iteration Time: 5.19843

Cumulative Model Updates: 36,721
Cumulative Timesteps: 612,596,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,079.14289
Policy Entropy: 1.08493
Value Function Loss: 9.67266

Mean KL Divergence: 0.02736
SB3 Clip Fraction: 0.15338
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.05846

Collected Steps per Second: 10,773.57578
Overall Steps per Second: 9,243.92144

Timestep Collection Time: 4.64303
Timestep Consumption Time: 0.76831
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.41134

Cumulative Model Updates: 36,724
Cumulative Timesteps: 612,647,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 612647006...
Checkpoint 612647006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,116.86692
Policy Entropy: 1.10136
Value Function Loss: 9.61413

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.15359
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.05591

Collected Steps per Second: 10,869.48985
Overall Steps per Second: 9,433.58569

Timestep Collection Time: 4.60077
Timestep Consumption Time: 0.70029
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.30106

Cumulative Model Updates: 36,727
Cumulative Timesteps: 612,697,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,287.61940
Policy Entropy: 1.09913
Value Function Loss: 9.35270

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.04974

Collected Steps per Second: 11,101.55998
Overall Steps per Second: 9,403.32370

Timestep Collection Time: 4.50441
Timestep Consumption Time: 0.81349
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.31791

Cumulative Model Updates: 36,730
Cumulative Timesteps: 612,747,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 612747020...
Checkpoint 612747020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,000.09842
Policy Entropy: 1.09111
Value Function Loss: 9.20758

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.04384

Collected Steps per Second: 10,922.66256
Overall Steps per Second: 9,358.58133

Timestep Collection Time: 4.57965
Timestep Consumption Time: 0.76539
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.34504

Cumulative Model Updates: 36,733
Cumulative Timesteps: 612,797,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,230.19631
Policy Entropy: 1.08688
Value Function Loss: 9.61892

Mean KL Divergence: 0.03898
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.04173

Collected Steps per Second: 11,032.85728
Overall Steps per Second: 9,423.11053

Timestep Collection Time: 4.53264
Timestep Consumption Time: 0.77431
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.30695

Cumulative Model Updates: 36,736
Cumulative Timesteps: 612,847,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 612847050...
Checkpoint 612847050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,283.92213
Policy Entropy: 1.09745
Value Function Loss: 9.48362

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.03904

Collected Steps per Second: 10,368.21233
Overall Steps per Second: 8,905.68501

Timestep Collection Time: 4.82282
Timestep Consumption Time: 0.79202
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.61484

Cumulative Model Updates: 36,739
Cumulative Timesteps: 612,897,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,707.23470
Policy Entropy: 1.10895
Value Function Loss: 9.62597

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.05971

Collected Steps per Second: 11,345.21178
Overall Steps per Second: 9,612.11524

Timestep Collection Time: 4.40944
Timestep Consumption Time: 0.79504
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 5.20447

Cumulative Model Updates: 36,742
Cumulative Timesteps: 612,947,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 612947080...
Checkpoint 612947080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,102.91446
Policy Entropy: 1.07418
Value Function Loss: 9.78171

Mean KL Divergence: 0.06184
SB3 Clip Fraction: 0.19391
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.05793

Collected Steps per Second: 12,232.76768
Overall Steps per Second: 10,274.04153

Timestep Collection Time: 4.08934
Timestep Consumption Time: 0.77963
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.86897

Cumulative Model Updates: 36,745
Cumulative Timesteps: 612,997,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,376.42596
Policy Entropy: 1.10038
Value Function Loss: 9.80007

Mean KL Divergence: 0.03457
SB3 Clip Fraction: 0.17137
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.05249

Collected Steps per Second: 11,919.63473
Overall Steps per Second: 10,088.68601

Timestep Collection Time: 4.19677
Timestep Consumption Time: 0.76165
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.95843

Cumulative Model Updates: 36,748
Cumulative Timesteps: 613,047,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 613047128...
Checkpoint 613047128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,079.29431
Policy Entropy: 1.08081
Value Function Loss: 9.78906

Mean KL Divergence: 0.03677
SB3 Clip Fraction: 0.15623
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.05774

Collected Steps per Second: 11,687.24333
Overall Steps per Second: 10,064.69028

Timestep Collection Time: 4.27868
Timestep Consumption Time: 0.68978
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.96846

Cumulative Model Updates: 36,751
Cumulative Timesteps: 613,097,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,276.52722
Policy Entropy: 1.10072
Value Function Loss: 9.57363

Mean KL Divergence: 0.03167
SB3 Clip Fraction: 0.15320
Policy Update Magnitude: 0.04342
Value Function Update Magnitude: 0.06098

Collected Steps per Second: 11,844.23982
Overall Steps per Second: 9,962.38078

Timestep Collection Time: 4.22349
Timestep Consumption Time: 0.79780
PPO Batch Consumption Time: 0.04019
Total Iteration Time: 5.02129

Cumulative Model Updates: 36,754
Cumulative Timesteps: 613,147,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 613147158...
Checkpoint 613147158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,702.93550
Policy Entropy: 1.09389
Value Function Loss: 9.32061

Mean KL Divergence: 0.02646
SB3 Clip Fraction: 0.15797
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.06161

Collected Steps per Second: 11,285.84303
Overall Steps per Second: 9,588.44531

Timestep Collection Time: 4.43157
Timestep Consumption Time: 0.78450
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.21607

Cumulative Model Updates: 36,757
Cumulative Timesteps: 613,197,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,956.86372
Policy Entropy: 1.07869
Value Function Loss: 9.47508

Mean KL Divergence: 0.02528
SB3 Clip Fraction: 0.14173
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.06998

Collected Steps per Second: 11,821.84006
Overall Steps per Second: 9,884.02321

Timestep Collection Time: 4.23048
Timestep Consumption Time: 0.82941
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 5.05988

Cumulative Model Updates: 36,760
Cumulative Timesteps: 613,247,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 613247184...
Checkpoint 613247184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,193.07217
Policy Entropy: 1.06419
Value Function Loss: 9.28225

Mean KL Divergence: 0.03148
SB3 Clip Fraction: 0.16887
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.06606

Collected Steps per Second: 11,013.83510
Overall Steps per Second: 9,366.20128

Timestep Collection Time: 4.54229
Timestep Consumption Time: 0.79905
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 5.34133

Cumulative Model Updates: 36,763
Cumulative Timesteps: 613,297,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,715.86589
Policy Entropy: 1.08519
Value Function Loss: 9.78750

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.04686
Value Function Update Magnitude: 0.06886

Collected Steps per Second: 11,138.53378
Overall Steps per Second: 9,588.62966

Timestep Collection Time: 4.49126
Timestep Consumption Time: 0.72597
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.21722

Cumulative Model Updates: 36,766
Cumulative Timesteps: 613,347,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 613347238...
Checkpoint 613347238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,568.40482
Policy Entropy: 1.09220
Value Function Loss: 9.50497

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.14655
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.06627

Collected Steps per Second: 11,232.50258
Overall Steps per Second: 9,525.30981

Timestep Collection Time: 4.45244
Timestep Consumption Time: 0.79800
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.25043

Cumulative Model Updates: 36,769
Cumulative Timesteps: 613,397,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,095.47499
Policy Entropy: 1.06017
Value Function Loss: 9.73076

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.07114

Collected Steps per Second: 11,100.27405
Overall Steps per Second: 9,458.11610

Timestep Collection Time: 4.50583
Timestep Consumption Time: 0.78232
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.28816

Cumulative Model Updates: 36,772
Cumulative Timesteps: 613,447,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 613447266...
Checkpoint 613447266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425,067.42338
Policy Entropy: 1.07690
Value Function Loss: 9.36825

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.04562
Value Function Update Magnitude: 0.06623

Collected Steps per Second: 10,860.15465
Overall Steps per Second: 9,291.41610

Timestep Collection Time: 4.60491
Timestep Consumption Time: 0.77748
PPO Batch Consumption Time: 0.03877
Total Iteration Time: 5.38239

Cumulative Model Updates: 36,775
Cumulative Timesteps: 613,497,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,393.68959
Policy Entropy: 1.07831
Value Function Loss: 9.67831

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 11,031.88635
Overall Steps per Second: 9,447.35326

Timestep Collection Time: 4.53359
Timestep Consumption Time: 0.76038
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.29397

Cumulative Model Updates: 36,778
Cumulative Timesteps: 613,547,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 613547290...
Checkpoint 613547290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,231.93972
Policy Entropy: 1.06742
Value Function Loss: 9.51529

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 11,016.78449
Overall Steps per Second: 9,533.25677

Timestep Collection Time: 4.53998
Timestep Consumption Time: 0.70649
PPO Batch Consumption Time: 0.03924
Total Iteration Time: 5.24648

Cumulative Model Updates: 36,781
Cumulative Timesteps: 613,597,306

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,225.08738
Policy Entropy: 1.06161
Value Function Loss: 9.24139

Mean KL Divergence: 0.02977
SB3 Clip Fraction: 0.16019
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.07314

Collected Steps per Second: 10,767.19123
Overall Steps per Second: 9,221.29341

Timestep Collection Time: 4.64448
Timestep Consumption Time: 0.77862
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 5.42310

Cumulative Model Updates: 36,784
Cumulative Timesteps: 613,647,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 613647314...
Checkpoint 613647314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,031.49782
Policy Entropy: 1.06735
Value Function Loss: 9.10616

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.06774

Collected Steps per Second: 11,048.94005
Overall Steps per Second: 9,535.28041

Timestep Collection Time: 4.52731
Timestep Consumption Time: 0.71868
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 5.24599

Cumulative Model Updates: 36,787
Cumulative Timesteps: 613,697,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407,970.97471
Policy Entropy: 1.08812
Value Function Loss: 8.94211

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.07001

Collected Steps per Second: 11,314.15943
Overall Steps per Second: 9,497.64167

Timestep Collection Time: 4.42066
Timestep Consumption Time: 0.84549
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.26615

Cumulative Model Updates: 36,790
Cumulative Timesteps: 613,747,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 613747352...
Checkpoint 613747352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,143.70099
Policy Entropy: 1.06905
Value Function Loss: 9.02562

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.08670

Collected Steps per Second: 10,959.73666
Overall Steps per Second: 9,414.56523

Timestep Collection Time: 4.56361
Timestep Consumption Time: 0.74901
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.31262

Cumulative Model Updates: 36,793
Cumulative Timesteps: 613,797,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,238.60715
Policy Entropy: 1.07382
Value Function Loss: 8.97123

Mean KL Divergence: 0.02922
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.07985

Collected Steps per Second: 10,715.93583
Overall Steps per Second: 9,263.44874

Timestep Collection Time: 4.66613
Timestep Consumption Time: 0.73164
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 5.39777

Cumulative Model Updates: 36,796
Cumulative Timesteps: 613,847,370

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 613847370...
Checkpoint 613847370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,199.98596
Policy Entropy: 1.08219
Value Function Loss: 8.88793

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.07542

Collected Steps per Second: 10,654.95403
Overall Steps per Second: 9,169.38980

Timestep Collection Time: 4.69528
Timestep Consumption Time: 0.76070
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.45598

Cumulative Model Updates: 36,799
Cumulative Timesteps: 613,897,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,486.62951
Policy Entropy: 1.10051
Value Function Loss: 8.91063

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.06916

Collected Steps per Second: 10,976.92456
Overall Steps per Second: 9,558.54686

Timestep Collection Time: 4.55683
Timestep Consumption Time: 0.67618
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.23301

Cumulative Model Updates: 36,802
Cumulative Timesteps: 613,947,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 613947418...
Checkpoint 613947418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,987.08641
Policy Entropy: 1.07636
Value Function Loss: 9.04422

Mean KL Divergence: 0.02738
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.07255

Collected Steps per Second: 10,933.05319
Overall Steps per Second: 9,345.95891

Timestep Collection Time: 4.57439
Timestep Consumption Time: 0.77680
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 5.35119

Cumulative Model Updates: 36,805
Cumulative Timesteps: 613,997,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,939.55804
Policy Entropy: 1.08745
Value Function Loss: 9.07895

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.08658

Collected Steps per Second: 10,269.99812
Overall Steps per Second: 8,803.51879

Timestep Collection Time: 4.87011
Timestep Consumption Time: 0.81126
PPO Batch Consumption Time: 0.03884
Total Iteration Time: 5.68136

Cumulative Model Updates: 36,808
Cumulative Timesteps: 614,047,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 614047446...
Checkpoint 614047446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,487.40430
Policy Entropy: 1.09069
Value Function Loss: 9.31937

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.08350

Collected Steps per Second: 11,432.64985
Overall Steps per Second: 9,907.58388

Timestep Collection Time: 4.37536
Timestep Consumption Time: 0.67350
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.04886

Cumulative Model Updates: 36,811
Cumulative Timesteps: 614,097,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,211.68348
Policy Entropy: 1.07148
Value Function Loss: 8.85693

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.07934

Collected Steps per Second: 11,305.79924
Overall Steps per Second: 9,635.75022

Timestep Collection Time: 4.42410
Timestep Consumption Time: 0.76678
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.19088

Cumulative Model Updates: 36,814
Cumulative Timesteps: 614,147,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 614147486...
Checkpoint 614147486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,534.51278
Policy Entropy: 1.06244
Value Function Loss: 8.73007

Mean KL Divergence: 0.03273
SB3 Clip Fraction: 0.17028
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.07018

Collected Steps per Second: 11,466.88309
Overall Steps per Second: 9,791.67748

Timestep Collection Time: 4.36248
Timestep Consumption Time: 0.74635
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 5.10883

Cumulative Model Updates: 36,817
Cumulative Timesteps: 614,197,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,075.71436
Policy Entropy: 1.07460
Value Function Loss: 8.26159

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 11,437.61619
Overall Steps per Second: 9,727.71085

Timestep Collection Time: 4.37241
Timestep Consumption Time: 0.76857
PPO Batch Consumption Time: 0.03824
Total Iteration Time: 5.14098

Cumulative Model Updates: 36,820
Cumulative Timesteps: 614,247,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 614247520...
Checkpoint 614247520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,880.57955
Policy Entropy: 1.07854
Value Function Loss: 8.48794

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.06591

Collected Steps per Second: 11,322.83359
Overall Steps per Second: 9,660.02198

Timestep Collection Time: 4.41603
Timestep Consumption Time: 0.76015
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.17618

Cumulative Model Updates: 36,823
Cumulative Timesteps: 614,297,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394,861.92933
Policy Entropy: 1.06936
Value Function Loss: 8.51889

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.07322

Collected Steps per Second: 10,795.14518
Overall Steps per Second: 9,366.67240

Timestep Collection Time: 4.63393
Timestep Consumption Time: 0.70670
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.34064

Cumulative Model Updates: 36,826
Cumulative Timesteps: 614,347,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 614347546...
Checkpoint 614347546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378,386.33631
Policy Entropy: 1.06552
Value Function Loss: 8.36940

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.16648
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.06983

Collected Steps per Second: 9,783.80729
Overall Steps per Second: 8,354.55206

Timestep Collection Time: 5.11089
Timestep Consumption Time: 0.87435
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 5.98524

Cumulative Model Updates: 36,829
Cumulative Timesteps: 614,397,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,052.37436
Policy Entropy: 1.08623
Value Function Loss: 8.52333

Mean KL Divergence: 0.02382
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.07371

Collected Steps per Second: 10,758.73376
Overall Steps per Second: 9,217.67728

Timestep Collection Time: 4.64962
Timestep Consumption Time: 0.77735
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.42696

Cumulative Model Updates: 36,832
Cumulative Timesteps: 614,447,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 614447574...
Checkpoint 614447574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,713.65096
Policy Entropy: 1.08528
Value Function Loss: 8.74363

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.06899

Collected Steps per Second: 11,173.48257
Overall Steps per Second: 9,583.43475

Timestep Collection Time: 4.47739
Timestep Consumption Time: 0.74287
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 5.22026

Cumulative Model Updates: 36,835
Cumulative Timesteps: 614,497,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,092.01995
Policy Entropy: 1.08341
Value Function Loss: 9.48820

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.06389

Collected Steps per Second: 11,234.18397
Overall Steps per Second: 9,525.74228

Timestep Collection Time: 4.45355
Timestep Consumption Time: 0.79874
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.25229

Cumulative Model Updates: 36,838
Cumulative Timesteps: 614,547,634

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 614547634...
Checkpoint 614547634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,850.89923
Policy Entropy: 1.06720
Value Function Loss: 9.39551

Mean KL Divergence: 0.02699
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 10,871.76413
Overall Steps per Second: 9,307.62972

Timestep Collection Time: 4.60109
Timestep Consumption Time: 0.77321
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.37430

Cumulative Model Updates: 36,841
Cumulative Timesteps: 614,597,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,999.44665
Policy Entropy: 1.08161
Value Function Loss: 9.21066

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.08520

Collected Steps per Second: 11,422.69771
Overall Steps per Second: 9,668.73927

Timestep Collection Time: 4.37883
Timestep Consumption Time: 0.79434
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.17317

Cumulative Model Updates: 36,844
Cumulative Timesteps: 614,647,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 614647674...
Checkpoint 614647674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,187.14806
Policy Entropy: 1.08545
Value Function Loss: 8.86756

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.15396
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.07996

Collected Steps per Second: 11,035.54923
Overall Steps per Second: 9,453.01512

Timestep Collection Time: 4.53136
Timestep Consumption Time: 0.75860
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.28995

Cumulative Model Updates: 36,847
Cumulative Timesteps: 614,697,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410,964.23842
Policy Entropy: 1.05616
Value Function Loss: 9.33510

Mean KL Divergence: 0.03464
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.07306

Collected Steps per Second: 11,126.12322
Overall Steps per Second: 9,660.57864

Timestep Collection Time: 4.49519
Timestep Consumption Time: 0.68194
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.17712

Cumulative Model Updates: 36,850
Cumulative Timesteps: 614,747,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 614747694...
Checkpoint 614747694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,461.96729
Policy Entropy: 1.08090
Value Function Loss: 9.56111

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 10,740.91247
Overall Steps per Second: 9,159.99723

Timestep Collection Time: 4.65584
Timestep Consumption Time: 0.80355
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 5.45939

Cumulative Model Updates: 36,853
Cumulative Timesteps: 614,797,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,032.71794
Policy Entropy: 1.08038
Value Function Loss: 9.67458

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.06881

Collected Steps per Second: 10,988.29339
Overall Steps per Second: 9,451.85390

Timestep Collection Time: 4.55121
Timestep Consumption Time: 0.73982
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.29103

Cumulative Model Updates: 36,856
Cumulative Timesteps: 614,847,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 614847712...
Checkpoint 614847712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,924.16608
Policy Entropy: 1.07661
Value Function Loss: 9.12095

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.06854

Collected Steps per Second: 10,552.29559
Overall Steps per Second: 9,101.42133

Timestep Collection Time: 4.74020
Timestep Consumption Time: 0.75564
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.49584

Cumulative Model Updates: 36,859
Cumulative Timesteps: 614,897,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,201.46645
Policy Entropy: 1.06317
Value Function Loss: 8.84344

Mean KL Divergence: 0.02859
SB3 Clip Fraction: 0.16569
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.06675

Collected Steps per Second: 10,999.06672
Overall Steps per Second: 9,345.72802

Timestep Collection Time: 4.54675
Timestep Consumption Time: 0.80436
PPO Batch Consumption Time: 0.04302
Total Iteration Time: 5.35111

Cumulative Model Updates: 36,862
Cumulative Timesteps: 614,947,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 614947742...
Checkpoint 614947742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,510.40347
Policy Entropy: 1.07630
Value Function Loss: 8.51029

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.06584

Collected Steps per Second: 10,964.40945
Overall Steps per Second: 9,514.05795

Timestep Collection Time: 4.56185
Timestep Consumption Time: 0.69542
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 5.25727

Cumulative Model Updates: 36,865
Cumulative Timesteps: 614,997,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,986.22162
Policy Entropy: 1.07822
Value Function Loss: 8.51510

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 10,657.11770
Overall Steps per Second: 9,106.90572

Timestep Collection Time: 4.69395
Timestep Consumption Time: 0.79902
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.49297

Cumulative Model Updates: 36,868
Cumulative Timesteps: 615,047,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 615047784...
Checkpoint 615047784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,019.05347
Policy Entropy: 1.05668
Value Function Loss: 8.63638

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.06343

Collected Steps per Second: 10,804.67237
Overall Steps per Second: 9,316.42515

Timestep Collection Time: 4.62781
Timestep Consumption Time: 0.73927
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 5.36708

Cumulative Model Updates: 36,871
Cumulative Timesteps: 615,097,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,451.71736
Policy Entropy: 1.07459
Value Function Loss: 8.68541

Mean KL Divergence: 0.02992
SB3 Clip Fraction: 0.17459
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.06074

Collected Steps per Second: 11,041.94249
Overall Steps per Second: 9,292.66609

Timestep Collection Time: 4.52837
Timestep Consumption Time: 0.85243
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 5.38080

Cumulative Model Updates: 36,874
Cumulative Timesteps: 615,147,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 615147788...
Checkpoint 615147788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481,969.65169
Policy Entropy: 1.07958
Value Function Loss: 8.93041

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.16709
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.05592

Collected Steps per Second: 11,023.07192
Overall Steps per Second: 9,397.35973

Timestep Collection Time: 4.53667
Timestep Consumption Time: 0.78483
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.32149

Cumulative Model Updates: 36,877
Cumulative Timesteps: 615,197,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,192.15720
Policy Entropy: 1.06987
Value Function Loss: 8.92817

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.05887

Collected Steps per Second: 11,988.37346
Overall Steps per Second: 10,283.97451

Timestep Collection Time: 4.17204
Timestep Consumption Time: 0.69145
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 4.86349

Cumulative Model Updates: 36,880
Cumulative Timesteps: 615,247,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 615247812...
Checkpoint 615247812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386,092.23740
Policy Entropy: 1.06783
Value Function Loss: 9.16631

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.04960

Collected Steps per Second: 12,285.26092
Overall Steps per Second: 10,238.71887

Timestep Collection Time: 4.07138
Timestep Consumption Time: 0.81380
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.88518

Cumulative Model Updates: 36,883
Cumulative Timesteps: 615,297,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,282.37221
Policy Entropy: 1.07621
Value Function Loss: 8.99165

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.04718

Collected Steps per Second: 12,006.01621
Overall Steps per Second: 10,069.69811

Timestep Collection Time: 4.16508
Timestep Consumption Time: 0.80091
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 4.96599

Cumulative Model Updates: 36,886
Cumulative Timesteps: 615,347,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 615347836...
Checkpoint 615347836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,606.97308
Policy Entropy: 1.08176
Value Function Loss: 9.14356

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.05263

Collected Steps per Second: 12,196.89870
Overall Steps per Second: 10,184.22964

Timestep Collection Time: 4.10039
Timestep Consumption Time: 0.81034
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.91073

Cumulative Model Updates: 36,889
Cumulative Timesteps: 615,397,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,064.67455
Policy Entropy: 1.07908
Value Function Loss: 9.21064

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.05516

Collected Steps per Second: 12,141.95526
Overall Steps per Second: 9,865.37852

Timestep Collection Time: 4.11878
Timestep Consumption Time: 0.95047
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 5.06924

Cumulative Model Updates: 36,892
Cumulative Timesteps: 615,447,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 615447858...
Checkpoint 615447858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,248.86782
Policy Entropy: 1.08807
Value Function Loss: 9.29025

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.05233

Collected Steps per Second: 11,781.57801
Overall Steps per Second: 10,041.71565

Timestep Collection Time: 4.24459
Timestep Consumption Time: 0.73543
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.98003

Cumulative Model Updates: 36,895
Cumulative Timesteps: 615,497,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,486.70244
Policy Entropy: 1.09809
Value Function Loss: 9.18715

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.05341

Collected Steps per Second: 10,960.79325
Overall Steps per Second: 9,307.89832

Timestep Collection Time: 4.56190
Timestep Consumption Time: 0.81010
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.37200

Cumulative Model Updates: 36,898
Cumulative Timesteps: 615,547,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 615547868...
Checkpoint 615547868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,174.62912
Policy Entropy: 1.09966
Value Function Loss: 9.23999

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.05581

Collected Steps per Second: 11,160.38262
Overall Steps per Second: 9,512.96144

Timestep Collection Time: 4.48228
Timestep Consumption Time: 0.77623
PPO Batch Consumption Time: 0.03801
Total Iteration Time: 5.25851

Cumulative Model Updates: 36,901
Cumulative Timesteps: 615,597,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338,984.01531
Policy Entropy: 1.08738
Value Function Loss: 9.28646

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.05715

Collected Steps per Second: 11,369.25634
Overall Steps per Second: 9,601.61127

Timestep Collection Time: 4.39888
Timestep Consumption Time: 0.80983
PPO Batch Consumption Time: 0.04074
Total Iteration Time: 5.20871

Cumulative Model Updates: 36,904
Cumulative Timesteps: 615,647,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 615647904...
Checkpoint 615647904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,170.80175
Policy Entropy: 1.09905
Value Function Loss: 9.35161

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.05550

Collected Steps per Second: 11,201.89309
Overall Steps per Second: 9,490.86479

Timestep Collection Time: 4.46585
Timestep Consumption Time: 0.80511
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.27096

Cumulative Model Updates: 36,907
Cumulative Timesteps: 615,697,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,360.53783
Policy Entropy: 1.10236
Value Function Loss: 9.22912

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.05602

Collected Steps per Second: 10,480.07005
Overall Steps per Second: 9,119.30273

Timestep Collection Time: 4.77306
Timestep Consumption Time: 0.71223
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.48529

Cumulative Model Updates: 36,910
Cumulative Timesteps: 615,747,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 615747952...
Checkpoint 615747952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,969.44049
Policy Entropy: 1.10403
Value Function Loss: 8.63360

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.05936

Collected Steps per Second: 10,858.47485
Overall Steps per Second: 9,294.51636

Timestep Collection Time: 4.60525
Timestep Consumption Time: 0.77491
PPO Batch Consumption Time: 0.03380
Total Iteration Time: 5.38016

Cumulative Model Updates: 36,913
Cumulative Timesteps: 615,797,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,034.30195
Policy Entropy: 1.08426
Value Function Loss: 8.21223

Mean KL Divergence: 0.05274
SB3 Clip Fraction: 0.17110
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.06460

Collected Steps per Second: 10,965.41290
Overall Steps per Second: 9,420.14065

Timestep Collection Time: 4.56016
Timestep Consumption Time: 0.74804
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.30820

Cumulative Model Updates: 36,916
Cumulative Timesteps: 615,847,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 615847962...
Checkpoint 615847962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,899.83441
Policy Entropy: 1.10709
Value Function Loss: 8.31750

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.08518

Collected Steps per Second: 11,288.83312
Overall Steps per Second: 9,606.45308

Timestep Collection Time: 4.43093
Timestep Consumption Time: 0.77599
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.20692

Cumulative Model Updates: 36,919
Cumulative Timesteps: 615,897,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,859.20591
Policy Entropy: 1.09765
Value Function Loss: 8.95421

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.08574

Collected Steps per Second: 10,808.59374
Overall Steps per Second: 9,223.75854

Timestep Collection Time: 4.62650
Timestep Consumption Time: 0.79493
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 5.42143

Cumulative Model Updates: 36,922
Cumulative Timesteps: 615,947,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 615947988...
Checkpoint 615947988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,205.38204
Policy Entropy: 1.10197
Value Function Loss: 9.20861

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.08014

Collected Steps per Second: 10,961.58179
Overall Steps per Second: 9,512.86473

Timestep Collection Time: 4.56376
Timestep Consumption Time: 0.69502
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.25877

Cumulative Model Updates: 36,925
Cumulative Timesteps: 615,998,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418,431.66210
Policy Entropy: 1.10681
Value Function Loss: 8.97653

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.08054

Collected Steps per Second: 10,512.86407
Overall Steps per Second: 9,014.65416

Timestep Collection Time: 4.75893
Timestep Consumption Time: 0.79092
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 5.54985

Cumulative Model Updates: 36,928
Cumulative Timesteps: 616,048,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 616048044...
Checkpoint 616048044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,529.47641
Policy Entropy: 1.11866
Value Function Loss: 8.84574

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.07378
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 10,638.63606
Overall Steps per Second: 9,004.33170

Timestep Collection Time: 4.70286
Timestep Consumption Time: 0.85358
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 5.55644

Cumulative Model Updates: 36,931
Cumulative Timesteps: 616,098,076

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,048.66891
Policy Entropy: 1.11984
Value Function Loss: 9.21756

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.07053

Collected Steps per Second: 11,266.62792
Overall Steps per Second: 9,583.82616

Timestep Collection Time: 4.44037
Timestep Consumption Time: 0.77967
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.22004

Cumulative Model Updates: 36,934
Cumulative Timesteps: 616,148,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 616148104...
Checkpoint 616148104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,420.61297
Policy Entropy: 1.10652
Value Function Loss: 9.78489

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.07695

Collected Steps per Second: 10,791.75819
Overall Steps per Second: 9,208.97006

Timestep Collection Time: 4.63428
Timestep Consumption Time: 0.79651
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.43079

Cumulative Model Updates: 36,937
Cumulative Timesteps: 616,198,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,533.59972
Policy Entropy: 1.11129
Value Function Loss: 10.15146

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.07421

Collected Steps per Second: 11,015.55753
Overall Steps per Second: 9,554.50227

Timestep Collection Time: 4.53994
Timestep Consumption Time: 0.69424
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.23418

Cumulative Model Updates: 36,940
Cumulative Timesteps: 616,248,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 616248126...
Checkpoint 616248126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,035.00479
Policy Entropy: 1.11159
Value Function Loss: 10.16182

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.07812

Collected Steps per Second: 10,734.86181
Overall Steps per Second: 9,168.24044

Timestep Collection Time: 4.65958
Timestep Consumption Time: 0.79621
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.45579

Cumulative Model Updates: 36,943
Cumulative Timesteps: 616,298,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,409.66813
Policy Entropy: 1.10308
Value Function Loss: 9.64315

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.07113

Collected Steps per Second: 10,975.36443
Overall Steps per Second: 9,467.46422

Timestep Collection Time: 4.55784
Timestep Consumption Time: 0.72594
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.28378

Cumulative Model Updates: 36,946
Cumulative Timesteps: 616,348,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 616348170...
Checkpoint 616348170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,142.70642
Policy Entropy: 1.09940
Value Function Loss: 9.73731

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.07171

Collected Steps per Second: 11,607.50773
Overall Steps per Second: 9,806.89813

Timestep Collection Time: 4.30773
Timestep Consumption Time: 0.79093
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.09866

Cumulative Model Updates: 36,949
Cumulative Timesteps: 616,398,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,320.35518
Policy Entropy: 1.11106
Value Function Loss: 9.51773

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.07098

Collected Steps per Second: 11,406.72152
Overall Steps per Second: 9,685.73070

Timestep Collection Time: 4.38566
Timestep Consumption Time: 0.77926
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.16492

Cumulative Model Updates: 36,952
Cumulative Timesteps: 616,448,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 616448198...
Checkpoint 616448198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412,625.33413
Policy Entropy: 1.12086
Value Function Loss: 10.11168

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.09053

Collected Steps per Second: 11,225.00964
Overall Steps per Second: 9,679.18304

Timestep Collection Time: 4.45541
Timestep Consumption Time: 0.71156
PPO Batch Consumption Time: 0.03981
Total Iteration Time: 5.16697

Cumulative Model Updates: 36,955
Cumulative Timesteps: 616,498,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,913.59603
Policy Entropy: 1.10566
Value Function Loss: 9.90854

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 11,340.53739
Overall Steps per Second: 9,661.61639

Timestep Collection Time: 4.40914
Timestep Consumption Time: 0.76619
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.17532

Cumulative Model Updates: 36,958
Cumulative Timesteps: 616,548,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 616548212...
Checkpoint 616548212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,029.72611
Policy Entropy: 1.08780
Value Function Loss: 9.41993

Mean KL Divergence: 0.03949
SB3 Clip Fraction: 0.17605
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.08422

Collected Steps per Second: 10,762.67080
Overall Steps per Second: 9,313.76636

Timestep Collection Time: 4.64829
Timestep Consumption Time: 0.72312
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 5.37140

Cumulative Model Updates: 36,961
Cumulative Timesteps: 616,598,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,456.28384
Policy Entropy: 1.11071
Value Function Loss: 9.04161

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.07419

Collected Steps per Second: 11,122.23300
Overall Steps per Second: 9,654.93573

Timestep Collection Time: 4.49784
Timestep Consumption Time: 0.68355
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 5.18139

Cumulative Model Updates: 36,964
Cumulative Timesteps: 616,648,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 616648266...
Checkpoint 616648266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,269.73328
Policy Entropy: 1.09584
Value Function Loss: 8.76826

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.06819

Collected Steps per Second: 11,043.34462
Overall Steps per Second: 9,423.84520

Timestep Collection Time: 4.52979
Timestep Consumption Time: 0.77845
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.30824

Cumulative Model Updates: 36,967
Cumulative Timesteps: 616,698,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,379.51498
Policy Entropy: 1.08550
Value Function Loss: 9.71088

Mean KL Divergence: 0.03133
SB3 Clip Fraction: 0.16439
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.06854

Collected Steps per Second: 11,139.08264
Overall Steps per Second: 9,473.66703

Timestep Collection Time: 4.49103
Timestep Consumption Time: 0.78950
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.28053

Cumulative Model Updates: 36,970
Cumulative Timesteps: 616,748,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 616748316...
Checkpoint 616748316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421,462.31505
Policy Entropy: 1.09485
Value Function Loss: 9.58667

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.06634

Collected Steps per Second: 11,294.67836
Overall Steps per Second: 9,586.40584

Timestep Collection Time: 4.42934
Timestep Consumption Time: 0.78930
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.21864

Cumulative Model Updates: 36,973
Cumulative Timesteps: 616,798,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,068.18201
Policy Entropy: 1.08608
Value Function Loss: 9.27381

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.07704

Collected Steps per Second: 11,092.97759
Overall Steps per Second: 9,456.72649

Timestep Collection Time: 4.50988
Timestep Consumption Time: 0.78032
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 5.29020

Cumulative Model Updates: 36,976
Cumulative Timesteps: 616,848,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 616848372...
Checkpoint 616848372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,644.00513
Policy Entropy: 1.07460
Value Function Loss: 8.77063

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 10,618.11555
Overall Steps per Second: 9,274.78731

Timestep Collection Time: 4.70893
Timestep Consumption Time: 0.68203
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 5.39096

Cumulative Model Updates: 36,979
Cumulative Timesteps: 616,898,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,103.19654
Policy Entropy: 1.09566
Value Function Loss: 8.64868

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.15240
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.06791

Collected Steps per Second: 11,065.37728
Overall Steps per Second: 9,436.72088

Timestep Collection Time: 4.51878
Timestep Consumption Time: 0.77988
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 5.29866

Cumulative Model Updates: 36,982
Cumulative Timesteps: 616,948,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 616948374...
Checkpoint 616948374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,108.75641
Policy Entropy: 1.10767
Value Function Loss: 9.25416

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.06440

Collected Steps per Second: 10,775.63012
Overall Steps per Second: 9,278.72376

Timestep Collection Time: 4.64121
Timestep Consumption Time: 0.74875
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.38997

Cumulative Model Updates: 36,985
Cumulative Timesteps: 616,998,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,164.31740
Policy Entropy: 1.10381
Value Function Loss: 9.08889

Mean KL Divergence: 0.02626
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.09465

Collected Steps per Second: 11,100.12657
Overall Steps per Second: 9,452.04642

Timestep Collection Time: 4.50644
Timestep Consumption Time: 0.78575
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.29219

Cumulative Model Updates: 36,988
Cumulative Timesteps: 617,048,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 617048408...
Checkpoint 617048408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,354.96381
Policy Entropy: 1.09464
Value Function Loss: 9.40470

Mean KL Divergence: 0.03118
SB3 Clip Fraction: 0.17024
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.09402

Collected Steps per Second: 10,995.42303
Overall Steps per Second: 9,353.18676

Timestep Collection Time: 4.54862
Timestep Consumption Time: 0.79865
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.34727

Cumulative Model Updates: 36,991
Cumulative Timesteps: 617,098,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,122.18187
Policy Entropy: 1.09925
Value Function Loss: 9.53304

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.09183

Collected Steps per Second: 10,632.38249
Overall Steps per Second: 9,224.06530

Timestep Collection Time: 4.70393
Timestep Consumption Time: 0.71819
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 5.42212

Cumulative Model Updates: 36,994
Cumulative Timesteps: 617,148,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 617148436...
Checkpoint 617148436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,411.25541
Policy Entropy: 1.10605
Value Function Loss: 9.97408

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.08459

Collected Steps per Second: 10,851.55096
Overall Steps per Second: 9,211.22180

Timestep Collection Time: 4.60800
Timestep Consumption Time: 0.82059
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.42860

Cumulative Model Updates: 36,997
Cumulative Timesteps: 617,198,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,676.68212
Policy Entropy: 1.10001
Value Function Loss: 9.62161

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.07844

Collected Steps per Second: 10,966.03535
Overall Steps per Second: 9,343.69030

Timestep Collection Time: 4.56044
Timestep Consumption Time: 0.79183
PPO Batch Consumption Time: 0.03906
Total Iteration Time: 5.35228

Cumulative Model Updates: 37,000
Cumulative Timesteps: 617,248,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 617248450...
Checkpoint 617248450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,129.68669
Policy Entropy: 1.08505
Value Function Loss: 8.84962

Mean KL Divergence: 0.03751
SB3 Clip Fraction: 0.16769
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.09061

Collected Steps per Second: 10,961.97032
Overall Steps per Second: 9,314.38252

Timestep Collection Time: 4.56232
Timestep Consumption Time: 0.80701
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.36933

Cumulative Model Updates: 37,003
Cumulative Timesteps: 617,298,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,148.52525
Policy Entropy: 1.10222
Value Function Loss: 8.38806

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.08223

Collected Steps per Second: 10,872.99701
Overall Steps per Second: 9,289.91527

Timestep Collection Time: 4.60020
Timestep Consumption Time: 0.78391
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.38412

Cumulative Model Updates: 37,006
Cumulative Timesteps: 617,348,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 617348480...
Checkpoint 617348480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,558.08602
Policy Entropy: 1.09580
Value Function Loss: 8.78811

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.07568

Collected Steps per Second: 10,984.24150
Overall Steps per Second: 9,491.61368

Timestep Collection Time: 4.55252
Timestep Consumption Time: 0.71592
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.26844

Cumulative Model Updates: 37,009
Cumulative Timesteps: 617,398,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,343.77177
Policy Entropy: 1.09134
Value Function Loss: 8.73027

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.08333

Collected Steps per Second: 10,559.77488
Overall Steps per Second: 9,056.56792

Timestep Collection Time: 4.73722
Timestep Consumption Time: 0.78628
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.52351

Cumulative Model Updates: 37,012
Cumulative Timesteps: 617,448,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 617448510...
Checkpoint 617448510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,020.69623
Policy Entropy: 1.08444
Value Function Loss: 8.67386

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.09501

Collected Steps per Second: 12,086.57792
Overall Steps per Second: 10,252.20876

Timestep Collection Time: 4.13881
Timestep Consumption Time: 0.74053
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.87934

Cumulative Model Updates: 37,015
Cumulative Timesteps: 617,498,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,468.12434
Policy Entropy: 1.10089
Value Function Loss: 8.14132

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.08527

Collected Steps per Second: 12,116.77641
Overall Steps per Second: 10,174.14546

Timestep Collection Time: 4.12684
Timestep Consumption Time: 0.78797
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.91481

Cumulative Model Updates: 37,018
Cumulative Timesteps: 617,548,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 617548538...
Checkpoint 617548538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,335.57474
Policy Entropy: 1.10850
Value Function Loss: 8.53122

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.07722

Collected Steps per Second: 11,654.00744
Overall Steps per Second: 9,816.30490

Timestep Collection Time: 4.29191
Timestep Consumption Time: 0.80349
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.09540

Cumulative Model Updates: 37,021
Cumulative Timesteps: 617,598,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,997.89977
Policy Entropy: 1.09284
Value Function Loss: 8.66554

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.08391

Collected Steps per Second: 12,032.70242
Overall Steps per Second: 10,273.34414

Timestep Collection Time: 4.15750
Timestep Consumption Time: 0.71199
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 4.86950

Cumulative Model Updates: 37,024
Cumulative Timesteps: 617,648,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 617648582...
Checkpoint 617648582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,063.11055
Policy Entropy: 1.08449
Value Function Loss: 8.84562

Mean KL Divergence: 0.02942
SB3 Clip Fraction: 0.15945
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.08038

Collected Steps per Second: 11,955.08717
Overall Steps per Second: 9,928.53377

Timestep Collection Time: 4.18433
Timestep Consumption Time: 0.85408
PPO Batch Consumption Time: 0.03850
Total Iteration Time: 5.03841

Cumulative Model Updates: 37,027
Cumulative Timesteps: 617,698,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,431.04309
Policy Entropy: 1.09986
Value Function Loss: 8.88563

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.08516

Collected Steps per Second: 11,429.40962
Overall Steps per Second: 9,737.80990

Timestep Collection Time: 4.37678
Timestep Consumption Time: 0.76031
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.13709

Cumulative Model Updates: 37,030
Cumulative Timesteps: 617,748,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 617748630...
Checkpoint 617748630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,993.29119
Policy Entropy: 1.11141
Value Function Loss: 8.89364

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.07404

Collected Steps per Second: 11,078.10561
Overall Steps per Second: 9,446.65297

Timestep Collection Time: 4.51413
Timestep Consumption Time: 0.77960
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.29373

Cumulative Model Updates: 37,033
Cumulative Timesteps: 617,798,638

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,214.46391
Policy Entropy: 1.08008
Value Function Loss: 8.86157

Mean KL Divergence: 0.03885
SB3 Clip Fraction: 0.17454
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 11,004.87622
Overall Steps per Second: 9,252.75051

Timestep Collection Time: 4.54598
Timestep Consumption Time: 0.86084
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 5.40682

Cumulative Model Updates: 37,036
Cumulative Timesteps: 617,848,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 617848666...
Checkpoint 617848666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,176.10650
Policy Entropy: 1.09554
Value Function Loss: 8.87395

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.08382

Collected Steps per Second: 11,196.28230
Overall Steps per Second: 9,724.85945

Timestep Collection Time: 4.46827
Timestep Consumption Time: 0.67607
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.14434

Cumulative Model Updates: 37,039
Cumulative Timesteps: 617,898,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,446.93022
Policy Entropy: 1.08531
Value Function Loss: 9.02601

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.06182
Value Function Update Magnitude: 0.08053

Collected Steps per Second: 11,038.71106
Overall Steps per Second: 9,380.06429

Timestep Collection Time: 4.53078
Timestep Consumption Time: 0.80116
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.33195

Cumulative Model Updates: 37,042
Cumulative Timesteps: 617,948,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 617948708...
Checkpoint 617948708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,100.68578
Policy Entropy: 1.08997
Value Function Loss: 9.20993

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.06480
Value Function Update Magnitude: 0.06650

Collected Steps per Second: 11,270.93586
Overall Steps per Second: 9,719.98504

Timestep Collection Time: 4.43637
Timestep Consumption Time: 0.70788
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 5.14425

Cumulative Model Updates: 37,045
Cumulative Timesteps: 617,998,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,415.51023
Policy Entropy: 1.08340
Value Function Loss: 8.77373

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.06879
Value Function Update Magnitude: 0.05615

Collected Steps per Second: 10,908.25663
Overall Steps per Second: 9,358.10138

Timestep Collection Time: 4.58533
Timestep Consumption Time: 0.75955
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.34489

Cumulative Model Updates: 37,048
Cumulative Timesteps: 618,048,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 618048728...
Checkpoint 618048728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,577.60730
Policy Entropy: 1.08668
Value Function Loss: 8.87910

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.07229
Value Function Update Magnitude: 0.05076

Collected Steps per Second: 10,904.73477
Overall Steps per Second: 9,358.12796

Timestep Collection Time: 4.58663
Timestep Consumption Time: 0.75803
PPO Batch Consumption Time: 0.03952
Total Iteration Time: 5.34466

Cumulative Model Updates: 37,051
Cumulative Timesteps: 618,098,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,122.83607
Policy Entropy: 1.09743
Value Function Loss: 8.54987

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.04439

Collected Steps per Second: 11,231.25080
Overall Steps per Second: 9,608.63009

Timestep Collection Time: 4.45258
Timestep Consumption Time: 0.75191
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 5.20449

Cumulative Model Updates: 37,054
Cumulative Timesteps: 618,148,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 618148752...
Checkpoint 618148752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,899.32172
Policy Entropy: 1.10561
Value Function Loss: 8.67861

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.05120

Collected Steps per Second: 10,971.86077
Overall Steps per Second: 9,444.29395

Timestep Collection Time: 4.56003
Timestep Consumption Time: 0.73756
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.29759

Cumulative Model Updates: 37,057
Cumulative Timesteps: 618,198,784

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469,437.41212
Policy Entropy: 1.10544
Value Function Loss: 7.99268

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.05177

Collected Steps per Second: 10,961.57384
Overall Steps per Second: 9,424.61930

Timestep Collection Time: 4.56175
Timestep Consumption Time: 0.74392
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.30568

Cumulative Model Updates: 37,060
Cumulative Timesteps: 618,248,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 618248788...
Checkpoint 618248788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,453.75213
Policy Entropy: 1.09474
Value Function Loss: 8.28869

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.04595

Collected Steps per Second: 10,654.00660
Overall Steps per Second: 9,170.00172

Timestep Collection Time: 4.69457
Timestep Consumption Time: 0.75973
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.45431

Cumulative Model Updates: 37,063
Cumulative Timesteps: 618,298,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,111.26720
Policy Entropy: 1.10031
Value Function Loss: 8.64367

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.04959

Collected Steps per Second: 10,818.97044
Overall Steps per Second: 9,230.06863

Timestep Collection Time: 4.62170
Timestep Consumption Time: 0.79560
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 5.41729

Cumulative Model Updates: 37,066
Cumulative Timesteps: 618,348,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 618348806...
Checkpoint 618348806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392,108.60506
Policy Entropy: 1.10291
Value Function Loss: 8.69895

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.06518
Value Function Update Magnitude: 0.04650

Collected Steps per Second: 10,994.88259
Overall Steps per Second: 9,537.11678

Timestep Collection Time: 4.54993
Timestep Consumption Time: 0.69547
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 5.24540

Cumulative Model Updates: 37,069
Cumulative Timesteps: 618,398,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,326.78548
Policy Entropy: 1.10369
Value Function Loss: 8.05037

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.04354

Collected Steps per Second: 10,985.35691
Overall Steps per Second: 9,387.73551

Timestep Collection Time: 4.55370
Timestep Consumption Time: 0.77496
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 5.32865

Cumulative Model Updates: 37,072
Cumulative Timesteps: 618,448,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 618448856...
Checkpoint 618448856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,126.91125
Policy Entropy: 1.11077
Value Function Loss: 8.04647

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.12026
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.04412

Collected Steps per Second: 10,854.64691
Overall Steps per Second: 9,286.04564

Timestep Collection Time: 4.60909
Timestep Consumption Time: 0.77857
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.38765

Cumulative Model Updates: 37,075
Cumulative Timesteps: 618,498,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,895.18185
Policy Entropy: 1.11366
Value Function Loss: 8.49214

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.04798

Collected Steps per Second: 11,041.20881
Overall Steps per Second: 9,388.20357

Timestep Collection Time: 4.53048
Timestep Consumption Time: 0.79769
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.32818

Cumulative Model Updates: 37,078
Cumulative Timesteps: 618,548,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 618548908...
Checkpoint 618548908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,199.09573
Policy Entropy: 1.12342
Value Function Loss: 9.17996

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.04560

Collected Steps per Second: 10,614.21423
Overall Steps per Second: 8,955.75227

Timestep Collection Time: 4.71142
Timestep Consumption Time: 0.87248
PPO Batch Consumption Time: 0.04943
Total Iteration Time: 5.58390

Cumulative Model Updates: 37,081
Cumulative Timesteps: 618,598,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,837.38039
Policy Entropy: 1.10821
Value Function Loss: 8.95785

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 11,554.57919
Overall Steps per Second: 9,953.33865

Timestep Collection Time: 4.32937
Timestep Consumption Time: 0.69649
PPO Batch Consumption Time: 0.03763
Total Iteration Time: 5.02585

Cumulative Model Updates: 37,084
Cumulative Timesteps: 618,648,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 618648940...
Checkpoint 618648940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,979.91517
Policy Entropy: 1.11337
Value Function Loss: 9.21078

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.04768

Collected Steps per Second: 11,370.71772
Overall Steps per Second: 9,622.84811

Timestep Collection Time: 4.39919
Timestep Consumption Time: 0.79906
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.19825

Cumulative Model Updates: 37,087
Cumulative Timesteps: 618,698,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,426.45621
Policy Entropy: 1.11271
Value Function Loss: 8.40706

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.14373
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.04743

Collected Steps per Second: 11,152.46659
Overall Steps per Second: 9,533.11977

Timestep Collection Time: 4.48475
Timestep Consumption Time: 0.76180
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.24655

Cumulative Model Updates: 37,090
Cumulative Timesteps: 618,748,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 618748978...
Checkpoint 618748978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,412.78925
Policy Entropy: 1.10321
Value Function Loss: 8.24017

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.05316

Collected Steps per Second: 11,566.71641
Overall Steps per Second: 9,800.24075

Timestep Collection Time: 4.32482
Timestep Consumption Time: 0.77954
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.10436

Cumulative Model Updates: 37,093
Cumulative Timesteps: 618,799,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,140.69877
Policy Entropy: 1.09544
Value Function Loss: 8.40840

Mean KL Divergence: 0.02949
SB3 Clip Fraction: 0.17292
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.05076

Collected Steps per Second: 11,487.51175
Overall Steps per Second: 9,688.36214

Timestep Collection Time: 4.35447
Timestep Consumption Time: 0.80863
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.16310

Cumulative Model Updates: 37,096
Cumulative Timesteps: 618,849,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 618849024...
Checkpoint 618849024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,334.24468
Policy Entropy: 1.10633
Value Function Loss: 9.27901

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.04661

Collected Steps per Second: 11,197.08158
Overall Steps per Second: 9,659.17438

Timestep Collection Time: 4.46652
Timestep Consumption Time: 0.71115
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 5.17767

Cumulative Model Updates: 37,099
Cumulative Timesteps: 618,899,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,907.09516
Policy Entropy: 1.11679
Value Function Loss: 9.67983

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.06275

Collected Steps per Second: 11,245.37719
Overall Steps per Second: 9,547.31920

Timestep Collection Time: 4.44841
Timestep Consumption Time: 0.79118
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.23959

Cumulative Model Updates: 37,102
Cumulative Timesteps: 618,949,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 618949060...
Checkpoint 618949060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,914.86091
Policy Entropy: 1.09551
Value Function Loss: 9.57177

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.07204

Collected Steps per Second: 11,053.55280
Overall Steps per Second: 9,467.84344

Timestep Collection Time: 4.52488
Timestep Consumption Time: 0.75784
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.28272

Cumulative Model Updates: 37,105
Cumulative Timesteps: 618,999,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,180.09723
Policy Entropy: 1.11628
Value Function Loss: 8.93314

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.06770

Collected Steps per Second: 11,279.32106
Overall Steps per Second: 9,634.85550

Timestep Collection Time: 4.43484
Timestep Consumption Time: 0.75693
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.19177

Cumulative Model Updates: 37,108
Cumulative Timesteps: 619,049,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 619049098...
Checkpoint 619049098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,476.64976
Policy Entropy: 1.10848
Value Function Loss: 8.40083

Mean KL Divergence: 0.02388
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.07192

Collected Steps per Second: 11,312.71880
Overall Steps per Second: 9,678.24863

Timestep Collection Time: 4.42246
Timestep Consumption Time: 0.74687
PPO Batch Consumption Time: 0.03831
Total Iteration Time: 5.16932

Cumulative Model Updates: 37,111
Cumulative Timesteps: 619,099,128

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,026.24209
Policy Entropy: 1.10484
Value Function Loss: 7.86430

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 10,644.12036
Overall Steps per Second: 9,259.44642

Timestep Collection Time: 4.69968
Timestep Consumption Time: 0.70280
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.40248

Cumulative Model Updates: 37,114
Cumulative Timesteps: 619,149,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 619149152...
Checkpoint 619149152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,368.98980
Policy Entropy: 1.09368
Value Function Loss: 7.84659

Mean KL Divergence: 0.03186
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.06378

Collected Steps per Second: 10,897.43696
Overall Steps per Second: 9,337.72680

Timestep Collection Time: 4.59044
Timestep Consumption Time: 0.76676
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.35719

Cumulative Model Updates: 37,117
Cumulative Timesteps: 619,199,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427,545.21372
Policy Entropy: 1.11133
Value Function Loss: 8.13729

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.07089

Collected Steps per Second: 10,873.78975
Overall Steps per Second: 9,384.29346

Timestep Collection Time: 4.59968
Timestep Consumption Time: 0.73007
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.32976

Cumulative Model Updates: 37,120
Cumulative Timesteps: 619,249,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 619249192...
Checkpoint 619249192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371,426.84784
Policy Entropy: 1.10786
Value Function Loss: 8.22264

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.07271

Collected Steps per Second: 10,995.67547
Overall Steps per Second: 9,364.41232

Timestep Collection Time: 4.54979
Timestep Consumption Time: 0.79256
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.34235

Cumulative Model Updates: 37,123
Cumulative Timesteps: 619,299,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,415.67067
Policy Entropy: 1.09441
Value Function Loss: 8.66475

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.15309
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.07028

Collected Steps per Second: 10,655.31940
Overall Steps per Second: 9,130.13445

Timestep Collection Time: 4.69381
Timestep Consumption Time: 0.78410
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 5.47790

Cumulative Model Updates: 37,126
Cumulative Timesteps: 619,349,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 619349234...
Checkpoint 619349234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,685.28675
Policy Entropy: 1.10790
Value Function Loss: 8.94506

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 11,119.44154
Overall Steps per Second: 9,600.99759

Timestep Collection Time: 4.49717
Timestep Consumption Time: 0.71125
PPO Batch Consumption Time: 0.03937
Total Iteration Time: 5.20842

Cumulative Model Updates: 37,129
Cumulative Timesteps: 619,399,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,956.16517
Policy Entropy: 1.11967
Value Function Loss: 9.00402

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.06999

Collected Steps per Second: 10,807.05011
Overall Steps per Second: 9,240.79644

Timestep Collection Time: 4.62939
Timestep Consumption Time: 0.78465
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.41404

Cumulative Model Updates: 37,132
Cumulative Timesteps: 619,449,270

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 619449270...
Checkpoint 619449270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,438.93152
Policy Entropy: 1.11013
Value Function Loss: 8.34271

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.07592

Collected Steps per Second: 10,756.08273
Overall Steps per Second: 9,215.16000

Timestep Collection Time: 4.65039
Timestep Consumption Time: 0.77762
PPO Batch Consumption Time: 0.03907
Total Iteration Time: 5.42801

Cumulative Model Updates: 37,135
Cumulative Timesteps: 619,499,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,144.45796
Policy Entropy: 1.11009
Value Function Loss: 8.26426

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.09956

Collected Steps per Second: 11,043.64060
Overall Steps per Second: 9,409.42586

Timestep Collection Time: 4.52785
Timestep Consumption Time: 0.78639
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 5.31425

Cumulative Model Updates: 37,138
Cumulative Timesteps: 619,549,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 619549294...
Checkpoint 619549294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,369.44912
Policy Entropy: 1.11600
Value Function Loss: 8.43027

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.09304

Collected Steps per Second: 10,752.58969
Overall Steps per Second: 9,150.38592

Timestep Collection Time: 4.65134
Timestep Consumption Time: 0.81444
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.46578

Cumulative Model Updates: 37,141
Cumulative Timesteps: 619,599,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,195.86877
Policy Entropy: 1.12373
Value Function Loss: 8.78524

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.08632

Collected Steps per Second: 10,816.67614
Overall Steps per Second: 9,422.74724

Timestep Collection Time: 4.62249
Timestep Consumption Time: 0.68382
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.30631

Cumulative Model Updates: 37,144
Cumulative Timesteps: 619,649,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 619649308...
Checkpoint 619649308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,928.23015
Policy Entropy: 1.09945
Value Function Loss: 8.84765

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.08271

Collected Steps per Second: 10,646.89579
Overall Steps per Second: 9,057.70048

Timestep Collection Time: 4.69696
Timestep Consumption Time: 0.82409
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.52105

Cumulative Model Updates: 37,147
Cumulative Timesteps: 619,699,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373,627.72338
Policy Entropy: 1.11864
Value Function Loss: 8.80641

Mean KL Divergence: 0.02552
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.08480

Collected Steps per Second: 11,343.09117
Overall Steps per Second: 9,809.12379

Timestep Collection Time: 4.40885
Timestep Consumption Time: 0.68946
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.09831

Cumulative Model Updates: 37,150
Cumulative Timesteps: 619,749,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 619749326...
Checkpoint 619749326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,100.52311
Policy Entropy: 1.11105
Value Function Loss: 8.79284

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.04394
Value Function Update Magnitude: 0.07846

Collected Steps per Second: 12,219.70726
Overall Steps per Second: 10,021.97158

Timestep Collection Time: 4.09257
Timestep Consumption Time: 0.89747
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 4.99004

Cumulative Model Updates: 37,153
Cumulative Timesteps: 619,799,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,427.59768
Policy Entropy: 1.09893
Value Function Loss: 8.41613

Mean KL Divergence: 0.02818
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.07108

Collected Steps per Second: 12,021.98512
Overall Steps per Second: 10,156.10153

Timestep Collection Time: 4.16038
Timestep Consumption Time: 0.76435
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 4.92472

Cumulative Model Updates: 37,156
Cumulative Timesteps: 619,849,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 619849352...
Checkpoint 619849352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,142.71985
Policy Entropy: 1.09368
Value Function Loss: 8.08298

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.06956

Collected Steps per Second: 12,333.80232
Overall Steps per Second: 10,296.95364

Timestep Collection Time: 4.05390
Timestep Consumption Time: 0.80191
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 4.85581

Cumulative Model Updates: 37,159
Cumulative Timesteps: 619,899,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,357.86620
Policy Entropy: 1.09869
Value Function Loss: 8.10395

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.07386

Collected Steps per Second: 12,184.59560
Overall Steps per Second: 10,236.93613

Timestep Collection Time: 4.10584
Timestep Consumption Time: 0.78117
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.88701

Cumulative Model Updates: 37,162
Cumulative Timesteps: 619,949,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 619949380...
Checkpoint 619949380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,848.07397
Policy Entropy: 1.10547
Value Function Loss: 8.34862

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.04281
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 11,674.68257
Overall Steps per Second: 9,912.19012

Timestep Collection Time: 4.28448
Timestep Consumption Time: 0.76183
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.04631

Cumulative Model Updates: 37,165
Cumulative Timesteps: 619,999,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,173.51475
Policy Entropy: 1.07765
Value Function Loss: 8.45224

Mean KL Divergence: 0.04274
SB3 Clip Fraction: 0.19725
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.09027

Collected Steps per Second: 11,787.71486
Overall Steps per Second: 9,993.40162

Timestep Collection Time: 4.24187
Timestep Consumption Time: 0.76163
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.00350

Cumulative Model Updates: 37,168
Cumulative Timesteps: 620,049,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 620049402...
Checkpoint 620049402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,698.71778
Policy Entropy: 1.09576
Value Function Loss: 8.60005

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.07966

Collected Steps per Second: 11,054.77899
Overall Steps per Second: 9,330.06342

Timestep Collection Time: 4.52329
Timestep Consumption Time: 0.83616
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.35945

Cumulative Model Updates: 37,171
Cumulative Timesteps: 620,099,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380,065.96530
Policy Entropy: 1.09755
Value Function Loss: 8.73955

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.09002

Collected Steps per Second: 11,292.13596
Overall Steps per Second: 9,593.49585

Timestep Collection Time: 4.42963
Timestep Consumption Time: 0.78432
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.21395

Cumulative Model Updates: 37,174
Cumulative Timesteps: 620,149,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 620149426...
Checkpoint 620149426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,787.19432
Policy Entropy: 1.08002
Value Function Loss: 8.45113

Mean KL Divergence: 0.02953
SB3 Clip Fraction: 0.17217
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.10309

Collected Steps per Second: 11,107.87542
Overall Steps per Second: 9,435.84015

Timestep Collection Time: 4.50221
Timestep Consumption Time: 0.79779
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.30000

Cumulative Model Updates: 37,177
Cumulative Timesteps: 620,199,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445,819.40567
Policy Entropy: 1.09206
Value Function Loss: 8.15155

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.10149

Collected Steps per Second: 11,429.65387
Overall Steps per Second: 9,916.44297

Timestep Collection Time: 4.37634
Timestep Consumption Time: 0.66781
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.04415

Cumulative Model Updates: 37,180
Cumulative Timesteps: 620,249,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 620249456...
Checkpoint 620249456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,236.45360
Policy Entropy: 1.08911
Value Function Loss: 8.11831

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.09337

Collected Steps per Second: 10,641.03879
Overall Steps per Second: 9,066.72975

Timestep Collection Time: 4.70180
Timestep Consumption Time: 0.81640
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.51820

Cumulative Model Updates: 37,183
Cumulative Timesteps: 620,299,488

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,122.12931
Policy Entropy: 1.07638
Value Function Loss: 8.44841

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.08719

Collected Steps per Second: 10,983.88184
Overall Steps per Second: 9,424.61751

Timestep Collection Time: 4.55231
Timestep Consumption Time: 0.75316
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.30547

Cumulative Model Updates: 37,186
Cumulative Timesteps: 620,349,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 620349490...
Checkpoint 620349490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,531.83050
Policy Entropy: 1.07410
Value Function Loss: 8.96494

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.16265
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.08956

Collected Steps per Second: 11,222.75920
Overall Steps per Second: 9,498.36720

Timestep Collection Time: 4.45595
Timestep Consumption Time: 0.80896
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 5.26490

Cumulative Model Updates: 37,189
Cumulative Timesteps: 620,399,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,139.20499
Policy Entropy: 1.07637
Value Function Loss: 9.42808

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.08443

Collected Steps per Second: 10,892.08089
Overall Steps per Second: 9,386.05191

Timestep Collection Time: 4.59178
Timestep Consumption Time: 0.73677
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 5.32855

Cumulative Model Updates: 37,192
Cumulative Timesteps: 620,449,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 620449512...
Checkpoint 620449512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,407.08895
Policy Entropy: 1.09064
Value Function Loss: 9.27314

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.09822

Collected Steps per Second: 10,942.13023
Overall Steps per Second: 9,472.57292

Timestep Collection Time: 4.57077
Timestep Consumption Time: 0.70910
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.27987

Cumulative Model Updates: 37,195
Cumulative Timesteps: 620,499,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,306.20356
Policy Entropy: 1.07523
Value Function Loss: 8.72996

Mean KL Divergence: 0.02528
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.09430

Collected Steps per Second: 11,000.66916
Overall Steps per Second: 9,416.68571

Timestep Collection Time: 4.54645
Timestep Consumption Time: 0.76476
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 5.31121

Cumulative Model Updates: 37,198
Cumulative Timesteps: 620,549,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 620549540...
Checkpoint 620549540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,568.70420
Policy Entropy: 1.06446
Value Function Loss: 8.08111

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.16485
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.09754

Collected Steps per Second: 10,597.93245
Overall Steps per Second: 9,079.37772

Timestep Collection Time: 4.71828
Timestep Consumption Time: 0.78915
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.50743

Cumulative Model Updates: 37,201
Cumulative Timesteps: 620,599,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,534.08975
Policy Entropy: 1.06586
Value Function Loss: 8.09998

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.10620

Collected Steps per Second: 10,788.31151
Overall Steps per Second: 9,187.82649

Timestep Collection Time: 4.63539
Timestep Consumption Time: 0.80747
PPO Batch Consumption Time: 0.04074
Total Iteration Time: 5.44285

Cumulative Model Updates: 37,204
Cumulative Timesteps: 620,649,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 620649552...
Checkpoint 620649552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,615.02460
Policy Entropy: 1.07641
Value Function Loss: 8.47949

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.04167
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 10,403.55835
Overall Steps per Second: 8,950.22606

Timestep Collection Time: 4.80778
Timestep Consumption Time: 0.78068
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.58846

Cumulative Model Updates: 37,207
Cumulative Timesteps: 620,699,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,875.52088
Policy Entropy: 1.05584
Value Function Loss: 8.30721

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.12126

Collected Steps per Second: 10,668.19960
Overall Steps per Second: 9,309.21642

Timestep Collection Time: 4.68851
Timestep Consumption Time: 0.68444
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.37295

Cumulative Model Updates: 37,210
Cumulative Timesteps: 620,749,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 620749588...
Checkpoint 620749588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,576.04224
Policy Entropy: 1.05693
Value Function Loss: 8.77070

Mean KL Divergence: 0.02923
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.04326
Value Function Update Magnitude: 0.11476

Collected Steps per Second: 11,010.71164
Overall Steps per Second: 9,460.14613

Timestep Collection Time: 4.54212
Timestep Consumption Time: 0.74448
PPO Batch Consumption Time: 0.03399
Total Iteration Time: 5.28660

Cumulative Model Updates: 37,213
Cumulative Timesteps: 620,799,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,076.63618
Policy Entropy: 1.06490
Value Function Loss: 8.52085

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.04265
Value Function Update Magnitude: 0.10689

Collected Steps per Second: 10,414.31893
Overall Steps per Second: 8,983.80462

Timestep Collection Time: 4.80339
Timestep Consumption Time: 0.76486
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.56824

Cumulative Model Updates: 37,216
Cumulative Timesteps: 620,849,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 620849624...
Checkpoint 620849624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,159.59332
Policy Entropy: 1.07912
Value Function Loss: 8.71681

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.15572
Policy Update Magnitude: 0.04313
Value Function Update Magnitude: 0.08790

Collected Steps per Second: 11,408.86479
Overall Steps per Second: 9,729.47129

Timestep Collection Time: 4.38431
Timestep Consumption Time: 0.75677
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.14108

Cumulative Model Updates: 37,219
Cumulative Timesteps: 620,899,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,400.36341
Policy Entropy: 1.05515
Value Function Loss: 8.36915

Mean KL Divergence: 0.02967
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.07908

Collected Steps per Second: 11,438.46718
Overall Steps per Second: 9,727.86732

Timestep Collection Time: 4.37244
Timestep Consumption Time: 0.76887
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 5.14131

Cumulative Model Updates: 37,222
Cumulative Timesteps: 620,949,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 620949658...
Checkpoint 620949658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,202.77691
Policy Entropy: 1.07520
Value Function Loss: 8.58830

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.07099

Collected Steps per Second: 11,306.33886
Overall Steps per Second: 9,812.23634

Timestep Collection Time: 4.42283
Timestep Consumption Time: 0.67346
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.09629

Cumulative Model Updates: 37,225
Cumulative Timesteps: 620,999,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,864.26112
Policy Entropy: 1.07652
Value Function Loss: 8.56033

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.07271

Collected Steps per Second: 11,559.74904
Overall Steps per Second: 9,823.07601

Timestep Collection Time: 4.32639
Timestep Consumption Time: 0.76489
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.09128

Cumulative Model Updates: 37,228
Cumulative Timesteps: 621,049,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 621049676...
Checkpoint 621049676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,125.62568
Policy Entropy: 1.06469
Value Function Loss: 8.78004

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.06941

Collected Steps per Second: 11,519.21579
Overall Steps per Second: 9,826.58773

Timestep Collection Time: 4.34318
Timestep Consumption Time: 0.74811
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.09129

Cumulative Model Updates: 37,231
Cumulative Timesteps: 621,099,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,211.59023
Policy Entropy: 1.06870
Value Function Loss: 8.53802

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.07174

Collected Steps per Second: 11,087.26913
Overall Steps per Second: 9,430.15787

Timestep Collection Time: 4.51058
Timestep Consumption Time: 0.79262
PPO Batch Consumption Time: 0.03843
Total Iteration Time: 5.30320

Cumulative Model Updates: 37,234
Cumulative Timesteps: 621,149,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 621149716...
Checkpoint 621149716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,958.08318
Policy Entropy: 1.07746
Value Function Loss: 8.40551

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.06920

Collected Steps per Second: 11,335.35597
Overall Steps per Second: 9,597.58347

Timestep Collection Time: 4.41239
Timestep Consumption Time: 0.79892
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.21131

Cumulative Model Updates: 37,237
Cumulative Timesteps: 621,199,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,590.99762
Policy Entropy: 1.08176
Value Function Loss: 8.15142

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 11,421.75769
Overall Steps per Second: 9,856.06807

Timestep Collection Time: 4.38006
Timestep Consumption Time: 0.69580
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.07586

Cumulative Model Updates: 37,240
Cumulative Timesteps: 621,249,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 621249760...
Checkpoint 621249760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,901.20225
Policy Entropy: 1.06122
Value Function Loss: 8.02840

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.06882

Collected Steps per Second: 11,266.32370
Overall Steps per Second: 9,509.08945

Timestep Collection Time: 4.43872
Timestep Consumption Time: 0.82025
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 5.25897

Cumulative Model Updates: 37,243
Cumulative Timesteps: 621,299,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,512.68529
Policy Entropy: 1.05764
Value Function Loss: 8.22659

Mean KL Divergence: 0.03214
SB3 Clip Fraction: 0.16583
Policy Update Magnitude: 0.04476
Value Function Update Magnitude: 0.07007

Collected Steps per Second: 11,282.42081
Overall Steps per Second: 9,627.13287

Timestep Collection Time: 4.43398
Timestep Consumption Time: 0.76238
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.19636

Cumulative Model Updates: 37,246
Cumulative Timesteps: 621,349,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 621349794...
Checkpoint 621349794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,614.46129
Policy Entropy: 1.08004
Value Function Loss: 8.09635

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.06866

Collected Steps per Second: 11,554.15891
Overall Steps per Second: 9,785.77076

Timestep Collection Time: 4.32797
Timestep Consumption Time: 0.78211
PPO Batch Consumption Time: 0.03801
Total Iteration Time: 5.11007

Cumulative Model Updates: 37,249
Cumulative Timesteps: 621,399,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,166.25818
Policy Entropy: 1.08073
Value Function Loss: 7.91440

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.07387

Collected Steps per Second: 10,615.70562
Overall Steps per Second: 9,102.19504

Timestep Collection Time: 4.71302
Timestep Consumption Time: 0.78368
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 5.49670

Cumulative Model Updates: 37,252
Cumulative Timesteps: 621,449,832

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 621449832...
Checkpoint 621449832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,451.21871
Policy Entropy: 1.07331
Value Function Loss: 7.88011

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.07273

Collected Steps per Second: 11,252.49788
Overall Steps per Second: 9,798.39501

Timestep Collection Time: 4.44417
Timestep Consumption Time: 0.65952
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.10369

Cumulative Model Updates: 37,255
Cumulative Timesteps: 621,499,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,426.12155
Policy Entropy: 1.06629
Value Function Loss: 8.20736

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.06650

Collected Steps per Second: 11,023.52560
Overall Steps per Second: 9,386.30688

Timestep Collection Time: 4.53594
Timestep Consumption Time: 0.79119
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.32712

Cumulative Model Updates: 37,258
Cumulative Timesteps: 621,549,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 621549842...
Checkpoint 621549842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,436.37200
Policy Entropy: 1.06583
Value Function Loss: 8.80723

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.06695
Value Function Update Magnitude: 0.06301

Collected Steps per Second: 11,133.41266
Overall Steps per Second: 9,548.04884

Timestep Collection Time: 4.49206
Timestep Consumption Time: 0.74586
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 5.23793

Cumulative Model Updates: 37,261
Cumulative Timesteps: 621,599,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,397.86323
Policy Entropy: 1.05571
Value Function Loss: 8.73301

Mean KL Divergence: 0.03437
SB3 Clip Fraction: 0.18440
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.07918

Collected Steps per Second: 11,317.92651
Overall Steps per Second: 9,532.08956

Timestep Collection Time: 4.41883
Timestep Consumption Time: 0.82787
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.24670

Cumulative Model Updates: 37,264
Cumulative Timesteps: 621,649,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 621649866...
Checkpoint 621649866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,441.37947
Policy Entropy: 1.07417
Value Function Loss: 8.63222

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.08812

Collected Steps per Second: 11,109.72528
Overall Steps per Second: 9,340.51720

Timestep Collection Time: 4.50110
Timestep Consumption Time: 0.85256
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 5.35367

Cumulative Model Updates: 37,267
Cumulative Timesteps: 621,699,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,651.52815
Policy Entropy: 1.08073
Value Function Loss: 8.09299

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.15491
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.08130

Collected Steps per Second: 10,934.36367
Overall Steps per Second: 9,488.66294

Timestep Collection Time: 4.57457
Timestep Consumption Time: 0.69699
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.27155

Cumulative Model Updates: 37,270
Cumulative Timesteps: 621,749,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 621749892...
Checkpoint 621749892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,100.15165
Policy Entropy: 1.04495
Value Function Loss: 8.18193

Mean KL Divergence: 0.05965
SB3 Clip Fraction: 0.19103
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.08547

Collected Steps per Second: 10,929.73610
Overall Steps per Second: 9,350.24297

Timestep Collection Time: 4.57705
Timestep Consumption Time: 0.77318
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.35024

Cumulative Model Updates: 37,273
Cumulative Timesteps: 621,799,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,451.52130
Policy Entropy: 1.06975
Value Function Loss: 8.19465

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.15900
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.07258

Collected Steps per Second: 10,983.47958
Overall Steps per Second: 9,334.18087

Timestep Collection Time: 4.55302
Timestep Consumption Time: 0.80449
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.35751

Cumulative Model Updates: 37,276
Cumulative Timesteps: 621,849,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 621849926...
Checkpoint 621849926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,440.75947
Policy Entropy: 1.05589
Value Function Loss: 8.44944

Mean KL Divergence: 0.02813
SB3 Clip Fraction: 0.16303
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.06577

Collected Steps per Second: 10,909.81844
Overall Steps per Second: 9,314.24287

Timestep Collection Time: 4.58486
Timestep Consumption Time: 0.78541
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.37027

Cumulative Model Updates: 37,279
Cumulative Timesteps: 621,899,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,172.15139
Policy Entropy: 1.05527
Value Function Loss: 8.55991

Mean KL Divergence: 0.03908
SB3 Clip Fraction: 0.18724
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.09543

Collected Steps per Second: 10,941.07074
Overall Steps per Second: 9,410.05983

Timestep Collection Time: 4.57231
Timestep Consumption Time: 0.74391
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.31623

Cumulative Model Updates: 37,282
Cumulative Timesteps: 621,949,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 621949972...
Checkpoint 621949972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,817.29454
Policy Entropy: 1.07332
Value Function Loss: 8.51016

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.09931

Collected Steps per Second: 10,510.64670
Overall Steps per Second: 9,177.35818

Timestep Collection Time: 4.75727
Timestep Consumption Time: 0.69114
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 5.44841

Cumulative Model Updates: 37,285
Cumulative Timesteps: 621,999,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,671.11412
Policy Entropy: 1.06857
Value Function Loss: 8.71680

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.08876

Collected Steps per Second: 11,927.20239
Overall Steps per Second: 10,025.08596

Timestep Collection Time: 4.19411
Timestep Consumption Time: 0.79577
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 4.98988

Cumulative Model Updates: 37,288
Cumulative Timesteps: 622,049,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 622049998...
Checkpoint 622049998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,384.92357
Policy Entropy: 1.05152
Value Function Loss: 8.20261

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.09870

Collected Steps per Second: 11,910.38923
Overall Steps per Second: 10,036.03706

Timestep Collection Time: 4.19869
Timestep Consumption Time: 0.78416
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.98284

Cumulative Model Updates: 37,291
Cumulative Timesteps: 622,100,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,544.06777
Policy Entropy: 1.03248
Value Function Loss: 7.87262

Mean KL Divergence: 0.03004
SB3 Clip Fraction: 0.16197
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.11330

Collected Steps per Second: 12,109.01552
Overall Steps per Second: 10,246.99441

Timestep Collection Time: 4.12982
Timestep Consumption Time: 0.75044
PPO Batch Consumption Time: 0.03336
Total Iteration Time: 4.88026

Cumulative Model Updates: 37,294
Cumulative Timesteps: 622,150,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 622150014...
Checkpoint 622150014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,913.46210
Policy Entropy: 1.06064
Value Function Loss: 7.85079

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.09872

Collected Steps per Second: 10,683.06166
Overall Steps per Second: 9,136.42864

Timestep Collection Time: 4.68143
Timestep Consumption Time: 0.79248
PPO Batch Consumption Time: 0.03890
Total Iteration Time: 5.47391

Cumulative Model Updates: 37,297
Cumulative Timesteps: 622,200,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,294.40728
Policy Entropy: 1.05746
Value Function Loss: 8.21895

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.15518
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.09793

Collected Steps per Second: 11,443.67699
Overall Steps per Second: 9,755.77870

Timestep Collection Time: 4.37167
Timestep Consumption Time: 0.75637
PPO Batch Consumption Time: 0.03865
Total Iteration Time: 5.12804

Cumulative Model Updates: 37,300
Cumulative Timesteps: 622,250,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 622250054...
Checkpoint 622250054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,322.73962
Policy Entropy: 1.04175
Value Function Loss: 8.65405

Mean KL Divergence: 0.02611
SB3 Clip Fraction: 0.15578
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.10408

Collected Steps per Second: 10,565.50700
Overall Steps per Second: 8,953.72402

Timestep Collection Time: 4.73503
Timestep Consumption Time: 0.85237
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.58740

Cumulative Model Updates: 37,303
Cumulative Timesteps: 622,300,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453,354.35031
Policy Entropy: 1.03165
Value Function Loss: 8.66744

Mean KL Divergence: 0.03406
SB3 Clip Fraction: 0.20101
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.10467

Collected Steps per Second: 10,288.99533
Overall Steps per Second: 8,958.99017

Timestep Collection Time: 4.86131
Timestep Consumption Time: 0.72168
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 5.58300

Cumulative Model Updates: 37,306
Cumulative Timesteps: 622,350,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 622350100...
Checkpoint 622350100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,655.55667
Policy Entropy: 1.04715
Value Function Loss: 8.57969

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.09146

Collected Steps per Second: 10,547.91417
Overall Steps per Second: 8,990.79908

Timestep Collection Time: 4.74046
Timestep Consumption Time: 0.82100
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.56146

Cumulative Model Updates: 37,309
Cumulative Timesteps: 622,400,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,386.78255
Policy Entropy: 1.06292
Value Function Loss: 8.16489

Mean KL Divergence: 0.02578
SB3 Clip Fraction: 0.16243
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.07952

Collected Steps per Second: 10,935.38345
Overall Steps per Second: 9,373.68844

Timestep Collection Time: 4.57414
Timestep Consumption Time: 0.76207
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.33621

Cumulative Model Updates: 37,312
Cumulative Timesteps: 622,450,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 622450122...
Checkpoint 622450122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,454.75748
Policy Entropy: 1.03483
Value Function Loss: 7.69862

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.07892

Collected Steps per Second: 11,176.55175
Overall Steps per Second: 9,638.24698

Timestep Collection Time: 4.47473
Timestep Consumption Time: 0.71418
PPO Batch Consumption Time: 0.03839
Total Iteration Time: 5.18891

Cumulative Model Updates: 37,315
Cumulative Timesteps: 622,500,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437,469.65742
Policy Entropy: 1.04445
Value Function Loss: 7.66069

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 10,882.93080
Overall Steps per Second: 9,321.79827

Timestep Collection Time: 4.59600
Timestep Consumption Time: 0.76970
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.36570

Cumulative Model Updates: 37,318
Cumulative Timesteps: 622,550,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 622550152...
Checkpoint 622550152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,234.35777
Policy Entropy: 1.05362
Value Function Loss: 7.60622

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.07063

Collected Steps per Second: 10,965.89806
Overall Steps per Second: 9,449.46433

Timestep Collection Time: 4.56160
Timestep Consumption Time: 0.73204
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.29363

Cumulative Model Updates: 37,321
Cumulative Timesteps: 622,600,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,467.86547
Policy Entropy: 1.06586
Value Function Loss: 8.09695

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.06676

Collected Steps per Second: 11,381.38078
Overall Steps per Second: 9,649.26979

Timestep Collection Time: 4.39402
Timestep Consumption Time: 0.78876
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.18278

Cumulative Model Updates: 37,324
Cumulative Timesteps: 622,650,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 622650184...
Checkpoint 622650184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,027.35003
Policy Entropy: 1.04730
Value Function Loss: 8.01648

Mean KL Divergence: 0.02567
SB3 Clip Fraction: 0.14787
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 11,126.42868
Overall Steps per Second: 9,469.56987

Timestep Collection Time: 4.49578
Timestep Consumption Time: 0.78661
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.28239

Cumulative Model Updates: 37,327
Cumulative Timesteps: 622,700,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,603.24388
Policy Entropy: 1.04957
Value Function Loss: 8.36818

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.06589

Collected Steps per Second: 11,129.34179
Overall Steps per Second: 9,686.85590

Timestep Collection Time: 4.49371
Timestep Consumption Time: 0.66917
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.16287

Cumulative Model Updates: 37,330
Cumulative Timesteps: 622,750,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 622750218...
Checkpoint 622750218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,595.14686
Policy Entropy: 1.06388
Value Function Loss: 8.31111

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.07240

Collected Steps per Second: 10,923.45354
Overall Steps per Second: 9,324.70184

Timestep Collection Time: 4.57895
Timestep Consumption Time: 0.78508
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.36403

Cumulative Model Updates: 37,333
Cumulative Timesteps: 622,800,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,822.22453
Policy Entropy: 1.07640
Value Function Loss: 8.16535

Mean KL Divergence: 0.02268
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.06759

Collected Steps per Second: 10,687.51731
Overall Steps per Second: 9,193.71272

Timestep Collection Time: 4.67892
Timestep Consumption Time: 0.76024
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.43915

Cumulative Model Updates: 37,336
Cumulative Timesteps: 622,850,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 622850242...
Checkpoint 622850242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,183.80628
Policy Entropy: 1.04428
Value Function Loss: 7.84171

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.14478
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.06851

Collected Steps per Second: 11,118.87466
Overall Steps per Second: 9,437.52391

Timestep Collection Time: 4.49938
Timestep Consumption Time: 0.80159
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.30097

Cumulative Model Updates: 37,339
Cumulative Timesteps: 622,900,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,691.38084
Policy Entropy: 1.05373
Value Function Loss: 7.77823

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.07032

Collected Steps per Second: 10,958.09639
Overall Steps per Second: 9,344.83179

Timestep Collection Time: 4.56284
Timestep Consumption Time: 0.78771
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.35055

Cumulative Model Updates: 37,342
Cumulative Timesteps: 622,950,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 622950270...
Checkpoint 622950270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,481.19824
Policy Entropy: 1.05403
Value Function Loss: 8.38827

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 10,833.67482
Overall Steps per Second: 9,325.03901

Timestep Collection Time: 4.61653
Timestep Consumption Time: 0.74688
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 5.36341

Cumulative Model Updates: 37,345
Cumulative Timesteps: 623,000,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,329.65192
Policy Entropy: 1.06376
Value Function Loss: 8.39466

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.07008

Collected Steps per Second: 10,285.66458
Overall Steps per Second: 8,840.39242

Timestep Collection Time: 4.86327
Timestep Consumption Time: 0.79507
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.65835

Cumulative Model Updates: 37,348
Cumulative Timesteps: 623,050,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 623050306...
Checkpoint 623050306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,211.29389
Policy Entropy: 1.05542
Value Function Loss: 8.06798

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.06272
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 10,938.92067
Overall Steps per Second: 9,300.51859

Timestep Collection Time: 4.57211
Timestep Consumption Time: 0.80543
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 5.37755

Cumulative Model Updates: 37,351
Cumulative Timesteps: 623,100,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,615.64846
Policy Entropy: 1.04463
Value Function Loss: 7.85956

Mean KL Divergence: 0.03128
SB3 Clip Fraction: 0.18530
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.08310

Collected Steps per Second: 10,751.09057
Overall Steps per Second: 9,266.86708

Timestep Collection Time: 4.65348
Timestep Consumption Time: 0.74532
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.39880

Cumulative Model Updates: 37,354
Cumulative Timesteps: 623,150,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 623150350...
Checkpoint 623150350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,951.39862
Policy Entropy: 1.05371
Value Function Loss: 8.55095

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.07765

Collected Steps per Second: 11,401.57132
Overall Steps per Second: 9,721.35189

Timestep Collection Time: 4.38711
Timestep Consumption Time: 0.75826
PPO Batch Consumption Time: 0.04070
Total Iteration Time: 5.14537

Cumulative Model Updates: 37,357
Cumulative Timesteps: 623,200,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,354.68303
Policy Entropy: 1.06924
Value Function Loss: 8.46379

Mean KL Divergence: 0.02689
SB3 Clip Fraction: 0.17803
Policy Update Magnitude: 0.06496
Value Function Update Magnitude: 0.07688

Collected Steps per Second: 11,175.32227
Overall Steps per Second: 9,729.71829

Timestep Collection Time: 4.47468
Timestep Consumption Time: 0.66483
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 5.13951

Cumulative Model Updates: 37,360
Cumulative Timesteps: 623,250,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 623250376...
Checkpoint 623250376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,143.73510
Policy Entropy: 1.05828
Value Function Loss: 8.27652

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.16655
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.08382

Collected Steps per Second: 11,499.11893
Overall Steps per Second: 9,729.97235

Timestep Collection Time: 4.34868
Timestep Consumption Time: 0.79070
PPO Batch Consumption Time: 0.03349
Total Iteration Time: 5.13938

Cumulative Model Updates: 37,363
Cumulative Timesteps: 623,300,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,285.51939
Policy Entropy: 1.07047
Value Function Loss: 7.77797

Mean KL Divergence: 0.02592
SB3 Clip Fraction: 0.16205
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.08456

Collected Steps per Second: 11,130.42822
Overall Steps per Second: 9,473.59991

Timestep Collection Time: 4.49435
Timestep Consumption Time: 0.78601
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.28036

Cumulative Model Updates: 37,366
Cumulative Timesteps: 623,350,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 623350406...
Checkpoint 623350406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,414.42829
Policy Entropy: 1.07154
Value Function Loss: 8.24321

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.07467

Collected Steps per Second: 11,558.09738
Overall Steps per Second: 9,759.99581

Timestep Collection Time: 4.32770
Timestep Consumption Time: 0.79730
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.12500

Cumulative Model Updates: 37,369
Cumulative Timesteps: 623,400,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,679.45261
Policy Entropy: 1.07000
Value Function Loss: 8.21210

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.06318
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 11,239.05518
Overall Steps per Second: 9,520.83084

Timestep Collection Time: 4.45144
Timestep Consumption Time: 0.80335
PPO Batch Consumption Time: 0.03852
Total Iteration Time: 5.25479

Cumulative Model Updates: 37,372
Cumulative Timesteps: 623,450,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 623450456...
Checkpoint 623450456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,830.61432
Policy Entropy: 1.06780
Value Function Loss: 8.53179

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.04923

Collected Steps per Second: 11,094.75799
Overall Steps per Second: 9,626.77815

Timestep Collection Time: 4.50807
Timestep Consumption Time: 0.68743
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.19551

Cumulative Model Updates: 37,375
Cumulative Timesteps: 623,500,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,564.31489
Policy Entropy: 1.06738
Value Function Loss: 8.49079

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.06859
Value Function Update Magnitude: 0.05039

Collected Steps per Second: 11,246.55408
Overall Steps per Second: 9,558.19469

Timestep Collection Time: 4.44794
Timestep Consumption Time: 0.78568
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 5.23362

Cumulative Model Updates: 37,378
Cumulative Timesteps: 623,550,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 623550496...
Checkpoint 623550496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,342.42940
Policy Entropy: 1.06357
Value Function Loss: 8.54192

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.04916

Collected Steps per Second: 10,935.58730
Overall Steps per Second: 9,486.81110

Timestep Collection Time: 4.57296
Timestep Consumption Time: 0.69836
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.27132

Cumulative Model Updates: 37,381
Cumulative Timesteps: 623,600,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,556.50813
Policy Entropy: 1.07666
Value Function Loss: 8.40477

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.04953

Collected Steps per Second: 11,317.29697
Overall Steps per Second: 9,580.19337

Timestep Collection Time: 4.41819
Timestep Consumption Time: 0.80112
PPO Batch Consumption Time: 0.03732
Total Iteration Time: 5.21931

Cumulative Model Updates: 37,384
Cumulative Timesteps: 623,650,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 623650506...
Checkpoint 623650506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386,268.24486
Policy Entropy: 1.07751
Value Function Loss: 8.27580

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.14985
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.04891

Collected Steps per Second: 10,539.89361
Overall Steps per Second: 8,920.44458

Timestep Collection Time: 4.74388
Timestep Consumption Time: 0.86122
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 5.60510

Cumulative Model Updates: 37,387
Cumulative Timesteps: 623,700,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,459.32511
Policy Entropy: 1.07489
Value Function Loss: 8.48356

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.05916

Collected Steps per Second: 11,120.88003
Overall Steps per Second: 9,704.34123

Timestep Collection Time: 4.49749
Timestep Consumption Time: 0.65650
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.15398

Cumulative Model Updates: 37,390
Cumulative Timesteps: 623,750,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 623750522...
Checkpoint 623750522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,321.02759
Policy Entropy: 1.05510
Value Function Loss: 8.40142

Mean KL Divergence: 0.04202
SB3 Clip Fraction: 0.19752
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.05771

Collected Steps per Second: 11,070.86251
Overall Steps per Second: 9,413.20014

Timestep Collection Time: 4.51853
Timestep Consumption Time: 0.79571
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.31424

Cumulative Model Updates: 37,393
Cumulative Timesteps: 623,800,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,702.45001
Policy Entropy: 1.08487
Value Function Loss: 8.13200

Mean KL Divergence: 0.04277
SB3 Clip Fraction: 0.18469
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.04980

Collected Steps per Second: 11,233.11198
Overall Steps per Second: 9,559.30284

Timestep Collection Time: 4.45237
Timestep Consumption Time: 0.77960
PPO Batch Consumption Time: 0.03940
Total Iteration Time: 5.23197

Cumulative Model Updates: 37,396
Cumulative Timesteps: 623,850,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 623850560...
Checkpoint 623850560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,243.03477
Policy Entropy: 1.04584
Value Function Loss: 8.14805

Mean KL Divergence: 0.06085
SB3 Clip Fraction: 0.22017
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.05073

Collected Steps per Second: 11,245.36567
Overall Steps per Second: 9,620.17137

Timestep Collection Time: 4.44681
Timestep Consumption Time: 0.75123
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 5.19804

Cumulative Model Updates: 37,399
Cumulative Timesteps: 623,900,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,704.48516
Policy Entropy: 1.07966
Value Function Loss: 7.95513

Mean KL Divergence: 0.04906
SB3 Clip Fraction: 0.21471
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.04659

Collected Steps per Second: 11,191.04326
Overall Steps per Second: 9,443.76172

Timestep Collection Time: 4.47036
Timestep Consumption Time: 0.82710
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.29747

Cumulative Model Updates: 37,402
Cumulative Timesteps: 623,950,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 623950594...
Checkpoint 623950594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,398.88318
Policy Entropy: 1.04399
Value Function Loss: 8.03292

Mean KL Divergence: 0.07599
SB3 Clip Fraction: 0.24207
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.04749

Collected Steps per Second: 10,705.64073
Overall Steps per Second: 9,345.62779

Timestep Collection Time: 4.67174
Timestep Consumption Time: 0.67985
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.35159

Cumulative Model Updates: 37,405
Cumulative Timesteps: 624,000,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,172.12590
Policy Entropy: 1.08890
Value Function Loss: 7.83432

Mean KL Divergence: 0.05693
SB3 Clip Fraction: 0.24025
Policy Update Magnitude: 0.04008
Value Function Update Magnitude: 0.04224

Collected Steps per Second: 10,906.61784
Overall Steps per Second: 9,301.55913

Timestep Collection Time: 4.58437
Timestep Consumption Time: 0.79107
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 5.37544

Cumulative Model Updates: 37,408
Cumulative Timesteps: 624,050,608

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 624050608...
Checkpoint 624050608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,652.28758
Policy Entropy: 1.05653
Value Function Loss: 8.14612

Mean KL Divergence: 0.06489
SB3 Clip Fraction: 0.23381
Policy Update Magnitude: 0.04117
Value Function Update Magnitude: 0.04721

Collected Steps per Second: 11,008.00227
Overall Steps per Second: 9,409.31005

Timestep Collection Time: 4.54379
Timestep Consumption Time: 0.77201
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.31580

Cumulative Model Updates: 37,411
Cumulative Timesteps: 624,100,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,928.00747
Policy Entropy: 1.08420
Value Function Loss: 8.11475

Mean KL Divergence: 0.05757
SB3 Clip Fraction: 0.22798
Policy Update Magnitude: 0.03888
Value Function Update Magnitude: 0.04364

Collected Steps per Second: 11,167.62991
Overall Steps per Second: 9,522.87455

Timestep Collection Time: 4.47937
Timestep Consumption Time: 0.77366
PPO Batch Consumption Time: 0.03221
Total Iteration Time: 5.25304

Cumulative Model Updates: 37,414
Cumulative Timesteps: 624,150,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 624150650...
Checkpoint 624150650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350,898.94865
Policy Entropy: 1.05812
Value Function Loss: 8.04936

Mean KL Divergence: 0.06763
SB3 Clip Fraction: 0.22281
Policy Update Magnitude: 0.03938
Value Function Update Magnitude: 0.04347

Collected Steps per Second: 11,044.67094
Overall Steps per Second: 9,433.08598

Timestep Collection Time: 4.52852
Timestep Consumption Time: 0.77367
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.30219

Cumulative Model Updates: 37,417
Cumulative Timesteps: 624,200,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,620.82408
Policy Entropy: 1.08910
Value Function Loss: 8.09627

Mean KL Divergence: 0.04930
SB3 Clip Fraction: 0.20223
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.04475

Collected Steps per Second: 10,685.53783
Overall Steps per Second: 9,145.09692

Timestep Collection Time: 4.68016
Timestep Consumption Time: 0.78835
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.46850

Cumulative Model Updates: 37,420
Cumulative Timesteps: 624,250,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 624250676...
Checkpoint 624250676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,963.35623
Policy Entropy: 1.04895
Value Function Loss: 7.84795

Mean KL Divergence: 0.08070
SB3 Clip Fraction: 0.25445
Policy Update Magnitude: 0.04293
Value Function Update Magnitude: 0.04083

Collected Steps per Second: 11,522.63803
Overall Steps per Second: 9,789.70892

Timestep Collection Time: 4.34171
Timestep Consumption Time: 0.76855
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.11026

Cumulative Model Updates: 37,423
Cumulative Timesteps: 624,300,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,563.49801
Policy Entropy: 1.08228
Value Function Loss: 7.69273

Mean KL Divergence: 0.04563
SB3 Clip Fraction: 0.20089
Policy Update Magnitude: 0.03913
Value Function Update Magnitude: 0.04714

Collected Steps per Second: 11,908.37778
Overall Steps per Second: 10,229.58376

Timestep Collection Time: 4.20007
Timestep Consumption Time: 0.68928
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 4.88935

Cumulative Model Updates: 37,426
Cumulative Timesteps: 624,350,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 624350720...
Checkpoint 624350720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,434.58107
Policy Entropy: 1.04117
Value Function Loss: 7.10912

Mean KL Divergence: 0.06883
SB3 Clip Fraction: 0.24653
Policy Update Magnitude: 0.04432
Value Function Update Magnitude: 0.04364

Collected Steps per Second: 11,965.89638
Overall Steps per Second: 10,088.47568

Timestep Collection Time: 4.17954
Timestep Consumption Time: 0.77779
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.95734

Cumulative Model Updates: 37,429
Cumulative Timesteps: 624,400,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382,451.00139
Policy Entropy: 1.07281
Value Function Loss: 7.47457

Mean KL Divergence: 0.04277
SB3 Clip Fraction: 0.21359
Policy Update Magnitude: 0.04640
Value Function Update Magnitude: 0.04299

Collected Steps per Second: 12,120.48695
Overall Steps per Second: 10,204.25066

Timestep Collection Time: 4.12690
Timestep Consumption Time: 0.77498
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.90188

Cumulative Model Updates: 37,432
Cumulative Timesteps: 624,450,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 624450752...
Checkpoint 624450752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,316.25861
Policy Entropy: 1.03980
Value Function Loss: 8.09674

Mean KL Divergence: 0.06907
SB3 Clip Fraction: 0.23803
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.04714

Collected Steps per Second: 12,386.29641
Overall Steps per Second: 10,314.60175

Timestep Collection Time: 4.03753
Timestep Consumption Time: 0.81094
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.84847

Cumulative Model Updates: 37,435
Cumulative Timesteps: 624,500,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,255.20236
Policy Entropy: 1.06262
Value Function Loss: 8.35510

Mean KL Divergence: 0.02725
SB3 Clip Fraction: 0.15700
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.04540

Collected Steps per Second: 11,552.94496
Overall Steps per Second: 9,654.20138

Timestep Collection Time: 4.32981
Timestep Consumption Time: 0.85157
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.18137

Cumulative Model Updates: 37,438
Cumulative Timesteps: 624,550,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 624550784...
Checkpoint 624550784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,436.59610
Policy Entropy: 1.05017
Value Function Loss: 8.05087

Mean KL Divergence: 0.03226
SB3 Clip Fraction: 0.17513
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.04488

Collected Steps per Second: 11,312.14657
Overall Steps per Second: 9,756.99563

Timestep Collection Time: 4.42073
Timestep Consumption Time: 0.70461
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 5.12535

Cumulative Model Updates: 37,441
Cumulative Timesteps: 624,600,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,717.53150
Policy Entropy: 1.05071
Value Function Loss: 8.06763

Mean KL Divergence: 0.03310
SB3 Clip Fraction: 0.18365
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.04532

Collected Steps per Second: 11,130.69322
Overall Steps per Second: 9,440.00349

Timestep Collection Time: 4.49316
Timestep Consumption Time: 0.80472
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.29788

Cumulative Model Updates: 37,444
Cumulative Timesteps: 624,650,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 624650804...
Checkpoint 624650804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,951.32936
Policy Entropy: 1.06116
Value Function Loss: 7.93528

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.04697

Collected Steps per Second: 11,074.64674
Overall Steps per Second: 9,446.45967

Timestep Collection Time: 4.51716
Timestep Consumption Time: 0.77858
PPO Batch Consumption Time: 0.03843
Total Iteration Time: 5.29574

Cumulative Model Updates: 37,447
Cumulative Timesteps: 624,700,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339,484.68388
Policy Entropy: 1.07013
Value Function Loss: 8.15441

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.04398

Collected Steps per Second: 11,491.37601
Overall Steps per Second: 9,744.15202

Timestep Collection Time: 4.35300
Timestep Consumption Time: 0.78054
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.13354

Cumulative Model Updates: 37,450
Cumulative Timesteps: 624,750,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 624750852...
Checkpoint 624750852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,870.44531
Policy Entropy: 1.04087
Value Function Loss: 7.91629

Mean KL Divergence: 0.03148
SB3 Clip Fraction: 0.16216
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.04102

Collected Steps per Second: 11,263.52538
Overall Steps per Second: 9,660.78865

Timestep Collection Time: 4.43911
Timestep Consumption Time: 0.73645
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.17556

Cumulative Model Updates: 37,453
Cumulative Timesteps: 624,800,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,523.37391
Policy Entropy: 1.06683
Value Function Loss: 8.06577

Mean KL Divergence: 0.02848
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.04112

Collected Steps per Second: 10,715.59416
Overall Steps per Second: 9,318.24842

Timestep Collection Time: 4.66722
Timestep Consumption Time: 0.69989
PPO Batch Consumption Time: 0.03831
Total Iteration Time: 5.36710

Cumulative Model Updates: 37,456
Cumulative Timesteps: 624,850,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 624850864...
Checkpoint 624850864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,622.23641
Policy Entropy: 1.06475
Value Function Loss: 7.84159

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.04144

Collected Steps per Second: 11,223.94613
Overall Steps per Second: 9,607.48269

Timestep Collection Time: 4.45708
Timestep Consumption Time: 0.74991
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 5.20698

Cumulative Model Updates: 37,459
Cumulative Timesteps: 624,900,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,762.15243
Policy Entropy: 1.05675
Value Function Loss: 7.40876

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.04009

Collected Steps per Second: 10,780.25106
Overall Steps per Second: 9,279.86975

Timestep Collection Time: 4.64034
Timestep Consumption Time: 0.75026
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.39059

Cumulative Model Updates: 37,462
Cumulative Timesteps: 624,950,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 624950914...
Checkpoint 624950914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,309.94666
Policy Entropy: 1.04472
Value Function Loss: 7.47973

Mean KL Divergence: 0.03305
SB3 Clip Fraction: 0.17832
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.04319

Collected Steps per Second: 11,271.14136
Overall Steps per Second: 9,511.28277

Timestep Collection Time: 4.43664
Timestep Consumption Time: 0.82091
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.25755

Cumulative Model Updates: 37,465
Cumulative Timesteps: 625,000,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,311.98948
Policy Entropy: 1.05284
Value Function Loss: 7.62340

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.04061

Collected Steps per Second: 11,215.40214
Overall Steps per Second: 9,508.43249

Timestep Collection Time: 4.45815
Timestep Consumption Time: 0.80034
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.25849

Cumulative Model Updates: 37,468
Cumulative Timesteps: 625,050,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 625050920...
Checkpoint 625050920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,297.86093
Policy Entropy: 1.06108
Value Function Loss: 8.04029

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.04483

Collected Steps per Second: 10,930.90551
Overall Steps per Second: 9,430.90228

Timestep Collection Time: 4.57510
Timestep Consumption Time: 0.72768
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.30278

Cumulative Model Updates: 37,471
Cumulative Timesteps: 625,100,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,058.43833
Policy Entropy: 1.05430
Value Function Loss: 8.09812

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.04655

Collected Steps per Second: 10,687.56718
Overall Steps per Second: 9,156.78655

Timestep Collection Time: 4.68077
Timestep Consumption Time: 0.78250
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.46327

Cumulative Model Updates: 37,474
Cumulative Timesteps: 625,150,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 625150956...
Checkpoint 625150956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,894.39807
Policy Entropy: 1.06118
Value Function Loss: 8.21625

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.04388

Collected Steps per Second: 11,104.04693
Overall Steps per Second: 9,497.05938

Timestep Collection Time: 4.50394
Timestep Consumption Time: 0.76211
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.26605

Cumulative Model Updates: 37,477
Cumulative Timesteps: 625,200,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,444.14039
Policy Entropy: 1.04570
Value Function Loss: 8.03382

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.06378
Value Function Update Magnitude: 0.06192

Collected Steps per Second: 11,059.56202
Overall Steps per Second: 9,586.01470

Timestep Collection Time: 4.52333
Timestep Consumption Time: 0.69532
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.21864

Cumulative Model Updates: 37,480
Cumulative Timesteps: 625,250,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 625250994...
Checkpoint 625250994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,679.04040
Policy Entropy: 1.02021
Value Function Loss: 8.00233

Mean KL Divergence: 0.04108
SB3 Clip Fraction: 0.18814
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.06350

Collected Steps per Second: 10,824.17927
Overall Steps per Second: 9,241.42639

Timestep Collection Time: 4.62040
Timestep Consumption Time: 0.79132
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.41172

Cumulative Model Updates: 37,483
Cumulative Timesteps: 625,301,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,238.20505
Policy Entropy: 1.03461
Value Function Loss: 7.76269

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.05132

Collected Steps per Second: 10,916.14034
Overall Steps per Second: 9,410.86952

Timestep Collection Time: 4.58276
Timestep Consumption Time: 0.73301
PPO Batch Consumption Time: 0.03384
Total Iteration Time: 5.31577

Cumulative Model Updates: 37,486
Cumulative Timesteps: 625,351,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 625351032...
Checkpoint 625351032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,980.90172
Policy Entropy: 1.03380
Value Function Loss: 7.72075

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.04797

Collected Steps per Second: 10,706.26899
Overall Steps per Second: 9,102.04873

Timestep Collection Time: 4.67278
Timestep Consumption Time: 0.82357
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 5.49634

Cumulative Model Updates: 37,489
Cumulative Timesteps: 625,401,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,907.54721
Policy Entropy: 1.03577
Value Function Loss: 7.76594

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.05059

Collected Steps per Second: 10,966.80218
Overall Steps per Second: 9,384.85999

Timestep Collection Time: 4.56140
Timestep Consumption Time: 0.76888
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.33029

Cumulative Model Updates: 37,492
Cumulative Timesteps: 625,451,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 625451084...
Checkpoint 625451084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,446.30869
Policy Entropy: 1.02544
Value Function Loss: 7.74811

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.04565

Collected Steps per Second: 11,169.22236
Overall Steps per Second: 9,672.10022

Timestep Collection Time: 4.47802
Timestep Consumption Time: 0.69314
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.17116

Cumulative Model Updates: 37,495
Cumulative Timesteps: 625,501,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,726.53522
Policy Entropy: 1.02146
Value Function Loss: 7.90148

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.04379

Collected Steps per Second: 11,385.88205
Overall Steps per Second: 9,647.17968

Timestep Collection Time: 4.39140
Timestep Consumption Time: 0.79146
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 5.18286

Cumulative Model Updates: 37,498
Cumulative Timesteps: 625,551,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 625551100...
Checkpoint 625551100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,568.97382
Policy Entropy: 1.03686
Value Function Loss: 8.18798

Mean KL Divergence: 0.02448
SB3 Clip Fraction: 0.14946
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.04539

Collected Steps per Second: 11,580.52763
Overall Steps per Second: 9,790.41067

Timestep Collection Time: 4.31915
Timestep Consumption Time: 0.78973
PPO Batch Consumption Time: 0.03320
Total Iteration Time: 5.10888

Cumulative Model Updates: 37,501
Cumulative Timesteps: 625,601,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,250.68575
Policy Entropy: 1.04246
Value Function Loss: 7.98791

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.04575

Collected Steps per Second: 11,563.91138
Overall Steps per Second: 9,846.63319

Timestep Collection Time: 4.32501
Timestep Consumption Time: 0.75429
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.07930

Cumulative Model Updates: 37,504
Cumulative Timesteps: 625,651,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 625651132...
Checkpoint 625651132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,082.76648
Policy Entropy: 1.03450
Value Function Loss: 7.70240

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.04245

Collected Steps per Second: 10,766.23757
Overall Steps per Second: 9,217.21755

Timestep Collection Time: 4.64489
Timestep Consumption Time: 0.78061
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.42550

Cumulative Model Updates: 37,507
Cumulative Timesteps: 625,701,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,519.03496
Policy Entropy: 1.01819
Value Function Loss: 7.22754

Mean KL Divergence: 0.03690
SB3 Clip Fraction: 0.18114
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.04020

Collected Steps per Second: 11,387.39875
Overall Steps per Second: 9,740.55935

Timestep Collection Time: 4.39187
Timestep Consumption Time: 0.74254
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.13441

Cumulative Model Updates: 37,510
Cumulative Timesteps: 625,751,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 625751152...
Checkpoint 625751152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,946.23062
Policy Entropy: 1.05721
Value Function Loss: 7.17985

Mean KL Divergence: 0.04597
SB3 Clip Fraction: 0.20221
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.04545

Collected Steps per Second: 11,233.68098
Overall Steps per Second: 9,583.25834

Timestep Collection Time: 4.45322
Timestep Consumption Time: 0.76693
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.22015

Cumulative Model Updates: 37,513
Cumulative Timesteps: 625,801,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,405.31792
Policy Entropy: 1.04359
Value Function Loss: 7.36628

Mean KL Divergence: 0.03929
SB3 Clip Fraction: 0.18879
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 10,919.65709
Overall Steps per Second: 9,278.78143

Timestep Collection Time: 4.58000
Timestep Consumption Time: 0.80993
PPO Batch Consumption Time: 0.04592
Total Iteration Time: 5.38993

Cumulative Model Updates: 37,516
Cumulative Timesteps: 625,851,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 625851190...
Checkpoint 625851190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,280.64730
Policy Entropy: 1.05455
Value Function Loss: 7.59075

Mean KL Divergence: 0.03672
SB3 Clip Fraction: 0.18168
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.05292

Collected Steps per Second: 11,298.94172
Overall Steps per Second: 9,553.89946

Timestep Collection Time: 4.42537
Timestep Consumption Time: 0.80830
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.23367

Cumulative Model Updates: 37,519
Cumulative Timesteps: 625,901,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,634.67852
Policy Entropy: 1.05832
Value Function Loss: 7.80885

Mean KL Divergence: 0.02810
SB3 Clip Fraction: 0.15195
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.06584

Collected Steps per Second: 11,300.29128
Overall Steps per Second: 9,556.59180

Timestep Collection Time: 4.42608
Timestep Consumption Time: 0.80758
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.23366

Cumulative Model Updates: 37,522
Cumulative Timesteps: 625,951,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 625951208...
Checkpoint 625951208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,653.21153
Policy Entropy: 1.07192
Value Function Loss: 7.91638

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.06885

Collected Steps per Second: 10,932.28394
Overall Steps per Second: 9,485.48443

Timestep Collection Time: 4.57562
Timestep Consumption Time: 0.69791
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.27353

Cumulative Model Updates: 37,525
Cumulative Timesteps: 626,001,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,047.53765
Policy Entropy: 1.07013
Value Function Loss: 7.80683

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.06590

Collected Steps per Second: 10,972.72455
Overall Steps per Second: 9,350.87355

Timestep Collection Time: 4.55803
Timestep Consumption Time: 0.79056
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 5.34859

Cumulative Model Updates: 37,528
Cumulative Timesteps: 626,051,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 626051244...
Checkpoint 626051244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,292.57082
Policy Entropy: 1.07108
Value Function Loss: 7.82405

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.07064

Collected Steps per Second: 11,106.05225
Overall Steps per Second: 9,536.28808

Timestep Collection Time: 4.50277
Timestep Consumption Time: 0.74120
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.24397

Cumulative Model Updates: 37,531
Cumulative Timesteps: 626,101,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,117.85577
Policy Entropy: 1.07501
Value Function Loss: 8.07711

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 11,336.77487
Overall Steps per Second: 9,674.03275

Timestep Collection Time: 4.41237
Timestep Consumption Time: 0.75838
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.17075

Cumulative Model Updates: 37,534
Cumulative Timesteps: 626,151,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 626151274...
Checkpoint 626151274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,226.36340
Policy Entropy: 1.06554
Value Function Loss: 8.57601

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.06407
Value Function Update Magnitude: 0.07711

Collected Steps per Second: 10,848.10994
Overall Steps per Second: 9,353.54380

Timestep Collection Time: 4.61131
Timestep Consumption Time: 0.73682
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.34813

Cumulative Model Updates: 37,537
Cumulative Timesteps: 626,201,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,466.57163
Policy Entropy: 1.07363
Value Function Loss: 8.66905

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.07890

Collected Steps per Second: 10,880.82204
Overall Steps per Second: 9,415.33149

Timestep Collection Time: 4.59634
Timestep Consumption Time: 0.71542
PPO Batch Consumption Time: 0.03952
Total Iteration Time: 5.31176

Cumulative Model Updates: 37,540
Cumulative Timesteps: 626,251,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 626251310...
Checkpoint 626251310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,172.31126
Policy Entropy: 1.06980
Value Function Loss: 8.39238

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.08859

Collected Steps per Second: 10,728.17544
Overall Steps per Second: 9,174.09853

Timestep Collection Time: 4.66174
Timestep Consumption Time: 0.78969
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 5.45143

Cumulative Model Updates: 37,543
Cumulative Timesteps: 626,301,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,899.64176
Policy Entropy: 1.08320
Value Function Loss: 8.10114

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.07622

Collected Steps per Second: 10,984.57309
Overall Steps per Second: 9,414.14512

Timestep Collection Time: 4.55220
Timestep Consumption Time: 0.75938
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.31158

Cumulative Model Updates: 37,546
Cumulative Timesteps: 626,351,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 626351326...
Checkpoint 626351326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,077.34571
Policy Entropy: 1.08095
Value Function Loss: 8.00353

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.08136

Collected Steps per Second: 11,155.73564
Overall Steps per Second: 9,523.49363

Timestep Collection Time: 4.48343
Timestep Consumption Time: 0.76842
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.25185

Cumulative Model Updates: 37,549
Cumulative Timesteps: 626,401,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,116.95667
Policy Entropy: 1.08624
Value Function Loss: 7.83385

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.08002

Collected Steps per Second: 10,760.14113
Overall Steps per Second: 9,185.96203

Timestep Collection Time: 4.64808
Timestep Consumption Time: 0.79653
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.44461

Cumulative Model Updates: 37,552
Cumulative Timesteps: 626,451,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 626451356...
Checkpoint 626451356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,827.71079
Policy Entropy: 1.08466
Value Function Loss: 7.67405

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.07266

Collected Steps per Second: 10,864.51504
Overall Steps per Second: 9,466.05242

Timestep Collection Time: 4.60379
Timestep Consumption Time: 0.68014
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.28393

Cumulative Model Updates: 37,555
Cumulative Timesteps: 626,501,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,298.64000
Policy Entropy: 1.08795
Value Function Loss: 7.74916

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.06463
Value Function Update Magnitude: 0.07775

Collected Steps per Second: 10,487.51381
Overall Steps per Second: 8,961.65752

Timestep Collection Time: 4.76910
Timestep Consumption Time: 0.81201
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.58111

Cumulative Model Updates: 37,558
Cumulative Timesteps: 626,551,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 626551390...
Checkpoint 626551390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,553.52501
Policy Entropy: 1.06415
Value Function Loss: 7.60826

Mean KL Divergence: 0.03710
SB3 Clip Fraction: 0.17961
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.07274

Collected Steps per Second: 11,786.63676
Overall Steps per Second: 9,987.86386

Timestep Collection Time: 4.24430
Timestep Consumption Time: 0.76438
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.00868

Cumulative Model Updates: 37,561
Cumulative Timesteps: 626,601,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,334.33234
Policy Entropy: 1.09187
Value Function Loss: 8.41444

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 12,064.57464
Overall Steps per Second: 10,316.00112

Timestep Collection Time: 4.14519
Timestep Consumption Time: 0.70261
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 4.84781

Cumulative Model Updates: 37,564
Cumulative Timesteps: 626,651,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 626651426...
Checkpoint 626651426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,451.95589
Policy Entropy: 1.08631
Value Function Loss: 8.47445

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.06066

Collected Steps per Second: 12,003.18604
Overall Steps per Second: 10,103.88857

Timestep Collection Time: 4.16706
Timestep Consumption Time: 0.78331
PPO Batch Consumption Time: 0.03761
Total Iteration Time: 4.95037

Cumulative Model Updates: 37,567
Cumulative Timesteps: 626,701,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,064.80335
Policy Entropy: 1.09002
Value Function Loss: 8.51267

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.05853

Collected Steps per Second: 11,708.72239
Overall Steps per Second: 9,896.05815

Timestep Collection Time: 4.27117
Timestep Consumption Time: 0.78235
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 5.05353

Cumulative Model Updates: 37,570
Cumulative Timesteps: 626,751,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 626751454...
Checkpoint 626751454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,243.34081
Policy Entropy: 1.07025
Value Function Loss: 8.21943

Mean KL Divergence: 0.03292
SB3 Clip Fraction: 0.18219
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.06752

Collected Steps per Second: 12,248.02213
Overall Steps per Second: 10,228.67629

Timestep Collection Time: 4.08376
Timestep Consumption Time: 0.80622
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 4.88998

Cumulative Model Updates: 37,573
Cumulative Timesteps: 626,801,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,641.82314
Policy Entropy: 1.08183
Value Function Loss: 8.01927

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.07645

Collected Steps per Second: 10,995.28471
Overall Steps per Second: 9,361.69289

Timestep Collection Time: 4.54959
Timestep Consumption Time: 0.79389
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.34348

Cumulative Model Updates: 37,576
Cumulative Timesteps: 626,851,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 626851496...
Checkpoint 626851496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,180.38103
Policy Entropy: 1.07560
Value Function Loss: 8.30950

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.06260
Value Function Update Magnitude: 0.08085

Collected Steps per Second: 10,913.39158
Overall Steps per Second: 9,489.63774

Timestep Collection Time: 4.58373
Timestep Consumption Time: 0.68771
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.27143

Cumulative Model Updates: 37,579
Cumulative Timesteps: 626,901,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,288.50838
Policy Entropy: 1.08067
Value Function Loss: 8.53524

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.08759

Collected Steps per Second: 11,326.73151
Overall Steps per Second: 9,631.59551

Timestep Collection Time: 4.41646
Timestep Consumption Time: 0.77728
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.19374

Cumulative Model Updates: 37,582
Cumulative Timesteps: 626,951,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 626951544...
Checkpoint 626951544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,174.15275
Policy Entropy: 1.08298
Value Function Loss: 8.47212

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.08174

Collected Steps per Second: 11,025.27082
Overall Steps per Second: 9,400.44962

Timestep Collection Time: 4.53594
Timestep Consumption Time: 0.78402
PPO Batch Consumption Time: 0.03922
Total Iteration Time: 5.31996

Cumulative Model Updates: 37,585
Cumulative Timesteps: 627,001,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,373.08972
Policy Entropy: 1.09868
Value Function Loss: 8.22802

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.07601

Collected Steps per Second: 11,102.63360
Overall Steps per Second: 9,658.26785

Timestep Collection Time: 4.50434
Timestep Consumption Time: 0.67361
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.17795

Cumulative Model Updates: 37,588
Cumulative Timesteps: 627,051,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 627051564...
Checkpoint 627051564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,699.36874
Policy Entropy: 1.09972
Value Function Loss: 8.11315

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.07543

Collected Steps per Second: 11,087.90542
Overall Steps per Second: 9,301.69676

Timestep Collection Time: 4.51230
Timestep Consumption Time: 0.86650
PPO Batch Consumption Time: 0.04406
Total Iteration Time: 5.37880

Cumulative Model Updates: 37,591
Cumulative Timesteps: 627,101,596

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,063.78228
Policy Entropy: 1.10140
Value Function Loss: 8.36608

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 10,654.65655
Overall Steps per Second: 9,175.54772

Timestep Collection Time: 4.69391
Timestep Consumption Time: 0.75666
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.45057

Cumulative Model Updates: 37,594
Cumulative Timesteps: 627,151,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 627151608...
Checkpoint 627151608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,146.05708
Policy Entropy: 1.09613
Value Function Loss: 8.40715

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.10125

Collected Steps per Second: 11,222.10445
Overall Steps per Second: 9,571.34313

Timestep Collection Time: 4.45727
Timestep Consumption Time: 0.76874
PPO Batch Consumption Time: 0.03821
Total Iteration Time: 5.22602

Cumulative Model Updates: 37,597
Cumulative Timesteps: 627,201,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,826.18911
Policy Entropy: 1.10545
Value Function Loss: 8.25830

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.09616

Collected Steps per Second: 10,874.58467
Overall Steps per Second: 9,285.45405

Timestep Collection Time: 4.59972
Timestep Consumption Time: 0.78720
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.38692

Cumulative Model Updates: 37,600
Cumulative Timesteps: 627,251,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 627251648...
Checkpoint 627251648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,827.56894
Policy Entropy: 1.11044
Value Function Loss: 8.44063

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.08956

Collected Steps per Second: 11,047.48217
Overall Steps per Second: 9,631.76737

Timestep Collection Time: 4.52719
Timestep Consumption Time: 0.66542
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.19261

Cumulative Model Updates: 37,603
Cumulative Timesteps: 627,301,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,674.30892
Policy Entropy: 1.09741
Value Function Loss: 8.11919

Mean KL Divergence: 0.02410
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.08156

Collected Steps per Second: 10,903.22884
Overall Steps per Second: 9,381.63084

Timestep Collection Time: 4.58671
Timestep Consumption Time: 0.74392
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.33063

Cumulative Model Updates: 37,606
Cumulative Timesteps: 627,351,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 627351672...
Checkpoint 627351672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,963.87587
Policy Entropy: 1.08921
Value Function Loss: 7.99626

Mean KL Divergence: 0.03012
SB3 Clip Fraction: 0.15860
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.07490

Collected Steps per Second: 10,642.83928
Overall Steps per Second: 9,168.02669

Timestep Collection Time: 4.70025
Timestep Consumption Time: 0.75610
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.45635

Cumulative Model Updates: 37,609
Cumulative Timesteps: 627,401,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,876.75527
Policy Entropy: 1.10228
Value Function Loss: 8.07623

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.06442

Collected Steps per Second: 10,707.04004
Overall Steps per Second: 9,304.67147

Timestep Collection Time: 4.67244
Timestep Consumption Time: 0.70421
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.37665

Cumulative Model Updates: 37,612
Cumulative Timesteps: 627,451,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 627451724...
Checkpoint 627451724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,985.42400
Policy Entropy: 1.11254
Value Function Loss: 8.06527

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.08463

Collected Steps per Second: 10,908.48320
Overall Steps per Second: 9,286.72472

Timestep Collection Time: 4.58414
Timestep Consumption Time: 0.80054
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.38468

Cumulative Model Updates: 37,615
Cumulative Timesteps: 627,501,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,475.63228
Policy Entropy: 1.09998
Value Function Loss: 8.21005

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.09596

Collected Steps per Second: 10,689.99782
Overall Steps per Second: 9,219.82448

Timestep Collection Time: 4.67783
Timestep Consumption Time: 0.74592
PPO Batch Consumption Time: 0.03769
Total Iteration Time: 5.42375

Cumulative Model Updates: 37,618
Cumulative Timesteps: 627,551,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 627551736...
Checkpoint 627551736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,211.69691
Policy Entropy: 1.09079
Value Function Loss: 7.93625

Mean KL Divergence: 0.03020
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.10754

Collected Steps per Second: 11,059.87497
Overall Steps per Second: 9,361.74477

Timestep Collection Time: 4.52103
Timestep Consumption Time: 0.82007
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.34110

Cumulative Model Updates: 37,621
Cumulative Timesteps: 627,601,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,975.14057
Policy Entropy: 1.09507
Value Function Loss: 8.41330

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.10783

Collected Steps per Second: 10,868.52399
Overall Steps per Second: 9,281.90569

Timestep Collection Time: 4.60265
Timestep Consumption Time: 0.78676
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.38941

Cumulative Model Updates: 37,624
Cumulative Timesteps: 627,651,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 627651762...
Checkpoint 627651762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,822.12490
Policy Entropy: 1.10796
Value Function Loss: 8.44964

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.09673

Collected Steps per Second: 10,370.56840
Overall Steps per Second: 9,087.23134

Timestep Collection Time: 4.82384
Timestep Consumption Time: 0.68124
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.50509

Cumulative Model Updates: 37,627
Cumulative Timesteps: 627,701,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,482.94512
Policy Entropy: 1.05967
Value Function Loss: 8.20224

Mean KL Divergence: 0.08648
SB3 Clip Fraction: 0.21344
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.09428

Collected Steps per Second: 11,260.32863
Overall Steps per Second: 9,592.80510

Timestep Collection Time: 4.44108
Timestep Consumption Time: 0.77200
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 5.21307

Cumulative Model Updates: 37,630
Cumulative Timesteps: 627,751,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 627751796...
Checkpoint 627751796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372,687.03854
Policy Entropy: 1.09781
Value Function Loss: 8.08779

Mean KL Divergence: 0.03955
SB3 Clip Fraction: 0.17623
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.09601

Collected Steps per Second: 11,204.76929
Overall Steps per Second: 9,561.19507

Timestep Collection Time: 4.46239
Timestep Consumption Time: 0.76709
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.22947

Cumulative Model Updates: 37,633
Cumulative Timesteps: 627,801,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,460.34128
Policy Entropy: 1.06451
Value Function Loss: 7.94691

Mean KL Divergence: 0.07531
SB3 Clip Fraction: 0.22594
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.08516

Collected Steps per Second: 11,389.12569
Overall Steps per Second: 9,643.06194

Timestep Collection Time: 4.39244
Timestep Consumption Time: 0.79534
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.18777

Cumulative Model Updates: 37,636
Cumulative Timesteps: 627,851,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 627851822...
Checkpoint 627851822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,236.49094
Policy Entropy: 1.09743
Value Function Loss: 8.76232

Mean KL Divergence: 0.03521
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 11,418.87344
Overall Steps per Second: 9,725.10092

Timestep Collection Time: 4.38029
Timestep Consumption Time: 0.76289
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.14319

Cumulative Model Updates: 37,639
Cumulative Timesteps: 627,901,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,447.58296
Policy Entropy: 1.08391
Value Function Loss: 8.71203

Mean KL Divergence: 0.02856
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.08258

Collected Steps per Second: 11,315.70777
Overall Steps per Second: 9,690.29489

Timestep Collection Time: 4.42076
Timestep Consumption Time: 0.74152
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.16228

Cumulative Model Updates: 37,642
Cumulative Timesteps: 627,951,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 627951864...
Checkpoint 627951864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,964.62981
Policy Entropy: 1.06712
Value Function Loss: 8.83574

Mean KL Divergence: 0.03832
SB3 Clip Fraction: 0.17084
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.09650

Collected Steps per Second: 10,962.15532
Overall Steps per Second: 9,376.11317

Timestep Collection Time: 4.56261
Timestep Consumption Time: 0.77180
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.33441

Cumulative Model Updates: 37,645
Cumulative Timesteps: 628,001,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,480.97991
Policy Entropy: 1.08262
Value Function Loss: 8.21570

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 11,195.49397
Overall Steps per Second: 9,571.84264

Timestep Collection Time: 4.46680
Timestep Consumption Time: 0.75769
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 5.22449

Cumulative Model Updates: 37,648
Cumulative Timesteps: 628,051,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 628051888...
Checkpoint 628051888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,825.28921
Policy Entropy: 1.08872
Value Function Loss: 7.92493

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.11603

Collected Steps per Second: 11,282.92503
Overall Steps per Second: 9,500.16776

Timestep Collection Time: 4.43183
Timestep Consumption Time: 0.83166
PPO Batch Consumption Time: 0.03940
Total Iteration Time: 5.26349

Cumulative Model Updates: 37,651
Cumulative Timesteps: 628,101,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,397.27356
Policy Entropy: 1.06736
Value Function Loss: 8.03787

Mean KL Divergence: 0.03170
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.12263

Collected Steps per Second: 11,137.79211
Overall Steps per Second: 9,406.41034

Timestep Collection Time: 4.49084
Timestep Consumption Time: 0.82660
PPO Batch Consumption Time: 0.03824
Total Iteration Time: 5.31744

Cumulative Model Updates: 37,654
Cumulative Timesteps: 628,151,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 628151910...
Checkpoint 628151910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,796.06072
Policy Entropy: 1.07361
Value Function Loss: 8.30105

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.11835

Collected Steps per Second: 11,114.91950
Overall Steps per Second: 9,627.17720

Timestep Collection Time: 4.49972
Timestep Consumption Time: 0.69537
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 5.19508

Cumulative Model Updates: 37,657
Cumulative Timesteps: 628,201,924

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,681.05033
Policy Entropy: 1.06620
Value Function Loss: 8.30640

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.06094
Value Function Update Magnitude: 0.10158

Collected Steps per Second: 10,704.35082
Overall Steps per Second: 9,138.12777

Timestep Collection Time: 4.67156
Timestep Consumption Time: 0.80068
PPO Batch Consumption Time: 0.03933
Total Iteration Time: 5.47224

Cumulative Model Updates: 37,660
Cumulative Timesteps: 628,251,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 628251930...
Checkpoint 628251930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,916.89571
Policy Entropy: 1.08041
Value Function Loss: 7.99064

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.08802

Collected Steps per Second: 11,035.89294
Overall Steps per Second: 9,429.47366

Timestep Collection Time: 4.53140
Timestep Consumption Time: 0.77198
PPO Batch Consumption Time: 0.04311
Total Iteration Time: 5.30337

Cumulative Model Updates: 37,663
Cumulative Timesteps: 628,301,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,180.14231
Policy Entropy: 1.06613
Value Function Loss: 7.43720

Mean KL Divergence: 0.03145
SB3 Clip Fraction: 0.16839
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.08743

Collected Steps per Second: 11,186.70636
Overall Steps per Second: 9,439.90347

Timestep Collection Time: 4.46977
Timestep Consumption Time: 0.82711
PPO Batch Consumption Time: 0.03895
Total Iteration Time: 5.29688

Cumulative Model Updates: 37,666
Cumulative Timesteps: 628,351,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 628351940...
Checkpoint 628351940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481,846.73608
Policy Entropy: 1.08767
Value Function Loss: 7.40078

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.07927

Collected Steps per Second: 11,116.61959
Overall Steps per Second: 9,481.39639

Timestep Collection Time: 4.49993
Timestep Consumption Time: 0.77609
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.27602

Cumulative Model Updates: 37,669
Cumulative Timesteps: 628,401,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,437.88443
Policy Entropy: 1.08555
Value Function Loss: 7.49929

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.07352

Collected Steps per Second: 11,222.75181
Overall Steps per Second: 9,597.30866

Timestep Collection Time: 4.45720
Timestep Consumption Time: 0.75489
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.21209

Cumulative Model Updates: 37,672
Cumulative Timesteps: 628,451,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 628451986...
Checkpoint 628451986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,851.34426
Policy Entropy: 1.07410
Value Function Loss: 7.26783

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.06813

Collected Steps per Second: 11,016.39180
Overall Steps per Second: 9,443.58311

Timestep Collection Time: 4.53887
Timestep Consumption Time: 0.75594
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.29481

Cumulative Model Updates: 37,675
Cumulative Timesteps: 628,501,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,286.81172
Policy Entropy: 1.06214
Value Function Loss: 7.68584

Mean KL Divergence: 0.04189
SB3 Clip Fraction: 0.18351
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.06541

Collected Steps per Second: 10,506.60707
Overall Steps per Second: 9,145.51929

Timestep Collection Time: 4.75910
Timestep Consumption Time: 0.70828
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 5.46738

Cumulative Model Updates: 37,678
Cumulative Timesteps: 628,551,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 628551990...
Checkpoint 628551990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,365.98020
Policy Entropy: 1.08852
Value Function Loss: 7.60205

Mean KL Divergence: 0.03096
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.09112

Collected Steps per Second: 11,042.59967
Overall Steps per Second: 9,385.94868

Timestep Collection Time: 4.52810
Timestep Consumption Time: 0.79922
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.32733

Cumulative Model Updates: 37,681
Cumulative Timesteps: 628,601,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,606.91611
Policy Entropy: 1.07273
Value Function Loss: 8.11334

Mean KL Divergence: 0.04641
SB3 Clip Fraction: 0.18250
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.10410

Collected Steps per Second: 10,814.97362
Overall Steps per Second: 9,257.13149

Timestep Collection Time: 4.62396
Timestep Consumption Time: 0.77815
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.40211

Cumulative Model Updates: 37,684
Cumulative Timesteps: 628,652,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 628652000...
Checkpoint 628652000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,241.91283
Policy Entropy: 1.09214
Value Function Loss: 8.18900

Mean KL Divergence: 0.03180
SB3 Clip Fraction: 0.17247
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.10505

Collected Steps per Second: 11,033.84449
Overall Steps per Second: 9,369.02117

Timestep Collection Time: 4.53206
Timestep Consumption Time: 0.80532
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.33738

Cumulative Model Updates: 37,687
Cumulative Timesteps: 628,702,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,917.86034
Policy Entropy: 1.09177
Value Function Loss: 8.64113

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.08838

Collected Steps per Second: 10,868.51827
Overall Steps per Second: 9,203.31819

Timestep Collection Time: 4.60136
Timestep Consumption Time: 0.83255
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.43391

Cumulative Model Updates: 37,690
Cumulative Timesteps: 628,752,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 628752016...
Checkpoint 628752016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,751.24223
Policy Entropy: 1.08776
Value Function Loss: 8.61987

Mean KL Divergence: 0.02390
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.07981

Collected Steps per Second: 10,640.20457
Overall Steps per Second: 9,160.14565

Timestep Collection Time: 4.70123
Timestep Consumption Time: 0.75960
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 5.46083

Cumulative Model Updates: 37,693
Cumulative Timesteps: 628,802,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356,081.01183
Policy Entropy: 1.09386
Value Function Loss: 8.61910

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.09897

Collected Steps per Second: 11,579.70231
Overall Steps per Second: 9,850.30475

Timestep Collection Time: 4.32015
Timestep Consumption Time: 0.75848
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.07862

Cumulative Model Updates: 37,696
Cumulative Timesteps: 628,852,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 628852064...
Checkpoint 628852064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,464.49369
Policy Entropy: 1.09011
Value Function Loss: 8.42981

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.09104

Collected Steps per Second: 11,949.06814
Overall Steps per Second: 10,150.04468

Timestep Collection Time: 4.18677
Timestep Consumption Time: 0.74208
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.92885

Cumulative Model Updates: 37,699
Cumulative Timesteps: 628,902,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,127.19448
Policy Entropy: 1.09141
Value Function Loss: 8.70460

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.06640
Value Function Update Magnitude: 0.07862

Collected Steps per Second: 12,375.73142
Overall Steps per Second: 10,314.91721

Timestep Collection Time: 4.04146
Timestep Consumption Time: 0.80744
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 4.84890

Cumulative Model Updates: 37,702
Cumulative Timesteps: 628,952,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 628952108...
Checkpoint 628952108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,921.28162
Policy Entropy: 1.08474
Value Function Loss: 8.32614

Mean KL Divergence: 0.02604
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.06463
Value Function Update Magnitude: 0.08010

Collected Steps per Second: 12,042.92535
Overall Steps per Second: 9,945.91024

Timestep Collection Time: 4.15397
Timestep Consumption Time: 0.87583
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.02981

Cumulative Model Updates: 37,705
Cumulative Timesteps: 629,002,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,435.53478
Policy Entropy: 1.10512
Value Function Loss: 8.64989

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.07938

Collected Steps per Second: 12,244.76013
Overall Steps per Second: 10,540.32497

Timestep Collection Time: 4.08387
Timestep Consumption Time: 0.66039
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.74426

Cumulative Model Updates: 37,708
Cumulative Timesteps: 629,052,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 629052140...
Checkpoint 629052140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,644.22787
Policy Entropy: 1.10518
Value Function Loss: 8.34440

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.10241

Collected Steps per Second: 11,307.83717
Overall Steps per Second: 9,567.86520

Timestep Collection Time: 4.42207
Timestep Consumption Time: 0.80418
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.22624

Cumulative Model Updates: 37,711
Cumulative Timesteps: 629,102,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,503.66751
Policy Entropy: 1.10156
Value Function Loss: 8.22460

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.11594

Collected Steps per Second: 11,659.99305
Overall Steps per Second: 9,926.68750

Timestep Collection Time: 4.28868
Timestep Consumption Time: 0.74885
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 5.03753

Cumulative Model Updates: 37,714
Cumulative Timesteps: 629,152,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 629152150...
Checkpoint 629152150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,424.95330
Policy Entropy: 1.08656
Value Function Loss: 7.71066

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.11125

Collected Steps per Second: 11,020.26791
Overall Steps per Second: 9,378.21842

Timestep Collection Time: 4.53909
Timestep Consumption Time: 0.79476
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.33385

Cumulative Model Updates: 37,717
Cumulative Timesteps: 629,202,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397,760.12201
Policy Entropy: 1.10845
Value Function Loss: 7.71872

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.09520

Collected Steps per Second: 10,189.64210
Overall Steps per Second: 8,709.50823

Timestep Collection Time: 4.90950
Timestep Consumption Time: 0.83434
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.74384

Cumulative Model Updates: 37,720
Cumulative Timesteps: 629,252,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 629252198...
Checkpoint 629252198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,991.13361
Policy Entropy: 1.09758
Value Function Loss: 7.96029

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.08137

Collected Steps per Second: 11,411.48816
Overall Steps per Second: 9,369.02747

Timestep Collection Time: 4.38330
Timestep Consumption Time: 0.95557
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.33887

Cumulative Model Updates: 37,723
Cumulative Timesteps: 629,302,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,021.10056
Policy Entropy: 1.08387
Value Function Loss: 7.85190

Mean KL Divergence: 0.02690
SB3 Clip Fraction: 0.15194
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.06526

Collected Steps per Second: 11,403.66864
Overall Steps per Second: 9,697.87743

Timestep Collection Time: 4.38473
Timestep Consumption Time: 0.77124
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.15597

Cumulative Model Updates: 37,726
Cumulative Timesteps: 629,352,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 629352220...
Checkpoint 629352220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,496.84416
Policy Entropy: 1.08243
Value Function Loss: 7.61934

Mean KL Divergence: 0.02684
SB3 Clip Fraction: 0.15976
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.07890

Collected Steps per Second: 10,273.56530
Overall Steps per Second: 9,000.51650

Timestep Collection Time: 4.86997
Timestep Consumption Time: 0.68882
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.55879

Cumulative Model Updates: 37,729
Cumulative Timesteps: 629,402,252

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,651.37421
Policy Entropy: 1.09390
Value Function Loss: 7.65211

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.08914

Collected Steps per Second: 11,054.06558
Overall Steps per Second: 9,364.62544

Timestep Collection Time: 4.52467
Timestep Consumption Time: 0.81628
PPO Batch Consumption Time: 0.04587
Total Iteration Time: 5.34095

Cumulative Model Updates: 37,732
Cumulative Timesteps: 629,452,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 629452268...
Checkpoint 629452268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,242.76172
Policy Entropy: 1.10660
Value Function Loss: 8.14817

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.07989

Collected Steps per Second: 10,917.04463
Overall Steps per Second: 9,379.94730

Timestep Collection Time: 4.58128
Timestep Consumption Time: 0.75074
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.33201

Cumulative Model Updates: 37,735
Cumulative Timesteps: 629,502,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,349.39615
Policy Entropy: 1.09668
Value Function Loss: 8.32957

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.07370

Collected Steps per Second: 11,385.79393
Overall Steps per Second: 9,742.22802

Timestep Collection Time: 4.39179
Timestep Consumption Time: 0.74092
PPO Batch Consumption Time: 0.03375
Total Iteration Time: 5.13271

Cumulative Model Updates: 37,738
Cumulative Timesteps: 629,552,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 629552286...
Checkpoint 629552286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,187.95608
Policy Entropy: 1.09296
Value Function Loss: 8.50465

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 10,861.11935
Overall Steps per Second: 9,245.14088

Timestep Collection Time: 4.60413
Timestep Consumption Time: 0.80477
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 5.40890

Cumulative Model Updates: 37,741
Cumulative Timesteps: 629,602,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,381.07313
Policy Entropy: 1.08579
Value Function Loss: 7.71764

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.07679

Collected Steps per Second: 10,914.25156
Overall Steps per Second: 9,389.49930

Timestep Collection Time: 4.58208
Timestep Consumption Time: 0.74408
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 5.32616

Cumulative Model Updates: 37,744
Cumulative Timesteps: 629,652,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 629652302...
Checkpoint 629652302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,325.47425
Policy Entropy: 1.10264
Value Function Loss: 7.68860

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.11168
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.09254

Collected Steps per Second: 10,821.67039
Overall Steps per Second: 9,302.56176

Timestep Collection Time: 4.62165
Timestep Consumption Time: 0.75472
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 5.37637

Cumulative Model Updates: 37,747
Cumulative Timesteps: 629,702,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,721.25593
Policy Entropy: 1.09716
Value Function Loss: 7.66118

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.07668
Value Function Update Magnitude: 0.09139

Collected Steps per Second: 11,044.62989
Overall Steps per Second: 9,394.86620

Timestep Collection Time: 4.52781
Timestep Consumption Time: 0.79510
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 5.32291

Cumulative Model Updates: 37,750
Cumulative Timesteps: 629,752,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 629752324...
Checkpoint 629752324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,094.70765
Policy Entropy: 1.09027
Value Function Loss: 8.26188

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.07357
Value Function Update Magnitude: 0.10479

Collected Steps per Second: 10,824.85288
Overall Steps per Second: 9,363.79845

Timestep Collection Time: 4.62048
Timestep Consumption Time: 0.72094
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.34142

Cumulative Model Updates: 37,753
Cumulative Timesteps: 629,802,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,960.61855
Policy Entropy: 1.07422
Value Function Loss: 8.16540

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.08521
Value Function Update Magnitude: 0.11054

Collected Steps per Second: 10,909.03025
Overall Steps per Second: 9,290.75621

Timestep Collection Time: 4.58593
Timestep Consumption Time: 0.79878
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 5.38471

Cumulative Model Updates: 37,756
Cumulative Timesteps: 629,852,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 629852368...
Checkpoint 629852368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,705.55479
Policy Entropy: 1.07578
Value Function Loss: 8.04294

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.07349
Value Function Update Magnitude: 0.08960

Collected Steps per Second: 10,952.62747
Overall Steps per Second: 9,449.61017

Timestep Collection Time: 4.56749
Timestep Consumption Time: 0.72649
PPO Batch Consumption Time: 0.03781
Total Iteration Time: 5.29397

Cumulative Model Updates: 37,759
Cumulative Timesteps: 629,902,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,612.38441
Policy Entropy: 1.09845
Value Function Loss: 7.82090

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.07631

Collected Steps per Second: 10,665.28678
Overall Steps per Second: 9,144.12728

Timestep Collection Time: 4.68829
Timestep Consumption Time: 0.77992
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.46821

Cumulative Model Updates: 37,762
Cumulative Timesteps: 629,952,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 629952396...
Checkpoint 629952396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,749.39511
Policy Entropy: 1.09790
Value Function Loss: 7.98549

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.07417

Collected Steps per Second: 11,304.53523
Overall Steps per Second: 9,690.17751

Timestep Collection Time: 4.42300
Timestep Consumption Time: 0.73686
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.15986

Cumulative Model Updates: 37,765
Cumulative Timesteps: 630,002,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,363.17901
Policy Entropy: 1.09270
Value Function Loss: 7.95484

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.07117

Collected Steps per Second: 11,410.36152
Overall Steps per Second: 9,668.32803

Timestep Collection Time: 4.38373
Timestep Consumption Time: 0.78986
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.17359

Cumulative Model Updates: 37,768
Cumulative Timesteps: 630,052,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 630052416...
Checkpoint 630052416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,114.31001
Policy Entropy: 1.07371
Value Function Loss: 8.21796

Mean KL Divergence: 0.04678
SB3 Clip Fraction: 0.18205
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.07479

Collected Steps per Second: 11,237.95152
Overall Steps per Second: 9,541.24898

Timestep Collection Time: 4.45170
Timestep Consumption Time: 0.79164
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.24334

Cumulative Model Updates: 37,771
Cumulative Timesteps: 630,102,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,527.10524
Policy Entropy: 1.10362
Value Function Loss: 8.28118

Mean KL Divergence: 0.03320
SB3 Clip Fraction: 0.18299
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.06978

Collected Steps per Second: 11,425.89948
Overall Steps per Second: 9,881.78492

Timestep Collection Time: 4.37690
Timestep Consumption Time: 0.68393
PPO Batch Consumption Time: 0.03822
Total Iteration Time: 5.06083

Cumulative Model Updates: 37,774
Cumulative Timesteps: 630,152,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 630152454...
Checkpoint 630152454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,694.78042
Policy Entropy: 1.06920
Value Function Loss: 8.30511

Mean KL Divergence: 0.05346
SB3 Clip Fraction: 0.20905
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.08020

Collected Steps per Second: 11,762.61914
Overall Steps per Second: 9,973.99465

Timestep Collection Time: 4.25092
Timestep Consumption Time: 0.76231
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.01324

Cumulative Model Updates: 37,777
Cumulative Timesteps: 630,202,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,106.79153
Policy Entropy: 1.08409
Value Function Loss: 8.44638

Mean KL Divergence: 0.02448
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.04323
Value Function Update Magnitude: 0.09810

Collected Steps per Second: 10,907.08513
Overall Steps per Second: 9,518.86594

Timestep Collection Time: 4.58693
Timestep Consumption Time: 0.66895
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.25588

Cumulative Model Updates: 37,780
Cumulative Timesteps: 630,252,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 630252486...
Checkpoint 630252486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,858.15574
Policy Entropy: 1.07302
Value Function Loss: 8.28909

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.09194

Collected Steps per Second: 11,119.99050
Overall Steps per Second: 9,489.81981

Timestep Collection Time: 4.49731
Timestep Consumption Time: 0.77255
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.26986

Cumulative Model Updates: 37,783
Cumulative Timesteps: 630,302,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,741.85786
Policy Entropy: 1.07448
Value Function Loss: 8.22233

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.06258
Value Function Update Magnitude: 0.09976

Collected Steps per Second: 11,105.51117
Overall Steps per Second: 9,607.12684

Timestep Collection Time: 4.50263
Timestep Consumption Time: 0.70226
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.20489

Cumulative Model Updates: 37,786
Cumulative Timesteps: 630,352,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 630352500...
Checkpoint 630352500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,374.91595
Policy Entropy: 1.08442
Value Function Loss: 7.88998

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.11674

Collected Steps per Second: 10,991.06901
Overall Steps per Second: 9,370.45416

Timestep Collection Time: 4.54933
Timestep Consumption Time: 0.78680
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 5.33613

Cumulative Model Updates: 37,789
Cumulative Timesteps: 630,402,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,465.81267
Policy Entropy: 1.09783
Value Function Loss: 7.62382

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.10875

Collected Steps per Second: 11,153.80913
Overall Steps per Second: 9,503.02150

Timestep Collection Time: 4.48439
Timestep Consumption Time: 0.77899
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.26338

Cumulative Model Updates: 37,792
Cumulative Timesteps: 630,452,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 630452520...
Checkpoint 630452520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,481.52678
Policy Entropy: 1.10202
Value Function Loss: 7.50815

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.09270

Collected Steps per Second: 11,169.02515
Overall Steps per Second: 9,641.84632

Timestep Collection Time: 4.47738
Timestep Consumption Time: 0.70918
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 5.18656

Cumulative Model Updates: 37,795
Cumulative Timesteps: 630,502,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,202.40342
Policy Entropy: 1.09299
Value Function Loss: 7.59825

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.08674

Collected Steps per Second: 10,722.71153
Overall Steps per Second: 9,185.78044

Timestep Collection Time: 4.66542
Timestep Consumption Time: 0.78060
PPO Batch Consumption Time: 0.03789
Total Iteration Time: 5.44603

Cumulative Model Updates: 37,798
Cumulative Timesteps: 630,552,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 630552554...
Checkpoint 630552554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,770.86161
Policy Entropy: 1.09036
Value Function Loss: 8.09348

Mean KL Divergence: 0.02711
SB3 Clip Fraction: 0.16361
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.08133

Collected Steps per Second: 10,900.80974
Overall Steps per Second: 9,408.96372

Timestep Collection Time: 4.58828
Timestep Consumption Time: 0.72750
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.31578

Cumulative Model Updates: 37,801
Cumulative Timesteps: 630,602,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,126.69699
Policy Entropy: 1.10347
Value Function Loss: 8.47227

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.08363

Collected Steps per Second: 10,928.31591
Overall Steps per Second: 9,317.40960

Timestep Collection Time: 4.57747
Timestep Consumption Time: 0.79141
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.36887

Cumulative Model Updates: 37,804
Cumulative Timesteps: 630,652,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 630652594...
Checkpoint 630652594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,698.59379
Policy Entropy: 1.11596
Value Function Loss: 8.48809

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 10,790.49305
Overall Steps per Second: 9,275.00868

Timestep Collection Time: 4.63464
Timestep Consumption Time: 0.75727
PPO Batch Consumption Time: 0.03821
Total Iteration Time: 5.39191

Cumulative Model Updates: 37,807
Cumulative Timesteps: 630,702,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,142.62189
Policy Entropy: 1.09327
Value Function Loss: 8.22073

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.07498

Collected Steps per Second: 11,124.17770
Overall Steps per Second: 9,701.66159

Timestep Collection Time: 4.49705
Timestep Consumption Time: 0.65938
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.15644

Cumulative Model Updates: 37,810
Cumulative Timesteps: 630,752,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 630752630...
Checkpoint 630752630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,571.45521
Policy Entropy: 1.07205
Value Function Loss: 8.10676

Mean KL Divergence: 0.03641
SB3 Clip Fraction: 0.16592
Policy Update Magnitude: 0.04204
Value Function Update Magnitude: 0.07005

Collected Steps per Second: 10,661.39239
Overall Steps per Second: 9,162.24151

Timestep Collection Time: 4.69094
Timestep Consumption Time: 0.76755
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 5.45849

Cumulative Model Updates: 37,813
Cumulative Timesteps: 630,802,642

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,786.64195
Policy Entropy: 1.08761
Value Function Loss: 7.90828

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.07341

Collected Steps per Second: 10,864.71251
Overall Steps per Second: 9,337.86351

Timestep Collection Time: 4.60500
Timestep Consumption Time: 0.75297
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 5.35797

Cumulative Model Updates: 37,816
Cumulative Timesteps: 630,852,674

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 630852674...
Checkpoint 630852674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,345.17746
Policy Entropy: 1.07594
Value Function Loss: 7.96082

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.07902

Collected Steps per Second: 11,015.18719
Overall Steps per Second: 9,363.16297

Timestep Collection Time: 4.53919
Timestep Consumption Time: 0.80089
PPO Batch Consumption Time: 0.03922
Total Iteration Time: 5.34008

Cumulative Model Updates: 37,819
Cumulative Timesteps: 630,902,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,164.06239
Policy Entropy: 1.06887
Value Function Loss: 7.88862

Mean KL Divergence: 0.03238
SB3 Clip Fraction: 0.17919
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.08724

Collected Steps per Second: 10,874.58253
Overall Steps per Second: 9,317.43865

Timestep Collection Time: 4.59843
Timestep Consumption Time: 0.76850
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.36693

Cumulative Model Updates: 37,822
Cumulative Timesteps: 630,952,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 630952680...
Checkpoint 630952680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,135.98093
Policy Entropy: 1.08024
Value Function Loss: 7.66756

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 10,819.47962
Overall Steps per Second: 9,404.47868

Timestep Collection Time: 4.62185
Timestep Consumption Time: 0.69540
PPO Batch Consumption Time: 0.03781
Total Iteration Time: 5.31725

Cumulative Model Updates: 37,825
Cumulative Timesteps: 631,002,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,337.66703
Policy Entropy: 1.09657
Value Function Loss: 7.29544

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.15103
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.09103

Collected Steps per Second: 10,854.51134
Overall Steps per Second: 9,294.10800

Timestep Collection Time: 4.60859
Timestep Consumption Time: 0.77374
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.38233

Cumulative Model Updates: 37,828
Cumulative Timesteps: 631,052,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 631052710...
Checkpoint 631052710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,138.68329
Policy Entropy: 1.06948
Value Function Loss: 7.09355

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.08753

Collected Steps per Second: 10,524.75404
Overall Steps per Second: 9,157.83754

Timestep Collection Time: 4.75108
Timestep Consumption Time: 0.70916
PPO Batch Consumption Time: 0.03852
Total Iteration Time: 5.46024

Cumulative Model Updates: 37,831
Cumulative Timesteps: 631,102,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,757.98485
Policy Entropy: 1.09188
Value Function Loss: 7.53917

Mean KL Divergence: 0.03346
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.07747

Collected Steps per Second: 12,017.15200
Overall Steps per Second: 10,121.15910

Timestep Collection Time: 4.16238
Timestep Consumption Time: 0.77974
PPO Batch Consumption Time: 0.03390
Total Iteration Time: 4.94212

Cumulative Model Updates: 37,834
Cumulative Timesteps: 631,152,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 631152734...
Checkpoint 631152734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,913.82787
Policy Entropy: 1.09280
Value Function Loss: 7.49918

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.08476

Collected Steps per Second: 12,142.36121
Overall Steps per Second: 10,076.78892

Timestep Collection Time: 4.11864
Timestep Consumption Time: 0.84425
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.96289

Cumulative Model Updates: 37,837
Cumulative Timesteps: 631,202,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,833.99527
Policy Entropy: 1.08181
Value Function Loss: 7.58760

Mean KL Divergence: 0.02981
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.09031

Collected Steps per Second: 11,981.49545
Overall Steps per Second: 10,232.39988

Timestep Collection Time: 4.17394
Timestep Consumption Time: 0.71348
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 4.88742

Cumulative Model Updates: 37,840
Cumulative Timesteps: 631,252,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 631252754...
Checkpoint 631252754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,379.94767
Policy Entropy: 1.07936
Value Function Loss: 7.58724

Mean KL Divergence: 0.03009
SB3 Clip Fraction: 0.16771
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.08063

Collected Steps per Second: 11,931.12613
Overall Steps per Second: 9,909.47109

Timestep Collection Time: 4.19273
Timestep Consumption Time: 0.85537
PPO Batch Consumption Time: 0.03975
Total Iteration Time: 5.04810

Cumulative Model Updates: 37,843
Cumulative Timesteps: 631,302,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,006.82366
Policy Entropy: 1.08654
Value Function Loss: 8.21002

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 11,880.58228
Overall Steps per Second: 10,046.90814

Timestep Collection Time: 4.20922
Timestep Consumption Time: 0.76823
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 4.97745

Cumulative Model Updates: 37,846
Cumulative Timesteps: 631,352,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 631352786...
Checkpoint 631352786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,117.12341
Policy Entropy: 1.09417
Value Function Loss: 8.55623

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.07470

Collected Steps per Second: 11,501.51139
Overall Steps per Second: 9,753.86480

Timestep Collection Time: 4.34812
Timestep Consumption Time: 0.77907
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.12720

Cumulative Model Updates: 37,849
Cumulative Timesteps: 631,402,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,218.02839
Policy Entropy: 1.05969
Value Function Loss: 8.25746

Mean KL Divergence: 0.05172
SB3 Clip Fraction: 0.20237
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.07008

Collected Steps per Second: 11,025.88563
Overall Steps per Second: 9,405.15569

Timestep Collection Time: 4.53515
Timestep Consumption Time: 0.78151
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.31666

Cumulative Model Updates: 37,852
Cumulative Timesteps: 631,452,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 631452800...
Checkpoint 631452800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,433.90297
Policy Entropy: 1.07724
Value Function Loss: 7.97514

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.08606

Collected Steps per Second: 11,219.36399
Overall Steps per Second: 9,704.66673

Timestep Collection Time: 4.45712
Timestep Consumption Time: 0.69566
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.15278

Cumulative Model Updates: 37,855
Cumulative Timesteps: 631,502,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,679.13961
Policy Entropy: 1.07130
Value Function Loss: 7.86058

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.08077

Collected Steps per Second: 11,110.85095
Overall Steps per Second: 9,513.33625

Timestep Collection Time: 4.50155
Timestep Consumption Time: 0.75592
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.25746

Cumulative Model Updates: 37,858
Cumulative Timesteps: 631,552,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 631552822...
Checkpoint 631552822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414,762.97204
Policy Entropy: 1.06827
Value Function Loss: 7.48485

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.08045

Collected Steps per Second: 11,217.96123
Overall Steps per Second: 9,539.34348

Timestep Collection Time: 4.45821
Timestep Consumption Time: 0.78450
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.24271

Cumulative Model Updates: 37,861
Cumulative Timesteps: 631,602,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,731.16237
Policy Entropy: 1.06075
Value Function Loss: 7.18001

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.09234

Collected Steps per Second: 11,217.73916
Overall Steps per Second: 9,521.66438

Timestep Collection Time: 4.45919
Timestep Consumption Time: 0.79431
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.25349

Cumulative Model Updates: 37,864
Cumulative Timesteps: 631,652,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 631652856...
Checkpoint 631652856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,679.87311
Policy Entropy: 1.07691
Value Function Loss: 7.13282

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.14914
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.08272

Collected Steps per Second: 11,252.39078
Overall Steps per Second: 9,595.04620

Timestep Collection Time: 4.44510
Timestep Consumption Time: 0.76780
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 5.21290

Cumulative Model Updates: 37,867
Cumulative Timesteps: 631,702,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,001.10123
Policy Entropy: 1.07934
Value Function Loss: 7.70531

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.08429

Collected Steps per Second: 10,811.46755
Overall Steps per Second: 9,234.27511

Timestep Collection Time: 4.62564
Timestep Consumption Time: 0.79005
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 5.41569

Cumulative Model Updates: 37,870
Cumulative Timesteps: 631,752,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 631752884...
Checkpoint 631752884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,483.86409
Policy Entropy: 1.06638
Value Function Loss: 7.61798

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.07526

Collected Steps per Second: 11,246.64571
Overall Steps per Second: 9,590.00891

Timestep Collection Time: 4.44755
Timestep Consumption Time: 0.76830
PPO Batch Consumption Time: 0.03775
Total Iteration Time: 5.21585

Cumulative Model Updates: 37,873
Cumulative Timesteps: 631,802,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,716.85031
Policy Entropy: 1.06833
Value Function Loss: 7.59925

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.06541
Value Function Update Magnitude: 0.07146

Collected Steps per Second: 11,193.19043
Overall Steps per Second: 9,560.08599

Timestep Collection Time: 4.46825
Timestep Consumption Time: 0.76329
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 5.23154

Cumulative Model Updates: 37,876
Cumulative Timesteps: 631,852,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 631852918...
Checkpoint 631852918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,294.64635
Policy Entropy: 1.06042
Value Function Loss: 7.26312

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.15226
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.07696

Collected Steps per Second: 10,953.72322
Overall Steps per Second: 9,504.77536

Timestep Collection Time: 4.56557
Timestep Consumption Time: 0.69599
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.26157

Cumulative Model Updates: 37,879
Cumulative Timesteps: 631,902,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,698.90043
Policy Entropy: 1.07504
Value Function Loss: 7.17963

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.07011

Collected Steps per Second: 10,828.13843
Overall Steps per Second: 9,274.42104

Timestep Collection Time: 4.61797
Timestep Consumption Time: 0.77364
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.39160

Cumulative Model Updates: 37,882
Cumulative Timesteps: 631,952,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 631952932...
Checkpoint 631952932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,585.39463
Policy Entropy: 1.06680
Value Function Loss: 7.09194

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.07037

Collected Steps per Second: 10,923.38311
Overall Steps per Second: 9,301.70081

Timestep Collection Time: 4.57953
Timestep Consumption Time: 0.79841
PPO Batch Consumption Time: 0.03924
Total Iteration Time: 5.37794

Cumulative Model Updates: 37,885
Cumulative Timesteps: 632,002,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,864.17640
Policy Entropy: 1.05813
Value Function Loss: 7.26675

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.07500

Collected Steps per Second: 11,532.58942
Overall Steps per Second: 9,761.34924

Timestep Collection Time: 4.33745
Timestep Consumption Time: 0.78705
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 5.12450

Cumulative Model Updates: 37,888
Cumulative Timesteps: 632,052,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 632052978...
Checkpoint 632052978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,213.62784
Policy Entropy: 1.04056
Value Function Loss: 7.77423

Mean KL Divergence: 0.04439
SB3 Clip Fraction: 0.18753
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 10,898.12829
Overall Steps per Second: 9,313.50404

Timestep Collection Time: 4.59015
Timestep Consumption Time: 0.78098
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 5.37113

Cumulative Model Updates: 37,891
Cumulative Timesteps: 632,103,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,654.41478
Policy Entropy: 1.06809
Value Function Loss: 7.52237

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.07485

Collected Steps per Second: 10,988.47443
Overall Steps per Second: 9,568.54283

Timestep Collection Time: 4.55077
Timestep Consumption Time: 0.67531
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.22608

Cumulative Model Updates: 37,894
Cumulative Timesteps: 632,153,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 632153008...
Checkpoint 632153008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,160.15539
Policy Entropy: 1.04954
Value Function Loss: 7.30844

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.07601

Collected Steps per Second: 10,803.18643
Overall Steps per Second: 9,243.81282

Timestep Collection Time: 4.62882
Timestep Consumption Time: 0.78085
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.40967

Cumulative Model Updates: 37,897
Cumulative Timesteps: 632,203,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,818.67851
Policy Entropy: 1.04263
Value Function Loss: 7.19479

Mean KL Divergence: 0.03023
SB3 Clip Fraction: 0.16742
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.09196

Collected Steps per Second: 10,676.77186
Overall Steps per Second: 9,238.50000

Timestep Collection Time: 4.68437
Timestep Consumption Time: 0.72927
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.41365

Cumulative Model Updates: 37,900
Cumulative Timesteps: 632,253,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 632253028...
Checkpoint 632253028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,699.36435
Policy Entropy: 1.07088
Value Function Loss: 7.62193

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.15057
Policy Update Magnitude: 0.04381
Value Function Update Magnitude: 0.09017

Collected Steps per Second: 11,477.69598
Overall Steps per Second: 9,679.12029

Timestep Collection Time: 4.35732
Timestep Consumption Time: 0.80968
PPO Batch Consumption Time: 0.04066
Total Iteration Time: 5.16700

Cumulative Model Updates: 37,903
Cumulative Timesteps: 632,303,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,675.12502
Policy Entropy: 1.08250
Value Function Loss: 8.34940

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.14326
Policy Update Magnitude: 0.04238
Value Function Update Magnitude: 0.08034

Collected Steps per Second: 11,411.59682
Overall Steps per Second: 9,769.78806

Timestep Collection Time: 4.38309
Timestep Consumption Time: 0.73658
PPO Batch Consumption Time: 0.03812
Total Iteration Time: 5.11966

Cumulative Model Updates: 37,906
Cumulative Timesteps: 632,353,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 632353058...
Checkpoint 632353058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,502.38185
Policy Entropy: 1.06170
Value Function Loss: 8.18755

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.06165

Collected Steps per Second: 11,313.92171
Overall Steps per Second: 9,749.99535

Timestep Collection Time: 4.42199
Timestep Consumption Time: 0.70930
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 5.13128

Cumulative Model Updates: 37,909
Cumulative Timesteps: 632,403,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,697.58672
Policy Entropy: 1.05976
Value Function Loss: 7.81759

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.06048

Collected Steps per Second: 11,493.64466
Overall Steps per Second: 9,748.33477

Timestep Collection Time: 4.35040
Timestep Consumption Time: 0.77888
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.12929

Cumulative Model Updates: 37,912
Cumulative Timesteps: 632,453,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 632453090...
Checkpoint 632453090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,075.92535
Policy Entropy: 1.06866
Value Function Loss: 7.46192

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.06723

Collected Steps per Second: 11,585.78162
Overall Steps per Second: 9,702.70490

Timestep Collection Time: 4.31702
Timestep Consumption Time: 0.83784
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.15485

Cumulative Model Updates: 37,915
Cumulative Timesteps: 632,503,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,176.24748
Policy Entropy: 1.07586
Value Function Loss: 7.65416

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.04241
Value Function Update Magnitude: 0.07355

Collected Steps per Second: 11,388.18993
Overall Steps per Second: 9,614.51604

Timestep Collection Time: 4.39174
Timestep Consumption Time: 0.81018
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.20193

Cumulative Model Updates: 37,918
Cumulative Timesteps: 632,553,120

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 632553120...
Checkpoint 632553120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,281.66099
Policy Entropy: 1.05276
Value Function Loss: 7.73760

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.08528

Collected Steps per Second: 11,210.03455
Overall Steps per Second: 9,504.00309

Timestep Collection Time: 4.46100
Timestep Consumption Time: 0.80078
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 5.26178

Cumulative Model Updates: 37,921
Cumulative Timesteps: 632,603,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,984.92875
Policy Entropy: 1.07449
Value Function Loss: 8.03174

Mean KL Divergence: 0.03144
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.10303

Collected Steps per Second: 11,407.19848
Overall Steps per Second: 9,818.82395

Timestep Collection Time: 4.38407
Timestep Consumption Time: 0.70920
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 5.09328

Cumulative Model Updates: 37,924
Cumulative Timesteps: 632,653,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 632653138...
Checkpoint 632653138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,102.43420
Policy Entropy: 1.07101
Value Function Loss: 7.67680

Mean KL Divergence: 0.02716
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.04608
Value Function Update Magnitude: 0.10434

Collected Steps per Second: 11,262.34905
Overall Steps per Second: 9,559.59228

Timestep Collection Time: 4.44223
Timestep Consumption Time: 0.79125
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.23349

Cumulative Model Updates: 37,927
Cumulative Timesteps: 632,703,168

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,220.57644
Policy Entropy: 1.07818
Value Function Loss: 7.81493

Mean KL Divergence: 0.02819
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.10713

Collected Steps per Second: 11,355.24074
Overall Steps per Second: 9,568.78462

Timestep Collection Time: 4.40449
Timestep Consumption Time: 0.82230
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.22679

Cumulative Model Updates: 37,930
Cumulative Timesteps: 632,753,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 632753182...
Checkpoint 632753182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,352.14821
Policy Entropy: 1.06624
Value Function Loss: 7.36509

Mean KL Divergence: 0.03643
SB3 Clip Fraction: 0.16494
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.09584

Collected Steps per Second: 10,529.88744
Overall Steps per Second: 9,176.03865

Timestep Collection Time: 4.75086
Timestep Consumption Time: 0.70095
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.45181

Cumulative Model Updates: 37,933
Cumulative Timesteps: 632,803,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,142.73177
Policy Entropy: 1.08763
Value Function Loss: 7.64462

Mean KL Divergence: 0.02664
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.08722

Collected Steps per Second: 11,161.87017
Overall Steps per Second: 9,453.39484

Timestep Collection Time: 4.48115
Timestep Consumption Time: 0.80986
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 5.29101

Cumulative Model Updates: 37,936
Cumulative Timesteps: 632,853,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 632853226...
Checkpoint 632853226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,461.93574
Policy Entropy: 1.07990
Value Function Loss: 7.38754

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.10214

Collected Steps per Second: 10,865.04023
Overall Steps per Second: 9,321.69833

Timestep Collection Time: 4.60486
Timestep Consumption Time: 0.76240
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 5.36726

Cumulative Model Updates: 37,939
Cumulative Timesteps: 632,903,258

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,317.61041
Policy Entropy: 1.06157
Value Function Loss: 7.60969

Mean KL Divergence: 0.03721
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.11095

Collected Steps per Second: 11,273.77851
Overall Steps per Second: 9,649.46471

Timestep Collection Time: 4.43649
Timestep Consumption Time: 0.74680
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.18329

Cumulative Model Updates: 37,942
Cumulative Timesteps: 632,953,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 632953274...
Checkpoint 632953274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,026.20135
Policy Entropy: 1.08311
Value Function Loss: 7.25160

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.10568

Collected Steps per Second: 10,966.85074
Overall Steps per Second: 9,405.75462

Timestep Collection Time: 4.56084
Timestep Consumption Time: 0.75697
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.31781

Cumulative Model Updates: 37,945
Cumulative Timesteps: 633,003,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,236.07921
Policy Entropy: 1.09120
Value Function Loss: 7.38199

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.09574

Collected Steps per Second: 11,085.35926
Overall Steps per Second: 9,636.54600

Timestep Collection Time: 4.51316
Timestep Consumption Time: 0.67853
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 5.19169

Cumulative Model Updates: 37,948
Cumulative Timesteps: 633,053,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 633053322...
Checkpoint 633053322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,135.08736
Policy Entropy: 1.07751
Value Function Loss: 7.43879

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.09250

Collected Steps per Second: 10,608.88035
Overall Steps per Second: 9,116.74262

Timestep Collection Time: 4.71303
Timestep Consumption Time: 0.77138
PPO Batch Consumption Time: 0.03868
Total Iteration Time: 5.48442

Cumulative Model Updates: 37,951
Cumulative Timesteps: 633,103,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,404.44566
Policy Entropy: 1.06332
Value Function Loss: 7.70593

Mean KL Divergence: 0.03302
SB3 Clip Fraction: 0.17117
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.10038

Collected Steps per Second: 10,856.42507
Overall Steps per Second: 9,250.16820

Timestep Collection Time: 4.60686
Timestep Consumption Time: 0.79996
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.40682

Cumulative Model Updates: 37,954
Cumulative Timesteps: 633,153,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 633153336...
Checkpoint 633153336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412,937.55319
Policy Entropy: 1.07161
Value Function Loss: 7.62304

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.10486

Collected Steps per Second: 11,268.72739
Overall Steps per Second: 9,557.65244

Timestep Collection Time: 4.43972
Timestep Consumption Time: 0.79483
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.23455

Cumulative Model Updates: 37,957
Cumulative Timesteps: 633,203,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,358.64412
Policy Entropy: 1.08057
Value Function Loss: 7.39070

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.09735

Collected Steps per Second: 11,072.48683
Overall Steps per Second: 9,415.25274

Timestep Collection Time: 4.51570
Timestep Consumption Time: 0.79483
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.31053

Cumulative Model Updates: 37,960
Cumulative Timesteps: 633,253,366

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 633253366...
Checkpoint 633253366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,847.87751
Policy Entropy: 1.05340
Value Function Loss: 7.16768

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.16190
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.08664

Collected Steps per Second: 10,852.04569
Overall Steps per Second: 9,305.13268

Timestep Collection Time: 4.60945
Timestep Consumption Time: 0.76629
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.37574

Cumulative Model Updates: 37,963
Cumulative Timesteps: 633,303,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,733.50858
Policy Entropy: 1.06761
Value Function Loss: 6.91708

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.15144
Policy Update Magnitude: 0.04259
Value Function Update Magnitude: 0.07498

Collected Steps per Second: 11,169.27359
Overall Steps per Second: 9,218.25206

Timestep Collection Time: 4.47925
Timestep Consumption Time: 0.94802
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.42728

Cumulative Model Updates: 37,966
Cumulative Timesteps: 633,353,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 633353418...
Checkpoint 633353418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,879.89522
Policy Entropy: 1.06012
Value Function Loss: 6.68545

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.16187
Policy Update Magnitude: 0.04102
Value Function Update Magnitude: 0.06619

Collected Steps per Second: 11,298.02933
Overall Steps per Second: 9,496.47958

Timestep Collection Time: 4.42590
Timestep Consumption Time: 0.83963
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 5.26553

Cumulative Model Updates: 37,969
Cumulative Timesteps: 633,403,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,504.94235
Policy Entropy: 1.05257
Value Function Loss: 6.58597

Mean KL Divergence: 0.02640
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.06498

Collected Steps per Second: 11,861.31493
Overall Steps per Second: 10,167.02895

Timestep Collection Time: 4.21606
Timestep Consumption Time: 0.70259
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 4.91864

Cumulative Model Updates: 37,972
Cumulative Timesteps: 633,453,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 633453430...
Checkpoint 633453430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,341.39779
Policy Entropy: 1.03682
Value Function Loss: 6.70046

Mean KL Divergence: 0.04869
SB3 Clip Fraction: 0.18267
Policy Update Magnitude: 0.04328
Value Function Update Magnitude: 0.06271

Collected Steps per Second: 11,807.65272
Overall Steps per Second: 9,924.65733

Timestep Collection Time: 4.23624
Timestep Consumption Time: 0.80374
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.03997

Cumulative Model Updates: 37,975
Cumulative Timesteps: 633,503,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,046.24195
Policy Entropy: 1.06071
Value Function Loss: 6.62559

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.06271
Value Function Update Magnitude: 0.07604

Collected Steps per Second: 11,346.05163
Overall Steps per Second: 9,637.84448

Timestep Collection Time: 4.40788
Timestep Consumption Time: 0.78125
PPO Batch Consumption Time: 0.03929
Total Iteration Time: 5.18913

Cumulative Model Updates: 37,978
Cumulative Timesteps: 633,553,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 633553462...
Checkpoint 633553462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,264.93270
Policy Entropy: 1.05357
Value Function Loss: 6.88760

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.07200

Collected Steps per Second: 12,350.17671
Overall Steps per Second: 10,331.50488

Timestep Collection Time: 4.05063
Timestep Consumption Time: 0.79145
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.84208

Cumulative Model Updates: 37,981
Cumulative Timesteps: 633,603,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,604.44304
Policy Entropy: 1.03936
Value Function Loss: 6.95130

Mean KL Divergence: 0.04675
SB3 Clip Fraction: 0.18361
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.07555

Collected Steps per Second: 11,698.76772
Overall Steps per Second: 9,723.96895

Timestep Collection Time: 4.27566
Timestep Consumption Time: 0.86833
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.14399

Cumulative Model Updates: 37,984
Cumulative Timesteps: 633,653,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 633653508...
Checkpoint 633653508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,054.43782
Policy Entropy: 1.05082
Value Function Loss: 7.36542

Mean KL Divergence: 0.02972
SB3 Clip Fraction: 0.16693
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.08920

Collected Steps per Second: 11,446.31335
Overall Steps per Second: 9,874.32707

Timestep Collection Time: 4.36822
Timestep Consumption Time: 0.69542
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.06364

Cumulative Model Updates: 37,987
Cumulative Timesteps: 633,703,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,553.37830
Policy Entropy: 1.04796
Value Function Loss: 8.00279

Mean KL Divergence: 0.02628
SB3 Clip Fraction: 0.16927
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.08859

Collected Steps per Second: 11,136.59328
Overall Steps per Second: 9,400.88487

Timestep Collection Time: 4.49024
Timestep Consumption Time: 0.82904
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.31929

Cumulative Model Updates: 37,990
Cumulative Timesteps: 633,753,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 633753514...
Checkpoint 633753514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,672.44615
Policy Entropy: 1.04162
Value Function Loss: 8.08494

Mean KL Divergence: 0.03009
SB3 Clip Fraction: 0.17969
Policy Update Magnitude: 0.06333
Value Function Update Magnitude: 0.08070

Collected Steps per Second: 10,850.35526
Overall Steps per Second: 9,281.19085

Timestep Collection Time: 4.60851
Timestep Consumption Time: 0.77916
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.38767

Cumulative Model Updates: 37,993
Cumulative Timesteps: 633,803,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,444.60328
Policy Entropy: 1.06711
Value Function Loss: 7.77044

Mean KL Divergence: 0.02923
SB3 Clip Fraction: 0.16697
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.08105

Collected Steps per Second: 11,496.49544
Overall Steps per Second: 9,703.15400

Timestep Collection Time: 4.34950
Timestep Consumption Time: 0.80388
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 5.15338

Cumulative Model Updates: 37,996
Cumulative Timesteps: 633,853,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 633853522...
Checkpoint 633853522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,524.67398
Policy Entropy: 1.07468
Value Function Loss: 7.08071

Mean KL Divergence: 0.02763
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.07513

Collected Steps per Second: 11,073.22795
Overall Steps per Second: 9,352.87369

Timestep Collection Time: 4.51576
Timestep Consumption Time: 0.83062
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.34638

Cumulative Model Updates: 37,999
Cumulative Timesteps: 633,903,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,817.19676
Policy Entropy: 1.05768
Value Function Loss: 6.92664

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.07811

Collected Steps per Second: 10,455.99068
Overall Steps per Second: 9,108.11327

Timestep Collection Time: 4.78233
Timestep Consumption Time: 0.70772
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.49005

Cumulative Model Updates: 38,002
Cumulative Timesteps: 633,953,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 633953530...
Checkpoint 633953530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,873.27250
Policy Entropy: 1.03326
Value Function Loss: 7.07445

Mean KL Divergence: 0.04221
SB3 Clip Fraction: 0.18483
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 10,923.31254
Overall Steps per Second: 9,353.60564

Timestep Collection Time: 4.57920
Timestep Consumption Time: 0.76847
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.34767

Cumulative Model Updates: 38,005
Cumulative Timesteps: 634,003,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,944.99974
Policy Entropy: 1.06849
Value Function Loss: 7.06306

Mean KL Divergence: 0.03607
SB3 Clip Fraction: 0.18009
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 10,867.92366
Overall Steps per Second: 9,314.85714

Timestep Collection Time: 4.60327
Timestep Consumption Time: 0.76750
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.37077

Cumulative Model Updates: 38,008
Cumulative Timesteps: 634,053,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 634053578...
Checkpoint 634053578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,723.23298
Policy Entropy: 1.04653
Value Function Loss: 6.74101

Mean KL Divergence: 0.03019
SB3 Clip Fraction: 0.15353
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 10,792.68296
Overall Steps per Second: 9,227.88713

Timestep Collection Time: 4.63369
Timestep Consumption Time: 0.78575
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.41944

Cumulative Model Updates: 38,011
Cumulative Timesteps: 634,103,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,271.64326
Policy Entropy: 1.06927
Value Function Loss: 6.74115

Mean KL Divergence: 0.02737
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.06919

Collected Steps per Second: 11,057.61510
Overall Steps per Second: 9,518.11240

Timestep Collection Time: 4.52304
Timestep Consumption Time: 0.73158
PPO Batch Consumption Time: 0.03389
Total Iteration Time: 5.25461

Cumulative Model Updates: 38,014
Cumulative Timesteps: 634,153,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 634153602...
Checkpoint 634153602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,824.65652
Policy Entropy: 1.06979
Value Function Loss: 6.95386

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.07317

Collected Steps per Second: 11,131.66811
Overall Steps per Second: 9,660.62982

Timestep Collection Time: 4.49385
Timestep Consumption Time: 0.68428
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.17813

Cumulative Model Updates: 38,017
Cumulative Timesteps: 634,203,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,640.60927
Policy Entropy: 1.07465
Value Function Loss: 6.89469

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 10,517.91975
Overall Steps per Second: 8,969.70410

Timestep Collection Time: 4.75512
Timestep Consumption Time: 0.82076
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 5.57588

Cumulative Model Updates: 38,020
Cumulative Timesteps: 634,253,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 634253640...
Checkpoint 634253640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,408.66912
Policy Entropy: 1.06823
Value Function Loss: 6.44945

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.06364
Value Function Update Magnitude: 0.07803

Collected Steps per Second: 10,906.30553
Overall Steps per Second: 9,378.41339

Timestep Collection Time: 4.58615
Timestep Consumption Time: 0.74716
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 5.33331

Cumulative Model Updates: 38,023
Cumulative Timesteps: 634,303,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,800.15621
Policy Entropy: 1.06814
Value Function Loss: 6.55953

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.08040

Collected Steps per Second: 11,161.77995
Overall Steps per Second: 9,542.17618

Timestep Collection Time: 4.48244
Timestep Consumption Time: 0.76081
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 5.24325

Cumulative Model Updates: 38,026
Cumulative Timesteps: 634,353,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 634353690...
Checkpoint 634353690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,532.57343
Policy Entropy: 1.06737
Value Function Loss: 7.09487

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.07013

Collected Steps per Second: 11,099.32702
Overall Steps per Second: 9,425.16000

Timestep Collection Time: 4.50730
Timestep Consumption Time: 0.80062
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.30792

Cumulative Model Updates: 38,029
Cumulative Timesteps: 634,403,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,048.09714
Policy Entropy: 1.07415
Value Function Loss: 7.83665

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.07428

Collected Steps per Second: 10,785.90913
Overall Steps per Second: 9,236.63525

Timestep Collection Time: 4.63605
Timestep Consumption Time: 0.77761
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 5.41366

Cumulative Model Updates: 38,032
Cumulative Timesteps: 634,453,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 634453722...
Checkpoint 634453722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,466.11394
Policy Entropy: 1.06723
Value Function Loss: 7.73520

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.06224
Value Function Update Magnitude: 0.06933

Collected Steps per Second: 10,505.48924
Overall Steps per Second: 8,963.06826

Timestep Collection Time: 4.76113
Timestep Consumption Time: 0.81933
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.58046

Cumulative Model Updates: 38,035
Cumulative Timesteps: 634,503,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362,129.27656
Policy Entropy: 1.07936
Value Function Loss: 7.90101

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.07517

Collected Steps per Second: 11,063.85392
Overall Steps per Second: 9,439.37403

Timestep Collection Time: 4.52103
Timestep Consumption Time: 0.77805
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.29908

Cumulative Model Updates: 38,038
Cumulative Timesteps: 634,553,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 634553760...
Checkpoint 634553760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,451.92033
Policy Entropy: 1.09135
Value Function Loss: 7.75492

Mean KL Divergence: 0.02642
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.06919

Collected Steps per Second: 11,346.52432
Overall Steps per Second: 9,824.22193

Timestep Collection Time: 4.40805
Timestep Consumption Time: 0.68304
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.09109

Cumulative Model Updates: 38,041
Cumulative Timesteps: 634,603,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,950.25585
Policy Entropy: 1.08369
Value Function Loss: 7.62095

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.06459

Collected Steps per Second: 11,489.38345
Overall Steps per Second: 9,764.38026

Timestep Collection Time: 4.35393
Timestep Consumption Time: 0.76918
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 5.12311

Cumulative Model Updates: 38,044
Cumulative Timesteps: 634,653,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 634653800...
Checkpoint 634653800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,172.46925
Policy Entropy: 1.07709
Value Function Loss: 7.23609

Mean KL Divergence: 0.03041
SB3 Clip Fraction: 0.15352
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.06482

Collected Steps per Second: 11,335.83723
Overall Steps per Second: 9,687.40234

Timestep Collection Time: 4.41291
Timestep Consumption Time: 0.75091
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.16382

Cumulative Model Updates: 38,047
Cumulative Timesteps: 634,703,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,511.68924
Policy Entropy: 1.08506
Value Function Loss: 6.84084

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.09256

Collected Steps per Second: 11,925.52734
Overall Steps per Second: 10,061.80070

Timestep Collection Time: 4.19470
Timestep Consumption Time: 0.77698
PPO Batch Consumption Time: 0.04042
Total Iteration Time: 4.97167

Cumulative Model Updates: 38,050
Cumulative Timesteps: 634,753,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 634753848...
Checkpoint 634753848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,703.18390
Policy Entropy: 1.09914
Value Function Loss: 6.68766

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.10933

Collected Steps per Second: 10,699.70989
Overall Steps per Second: 9,149.27897

Timestep Collection Time: 4.67396
Timestep Consumption Time: 0.79205
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 5.46600

Cumulative Model Updates: 38,053
Cumulative Timesteps: 634,803,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,000.29881
Policy Entropy: 1.08426
Value Function Loss: 6.77930

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.12440

Collected Steps per Second: 11,214.30351
Overall Steps per Second: 9,655.83836

Timestep Collection Time: 4.46002
Timestep Consumption Time: 0.71985
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 5.17987

Cumulative Model Updates: 38,056
Cumulative Timesteps: 634,853,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 634853874...
Checkpoint 634853874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,794.59993
Policy Entropy: 1.07780
Value Function Loss: 6.99718

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.09889

Collected Steps per Second: 11,201.45592
Overall Steps per Second: 9,502.65518

Timestep Collection Time: 4.46531
Timestep Consumption Time: 0.79827
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.26358

Cumulative Model Updates: 38,059
Cumulative Timesteps: 634,903,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,227.30535
Policy Entropy: 1.09097
Value Function Loss: 7.22950

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.08951

Collected Steps per Second: 11,273.14044
Overall Steps per Second: 9,616.84698

Timestep Collection Time: 4.43798
Timestep Consumption Time: 0.76435
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.20233

Cumulative Model Updates: 38,062
Cumulative Timesteps: 634,953,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 634953922...
Checkpoint 634953922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,776.35548
Policy Entropy: 1.09086
Value Function Loss: 6.99692

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.04608
Value Function Update Magnitude: 0.07711

Collected Steps per Second: 11,311.62549
Overall Steps per Second: 9,752.11382

Timestep Collection Time: 4.42200
Timestep Consumption Time: 0.70715
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.12914

Cumulative Model Updates: 38,065
Cumulative Timesteps: 635,003,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,189.88354
Policy Entropy: 1.07347
Value Function Loss: 6.79402

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.08186

Collected Steps per Second: 11,106.11219
Overall Steps per Second: 9,479.12054

Timestep Collection Time: 4.50275
Timestep Consumption Time: 0.77285
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.27559

Cumulative Model Updates: 38,068
Cumulative Timesteps: 635,053,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 635053950...
Checkpoint 635053950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,207.77857
Policy Entropy: 1.05950
Value Function Loss: 6.52479

Mean KL Divergence: 0.04617
SB3 Clip Fraction: 0.18930
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.08927

Collected Steps per Second: 10,728.29618
Overall Steps per Second: 9,369.64917

Timestep Collection Time: 4.66057
Timestep Consumption Time: 0.67581
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.33638

Cumulative Model Updates: 38,071
Cumulative Timesteps: 635,103,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,265.74318
Policy Entropy: 1.07266
Value Function Loss: 6.91886

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.07914

Collected Steps per Second: 10,968.41063
Overall Steps per Second: 9,341.49434

Timestep Collection Time: 4.55855
Timestep Consumption Time: 0.79392
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 5.35246

Cumulative Model Updates: 38,074
Cumulative Timesteps: 635,153,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 635153950...
Checkpoint 635153950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,162.81303
Policy Entropy: 1.07392
Value Function Loss: 7.15767

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.07533

Collected Steps per Second: 10,995.05029
Overall Steps per Second: 9,425.57627

Timestep Collection Time: 4.54823
Timestep Consumption Time: 0.75734
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.30556

Cumulative Model Updates: 38,077
Cumulative Timesteps: 635,203,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,618.38030
Policy Entropy: 1.06330
Value Function Loss: 7.55455

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.07563

Collected Steps per Second: 11,167.09195
Overall Steps per Second: 9,440.21688

Timestep Collection Time: 4.47870
Timestep Consumption Time: 0.81928
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.29797

Cumulative Model Updates: 38,080
Cumulative Timesteps: 635,253,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 635253972...
Checkpoint 635253972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,411.67453
Policy Entropy: 1.08009
Value Function Loss: 7.14021

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.07266

Collected Steps per Second: 11,112.55299
Overall Steps per Second: 9,456.66603

Timestep Collection Time: 4.50032
Timestep Consumption Time: 0.78802
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.28833

Cumulative Model Updates: 38,083
Cumulative Timesteps: 635,303,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,132.63813
Policy Entropy: 1.08102
Value Function Loss: 7.04995

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.09341

Collected Steps per Second: 10,914.81799
Overall Steps per Second: 9,317.77330

Timestep Collection Time: 4.58129
Timestep Consumption Time: 0.78522
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.36652

Cumulative Model Updates: 38,086
Cumulative Timesteps: 635,353,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 635353986...
Checkpoint 635353986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,493.01385
Policy Entropy: 1.07263
Value Function Loss: 7.08529

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.08143

Collected Steps per Second: 11,209.97751
Overall Steps per Second: 9,483.90313

Timestep Collection Time: 4.46103
Timestep Consumption Time: 0.81191
PPO Batch Consumption Time: 0.04418
Total Iteration Time: 5.27293

Cumulative Model Updates: 38,089
Cumulative Timesteps: 635,403,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,694.42975
Policy Entropy: 1.05337
Value Function Loss: 7.05712

Mean KL Divergence: 0.05060
SB3 Clip Fraction: 0.17719
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.07532

Collected Steps per Second: 11,289.39172
Overall Steps per Second: 9,587.64076

Timestep Collection Time: 4.42929
Timestep Consumption Time: 0.78617
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 5.21546

Cumulative Model Updates: 38,092
Cumulative Timesteps: 635,453,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 635453998...
Checkpoint 635453998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,990.79967
Policy Entropy: 1.08246
Value Function Loss: 6.82967

Mean KL Divergence: 0.02649
SB3 Clip Fraction: 0.14967
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.07746

Collected Steps per Second: 10,757.53398
Overall Steps per Second: 9,340.29769

Timestep Collection Time: 4.65051
Timestep Consumption Time: 0.70564
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.35615

Cumulative Model Updates: 38,095
Cumulative Timesteps: 635,504,026

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,534.74083
Policy Entropy: 1.06302
Value Function Loss: 6.88613

Mean KL Divergence: 0.02744
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 11,187.76429
Overall Steps per Second: 9,530.23815

Timestep Collection Time: 4.47006
Timestep Consumption Time: 0.77745
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.24751

Cumulative Model Updates: 38,098
Cumulative Timesteps: 635,554,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 635554036...
Checkpoint 635554036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,524.05073
Policy Entropy: 1.06482
Value Function Loss: 7.29218

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.04536
Value Function Update Magnitude: 0.08785

Collected Steps per Second: 10,796.55798
Overall Steps per Second: 9,259.18521

Timestep Collection Time: 4.63240
Timestep Consumption Time: 0.76915
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.40156

Cumulative Model Updates: 38,101
Cumulative Timesteps: 635,604,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,738.11145
Policy Entropy: 1.06978
Value Function Loss: 7.77983

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.08409

Collected Steps per Second: 10,600.92859
Overall Steps per Second: 9,059.68497

Timestep Collection Time: 4.71883
Timestep Consumption Time: 0.80277
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.52160

Cumulative Model Updates: 38,104
Cumulative Timesteps: 635,654,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 635654074...
Checkpoint 635654074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,962.51481
Policy Entropy: 1.07686
Value Function Loss: 7.62619

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.07837

Collected Steps per Second: 11,760.66430
Overall Steps per Second: 9,956.13450

Timestep Collection Time: 4.25401
Timestep Consumption Time: 0.77103
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.02504

Cumulative Model Updates: 38,107
Cumulative Timesteps: 635,704,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,104.33883
Policy Entropy: 1.07697
Value Function Loss: 7.52131

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.07723

Collected Steps per Second: 12,174.98800
Overall Steps per Second: 10,294.86590

Timestep Collection Time: 4.10694
Timestep Consumption Time: 0.75004
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.85698

Cumulative Model Updates: 38,110
Cumulative Timesteps: 635,754,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 635754106...
Checkpoint 635754106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,033.14541
Policy Entropy: 1.08619
Value Function Loss: 7.50902

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.11383
Policy Update Magnitude: 0.04994
Value Function Update Magnitude: 0.09069

Collected Steps per Second: 11,836.33744
Overall Steps per Second: 10,006.53824

Timestep Collection Time: 4.22546
Timestep Consumption Time: 0.77267
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 4.99813

Cumulative Model Updates: 38,113
Cumulative Timesteps: 635,804,120

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377,561.64198
Policy Entropy: 1.08674
Value Function Loss: 7.43519

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.11733
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.08509

Collected Steps per Second: 12,053.74694
Overall Steps per Second: 10,176.85412

Timestep Collection Time: 4.15058
Timestep Consumption Time: 0.76548
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.91606

Cumulative Model Updates: 38,116
Cumulative Timesteps: 635,854,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 635854150...
Checkpoint 635854150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,295.44769
Policy Entropy: 1.09100
Value Function Loss: 7.47950

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.07468

Collected Steps per Second: 12,208.00420
Overall Steps per Second: 10,183.90440

Timestep Collection Time: 4.09715
Timestep Consumption Time: 0.81433
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 4.91148

Cumulative Model Updates: 38,119
Cumulative Timesteps: 635,904,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,863.20148
Policy Entropy: 1.09228
Value Function Loss: 7.26632

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.11597
Policy Update Magnitude: 0.06279
Value Function Update Magnitude: 0.07934

Collected Steps per Second: 11,286.85616
Overall Steps per Second: 9,618.91783

Timestep Collection Time: 4.43188
Timestep Consumption Time: 0.76850
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 5.20038

Cumulative Model Updates: 38,122
Cumulative Timesteps: 635,954,190

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 635954190...
Checkpoint 635954190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,044.94263
Policy Entropy: 1.09761
Value Function Loss: 7.18364

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.07690

Collected Steps per Second: 11,108.76834
Overall Steps per Second: 9,605.62625

Timestep Collection Time: 4.50275
Timestep Consumption Time: 0.70462
PPO Batch Consumption Time: 0.03789
Total Iteration Time: 5.20736

Cumulative Model Updates: 38,125
Cumulative Timesteps: 636,004,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,800.74789
Policy Entropy: 1.08954
Value Function Loss: 7.09093

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.07624

Collected Steps per Second: 11,364.13225
Overall Steps per Second: 9,601.47319

Timestep Collection Time: 4.39981
Timestep Consumption Time: 0.80773
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.20753

Cumulative Model Updates: 38,128
Cumulative Timesteps: 636,054,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 636054210...
Checkpoint 636054210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,700.94155
Policy Entropy: 1.10361
Value Function Loss: 7.15610

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.06560

Collected Steps per Second: 10,934.68937
Overall Steps per Second: 9,509.19742

Timestep Collection Time: 4.57260
Timestep Consumption Time: 0.68546
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 5.25807

Cumulative Model Updates: 38,131
Cumulative Timesteps: 636,104,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,946.63667
Policy Entropy: 1.11028
Value Function Loss: 7.13401

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.06003

Collected Steps per Second: 11,254.06520
Overall Steps per Second: 9,547.74279

Timestep Collection Time: 4.44391
Timestep Consumption Time: 0.79419
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 5.23810

Cumulative Model Updates: 38,134
Cumulative Timesteps: 636,154,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 636154222...
Checkpoint 636154222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,786.23760
Policy Entropy: 1.09901
Value Function Loss: 7.08305

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.06099

Collected Steps per Second: 10,756.54071
Overall Steps per Second: 9,226.94230

Timestep Collection Time: 4.65075
Timestep Consumption Time: 0.77098
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 5.42173

Cumulative Model Updates: 38,137
Cumulative Timesteps: 636,204,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,533.02275
Policy Entropy: 1.08502
Value Function Loss: 7.18754

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.06012

Collected Steps per Second: 10,690.23831
Overall Steps per Second: 9,322.31994

Timestep Collection Time: 4.67866
Timestep Consumption Time: 0.68653
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.36519

Cumulative Model Updates: 38,140
Cumulative Timesteps: 636,254,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 636254264...
Checkpoint 636254264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,777.91725
Policy Entropy: 1.09497
Value Function Loss: 6.87915

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.05744

Collected Steps per Second: 11,058.85972
Overall Steps per Second: 9,452.71005

Timestep Collection Time: 4.52199
Timestep Consumption Time: 0.76835
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.29033

Cumulative Model Updates: 38,143
Cumulative Timesteps: 636,304,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,133.98725
Policy Entropy: 1.08798
Value Function Loss: 7.20638

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.04196
Value Function Update Magnitude: 0.05110

Collected Steps per Second: 11,042.21869
Overall Steps per Second: 9,472.08416

Timestep Collection Time: 4.52880
Timestep Consumption Time: 0.75071
PPO Batch Consumption Time: 0.03346
Total Iteration Time: 5.27951

Cumulative Model Updates: 38,146
Cumulative Timesteps: 636,354,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 636354280...
Checkpoint 636354280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,283.51734
Policy Entropy: 1.05893
Value Function Loss: 7.33385

Mean KL Divergence: 0.04262
SB3 Clip Fraction: 0.16573
Policy Update Magnitude: 0.06297
Value Function Update Magnitude: 0.05303

Collected Steps per Second: 10,837.61685
Overall Steps per Second: 9,248.52602

Timestep Collection Time: 4.61614
Timestep Consumption Time: 0.79315
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.40929

Cumulative Model Updates: 38,149
Cumulative Timesteps: 636,404,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403,395.96385
Policy Entropy: 1.07578
Value Function Loss: 8.06949

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.05484

Collected Steps per Second: 10,936.35684
Overall Steps per Second: 9,322.84093

Timestep Collection Time: 4.57355
Timestep Consumption Time: 0.79155
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 5.36510

Cumulative Model Updates: 38,152
Cumulative Timesteps: 636,454,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 636454326...
Checkpoint 636454326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,447.36069
Policy Entropy: 1.08365
Value Function Loss: 7.99151

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.05105

Collected Steps per Second: 10,780.24229
Overall Steps per Second: 9,405.24704

Timestep Collection Time: 4.63904
Timestep Consumption Time: 0.67820
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.31724

Cumulative Model Updates: 38,155
Cumulative Timesteps: 636,504,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,299.75895
Policy Entropy: 1.07591
Value Function Loss: 8.13288

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.04794

Collected Steps per Second: 11,134.77326
Overall Steps per Second: 9,453.96384

Timestep Collection Time: 4.49151
Timestep Consumption Time: 0.79854
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.29006

Cumulative Model Updates: 38,158
Cumulative Timesteps: 636,554,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 636554348...
Checkpoint 636554348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,758.26381
Policy Entropy: 1.05608
Value Function Loss: 7.73332

Mean KL Divergence: 0.04148
SB3 Clip Fraction: 0.19559
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.04874

Collected Steps per Second: 10,949.64142
Overall Steps per Second: 9,403.08499

Timestep Collection Time: 4.56709
Timestep Consumption Time: 0.75116
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 5.31825

Cumulative Model Updates: 38,161
Cumulative Timesteps: 636,604,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,672.61857
Policy Entropy: 1.07206
Value Function Loss: 7.77471

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.05504

Collected Steps per Second: 10,974.72635
Overall Steps per Second: 9,318.69786

Timestep Collection Time: 4.55665
Timestep Consumption Time: 0.80976
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.36642

Cumulative Model Updates: 38,164
Cumulative Timesteps: 636,654,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 636654364...
Checkpoint 636654364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,731.94653
Policy Entropy: 1.07640
Value Function Loss: 7.31772

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.14868
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.06123

Collected Steps per Second: 10,828.94327
Overall Steps per Second: 9,296.70622

Timestep Collection Time: 4.61910
Timestep Consumption Time: 0.76130
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 5.38040

Cumulative Model Updates: 38,167
Cumulative Timesteps: 636,704,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,247.00751
Policy Entropy: 1.06341
Value Function Loss: 7.21383

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.06766

Collected Steps per Second: 10,927.45484
Overall Steps per Second: 9,455.98914

Timestep Collection Time: 4.57783
Timestep Consumption Time: 0.71236
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.29019

Cumulative Model Updates: 38,170
Cumulative Timesteps: 636,754,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 636754408...
Checkpoint 636754408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,277.85665
Policy Entropy: 1.05733
Value Function Loss: 6.86976

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.07860

Collected Steps per Second: 10,560.80863
Overall Steps per Second: 9,111.33955

Timestep Collection Time: 4.73486
Timestep Consumption Time: 0.75324
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 5.48811

Cumulative Model Updates: 38,173
Cumulative Timesteps: 636,804,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,439.06716
Policy Entropy: 1.06049
Value Function Loss: 6.98388

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.11767
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.08339

Collected Steps per Second: 11,233.51584
Overall Steps per Second: 9,755.01837

Timestep Collection Time: 4.45114
Timestep Consumption Time: 0.67463
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.12577

Cumulative Model Updates: 38,176
Cumulative Timesteps: 636,854,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 636854414...
Checkpoint 636854414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,909.68388
Policy Entropy: 1.06920
Value Function Loss: 7.24474

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.08367

Collected Steps per Second: 11,275.41676
Overall Steps per Second: 9,666.61132

Timestep Collection Time: 4.43514
Timestep Consumption Time: 0.73814
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.17327

Cumulative Model Updates: 38,179
Cumulative Timesteps: 636,904,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,504.21460
Policy Entropy: 1.07051
Value Function Loss: 7.20496

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.07766

Collected Steps per Second: 11,417.19238
Overall Steps per Second: 9,880.56426

Timestep Collection Time: 4.38199
Timestep Consumption Time: 0.68149
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.06348

Cumulative Model Updates: 38,182
Cumulative Timesteps: 636,954,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 636954452...
Checkpoint 636954452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,868.66125
Policy Entropy: 1.07040
Value Function Loss: 7.32476

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.07465

Collected Steps per Second: 11,457.79260
Overall Steps per Second: 9,636.47200

Timestep Collection Time: 4.36384
Timestep Consumption Time: 0.82478
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 5.18862

Cumulative Model Updates: 38,185
Cumulative Timesteps: 637,004,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,883.34560
Policy Entropy: 1.06469
Value Function Loss: 7.31995

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.15787
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.07022

Collected Steps per Second: 11,438.35822
Overall Steps per Second: 9,758.69553

Timestep Collection Time: 4.37196
Timestep Consumption Time: 0.75250
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.12446

Cumulative Model Updates: 38,188
Cumulative Timesteps: 637,054,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 637054460...
Checkpoint 637054460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,378.34656
Policy Entropy: 1.07912
Value Function Loss: 7.38764

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 10,912.44366
Overall Steps per Second: 9,465.27643

Timestep Collection Time: 4.58229
Timestep Consumption Time: 0.70060
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.28289

Cumulative Model Updates: 38,191
Cumulative Timesteps: 637,104,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400,280.37147
Policy Entropy: 1.08177
Value Function Loss: 7.16267

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.08664

Collected Steps per Second: 11,317.76765
Overall Steps per Second: 9,595.05981

Timestep Collection Time: 4.41854
Timestep Consumption Time: 0.79331
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 5.21185

Cumulative Model Updates: 38,194
Cumulative Timesteps: 637,154,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 637154472...
Checkpoint 637154472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,913.19106
Policy Entropy: 1.07011
Value Function Loss: 6.98662

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.07586

Collected Steps per Second: 11,197.06635
Overall Steps per Second: 9,578.65434

Timestep Collection Time: 4.46581
Timestep Consumption Time: 0.75454
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.22036

Cumulative Model Updates: 38,197
Cumulative Timesteps: 637,204,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,871.35328
Policy Entropy: 1.05897
Value Function Loss: 6.97065

Mean KL Divergence: 0.03182
SB3 Clip Fraction: 0.15433
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.07224

Collected Steps per Second: 11,452.19753
Overall Steps per Second: 9,700.29227

Timestep Collection Time: 4.36824
Timestep Consumption Time: 0.78892
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.15716

Cumulative Model Updates: 38,200
Cumulative Timesteps: 637,254,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 637254502...
Checkpoint 637254502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,307.15647
Policy Entropy: 1.06949
Value Function Loss: 7.20030

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.06664

Collected Steps per Second: 11,145.02075
Overall Steps per Second: 9,417.22220

Timestep Collection Time: 4.48774
Timestep Consumption Time: 0.82338
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.31112

Cumulative Model Updates: 38,203
Cumulative Timesteps: 637,304,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,524.95093
Policy Entropy: 1.06983
Value Function Loss: 7.38541

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.06774

Collected Steps per Second: 10,909.61023
Overall Steps per Second: 9,471.17045

Timestep Collection Time: 4.58568
Timestep Consumption Time: 0.69645
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.28213

Cumulative Model Updates: 38,206
Cumulative Timesteps: 637,354,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 637354546...
Checkpoint 637354546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,475.31218
Policy Entropy: 1.05906
Value Function Loss: 7.49111

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.06954

Collected Steps per Second: 11,170.03130
Overall Steps per Second: 9,571.73837

Timestep Collection Time: 4.47841
Timestep Consumption Time: 0.74781
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.22622

Cumulative Model Updates: 38,209
Cumulative Timesteps: 637,404,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,474.63166
Policy Entropy: 1.05180
Value Function Loss: 7.31997

Mean KL Divergence: 0.03861
SB3 Clip Fraction: 0.16589
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.07081

Collected Steps per Second: 11,268.29396
Overall Steps per Second: 9,628.33224

Timestep Collection Time: 4.43776
Timestep Consumption Time: 0.75587
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.19363

Cumulative Model Updates: 38,212
Cumulative Timesteps: 637,454,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 637454576...
Checkpoint 637454576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,182.02988
Policy Entropy: 1.06558
Value Function Loss: 7.32596

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.07151

Collected Steps per Second: 11,081.90130
Overall Steps per Second: 9,659.28873

Timestep Collection Time: 4.51294
Timestep Consumption Time: 0.66466
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.17761

Cumulative Model Updates: 38,215
Cumulative Timesteps: 637,504,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592,531.40848
Policy Entropy: 1.07406
Value Function Loss: 7.41989

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.07053

Collected Steps per Second: 10,908.21753
Overall Steps per Second: 9,336.80595

Timestep Collection Time: 4.58407
Timestep Consumption Time: 0.77151
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.35558

Cumulative Model Updates: 38,218
Cumulative Timesteps: 637,554,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 637554592...
Checkpoint 637554592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,661.35635
Policy Entropy: 1.05832
Value Function Loss: 7.77345

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.07581

Collected Steps per Second: 10,882.80559
Overall Steps per Second: 9,408.63328

Timestep Collection Time: 4.59587
Timestep Consumption Time: 0.72009
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 5.31597

Cumulative Model Updates: 38,221
Cumulative Timesteps: 637,604,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,695.09377
Policy Entropy: 1.05020
Value Function Loss: 7.66755

Mean KL Divergence: 0.03274
SB3 Clip Fraction: 0.16316
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.07997

Collected Steps per Second: 10,794.73082
Overall Steps per Second: 9,223.06048

Timestep Collection Time: 4.63467
Timestep Consumption Time: 0.78978
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.42445

Cumulative Model Updates: 38,224
Cumulative Timesteps: 637,654,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 637654638...
Checkpoint 637654638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,757.58210
Policy Entropy: 1.06501
Value Function Loss: 7.79167

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.08291

Collected Steps per Second: 11,092.41725
Overall Steps per Second: 9,407.33772

Timestep Collection Time: 4.50903
Timestep Consumption Time: 0.80767
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.31670

Cumulative Model Updates: 38,227
Cumulative Timesteps: 637,704,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,519.27608
Policy Entropy: 1.07751
Value Function Loss: 7.01201

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.10669

Collected Steps per Second: 11,083.82397
Overall Steps per Second: 9,575.54024

Timestep Collection Time: 4.51108
Timestep Consumption Time: 0.71056
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.22164

Cumulative Model Updates: 38,230
Cumulative Timesteps: 637,754,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 637754654...
Checkpoint 637754654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,767.45258
Policy Entropy: 1.06334
Value Function Loss: 6.78909

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 10,727.56254
Overall Steps per Second: 9,044.63730

Timestep Collection Time: 4.66126
Timestep Consumption Time: 0.86732
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.52858

Cumulative Model Updates: 38,233
Cumulative Timesteps: 637,804,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,420.77591
Policy Entropy: 1.04580
Value Function Loss: 6.46464

Mean KL Divergence: 0.03625
SB3 Clip Fraction: 0.17380
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.11661

Collected Steps per Second: 10,608.89317
Overall Steps per Second: 9,135.46971

Timestep Collection Time: 4.71567
Timestep Consumption Time: 0.76057
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.47624

Cumulative Model Updates: 38,236
Cumulative Timesteps: 637,854,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 637854686...
Checkpoint 637854686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,960.19073
Policy Entropy: 1.06637
Value Function Loss: 7.19046

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.10704

Collected Steps per Second: 10,818.97111
Overall Steps per Second: 9,135.57031

Timestep Collection Time: 4.62410
Timestep Consumption Time: 0.85208
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 5.47618

Cumulative Model Updates: 38,239
Cumulative Timesteps: 637,904,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,523.53151
Policy Entropy: 1.04613
Value Function Loss: 7.44600

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.11020

Collected Steps per Second: 11,045.88961
Overall Steps per Second: 9,484.62256

Timestep Collection Time: 4.52693
Timestep Consumption Time: 0.74518
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.27211

Cumulative Model Updates: 38,242
Cumulative Timesteps: 637,954,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 637954718...
Checkpoint 637954718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,713.13249
Policy Entropy: 1.03692
Value Function Loss: 7.68296

Mean KL Divergence: 0.03508
SB3 Clip Fraction: 0.17829
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.09062

Collected Steps per Second: 12,291.60589
Overall Steps per Second: 10,334.66098

Timestep Collection Time: 4.07009
Timestep Consumption Time: 0.77070
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 4.84080

Cumulative Model Updates: 38,245
Cumulative Timesteps: 638,004,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,358.90847
Policy Entropy: 1.05669
Value Function Loss: 7.54109

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.07438

Collected Steps per Second: 11,936.50191
Overall Steps per Second: 10,078.67470

Timestep Collection Time: 4.19135
Timestep Consumption Time: 0.77260
PPO Batch Consumption Time: 0.03340
Total Iteration Time: 4.96395

Cumulative Model Updates: 38,248
Cumulative Timesteps: 638,054,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 638054776...
Checkpoint 638054776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,696.26692
Policy Entropy: 1.06172
Value Function Loss: 7.52960

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.08355

Collected Steps per Second: 11,900.20686
Overall Steps per Second: 10,225.58608

Timestep Collection Time: 4.20413
Timestep Consumption Time: 0.68850
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.89263

Cumulative Model Updates: 38,251
Cumulative Timesteps: 638,104,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,823.02462
Policy Entropy: 1.04512
Value Function Loss: 7.33054

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.10044

Collected Steps per Second: 11,964.00858
Overall Steps per Second: 10,112.96729

Timestep Collection Time: 4.18121
Timestep Consumption Time: 0.76531
PPO Batch Consumption Time: 0.03789
Total Iteration Time: 4.94652

Cumulative Model Updates: 38,254
Cumulative Timesteps: 638,154,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 638154830...
Checkpoint 638154830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,309.43555
Policy Entropy: 1.05371
Value Function Loss: 7.44011

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.10968

Collected Steps per Second: 12,013.57988
Overall Steps per Second: 9,988.86337

Timestep Collection Time: 4.16395
Timestep Consumption Time: 0.84402
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.00798

Cumulative Model Updates: 38,257
Cumulative Timesteps: 638,204,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,501.30283
Policy Entropy: 1.06735
Value Function Loss: 7.34809

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.10877

Collected Steps per Second: 11,981.10602
Overall Steps per Second: 9,957.78970

Timestep Collection Time: 4.17424
Timestep Consumption Time: 0.84816
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.02240

Cumulative Model Updates: 38,260
Cumulative Timesteps: 638,254,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 638254866...
Checkpoint 638254866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,938.63810
Policy Entropy: 1.06513
Value Function Loss: 7.38088

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.09293

Collected Steps per Second: 11,248.79373
Overall Steps per Second: 9,568.43746

Timestep Collection Time: 4.44759
Timestep Consumption Time: 0.78106
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.22865

Cumulative Model Updates: 38,263
Cumulative Timesteps: 638,304,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,279.68193
Policy Entropy: 1.06412
Value Function Loss: 7.24422

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.06732
Value Function Update Magnitude: 0.09292

Collected Steps per Second: 11,224.32353
Overall Steps per Second: 9,720.21812

Timestep Collection Time: 4.45622
Timestep Consumption Time: 0.68955
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.14577

Cumulative Model Updates: 38,266
Cumulative Timesteps: 638,354,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 638354914...
Checkpoint 638354914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,057.25830
Policy Entropy: 1.06641
Value Function Loss: 7.28757

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.08526

Collected Steps per Second: 11,060.25219
Overall Steps per Second: 9,283.73125

Timestep Collection Time: 4.52214
Timestep Consumption Time: 0.86535
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.38749

Cumulative Model Updates: 38,269
Cumulative Timesteps: 638,404,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,496.26195
Policy Entropy: 1.06831
Value Function Loss: 7.10458

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.09170

Collected Steps per Second: 11,187.87543
Overall Steps per Second: 9,561.16026

Timestep Collection Time: 4.46948
Timestep Consumption Time: 0.76043
PPO Batch Consumption Time: 0.03775
Total Iteration Time: 5.22991

Cumulative Model Updates: 38,272
Cumulative Timesteps: 638,454,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 638454934...
Checkpoint 638454934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,587.51287
Policy Entropy: 1.07492
Value Function Loss: 6.86981

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.07865

Collected Steps per Second: 10,841.34433
Overall Steps per Second: 9,300.83498

Timestep Collection Time: 4.61345
Timestep Consumption Time: 0.76413
PPO Batch Consumption Time: 0.04548
Total Iteration Time: 5.37758

Cumulative Model Updates: 38,275
Cumulative Timesteps: 638,504,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,833.46922
Policy Entropy: 1.07984
Value Function Loss: 6.58804

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.07909

Collected Steps per Second: 11,123.63285
Overall Steps per Second: 9,458.29401

Timestep Collection Time: 4.49529
Timestep Consumption Time: 0.79149
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.28679

Cumulative Model Updates: 38,278
Cumulative Timesteps: 638,554,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 638554954...
Checkpoint 638554954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379,269.42573
Policy Entropy: 1.08398
Value Function Loss: 6.78861

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.07906

Collected Steps per Second: 11,023.35320
Overall Steps per Second: 9,487.57553

Timestep Collection Time: 4.53855
Timestep Consumption Time: 0.73467
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 5.27321

Cumulative Model Updates: 38,281
Cumulative Timesteps: 638,604,984

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,044.59850
Policy Entropy: 1.08656
Value Function Loss: 6.83628

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.07180
Value Function Update Magnitude: 0.06816

Collected Steps per Second: 11,421.81841
Overall Steps per Second: 9,678.11044

Timestep Collection Time: 4.37916
Timestep Consumption Time: 0.78900
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.16816

Cumulative Model Updates: 38,284
Cumulative Timesteps: 638,655,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 638655002...
Checkpoint 638655002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,733.57693
Policy Entropy: 1.09300
Value Function Loss: 7.01822

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.07043
Value Function Update Magnitude: 0.06344

Collected Steps per Second: 11,044.89622
Overall Steps per Second: 9,384.78370

Timestep Collection Time: 4.52698
Timestep Consumption Time: 0.80080
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 5.32777

Cumulative Model Updates: 38,287
Cumulative Timesteps: 638,705,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,641.36022
Policy Entropy: 1.08527
Value Function Loss: 7.03948

Mean KL Divergence: 0.03051
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.07347
Value Function Update Magnitude: 0.06545

Collected Steps per Second: 11,041.25782
Overall Steps per Second: 9,601.22602

Timestep Collection Time: 4.52956
Timestep Consumption Time: 0.67936
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.20892

Cumulative Model Updates: 38,290
Cumulative Timesteps: 638,755,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 638755014...
Checkpoint 638755014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,622.32765
Policy Entropy: 1.10376
Value Function Loss: 7.22736

Mean KL Divergence: 0.02693
SB3 Clip Fraction: 0.15776
Policy Update Magnitude: 0.06065
Value Function Update Magnitude: 0.07478

Collected Steps per Second: 10,694.58101
Overall Steps per Second: 9,214.01474

Timestep Collection Time: 4.67751
Timestep Consumption Time: 0.75161
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 5.42912

Cumulative Model Updates: 38,293
Cumulative Timesteps: 638,805,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362,170.03804
Policy Entropy: 1.10871
Value Function Loss: 7.28521

Mean KL Divergence: 0.02826
SB3 Clip Fraction: 0.15534
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.07870

Collected Steps per Second: 11,142.09876
Overall Steps per Second: 9,551.92908

Timestep Collection Time: 4.48874
Timestep Consumption Time: 0.74727
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.23601

Cumulative Model Updates: 38,296
Cumulative Timesteps: 638,855,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 638855052...
Checkpoint 638855052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,225.67920
Policy Entropy: 1.09944
Value Function Loss: 7.56260

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.07654

Collected Steps per Second: 11,082.04156
Overall Steps per Second: 9,460.91778

Timestep Collection Time: 4.51343
Timestep Consumption Time: 0.77337
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.28680

Cumulative Model Updates: 38,299
Cumulative Timesteps: 638,905,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,478.72132
Policy Entropy: 1.09085
Value Function Loss: 7.54889

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.09182

Collected Steps per Second: 10,794.01638
Overall Steps per Second: 9,292.90235

Timestep Collection Time: 4.63442
Timestep Consumption Time: 0.74861
PPO Batch Consumption Time: 0.03758
Total Iteration Time: 5.38303

Cumulative Model Updates: 38,302
Cumulative Timesteps: 638,955,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 638955094...
Checkpoint 638955094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,643.21265
Policy Entropy: 1.10565
Value Function Loss: 7.11783

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.04994
Value Function Update Magnitude: 0.11056

Collected Steps per Second: 10,815.33151
Overall Steps per Second: 9,367.37010

Timestep Collection Time: 4.62473
Timestep Consumption Time: 0.71487
PPO Batch Consumption Time: 0.03981
Total Iteration Time: 5.33960

Cumulative Model Updates: 38,305
Cumulative Timesteps: 639,005,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,943.32698
Policy Entropy: 1.11168
Value Function Loss: 6.87118

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.10627

Collected Steps per Second: 11,036.16961
Overall Steps per Second: 9,335.44790

Timestep Collection Time: 4.53291
Timestep Consumption Time: 0.82580
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.35871

Cumulative Model Updates: 38,308
Cumulative Timesteps: 639,055,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 639055138...
Checkpoint 639055138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,033.58691
Policy Entropy: 1.09453
Value Function Loss: 6.64284

Mean KL Divergence: 0.03318
SB3 Clip Fraction: 0.14954
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.09325

Collected Steps per Second: 10,790.98284
Overall Steps per Second: 9,406.31587

Timestep Collection Time: 4.63517
Timestep Consumption Time: 0.68232
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.31749

Cumulative Model Updates: 38,311
Cumulative Timesteps: 639,105,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,187.07741
Policy Entropy: 1.10719
Value Function Loss: 6.88739

Mean KL Divergence: 0.02711
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.07933

Collected Steps per Second: 11,380.51263
Overall Steps per Second: 9,631.09534

Timestep Collection Time: 4.39348
Timestep Consumption Time: 0.79804
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.19152

Cumulative Model Updates: 38,314
Cumulative Timesteps: 639,155,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 639155156...
Checkpoint 639155156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,059.38800
Policy Entropy: 1.11358
Value Function Loss: 6.76208

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.07530

Collected Steps per Second: 11,419.54341
Overall Steps per Second: 9,747.63522

Timestep Collection Time: 4.37951
Timestep Consumption Time: 0.75117
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.13068

Cumulative Model Updates: 38,317
Cumulative Timesteps: 639,205,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,285.65377
Policy Entropy: 1.09247
Value Function Loss: 7.15035

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.07211

Collected Steps per Second: 11,074.06884
Overall Steps per Second: 9,659.28327

Timestep Collection Time: 4.51505
Timestep Consumption Time: 0.66132
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.17637

Cumulative Model Updates: 38,320
Cumulative Timesteps: 639,255,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 639255168...
Checkpoint 639255168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,185.53923
Policy Entropy: 1.10111
Value Function Loss: 7.08118

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.07122

Collected Steps per Second: 11,341.46006
Overall Steps per Second: 9,601.66180

Timestep Collection Time: 4.40878
Timestep Consumption Time: 0.79886
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.20764

Cumulative Model Updates: 38,323
Cumulative Timesteps: 639,305,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,259.88173
Policy Entropy: 1.10638
Value Function Loss: 7.18732

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.07235

Collected Steps per Second: 10,883.62472
Overall Steps per Second: 9,383.77965

Timestep Collection Time: 4.59700
Timestep Consumption Time: 0.73476
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.33175

Cumulative Model Updates: 38,326
Cumulative Timesteps: 639,355,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 639355202...
Checkpoint 639355202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,266.64558
Policy Entropy: 1.11065
Value Function Loss: 7.03874

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.08322

Collected Steps per Second: 11,548.62035
Overall Steps per Second: 9,784.54958

Timestep Collection Time: 4.33125
Timestep Consumption Time: 0.78089
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.11214

Cumulative Model Updates: 38,329
Cumulative Timesteps: 639,405,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,017.51219
Policy Entropy: 1.11022
Value Function Loss: 6.90377

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.06371
Value Function Update Magnitude: 0.07718

Collected Steps per Second: 11,252.60572
Overall Steps per Second: 9,571.97556

Timestep Collection Time: 4.44555
Timestep Consumption Time: 0.78054
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.22609

Cumulative Model Updates: 38,332
Cumulative Timesteps: 639,455,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 639455246...
Checkpoint 639455246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,448.29677
Policy Entropy: 1.10952
Value Function Loss: 7.12719

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.06191
Value Function Update Magnitude: 0.07783

Collected Steps per Second: 11,055.70269
Overall Steps per Second: 9,584.40082

Timestep Collection Time: 4.52454
Timestep Consumption Time: 0.69456
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.21911

Cumulative Model Updates: 38,335
Cumulative Timesteps: 639,505,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,215.43955
Policy Entropy: 1.11269
Value Function Loss: 6.99617

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.07219

Collected Steps per Second: 11,195.24968
Overall Steps per Second: 9,463.08396

Timestep Collection Time: 4.46815
Timestep Consumption Time: 0.81787
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.28601

Cumulative Model Updates: 38,338
Cumulative Timesteps: 639,555,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 639555290...
Checkpoint 639555290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,276.13147
Policy Entropy: 1.11117
Value Function Loss: 7.18981

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.08468

Collected Steps per Second: 11,155.69513
Overall Steps per Second: 9,488.04293

Timestep Collection Time: 4.48327
Timestep Consumption Time: 0.78800
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.27127

Cumulative Model Updates: 38,341
Cumulative Timesteps: 639,605,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,117.68800
Policy Entropy: 1.10796
Value Function Loss: 7.32697

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.07715

Collected Steps per Second: 10,998.84365
Overall Steps per Second: 9,369.07091

Timestep Collection Time: 4.54630
Timestep Consumption Time: 0.79084
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.33714

Cumulative Model Updates: 38,344
Cumulative Timesteps: 639,655,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 639655308...
Checkpoint 639655308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,299.79882
Policy Entropy: 1.10662
Value Function Loss: 7.13396

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.06188
Value Function Update Magnitude: 0.07984

Collected Steps per Second: 11,003.70509
Overall Steps per Second: 9,419.64409

Timestep Collection Time: 4.54574
Timestep Consumption Time: 0.76444
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 5.31018

Cumulative Model Updates: 38,347
Cumulative Timesteps: 639,705,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,078.28779
Policy Entropy: 1.11154
Value Function Loss: 7.13002

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.07071

Collected Steps per Second: 10,973.47366
Overall Steps per Second: 9,538.56632

Timestep Collection Time: 4.55790
Timestep Consumption Time: 0.68565
PPO Batch Consumption Time: 0.03869
Total Iteration Time: 5.24356

Cumulative Model Updates: 38,350
Cumulative Timesteps: 639,755,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 639755344...
Checkpoint 639755344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,305.07772
Policy Entropy: 1.12120
Value Function Loss: 6.76104

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.07168

Collected Steps per Second: 11,001.19786
Overall Steps per Second: 9,396.51387

Timestep Collection Time: 4.54678
Timestep Consumption Time: 0.77647
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.32325

Cumulative Model Updates: 38,353
Cumulative Timesteps: 639,805,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420,667.07555
Policy Entropy: 1.10803
Value Function Loss: 7.26848

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.07096

Collected Steps per Second: 10,911.28565
Overall Steps per Second: 9,343.70461

Timestep Collection Time: 4.58369
Timestep Consumption Time: 0.76900
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 5.35269

Cumulative Model Updates: 38,356
Cumulative Timesteps: 639,855,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 639855378...
Checkpoint 639855378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,877.87031
Policy Entropy: 1.11952
Value Function Loss: 7.20044

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.07921

Collected Steps per Second: 11,354.05790
Overall Steps per Second: 9,702.39195

Timestep Collection Time: 4.40477
Timestep Consumption Time: 0.74984
PPO Batch Consumption Time: 0.03822
Total Iteration Time: 5.15461

Cumulative Model Updates: 38,359
Cumulative Timesteps: 639,905,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,415.34025
Policy Entropy: 1.12080
Value Function Loss: 7.27736

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.07588
Value Function Update Magnitude: 0.07519

Collected Steps per Second: 10,595.70861
Overall Steps per Second: 9,071.09449

Timestep Collection Time: 4.72002
Timestep Consumption Time: 0.79331
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 5.51334

Cumulative Model Updates: 38,362
Cumulative Timesteps: 639,955,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 639955402...
Checkpoint 639955402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,978.63792
Policy Entropy: 1.12698
Value Function Loss: 6.79659

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.09187
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.06817

Collected Steps per Second: 11,255.00762
Overall Steps per Second: 9,637.76084

Timestep Collection Time: 4.44318
Timestep Consumption Time: 0.74558
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.18876

Cumulative Model Updates: 38,365
Cumulative Timesteps: 640,005,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,686.95386
Policy Entropy: 1.11146
Value Function Loss: 6.78937

Mean KL Divergence: 0.03427
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.06932
Value Function Update Magnitude: 0.05926

Collected Steps per Second: 11,071.03316
Overall Steps per Second: 9,452.19356

Timestep Collection Time: 4.51864
Timestep Consumption Time: 0.77389
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 5.29253

Cumulative Model Updates: 38,368
Cumulative Timesteps: 640,055,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 640055436...
Checkpoint 640055436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,597.70291
Policy Entropy: 1.12230
Value Function Loss: 6.55141

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.11810
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.05807

Collected Steps per Second: 10,721.61177
Overall Steps per Second: 9,313.22750

Timestep Collection Time: 4.66422
Timestep Consumption Time: 0.70534
PPO Batch Consumption Time: 0.03925
Total Iteration Time: 5.36957

Cumulative Model Updates: 38,371
Cumulative Timesteps: 640,105,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,164.78598
Policy Entropy: 1.12187
Value Function Loss: 6.74301

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.06422

Collected Steps per Second: 10,783.53598
Overall Steps per Second: 9,221.10587

Timestep Collection Time: 4.63744
Timestep Consumption Time: 0.78577
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.42321

Cumulative Model Updates: 38,374
Cumulative Timesteps: 640,155,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 640155452...
Checkpoint 640155452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,112.05525
Policy Entropy: 1.11958
Value Function Loss: 6.69572

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.06942
Value Function Update Magnitude: 0.06680

Collected Steps per Second: 10,656.12865
Overall Steps per Second: 9,270.05335

Timestep Collection Time: 4.69401
Timestep Consumption Time: 0.70186
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.39587

Cumulative Model Updates: 38,377
Cumulative Timesteps: 640,205,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,062.63629
Policy Entropy: 1.10980
Value Function Loss: 7.33878

Mean KL Divergence: 0.03287
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.06260
Value Function Update Magnitude: 0.07177

Collected Steps per Second: 11,631.61561
Overall Steps per Second: 9,880.28896

Timestep Collection Time: 4.29983
Timestep Consumption Time: 0.76217
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.06200

Cumulative Model Updates: 38,380
Cumulative Timesteps: 640,255,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 640255486...
Checkpoint 640255486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,259.68703
Policy Entropy: 1.12617
Value Function Loss: 7.38687

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.06505

Collected Steps per Second: 11,803.22592
Overall Steps per Second: 10,041.66972

Timestep Collection Time: 4.23782
Timestep Consumption Time: 0.74342
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 4.98124

Cumulative Model Updates: 38,383
Cumulative Timesteps: 640,305,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,748.92724
Policy Entropy: 1.12517
Value Function Loss: 7.14383

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.06938

Collected Steps per Second: 11,806.62100
Overall Steps per Second: 9,966.20875

Timestep Collection Time: 4.23576
Timestep Consumption Time: 0.78220
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.01796

Cumulative Model Updates: 38,386
Cumulative Timesteps: 640,355,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 640355516...
Checkpoint 640355516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,179.53451
Policy Entropy: 1.11625
Value Function Loss: 7.06231

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.11645
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.06643

Collected Steps per Second: 11,595.81344
Overall Steps per Second: 9,885.25766

Timestep Collection Time: 4.31432
Timestep Consumption Time: 0.74655
PPO Batch Consumption Time: 0.03389
Total Iteration Time: 5.06087

Cumulative Model Updates: 38,389
Cumulative Timesteps: 640,405,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,352.20403
Policy Entropy: 1.10516
Value Function Loss: 7.01410

Mean KL Divergence: 0.03322
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.06753

Collected Steps per Second: 11,798.69643
Overall Steps per Second: 10,153.35440

Timestep Collection Time: 4.23793
Timestep Consumption Time: 0.68675
PPO Batch Consumption Time: 0.03870
Total Iteration Time: 4.92468

Cumulative Model Updates: 38,392
Cumulative Timesteps: 640,455,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 640455546...
Checkpoint 640455546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,984.77969
Policy Entropy: 1.11962
Value Function Loss: 7.35083

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.06366

Collected Steps per Second: 11,207.87909
Overall Steps per Second: 9,510.62438

Timestep Collection Time: 4.46293
Timestep Consumption Time: 0.79645
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.25938

Cumulative Model Updates: 38,395
Cumulative Timesteps: 640,505,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,568.93394
Policy Entropy: 1.12848
Value Function Loss: 7.02263

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.07421

Collected Steps per Second: 11,274.57533
Overall Steps per Second: 9,779.11511

Timestep Collection Time: 4.43724
Timestep Consumption Time: 0.67856
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.11580

Cumulative Model Updates: 38,398
Cumulative Timesteps: 640,555,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 640555594...
Checkpoint 640555594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,124.99514
Policy Entropy: 1.10119
Value Function Loss: 6.79627

Mean KL Divergence: 0.05938
SB3 Clip Fraction: 0.18237
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.10839

Collected Steps per Second: 11,362.63056
Overall Steps per Second: 9,637.94033

Timestep Collection Time: 4.40285
Timestep Consumption Time: 0.78788
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.19074

Cumulative Model Updates: 38,401
Cumulative Timesteps: 640,605,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,462.40152
Policy Entropy: 1.12388
Value Function Loss: 7.15039

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.11539

Collected Steps per Second: 11,094.48816
Overall Steps per Second: 9,474.51149

Timestep Collection Time: 4.50782
Timestep Consumption Time: 0.77076
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.27858

Cumulative Model Updates: 38,404
Cumulative Timesteps: 640,655,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 640655634...
Checkpoint 640655634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,138.69174
Policy Entropy: 1.10268
Value Function Loss: 7.55705

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.09762

Collected Steps per Second: 11,159.29563
Overall Steps per Second: 9,645.14820

Timestep Collection Time: 4.48111
Timestep Consumption Time: 0.70347
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.18458

Cumulative Model Updates: 38,407
Cumulative Timesteps: 640,705,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,158.06211
Policy Entropy: 1.09631
Value Function Loss: 8.28777

Mean KL Divergence: 0.03846
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.08759

Collected Steps per Second: 11,132.18100
Overall Steps per Second: 9,450.39327

Timestep Collection Time: 4.49256
Timestep Consumption Time: 0.79949
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.29205

Cumulative Model Updates: 38,410
Cumulative Timesteps: 640,755,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 640755652...
Checkpoint 640755652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,717.81686
Policy Entropy: 1.10978
Value Function Loss: 7.91143

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.08971

Collected Steps per Second: 10,656.69592
Overall Steps per Second: 9,263.74272

Timestep Collection Time: 4.69245
Timestep Consumption Time: 0.70559
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 5.39803

Cumulative Model Updates: 38,413
Cumulative Timesteps: 640,805,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342,366.95543
Policy Entropy: 1.11185
Value Function Loss: 7.60015

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.08523

Collected Steps per Second: 10,844.19900
Overall Steps per Second: 9,287.44846

Timestep Collection Time: 4.61260
Timestep Consumption Time: 0.77316
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.38576

Cumulative Model Updates: 38,416
Cumulative Timesteps: 640,855,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 640855678...
Checkpoint 640855678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,596.67106
Policy Entropy: 1.10431
Value Function Loss: 7.28958

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.08298

Collected Steps per Second: 11,275.54209
Overall Steps per Second: 9,658.11266

Timestep Collection Time: 4.43438
Timestep Consumption Time: 0.74262
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.17699

Cumulative Model Updates: 38,419
Cumulative Timesteps: 640,905,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410,222.32322
Policy Entropy: 1.10063
Value Function Loss: 7.64211

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.08058

Collected Steps per Second: 10,898.65959
Overall Steps per Second: 9,508.66842

Timestep Collection Time: 4.58919
Timestep Consumption Time: 0.67085
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.26004

Cumulative Model Updates: 38,422
Cumulative Timesteps: 640,955,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 640955694...
Checkpoint 640955694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,479.43350
Policy Entropy: 1.11208
Value Function Loss: 7.58186

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.07962

Collected Steps per Second: 11,099.69673
Overall Steps per Second: 9,436.72519

Timestep Collection Time: 4.50679
Timestep Consumption Time: 0.79420
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 5.30099

Cumulative Model Updates: 38,425
Cumulative Timesteps: 641,005,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,574.45857
Policy Entropy: 1.11550
Value Function Loss: 7.66687

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.07833

Collected Steps per Second: 10,839.10522
Overall Steps per Second: 9,199.20112

Timestep Collection Time: 4.61514
Timestep Consumption Time: 0.82272
PPO Batch Consumption Time: 0.04389
Total Iteration Time: 5.43786

Cumulative Model Updates: 38,428
Cumulative Timesteps: 641,055,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 641055742...
Checkpoint 641055742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,783.03489
Policy Entropy: 1.11809
Value Function Loss: 7.40428

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.08978

Collected Steps per Second: 11,016.13021
Overall Steps per Second: 9,336.18323

Timestep Collection Time: 4.54080
Timestep Consumption Time: 0.81707
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 5.35786

Cumulative Model Updates: 38,431
Cumulative Timesteps: 641,105,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,595.86447
Policy Entropy: 1.10474
Value Function Loss: 7.73249

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.06464
Value Function Update Magnitude: 0.08221

Collected Steps per Second: 10,977.57871
Overall Steps per Second: 9,314.86966

Timestep Collection Time: 4.55583
Timestep Consumption Time: 0.81322
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.36905

Cumulative Model Updates: 38,434
Cumulative Timesteps: 641,155,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 641155776...
Checkpoint 641155776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,408.73258
Policy Entropy: 1.10836
Value Function Loss: 7.57981

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.08059

Collected Steps per Second: 10,926.16319
Overall Steps per Second: 9,536.38337

Timestep Collection Time: 4.57690
Timestep Consumption Time: 0.66701
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.24392

Cumulative Model Updates: 38,437
Cumulative Timesteps: 641,205,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,459.95462
Policy Entropy: 1.09789
Value Function Loss: 7.46482

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.08421

Collected Steps per Second: 11,053.49378
Overall Steps per Second: 9,420.22701

Timestep Collection Time: 4.52509
Timestep Consumption Time: 0.78455
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.30964

Cumulative Model Updates: 38,440
Cumulative Timesteps: 641,255,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 641255802...
Checkpoint 641255802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432,368.25684
Policy Entropy: 1.10030
Value Function Loss: 6.95278

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.08719

Collected Steps per Second: 10,916.41023
Overall Steps per Second: 9,321.17855

Timestep Collection Time: 4.58264
Timestep Consumption Time: 0.78428
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.36692

Cumulative Model Updates: 38,443
Cumulative Timesteps: 641,305,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,908.13767
Policy Entropy: 1.10450
Value Function Loss: 6.92092

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.08830

Collected Steps per Second: 10,772.07603
Overall Steps per Second: 9,245.34506

Timestep Collection Time: 4.64330
Timestep Consumption Time: 0.76677
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.41007

Cumulative Model Updates: 38,446
Cumulative Timesteps: 641,355,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 641355846...
Checkpoint 641355846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,227.28779
Policy Entropy: 1.09901
Value Function Loss: 6.77928

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.08243

Collected Steps per Second: 11,020.54232
Overall Steps per Second: 9,460.68730

Timestep Collection Time: 4.53880
Timestep Consumption Time: 0.74835
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.28714

Cumulative Model Updates: 38,449
Cumulative Timesteps: 641,405,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,602.16299
Policy Entropy: 1.10597
Value Function Loss: 6.85340

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.08995

Collected Steps per Second: 11,466.21212
Overall Steps per Second: 9,945.93131

Timestep Collection Time: 4.36081
Timestep Consumption Time: 0.66657
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 5.02738

Cumulative Model Updates: 38,452
Cumulative Timesteps: 641,455,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 641455868...
Checkpoint 641455868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,486.17303
Policy Entropy: 1.09300
Value Function Loss: 6.97067

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.08032

Collected Steps per Second: 11,373.18874
Overall Steps per Second: 9,664.75854

Timestep Collection Time: 4.39824
Timestep Consumption Time: 0.77747
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 5.17571

Cumulative Model Updates: 38,455
Cumulative Timesteps: 641,505,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329,176.62281
Policy Entropy: 1.10835
Value Function Loss: 7.08060

Mean KL Divergence: 0.02601
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.07742

Collected Steps per Second: 11,503.60697
Overall Steps per Second: 9,833.34050

Timestep Collection Time: 4.34907
Timestep Consumption Time: 0.73872
PPO Batch Consumption Time: 0.03831
Total Iteration Time: 5.08779

Cumulative Model Updates: 38,458
Cumulative Timesteps: 641,555,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 641555920...
Checkpoint 641555920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,392.11814
Policy Entropy: 1.10465
Value Function Loss: 7.02198

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 11,653.92069
Overall Steps per Second: 9,886.55469

Timestep Collection Time: 4.29143
Timestep Consumption Time: 0.76716
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.05859

Cumulative Model Updates: 38,461
Cumulative Timesteps: 641,605,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,457.01040
Policy Entropy: 1.10074
Value Function Loss: 7.04842

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.07528

Collected Steps per Second: 10,895.79040
Overall Steps per Second: 9,334.63709

Timestep Collection Time: 4.59113
Timestep Consumption Time: 0.76783
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.35897

Cumulative Model Updates: 38,464
Cumulative Timesteps: 641,655,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 641655956...
Checkpoint 641655956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,835.04672
Policy Entropy: 1.08913
Value Function Loss: 6.88123

Mean KL Divergence: 0.03253
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.08263

Collected Steps per Second: 11,340.71049
Overall Steps per Second: 9,826.89440

Timestep Collection Time: 4.41066
Timestep Consumption Time: 0.67945
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.09011

Cumulative Model Updates: 38,467
Cumulative Timesteps: 641,705,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,936.08088
Policy Entropy: 1.09769
Value Function Loss: 7.17238

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.08383

Collected Steps per Second: 11,536.82642
Overall Steps per Second: 9,754.53836

Timestep Collection Time: 4.33395
Timestep Consumption Time: 0.79187
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.12582

Cumulative Model Updates: 38,470
Cumulative Timesteps: 641,755,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 641755976...
Checkpoint 641755976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403,651.41840
Policy Entropy: 1.09261
Value Function Loss: 6.94107

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.07297

Collected Steps per Second: 11,279.19976
Overall Steps per Second: 9,561.94987

Timestep Collection Time: 4.43294
Timestep Consumption Time: 0.79612
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.22906

Cumulative Model Updates: 38,473
Cumulative Timesteps: 641,805,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,244.05236
Policy Entropy: 1.08306
Value Function Loss: 6.66909

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.06368

Collected Steps per Second: 11,445.34371
Overall Steps per Second: 9,733.42416

Timestep Collection Time: 4.36911
Timestep Consumption Time: 0.76844
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.13755

Cumulative Model Updates: 38,476
Cumulative Timesteps: 641,855,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 641855982...
Checkpoint 641855982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,605.84642
Policy Entropy: 1.08223
Value Function Loss: 6.49626

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.06276

Collected Steps per Second: 11,175.66693
Overall Steps per Second: 9,617.80746

Timestep Collection Time: 4.47454
Timestep Consumption Time: 0.72477
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.19931

Cumulative Model Updates: 38,479
Cumulative Timesteps: 641,905,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481,030.09722
Policy Entropy: 1.08437
Value Function Loss: 6.73745

Mean KL Divergence: 0.03003
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.07010

Collected Steps per Second: 10,517.66704
Overall Steps per Second: 9,174.45325

Timestep Collection Time: 4.75676
Timestep Consumption Time: 0.69643
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 5.45319

Cumulative Model Updates: 38,482
Cumulative Timesteps: 641,956,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 641956018...
Checkpoint 641956018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396,223.73813
Policy Entropy: 1.11039
Value Function Loss: 6.94304

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.08538

Collected Steps per Second: 10,988.48017
Overall Steps per Second: 9,386.53538

Timestep Collection Time: 4.55240
Timestep Consumption Time: 0.77693
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.32934

Cumulative Model Updates: 38,485
Cumulative Timesteps: 642,006,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,119.80545
Policy Entropy: 1.11132
Value Function Loss: 7.21960

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.07658

Collected Steps per Second: 11,221.36228
Overall Steps per Second: 9,580.42214

Timestep Collection Time: 4.45757
Timestep Consumption Time: 0.76349
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 5.22106

Cumulative Model Updates: 38,488
Cumulative Timesteps: 642,056,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 642056062...
Checkpoint 642056062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,108.79650
Policy Entropy: 1.08986
Value Function Loss: 7.16455

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.04400
Value Function Update Magnitude: 0.07484

Collected Steps per Second: 10,821.48073
Overall Steps per Second: 9,276.68045

Timestep Collection Time: 4.62173
Timestep Consumption Time: 0.76963
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.39137

Cumulative Model Updates: 38,491
Cumulative Timesteps: 642,106,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,997.93165
Policy Entropy: 1.08311
Value Function Loss: 7.55265

Mean KL Divergence: 0.03194
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.07040

Collected Steps per Second: 11,057.11965
Overall Steps per Second: 9,419.91015

Timestep Collection Time: 4.52469
Timestep Consumption Time: 0.78640
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 5.31109

Cumulative Model Updates: 38,494
Cumulative Timesteps: 642,156,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 642156106...
Checkpoint 642156106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,178.92177
Policy Entropy: 1.09112
Value Function Loss: 7.57122

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.08312

Collected Steps per Second: 10,253.67492
Overall Steps per Second: 8,979.48475

Timestep Collection Time: 4.87747
Timestep Consumption Time: 0.69211
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.56958

Cumulative Model Updates: 38,497
Cumulative Timesteps: 642,206,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,979.91380
Policy Entropy: 1.10172
Value Function Loss: 7.63429

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.07823

Collected Steps per Second: 11,108.14787
Overall Steps per Second: 9,449.33809

Timestep Collection Time: 4.50408
Timestep Consumption Time: 0.79068
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.29476

Cumulative Model Updates: 38,500
Cumulative Timesteps: 642,256,150

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 642256150...
Checkpoint 642256150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,207.47089
Policy Entropy: 1.07373
Value Function Loss: 7.54526

Mean KL Divergence: 0.03071
SB3 Clip Fraction: 0.15915
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 10,942.25089
Overall Steps per Second: 9,352.90935

Timestep Collection Time: 4.57072
Timestep Consumption Time: 0.77670
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 5.34743

Cumulative Model Updates: 38,503
Cumulative Timesteps: 642,306,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,139.48200
Policy Entropy: 1.09192
Value Function Loss: 7.15391

Mean KL Divergence: 0.03148
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.07357

Collected Steps per Second: 11,057.47597
Overall Steps per Second: 9,414.82980

Timestep Collection Time: 4.52382
Timestep Consumption Time: 0.78929
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 5.31311

Cumulative Model Updates: 38,506
Cumulative Timesteps: 642,356,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 642356186...
Checkpoint 642356186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,457.56759
Policy Entropy: 1.09811
Value Function Loss: 7.13570

Mean KL Divergence: 0.02767
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.07410

Collected Steps per Second: 11,052.56037
Overall Steps per Second: 9,420.79798

Timestep Collection Time: 4.52529
Timestep Consumption Time: 0.78382
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.30910

Cumulative Model Updates: 38,509
Cumulative Timesteps: 642,406,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407,168.80028
Policy Entropy: 1.08816
Value Function Loss: 6.69513

Mean KL Divergence: 0.02544
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.08183

Collected Steps per Second: 10,706.75155
Overall Steps per Second: 9,305.72335

Timestep Collection Time: 4.67219
Timestep Consumption Time: 0.70342
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.37562

Cumulative Model Updates: 38,512
Cumulative Timesteps: 642,456,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 642456226...
Checkpoint 642456226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,031.97857
Policy Entropy: 1.08601
Value Function Loss: 6.65995

Mean KL Divergence: 0.02649
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.07516

Collected Steps per Second: 10,583.65898
Overall Steps per Second: 9,091.33154

Timestep Collection Time: 4.72672
Timestep Consumption Time: 0.77588
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.50260

Cumulative Model Updates: 38,515
Cumulative Timesteps: 642,506,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,518.44637
Policy Entropy: 1.09913
Value Function Loss: 6.76883

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.07660

Collected Steps per Second: 11,996.62863
Overall Steps per Second: 10,172.59495

Timestep Collection Time: 4.17017
Timestep Consumption Time: 0.74775
PPO Batch Consumption Time: 0.03336
Total Iteration Time: 4.91792

Cumulative Model Updates: 38,518
Cumulative Timesteps: 642,556,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 642556280...
Checkpoint 642556280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,039.06232
Policy Entropy: 1.10105
Value Function Loss: 6.67119

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.07188

Collected Steps per Second: 11,918.17676
Overall Steps per Second: 10,056.22828

Timestep Collection Time: 4.19578
Timestep Consumption Time: 0.77686
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.97264

Cumulative Model Updates: 38,521
Cumulative Timesteps: 642,606,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,547.27552
Policy Entropy: 1.09640
Value Function Loss: 6.95488

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.08722

Collected Steps per Second: 11,981.09091
Overall Steps per Second: 10,106.82919

Timestep Collection Time: 4.17558
Timestep Consumption Time: 0.77434
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.94992

Cumulative Model Updates: 38,524
Cumulative Timesteps: 642,656,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 642656314...
Checkpoint 642656314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,493.13408
Policy Entropy: 1.09389
Value Function Loss: 6.90174

Mean KL Divergence: 0.02887
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.07003
Value Function Update Magnitude: 0.08033

Collected Steps per Second: 11,850.65128
Overall Steps per Second: 10,189.89018

Timestep Collection Time: 4.22120
Timestep Consumption Time: 0.68798
PPO Batch Consumption Time: 0.03961
Total Iteration Time: 4.90918

Cumulative Model Updates: 38,527
Cumulative Timesteps: 642,706,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,028.15286
Policy Entropy: 1.09798
Value Function Loss: 7.52276

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.06375
Value Function Update Magnitude: 0.07308

Collected Steps per Second: 12,099.59902
Overall Steps per Second: 10,163.98298

Timestep Collection Time: 4.13386
Timestep Consumption Time: 0.78725
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.92110

Cumulative Model Updates: 38,530
Cumulative Timesteps: 642,756,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 642756356...
Checkpoint 642756356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,914.07351
Policy Entropy: 1.09280
Value Function Loss: 7.77007

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.06782
Value Function Update Magnitude: 0.07032

Collected Steps per Second: 11,064.13203
Overall Steps per Second: 9,446.57487

Timestep Collection Time: 4.52019
Timestep Consumption Time: 0.77400
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.29419

Cumulative Model Updates: 38,533
Cumulative Timesteps: 642,806,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,881.24283
Policy Entropy: 1.09564
Value Function Loss: 7.86073

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.07042
Value Function Update Magnitude: 0.06979

Collected Steps per Second: 11,498.95148
Overall Steps per Second: 9,703.83030

Timestep Collection Time: 4.35101
Timestep Consumption Time: 0.80490
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.15590

Cumulative Model Updates: 38,536
Cumulative Timesteps: 642,856,400

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 642856400...
Checkpoint 642856400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,236.55813
Policy Entropy: 1.10402
Value Function Loss: 7.67806

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.06766
Value Function Update Magnitude: 0.07966

Collected Steps per Second: 11,193.79613
Overall Steps per Second: 9,474.26453

Timestep Collection Time: 4.46694
Timestep Consumption Time: 0.81073
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.27767

Cumulative Model Updates: 38,539
Cumulative Timesteps: 642,906,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,561.33054
Policy Entropy: 1.10478
Value Function Loss: 7.43991

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.06962
Value Function Update Magnitude: 0.08260

Collected Steps per Second: 11,431.44883
Overall Steps per Second: 9,662.03038

Timestep Collection Time: 4.37617
Timestep Consumption Time: 0.80141
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.17759

Cumulative Model Updates: 38,542
Cumulative Timesteps: 642,956,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 642956428...
Checkpoint 642956428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,602.50119
Policy Entropy: 1.09808
Value Function Loss: 7.31487

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.06899
Value Function Update Magnitude: 0.09101

Collected Steps per Second: 11,132.45861
Overall Steps per Second: 9,417.64399

Timestep Collection Time: 4.49353
Timestep Consumption Time: 0.81821
PPO Batch Consumption Time: 0.04004
Total Iteration Time: 5.31173

Cumulative Model Updates: 38,545
Cumulative Timesteps: 643,006,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,687.86608
Policy Entropy: 1.10186
Value Function Loss: 7.27032

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.08817

Collected Steps per Second: 11,065.43721
Overall Steps per Second: 9,465.82967

Timestep Collection Time: 4.52074
Timestep Consumption Time: 0.76395
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.28469

Cumulative Model Updates: 38,548
Cumulative Timesteps: 643,056,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 643056476...
Checkpoint 643056476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447,092.70811
Policy Entropy: 1.09976
Value Function Loss: 6.87446

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.06372
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 11,040.02896
Overall Steps per Second: 9,408.82425

Timestep Collection Time: 4.53042
Timestep Consumption Time: 0.78544
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.31586

Cumulative Model Updates: 38,551
Cumulative Timesteps: 643,106,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,625.71427
Policy Entropy: 1.10528
Value Function Loss: 6.92053

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 10,775.06935
Overall Steps per Second: 9,300.85464

Timestep Collection Time: 4.64220
Timestep Consumption Time: 0.73580
PPO Batch Consumption Time: 0.03792
Total Iteration Time: 5.37800

Cumulative Model Updates: 38,554
Cumulative Timesteps: 643,156,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 643156512...
Checkpoint 643156512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,076.74543
Policy Entropy: 1.09458
Value Function Loss: 6.84166

Mean KL Divergence: 0.03354
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.06585
Value Function Update Magnitude: 0.09544

Collected Steps per Second: 10,964.58684
Overall Steps per Second: 9,387.40360

Timestep Collection Time: 4.56196
Timestep Consumption Time: 0.76646
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.32842

Cumulative Model Updates: 38,557
Cumulative Timesteps: 643,206,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,384.23574
Policy Entropy: 1.11656
Value Function Loss: 7.04189

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.11247
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.11119

Collected Steps per Second: 10,722.76965
Overall Steps per Second: 9,142.77851

Timestep Collection Time: 4.66428
Timestep Consumption Time: 0.80605
PPO Batch Consumption Time: 0.04415
Total Iteration Time: 5.47033

Cumulative Model Updates: 38,560
Cumulative Timesteps: 643,256,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 643256546...
Checkpoint 643256546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,800.59144
Policy Entropy: 1.11986
Value Function Loss: 7.05064

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.07081
Value Function Update Magnitude: 0.10548

Collected Steps per Second: 11,390.67322
Overall Steps per Second: 9,709.24933

Timestep Collection Time: 4.39131
Timestep Consumption Time: 0.76048
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.15179

Cumulative Model Updates: 38,563
Cumulative Timesteps: 643,306,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,795.40106
Policy Entropy: 1.11381
Value Function Loss: 7.03806

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.07613
Value Function Update Magnitude: 0.09604

Collected Steps per Second: 10,417.49356
Overall Steps per Second: 8,963.33798

Timestep Collection Time: 4.79962
Timestep Consumption Time: 0.77866
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 5.57828

Cumulative Model Updates: 38,566
Cumulative Timesteps: 643,356,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 643356566...
Checkpoint 643356566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,524.18112
Policy Entropy: 1.10073
Value Function Loss: 7.24187

Mean KL Divergence: 0.02797
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.06801
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 10,942.59417
Overall Steps per Second: 9,508.08608

Timestep Collection Time: 4.57131
Timestep Consumption Time: 0.68968
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.26100

Cumulative Model Updates: 38,569
Cumulative Timesteps: 643,406,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,340.72721
Policy Entropy: 1.10961
Value Function Loss: 7.10391

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.08368

Collected Steps per Second: 10,816.05322
Overall Steps per Second: 9,251.21533

Timestep Collection Time: 4.62424
Timestep Consumption Time: 0.78219
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.40642

Cumulative Model Updates: 38,572
Cumulative Timesteps: 643,456,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 643456604...
Checkpoint 643456604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,710.29372
Policy Entropy: 1.10811
Value Function Loss: 7.12838

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.07779

Collected Steps per Second: 11,002.11620
Overall Steps per Second: 9,450.04705

Timestep Collection Time: 4.54622
Timestep Consumption Time: 0.74667
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.29288

Cumulative Model Updates: 38,575
Cumulative Timesteps: 643,506,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,762.45217
Policy Entropy: 1.10177
Value Function Loss: 7.23257

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.07418

Collected Steps per Second: 11,240.66104
Overall Steps per Second: 9,553.51814

Timestep Collection Time: 4.44831
Timestep Consumption Time: 0.78557
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.23388

Cumulative Model Updates: 38,578
Cumulative Timesteps: 643,556,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 643556624...
Checkpoint 643556624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,168.39507
Policy Entropy: 1.08001
Value Function Loss: 7.04958

Mean KL Divergence: 0.03663
SB3 Clip Fraction: 0.17425
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.06477

Collected Steps per Second: 10,910.62075
Overall Steps per Second: 9,267.40296

Timestep Collection Time: 4.58324
Timestep Consumption Time: 0.81266
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.39590

Cumulative Model Updates: 38,581
Cumulative Timesteps: 643,606,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,767.17968
Policy Entropy: 1.09719
Value Function Loss: 7.04720

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.09002

Collected Steps per Second: 10,609.19583
Overall Steps per Second: 9,255.52133

Timestep Collection Time: 4.71346
Timestep Consumption Time: 0.68937
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 5.40283

Cumulative Model Updates: 38,584
Cumulative Timesteps: 643,656,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 643656636...
Checkpoint 643656636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,390.39160
Policy Entropy: 1.08694
Value Function Loss: 6.93468

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.10541

Collected Steps per Second: 11,268.87745
Overall Steps per Second: 9,584.99453

Timestep Collection Time: 4.43860
Timestep Consumption Time: 0.77977
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.21836

Cumulative Model Updates: 38,587
Cumulative Timesteps: 643,706,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,604.79457
Policy Entropy: 1.07694
Value Function Loss: 7.09606

Mean KL Divergence: 0.02674
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.10319

Collected Steps per Second: 11,333.78355
Overall Steps per Second: 9,712.29647

Timestep Collection Time: 4.41282
Timestep Consumption Time: 0.73673
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.14955

Cumulative Model Updates: 38,590
Cumulative Timesteps: 643,756,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 643756668...
Checkpoint 643756668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404,530.76265
Policy Entropy: 1.10262
Value Function Loss: 7.00278

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.09271

Collected Steps per Second: 11,838.95685
Overall Steps per Second: 10,022.57033

Timestep Collection Time: 4.22351
Timestep Consumption Time: 0.76543
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.98894

Cumulative Model Updates: 38,593
Cumulative Timesteps: 643,806,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,067.31786
Policy Entropy: 1.09222
Value Function Loss: 7.12186

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.08820

Collected Steps per Second: 11,397.43007
Overall Steps per Second: 9,781.67021

Timestep Collection Time: 4.38836
Timestep Consumption Time: 0.72488
PPO Batch Consumption Time: 0.03360
Total Iteration Time: 5.11324

Cumulative Model Updates: 38,596
Cumulative Timesteps: 643,856,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 643856686...
Checkpoint 643856686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,121.01334
Policy Entropy: 1.09007
Value Function Loss: 6.97725

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.06140
Value Function Update Magnitude: 0.08457

Collected Steps per Second: 11,316.29786
Overall Steps per Second: 9,635.83614

Timestep Collection Time: 4.41964
Timestep Consumption Time: 0.77077
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 5.19042

Cumulative Model Updates: 38,599
Cumulative Timesteps: 643,906,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,319.73160
Policy Entropy: 1.07199
Value Function Loss: 7.05580

Mean KL Divergence: 0.02844
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.07944

Collected Steps per Second: 11,136.95694
Overall Steps per Second: 9,402.07742

Timestep Collection Time: 4.49189
Timestep Consumption Time: 0.82885
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.32074

Cumulative Model Updates: 38,602
Cumulative Timesteps: 643,956,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 643956726...
Checkpoint 643956726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,573.61040
Policy Entropy: 1.08259
Value Function Loss: 7.05388

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.06677

Collected Steps per Second: 10,813.96156
Overall Steps per Second: 9,275.39032

Timestep Collection Time: 4.62421
Timestep Consumption Time: 0.76705
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.39126

Cumulative Model Updates: 38,605
Cumulative Timesteps: 644,006,732

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,455.76788
Policy Entropy: 1.09205
Value Function Loss: 6.88754

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.05314

Collected Steps per Second: 11,614.13182
Overall Steps per Second: 9,870.82489

Timestep Collection Time: 4.30527
Timestep Consumption Time: 0.76036
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.06564

Cumulative Model Updates: 38,608
Cumulative Timesteps: 644,056,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 644056734...
Checkpoint 644056734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,510.99611
Policy Entropy: 1.07927
Value Function Loss: 6.72642

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.05642

Collected Steps per Second: 11,197.49938
Overall Steps per Second: 9,488.46671

Timestep Collection Time: 4.46725
Timestep Consumption Time: 0.80463
PPO Batch Consumption Time: 0.04200
Total Iteration Time: 5.27187

Cumulative Model Updates: 38,611
Cumulative Timesteps: 644,106,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,929.05904
Policy Entropy: 1.07049
Value Function Loss: 6.72959

Mean KL Divergence: 0.03420
SB3 Clip Fraction: 0.16527
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.05433

Collected Steps per Second: 11,285.82062
Overall Steps per Second: 9,746.01758

Timestep Collection Time: 4.43158
Timestep Consumption Time: 0.70016
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.13174

Cumulative Model Updates: 38,614
Cumulative Timesteps: 644,156,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 644156770...
Checkpoint 644156770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422,307.69209
Policy Entropy: 1.07914
Value Function Loss: 6.81623

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.04885

Collected Steps per Second: 10,745.63674
Overall Steps per Second: 9,193.84035

Timestep Collection Time: 4.65566
Timestep Consumption Time: 0.78581
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.44147

Cumulative Model Updates: 38,617
Cumulative Timesteps: 644,206,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,459.04268
Policy Entropy: 1.08665
Value Function Loss: 7.17319

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.06041

Collected Steps per Second: 11,104.02366
Overall Steps per Second: 9,380.21408

Timestep Collection Time: 4.50467
Timestep Consumption Time: 0.82783
PPO Batch Consumption Time: 0.04543
Total Iteration Time: 5.33250

Cumulative Model Updates: 38,620
Cumulative Timesteps: 644,256,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 644256818...
Checkpoint 644256818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,565.84481
Policy Entropy: 1.06775
Value Function Loss: 6.88254

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.06362

Collected Steps per Second: 11,242.92908
Overall Steps per Second: 9,634.03683

Timestep Collection Time: 4.44813
Timestep Consumption Time: 0.74284
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.19097

Cumulative Model Updates: 38,623
Cumulative Timesteps: 644,306,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439,785.26699
Policy Entropy: 1.07396
Value Function Loss: 6.96594

Mean KL Divergence: 0.02435
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.05885

Collected Steps per Second: 10,825.81943
Overall Steps per Second: 9,315.23660

Timestep Collection Time: 4.61933
Timestep Consumption Time: 0.74908
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.36841

Cumulative Model Updates: 38,626
Cumulative Timesteps: 644,356,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 644356836...
Checkpoint 644356836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,404.47411
Policy Entropy: 1.09502
Value Function Loss: 6.89418

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.06205

Collected Steps per Second: 10,585.60610
Overall Steps per Second: 9,218.84861

Timestep Collection Time: 4.72340
Timestep Consumption Time: 0.70028
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.42367

Cumulative Model Updates: 38,629
Cumulative Timesteps: 644,406,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369,162.48085
Policy Entropy: 1.09884
Value Function Loss: 7.05756

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.06943

Collected Steps per Second: 11,021.14188
Overall Steps per Second: 9,398.76775

Timestep Collection Time: 4.53728
Timestep Consumption Time: 0.78321
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.32048

Cumulative Model Updates: 38,632
Cumulative Timesteps: 644,456,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 644456842...
Checkpoint 644456842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,361.40478
Policy Entropy: 1.10178
Value Function Loss: 6.78529

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.08112

Collected Steps per Second: 10,539.98761
Overall Steps per Second: 9,085.78248

Timestep Collection Time: 4.74422
Timestep Consumption Time: 0.75933
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.50354

Cumulative Model Updates: 38,635
Cumulative Timesteps: 644,506,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,153.55578
Policy Entropy: 1.09952
Value Function Loss: 7.24155

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.07558

Collected Steps per Second: 11,016.26377
Overall Steps per Second: 9,384.87563

Timestep Collection Time: 4.54056
Timestep Consumption Time: 0.78929
PPO Batch Consumption Time: 0.03343
Total Iteration Time: 5.32985

Cumulative Model Updates: 38,638
Cumulative Timesteps: 644,556,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 644556866...
Checkpoint 644556866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,964.19274
Policy Entropy: 1.09840
Value Function Loss: 7.27363

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.06544

Collected Steps per Second: 10,945.38223
Overall Steps per Second: 9,380.78335

Timestep Collection Time: 4.57033
Timestep Consumption Time: 0.76227
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 5.33260

Cumulative Model Updates: 38,641
Cumulative Timesteps: 644,606,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,450.51267
Policy Entropy: 1.10044
Value Function Loss: 7.56479

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.05761

Collected Steps per Second: 11,004.93541
Overall Steps per Second: 9,479.50236

Timestep Collection Time: 4.54523
Timestep Consumption Time: 0.73141
PPO Batch Consumption Time: 0.03809
Total Iteration Time: 5.27665

Cumulative Model Updates: 38,644
Cumulative Timesteps: 644,656,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 644656910...
Checkpoint 644656910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,168.78610
Policy Entropy: 1.11412
Value Function Loss: 6.95892

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.05798

Collected Steps per Second: 10,844.15574
Overall Steps per Second: 9,240.54830

Timestep Collection Time: 4.61262
Timestep Consumption Time: 0.80048
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.41310

Cumulative Model Updates: 38,647
Cumulative Timesteps: 644,706,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,026.58183
Policy Entropy: 1.11050
Value Function Loss: 7.07864

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.06158

Collected Steps per Second: 10,683.59708
Overall Steps per Second: 9,174.32842

Timestep Collection Time: 4.68232
Timestep Consumption Time: 0.77029
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 5.45261

Cumulative Model Updates: 38,650
Cumulative Timesteps: 644,756,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 644756954...
Checkpoint 644756954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,336.20773
Policy Entropy: 1.08877
Value Function Loss: 6.76651

Mean KL Divergence: 0.02369
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.07398

Collected Steps per Second: 11,558.28116
Overall Steps per Second: 9,662.85199

Timestep Collection Time: 4.32625
Timestep Consumption Time: 0.84862
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 5.17487

Cumulative Model Updates: 38,653
Cumulative Timesteps: 644,806,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,542.66804
Policy Entropy: 1.08861
Value Function Loss: 7.00939

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.09261

Collected Steps per Second: 11,904.66330
Overall Steps per Second: 10,090.63108

Timestep Collection Time: 4.20138
Timestep Consumption Time: 0.75530
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.95668

Cumulative Model Updates: 38,656
Cumulative Timesteps: 644,856,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 644856974...
Checkpoint 644856974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,384.43401
Policy Entropy: 1.09415
Value Function Loss: 6.57005

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.10975

Collected Steps per Second: 11,790.49886
Overall Steps per Second: 10,139.81002

Timestep Collection Time: 4.24087
Timestep Consumption Time: 0.69038
PPO Batch Consumption Time: 0.03925
Total Iteration Time: 4.93126

Cumulative Model Updates: 38,659
Cumulative Timesteps: 644,906,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,793.64770
Policy Entropy: 1.09842
Value Function Loss: 6.24898

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.10721

Collected Steps per Second: 11,535.76530
Overall Steps per Second: 9,757.48155

Timestep Collection Time: 4.33539
Timestep Consumption Time: 0.79012
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.12550

Cumulative Model Updates: 38,662
Cumulative Timesteps: 644,956,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 644956988...
Checkpoint 644956988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,735.90844
Policy Entropy: 1.07934
Value Function Loss: 5.94186

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.09129

Collected Steps per Second: 12,003.80036
Overall Steps per Second: 10,193.38427

Timestep Collection Time: 4.16635
Timestep Consumption Time: 0.73997
PPO Batch Consumption Time: 0.03373
Total Iteration Time: 4.90632

Cumulative Model Updates: 38,665
Cumulative Timesteps: 645,007,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,134.93378
Policy Entropy: 1.07107
Value Function Loss: 6.05585

Mean KL Divergence: 0.03427
SB3 Clip Fraction: 0.16820
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.08452

Collected Steps per Second: 11,514.37831
Overall Steps per Second: 9,748.44301

Timestep Collection Time: 4.34413
Timestep Consumption Time: 0.78694
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 5.13108

Cumulative Model Updates: 38,668
Cumulative Timesteps: 645,057,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 645057020...
Checkpoint 645057020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,333.25816
Policy Entropy: 1.08367
Value Function Loss: 6.33620

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.09515

Collected Steps per Second: 11,450.54574
Overall Steps per Second: 9,595.99293

Timestep Collection Time: 4.36905
Timestep Consumption Time: 0.84438
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 5.21343

Cumulative Model Updates: 38,671
Cumulative Timesteps: 645,107,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,587.96793
Policy Entropy: 1.09219
Value Function Loss: 6.46489

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.09897

Collected Steps per Second: 11,167.82349
Overall Steps per Second: 9,685.22684

Timestep Collection Time: 4.47876
Timestep Consumption Time: 0.68560
PPO Batch Consumption Time: 0.03732
Total Iteration Time: 5.16436

Cumulative Model Updates: 38,674
Cumulative Timesteps: 645,157,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 645157066...
Checkpoint 645157066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,667.71621
Policy Entropy: 1.06555
Value Function Loss: 6.61923

Mean KL Divergence: 0.03006
SB3 Clip Fraction: 0.15210
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.10186

Collected Steps per Second: 11,137.88272
Overall Steps per Second: 9,466.05647

Timestep Collection Time: 4.49116
Timestep Consumption Time: 0.79320
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.28435

Cumulative Model Updates: 38,677
Cumulative Timesteps: 645,207,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,091.09289
Policy Entropy: 1.08732
Value Function Loss: 6.57972

Mean KL Divergence: 0.03113
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.08273

Collected Steps per Second: 11,349.44698
Overall Steps per Second: 9,673.68032

Timestep Collection Time: 4.40638
Timestep Consumption Time: 0.76332
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.16970

Cumulative Model Updates: 38,680
Cumulative Timesteps: 645,257,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 645257098...
Checkpoint 645257098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394,504.80205
Policy Entropy: 1.08331
Value Function Loss: 6.47626

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.15364
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.07223

Collected Steps per Second: 11,361.93336
Overall Steps per Second: 9,632.34347

Timestep Collection Time: 4.40066
Timestep Consumption Time: 0.79019
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.19084

Cumulative Model Updates: 38,683
Cumulative Timesteps: 645,307,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,873.04508
Policy Entropy: 1.06885
Value Function Loss: 6.76069

Mean KL Divergence: 0.02955
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.07848

Collected Steps per Second: 10,817.12847
Overall Steps per Second: 9,226.88579

Timestep Collection Time: 4.62470
Timestep Consumption Time: 0.79706
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.42176

Cumulative Model Updates: 38,686
Cumulative Timesteps: 645,357,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 645357124...
Checkpoint 645357124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,070.60532
Policy Entropy: 1.06419
Value Function Loss: 6.89530

Mean KL Divergence: 0.03029
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.07539

Collected Steps per Second: 11,044.85850
Overall Steps per Second: 9,537.92796

Timestep Collection Time: 4.52754
Timestep Consumption Time: 0.71532
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 5.24286

Cumulative Model Updates: 38,689
Cumulative Timesteps: 645,407,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,208.08241
Policy Entropy: 1.08195
Value Function Loss: 6.73631

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.07755

Collected Steps per Second: 11,045.88731
Overall Steps per Second: 9,378.20977

Timestep Collection Time: 4.52911
Timestep Consumption Time: 0.80539
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.33449

Cumulative Model Updates: 38,692
Cumulative Timesteps: 645,457,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 645457158...
Checkpoint 645457158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,194.13555
Policy Entropy: 1.09427
Value Function Loss: 6.80893

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.07306

Collected Steps per Second: 10,961.74426
Overall Steps per Second: 9,378.39468

Timestep Collection Time: 4.56314
Timestep Consumption Time: 0.77039
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.33354

Cumulative Model Updates: 38,695
Cumulative Timesteps: 645,507,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,658.11560
Policy Entropy: 1.06952
Value Function Loss: 6.50334

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.06453

Collected Steps per Second: 11,216.64562
Overall Steps per Second: 9,574.34888

Timestep Collection Time: 4.45855
Timestep Consumption Time: 0.76478
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.22333

Cumulative Model Updates: 38,698
Cumulative Timesteps: 645,557,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 645557188...
Checkpoint 645557188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,609.69664
Policy Entropy: 1.07063
Value Function Loss: 6.78208

Mean KL Divergence: 0.02326
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.07648

Collected Steps per Second: 10,977.81874
Overall Steps per Second: 9,329.69836

Timestep Collection Time: 4.55683
Timestep Consumption Time: 0.80498
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.36180

Cumulative Model Updates: 38,701
Cumulative Timesteps: 645,607,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,401.66843
Policy Entropy: 1.08416
Value Function Loss: 6.67621

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.07132

Collected Steps per Second: 10,441.75845
Overall Steps per Second: 9,131.55725

Timestep Collection Time: 4.79000
Timestep Consumption Time: 0.68727
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.47727

Cumulative Model Updates: 38,704
Cumulative Timesteps: 645,657,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 645657228...
Checkpoint 645657228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419,700.22709
Policy Entropy: 1.10206
Value Function Loss: 7.07799

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 10,935.94039
Overall Steps per Second: 9,351.57798

Timestep Collection Time: 4.57226
Timestep Consumption Time: 0.77464
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 5.34691

Cumulative Model Updates: 38,707
Cumulative Timesteps: 645,707,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,331.08129
Policy Entropy: 1.09489
Value Function Loss: 6.93510

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.06479
Value Function Update Magnitude: 0.06803

Collected Steps per Second: 11,137.90082
Overall Steps per Second: 9,522.62700

Timestep Collection Time: 4.48954
Timestep Consumption Time: 0.76154
PPO Batch Consumption Time: 0.03849
Total Iteration Time: 5.25107

Cumulative Model Updates: 38,710
Cumulative Timesteps: 645,757,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 645757234...
Checkpoint 645757234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,635.83273
Policy Entropy: 1.09002
Value Function Loss: 6.54042

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.06065
Value Function Update Magnitude: 0.07531

Collected Steps per Second: 11,151.71495
Overall Steps per Second: 9,476.11873

Timestep Collection Time: 4.48595
Timestep Consumption Time: 0.79322
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.27917

Cumulative Model Updates: 38,713
Cumulative Timesteps: 645,807,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,299.14246
Policy Entropy: 1.07479
Value Function Loss: 6.48953

Mean KL Divergence: 0.02949
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.07090

Collected Steps per Second: 10,983.37834
Overall Steps per Second: 9,404.87384

Timestep Collection Time: 4.55488
Timestep Consumption Time: 0.76449
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.31937

Cumulative Model Updates: 38,716
Cumulative Timesteps: 645,857,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 645857288...
Checkpoint 645857288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,061.23071
Policy Entropy: 1.08924
Value Function Loss: 6.69158

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.06620

Collected Steps per Second: 10,604.61872
Overall Steps per Second: 9,258.75675

Timestep Collection Time: 4.71530
Timestep Consumption Time: 0.68542
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.40073

Cumulative Model Updates: 38,719
Cumulative Timesteps: 645,907,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410,580.19948
Policy Entropy: 1.09478
Value Function Loss: 6.83714

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.06575

Collected Steps per Second: 11,323.88561
Overall Steps per Second: 9,624.32444

Timestep Collection Time: 4.41721
Timestep Consumption Time: 0.78004
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.19725

Cumulative Model Updates: 38,722
Cumulative Timesteps: 645,957,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 645957312...
Checkpoint 645957312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,672.61297
Policy Entropy: 1.09623
Value Function Loss: 6.96254

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.06514

Collected Steps per Second: 11,179.94662
Overall Steps per Second: 9,615.06557

Timestep Collection Time: 4.47372
Timestep Consumption Time: 0.72811
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 5.20184

Cumulative Model Updates: 38,725
Cumulative Timesteps: 646,007,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,191.65941
Policy Entropy: 1.10284
Value Function Loss: 6.76053

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 11,625.85553
Overall Steps per Second: 9,874.90777

Timestep Collection Time: 4.30213
Timestep Consumption Time: 0.76282
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.06496

Cumulative Model Updates: 38,728
Cumulative Timesteps: 646,057,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 646057344...
Checkpoint 646057344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432,245.34528
Policy Entropy: 1.10535
Value Function Loss: 6.99559

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 11,309.27489
Overall Steps per Second: 9,686.27976

Timestep Collection Time: 4.42292
Timestep Consumption Time: 0.74109
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.16401

Cumulative Model Updates: 38,731
Cumulative Timesteps: 646,107,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,615.58175
Policy Entropy: 1.10643
Value Function Loss: 6.84142

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.07091

Collected Steps per Second: 11,601.36423
Overall Steps per Second: 9,990.93905

Timestep Collection Time: 4.31156
Timestep Consumption Time: 0.69497
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.00654

Cumulative Model Updates: 38,734
Cumulative Timesteps: 646,157,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 646157384...
Checkpoint 646157384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,984.55450
Policy Entropy: 1.10752
Value Function Loss: 6.56773

Mean KL Divergence: 0.02502
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.08055

Collected Steps per Second: 10,876.57258
Overall Steps per Second: 9,303.67196

Timestep Collection Time: 4.59796
Timestep Consumption Time: 0.77734
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 5.37530

Cumulative Model Updates: 38,737
Cumulative Timesteps: 646,207,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,034.98469
Policy Entropy: 1.11066
Value Function Loss: 6.66323

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12186
Policy Update Magnitude: 0.05683
Value Function Update Magnitude: 0.08325

Collected Steps per Second: 11,000.75500
Overall Steps per Second: 9,473.26050

Timestep Collection Time: 4.54569
Timestep Consumption Time: 0.73296
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.27865

Cumulative Model Updates: 38,740
Cumulative Timesteps: 646,257,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 646257400...
Checkpoint 646257400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414,892.01101
Policy Entropy: 1.12094
Value Function Loss: 6.43176

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12144
Policy Update Magnitude: 0.06210
Value Function Update Magnitude: 0.07158

Collected Steps per Second: 11,418.37736
Overall Steps per Second: 9,660.24979

Timestep Collection Time: 4.37891
Timestep Consumption Time: 0.79694
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 5.17585

Cumulative Model Updates: 38,743
Cumulative Timesteps: 646,307,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418,459.93704
Policy Entropy: 1.11462
Value Function Loss: 7.07055

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.07209

Collected Steps per Second: 11,187.22427
Overall Steps per Second: 9,539.60187

Timestep Collection Time: 4.47081
Timestep Consumption Time: 0.77217
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.24299

Cumulative Model Updates: 38,746
Cumulative Timesteps: 646,357,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 646357416...
Checkpoint 646357416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,992.32351
Policy Entropy: 1.11630
Value Function Loss: 6.78080

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.07844

Collected Steps per Second: 10,992.63866
Overall Steps per Second: 9,383.14244

Timestep Collection Time: 4.54959
Timestep Consumption Time: 0.78039
PPO Batch Consumption Time: 0.04458
Total Iteration Time: 5.32998

Cumulative Model Updates: 38,749
Cumulative Timesteps: 646,407,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,956.97298
Policy Entropy: 1.11087
Value Function Loss: 7.09193

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.07715

Collected Steps per Second: 10,832.37294
Overall Steps per Second: 9,157.86947

Timestep Collection Time: 4.61746
Timestep Consumption Time: 0.84430
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 5.46175

Cumulative Model Updates: 38,752
Cumulative Timesteps: 646,457,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 646457446...
Checkpoint 646457446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,154.89588
Policy Entropy: 1.12464
Value Function Loss: 6.93365

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.07794

Collected Steps per Second: 10,861.76938
Overall Steps per Second: 9,349.39385

Timestep Collection Time: 4.60349
Timestep Consumption Time: 0.74467
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.34815

Cumulative Model Updates: 38,755
Cumulative Timesteps: 646,507,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,584.50299
Policy Entropy: 1.13525
Value Function Loss: 7.36269

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.07074

Collected Steps per Second: 11,294.00227
Overall Steps per Second: 9,569.12237

Timestep Collection Time: 4.42784
Timestep Consumption Time: 0.79814
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.22598

Cumulative Model Updates: 38,758
Cumulative Timesteps: 646,557,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 646557456...
Checkpoint 646557456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,013.92334
Policy Entropy: 1.11731
Value Function Loss: 7.04159

Mean KL Divergence: 0.03976
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.07435

Collected Steps per Second: 11,314.00727
Overall Steps per Second: 9,652.51505

Timestep Collection Time: 4.42107
Timestep Consumption Time: 0.76100
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.18207

Cumulative Model Updates: 38,761
Cumulative Timesteps: 646,607,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405,802.43577
Policy Entropy: 1.13653
Value Function Loss: 7.25457

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.09128

Collected Steps per Second: 11,201.97491
Overall Steps per Second: 9,763.10138

Timestep Collection Time: 4.46368
Timestep Consumption Time: 0.65785
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.12153

Cumulative Model Updates: 38,764
Cumulative Timesteps: 646,657,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 646657478...
Checkpoint 646657478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416,993.51879
Policy Entropy: 1.12658
Value Function Loss: 6.74801

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 11,310.80519
Overall Steps per Second: 9,616.21528

Timestep Collection Time: 4.42073
Timestep Consumption Time: 0.77903
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 5.19976

Cumulative Model Updates: 38,767
Cumulative Timesteps: 646,707,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427,425.12138
Policy Entropy: 1.12764
Value Function Loss: 6.93955

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.06824
Value Function Update Magnitude: 0.09055

Collected Steps per Second: 10,742.44254
Overall Steps per Second: 9,137.11025

Timestep Collection Time: 4.65648
Timestep Consumption Time: 0.81811
PPO Batch Consumption Time: 0.03829
Total Iteration Time: 5.47460

Cumulative Model Updates: 38,770
Cumulative Timesteps: 646,757,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 646757502...
Checkpoint 646757502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442,000.45981
Policy Entropy: 1.12317
Value Function Loss: 6.78604

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.06904
Value Function Update Magnitude: 0.08117

Collected Steps per Second: 11,194.27648
Overall Steps per Second: 9,530.18112

Timestep Collection Time: 4.46925
Timestep Consumption Time: 0.78039
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.24964

Cumulative Model Updates: 38,773
Cumulative Timesteps: 646,807,532

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,341.02265
Policy Entropy: 1.12434
Value Function Loss: 7.07452

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.06897
Value Function Update Magnitude: 0.07792

Collected Steps per Second: 11,149.26458
Overall Steps per Second: 9,538.54805

Timestep Collection Time: 4.48711
Timestep Consumption Time: 0.75771
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 5.24482

Cumulative Model Updates: 38,776
Cumulative Timesteps: 646,857,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 646857560...
Checkpoint 646857560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558,891.83828
Policy Entropy: 1.10719
Value Function Loss: 6.80033

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.06880
Value Function Update Magnitude: 0.07856

Collected Steps per Second: 11,056.18314
Overall Steps per Second: 9,541.50417

Timestep Collection Time: 4.52380
Timestep Consumption Time: 0.71814
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.24194

Cumulative Model Updates: 38,779
Cumulative Timesteps: 646,907,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,982.96077
Policy Entropy: 1.12645
Value Function Loss: 6.69288

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.07564

Collected Steps per Second: 10,791.06214
Overall Steps per Second: 9,221.14373

Timestep Collection Time: 4.63495
Timestep Consumption Time: 0.78911
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.42406

Cumulative Model Updates: 38,782
Cumulative Timesteps: 646,957,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 646957592...
Checkpoint 646957592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,247.30300
Policy Entropy: 1.12968
Value Function Loss: 6.52863

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.07909

Collected Steps per Second: 11,085.52453
Overall Steps per Second: 9,457.42842

Timestep Collection Time: 4.51057
Timestep Consumption Time: 0.77649
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.28706

Cumulative Model Updates: 38,785
Cumulative Timesteps: 647,007,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,540.21126
Policy Entropy: 1.11693
Value Function Loss: 6.68279

Mean KL Divergence: 0.02447
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.10394

Collected Steps per Second: 10,913.90736
Overall Steps per Second: 9,359.42642

Timestep Collection Time: 4.58149
Timestep Consumption Time: 0.76093
PPO Batch Consumption Time: 0.03361
Total Iteration Time: 5.34242

Cumulative Model Updates: 38,788
Cumulative Timesteps: 647,057,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 647057596...
Checkpoint 647057596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,608.50945
Policy Entropy: 1.11397
Value Function Loss: 6.72789

Mean KL Divergence: 0.02566
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.10715

Collected Steps per Second: 11,777.69755
Overall Steps per Second: 10,014.99948

Timestep Collection Time: 4.24752
Timestep Consumption Time: 0.74759
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.99511

Cumulative Model Updates: 38,791
Cumulative Timesteps: 647,107,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407,314.10690
Policy Entropy: 1.11918
Value Function Loss: 6.86490

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 11,957.47230
Overall Steps per Second: 10,246.10039

Timestep Collection Time: 4.18333
Timestep Consumption Time: 0.69873
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.88205

Cumulative Model Updates: 38,794
Cumulative Timesteps: 647,157,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 647157644...
Checkpoint 647157644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,888.54712
Policy Entropy: 1.12976
Value Function Loss: 7.02180

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.12869

Collected Steps per Second: 12,270.18030
Overall Steps per Second: 10,272.30478

Timestep Collection Time: 4.07736
Timestep Consumption Time: 0.79301
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.87038

Cumulative Model Updates: 38,797
Cumulative Timesteps: 647,207,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,142.04651
Policy Entropy: 1.09253
Value Function Loss: 7.14541

Mean KL Divergence: 0.07794
SB3 Clip Fraction: 0.21917
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 12,220.57916
Overall Steps per Second: 10,327.24824

Timestep Collection Time: 4.09310
Timestep Consumption Time: 0.75040
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 4.84350

Cumulative Model Updates: 38,800
Cumulative Timesteps: 647,257,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 647257694...
Checkpoint 647257694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,476.23379
Policy Entropy: 1.12011
Value Function Loss: 7.06374

Mean KL Divergence: 0.03262
SB3 Clip Fraction: 0.16820
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.09274

Collected Steps per Second: 11,918.78782
Overall Steps per Second: 10,064.78521

Timestep Collection Time: 4.19640
Timestep Consumption Time: 0.77301
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 4.96941

Cumulative Model Updates: 38,803
Cumulative Timesteps: 647,307,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,488.91131
Policy Entropy: 1.09032
Value Function Loss: 6.87118

Mean KL Divergence: 0.06995
SB3 Clip Fraction: 0.23536
Policy Update Magnitude: 0.04536
Value Function Update Magnitude: 0.08146

Collected Steps per Second: 11,032.01954
Overall Steps per Second: 9,429.70314

Timestep Collection Time: 4.53480
Timestep Consumption Time: 0.77056
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.30536

Cumulative Model Updates: 38,806
Cumulative Timesteps: 647,357,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 647357738...
Checkpoint 647357738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,475.51688
Policy Entropy: 1.11692
Value Function Loss: 6.74471

Mean KL Divergence: 0.04378
SB3 Clip Fraction: 0.19855
Policy Update Magnitude: 0.04219
Value Function Update Magnitude: 0.08144

Collected Steps per Second: 11,507.91924
Overall Steps per Second: 9,903.63927

Timestep Collection Time: 4.34501
Timestep Consumption Time: 0.70384
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.04885

Cumulative Model Updates: 38,809
Cumulative Timesteps: 647,407,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,649.55778
Policy Entropy: 1.10180
Value Function Loss: 6.58768

Mean KL Divergence: 0.04856
SB3 Clip Fraction: 0.18047
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.08190

Collected Steps per Second: 11,426.33631
Overall Steps per Second: 9,706.02470

Timestep Collection Time: 4.37586
Timestep Consumption Time: 0.77558
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.15144

Cumulative Model Updates: 38,812
Cumulative Timesteps: 647,457,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 647457740...
Checkpoint 647457740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,472.95465
Policy Entropy: 1.11130
Value Function Loss: 6.40822

Mean KL Divergence: 0.02414
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.07751

Collected Steps per Second: 11,161.84248
Overall Steps per Second: 9,532.51113

Timestep Collection Time: 4.48134
Timestep Consumption Time: 0.76597
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.24731

Cumulative Model Updates: 38,815
Cumulative Timesteps: 647,507,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389,706.72492
Policy Entropy: 1.11598
Value Function Loss: 6.41718

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.06761

Collected Steps per Second: 11,232.87874
Overall Steps per Second: 9,527.44421

Timestep Collection Time: 4.45264
Timestep Consumption Time: 0.79703
PPO Batch Consumption Time: 0.03860
Total Iteration Time: 5.24968

Cumulative Model Updates: 38,818
Cumulative Timesteps: 647,557,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 647557776...
Checkpoint 647557776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,774.26892
Policy Entropy: 1.09697
Value Function Loss: 6.70703

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.06511

Collected Steps per Second: 11,183.84596
Overall Steps per Second: 9,482.81947

Timestep Collection Time: 4.47216
Timestep Consumption Time: 0.80222
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 5.27438

Cumulative Model Updates: 38,821
Cumulative Timesteps: 647,607,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,646.66422
Policy Entropy: 1.08764
Value Function Loss: 6.88554

Mean KL Divergence: 0.02810
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 10,719.83837
Overall Steps per Second: 9,341.22331

Timestep Collection Time: 4.66444
Timestep Consumption Time: 0.68840
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 5.35283

Cumulative Model Updates: 38,824
Cumulative Timesteps: 647,657,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 647657794...
Checkpoint 647657794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,127.20682
Policy Entropy: 1.10375
Value Function Loss: 6.85410

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.06524

Collected Steps per Second: 11,089.95301
Overall Steps per Second: 9,483.75474

Timestep Collection Time: 4.51075
Timestep Consumption Time: 0.76395
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.27470

Cumulative Model Updates: 38,827
Cumulative Timesteps: 647,707,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,766.54392
Policy Entropy: 1.11304
Value Function Loss: 6.72427

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.11018
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 10,790.50954
Overall Steps per Second: 9,294.11503

Timestep Collection Time: 4.63648
Timestep Consumption Time: 0.74649
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.38298

Cumulative Model Updates: 38,830
Cumulative Timesteps: 647,757,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 647757848...
Checkpoint 647757848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,310.64716
Policy Entropy: 1.10475
Value Function Loss: 6.57327

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.06583

Collected Steps per Second: 10,785.55753
Overall Steps per Second: 9,279.46931

Timestep Collection Time: 4.63601
Timestep Consumption Time: 0.75244
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 5.38845

Cumulative Model Updates: 38,833
Cumulative Timesteps: 647,807,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,127.15801
Policy Entropy: 1.10598
Value Function Loss: 6.82154

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.07052

Collected Steps per Second: 11,144.80632
Overall Steps per Second: 9,513.04373

Timestep Collection Time: 4.48801
Timestep Consumption Time: 0.76982
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 5.25783

Cumulative Model Updates: 38,836
Cumulative Timesteps: 647,857,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 647857868...
Checkpoint 647857868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,933.64909
Policy Entropy: 1.11417
Value Function Loss: 6.64070

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.07915

Collected Steps per Second: 10,871.69591
Overall Steps per Second: 9,319.27421

Timestep Collection Time: 4.60149
Timestep Consumption Time: 0.76652
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.36801

Cumulative Model Updates: 38,839
Cumulative Timesteps: 647,907,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,505.90721
Policy Entropy: 1.11067
Value Function Loss: 6.84232

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.09271

Collected Steps per Second: 10,855.38502
Overall Steps per Second: 9,222.95464

Timestep Collection Time: 4.60601
Timestep Consumption Time: 0.81525
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.42126

Cumulative Model Updates: 38,842
Cumulative Timesteps: 647,957,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 647957894...
Checkpoint 647957894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419,865.08660
Policy Entropy: 1.11115
Value Function Loss: 6.74368

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.08680

Collected Steps per Second: 10,652.86837
Overall Steps per Second: 9,199.52978

Timestep Collection Time: 4.69376
Timestep Consumption Time: 0.74152
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.43528

Cumulative Model Updates: 38,845
Cumulative Timesteps: 648,007,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,979.20199
Policy Entropy: 1.10000
Value Function Loss: 6.94921

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.06357
Value Function Update Magnitude: 0.07954

Collected Steps per Second: 11,252.37331
Overall Steps per Second: 9,534.36301

Timestep Collection Time: 4.44422
Timestep Consumption Time: 0.80081
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.24503

Cumulative Model Updates: 38,848
Cumulative Timesteps: 648,057,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 648057904...
Checkpoint 648057904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,851.13799
Policy Entropy: 1.11053
Value Function Loss: 7.17004

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.05783
Value Function Update Magnitude: 0.07091

Collected Steps per Second: 10,891.34686
Overall Steps per Second: 9,283.09354

Timestep Collection Time: 4.59227
Timestep Consumption Time: 0.79559
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.38786

Cumulative Model Updates: 38,851
Cumulative Timesteps: 648,107,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,521.18152
Policy Entropy: 1.10647
Value Function Loss: 7.21555

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.07634

Collected Steps per Second: 10,896.53973
Overall Steps per Second: 9,494.69490

Timestep Collection Time: 4.59008
Timestep Consumption Time: 0.67770
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.26778

Cumulative Model Updates: 38,854
Cumulative Timesteps: 648,157,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 648157936...
Checkpoint 648157936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,076.75438
Policy Entropy: 1.09768
Value Function Loss: 7.18360

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.10224

Collected Steps per Second: 10,662.70512
Overall Steps per Second: 9,156.60397

Timestep Collection Time: 4.68962
Timestep Consumption Time: 0.77136
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 5.46098

Cumulative Model Updates: 38,857
Cumulative Timesteps: 648,207,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,948.54878
Policy Entropy: 1.09325
Value Function Loss: 6.98761

Mean KL Divergence: 0.02943
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.11145

Collected Steps per Second: 11,453.05657
Overall Steps per Second: 9,813.36477

Timestep Collection Time: 4.36687
Timestep Consumption Time: 0.72965
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.09652

Cumulative Model Updates: 38,860
Cumulative Timesteps: 648,257,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 648257954...
Checkpoint 648257954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,411.53239
Policy Entropy: 1.10456
Value Function Loss: 7.14495

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.09342

Collected Steps per Second: 11,681.24896
Overall Steps per Second: 9,872.09564

Timestep Collection Time: 4.28139
Timestep Consumption Time: 0.78460
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.06600

Cumulative Model Updates: 38,863
Cumulative Timesteps: 648,307,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,064.69536
Policy Entropy: 1.10441
Value Function Loss: 7.18695

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.06030
Value Function Update Magnitude: 0.08387

Collected Steps per Second: 11,362.41896
Overall Steps per Second: 9,649.53520

Timestep Collection Time: 4.40206
Timestep Consumption Time: 0.78141
PPO Batch Consumption Time: 0.03876
Total Iteration Time: 5.18346

Cumulative Model Updates: 38,866
Cumulative Timesteps: 648,357,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 648357984...
Checkpoint 648357984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,259.64967
Policy Entropy: 1.10020
Value Function Loss: 7.35038

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.08411

Collected Steps per Second: 11,496.87375
Overall Steps per Second: 9,985.27522

Timestep Collection Time: 4.35057
Timestep Consumption Time: 0.65860
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.00918

Cumulative Model Updates: 38,869
Cumulative Timesteps: 648,408,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,649.06653
Policy Entropy: 1.10755
Value Function Loss: 7.19090

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.08017

Collected Steps per Second: 11,419.56978
Overall Steps per Second: 9,696.47483

Timestep Collection Time: 4.38002
Timestep Consumption Time: 0.77834
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.15837

Cumulative Model Updates: 38,872
Cumulative Timesteps: 648,458,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 648458020...
Checkpoint 648458020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,412.73822
Policy Entropy: 1.11664
Value Function Loss: 7.01233

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.07696

Collected Steps per Second: 10,887.66465
Overall Steps per Second: 9,360.76500

Timestep Collection Time: 4.59401
Timestep Consumption Time: 0.74936
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.34337

Cumulative Model Updates: 38,875
Cumulative Timesteps: 648,508,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382,311.32713
Policy Entropy: 1.11889
Value Function Loss: 6.80081

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.06454
Value Function Update Magnitude: 0.07397

Collected Steps per Second: 11,279.59801
Overall Steps per Second: 9,810.39345

Timestep Collection Time: 4.43456
Timestep Consumption Time: 0.66412
PPO Batch Consumption Time: 0.03785
Total Iteration Time: 5.09867

Cumulative Model Updates: 38,878
Cumulative Timesteps: 648,558,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 648558058...
Checkpoint 648558058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360,363.00053
Policy Entropy: 1.11999
Value Function Loss: 6.48000

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 11,203.26698
Overall Steps per Second: 9,523.27138

Timestep Collection Time: 4.46495
Timestep Consumption Time: 0.78766
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.25261

Cumulative Model Updates: 38,881
Cumulative Timesteps: 648,608,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404,964.22685
Policy Entropy: 1.10344
Value Function Loss: 6.64084

Mean KL Divergence: 0.03159
SB3 Clip Fraction: 0.16067
Policy Update Magnitude: 0.05982
Value Function Update Magnitude: 0.07113

Collected Steps per Second: 11,149.12955
Overall Steps per Second: 9,646.82607

Timestep Collection Time: 4.48645
Timestep Consumption Time: 0.69868
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 5.18513

Cumulative Model Updates: 38,884
Cumulative Timesteps: 648,658,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 648658100...
Checkpoint 648658100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,387.83103
Policy Entropy: 1.12695
Value Function Loss: 6.33823

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.11313
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.06657

Collected Steps per Second: 11,234.54708
Overall Steps per Second: 9,548.20833

Timestep Collection Time: 4.45216
Timestep Consumption Time: 0.78631
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.23847

Cumulative Model Updates: 38,887
Cumulative Timesteps: 648,708,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364,236.45412
Policy Entropy: 1.13259
Value Function Loss: 6.54480

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 10,958.79774
Overall Steps per Second: 9,263.84150

Timestep Collection Time: 4.56419
Timestep Consumption Time: 0.83509
PPO Batch Consumption Time: 0.04132
Total Iteration Time: 5.39927

Cumulative Model Updates: 38,890
Cumulative Timesteps: 648,758,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 648758136...
Checkpoint 648758136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,336.26015
Policy Entropy: 1.11763
Value Function Loss: 6.54678

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.11766
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.07908

Collected Steps per Second: 11,016.77841
Overall Steps per Second: 9,610.47111

Timestep Collection Time: 4.53908
Timestep Consumption Time: 0.66421
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.20328

Cumulative Model Updates: 38,893
Cumulative Timesteps: 648,808,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,583.25786
Policy Entropy: 1.09714
Value Function Loss: 6.71809

Mean KL Divergence: 0.03158
SB3 Clip Fraction: 0.15722
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.07629

Collected Steps per Second: 10,911.87790
Overall Steps per Second: 9,340.10364

Timestep Collection Time: 4.58363
Timestep Consumption Time: 0.77134
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.35497

Cumulative Model Updates: 38,896
Cumulative Timesteps: 648,858,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 648858158...
Checkpoint 648858158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,534.10919
Policy Entropy: 1.10422
Value Function Loss: 6.50575

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.08858

Collected Steps per Second: 10,597.72325
Overall Steps per Second: 9,275.27205

Timestep Collection Time: 4.71894
Timestep Consumption Time: 0.67282
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.39176

Cumulative Model Updates: 38,899
Cumulative Timesteps: 648,908,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,575.22837
Policy Entropy: 1.11767
Value Function Loss: 6.65706

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.11720
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.08756

Collected Steps per Second: 10,970.23860
Overall Steps per Second: 9,408.27825

Timestep Collection Time: 4.55924
Timestep Consumption Time: 0.75692
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.31617

Cumulative Model Updates: 38,902
Cumulative Timesteps: 648,958,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 648958184...
Checkpoint 648958184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,376.02229
Policy Entropy: 1.11119
Value Function Loss: 6.70568

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.08603

Collected Steps per Second: 11,104.48607
Overall Steps per Second: 9,645.05779

Timestep Collection Time: 4.50413
Timestep Consumption Time: 0.68154
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.18566

Cumulative Model Updates: 38,905
Cumulative Timesteps: 649,008,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402,462.17350
Policy Entropy: 1.09975
Value Function Loss: 6.89011

Mean KL Divergence: 0.03527
SB3 Clip Fraction: 0.15645
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.08675

Collected Steps per Second: 10,696.70455
Overall Steps per Second: 9,156.31055

Timestep Collection Time: 4.67733
Timestep Consumption Time: 0.78688
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.46421

Cumulative Model Updates: 38,908
Cumulative Timesteps: 649,058,232

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 649058232...
Checkpoint 649058232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427,579.37709
Policy Entropy: 1.11150
Value Function Loss: 6.93477

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.07882

Collected Steps per Second: 11,146.23529
Overall Steps per Second: 9,515.15596

Timestep Collection Time: 4.48618
Timestep Consumption Time: 0.76902
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.25519

Cumulative Model Updates: 38,911
Cumulative Timesteps: 649,108,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,090.65069
Policy Entropy: 1.10799
Value Function Loss: 7.29388

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.06642
Value Function Update Magnitude: 0.07617

Collected Steps per Second: 11,016.38839
Overall Steps per Second: 9,400.87851

Timestep Collection Time: 4.53924
Timestep Consumption Time: 0.78005
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 5.31929

Cumulative Model Updates: 38,914
Cumulative Timesteps: 649,158,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 649158242...
Checkpoint 649158242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,302.37001
Policy Entropy: 1.10555
Value Function Loss: 7.52844

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.06465
Value Function Update Magnitude: 0.07583

Collected Steps per Second: 10,951.74036
Overall Steps per Second: 9,393.58023

Timestep Collection Time: 4.56621
Timestep Consumption Time: 0.75742
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.32364

Cumulative Model Updates: 38,917
Cumulative Timesteps: 649,208,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,227.04468
Policy Entropy: 1.09595
Value Function Loss: 7.27162

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.06383
Value Function Update Magnitude: 0.07761

Collected Steps per Second: 10,887.48626
Overall Steps per Second: 9,447.45983

Timestep Collection Time: 4.59243
Timestep Consumption Time: 0.70000
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.29243

Cumulative Model Updates: 38,920
Cumulative Timesteps: 649,258,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 649258250...
Checkpoint 649258250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,272.48819
Policy Entropy: 1.11067
Value Function Loss: 6.89613

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.07388

Collected Steps per Second: 11,048.79907
Overall Steps per Second: 9,432.41757

Timestep Collection Time: 4.52773
Timestep Consumption Time: 0.77589
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.30362

Cumulative Model Updates: 38,923
Cumulative Timesteps: 649,308,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,043.71881
Policy Entropy: 1.11309
Value Function Loss: 6.56475

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.06975

Collected Steps per Second: 10,629.65427
Overall Steps per Second: 9,129.09290

Timestep Collection Time: 4.70401
Timestep Consumption Time: 0.77320
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.47721

Cumulative Model Updates: 38,926
Cumulative Timesteps: 649,358,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 649358278...
Checkpoint 649358278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,235.89475
Policy Entropy: 1.09330
Value Function Loss: 6.35051

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.08137

Collected Steps per Second: 12,123.81935
Overall Steps per Second: 10,219.02105

Timestep Collection Time: 4.12560
Timestep Consumption Time: 0.76900
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 4.89460

Cumulative Model Updates: 38,929
Cumulative Timesteps: 649,408,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,337.06161
Policy Entropy: 1.08820
Value Function Loss: 6.20134

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.08198

Collected Steps per Second: 11,702.78957
Overall Steps per Second: 9,950.44073

Timestep Collection Time: 4.27471
Timestep Consumption Time: 0.75281
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 5.02752

Cumulative Model Updates: 38,932
Cumulative Timesteps: 649,458,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 649458322...
Checkpoint 649458322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,558.45333
Policy Entropy: 1.10194
Value Function Loss: 6.48279

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.08067

Collected Steps per Second: 12,017.77027
Overall Steps per Second: 10,201.60030

Timestep Collection Time: 4.16250
Timestep Consumption Time: 0.74104
PPO Batch Consumption Time: 0.05156
Total Iteration Time: 4.90354

Cumulative Model Updates: 38,935
Cumulative Timesteps: 649,508,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,036.06972
Policy Entropy: 1.11087
Value Function Loss: 6.80382

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.04727
Value Function Update Magnitude: 0.06697

Collected Steps per Second: 11,865.96793
Overall Steps per Second: 10,016.70345

Timestep Collection Time: 4.21626
Timestep Consumption Time: 0.77840
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 4.99466

Cumulative Model Updates: 38,938
Cumulative Timesteps: 649,558,376

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 649558376...
Checkpoint 649558376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,662.46200
Policy Entropy: 1.09046
Value Function Loss: 6.91133

Mean KL Divergence: 0.04731
SB3 Clip Fraction: 0.16309
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.05668

Collected Steps per Second: 11,853.52203
Overall Steps per Second: 10,064.24819

Timestep Collection Time: 4.21832
Timestep Consumption Time: 0.74996
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.96828

Cumulative Model Updates: 38,941
Cumulative Timesteps: 649,608,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,368.83181
Policy Entropy: 1.10283
Value Function Loss: 7.17775

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.05634

Collected Steps per Second: 11,269.95757
Overall Steps per Second: 9,526.05904

Timestep Collection Time: 4.43817
Timestep Consumption Time: 0.81248
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.25065

Cumulative Model Updates: 38,944
Cumulative Timesteps: 649,658,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 649658396...
Checkpoint 649658396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,254.47975
Policy Entropy: 1.10245
Value Function Loss: 7.02331

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.06255

Collected Steps per Second: 11,000.79277
Overall Steps per Second: 9,428.72180

Timestep Collection Time: 4.54585
Timestep Consumption Time: 0.75794
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.30379

Cumulative Model Updates: 38,947
Cumulative Timesteps: 649,708,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,251.57709
Policy Entropy: 1.08906
Value Function Loss: 7.08030

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.11018
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.06114

Collected Steps per Second: 11,293.76390
Overall Steps per Second: 9,770.36477

Timestep Collection Time: 4.42722
Timestep Consumption Time: 0.69029
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.11752

Cumulative Model Updates: 38,950
Cumulative Timesteps: 649,758,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 649758404...
Checkpoint 649758404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,963.56308
Policy Entropy: 1.07874
Value Function Loss: 6.91274

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.05856

Collected Steps per Second: 11,337.58913
Overall Steps per Second: 9,603.53480

Timestep Collection Time: 4.41170
Timestep Consumption Time: 0.79659
PPO Batch Consumption Time: 0.03896
Total Iteration Time: 5.20829

Cumulative Model Updates: 38,953
Cumulative Timesteps: 649,808,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,153.53972
Policy Entropy: 1.07575
Value Function Loss: 7.19557

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.06126
Value Function Update Magnitude: 0.05398

Collected Steps per Second: 11,332.70319
Overall Steps per Second: 9,704.17288

Timestep Collection Time: 4.41395
Timestep Consumption Time: 0.74074
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.15469

Cumulative Model Updates: 38,956
Cumulative Timesteps: 649,858,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 649858444...
Checkpoint 649858444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,681.47908
Policy Entropy: 1.08386
Value Function Loss: 7.14182

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.05041

Collected Steps per Second: 11,401.85499
Overall Steps per Second: 9,512.11088

Timestep Collection Time: 4.38613
Timestep Consumption Time: 0.87138
PPO Batch Consumption Time: 0.04538
Total Iteration Time: 5.25751

Cumulative Model Updates: 38,959
Cumulative Timesteps: 649,908,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,209.46255
Policy Entropy: 1.09591
Value Function Loss: 7.14393

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.05590

Collected Steps per Second: 11,353.24977
Overall Steps per Second: 9,683.98019

Timestep Collection Time: 4.40614
Timestep Consumption Time: 0.75951
PPO Batch Consumption Time: 0.03932
Total Iteration Time: 5.16564

Cumulative Model Updates: 38,962
Cumulative Timesteps: 649,958,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 649958478...
Checkpoint 649958478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,361.14594
Policy Entropy: 1.10171
Value Function Loss: 7.05934

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.06216
Value Function Update Magnitude: 0.05226

Collected Steps per Second: 11,155.06126
Overall Steps per Second: 9,682.01370

Timestep Collection Time: 4.48263
Timestep Consumption Time: 0.68200
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 5.16463

Cumulative Model Updates: 38,965
Cumulative Timesteps: 650,008,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,124.81197
Policy Entropy: 1.10260
Value Function Loss: 7.10521

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.04874

Collected Steps per Second: 10,882.28611
Overall Steps per Second: 9,266.46110

Timestep Collection Time: 4.59720
Timestep Consumption Time: 0.80163
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.39882

Cumulative Model Updates: 38,968
Cumulative Timesteps: 650,058,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 650058510...
Checkpoint 650058510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,507.69798
Policy Entropy: 1.10827
Value Function Loss: 7.24600

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.04827

Collected Steps per Second: 10,999.77005
Overall Steps per Second: 9,572.11908

Timestep Collection Time: 4.54664
Timestep Consumption Time: 0.67812
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.22476

Cumulative Model Updates: 38,971
Cumulative Timesteps: 650,108,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,703.34908
Policy Entropy: 1.11915
Value Function Loss: 7.04632

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.05419

Collected Steps per Second: 11,251.77429
Overall Steps per Second: 9,620.92434

Timestep Collection Time: 4.44410
Timestep Consumption Time: 0.75332
PPO Batch Consumption Time: 0.03874
Total Iteration Time: 5.19742

Cumulative Model Updates: 38,974
Cumulative Timesteps: 650,158,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 650158526...
Checkpoint 650158526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,431.66042
Policy Entropy: 1.12281
Value Function Loss: 6.87944

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.05966

Collected Steps per Second: 10,537.78622
Overall Steps per Second: 9,110.41903

Timestep Collection Time: 4.74768
Timestep Consumption Time: 0.74384
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.49151

Cumulative Model Updates: 38,977
Cumulative Timesteps: 650,208,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,568.12826
Policy Entropy: 1.11642
Value Function Loss: 6.91348

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.06457

Collected Steps per Second: 10,922.88795
Overall Steps per Second: 9,518.92167

Timestep Collection Time: 4.57956
Timestep Consumption Time: 0.67545
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.25501

Cumulative Model Updates: 38,980
Cumulative Timesteps: 650,258,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 650258578...
Checkpoint 650258578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,029.63247
Policy Entropy: 1.10990
Value Function Loss: 7.03413

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.07101

Collected Steps per Second: 10,860.40027
Overall Steps per Second: 9,224.33026

Timestep Collection Time: 4.60462
Timestep Consumption Time: 0.81670
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.42131

Cumulative Model Updates: 38,983
Cumulative Timesteps: 650,308,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,654.09956
Policy Entropy: 1.10725
Value Function Loss: 7.17246

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.07031

Collected Steps per Second: 10,770.87004
Overall Steps per Second: 9,407.97879

Timestep Collection Time: 4.64382
Timestep Consumption Time: 0.67273
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.31655

Cumulative Model Updates: 38,986
Cumulative Timesteps: 650,358,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 650358604...
Checkpoint 650358604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,977.10895
Policy Entropy: 1.09715
Value Function Loss: 6.89345

Mean KL Divergence: 0.03240
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.08242

Collected Steps per Second: 10,951.12119
Overall Steps per Second: 9,336.94979

Timestep Collection Time: 4.56666
Timestep Consumption Time: 0.78948
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.35614

Cumulative Model Updates: 38,989
Cumulative Timesteps: 650,408,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,463.26158
Policy Entropy: 1.11606
Value Function Loss: 6.64991

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11103
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.08623

Collected Steps per Second: 11,020.73360
Overall Steps per Second: 9,462.39478

Timestep Collection Time: 4.53890
Timestep Consumption Time: 0.74750
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 5.28640

Cumulative Model Updates: 38,992
Cumulative Timesteps: 650,458,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 650458636...
Checkpoint 650458636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372,841.28068
Policy Entropy: 1.10782
Value Function Loss: 6.46697

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.08365

Collected Steps per Second: 10,596.40408
Overall Steps per Second: 9,114.25499

Timestep Collection Time: 4.72009
Timestep Consumption Time: 0.76758
PPO Batch Consumption Time: 0.03800
Total Iteration Time: 5.48767

Cumulative Model Updates: 38,995
Cumulative Timesteps: 650,508,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,698.28566
Policy Entropy: 1.09788
Value Function Loss: 6.17543

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.09358

Collected Steps per Second: 11,516.81810
Overall Steps per Second: 9,843.43009

Timestep Collection Time: 4.34200
Timestep Consumption Time: 0.73814
PPO Batch Consumption Time: 0.03357
Total Iteration Time: 5.08014

Cumulative Model Updates: 38,998
Cumulative Timesteps: 650,558,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 650558658...
Checkpoint 650558658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,834.00460
Policy Entropy: 1.08192
Value Function Loss: 6.33361

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.10256

Collected Steps per Second: 11,323.37170
Overall Steps per Second: 9,822.03333

Timestep Collection Time: 4.41759
Timestep Consumption Time: 0.67525
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 5.09284

Cumulative Model Updates: 39,001
Cumulative Timesteps: 650,608,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,270.63866
Policy Entropy: 1.09759
Value Function Loss: 6.43681

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.09525

Collected Steps per Second: 11,179.37636
Overall Steps per Second: 9,517.02923

Timestep Collection Time: 4.47252
Timestep Consumption Time: 0.78122
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.25374

Cumulative Model Updates: 39,004
Cumulative Timesteps: 650,658,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 650658680...
Checkpoint 650658680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,183.73244
Policy Entropy: 1.09846
Value Function Loss: 6.86796

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.09562

Collected Steps per Second: 11,315.73135
Overall Steps per Second: 9,637.57552

Timestep Collection Time: 4.42039
Timestep Consumption Time: 0.76971
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.19010

Cumulative Model Updates: 39,007
Cumulative Timesteps: 650,708,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,829.18269
Policy Entropy: 1.09094
Value Function Loss: 6.59212

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.09445

Collected Steps per Second: 11,543.80673
Overall Steps per Second: 9,616.00001

Timestep Collection Time: 4.33150
Timestep Consumption Time: 0.86838
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 5.19988

Cumulative Model Updates: 39,010
Cumulative Timesteps: 650,758,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 650758702...
Checkpoint 650758702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,977.26188
Policy Entropy: 1.08403
Value Function Loss: 6.55929

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.09126

Collected Steps per Second: 11,242.99884
Overall Steps per Second: 9,580.36488

Timestep Collection Time: 4.44810
Timestep Consumption Time: 0.77195
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 5.22005

Cumulative Model Updates: 39,013
Cumulative Timesteps: 650,808,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,902.93907
Policy Entropy: 1.09571
Value Function Loss: 6.33156

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.10949

Collected Steps per Second: 11,138.55796
Overall Steps per Second: 9,659.08565

Timestep Collection Time: 4.48981
Timestep Consumption Time: 0.68770
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 5.17751

Cumulative Model Updates: 39,016
Cumulative Timesteps: 650,858,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 650858722...
Checkpoint 650858722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,241.50260
Policy Entropy: 1.09813
Value Function Loss: 6.59659

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.12793

Collected Steps per Second: 11,509.55089
Overall Steps per Second: 9,762.63467

Timestep Collection Time: 4.34457
Timestep Consumption Time: 0.77741
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.12198

Cumulative Model Updates: 39,019
Cumulative Timesteps: 650,908,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,467.82705
Policy Entropy: 1.07589
Value Function Loss: 6.81214

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.12110

Collected Steps per Second: 11,138.04054
Overall Steps per Second: 9,503.08552

Timestep Collection Time: 4.49092
Timestep Consumption Time: 0.77264
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.26355

Cumulative Model Updates: 39,022
Cumulative Timesteps: 650,958,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 650958746...
Checkpoint 650958746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,002.07914
Policy Entropy: 1.08473
Value Function Loss: 7.03994

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.09912

Collected Steps per Second: 11,336.50752
Overall Steps per Second: 9,663.04865

Timestep Collection Time: 4.41282
Timestep Consumption Time: 0.76422
PPO Batch Consumption Time: 0.04035
Total Iteration Time: 5.17704

Cumulative Model Updates: 39,025
Cumulative Timesteps: 651,008,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,648.35739
Policy Entropy: 1.08688
Value Function Loss: 6.77771

Mean KL Divergence: 0.02707
SB3 Clip Fraction: 0.15453
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.08886

Collected Steps per Second: 10,773.94759
Overall Steps per Second: 9,250.68183

Timestep Collection Time: 4.64305
Timestep Consumption Time: 0.76455
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.40760

Cumulative Model Updates: 39,028
Cumulative Timesteps: 651,058,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 651058796...
Checkpoint 651058796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,308.06095
Policy Entropy: 1.07854
Value Function Loss: 6.63604

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.08043

Collected Steps per Second: 10,989.67547
Overall Steps per Second: 9,509.96997

Timestep Collection Time: 4.55118
Timestep Consumption Time: 0.70814
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 5.25932

Cumulative Model Updates: 39,031
Cumulative Timesteps: 651,108,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,374.77852
Policy Entropy: 1.05793
Value Function Loss: 6.62764

Mean KL Divergence: 0.04114
SB3 Clip Fraction: 0.18973
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.07623

Collected Steps per Second: 11,108.74645
Overall Steps per Second: 9,484.60422

Timestep Collection Time: 4.50240
Timestep Consumption Time: 0.77099
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 5.27339

Cumulative Model Updates: 39,034
Cumulative Timesteps: 651,158,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 651158828...
Checkpoint 651158828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,844.25798
Policy Entropy: 1.07935
Value Function Loss: 6.66348

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.07093

Collected Steps per Second: 10,786.26079
Overall Steps per Second: 9,231.26731

Timestep Collection Time: 4.63720
Timestep Consumption Time: 0.78113
PPO Batch Consumption Time: 0.03963
Total Iteration Time: 5.41832

Cumulative Model Updates: 39,037
Cumulative Timesteps: 651,208,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,850.83804
Policy Entropy: 1.06611
Value Function Loss: 6.50665

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.08712

Collected Steps per Second: 11,188.01733
Overall Steps per Second: 9,589.68516

Timestep Collection Time: 4.46996
Timestep Consumption Time: 0.74502
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.21498

Cumulative Model Updates: 39,040
Cumulative Timesteps: 651,258,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 651258856...
Checkpoint 651258856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,687.30337
Policy Entropy: 1.05790
Value Function Loss: 6.44662

Mean KL Divergence: 0.03023
SB3 Clip Fraction: 0.15609
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.08939

Collected Steps per Second: 10,978.57738
Overall Steps per Second: 9,315.77289

Timestep Collection Time: 4.55596
Timestep Consumption Time: 0.81321
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.36917

Cumulative Model Updates: 39,043
Cumulative Timesteps: 651,308,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,590.66265
Policy Entropy: 1.07635
Value Function Loss: 6.64509

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.04994
Value Function Update Magnitude: 0.08150

Collected Steps per Second: 10,647.81035
Overall Steps per Second: 9,282.13911

Timestep Collection Time: 4.69730
Timestep Consumption Time: 0.69111
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 5.38841

Cumulative Model Updates: 39,046
Cumulative Timesteps: 651,358,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 651358890...
Checkpoint 651358890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,936.08682
Policy Entropy: 1.08338
Value Function Loss: 6.69568

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.07191

Collected Steps per Second: 10,851.81874
Overall Steps per Second: 9,334.65573

Timestep Collection Time: 4.60973
Timestep Consumption Time: 0.74922
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.35895

Cumulative Model Updates: 39,049
Cumulative Timesteps: 651,408,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,789.17592
Policy Entropy: 1.07684
Value Function Loss: 6.82515

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.07286

Collected Steps per Second: 10,831.17871
Overall Steps per Second: 9,426.96669

Timestep Collection Time: 4.61686
Timestep Consumption Time: 0.68771
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.30457

Cumulative Model Updates: 39,052
Cumulative Timesteps: 651,458,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 651458920...
Checkpoint 651458920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,999.66865
Policy Entropy: 1.07200
Value Function Loss: 6.44130

Mean KL Divergence: 0.03619
SB3 Clip Fraction: 0.16993
Policy Update Magnitude: 0.04326
Value Function Update Magnitude: 0.06946

Collected Steps per Second: 11,132.11301
Overall Steps per Second: 9,472.08722

Timestep Collection Time: 4.49187
Timestep Consumption Time: 0.78722
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 5.27909

Cumulative Model Updates: 39,055
Cumulative Timesteps: 651,508,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318,532.88287
Policy Entropy: 1.08123
Value Function Loss: 6.37166

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.10596
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.07415

Collected Steps per Second: 11,021.59332
Overall Steps per Second: 9,373.59728

Timestep Collection Time: 4.53782
Timestep Consumption Time: 0.79781
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.33562

Cumulative Model Updates: 39,058
Cumulative Timesteps: 651,558,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 651558938...
Checkpoint 651558938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427,421.43845
Policy Entropy: 1.08841
Value Function Loss: 5.94195

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.07006

Collected Steps per Second: 10,652.66989
Overall Steps per Second: 9,235.87385

Timestep Collection Time: 4.69403
Timestep Consumption Time: 0.72007
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.41411

Cumulative Model Updates: 39,061
Cumulative Timesteps: 651,608,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,249.27106
Policy Entropy: 1.07716
Value Function Loss: 6.10198

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.08894

Collected Steps per Second: 11,454.85784
Overall Steps per Second: 9,716.25826

Timestep Collection Time: 4.36758
Timestep Consumption Time: 0.78152
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.14910

Cumulative Model Updates: 39,064
Cumulative Timesteps: 651,658,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 651658972...
Checkpoint 651658972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,276.51002
Policy Entropy: 1.08542
Value Function Loss: 6.34062

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.08760

Collected Steps per Second: 11,771.82345
Overall Steps per Second: 9,941.37245

Timestep Collection Time: 4.24947
Timestep Consumption Time: 0.78243
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 5.03190

Cumulative Model Updates: 39,067
Cumulative Timesteps: 651,708,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,241.28697
Policy Entropy: 1.09518
Value Function Loss: 6.72049

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.08948

Collected Steps per Second: 12,167.62678
Overall Steps per Second: 10,210.71746

Timestep Collection Time: 4.11074
Timestep Consumption Time: 0.78783
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.89858

Cumulative Model Updates: 39,070
Cumulative Timesteps: 651,759,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 651759014...
Checkpoint 651759014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,761.91034
Policy Entropy: 1.10254
Value Function Loss: 6.97981

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.11964
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.07921

Collected Steps per Second: 11,781.91307
Overall Steps per Second: 9,861.53844

Timestep Collection Time: 4.24549
Timestep Consumption Time: 0.82674
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 5.07223

Cumulative Model Updates: 39,073
Cumulative Timesteps: 651,809,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,681.91883
Policy Entropy: 1.09274
Value Function Loss: 7.17004

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.07281

Collected Steps per Second: 11,959.63692
Overall Steps per Second: 10,204.51283

Timestep Collection Time: 4.18173
Timestep Consumption Time: 0.71924
PPO Batch Consumption Time: 0.04002
Total Iteration Time: 4.90097

Cumulative Model Updates: 39,076
Cumulative Timesteps: 651,859,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 651859046...
Checkpoint 651859046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,547.51055
Policy Entropy: 1.07378
Value Function Loss: 7.03518

Mean KL Divergence: 0.03842
SB3 Clip Fraction: 0.17263
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.06127

Collected Steps per Second: 11,491.20790
Overall Steps per Second: 9,547.58253

Timestep Collection Time: 4.35237
Timestep Consumption Time: 0.88602
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 5.23839

Cumulative Model Updates: 39,079
Cumulative Timesteps: 651,909,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,902.75796
Policy Entropy: 1.08557
Value Function Loss: 6.95873

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.06094

Collected Steps per Second: 11,390.30230
Overall Steps per Second: 9,842.72130

Timestep Collection Time: 4.39145
Timestep Consumption Time: 0.69047
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.08193

Cumulative Model Updates: 39,082
Cumulative Timesteps: 651,959,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 651959080...
Checkpoint 651959080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,061.57892
Policy Entropy: 1.08760
Value Function Loss: 6.23805

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.06558

Collected Steps per Second: 11,338.12440
Overall Steps per Second: 9,650.91206

Timestep Collection Time: 4.41255
Timestep Consumption Time: 0.77142
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 5.18397

Cumulative Model Updates: 39,085
Cumulative Timesteps: 652,009,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,916.43710
Policy Entropy: 1.06812
Value Function Loss: 6.06615

Mean KL Divergence: 0.03292
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.07980

Collected Steps per Second: 11,291.01932
Overall Steps per Second: 9,638.12991

Timestep Collection Time: 4.43078
Timestep Consumption Time: 0.75986
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 5.19063

Cumulative Model Updates: 39,088
Cumulative Timesteps: 652,059,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 652059138...
Checkpoint 652059138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,911.90866
Policy Entropy: 1.08085
Value Function Loss: 6.08134

Mean KL Divergence: 0.02567
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.08296

Collected Steps per Second: 11,415.86621
Overall Steps per Second: 9,662.02726

Timestep Collection Time: 4.38092
Timestep Consumption Time: 0.79522
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.17614

Cumulative Model Updates: 39,091
Cumulative Timesteps: 652,109,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402,347.27132
Policy Entropy: 1.08032
Value Function Loss: 6.29165

Mean KL Divergence: 0.02643
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.07405

Collected Steps per Second: 11,165.74106
Overall Steps per Second: 9,570.39843

Timestep Collection Time: 4.47870
Timestep Consumption Time: 0.74658
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.22528

Cumulative Model Updates: 39,094
Cumulative Timesteps: 652,159,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 652159158...
Checkpoint 652159158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,257.15222
Policy Entropy: 1.07298
Value Function Loss: 6.53054

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.07599

Collected Steps per Second: 10,669.46897
Overall Steps per Second: 9,303.62035

Timestep Collection Time: 4.68796
Timestep Consumption Time: 0.68823
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 5.37619

Cumulative Model Updates: 39,097
Cumulative Timesteps: 652,209,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,491.20078
Policy Entropy: 1.06114
Value Function Loss: 6.58368

Mean KL Divergence: 0.02774
SB3 Clip Fraction: 0.16465
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.07363

Collected Steps per Second: 10,940.16406
Overall Steps per Second: 9,370.60764

Timestep Collection Time: 4.57214
Timestep Consumption Time: 0.76582
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 5.33797

Cumulative Model Updates: 39,100
Cumulative Timesteps: 652,259,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 652259196...
Checkpoint 652259196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,936.79566
Policy Entropy: 1.06555
Value Function Loss: 6.92068

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.06918

Collected Steps per Second: 10,834.28499
Overall Steps per Second: 9,490.46112

Timestep Collection Time: 4.61738
Timestep Consumption Time: 0.65381
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.27119

Cumulative Model Updates: 39,103
Cumulative Timesteps: 652,309,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,368.60729
Policy Entropy: 1.07447
Value Function Loss: 6.72511

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 11,142.38748
Overall Steps per Second: 9,533.09744

Timestep Collection Time: 4.48827
Timestep Consumption Time: 0.75767
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.24593

Cumulative Model Updates: 39,106
Cumulative Timesteps: 652,359,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 652359232...
Checkpoint 652359232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,003.82530
Policy Entropy: 1.06139
Value Function Loss: 6.44754

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.07243

Collected Steps per Second: 10,911.43505
Overall Steps per Second: 9,397.68585

Timestep Collection Time: 4.58473
Timestep Consumption Time: 0.73849
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.32323

Cumulative Model Updates: 39,109
Cumulative Timesteps: 652,409,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,268.51910
Policy Entropy: 1.06008
Value Function Loss: 6.18441

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.11759
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.07469

Collected Steps per Second: 10,923.19830
Overall Steps per Second: 9,532.33358

Timestep Collection Time: 4.57870
Timestep Consumption Time: 0.66808
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.24677

Cumulative Model Updates: 39,112
Cumulative Timesteps: 652,459,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 652459272...
Checkpoint 652459272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442,052.60506
Policy Entropy: 1.07026
Value Function Loss: 6.02929

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.08120

Collected Steps per Second: 10,429.57498
Overall Steps per Second: 8,978.53031

Timestep Collection Time: 4.79463
Timestep Consumption Time: 0.77487
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.56951

Cumulative Model Updates: 39,115
Cumulative Timesteps: 652,509,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,326.78032
Policy Entropy: 1.08089
Value Function Loss: 6.33419

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.08135

Collected Steps per Second: 10,892.36244
Overall Steps per Second: 9,470.55300

Timestep Collection Time: 4.59276
Timestep Consumption Time: 0.68951
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 5.28227

Cumulative Model Updates: 39,118
Cumulative Timesteps: 652,559,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 652559304...
Checkpoint 652559304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,795.47041
Policy Entropy: 1.07891
Value Function Loss: 6.30549

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.07439

Collected Steps per Second: 11,048.03634
Overall Steps per Second: 9,365.36876

Timestep Collection Time: 4.52750
Timestep Consumption Time: 0.81345
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.34095

Cumulative Model Updates: 39,121
Cumulative Timesteps: 652,609,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,197.25810
Policy Entropy: 1.07212
Value Function Loss: 6.60573

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.06842

Collected Steps per Second: 10,801.47441
Overall Steps per Second: 9,375.78795

Timestep Collection Time: 4.63122
Timestep Consumption Time: 0.70423
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.33544

Cumulative Model Updates: 39,124
Cumulative Timesteps: 652,659,348

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 652659348...
Checkpoint 652659348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,786.03604
Policy Entropy: 1.08358
Value Function Loss: 6.69971

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.06787

Collected Steps per Second: 11,022.60549
Overall Steps per Second: 9,409.08862

Timestep Collection Time: 4.53777
Timestep Consumption Time: 0.77816
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.31592

Cumulative Model Updates: 39,127
Cumulative Timesteps: 652,709,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375,347.81373
Policy Entropy: 1.07570
Value Function Loss: 6.88110

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.15404
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.07007

Collected Steps per Second: 10,696.92789
Overall Steps per Second: 9,128.46775

Timestep Collection Time: 4.67443
Timestep Consumption Time: 0.80316
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.47759

Cumulative Model Updates: 39,130
Cumulative Timesteps: 652,759,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 652759368...
Checkpoint 652759368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,641.41750
Policy Entropy: 1.06700
Value Function Loss: 6.69711

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.07902

Collected Steps per Second: 10,799.18550
Overall Steps per Second: 9,430.47758

Timestep Collection Time: 4.63183
Timestep Consumption Time: 0.67225
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.30408

Cumulative Model Updates: 39,133
Cumulative Timesteps: 652,809,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,712.56500
Policy Entropy: 1.04921
Value Function Loss: 6.20966

Mean KL Divergence: 0.02696
SB3 Clip Fraction: 0.16194
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 11,469.91785
Overall Steps per Second: 9,740.41564

Timestep Collection Time: 4.35940
Timestep Consumption Time: 0.77405
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.13346

Cumulative Model Updates: 39,136
Cumulative Timesteps: 652,859,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 652859390...
Checkpoint 652859390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,137.26872
Policy Entropy: 1.06385
Value Function Loss: 6.00281

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.07611

Collected Steps per Second: 11,250.40325
Overall Steps per Second: 9,651.41580

Timestep Collection Time: 4.44517
Timestep Consumption Time: 0.73645
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.18162

Cumulative Model Updates: 39,139
Cumulative Timesteps: 652,909,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,772.71179
Policy Entropy: 1.06773
Value Function Loss: 5.89855

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 11,687.33108
Overall Steps per Second: 9,939.13275

Timestep Collection Time: 4.27814
Timestep Consumption Time: 0.75248
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.03062

Cumulative Model Updates: 39,142
Cumulative Timesteps: 652,959,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 652959400...
Checkpoint 652959400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,420.96504
Policy Entropy: 1.06754
Value Function Loss: 6.22416

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.08470

Collected Steps per Second: 11,463.11603
Overall Steps per Second: 9,783.72774

Timestep Collection Time: 4.36339
Timestep Consumption Time: 0.74898
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.11237

Cumulative Model Updates: 39,145
Cumulative Timesteps: 653,009,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,459.67406
Policy Entropy: 1.05309
Value Function Loss: 6.46982

Mean KL Divergence: 0.02971
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.08867

Collected Steps per Second: 10,948.78412
Overall Steps per Second: 9,553.18138

Timestep Collection Time: 4.56690
Timestep Consumption Time: 0.66717
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.23407

Cumulative Model Updates: 39,148
Cumulative Timesteps: 653,059,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 653059420...
Checkpoint 653059420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,110.56255
Policy Entropy: 1.07495
Value Function Loss: 6.55272

Mean KL Divergence: 0.02437
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.07871

Collected Steps per Second: 11,124.50935
Overall Steps per Second: 9,425.31389

Timestep Collection Time: 4.49512
Timestep Consumption Time: 0.81038
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 5.30550

Cumulative Model Updates: 39,151
Cumulative Timesteps: 653,109,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,033.83901
Policy Entropy: 1.08278
Value Function Loss: 6.48588

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.07449

Collected Steps per Second: 11,035.57122
Overall Steps per Second: 9,473.91024

Timestep Collection Time: 4.53207
Timestep Consumption Time: 0.74706
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.27913

Cumulative Model Updates: 39,154
Cumulative Timesteps: 653,159,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 653159440...
Checkpoint 653159440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,875.57080
Policy Entropy: 1.07107
Value Function Loss: 6.18568

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.06961

Collected Steps per Second: 11,389.06081
Overall Steps per Second: 9,728.93329

Timestep Collection Time: 4.39193
Timestep Consumption Time: 0.74943
PPO Batch Consumption Time: 0.03309
Total Iteration Time: 5.14137

Cumulative Model Updates: 39,157
Cumulative Timesteps: 653,209,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,601.14153
Policy Entropy: 1.05579
Value Function Loss: 6.24503

Mean KL Divergence: 0.03337
SB3 Clip Fraction: 0.16132
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 11,144.34322
Overall Steps per Second: 9,467.44693

Timestep Collection Time: 4.48820
Timestep Consumption Time: 0.79496
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.28316

Cumulative Model Updates: 39,160
Cumulative Timesteps: 653,259,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 653259478...
Checkpoint 653259478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398,452.01480
Policy Entropy: 1.06554
Value Function Loss: 6.20089

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.08531

Collected Steps per Second: 11,140.86224
Overall Steps per Second: 9,677.36238

Timestep Collection Time: 4.49014
Timestep Consumption Time: 0.67904
PPO Batch Consumption Time: 0.04023
Total Iteration Time: 5.16918

Cumulative Model Updates: 39,163
Cumulative Timesteps: 653,309,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566,873.62882
Policy Entropy: 1.07500
Value Function Loss: 6.40052

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.07905

Collected Steps per Second: 10,607.92905
Overall Steps per Second: 9,116.79462

Timestep Collection Time: 4.71515
Timestep Consumption Time: 0.77121
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.48636

Cumulative Model Updates: 39,166
Cumulative Timesteps: 653,359,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 653359520...
Checkpoint 653359520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,109.14247
Policy Entropy: 1.05975
Value Function Loss: 6.31082

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.07369

Collected Steps per Second: 10,974.84172
Overall Steps per Second: 9,541.26270

Timestep Collection Time: 4.55660
Timestep Consumption Time: 0.68463
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.24123

Cumulative Model Updates: 39,169
Cumulative Timesteps: 653,409,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,138.09746
Policy Entropy: 1.05194
Value Function Loss: 6.55661

Mean KL Divergence: 0.03499
SB3 Clip Fraction: 0.16325
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 11,194.28274
Overall Steps per Second: 9,555.42439

Timestep Collection Time: 4.46782
Timestep Consumption Time: 0.76628
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.23410

Cumulative Model Updates: 39,172
Cumulative Timesteps: 653,459,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 653459542...
Checkpoint 653459542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,919.62240
Policy Entropy: 1.07106
Value Function Loss: 6.53753

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.10997
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 10,585.07696
Overall Steps per Second: 9,256.39184

Timestep Collection Time: 4.72647
Timestep Consumption Time: 0.67845
PPO Batch Consumption Time: 0.03389
Total Iteration Time: 5.40491

Cumulative Model Updates: 39,175
Cumulative Timesteps: 653,509,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,482.97709
Policy Entropy: 1.07558
Value Function Loss: 6.61569

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.07317

Collected Steps per Second: 11,111.18936
Overall Steps per Second: 9,450.28225

Timestep Collection Time: 4.50123
Timestep Consumption Time: 0.79110
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.29233

Cumulative Model Updates: 39,178
Cumulative Timesteps: 653,559,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 653559586...
Checkpoint 653559586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,039.23332
Policy Entropy: 1.04330
Value Function Loss: 6.57321

Mean KL Divergence: 0.05975
SB3 Clip Fraction: 0.17665
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.06982

Collected Steps per Second: 10,941.00617
Overall Steps per Second: 9,310.32371

Timestep Collection Time: 4.57051
Timestep Consumption Time: 0.80052
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.37103

Cumulative Model Updates: 39,181
Cumulative Timesteps: 653,609,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,011.52081
Policy Entropy: 1.05894
Value Function Loss: 6.60486

Mean KL Divergence: 0.03327
SB3 Clip Fraction: 0.14864
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.06303

Collected Steps per Second: 10,974.66505
Overall Steps per Second: 9,528.20375

Timestep Collection Time: 4.55595
Timestep Consumption Time: 0.69163
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.24758

Cumulative Model Updates: 39,184
Cumulative Timesteps: 653,659,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 653659592...
Checkpoint 653659592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,555.27351
Policy Entropy: 1.05564
Value Function Loss: 6.54741

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 10,916.29074
Overall Steps per Second: 9,340.68059

Timestep Collection Time: 4.58031
Timestep Consumption Time: 0.77262
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.35293

Cumulative Model Updates: 39,187
Cumulative Timesteps: 653,709,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,537.89705
Policy Entropy: 1.05525
Value Function Loss: 6.36732

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.07801

Collected Steps per Second: 10,808.90672
Overall Steps per Second: 9,324.11535

Timestep Collection Time: 4.62730
Timestep Consumption Time: 0.73686
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 5.36415

Cumulative Model Updates: 39,190
Cumulative Timesteps: 653,759,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 653759608...
Checkpoint 653759608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,030.42749
Policy Entropy: 1.06596
Value Function Loss: 6.32484

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.07140

Collected Steps per Second: 10,740.25872
Overall Steps per Second: 9,186.38124

Timestep Collection Time: 4.65613
Timestep Consumption Time: 0.78758
PPO Batch Consumption Time: 0.03350
Total Iteration Time: 5.44371

Cumulative Model Updates: 39,193
Cumulative Timesteps: 653,809,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399,576.59492
Policy Entropy: 1.06647
Value Function Loss: 6.15499

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.07607

Collected Steps per Second: 10,912.39386
Overall Steps per Second: 9,484.62281

Timestep Collection Time: 4.58323
Timestep Consumption Time: 0.68994
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.27317

Cumulative Model Updates: 39,196
Cumulative Timesteps: 653,859,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 653859630...
Checkpoint 653859630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,603.95942
Policy Entropy: 1.06914
Value Function Loss: 5.96402

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.07391

Collected Steps per Second: 10,489.70064
Overall Steps per Second: 8,986.34047

Timestep Collection Time: 4.76791
Timestep Consumption Time: 0.79764
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.56556

Cumulative Model Updates: 39,199
Cumulative Timesteps: 653,909,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,350.58633
Policy Entropy: 1.06858
Value Function Loss: 6.23832

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.06514
Value Function Update Magnitude: 0.07256

Collected Steps per Second: 11,894.96366
Overall Steps per Second: 10,071.14057

Timestep Collection Time: 4.20447
Timestep Consumption Time: 0.76140
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 4.96587

Cumulative Model Updates: 39,202
Cumulative Timesteps: 653,959,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 653959656...
Checkpoint 653959656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,900.36837
Policy Entropy: 1.06606
Value Function Loss: 6.73868

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.06963

Collected Steps per Second: 11,817.76868
Overall Steps per Second: 10,106.58405

Timestep Collection Time: 4.23261
Timestep Consumption Time: 0.71664
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 4.94925

Cumulative Model Updates: 39,205
Cumulative Timesteps: 654,009,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,969.74975
Policy Entropy: 1.07797
Value Function Loss: 7.12091

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.07160

Collected Steps per Second: 11,546.08751
Overall Steps per Second: 9,774.14907

Timestep Collection Time: 4.33186
Timestep Consumption Time: 0.78531
PPO Batch Consumption Time: 0.03886
Total Iteration Time: 5.11717

Cumulative Model Updates: 39,208
Cumulative Timesteps: 654,059,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 654059692...
Checkpoint 654059692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,145.22069
Policy Entropy: 1.08583
Value Function Loss: 6.83302

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.06209

Collected Steps per Second: 11,936.01061
Overall Steps per Second: 10,299.26375

Timestep Collection Time: 4.19118
Timestep Consumption Time: 0.66606
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.85724

Cumulative Model Updates: 39,211
Cumulative Timesteps: 654,109,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,950.66934
Policy Entropy: 1.07204
Value Function Loss: 6.34494

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.05494

Collected Steps per Second: 11,793.12866
Overall Steps per Second: 10,027.94510

Timestep Collection Time: 4.24179
Timestep Consumption Time: 0.74667
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 4.98846

Cumulative Model Updates: 39,214
Cumulative Timesteps: 654,159,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 654159742...
Checkpoint 654159742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,823.83747
Policy Entropy: 1.05614
Value Function Loss: 6.24067

Mean KL Divergence: 0.04341
SB3 Clip Fraction: 0.20387
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.05156

Collected Steps per Second: 11,094.21511
Overall Steps per Second: 9,590.12662

Timestep Collection Time: 4.50685
Timestep Consumption Time: 0.70684
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 5.21370

Cumulative Model Updates: 39,217
Cumulative Timesteps: 654,209,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,846.62098
Policy Entropy: 1.07358
Value Function Loss: 6.37414

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.04799

Collected Steps per Second: 11,194.82573
Overall Steps per Second: 9,482.48168

Timestep Collection Time: 4.46796
Timestep Consumption Time: 0.80682
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.27478

Cumulative Model Updates: 39,220
Cumulative Timesteps: 654,259,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 654259760...
Checkpoint 654259760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329,316.41962
Policy Entropy: 1.06063
Value Function Loss: 6.63427

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.04541

Collected Steps per Second: 11,193.95004
Overall Steps per Second: 9,562.47674

Timestep Collection Time: 4.46956
Timestep Consumption Time: 0.76256
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.23212

Cumulative Model Updates: 39,223
Cumulative Timesteps: 654,309,792

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,753.14135
Policy Entropy: 1.04804
Value Function Loss: 6.88071

Mean KL Divergence: 0.03922
SB3 Clip Fraction: 0.19415
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.04715

Collected Steps per Second: 11,318.89498
Overall Steps per Second: 9,805.42735

Timestep Collection Time: 4.41916
Timestep Consumption Time: 0.68210
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.10126

Cumulative Model Updates: 39,226
Cumulative Timesteps: 654,359,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 654359812...
Checkpoint 654359812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,912.66544
Policy Entropy: 1.05948
Value Function Loss: 6.61584

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.04795

Collected Steps per Second: 10,933.67990
Overall Steps per Second: 9,345.25529

Timestep Collection Time: 4.57412
Timestep Consumption Time: 0.77747
PPO Batch Consumption Time: 0.03746
Total Iteration Time: 5.35159

Cumulative Model Updates: 39,229
Cumulative Timesteps: 654,409,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445,979.07573
Policy Entropy: 1.07324
Value Function Loss: 6.50833

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.04799

Collected Steps per Second: 11,141.41522
Overall Steps per Second: 9,528.29492

Timestep Collection Time: 4.48920
Timestep Consumption Time: 0.76001
PPO Batch Consumption Time: 0.03889
Total Iteration Time: 5.24921

Cumulative Model Updates: 39,232
Cumulative Timesteps: 654,459,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 654459840...
Checkpoint 654459840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,085.69108
Policy Entropy: 1.06664
Value Function Loss: 6.33453

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.06750
Value Function Update Magnitude: 0.05013

Collected Steps per Second: 10,989.31795
Overall Steps per Second: 9,350.67630

Timestep Collection Time: 4.55005
Timestep Consumption Time: 0.79737
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.34742

Cumulative Model Updates: 39,235
Cumulative Timesteps: 654,509,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,427.88149
Policy Entropy: 1.06189
Value Function Loss: 6.64024

Mean KL Divergence: 0.02837
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.07123
Value Function Update Magnitude: 0.04617

Collected Steps per Second: 11,166.33960
Overall Steps per Second: 9,561.34203

Timestep Collection Time: 4.47792
Timestep Consumption Time: 0.75168
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 5.22960

Cumulative Model Updates: 39,238
Cumulative Timesteps: 654,559,844

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 654559844...
Checkpoint 654559844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,022.20764
Policy Entropy: 1.07885
Value Function Loss: 6.60401

Mean KL Divergence: 0.02905
SB3 Clip Fraction: 0.16924
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.04441

Collected Steps per Second: 10,694.31953
Overall Steps per Second: 9,271.33142

Timestep Collection Time: 4.67557
Timestep Consumption Time: 0.71762
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.39318

Cumulative Model Updates: 39,241
Cumulative Timesteps: 654,609,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,541.26425
Policy Entropy: 1.06939
Value Function Loss: 6.52185

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.16517
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.05120

Collected Steps per Second: 10,737.70373
Overall Steps per Second: 9,164.05054

Timestep Collection Time: 4.65817
Timestep Consumption Time: 0.79990
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 5.45807

Cumulative Model Updates: 39,244
Cumulative Timesteps: 654,659,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 654659864...
Checkpoint 654659864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,351.53931
Policy Entropy: 1.06595
Value Function Loss: 6.45178

Mean KL Divergence: 0.02546
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.04574

Collected Steps per Second: 10,807.98519
Overall Steps per Second: 9,317.62651

Timestep Collection Time: 4.62639
Timestep Consumption Time: 0.73999
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.36639

Cumulative Model Updates: 39,247
Cumulative Timesteps: 654,709,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305,699.31077
Policy Entropy: 1.05528
Value Function Loss: 6.69855

Mean KL Divergence: 0.03864
SB3 Clip Fraction: 0.18737
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 10,730.61295
Overall Steps per Second: 9,222.65527

Timestep Collection Time: 4.66031
Timestep Consumption Time: 0.76199
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.42230

Cumulative Model Updates: 39,250
Cumulative Timesteps: 654,759,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 654759874...
Checkpoint 654759874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,169.17527
Policy Entropy: 1.06879
Value Function Loss: 6.67257

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.07870

Collected Steps per Second: 10,869.99902
Overall Steps per Second: 9,308.03302

Timestep Collection Time: 4.60037
Timestep Consumption Time: 0.77198
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.37235

Cumulative Model Updates: 39,253
Cumulative Timesteps: 654,809,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,738.29824
Policy Entropy: 1.05846
Value Function Loss: 6.55016

Mean KL Divergence: 0.02511
SB3 Clip Fraction: 0.16242
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.06828

Collected Steps per Second: 10,873.98053
Overall Steps per Second: 9,523.72954

Timestep Collection Time: 4.59887
Timestep Consumption Time: 0.65202
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 5.25088

Cumulative Model Updates: 39,256
Cumulative Timesteps: 654,859,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 654859888...
Checkpoint 654859888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,961.75656
Policy Entropy: 1.04679
Value Function Loss: 6.16701

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.06643

Collected Steps per Second: 10,911.48269
Overall Steps per Second: 9,324.16592

Timestep Collection Time: 4.58434
Timestep Consumption Time: 0.78042
PPO Batch Consumption Time: 0.03812
Total Iteration Time: 5.36477

Cumulative Model Updates: 39,259
Cumulative Timesteps: 654,909,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,582.57566
Policy Entropy: 1.05310
Value Function Loss: 6.05953

Mean KL Divergence: 0.02216
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.06729

Collected Steps per Second: 10,854.55891
Overall Steps per Second: 9,443.02553

Timestep Collection Time: 4.60857
Timestep Consumption Time: 0.68888
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.29745

Cumulative Model Updates: 39,262
Cumulative Timesteps: 654,959,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 654959934...
Checkpoint 654959934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,756.09996
Policy Entropy: 1.05483
Value Function Loss: 5.93094

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.07242

Collected Steps per Second: 10,727.24892
Overall Steps per Second: 9,101.41234

Timestep Collection Time: 4.66196
Timestep Consumption Time: 0.83279
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 5.49475

Cumulative Model Updates: 39,265
Cumulative Timesteps: 655,009,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,074.37370
Policy Entropy: 1.06826
Value Function Loss: 6.00192

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.06716

Collected Steps per Second: 10,030.86242
Overall Steps per Second: 8,689.00672

Timestep Collection Time: 4.98681
Timestep Consumption Time: 0.77012
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.75693

Cumulative Model Updates: 39,268
Cumulative Timesteps: 655,059,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 655059966...
Checkpoint 655059966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,389.92891
Policy Entropy: 1.06489
Value Function Loss: 5.89868

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.08498

Collected Steps per Second: 11,727.80253
Overall Steps per Second: 9,854.66681

Timestep Collection Time: 4.26491
Timestep Consumption Time: 0.81066
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.07556

Cumulative Model Updates: 39,271
Cumulative Timesteps: 655,109,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,100.08130
Policy Entropy: 1.06249
Value Function Loss: 6.01166

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.09263

Collected Steps per Second: 11,383.23456
Overall Steps per Second: 9,702.20845

Timestep Collection Time: 4.39488
Timestep Consumption Time: 0.76147
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.15635

Cumulative Model Updates: 39,274
Cumulative Timesteps: 655,160,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 655160012...
Checkpoint 655160012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,063.36829
Policy Entropy: 1.03199
Value Function Loss: 6.21214

Mean KL Divergence: 0.04430
SB3 Clip Fraction: 0.19547
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.08037

Collected Steps per Second: 11,180.45474
Overall Steps per Second: 9,688.97822

Timestep Collection Time: 4.47227
Timestep Consumption Time: 0.68844
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.16071

Cumulative Model Updates: 39,277
Cumulative Timesteps: 655,210,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,509.57767
Policy Entropy: 1.05232
Value Function Loss: 6.43676

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.15309
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.07727

Collected Steps per Second: 11,513.86761
Overall Steps per Second: 9,766.89894

Timestep Collection Time: 4.34502
Timestep Consumption Time: 0.77718
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.12220

Cumulative Model Updates: 39,280
Cumulative Timesteps: 655,260,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 655260042...
Checkpoint 655260042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,436.27572
Policy Entropy: 1.04737
Value Function Loss: 6.70635

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.07249

Collected Steps per Second: 11,240.82531
Overall Steps per Second: 9,585.17593

Timestep Collection Time: 4.44985
Timestep Consumption Time: 0.76862
PPO Batch Consumption Time: 0.04132
Total Iteration Time: 5.21847

Cumulative Model Updates: 39,283
Cumulative Timesteps: 655,310,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,295.63986
Policy Entropy: 1.03839
Value Function Loss: 6.88664

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.16398
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.06918

Collected Steps per Second: 11,153.65900
Overall Steps per Second: 9,492.22624

Timestep Collection Time: 4.48499
Timestep Consumption Time: 0.78501
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.27000

Cumulative Model Updates: 39,286
Cumulative Timesteps: 655,360,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 655360086...
Checkpoint 655360086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419,525.08818
Policy Entropy: 1.04791
Value Function Loss: 6.76981

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.15526
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.07132

Collected Steps per Second: 11,096.16229
Overall Steps per Second: 9,661.88540

Timestep Collection Time: 4.50678
Timestep Consumption Time: 0.66902
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.17580

Cumulative Model Updates: 39,289
Cumulative Timesteps: 655,410,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,438.76675
Policy Entropy: 1.05196
Value Function Loss: 6.51764

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 11,476.65341
Overall Steps per Second: 9,778.87186

Timestep Collection Time: 4.35946
Timestep Consumption Time: 0.75688
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.11634

Cumulative Model Updates: 39,292
Cumulative Timesteps: 655,460,126

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 655460126...
Checkpoint 655460126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,999.88341
Policy Entropy: 1.04534
Value Function Loss: 6.40544

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.08546

Collected Steps per Second: 11,277.77400
Overall Steps per Second: 9,656.40803

Timestep Collection Time: 4.43474
Timestep Consumption Time: 0.74462
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.17936

Cumulative Model Updates: 39,295
Cumulative Timesteps: 655,510,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,542.14763
Policy Entropy: 1.02953
Value Function Loss: 6.96832

Mean KL Divergence: 0.04008
SB3 Clip Fraction: 0.17037
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.09354

Collected Steps per Second: 11,330.03930
Overall Steps per Second: 9,621.78824

Timestep Collection Time: 4.41499
Timestep Consumption Time: 0.78384
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.19883

Cumulative Model Updates: 39,298
Cumulative Timesteps: 655,560,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 655560162...
Checkpoint 655560162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,692.25840
Policy Entropy: 1.04444
Value Function Loss: 6.91792

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.08963

Collected Steps per Second: 10,645.21001
Overall Steps per Second: 9,124.23494

Timestep Collection Time: 4.69695
Timestep Consumption Time: 0.78296
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.47991

Cumulative Model Updates: 39,301
Cumulative Timesteps: 655,610,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,964.25097
Policy Entropy: 1.06200
Value Function Loss: 7.13296

Mean KL Divergence: 0.02919
SB3 Clip Fraction: 0.17005
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.07697

Collected Steps per Second: 10,841.88372
Overall Steps per Second: 9,462.54493

Timestep Collection Time: 4.61248
Timestep Consumption Time: 0.67235
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.28484

Cumulative Model Updates: 39,304
Cumulative Timesteps: 655,660,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 655660170...
Checkpoint 655660170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,207.14615
Policy Entropy: 1.03219
Value Function Loss: 6.82017

Mean KL Divergence: 0.02863
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.07287

Collected Steps per Second: 11,027.13998
Overall Steps per Second: 9,459.16819

Timestep Collection Time: 4.53663
Timestep Consumption Time: 0.75200
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.28863

Cumulative Model Updates: 39,307
Cumulative Timesteps: 655,710,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,196.70216
Policy Entropy: 1.06147
Value Function Loss: 6.80804

Mean KL Divergence: 0.03053
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.07966

Collected Steps per Second: 11,141.03469
Overall Steps per Second: 9,571.65009

Timestep Collection Time: 4.48899
Timestep Consumption Time: 0.73602
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.22501

Cumulative Model Updates: 39,310
Cumulative Timesteps: 655,760,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 655760208...
Checkpoint 655760208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,541.48190
Policy Entropy: 1.06883
Value Function Loss: 6.67936

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 10,901.25531
Overall Steps per Second: 9,472.46005

Timestep Collection Time: 4.58736
Timestep Consumption Time: 0.69194
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.27930

Cumulative Model Updates: 39,313
Cumulative Timesteps: 655,810,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,096.70986
Policy Entropy: 1.06430
Value Function Loss: 6.57540

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.08387

Collected Steps per Second: 10,863.83099
Overall Steps per Second: 9,326.15526

Timestep Collection Time: 4.60280
Timestep Consumption Time: 0.75890
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.36170

Cumulative Model Updates: 39,316
Cumulative Timesteps: 655,860,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 655860220...
Checkpoint 655860220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,285.82703
Policy Entropy: 1.05166
Value Function Loss: 6.34728

Mean KL Divergence: 0.03005
SB3 Clip Fraction: 0.15391
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.09257

Collected Steps per Second: 10,456.27845
Overall Steps per Second: 9,016.36734

Timestep Collection Time: 4.78488
Timestep Consumption Time: 0.76414
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.54902

Cumulative Model Updates: 39,319
Cumulative Timesteps: 655,910,252

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,405.30902
Policy Entropy: 1.05601
Value Function Loss: 6.27659

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.08617

Collected Steps per Second: 11,044.79757
Overall Steps per Second: 9,374.86358

Timestep Collection Time: 4.52829
Timestep Consumption Time: 0.80662
PPO Batch Consumption Time: 0.03751
Total Iteration Time: 5.33490

Cumulative Model Updates: 39,322
Cumulative Timesteps: 655,960,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 655960266...
Checkpoint 655960266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,584.55129
Policy Entropy: 1.06296
Value Function Loss: 6.28028

Mean KL Divergence: 0.02566
SB3 Clip Fraction: 0.16557
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.08188

Collected Steps per Second: 10,792.98954
Overall Steps per Second: 9,245.00312

Timestep Collection Time: 4.63430
Timestep Consumption Time: 0.77597
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.41027

Cumulative Model Updates: 39,325
Cumulative Timesteps: 656,010,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,155.79361
Policy Entropy: 1.04193
Value Function Loss: 6.80745

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.07996

Collected Steps per Second: 10,785.56473
Overall Steps per Second: 9,432.53158

Timestep Collection Time: 4.63768
Timestep Consumption Time: 0.66524
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.30292

Cumulative Model Updates: 39,328
Cumulative Timesteps: 656,060,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 656060304...
Checkpoint 656060304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,025.82426
Policy Entropy: 1.06187
Value Function Loss: 6.39952

Mean KL Divergence: 0.03128
SB3 Clip Fraction: 0.16483
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.07987

Collected Steps per Second: 11,038.39365
Overall Steps per Second: 9,444.80425

Timestep Collection Time: 4.53200
Timestep Consumption Time: 0.76467
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.29667

Cumulative Model Updates: 39,331
Cumulative Timesteps: 656,110,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,890.87275
Policy Entropy: 1.05718
Value Function Loss: 6.54882

Mean KL Divergence: 0.02582
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.07856

Collected Steps per Second: 10,823.46398
Overall Steps per Second: 9,162.59504

Timestep Collection Time: 4.62236
Timestep Consumption Time: 0.83788
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.46024

Cumulative Model Updates: 39,334
Cumulative Timesteps: 656,160,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 656160360...
Checkpoint 656160360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,769.94030
Policy Entropy: 1.04354
Value Function Loss: 6.19351

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.09237

Collected Steps per Second: 11,614.36761
Overall Steps per Second: 9,812.75824

Timestep Collection Time: 4.30708
Timestep Consumption Time: 0.79077
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 5.09785

Cumulative Model Updates: 39,337
Cumulative Timesteps: 656,210,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,641.35643
Policy Entropy: 1.02390
Value Function Loss: 6.67289

Mean KL Divergence: 0.02992
SB3 Clip Fraction: 0.17639
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.09690

Collected Steps per Second: 12,033.77947
Overall Steps per Second: 10,163.00598

Timestep Collection Time: 4.15597
Timestep Consumption Time: 0.76502
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 4.92098

Cumulative Model Updates: 39,340
Cumulative Timesteps: 656,260,396

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 656260396...
Checkpoint 656260396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,367.56860
Policy Entropy: 1.04371
Value Function Loss: 6.53620

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.08792

Collected Steps per Second: 11,793.77303
Overall Steps per Second: 10,124.26279

Timestep Collection Time: 4.24105
Timestep Consumption Time: 0.69936
PPO Batch Consumption Time: 0.03311
Total Iteration Time: 4.94041

Cumulative Model Updates: 39,343
Cumulative Timesteps: 656,310,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,887.51775
Policy Entropy: 1.04791
Value Function Loss: 6.46790

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.08131

Collected Steps per Second: 11,141.92030
Overall Steps per Second: 9,405.98964

Timestep Collection Time: 4.48899
Timestep Consumption Time: 0.82847
PPO Batch Consumption Time: 0.03851
Total Iteration Time: 5.31746

Cumulative Model Updates: 39,346
Cumulative Timesteps: 656,360,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 656360430...
Checkpoint 656360430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,405.88776
Policy Entropy: 1.05695
Value Function Loss: 6.08444

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.08513

Collected Steps per Second: 11,956.02255
Overall Steps per Second: 10,249.51749

Timestep Collection Time: 4.18350
Timestep Consumption Time: 0.69654
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.88003

Cumulative Model Updates: 39,349
Cumulative Timesteps: 656,410,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,689.42030
Policy Entropy: 1.05304
Value Function Loss: 6.15500

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 11,692.12917
Overall Steps per Second: 9,793.04408

Timestep Collection Time: 4.27860
Timestep Consumption Time: 0.82971
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.10832

Cumulative Model Updates: 39,352
Cumulative Timesteps: 656,460,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 656460474...
Checkpoint 656460474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,062.58812
Policy Entropy: 1.06920
Value Function Loss: 6.25810

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.11316

Collected Steps per Second: 11,295.05369
Overall Steps per Second: 9,665.71947

Timestep Collection Time: 4.42813
Timestep Consumption Time: 0.74644
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.17458

Cumulative Model Updates: 39,355
Cumulative Timesteps: 656,510,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,461.34592
Policy Entropy: 1.07539
Value Function Loss: 6.69555

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.11746
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.09626

Collected Steps per Second: 11,565.77300
Overall Steps per Second: 9,814.17446

Timestep Collection Time: 4.32466
Timestep Consumption Time: 0.77185
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 5.09651

Cumulative Model Updates: 39,358
Cumulative Timesteps: 656,560,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 656560508...
Checkpoint 656560508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,966.00452
Policy Entropy: 1.07627
Value Function Loss: 6.56954

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.06265
Value Function Update Magnitude: 0.08372

Collected Steps per Second: 11,151.27021
Overall Steps per Second: 9,483.00843

Timestep Collection Time: 4.48505
Timestep Consumption Time: 0.78902
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.27406

Cumulative Model Updates: 39,361
Cumulative Timesteps: 656,610,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,863.80029
Policy Entropy: 1.08566
Value Function Loss: 6.47520

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.09590

Collected Steps per Second: 11,131.70040
Overall Steps per Second: 9,692.57362

Timestep Collection Time: 4.49365
Timestep Consumption Time: 0.66721
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 5.16086

Cumulative Model Updates: 39,364
Cumulative Timesteps: 656,660,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 656660544...
Checkpoint 656660544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,944.51750
Policy Entropy: 1.09023
Value Function Loss: 6.22035

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.09358

Collected Steps per Second: 11,202.97253
Overall Steps per Second: 9,523.27922

Timestep Collection Time: 4.46542
Timestep Consumption Time: 0.78760
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.25302

Cumulative Model Updates: 39,367
Cumulative Timesteps: 656,710,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,708.97064
Policy Entropy: 1.10175
Value Function Loss: 6.35623

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.07754

Collected Steps per Second: 10,603.68522
Overall Steps per Second: 9,116.17380

Timestep Collection Time: 4.71553
Timestep Consumption Time: 0.76945
PPO Batch Consumption Time: 0.03320
Total Iteration Time: 5.48498

Cumulative Model Updates: 39,370
Cumulative Timesteps: 656,760,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 656760572...
Checkpoint 656760572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,377.99201
Policy Entropy: 1.10574
Value Function Loss: 6.79937

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.09368

Collected Steps per Second: 10,889.68192
Overall Steps per Second: 9,448.43072

Timestep Collection Time: 4.59352
Timestep Consumption Time: 0.70069
PPO Batch Consumption Time: 0.03821
Total Iteration Time: 5.29421

Cumulative Model Updates: 39,373
Cumulative Timesteps: 656,810,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,143.23742
Policy Entropy: 1.10851
Value Function Loss: 6.98307

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.06818
Value Function Update Magnitude: 0.11955

Collected Steps per Second: 10,808.17147
Overall Steps per Second: 9,281.08488

Timestep Collection Time: 4.62687
Timestep Consumption Time: 0.76129
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.38816

Cumulative Model Updates: 39,376
Cumulative Timesteps: 656,860,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 656860602...
Checkpoint 656860602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,644.61352
Policy Entropy: 1.10223
Value Function Loss: 6.96601

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.06711
Value Function Update Magnitude: 0.12351

Collected Steps per Second: 10,870.73586
Overall Steps per Second: 9,478.21609

Timestep Collection Time: 4.60171
Timestep Consumption Time: 0.67607
PPO Batch Consumption Time: 0.03763
Total Iteration Time: 5.27779

Cumulative Model Updates: 39,379
Cumulative Timesteps: 656,910,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,336.99928
Policy Entropy: 1.10017
Value Function Loss: 6.70127

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.09973

Collected Steps per Second: 10,869.59167
Overall Steps per Second: 9,340.95471

Timestep Collection Time: 4.60146
Timestep Consumption Time: 0.75302
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 5.35448

Cumulative Model Updates: 39,382
Cumulative Timesteps: 656,960,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 656960642...
Checkpoint 656960642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417,252.15206
Policy Entropy: 1.10887
Value Function Loss: 6.44196

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.09083

Collected Steps per Second: 11,178.88766
Overall Steps per Second: 9,619.34784

Timestep Collection Time: 4.47433
Timestep Consumption Time: 0.72540
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 5.19973

Cumulative Model Updates: 39,385
Cumulative Timesteps: 657,010,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,030.59091
Policy Entropy: 1.11629
Value Function Loss: 6.38990

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.08065

Collected Steps per Second: 10,764.40398
Overall Steps per Second: 9,245.32506

Timestep Collection Time: 4.64587
Timestep Consumption Time: 0.76335
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.40922

Cumulative Model Updates: 39,388
Cumulative Timesteps: 657,060,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 657060670...
Checkpoint 657060670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,919.74078
Policy Entropy: 1.11508
Value Function Loss: 6.63854

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.08498

Collected Steps per Second: 10,731.16379
Overall Steps per Second: 9,076.80159

Timestep Collection Time: 4.66063
Timestep Consumption Time: 0.84946
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.51009

Cumulative Model Updates: 39,391
Cumulative Timesteps: 657,110,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367,504.19471
Policy Entropy: 1.10720
Value Function Loss: 6.98783

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.06987
Value Function Update Magnitude: 0.10330

Collected Steps per Second: 10,771.89837
Overall Steps per Second: 9,287.29398

Timestep Collection Time: 4.64208
Timestep Consumption Time: 0.74205
PPO Batch Consumption Time: 0.03971
Total Iteration Time: 5.38413

Cumulative Model Updates: 39,394
Cumulative Timesteps: 657,160,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 657160688...
Checkpoint 657160688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422,710.67031
Policy Entropy: 1.11435
Value Function Loss: 7.04973

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 10,726.57992
Overall Steps per Second: 9,188.08385

Timestep Collection Time: 4.66169
Timestep Consumption Time: 0.78058
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.44227

Cumulative Model Updates: 39,397
Cumulative Timesteps: 657,210,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464,236.07425
Policy Entropy: 1.11773
Value Function Loss: 7.07308

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.06318
Value Function Update Magnitude: 0.09326

Collected Steps per Second: 11,081.80884
Overall Steps per Second: 9,482.88662

Timestep Collection Time: 4.51190
Timestep Consumption Time: 0.76076
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.27266

Cumulative Model Updates: 39,400
Cumulative Timesteps: 657,260,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 657260692...
Checkpoint 657260692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414,903.05498
Policy Entropy: 1.12378
Value Function Loss: 6.67132

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.08275
Policy Update Magnitude: 0.07249
Value Function Update Magnitude: 0.08672

Collected Steps per Second: 10,303.50052
Overall Steps per Second: 8,877.87964

Timestep Collection Time: 4.85485
Timestep Consumption Time: 0.77960
PPO Batch Consumption Time: 0.04160
Total Iteration Time: 5.63445

Cumulative Model Updates: 39,403
Cumulative Timesteps: 657,310,714

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,620.04618
Policy Entropy: 1.11823
Value Function Loss: 6.69164

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.07048
Value Function Update Magnitude: 0.07882

Collected Steps per Second: 10,948.21764
Overall Steps per Second: 9,330.09012

Timestep Collection Time: 4.56714
Timestep Consumption Time: 0.79208
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.35922

Cumulative Model Updates: 39,406
Cumulative Timesteps: 657,360,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 657360716...
Checkpoint 657360716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,473.69192
Policy Entropy: 1.11571
Value Function Loss: 6.71122

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.08306

Collected Steps per Second: 11,517.92365
Overall Steps per Second: 9,799.70427

Timestep Collection Time: 4.34228
Timestep Consumption Time: 0.76135
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.10362

Cumulative Model Updates: 39,409
Cumulative Timesteps: 657,410,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,603.72772
Policy Entropy: 1.12399
Value Function Loss: 7.14273

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.07299

Collected Steps per Second: 11,813.63594
Overall Steps per Second: 9,884.51615

Timestep Collection Time: 4.23358
Timestep Consumption Time: 0.82625
PPO Batch Consumption Time: 0.04681
Total Iteration Time: 5.05983

Cumulative Model Updates: 39,412
Cumulative Timesteps: 657,460,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 657460744...
Checkpoint 657460744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,418.73174
Policy Entropy: 1.13474
Value Function Loss: 7.25550

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.06736

Collected Steps per Second: 11,393.66264
Overall Steps per Second: 9,731.04280

Timestep Collection Time: 4.39051
Timestep Consumption Time: 0.75015
PPO Batch Consumption Time: 0.03961
Total Iteration Time: 5.14066

Cumulative Model Updates: 39,415
Cumulative Timesteps: 657,510,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398,591.91461
Policy Entropy: 1.14032
Value Function Loss: 6.90685

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.10020

Collected Steps per Second: 11,489.80929
Overall Steps per Second: 9,894.10562

Timestep Collection Time: 4.35395
Timestep Consumption Time: 0.70220
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.05614

Cumulative Model Updates: 39,418
Cumulative Timesteps: 657,560,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 657560794...
Checkpoint 657560794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,010.72651
Policy Entropy: 1.13181
Value Function Loss: 6.52305

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.06624
Value Function Update Magnitude: 0.10446

Collected Steps per Second: 10,803.44725
Overall Steps per Second: 9,248.04687

Timestep Collection Time: 4.62908
Timestep Consumption Time: 0.77855
PPO Batch Consumption Time: 0.03819
Total Iteration Time: 5.40763

Cumulative Model Updates: 39,421
Cumulative Timesteps: 657,610,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,363.01933
Policy Entropy: 1.13734
Value Function Loss: 6.77181

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.09954

Collected Steps per Second: 11,213.38426
Overall Steps per Second: 9,584.80007

Timestep Collection Time: 4.46092
Timestep Consumption Time: 0.75797
PPO Batch Consumption Time: 0.04082
Total Iteration Time: 5.21889

Cumulative Model Updates: 39,424
Cumulative Timesteps: 657,660,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 657660826...
Checkpoint 657660826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,909.73064
Policy Entropy: 1.13943
Value Function Loss: 7.18369

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.10705

Collected Steps per Second: 11,750.49241
Overall Steps per Second: 9,905.51133

Timestep Collection Time: 4.25735
Timestep Consumption Time: 0.79297
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.05032

Cumulative Model Updates: 39,427
Cumulative Timesteps: 657,710,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,290.57945
Policy Entropy: 1.14415
Value Function Loss: 7.42648

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.10614

Collected Steps per Second: 11,390.26966
Overall Steps per Second: 9,704.24847

Timestep Collection Time: 4.38971
Timestep Consumption Time: 0.76267
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.15238

Cumulative Model Updates: 39,430
Cumulative Timesteps: 657,760,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 657760852...
Checkpoint 657760852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338,151.68774
Policy Entropy: 1.12955
Value Function Loss: 6.85258

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.12149

Collected Steps per Second: 11,212.35285
Overall Steps per Second: 9,711.33802

Timestep Collection Time: 4.46169
Timestep Consumption Time: 0.68961
PPO Batch Consumption Time: 0.03898
Total Iteration Time: 5.15130

Cumulative Model Updates: 39,433
Cumulative Timesteps: 657,810,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,518.89625
Policy Entropy: 1.13615
Value Function Loss: 6.87576

Mean KL Divergence: 0.02933
SB3 Clip Fraction: 0.14710
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.11206

Collected Steps per Second: 11,311.12469
Overall Steps per Second: 9,648.00557

Timestep Collection Time: 4.42237
Timestep Consumption Time: 0.76233
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.18470

Cumulative Model Updates: 39,436
Cumulative Timesteps: 657,860,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 657860900...
Checkpoint 657860900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,753.35638
Policy Entropy: 1.14793
Value Function Loss: 6.99601

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.10115

Collected Steps per Second: 10,549.00189
Overall Steps per Second: 9,124.83351

Timestep Collection Time: 4.74225
Timestep Consumption Time: 0.74015
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.48240

Cumulative Model Updates: 39,439
Cumulative Timesteps: 657,910,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,474.80010
Policy Entropy: 1.15630
Value Function Loss: 7.08429

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.09861

Collected Steps per Second: 11,271.98391
Overall Steps per Second: 9,614.40126

Timestep Collection Time: 4.43702
Timestep Consumption Time: 0.76497
PPO Batch Consumption Time: 0.03375
Total Iteration Time: 5.20199

Cumulative Model Updates: 39,442
Cumulative Timesteps: 657,960,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 657960940...
Checkpoint 657960940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,156.73445
Policy Entropy: 1.14335
Value Function Loss: 6.86300

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.11140

Collected Steps per Second: 10,809.39716
Overall Steps per Second: 9,278.52872

Timestep Collection Time: 4.62672
Timestep Consumption Time: 0.76336
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 5.39008

Cumulative Model Updates: 39,445
Cumulative Timesteps: 658,010,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,064.92091
Policy Entropy: 1.13017
Value Function Loss: 6.79452

Mean KL Divergence: 0.03259
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.10593

Collected Steps per Second: 11,061.72153
Overall Steps per Second: 9,593.66256

Timestep Collection Time: 4.52063
Timestep Consumption Time: 0.69176
PPO Batch Consumption Time: 0.04305
Total Iteration Time: 5.21240

Cumulative Model Updates: 39,448
Cumulative Timesteps: 658,060,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 658060958...
Checkpoint 658060958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,658.97315
Policy Entropy: 1.14142
Value Function Loss: 6.88786

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.10188

Collected Steps per Second: 11,089.19487
Overall Steps per Second: 9,395.32401

Timestep Collection Time: 4.50980
Timestep Consumption Time: 0.81307
PPO Batch Consumption Time: 0.04858
Total Iteration Time: 5.32286

Cumulative Model Updates: 39,451
Cumulative Timesteps: 658,110,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,810.41450
Policy Entropy: 1.14078
Value Function Loss: 6.89276

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.08692

Collected Steps per Second: 10,835.89822
Overall Steps per Second: 9,210.51417

Timestep Collection Time: 4.61521
Timestep Consumption Time: 0.81445
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 5.42966

Cumulative Model Updates: 39,454
Cumulative Timesteps: 658,160,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 658160978...
Checkpoint 658160978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,624.38463
Policy Entropy: 1.13005
Value Function Loss: 6.82973

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.08521

Collected Steps per Second: 11,350.69091
Overall Steps per Second: 9,564.19601

Timestep Collection Time: 4.40555
Timestep Consumption Time: 0.82291
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 5.22846

Cumulative Model Updates: 39,457
Cumulative Timesteps: 658,210,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,409.52994
Policy Entropy: 1.11895
Value Function Loss: 6.83874

Mean KL Divergence: 0.03637
SB3 Clip Fraction: 0.15379
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.07739

Collected Steps per Second: 10,557.16710
Overall Steps per Second: 9,007.23654

Timestep Collection Time: 4.73896
Timestep Consumption Time: 0.81546
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.55442

Cumulative Model Updates: 39,460
Cumulative Timesteps: 658,261,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 658261014...
Checkpoint 658261014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,327.31001
Policy Entropy: 1.13169
Value Function Loss: 6.35235

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.07354

Collected Steps per Second: 10,792.59797
Overall Steps per Second: 9,395.39467

Timestep Collection Time: 4.63540
Timestep Consumption Time: 0.68934
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 5.32474

Cumulative Model Updates: 39,463
Cumulative Timesteps: 658,311,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,037.54365
Policy Entropy: 1.12913
Value Function Loss: 6.14905

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.06582
Value Function Update Magnitude: 0.07010

Collected Steps per Second: 10,875.34026
Overall Steps per Second: 9,166.13624

Timestep Collection Time: 4.59756
Timestep Consumption Time: 0.85730
PPO Batch Consumption Time: 0.04277
Total Iteration Time: 5.45486

Cumulative Model Updates: 39,466
Cumulative Timesteps: 658,361,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 658361042...
Checkpoint 658361042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,960.46383
Policy Entropy: 1.12310
Value Function Loss: 6.37862

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.06680
Value Function Update Magnitude: 0.07430

Collected Steps per Second: 10,914.81189
Overall Steps per Second: 9,347.38640

Timestep Collection Time: 4.58148
Timestep Consumption Time: 0.76825
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.34973

Cumulative Model Updates: 39,469
Cumulative Timesteps: 658,411,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404,156.68275
Policy Entropy: 1.12110
Value Function Loss: 6.50393

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.06779
Value Function Update Magnitude: 0.08271

Collected Steps per Second: 10,661.34351
Overall Steps per Second: 9,001.40552

Timestep Collection Time: 4.69115
Timestep Consumption Time: 0.86509
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.55624

Cumulative Model Updates: 39,472
Cumulative Timesteps: 658,461,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 658461062...
Checkpoint 658461062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,060.97096
Policy Entropy: 1.11939
Value Function Loss: 6.76436

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.08498

Collected Steps per Second: 11,965.43632
Overall Steps per Second: 10,112.57345

Timestep Collection Time: 4.17971
Timestep Consumption Time: 0.76582
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 4.94553

Cumulative Model Updates: 39,475
Cumulative Timesteps: 658,511,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,296.41940
Policy Entropy: 1.13947
Value Function Loss: 6.57061

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.08258

Collected Steps per Second: 11,725.41484
Overall Steps per Second: 10,099.27623

Timestep Collection Time: 4.26509
Timestep Consumption Time: 0.68675
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 4.95184

Cumulative Model Updates: 39,478
Cumulative Timesteps: 658,561,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 658561084...
Checkpoint 658561084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396,337.38394
Policy Entropy: 1.14232
Value Function Loss: 6.85167

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.07435

Collected Steps per Second: 12,085.63607
Overall Steps per Second: 10,058.90562

Timestep Collection Time: 4.13847
Timestep Consumption Time: 0.83384
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.97231

Cumulative Model Updates: 39,481
Cumulative Timesteps: 658,611,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365,655.36854
Policy Entropy: 1.12262
Value Function Loss: 6.76438

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.08032

Collected Steps per Second: 12,005.32047
Overall Steps per Second: 10,109.07367

Timestep Collection Time: 4.16482
Timestep Consumption Time: 0.78123
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 4.94605

Cumulative Model Updates: 39,484
Cumulative Timesteps: 658,661,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 658661100...
Checkpoint 658661100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,177.27097
Policy Entropy: 1.10904
Value Function Loss: 6.55532

Mean KL Divergence: 0.02779
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.07446

Collected Steps per Second: 12,179.61862
Overall Steps per Second: 10,109.44418

Timestep Collection Time: 4.10604
Timestep Consumption Time: 0.84082
PPO Batch Consumption Time: 0.04094
Total Iteration Time: 4.94686

Cumulative Model Updates: 39,487
Cumulative Timesteps: 658,711,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,076.53630
Policy Entropy: 1.11856
Value Function Loss: 6.32175

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.08441

Collected Steps per Second: 11,434.99124
Overall Steps per Second: 9,689.58752

Timestep Collection Time: 4.37307
Timestep Consumption Time: 0.78773
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.16080

Cumulative Model Updates: 39,490
Cumulative Timesteps: 658,761,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 658761116...
Checkpoint 658761116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,628.36942
Policy Entropy: 1.12699
Value Function Loss: 6.45576

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.08014

Collected Steps per Second: 11,193.70832
Overall Steps per Second: 9,688.30560

Timestep Collection Time: 4.46912
Timestep Consumption Time: 0.69443
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.16354

Cumulative Model Updates: 39,493
Cumulative Timesteps: 658,811,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,710.08595
Policy Entropy: 1.10723
Value Function Loss: 6.65183

Mean KL Divergence: 0.02966
SB3 Clip Fraction: 0.15175
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 11,354.26236
Overall Steps per Second: 9,644.68960

Timestep Collection Time: 4.40592
Timestep Consumption Time: 0.78097
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.18690

Cumulative Model Updates: 39,496
Cumulative Timesteps: 658,861,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 658861168...
Checkpoint 658861168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596,471.09799
Policy Entropy: 1.12878
Value Function Loss: 7.17629

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.08791

Collected Steps per Second: 10,951.90137
Overall Steps per Second: 9,397.74478

Timestep Collection Time: 4.56761
Timestep Consumption Time: 0.75537
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 5.32298

Cumulative Model Updates: 39,499
Cumulative Timesteps: 658,911,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,488.61394
Policy Entropy: 1.12660
Value Function Loss: 7.08391

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.10121

Collected Steps per Second: 10,914.01790
Overall Steps per Second: 9,482.20200

Timestep Collection Time: 4.58218
Timestep Consumption Time: 0.69191
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.27409

Cumulative Model Updates: 39,502
Cumulative Timesteps: 658,961,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 658961202...
Checkpoint 658961202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,896.61709
Policy Entropy: 1.11064
Value Function Loss: 6.97045

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.11089

Collected Steps per Second: 11,321.05878
Overall Steps per Second: 9,640.40934

Timestep Collection Time: 4.41814
Timestep Consumption Time: 0.77023
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.18837

Cumulative Model Updates: 39,505
Cumulative Timesteps: 659,011,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,637.11209
Policy Entropy: 1.09640
Value Function Loss: 6.58779

Mean KL Divergence: 0.03433
SB3 Clip Fraction: 0.15422
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.09401

Collected Steps per Second: 10,634.68463
Overall Steps per Second: 9,182.24779

Timestep Collection Time: 4.70197
Timestep Consumption Time: 0.74375
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 5.44573

Cumulative Model Updates: 39,508
Cumulative Timesteps: 659,061,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 659061224...
Checkpoint 659061224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435,549.43747
Policy Entropy: 1.10375
Value Function Loss: 6.40379

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.08152

Collected Steps per Second: 11,056.34066
Overall Steps per Second: 9,401.74121

Timestep Collection Time: 4.52482
Timestep Consumption Time: 0.79632
PPO Batch Consumption Time: 0.04441
Total Iteration Time: 5.32114

Cumulative Model Updates: 39,511
Cumulative Timesteps: 659,111,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417,315.88043
Policy Entropy: 1.11220
Value Function Loss: 6.48518

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.14501
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.07242

Collected Steps per Second: 10,856.55558
Overall Steps per Second: 9,177.77287

Timestep Collection Time: 4.60754
Timestep Consumption Time: 0.84280
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 5.45034

Cumulative Model Updates: 39,514
Cumulative Timesteps: 659,161,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 659161274...
Checkpoint 659161274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,155.47898
Policy Entropy: 1.09125
Value Function Loss: 6.75457

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.11873
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.07234

Collected Steps per Second: 10,667.82099
Overall Steps per Second: 9,217.67533

Timestep Collection Time: 4.68962
Timestep Consumption Time: 0.73778
PPO Batch Consumption Time: 0.04335
Total Iteration Time: 5.42740

Cumulative Model Updates: 39,517
Cumulative Timesteps: 659,211,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437,856.44063
Policy Entropy: 1.10235
Value Function Loss: 6.73938

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.08364

Collected Steps per Second: 10,814.96797
Overall Steps per Second: 9,280.39425

Timestep Collection Time: 4.62452
Timestep Consumption Time: 0.76469
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.38921

Cumulative Model Updates: 39,520
Cumulative Timesteps: 659,261,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 659261316...
Checkpoint 659261316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,547.36639
Policy Entropy: 1.10569
Value Function Loss: 6.69301

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 10,756.46128
Overall Steps per Second: 9,270.40321

Timestep Collection Time: 4.64948
Timestep Consumption Time: 0.74532
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.39480

Cumulative Model Updates: 39,523
Cumulative Timesteps: 659,311,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,207.39730
Policy Entropy: 1.10951
Value Function Loss: 6.54215

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.07006

Collected Steps per Second: 11,116.65074
Overall Steps per Second: 9,429.49589

Timestep Collection Time: 4.49830
Timestep Consumption Time: 0.80485
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.30315

Cumulative Model Updates: 39,526
Cumulative Timesteps: 659,361,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 659361334...
Checkpoint 659361334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357,703.57076
Policy Entropy: 1.10644
Value Function Loss: 6.46287

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.06934
Value Function Update Magnitude: 0.06450

Collected Steps per Second: 10,759.11328
Overall Steps per Second: 9,220.34246

Timestep Collection Time: 4.64927
Timestep Consumption Time: 0.77591
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.42518

Cumulative Model Updates: 39,529
Cumulative Timesteps: 659,411,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,052.14396
Policy Entropy: 1.11874
Value Function Loss: 6.44351

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.06864
Value Function Update Magnitude: 0.07686

Collected Steps per Second: 10,906.80431
Overall Steps per Second: 9,471.48145

Timestep Collection Time: 4.58576
Timestep Consumption Time: 0.69493
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.28069

Cumulative Model Updates: 39,532
Cumulative Timesteps: 659,461,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 659461372...
Checkpoint 659461372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,844.22563
Policy Entropy: 1.10859
Value Function Loss: 6.73639

Mean KL Divergence: 0.02878
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.07052
Value Function Update Magnitude: 0.07643

Collected Steps per Second: 11,047.17264
Overall Steps per Second: 9,427.65453

Timestep Collection Time: 4.52840
Timestep Consumption Time: 0.77791
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.30630

Cumulative Model Updates: 39,535
Cumulative Timesteps: 659,511,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,175.59999
Policy Entropy: 1.12413
Value Function Loss: 6.97698

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.08853

Collected Steps per Second: 11,200.33287
Overall Steps per Second: 9,676.54661

Timestep Collection Time: 4.46487
Timestep Consumption Time: 0.70309
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.16796

Cumulative Model Updates: 39,538
Cumulative Timesteps: 659,561,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 659561406...
Checkpoint 659561406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407,081.01363
Policy Entropy: 1.11277
Value Function Loss: 7.19075

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.07424
Value Function Update Magnitude: 0.09450

Collected Steps per Second: 10,954.96111
Overall Steps per Second: 9,358.53852

Timestep Collection Time: 4.56505
Timestep Consumption Time: 0.77873
PPO Batch Consumption Time: 0.04068
Total Iteration Time: 5.34378

Cumulative Model Updates: 39,541
Cumulative Timesteps: 659,611,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,671.32687
Policy Entropy: 1.11565
Value Function Loss: 6.91140

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.08292
Value Function Update Magnitude: 0.08523

Collected Steps per Second: 11,469.31468
Overall Steps per Second: 9,836.56101

Timestep Collection Time: 4.36173
Timestep Consumption Time: 0.72400
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.08572

Cumulative Model Updates: 39,544
Cumulative Timesteps: 659,661,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 659661442...
Checkpoint 659661442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,960.99200
Policy Entropy: 1.10675
Value Function Loss: 6.80966

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.07248
Value Function Update Magnitude: 0.07668

Collected Steps per Second: 11,300.98071
Overall Steps per Second: 9,673.70260

Timestep Collection Time: 4.42493
Timestep Consumption Time: 0.74435
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.16927

Cumulative Model Updates: 39,547
Cumulative Timesteps: 659,711,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,112.67829
Policy Entropy: 1.11915
Value Function Loss: 6.95418

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.07280

Collected Steps per Second: 11,562.48585
Overall Steps per Second: 9,878.97017

Timestep Collection Time: 4.32571
Timestep Consumption Time: 0.73716
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.06288

Cumulative Model Updates: 39,550
Cumulative Timesteps: 659,761,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 659761464...
Checkpoint 659761464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410,153.41826
Policy Entropy: 1.12022
Value Function Loss: 6.85474

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.07352

Collected Steps per Second: 11,419.42211
Overall Steps per Second: 9,719.16064

Timestep Collection Time: 4.37991
Timestep Consumption Time: 0.76622
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 5.14612

Cumulative Model Updates: 39,553
Cumulative Timesteps: 659,811,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,680.46928
Policy Entropy: 1.11402
Value Function Loss: 6.66701

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.08773

Collected Steps per Second: 11,538.17513
Overall Steps per Second: 9,758.72242

Timestep Collection Time: 4.33344
Timestep Consumption Time: 0.79018
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 5.12362

Cumulative Model Updates: 39,556
Cumulative Timesteps: 659,861,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 659861480...
Checkpoint 659861480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,935.14778
Policy Entropy: 1.10000
Value Function Loss: 6.56575

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.08780

Collected Steps per Second: 10,720.64334
Overall Steps per Second: 9,348.56918

Timestep Collection Time: 4.66521
Timestep Consumption Time: 0.68470
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.34991

Cumulative Model Updates: 39,559
Cumulative Timesteps: 659,911,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,065.96763
Policy Entropy: 1.08793
Value Function Loss: 6.55259

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.08159

Collected Steps per Second: 11,315.06416
Overall Steps per Second: 9,599.02512

Timestep Collection Time: 4.41924
Timestep Consumption Time: 0.79004
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.20928

Cumulative Model Updates: 39,562
Cumulative Timesteps: 659,961,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 659961498...
Checkpoint 659961498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,425.07080
Policy Entropy: 1.09590
Value Function Loss: 6.76682

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.09471

Collected Steps per Second: 11,543.92639
Overall Steps per Second: 9,667.56245

Timestep Collection Time: 4.33146
Timestep Consumption Time: 0.84069
PPO Batch Consumption Time: 0.03746
Total Iteration Time: 5.17214

Cumulative Model Updates: 39,565
Cumulative Timesteps: 660,011,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,974.07378
Policy Entropy: 1.09852
Value Function Loss: 6.71919

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.09258

Collected Steps per Second: 11,491.84646
Overall Steps per Second: 9,672.03502

Timestep Collection Time: 4.35283
Timestep Consumption Time: 0.81899
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.17182

Cumulative Model Updates: 39,568
Cumulative Timesteps: 660,061,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 660061522...
Checkpoint 660061522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,133.99131
Policy Entropy: 1.08910
Value Function Loss: 6.80756

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.09622

Collected Steps per Second: 11,252.90384
Overall Steps per Second: 9,514.15457

Timestep Collection Time: 4.44472
Timestep Consumption Time: 0.81229
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.25701

Cumulative Model Updates: 39,571
Cumulative Timesteps: 660,111,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,328.37424
Policy Entropy: 1.08236
Value Function Loss: 6.86703

Mean KL Divergence: 0.03341
SB3 Clip Fraction: 0.17555
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.09780

Collected Steps per Second: 10,899.35402
Overall Steps per Second: 9,402.79171

Timestep Collection Time: 4.58963
Timestep Consumption Time: 0.73049
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.32012

Cumulative Model Updates: 39,574
Cumulative Timesteps: 660,161,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 660161562...
Checkpoint 660161562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,465.80564
Policy Entropy: 1.09708
Value Function Loss: 6.70231

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.09677

Collected Steps per Second: 10,965.96230
Overall Steps per Second: 9,391.26630

Timestep Collection Time: 4.56029
Timestep Consumption Time: 0.76465
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.32495

Cumulative Model Updates: 39,577
Cumulative Timesteps: 660,211,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,919.37362
Policy Entropy: 1.09918
Value Function Loss: 6.34745

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.10179

Collected Steps per Second: 11,003.54809
Overall Steps per Second: 9,411.82651

Timestep Collection Time: 4.54562
Timestep Consumption Time: 0.76875
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.31438

Cumulative Model Updates: 39,580
Cumulative Timesteps: 660,261,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 660261588...
Checkpoint 660261588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,968.97481
Policy Entropy: 1.08042
Value Function Loss: 6.26630

Mean KL Divergence: 0.03285
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.05857
Value Function Update Magnitude: 0.10135

Collected Steps per Second: 10,806.63583
Overall Steps per Second: 9,469.90640

Timestep Collection Time: 4.62808
Timestep Consumption Time: 0.65328
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.28136

Cumulative Model Updates: 39,583
Cumulative Timesteps: 660,311,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,489.05092
Policy Entropy: 1.08959
Value Function Loss: 6.01385

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.09978

Collected Steps per Second: 10,987.45326
Overall Steps per Second: 9,354.66887

Timestep Collection Time: 4.55228
Timestep Consumption Time: 0.79457
PPO Batch Consumption Time: 0.04121
Total Iteration Time: 5.34685

Cumulative Model Updates: 39,586
Cumulative Timesteps: 660,361,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 660361620...
Checkpoint 660361620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,945.84480
Policy Entropy: 1.09092
Value Function Loss: 6.07195

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.05900
Value Function Update Magnitude: 0.09655

Collected Steps per Second: 10,901.54286
Overall Steps per Second: 9,368.69775

Timestep Collection Time: 4.58908
Timestep Consumption Time: 0.75083
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.33991

Cumulative Model Updates: 39,589
Cumulative Timesteps: 660,411,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,907.97352
Policy Entropy: 1.08393
Value Function Loss: 6.02135

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.06945
Value Function Update Magnitude: 0.08885

Collected Steps per Second: 10,809.20814
Overall Steps per Second: 9,229.50616

Timestep Collection Time: 4.62809
Timestep Consumption Time: 0.79213
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.42022

Cumulative Model Updates: 39,592
Cumulative Timesteps: 660,461,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 660461674...
Checkpoint 660461674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,371.22584
Policy Entropy: 1.08853
Value Function Loss: 6.37430

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.11507
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.07567

Collected Steps per Second: 10,776.76428
Overall Steps per Second: 9,211.56942

Timestep Collection Time: 4.64258
Timestep Consumption Time: 0.78885
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.43143

Cumulative Model Updates: 39,595
Cumulative Timesteps: 660,511,706

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,213.58452
Policy Entropy: 1.08220
Value Function Loss: 6.38956

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.07062

Collected Steps per Second: 10,865.07289
Overall Steps per Second: 9,461.08187

Timestep Collection Time: 4.60374
Timestep Consumption Time: 0.68318
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 5.28692

Cumulative Model Updates: 39,598
Cumulative Timesteps: 660,561,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 660561726...
Checkpoint 660561726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,395.57622
Policy Entropy: 1.09841
Value Function Loss: 6.56526

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.07140

Collected Steps per Second: 11,039.60130
Overall Steps per Second: 9,376.38124

Timestep Collection Time: 4.53114
Timestep Consumption Time: 0.80375
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.33489

Cumulative Model Updates: 39,601
Cumulative Timesteps: 660,611,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,317.29113
Policy Entropy: 1.09766
Value Function Loss: 6.40075

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.11797
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.07313

Collected Steps per Second: 10,889.13772
Overall Steps per Second: 9,318.33440

Timestep Collection Time: 4.59357
Timestep Consumption Time: 0.77434
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.36791

Cumulative Model Updates: 39,604
Cumulative Timesteps: 660,661,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 660661768...
Checkpoint 660661768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,364.50710
Policy Entropy: 1.10795
Value Function Loss: 6.52932

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.06230
Value Function Update Magnitude: 0.06712

Collected Steps per Second: 10,899.48201
Overall Steps per Second: 9,224.68960

Timestep Collection Time: 4.58976
Timestep Consumption Time: 0.83330
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 5.42306

Cumulative Model Updates: 39,607
Cumulative Timesteps: 660,711,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,803.83455
Policy Entropy: 1.09773
Value Function Loss: 6.35849

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.06573

Collected Steps per Second: 11,388.85386
Overall Steps per Second: 9,674.72719

Timestep Collection Time: 4.39184
Timestep Consumption Time: 0.77813
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.16996

Cumulative Model Updates: 39,610
Cumulative Timesteps: 660,761,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 660761812...
Checkpoint 660761812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,008.74712
Policy Entropy: 1.10715
Value Function Loss: 6.57976

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.06490

Collected Steps per Second: 11,903.30018
Overall Steps per Second: 10,082.52247

Timestep Collection Time: 4.20085
Timestep Consumption Time: 0.75862
PPO Batch Consumption Time: 0.03310
Total Iteration Time: 4.95947

Cumulative Model Updates: 39,613
Cumulative Timesteps: 660,811,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,508.51613
Policy Entropy: 1.12208
Value Function Loss: 6.62246

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.08955

Collected Steps per Second: 12,254.44900
Overall Steps per Second: 10,292.74941

Timestep Collection Time: 4.08260
Timestep Consumption Time: 0.77810
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 4.86070

Cumulative Model Updates: 39,616
Cumulative Timesteps: 660,861,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 660861846...
Checkpoint 660861846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,684.19464
Policy Entropy: 1.10195
Value Function Loss: 6.51352

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.11059

Collected Steps per Second: 11,909.19166
Overall Steps per Second: 10,079.97820

Timestep Collection Time: 4.19861
Timestep Consumption Time: 0.76192
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 4.96053

Cumulative Model Updates: 39,619
Cumulative Timesteps: 660,911,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,988.79249
Policy Entropy: 1.10718
Value Function Loss: 6.38229

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.11465

Collected Steps per Second: 11,685.27567
Overall Steps per Second: 10,002.08370

Timestep Collection Time: 4.28163
Timestep Consumption Time: 0.72053
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 5.00216

Cumulative Model Updates: 39,622
Cumulative Timesteps: 660,961,880

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 660961880...
Checkpoint 660961880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,659.83960
Policy Entropy: 1.11556
Value Function Loss: 6.23251

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.12076

Collected Steps per Second: 12,119.85798
Overall Steps per Second: 9,970.49291

Timestep Collection Time: 4.12563
Timestep Consumption Time: 0.88937
PPO Batch Consumption Time: 0.03844
Total Iteration Time: 5.01500

Cumulative Model Updates: 39,625
Cumulative Timesteps: 661,011,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,778.00906
Policy Entropy: 1.11394
Value Function Loss: 6.59002

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.11371

Collected Steps per Second: 11,629.34919
Overall Steps per Second: 9,775.52524

Timestep Collection Time: 4.30136
Timestep Consumption Time: 0.81571
PPO Batch Consumption Time: 0.03769
Total Iteration Time: 5.11707

Cumulative Model Updates: 39,628
Cumulative Timesteps: 661,061,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 661061904...
Checkpoint 661061904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,256.70929
Policy Entropy: 1.12326
Value Function Loss: 6.78340

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.10108

Collected Steps per Second: 10,891.35326
Overall Steps per Second: 9,390.25346

Timestep Collection Time: 4.59227
Timestep Consumption Time: 0.73411
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.32637

Cumulative Model Updates: 39,631
Cumulative Timesteps: 661,111,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,143.22883
Policy Entropy: 1.12178
Value Function Loss: 7.08900

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.07246
Value Function Update Magnitude: 0.08408

Collected Steps per Second: 11,348.32361
Overall Steps per Second: 9,623.76229

Timestep Collection Time: 4.40594
Timestep Consumption Time: 0.78954
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.19547

Cumulative Model Updates: 39,634
Cumulative Timesteps: 661,161,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 661161920...
Checkpoint 661161920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,720.16765
Policy Entropy: 1.10993
Value Function Loss: 6.92306

Mean KL Divergence: 0.03611
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.07867

Collected Steps per Second: 11,050.55190
Overall Steps per Second: 9,395.37473

Timestep Collection Time: 4.52719
Timestep Consumption Time: 0.79755
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 5.32475

Cumulative Model Updates: 39,637
Cumulative Timesteps: 661,211,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,727.28239
Policy Entropy: 1.12056
Value Function Loss: 6.94486

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 11,577.47266
Overall Steps per Second: 9,695.75954

Timestep Collection Time: 4.32063
Timestep Consumption Time: 0.83853
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.15916

Cumulative Model Updates: 39,640
Cumulative Timesteps: 661,261,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 661261970...
Checkpoint 661261970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,214.09445
Policy Entropy: 1.12163
Value Function Loss: 6.72595

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.06234
Value Function Update Magnitude: 0.08238

Collected Steps per Second: 10,487.41360
Overall Steps per Second: 9,052.31982

Timestep Collection Time: 4.77048
Timestep Consumption Time: 0.75628
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 5.52676

Cumulative Model Updates: 39,643
Cumulative Timesteps: 661,312,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,975.28532
Policy Entropy: 1.11467
Value Function Loss: 6.96678

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.08673

Collected Steps per Second: 10,708.19578
Overall Steps per Second: 9,316.55539

Timestep Collection Time: 4.67194
Timestep Consumption Time: 0.69786
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.36980

Cumulative Model Updates: 39,646
Cumulative Timesteps: 661,362,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 661362028...
Checkpoint 661362028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,122.81768
Policy Entropy: 1.10431
Value Function Loss: 7.03675

Mean KL Divergence: 0.02547
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.08815

Collected Steps per Second: 10,813.41413
Overall Steps per Second: 9,262.76617

Timestep Collection Time: 4.62444
Timestep Consumption Time: 0.77416
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.39860

Cumulative Model Updates: 39,649
Cumulative Timesteps: 661,412,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392,245.33335
Policy Entropy: 1.10791
Value Function Loss: 6.98423

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.07343

Collected Steps per Second: 10,870.02598
Overall Steps per Second: 9,356.86732

Timestep Collection Time: 4.60017
Timestep Consumption Time: 0.74392
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.34410

Cumulative Model Updates: 39,652
Cumulative Timesteps: 661,462,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 661462038...
Checkpoint 661462038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,268.15960
Policy Entropy: 1.10723
Value Function Loss: 6.71491

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.06261

Collected Steps per Second: 11,133.15259
Overall Steps per Second: 9,307.13407

Timestep Collection Time: 4.49325
Timestep Consumption Time: 0.88156
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 5.37480

Cumulative Model Updates: 39,655
Cumulative Timesteps: 661,512,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,557.45450
Policy Entropy: 1.11691
Value Function Loss: 6.79723

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.06743

Collected Steps per Second: 11,106.74477
Overall Steps per Second: 9,553.26829

Timestep Collection Time: 4.50339
Timestep Consumption Time: 0.73231
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.23570

Cumulative Model Updates: 39,658
Cumulative Timesteps: 661,562,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 661562080...
Checkpoint 661562080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,650.23615
Policy Entropy: 1.11305
Value Function Loss: 7.41201

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.06874

Collected Steps per Second: 10,408.49069
Overall Steps per Second: 9,035.91771

Timestep Collection Time: 4.80396
Timestep Consumption Time: 0.72973
PPO Batch Consumption Time: 0.03850
Total Iteration Time: 5.53369

Cumulative Model Updates: 39,661
Cumulative Timesteps: 661,612,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,536.28353
Policy Entropy: 1.09946
Value Function Loss: 7.51508

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.11766
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.06161

Collected Steps per Second: 11,081.18155
Overall Steps per Second: 9,462.88909

Timestep Collection Time: 4.51360
Timestep Consumption Time: 0.77189
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.28549

Cumulative Model Updates: 39,664
Cumulative Timesteps: 661,662,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 661662098...
Checkpoint 661662098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,032.83671
Policy Entropy: 1.12497
Value Function Loss: 7.33817

Mean KL Divergence: 0.02396
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.05453

Collected Steps per Second: 10,921.43887
Overall Steps per Second: 9,388.50712

Timestep Collection Time: 4.57998
Timestep Consumption Time: 0.74781
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 5.32779

Cumulative Model Updates: 39,667
Cumulative Timesteps: 661,712,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,656.26886
Policy Entropy: 1.11942
Value Function Loss: 7.25652

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.04948

Collected Steps per Second: 11,268.77165
Overall Steps per Second: 9,628.91160

Timestep Collection Time: 4.43740
Timestep Consumption Time: 0.75571
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.19311

Cumulative Model Updates: 39,670
Cumulative Timesteps: 661,762,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 661762122...
Checkpoint 661762122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,919.08168
Policy Entropy: 1.10998
Value Function Loss: 7.24648

Mean KL Divergence: 0.02879
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.06071

Collected Steps per Second: 10,811.30840
Overall Steps per Second: 9,268.80701

Timestep Collection Time: 4.62553
Timestep Consumption Time: 0.76977
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.39530

Cumulative Model Updates: 39,673
Cumulative Timesteps: 661,812,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417,166.18913
Policy Entropy: 1.10465
Value Function Loss: 7.50388

Mean KL Divergence: 0.03117
SB3 Clip Fraction: 0.15520
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.06869

Collected Steps per Second: 10,445.48208
Overall Steps per Second: 9,065.44040

Timestep Collection Time: 4.78733
Timestep Consumption Time: 0.72878
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 5.51611

Cumulative Model Updates: 39,676
Cumulative Timesteps: 661,862,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 661862136...
Checkpoint 661862136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,891.49512
Policy Entropy: 1.11238
Value Function Loss: 7.13110

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.07116

Collected Steps per Second: 11,075.65045
Overall Steps per Second: 9,466.57486

Timestep Collection Time: 4.51477
Timestep Consumption Time: 0.76740
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.28216

Cumulative Model Updates: 39,679
Cumulative Timesteps: 661,912,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,512.78660
Policy Entropy: 1.12813
Value Function Loss: 7.07926

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.07883

Collected Steps per Second: 11,262.44686
Overall Steps per Second: 9,658.56192

Timestep Collection Time: 4.43953
Timestep Consumption Time: 0.73722
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.17675

Cumulative Model Updates: 39,682
Cumulative Timesteps: 661,962,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 661962140...
Checkpoint 661962140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,562.32766
Policy Entropy: 1.11561
Value Function Loss: 7.16528

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.06931

Collected Steps per Second: 11,509.20681
Overall Steps per Second: 9,611.12011

Timestep Collection Time: 4.34591
Timestep Consumption Time: 0.85827
PPO Batch Consumption Time: 0.04035
Total Iteration Time: 5.20418

Cumulative Model Updates: 39,685
Cumulative Timesteps: 662,012,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,475.96073
Policy Entropy: 1.09822
Value Function Loss: 7.23549

Mean KL Divergence: 0.03595
SB3 Clip Fraction: 0.16957
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.06314

Collected Steps per Second: 11,389.53435
Overall Steps per Second: 9,685.85120

Timestep Collection Time: 4.39158
Timestep Consumption Time: 0.77245
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.16403

Cumulative Model Updates: 39,688
Cumulative Timesteps: 662,062,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 662062176...
Checkpoint 662062176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,566.35362
Policy Entropy: 1.11562
Value Function Loss: 7.29210

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.06789

Collected Steps per Second: 11,160.39751
Overall Steps per Second: 9,667.53525

Timestep Collection Time: 4.48156
Timestep Consumption Time: 0.69204
PPO Batch Consumption Time: 0.03886
Total Iteration Time: 5.17360

Cumulative Model Updates: 39,691
Cumulative Timesteps: 662,112,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,001.25678
Policy Entropy: 1.11689
Value Function Loss: 7.06400

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.07182

Collected Steps per Second: 10,808.90235
Overall Steps per Second: 9,290.68073

Timestep Collection Time: 4.62748
Timestep Consumption Time: 0.75619
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.38367

Cumulative Model Updates: 39,694
Cumulative Timesteps: 662,162,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 662162210...
Checkpoint 662162210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,667.20569
Policy Entropy: 1.11781
Value Function Loss: 6.95090

Mean KL Divergence: 0.03103
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.08032

Collected Steps per Second: 11,167.91247
Overall Steps per Second: 9,565.41958

Timestep Collection Time: 4.47890
Timestep Consumption Time: 0.75035
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.22925

Cumulative Model Updates: 39,697
Cumulative Timesteps: 662,212,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,228.97390
Policy Entropy: 1.12736
Value Function Loss: 6.83533

Mean KL Divergence: 0.02216
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.08070

Collected Steps per Second: 11,420.55184
Overall Steps per Second: 9,635.95741

Timestep Collection Time: 4.37842
Timestep Consumption Time: 0.81089
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.18931

Cumulative Model Updates: 39,700
Cumulative Timesteps: 662,262,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 662262234...
Checkpoint 662262234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322,963.57754
Policy Entropy: 1.12451
Value Function Loss: 6.63473

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.07712

Collected Steps per Second: 11,128.29006
Overall Steps per Second: 9,489.15477

Timestep Collection Time: 4.49413
Timestep Consumption Time: 0.77631
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.27044

Cumulative Model Updates: 39,703
Cumulative Timesteps: 662,312,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,612.46435
Policy Entropy: 1.12598
Value Function Loss: 6.81870

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.08622

Collected Steps per Second: 10,994.92196
Overall Steps per Second: 9,525.64599

Timestep Collection Time: 4.54955
Timestep Consumption Time: 0.70174
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.25130

Cumulative Model Updates: 39,706
Cumulative Timesteps: 662,362,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 662362268...
Checkpoint 662362268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481,962.59836
Policy Entropy: 1.14256
Value Function Loss: 6.87537

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.08283

Collected Steps per Second: 11,361.31607
Overall Steps per Second: 9,680.76853

Timestep Collection Time: 4.40090
Timestep Consumption Time: 0.76398
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.16488

Cumulative Model Updates: 39,709
Cumulative Timesteps: 662,412,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439,402.61751
Policy Entropy: 1.13595
Value Function Loss: 6.63297

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.08404

Collected Steps per Second: 10,634.23383
Overall Steps per Second: 9,133.45147

Timestep Collection Time: 4.70368
Timestep Consumption Time: 0.77289
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.47657

Cumulative Model Updates: 39,712
Cumulative Timesteps: 662,462,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 662462288...
Checkpoint 662462288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,587.36119
Policy Entropy: 1.14190
Value Function Loss: 6.24359

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.10913
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.08628

Collected Steps per Second: 10,934.75283
Overall Steps per Second: 9,342.00475

Timestep Collection Time: 4.57477
Timestep Consumption Time: 0.77997
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.35474

Cumulative Model Updates: 39,715
Cumulative Timesteps: 662,512,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,196.71018
Policy Entropy: 1.12492
Value Function Loss: 6.20306

Mean KL Divergence: 0.02743
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.07873

Collected Steps per Second: 11,133.01982
Overall Steps per Second: 9,581.28284

Timestep Collection Time: 4.49258
Timestep Consumption Time: 0.72760
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.22018

Cumulative Model Updates: 39,718
Cumulative Timesteps: 662,562,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 662562328...
Checkpoint 662562328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396,045.26032
Policy Entropy: 1.13933
Value Function Loss: 6.34649

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.08972

Collected Steps per Second: 10,935.93314
Overall Steps per Second: 9,554.05734

Timestep Collection Time: 4.57373
Timestep Consumption Time: 0.66153
PPO Batch Consumption Time: 0.03897
Total Iteration Time: 5.23526

Cumulative Model Updates: 39,721
Cumulative Timesteps: 662,612,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,384.93037
Policy Entropy: 1.14127
Value Function Loss: 6.69429

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.13205

Collected Steps per Second: 10,998.28416
Overall Steps per Second: 9,384.20230

Timestep Collection Time: 4.54780
Timestep Consumption Time: 0.78222
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.33002

Cumulative Model Updates: 39,724
Cumulative Timesteps: 662,662,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 662662364...
Checkpoint 662662364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,540.56367
Policy Entropy: 1.12749
Value Function Loss: 6.44990

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.11527

Collected Steps per Second: 10,618.64360
Overall Steps per Second: 9,202.78443

Timestep Collection Time: 4.71134
Timestep Consumption Time: 0.72484
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.43618

Cumulative Model Updates: 39,727
Cumulative Timesteps: 662,712,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,351.98175
Policy Entropy: 1.11605
Value Function Loss: 6.46530

Mean KL Divergence: 0.02795
SB3 Clip Fraction: 0.15758
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.09348

Collected Steps per Second: 10,856.52257
Overall Steps per Second: 9,183.54633

Timestep Collection Time: 4.60571
Timestep Consumption Time: 0.83903
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.44474

Cumulative Model Updates: 39,730
Cumulative Timesteps: 662,762,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 662762394...
Checkpoint 662762394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,554.45049
Policy Entropy: 1.11787
Value Function Loss: 5.98508

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.10308

Collected Steps per Second: 10,877.27501
Overall Steps per Second: 9,292.35576

Timestep Collection Time: 4.59692
Timestep Consumption Time: 0.78406
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.38098

Cumulative Model Updates: 39,733
Cumulative Timesteps: 662,812,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,867.76000
Policy Entropy: 1.12454
Value Function Loss: 6.18332

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.04216
Value Function Update Magnitude: 0.10320

Collected Steps per Second: 10,846.70220
Overall Steps per Second: 9,411.70448

Timestep Collection Time: 4.61006
Timestep Consumption Time: 0.70289
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.31296

Cumulative Model Updates: 39,736
Cumulative Timesteps: 662,862,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 662862400...
Checkpoint 662862400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,786.98645
Policy Entropy: 1.09102
Value Function Loss: 6.35739

Mean KL Divergence: 0.06290
SB3 Clip Fraction: 0.19174
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.09293

Collected Steps per Second: 10,955.30649
Overall Steps per Second: 9,356.52144

Timestep Collection Time: 4.56619
Timestep Consumption Time: 0.78024
PPO Batch Consumption Time: 0.03250
Total Iteration Time: 5.34643

Cumulative Model Updates: 39,739
Cumulative Timesteps: 662,912,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551,689.18511
Policy Entropy: 1.11538
Value Function Loss: 6.71217

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.08597

Collected Steps per Second: 10,926.00408
Overall Steps per Second: 9,386.54304

Timestep Collection Time: 4.57752
Timestep Consumption Time: 0.75075
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 5.32827

Cumulative Model Updates: 39,742
Cumulative Timesteps: 662,962,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 662962438...
Checkpoint 662962438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,967.58230
Policy Entropy: 1.09068
Value Function Loss: 6.72946

Mean KL Divergence: 0.03019
SB3 Clip Fraction: 0.15935
Policy Update Magnitude: 0.04646
Value Function Update Magnitude: 0.08180

Collected Steps per Second: 10,540.64230
Overall Steps per Second: 8,931.20072

Timestep Collection Time: 4.74468
Timestep Consumption Time: 0.85501
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 5.59970

Cumulative Model Updates: 39,745
Cumulative Timesteps: 663,012,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,519.76574
Policy Entropy: 1.10074
Value Function Loss: 6.82634

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.15773
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.10065

Collected Steps per Second: 12,066.34390
Overall Steps per Second: 10,261.36124

Timestep Collection Time: 4.14459
Timestep Consumption Time: 0.72904
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.87362

Cumulative Model Updates: 39,748
Cumulative Timesteps: 663,062,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 663062460...
Checkpoint 663062460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,597.77236
Policy Entropy: 1.10880
Value Function Loss: 6.88526

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.15048
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.10081

Collected Steps per Second: 11,531.51864
Overall Steps per Second: 9,932.67409

Timestep Collection Time: 4.33802
Timestep Consumption Time: 0.69828
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.03631

Cumulative Model Updates: 39,751
Cumulative Timesteps: 663,112,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,902.10653
Policy Entropy: 1.11610
Value Function Loss: 6.75914

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.08920

Collected Steps per Second: 11,840.00455
Overall Steps per Second: 10,013.35655

Timestep Collection Time: 4.22432
Timestep Consumption Time: 0.77061
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 4.99493

Cumulative Model Updates: 39,754
Cumulative Timesteps: 663,162,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 663162500...
Checkpoint 663162500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442,341.06928
Policy Entropy: 1.09677
Value Function Loss: 6.18558

Mean KL Divergence: 0.02431
SB3 Clip Fraction: 0.15190
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.07952

Collected Steps per Second: 11,730.53538
Overall Steps per Second: 9,868.61243

Timestep Collection Time: 4.26426
Timestep Consumption Time: 0.80454
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.06880

Cumulative Model Updates: 39,757
Cumulative Timesteps: 663,212,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,807.73478
Policy Entropy: 1.10701
Value Function Loss: 6.14674

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.07325

Collected Steps per Second: 11,949.57871
Overall Steps per Second: 9,999.83927

Timestep Collection Time: 4.18609
Timestep Consumption Time: 0.81619
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.00228

Cumulative Model Updates: 39,760
Cumulative Timesteps: 663,262,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 663262544...
Checkpoint 663262544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404,250.07543
Policy Entropy: 1.10648
Value Function Loss: 6.17929

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.07358

Collected Steps per Second: 11,293.32154
Overall Steps per Second: 9,631.30677

Timestep Collection Time: 4.42793
Timestep Consumption Time: 0.76410
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.19203

Cumulative Model Updates: 39,763
Cumulative Timesteps: 663,312,550

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403,159.74395
Policy Entropy: 1.11612
Value Function Loss: 6.36484

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.09265

Collected Steps per Second: 11,021.68023
Overall Steps per Second: 9,524.76380

Timestep Collection Time: 4.53833
Timestep Consumption Time: 0.71325
PPO Batch Consumption Time: 0.03922
Total Iteration Time: 5.25157

Cumulative Model Updates: 39,766
Cumulative Timesteps: 663,362,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 663362570...
Checkpoint 663362570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,758.87274
Policy Entropy: 1.11084
Value Function Loss: 6.12254

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.06470
Value Function Update Magnitude: 0.11013

Collected Steps per Second: 11,212.22127
Overall Steps per Second: 9,465.44158

Timestep Collection Time: 4.46067
Timestep Consumption Time: 0.82318
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 5.28385

Cumulative Model Updates: 39,769
Cumulative Timesteps: 663,412,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,522.92437
Policy Entropy: 1.10303
Value Function Loss: 6.27939

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 10,983.30084
Overall Steps per Second: 9,448.90793

Timestep Collection Time: 4.55291
Timestep Consumption Time: 0.73934
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 5.29225

Cumulative Model Updates: 39,772
Cumulative Timesteps: 663,462,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 663462590...
Checkpoint 663462590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,205.06775
Policy Entropy: 1.09541
Value Function Loss: 6.53870

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.12088

Collected Steps per Second: 11,055.90891
Overall Steps per Second: 9,571.93111

Timestep Collection Time: 4.52518
Timestep Consumption Time: 0.70156
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.22674

Cumulative Model Updates: 39,775
Cumulative Timesteps: 663,512,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,185.73796
Policy Entropy: 1.10543
Value Function Loss: 6.69290

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.10604

Collected Steps per Second: 11,058.91952
Overall Steps per Second: 9,280.53680

Timestep Collection Time: 4.52178
Timestep Consumption Time: 0.86649
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.38827

Cumulative Model Updates: 39,778
Cumulative Timesteps: 663,562,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 663562626...
Checkpoint 663562626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379,032.69945
Policy Entropy: 1.10584
Value Function Loss: 6.51211

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.10407

Collected Steps per Second: 10,121.06849
Overall Steps per Second: 8,737.00533

Timestep Collection Time: 4.94098
Timestep Consumption Time: 0.78272
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 5.72370

Cumulative Model Updates: 39,781
Cumulative Timesteps: 663,612,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,870.97147
Policy Entropy: 1.09382
Value Function Loss: 6.18591

Mean KL Divergence: 0.02597
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.09008

Collected Steps per Second: 11,178.95763
Overall Steps per Second: 9,495.37943

Timestep Collection Time: 4.47448
Timestep Consumption Time: 0.79335
PPO Batch Consumption Time: 0.04179
Total Iteration Time: 5.26783

Cumulative Model Updates: 39,784
Cumulative Timesteps: 663,662,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 663662654...
Checkpoint 663662654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,006.71192
Policy Entropy: 1.08641
Value Function Loss: 6.14279

Mean KL Divergence: 0.02842
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.07756

Collected Steps per Second: 10,857.86512
Overall Steps per Second: 9,366.14826

Timestep Collection Time: 4.60680
Timestep Consumption Time: 0.73371
PPO Batch Consumption Time: 0.03321
Total Iteration Time: 5.34051

Cumulative Model Updates: 39,787
Cumulative Timesteps: 663,712,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,051.19008
Policy Entropy: 1.10160
Value Function Loss: 6.20110

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.07460

Collected Steps per Second: 10,815.37727
Overall Steps per Second: 9,464.97589

Timestep Collection Time: 4.62527
Timestep Consumption Time: 0.65990
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.28517

Cumulative Model Updates: 39,790
Cumulative Timesteps: 663,762,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 663762698...
Checkpoint 663762698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,460.10702
Policy Entropy: 1.10478
Value Function Loss: 6.64057

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.07300

Collected Steps per Second: 10,859.96410
Overall Steps per Second: 9,314.90156

Timestep Collection Time: 4.60499
Timestep Consumption Time: 0.76383
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.36882

Cumulative Model Updates: 39,793
Cumulative Timesteps: 663,812,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,471.83181
Policy Entropy: 1.08071
Value Function Loss: 6.55106

Mean KL Divergence: 0.02794
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.07180

Collected Steps per Second: 10,592.24393
Overall Steps per Second: 9,211.01077

Timestep Collection Time: 4.72157
Timestep Consumption Time: 0.70802
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.42959

Cumulative Model Updates: 39,796
Cumulative Timesteps: 663,862,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 663862720...
Checkpoint 663862720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415,234.78047
Policy Entropy: 1.08569
Value Function Loss: 6.42373

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.07469

Collected Steps per Second: 10,838.29131
Overall Steps per Second: 9,262.23894

Timestep Collection Time: 4.61383
Timestep Consumption Time: 0.78508
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.39891

Cumulative Model Updates: 39,799
Cumulative Timesteps: 663,912,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,575.48130
Policy Entropy: 1.09333
Value Function Loss: 6.19265

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.08279

Collected Steps per Second: 10,769.77448
Overall Steps per Second: 9,241.04543

Timestep Collection Time: 4.64448
Timestep Consumption Time: 0.76833
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.41281

Cumulative Model Updates: 39,802
Cumulative Timesteps: 663,962,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 663962746...
Checkpoint 663962746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,387.62244
Policy Entropy: 1.10380
Value Function Loss: 6.15537

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.08555

Collected Steps per Second: 10,835.05926
Overall Steps per Second: 9,413.85405

Timestep Collection Time: 4.61631
Timestep Consumption Time: 0.69692
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.31323

Cumulative Model Updates: 39,805
Cumulative Timesteps: 664,012,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,341.34745
Policy Entropy: 1.08511
Value Function Loss: 6.02216

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.10139

Collected Steps per Second: 10,934.45972
Overall Steps per Second: 9,364.67945

Timestep Collection Time: 4.57416
Timestep Consumption Time: 0.76676
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.34092

Cumulative Model Updates: 39,808
Cumulative Timesteps: 664,062,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 664062780...
Checkpoint 664062780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,124.95607
Policy Entropy: 1.07655
Value Function Loss: 5.92007

Mean KL Divergence: 0.03240
SB3 Clip Fraction: 0.16775
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.09655

Collected Steps per Second: 10,954.16923
Overall Steps per Second: 9,528.13561

Timestep Collection Time: 4.56721
Timestep Consumption Time: 0.68355
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.25076

Cumulative Model Updates: 39,811
Cumulative Timesteps: 664,112,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,497.33888
Policy Entropy: 1.08058
Value Function Loss: 6.00075

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.05856
Value Function Update Magnitude: 0.08052

Collected Steps per Second: 10,485.75910
Overall Steps per Second: 9,023.17541

Timestep Collection Time: 4.76952
Timestep Consumption Time: 0.77310
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.54262

Cumulative Model Updates: 39,814
Cumulative Timesteps: 664,162,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 664162822...
Checkpoint 664162822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,191.64636
Policy Entropy: 1.09582
Value Function Loss: 6.21690

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.07417

Collected Steps per Second: 11,327.14666
Overall Steps per Second: 9,683.90882

Timestep Collection Time: 4.41647
Timestep Consumption Time: 0.74942
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.16589

Cumulative Model Updates: 39,817
Cumulative Timesteps: 664,212,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469,331.55830
Policy Entropy: 1.06140
Value Function Loss: 6.39323

Mean KL Divergence: 0.04155
SB3 Clip Fraction: 0.18594
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.06725

Collected Steps per Second: 11,417.06684
Overall Steps per Second: 9,914.67335

Timestep Collection Time: 4.38116
Timestep Consumption Time: 0.66389
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.04505

Cumulative Model Updates: 39,820
Cumulative Timesteps: 664,262,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 664262868...
Checkpoint 664262868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,368.51203
Policy Entropy: 1.08617
Value Function Loss: 6.45867

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 11,618.55792
Overall Steps per Second: 9,864.49916

Timestep Collection Time: 4.30363
Timestep Consumption Time: 0.76525
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.06888

Cumulative Model Updates: 39,823
Cumulative Timesteps: 664,312,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,159.56488
Policy Entropy: 1.08101
Value Function Loss: 6.68572

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 11,538.47254
Overall Steps per Second: 10,008.94378

Timestep Collection Time: 4.33489
Timestep Consumption Time: 0.66244
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.99733

Cumulative Model Updates: 39,826
Cumulative Timesteps: 664,362,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 664362888...
Checkpoint 664362888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,386.97137
Policy Entropy: 1.07800
Value Function Loss: 6.61667

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.07474

Collected Steps per Second: 11,139.81770
Overall Steps per Second: 9,460.00449

Timestep Collection Time: 4.48894
Timestep Consumption Time: 0.79710
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.28604

Cumulative Model Updates: 39,829
Cumulative Timesteps: 664,412,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,795.35963
Policy Entropy: 1.07732
Value Function Loss: 6.51539

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 11,151.78688
Overall Steps per Second: 9,644.50639

Timestep Collection Time: 4.48359
Timestep Consumption Time: 0.70071
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 5.18430

Cumulative Model Updates: 39,832
Cumulative Timesteps: 664,462,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 664462894...
Checkpoint 664462894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,541.24512
Policy Entropy: 1.08595
Value Function Loss: 6.16162

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.07942

Collected Steps per Second: 10,971.95554
Overall Steps per Second: 9,367.44538

Timestep Collection Time: 4.55908
Timestep Consumption Time: 0.78091
PPO Batch Consumption Time: 0.03746
Total Iteration Time: 5.33998

Cumulative Model Updates: 39,835
Cumulative Timesteps: 664,512,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,625.78498
Policy Entropy: 1.09269
Value Function Loss: 6.25016

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.07167

Collected Steps per Second: 11,535.40695
Overall Steps per Second: 9,847.23475

Timestep Collection Time: 4.33535
Timestep Consumption Time: 0.74324
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.07858

Cumulative Model Updates: 39,838
Cumulative Timesteps: 664,562,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 664562926...
Checkpoint 664562926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,715.98814
Policy Entropy: 1.08547
Value Function Loss: 6.32570

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.06623
Value Function Update Magnitude: 0.08351

Collected Steps per Second: 11,512.78369
Overall Steps per Second: 9,799.38147

Timestep Collection Time: 4.34474
Timestep Consumption Time: 0.75967
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.10440

Cumulative Model Updates: 39,841
Cumulative Timesteps: 664,612,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,716.84969
Policy Entropy: 1.09153
Value Function Loss: 6.09130

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.06545
Value Function Update Magnitude: 0.08651

Collected Steps per Second: 10,983.48229
Overall Steps per Second: 9,442.20191

Timestep Collection Time: 4.55466
Timestep Consumption Time: 0.74347
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.29813

Cumulative Model Updates: 39,844
Cumulative Timesteps: 664,662,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 664662972...
Checkpoint 664662972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,667.62817
Policy Entropy: 1.09107
Value Function Loss: 6.03443

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.07613

Collected Steps per Second: 10,651.96209
Overall Steps per Second: 9,253.80214

Timestep Collection Time: 4.69622
Timestep Consumption Time: 0.70955
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 5.40578

Cumulative Model Updates: 39,847
Cumulative Timesteps: 664,712,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,019.15090
Policy Entropy: 1.09664
Value Function Loss: 5.79968

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.07267
Value Function Update Magnitude: 0.07317

Collected Steps per Second: 10,885.20337
Overall Steps per Second: 9,337.41205

Timestep Collection Time: 4.59523
Timestep Consumption Time: 0.76172
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 5.35694

Cumulative Model Updates: 39,850
Cumulative Timesteps: 664,763,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 664763016...
Checkpoint 664763016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,076.07740
Policy Entropy: 1.11227
Value Function Loss: 5.99588

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.07184

Collected Steps per Second: 11,017.30949
Overall Steps per Second: 9,469.47153

Timestep Collection Time: 4.53831
Timestep Consumption Time: 0.74181
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.28013

Cumulative Model Updates: 39,853
Cumulative Timesteps: 664,813,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,549.17478
Policy Entropy: 1.11529
Value Function Loss: 6.09251

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.07365

Collected Steps per Second: 10,796.61961
Overall Steps per Second: 9,308.60577

Timestep Collection Time: 4.63386
Timestep Consumption Time: 0.74074
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.37460

Cumulative Model Updates: 39,856
Cumulative Timesteps: 664,863,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 664863046...
Checkpoint 664863046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,161.11916
Policy Entropy: 1.09507
Value Function Loss: 6.26329

Mean KL Divergence: 0.02867
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.06398
Value Function Update Magnitude: 0.08858

Collected Steps per Second: 10,904.58607
Overall Steps per Second: 9,308.43819

Timestep Collection Time: 4.58779
Timestep Consumption Time: 0.78668
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.37448

Cumulative Model Updates: 39,859
Cumulative Timesteps: 664,913,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,706.56264
Policy Entropy: 1.09118
Value Function Loss: 6.71290

Mean KL Divergence: 0.03343
SB3 Clip Fraction: 0.15710
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.08134

Collected Steps per Second: 11,051.70315
Overall Steps per Second: 9,451.40862

Timestep Collection Time: 4.52564
Timestep Consumption Time: 0.76627
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 5.29191

Cumulative Model Updates: 39,862
Cumulative Timesteps: 664,963,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 664963090...
Checkpoint 664963090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,964.33128
Policy Entropy: 1.09838
Value Function Loss: 6.37694

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.07384

Collected Steps per Second: 10,767.86027
Overall Steps per Second: 9,211.08050

Timestep Collection Time: 4.64456
Timestep Consumption Time: 0.78499
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.42955

Cumulative Model Updates: 39,865
Cumulative Timesteps: 665,013,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,193.37997
Policy Entropy: 1.10819
Value Function Loss: 6.22416

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.06795
Value Function Update Magnitude: 0.08961

Collected Steps per Second: 10,725.23971
Overall Steps per Second: 9,205.58747

Timestep Collection Time: 4.66321
Timestep Consumption Time: 0.76980
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.43300

Cumulative Model Updates: 39,868
Cumulative Timesteps: 665,063,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 665063116...
Checkpoint 665063116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,213.50675
Policy Entropy: 1.10086
Value Function Loss: 5.91281

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.07278
Value Function Update Magnitude: 0.08354

Collected Steps per Second: 10,898.02564
Overall Steps per Second: 9,448.07829

Timestep Collection Time: 4.58982
Timestep Consumption Time: 0.70438
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.29420

Cumulative Model Updates: 39,871
Cumulative Timesteps: 665,113,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,147.52193
Policy Entropy: 1.09521
Value Function Loss: 6.00988

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.07312
Value Function Update Magnitude: 0.07489

Collected Steps per Second: 10,793.49845
Overall Steps per Second: 9,174.04941

Timestep Collection Time: 4.63390
Timestep Consumption Time: 0.81800
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 5.45190

Cumulative Model Updates: 39,874
Cumulative Timesteps: 665,163,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 665163152...
Checkpoint 665163152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,769.21634
Policy Entropy: 1.10166
Value Function Loss: 6.26451

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.06726
Value Function Update Magnitude: 0.08747

Collected Steps per Second: 10,847.86395
Overall Steps per Second: 9,313.59657

Timestep Collection Time: 4.61123
Timestep Consumption Time: 0.75963
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.37086

Cumulative Model Updates: 39,877
Cumulative Timesteps: 665,213,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,585.50947
Policy Entropy: 1.10482
Value Function Loss: 6.37603

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.07127
Value Function Update Magnitude: 0.09262

Collected Steps per Second: 10,774.32882
Overall Steps per Second: 9,183.18507

Timestep Collection Time: 4.64066
Timestep Consumption Time: 0.80407
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.44473

Cumulative Model Updates: 39,880
Cumulative Timesteps: 665,263,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 665263174...
Checkpoint 665263174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,498.25783
Policy Entropy: 1.12642
Value Function Loss: 6.65639

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.07195
Value Function Update Magnitude: 0.08302

Collected Steps per Second: 11,727.43082
Overall Steps per Second: 9,996.00551

Timestep Collection Time: 4.26555
Timestep Consumption Time: 0.73884
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.00440

Cumulative Model Updates: 39,883
Cumulative Timesteps: 665,313,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342,586.73323
Policy Entropy: 1.12945
Value Function Loss: 6.86586

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.07455
Value Function Update Magnitude: 0.07864

Collected Steps per Second: 11,863.63964
Overall Steps per Second: 10,200.92211

Timestep Collection Time: 4.21574
Timestep Consumption Time: 0.68715
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 4.90289

Cumulative Model Updates: 39,886
Cumulative Timesteps: 665,363,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 665363212...
Checkpoint 665363212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,983.21205
Policy Entropy: 1.13124
Value Function Loss: 6.78075

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.06634
Value Function Update Magnitude: 0.07993

Collected Steps per Second: 11,791.45926
Overall Steps per Second: 9,996.85133

Timestep Collection Time: 4.24188
Timestep Consumption Time: 0.76149
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 5.00338

Cumulative Model Updates: 39,889
Cumulative Timesteps: 665,413,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,468.33404
Policy Entropy: 1.12980
Value Function Loss: 6.77447

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.08183

Collected Steps per Second: 11,795.60826
Overall Steps per Second: 10,029.06878

Timestep Collection Time: 4.24022
Timestep Consumption Time: 0.74688
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 4.98710

Cumulative Model Updates: 39,892
Cumulative Timesteps: 665,463,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 665463246...
Checkpoint 665463246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,834.54170
Policy Entropy: 1.12783
Value Function Loss: 6.91549

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.09462

Collected Steps per Second: 12,019.66674
Overall Steps per Second: 9,973.34498

Timestep Collection Time: 4.16018
Timestep Consumption Time: 0.85358
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.01376

Cumulative Model Updates: 39,895
Cumulative Timesteps: 665,513,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453,477.54737
Policy Entropy: 1.13803
Value Function Loss: 7.07368

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.06007
Value Function Update Magnitude: 0.08573

Collected Steps per Second: 10,807.62546
Overall Steps per Second: 9,215.42130

Timestep Collection Time: 4.62895
Timestep Consumption Time: 0.79977
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.42873

Cumulative Model Updates: 39,898
Cumulative Timesteps: 665,563,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 665563278...
Checkpoint 665563278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,671.35576
Policy Entropy: 1.13339
Value Function Loss: 7.01145

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.06792
Value Function Update Magnitude: 0.09381

Collected Steps per Second: 11,005.71229
Overall Steps per Second: 9,581.97798

Timestep Collection Time: 4.54600
Timestep Consumption Time: 0.67547
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.22147

Cumulative Model Updates: 39,901
Cumulative Timesteps: 665,613,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,103.99744
Policy Entropy: 1.13209
Value Function Loss: 6.60859

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.06884
Value Function Update Magnitude: 0.10357

Collected Steps per Second: 11,089.79654
Overall Steps per Second: 9,381.88562

Timestep Collection Time: 4.51063
Timestep Consumption Time: 0.82113
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.33176

Cumulative Model Updates: 39,904
Cumulative Timesteps: 665,663,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 665663332...
Checkpoint 665663332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440,364.34795
Policy Entropy: 1.12483
Value Function Loss: 6.48070

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.07349
Value Function Update Magnitude: 0.08749

Collected Steps per Second: 11,118.55138
Overall Steps per Second: 9,475.82440

Timestep Collection Time: 4.49969
Timestep Consumption Time: 0.78006
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 5.27975

Cumulative Model Updates: 39,907
Cumulative Timesteps: 665,713,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,504.56728
Policy Entropy: 1.12699
Value Function Loss: 6.46511

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.08978

Collected Steps per Second: 11,167.75460
Overall Steps per Second: 9,478.89769

Timestep Collection Time: 4.47915
Timestep Consumption Time: 0.79805
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.27720

Cumulative Model Updates: 39,910
Cumulative Timesteps: 665,763,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 665763384...
Checkpoint 665763384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,066.76306
Policy Entropy: 1.14205
Value Function Loss: 6.46106

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.09156

Collected Steps per Second: 11,216.98802
Overall Steps per Second: 9,464.81944

Timestep Collection Time: 4.45842
Timestep Consumption Time: 0.82536
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.28378

Cumulative Model Updates: 39,913
Cumulative Timesteps: 665,813,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,366.88482
Policy Entropy: 1.14179
Value Function Loss: 6.52678

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.06080
Value Function Update Magnitude: 0.08689

Collected Steps per Second: 10,531.35109
Overall Steps per Second: 9,209.68375

Timestep Collection Time: 4.74963
Timestep Consumption Time: 0.68161
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.43124

Cumulative Model Updates: 39,916
Cumulative Timesteps: 665,863,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 665863414...
Checkpoint 665863414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,947.82019
Policy Entropy: 1.13665
Value Function Loss: 6.68295

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.07852

Collected Steps per Second: 10,913.46425
Overall Steps per Second: 9,344.15794

Timestep Collection Time: 4.58223
Timestep Consumption Time: 0.76956
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.35179

Cumulative Model Updates: 39,919
Cumulative Timesteps: 665,913,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,486.24132
Policy Entropy: 1.13413
Value Function Loss: 6.43442

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.07172
Value Function Update Magnitude: 0.08074

Collected Steps per Second: 10,680.88210
Overall Steps per Second: 9,228.52788

Timestep Collection Time: 4.68201
Timestep Consumption Time: 0.73684
PPO Batch Consumption Time: 0.03417
Total Iteration Time: 5.41885

Cumulative Model Updates: 39,922
Cumulative Timesteps: 665,963,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 665963430...
Checkpoint 665963430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,004.07343
Policy Entropy: 1.11997
Value Function Loss: 6.29112

Mean KL Divergence: 0.03561
SB3 Clip Fraction: 0.16378
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.08184

Collected Steps per Second: 11,139.57570
Overall Steps per Second: 9,517.02659

Timestep Collection Time: 4.49119
Timestep Consumption Time: 0.76570
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.25689

Cumulative Model Updates: 39,925
Cumulative Timesteps: 666,013,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,903.13863
Policy Entropy: 1.13436
Value Function Loss: 6.26649

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.08127

Collected Steps per Second: 11,087.02885
Overall Steps per Second: 9,470.84965

Timestep Collection Time: 4.51176
Timestep Consumption Time: 0.76992
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 5.28168

Cumulative Model Updates: 39,928
Cumulative Timesteps: 666,063,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 666063482...
Checkpoint 666063482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,888.80873
Policy Entropy: 1.13304
Value Function Loss: 6.42274

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.07235
Value Function Update Magnitude: 0.07735

Collected Steps per Second: 10,603.09401
Overall Steps per Second: 9,106.31468

Timestep Collection Time: 4.71636
Timestep Consumption Time: 0.77521
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.49157

Cumulative Model Updates: 39,931
Cumulative Timesteps: 666,113,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,249.39651
Policy Entropy: 1.13777
Value Function Loss: 6.35631

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.06917
Value Function Update Magnitude: 0.07206

Collected Steps per Second: 10,923.40025
Overall Steps per Second: 9,342.83717

Timestep Collection Time: 4.57733
Timestep Consumption Time: 0.77436
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 5.35169

Cumulative Model Updates: 39,934
Cumulative Timesteps: 666,163,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 666163490...
Checkpoint 666163490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,620.61363
Policy Entropy: 1.12273
Value Function Loss: 6.25688

Mean KL Divergence: 0.05098
SB3 Clip Fraction: 0.14829
Policy Update Magnitude: 0.07186
Value Function Update Magnitude: 0.08047

Collected Steps per Second: 10,974.84532
Overall Steps per Second: 9,368.25524

Timestep Collection Time: 4.55606
Timestep Consumption Time: 0.78133
PPO Batch Consumption Time: 0.04428
Total Iteration Time: 5.33739

Cumulative Model Updates: 39,937
Cumulative Timesteps: 666,213,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,348.77313
Policy Entropy: 1.14574
Value Function Loss: 6.23053

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 11,139.54911
Overall Steps per Second: 9,420.07911

Timestep Collection Time: 4.49067
Timestep Consumption Time: 0.81969
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 5.31036

Cumulative Model Updates: 39,940
Cumulative Timesteps: 666,263,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 666263516...
Checkpoint 666263516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,931.40955
Policy Entropy: 1.13439
Value Function Loss: 6.35085

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.07972

Collected Steps per Second: 10,675.11673
Overall Steps per Second: 9,194.36487

Timestep Collection Time: 4.68585
Timestep Consumption Time: 0.75466
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.44051

Cumulative Model Updates: 39,943
Cumulative Timesteps: 666,313,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,473.47739
Policy Entropy: 1.13073
Value Function Loss: 6.15624

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.07731

Collected Steps per Second: 10,799.05983
Overall Steps per Second: 9,419.74329

Timestep Collection Time: 4.63207
Timestep Consumption Time: 0.67827
PPO Batch Consumption Time: 0.03382
Total Iteration Time: 5.31034

Cumulative Model Updates: 39,946
Cumulative Timesteps: 666,363,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 666363560...
Checkpoint 666363560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,050.88255
Policy Entropy: 1.13947
Value Function Loss: 6.09908

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.07495

Collected Steps per Second: 10,498.65328
Overall Steps per Second: 8,913.58663

Timestep Collection Time: 4.76385
Timestep Consumption Time: 0.84714
PPO Batch Consumption Time: 0.03989
Total Iteration Time: 5.61098

Cumulative Model Updates: 39,949
Cumulative Timesteps: 666,413,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,721.36583
Policy Entropy: 1.14139
Value Function Loss: 6.36208

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.07334

Collected Steps per Second: 11,597.98204
Overall Steps per Second: 9,873.74346

Timestep Collection Time: 4.31230
Timestep Consumption Time: 0.75305
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.06535

Cumulative Model Updates: 39,952
Cumulative Timesteps: 666,463,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 666463588...
Checkpoint 666463588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,491.41686
Policy Entropy: 1.15362
Value Function Loss: 6.67813

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.06818

Collected Steps per Second: 11,651.87152
Overall Steps per Second: 9,896.59111

Timestep Collection Time: 4.29287
Timestep Consumption Time: 0.76139
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.05427

Cumulative Model Updates: 39,955
Cumulative Timesteps: 666,513,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,860.38354
Policy Entropy: 1.15047
Value Function Loss: 6.83134

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.07191
Value Function Update Magnitude: 0.07588

Collected Steps per Second: 11,298.96478
Overall Steps per Second: 9,647.16660

Timestep Collection Time: 4.42607
Timestep Consumption Time: 0.75784
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.18391

Cumulative Model Updates: 39,958
Cumulative Timesteps: 666,563,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 666563618...
Checkpoint 666563618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,320.90966
Policy Entropy: 1.15896
Value Function Loss: 6.53743

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.06076
Value Function Update Magnitude: 0.07443

Collected Steps per Second: 11,384.30504
Overall Steps per Second: 9,873.74919

Timestep Collection Time: 4.39307
Timestep Consumption Time: 0.67208
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.06515

Cumulative Model Updates: 39,961
Cumulative Timesteps: 666,613,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,856.88501
Policy Entropy: 1.15154
Value Function Loss: 6.27784

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.06272
Value Function Update Magnitude: 0.06864

Collected Steps per Second: 11,410.39656
Overall Steps per Second: 9,648.76463

Timestep Collection Time: 4.38320
Timestep Consumption Time: 0.80027
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 5.18346

Cumulative Model Updates: 39,964
Cumulative Timesteps: 666,663,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 666663644...
Checkpoint 666663644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,249.89454
Policy Entropy: 1.14874
Value Function Loss: 6.06138

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.07685
Value Function Update Magnitude: 0.07346

Collected Steps per Second: 10,626.89527
Overall Steps per Second: 9,173.64321

Timestep Collection Time: 4.70768
Timestep Consumption Time: 0.74577
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.45345

Cumulative Model Updates: 39,967
Cumulative Timesteps: 666,713,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,945.24004
Policy Entropy: 1.13263
Value Function Loss: 6.13811

Mean KL Divergence: 0.03268
SB3 Clip Fraction: 0.15092
Policy Update Magnitude: 0.07315
Value Function Update Magnitude: 0.07781

Collected Steps per Second: 11,202.35487
Overall Steps per Second: 9,520.03339

Timestep Collection Time: 4.46353
Timestep Consumption Time: 0.78877
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.25229

Cumulative Model Updates: 39,970
Cumulative Timesteps: 666,763,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 666763674...
Checkpoint 666763674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,336.30851
Policy Entropy: 1.15128
Value Function Loss: 6.50206

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.07178

Collected Steps per Second: 11,008.15070
Overall Steps per Second: 9,452.47526

Timestep Collection Time: 4.54409
Timestep Consumption Time: 0.74786
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.29195

Cumulative Model Updates: 39,973
Cumulative Timesteps: 666,813,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,369.00830
Policy Entropy: 1.15318
Value Function Loss: 6.55092

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.06151
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 11,129.81975
Overall Steps per Second: 9,692.02078

Timestep Collection Time: 4.49513
Timestep Consumption Time: 0.66685
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.16198

Cumulative Model Updates: 39,976
Cumulative Timesteps: 666,863,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 666863726...
Checkpoint 666863726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,834.72065
Policy Entropy: 1.14314
Value Function Loss: 6.38211

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 10,952.41078
Overall Steps per Second: 9,330.71061

Timestep Collection Time: 4.56612
Timestep Consumption Time: 0.79360
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.35972

Cumulative Model Updates: 39,979
Cumulative Timesteps: 666,913,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,056.77259
Policy Entropy: 1.12526
Value Function Loss: 6.23401

Mean KL Divergence: 0.03348
SB3 Clip Fraction: 0.17260
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.07412

Collected Steps per Second: 11,093.70968
Overall Steps per Second: 9,434.45388

Timestep Collection Time: 4.50742
Timestep Consumption Time: 0.79273
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.30015

Cumulative Model Updates: 39,982
Cumulative Timesteps: 666,963,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 666963740...
Checkpoint 666963740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290,822.70830
Policy Entropy: 1.13553
Value Function Loss: 6.37445

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.06726

Collected Steps per Second: 10,908.12567
Overall Steps per Second: 9,245.64209

Timestep Collection Time: 4.58447
Timestep Consumption Time: 0.82435
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.40882

Cumulative Model Updates: 39,985
Cumulative Timesteps: 667,013,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,025.73406
Policy Entropy: 1.13553
Value Function Loss: 6.90954

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.07247

Collected Steps per Second: 11,302.36419
Overall Steps per Second: 9,633.62180

Timestep Collection Time: 4.42385
Timestep Consumption Time: 0.76630
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 5.19016

Cumulative Model Updates: 39,988
Cumulative Timesteps: 667,063,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 667063748...
Checkpoint 667063748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,276.15442
Policy Entropy: 1.13265
Value Function Loss: 6.93188

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.07943

Collected Steps per Second: 11,187.89175
Overall Steps per Second: 9,473.30425

Timestep Collection Time: 4.47037
Timestep Consumption Time: 0.80910
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.27947

Cumulative Model Updates: 39,991
Cumulative Timesteps: 667,113,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417,470.15852
Policy Entropy: 1.11359
Value Function Loss: 7.10208

Mean KL Divergence: 0.04252
SB3 Clip Fraction: 0.18901
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 11,145.47758
Overall Steps per Second: 9,493.79084

Timestep Collection Time: 4.48774
Timestep Consumption Time: 0.78076
PPO Batch Consumption Time: 0.03356
Total Iteration Time: 5.26850

Cumulative Model Updates: 39,994
Cumulative Timesteps: 667,163,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 667163780...
Checkpoint 667163780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,459.74293
Policy Entropy: 1.12915
Value Function Loss: 6.80676

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.08872

Collected Steps per Second: 11,030.77095
Overall Steps per Second: 9,591.34889

Timestep Collection Time: 4.53368
Timestep Consumption Time: 0.68039
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.21407

Cumulative Model Updates: 39,997
Cumulative Timesteps: 667,213,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456,450.07054
Policy Entropy: 1.12700
Value Function Loss: 6.52396

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.06670
Value Function Update Magnitude: 0.08209

Collected Steps per Second: 10,664.25021
Overall Steps per Second: 9,116.56783

Timestep Collection Time: 4.69006
Timestep Consumption Time: 0.79621
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.48628

Cumulative Model Updates: 40,000
Cumulative Timesteps: 667,263,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 667263806...
Checkpoint 667263806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,759.76806
Policy Entropy: 1.11179
Value Function Loss: 6.27598

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.08565

Collected Steps per Second: 10,810.76524
Overall Steps per Second: 9,184.43276

Timestep Collection Time: 4.62613
Timestep Consumption Time: 0.81917
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 5.44530

Cumulative Model Updates: 40,003
Cumulative Timesteps: 667,313,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,399.38349
Policy Entropy: 1.13550
Value Function Loss: 6.11641

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.09014

Collected Steps per Second: 10,566.77635
Overall Steps per Second: 9,229.14135

Timestep Collection Time: 4.73238
Timestep Consumption Time: 0.68589
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.41827

Cumulative Model Updates: 40,006
Cumulative Timesteps: 667,363,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 667363824...
Checkpoint 667363824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,755.68455
Policy Entropy: 1.13936
Value Function Loss: 6.29573

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.08853

Collected Steps per Second: 10,575.02485
Overall Steps per Second: 9,029.57162

Timestep Collection Time: 4.72982
Timestep Consumption Time: 0.80953
PPO Batch Consumption Time: 0.03854
Total Iteration Time: 5.53935

Cumulative Model Updates: 40,009
Cumulative Timesteps: 667,413,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,193.01084
Policy Entropy: 1.12647
Value Function Loss: 6.18964

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.08119

Collected Steps per Second: 10,880.92132
Overall Steps per Second: 9,406.30039

Timestep Collection Time: 4.59722
Timestep Consumption Time: 0.72070
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.31793

Cumulative Model Updates: 40,012
Cumulative Timesteps: 667,463,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 667463864...
Checkpoint 667463864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,530.21490
Policy Entropy: 1.11936
Value Function Loss: 6.01500

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.08100

Collected Steps per Second: 11,003.84974
Overall Steps per Second: 9,394.05314

Timestep Collection Time: 4.54386
Timestep Consumption Time: 0.77865
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.32252

Cumulative Model Updates: 40,015
Cumulative Timesteps: 667,513,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,441.31105
Policy Entropy: 1.13039
Value Function Loss: 5.63147

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.04727
Value Function Update Magnitude: 0.07707

Collected Steps per Second: 10,864.34277
Overall Steps per Second: 9,303.28482

Timestep Collection Time: 4.60387
Timestep Consumption Time: 0.77251
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.37638

Cumulative Model Updates: 40,018
Cumulative Timesteps: 667,563,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 667563882...
Checkpoint 667563882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,902.14176
Policy Entropy: 1.13296
Value Function Loss: 5.92311

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.07235

Collected Steps per Second: 11,701.32749
Overall Steps per Second: 10,020.38477

Timestep Collection Time: 4.27422
Timestep Consumption Time: 0.71701
PPO Batch Consumption Time: 0.04035
Total Iteration Time: 4.99123

Cumulative Model Updates: 40,021
Cumulative Timesteps: 667,613,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,245.40815
Policy Entropy: 1.11708
Value Function Loss: 6.31712

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.07706

Collected Steps per Second: 11,729.47067
Overall Steps per Second: 9,871.78056

Timestep Collection Time: 4.26345
Timestep Consumption Time: 0.80230
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.06575

Cumulative Model Updates: 40,024
Cumulative Timesteps: 667,663,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 667663904...
Checkpoint 667663904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,696.91891
Policy Entropy: 1.10233
Value Function Loss: 7.09105

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 11,394.49141
Overall Steps per Second: 9,762.58671

Timestep Collection Time: 4.38826
Timestep Consumption Time: 0.73354
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.12180

Cumulative Model Updates: 40,027
Cumulative Timesteps: 667,713,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,381.89495
Policy Entropy: 1.11589
Value Function Loss: 7.14766

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.07781

Collected Steps per Second: 12,392.28499
Overall Steps per Second: 10,324.95752

Timestep Collection Time: 4.03671
Timestep Consumption Time: 0.80825
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 4.84496

Cumulative Model Updates: 40,030
Cumulative Timesteps: 667,763,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 667763930...
Checkpoint 667763930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,973.56110
Policy Entropy: 1.11860
Value Function Loss: 6.71599

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.07188

Collected Steps per Second: 11,756.89665
Overall Steps per Second: 9,601.17946

Timestep Collection Time: 4.25469
Timestep Consumption Time: 0.95529
PPO Batch Consumption Time: 0.03814
Total Iteration Time: 5.20998

Cumulative Model Updates: 40,033
Cumulative Timesteps: 667,813,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,177.38154
Policy Entropy: 1.10981
Value Function Loss: 6.22493

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.07656

Collected Steps per Second: 11,519.20296
Overall Steps per Second: 9,837.90934

Timestep Collection Time: 4.34214
Timestep Consumption Time: 0.74207
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 5.08421

Cumulative Model Updates: 40,036
Cumulative Timesteps: 667,863,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 667863970...
Checkpoint 667863970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,870.40125
Policy Entropy: 1.08724
Value Function Loss: 6.12373

Mean KL Divergence: 0.04101
SB3 Clip Fraction: 0.16997
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.07513

Collected Steps per Second: 11,088.79205
Overall Steps per Second: 9,396.17224

Timestep Collection Time: 4.51104
Timestep Consumption Time: 0.81262
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.32366

Cumulative Model Updates: 40,039
Cumulative Timesteps: 667,913,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469,375.61851
Policy Entropy: 1.11232
Value Function Loss: 6.30500

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.08932

Collected Steps per Second: 11,066.51130
Overall Steps per Second: 9,436.51732

Timestep Collection Time: 4.52085
Timestep Consumption Time: 0.78090
PPO Batch Consumption Time: 0.03309
Total Iteration Time: 5.30174

Cumulative Model Updates: 40,042
Cumulative Timesteps: 667,964,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 667964022...
Checkpoint 667964022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442,072.99096
Policy Entropy: 1.08681
Value Function Loss: 5.87460

Mean KL Divergence: 0.02803
SB3 Clip Fraction: 0.16011
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.08048

Collected Steps per Second: 11,211.54931
Overall Steps per Second: 9,617.99559

Timestep Collection Time: 4.46022
Timestep Consumption Time: 0.73899
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.19921

Cumulative Model Updates: 40,045
Cumulative Timesteps: 668,014,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,485.29994
Policy Entropy: 1.09738
Value Function Loss: 5.91019

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.08631

Collected Steps per Second: 11,041.52410
Overall Steps per Second: 9,366.33101

Timestep Collection Time: 4.53017
Timestep Consumption Time: 0.81023
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 5.34040

Cumulative Model Updates: 40,048
Cumulative Timesteps: 668,064,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 668064048...
Checkpoint 668064048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,517.58870
Policy Entropy: 1.10221
Value Function Loss: 6.23177

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.09050

Collected Steps per Second: 10,599.29414
Overall Steps per Second: 9,068.53701

Timestep Collection Time: 4.71862
Timestep Consumption Time: 0.79650
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.51511

Cumulative Model Updates: 40,051
Cumulative Timesteps: 668,114,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,089.45644
Policy Entropy: 1.12101
Value Function Loss: 6.38160

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.15937
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.09059

Collected Steps per Second: 11,019.32890
Overall Steps per Second: 9,432.87743

Timestep Collection Time: 4.53875
Timestep Consumption Time: 0.76334
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.30209

Cumulative Model Updates: 40,054
Cumulative Timesteps: 668,164,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 668164076...
Checkpoint 668164076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,801.46663
Policy Entropy: 1.11077
Value Function Loss: 6.57651

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.09767

Collected Steps per Second: 10,713.06768
Overall Steps per Second: 9,268.50242

Timestep Collection Time: 4.66794
Timestep Consumption Time: 0.72753
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.39548

Cumulative Model Updates: 40,057
Cumulative Timesteps: 668,214,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,801.95861
Policy Entropy: 1.11901
Value Function Loss: 6.38312

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.10780

Collected Steps per Second: 10,431.74608
Overall Steps per Second: 9,149.92141

Timestep Collection Time: 4.79517
Timestep Consumption Time: 0.67176
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.46693

Cumulative Model Updates: 40,060
Cumulative Timesteps: 668,264,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 668264106...
Checkpoint 668264106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442,051.23724
Policy Entropy: 1.11951
Value Function Loss: 6.89351

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.05876
Value Function Update Magnitude: 0.10088

Collected Steps per Second: 10,883.09087
Overall Steps per Second: 9,312.90019

Timestep Collection Time: 4.59594
Timestep Consumption Time: 0.77489
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.37083

Cumulative Model Updates: 40,063
Cumulative Timesteps: 668,314,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,227.70602
Policy Entropy: 1.10052
Value Function Loss: 6.62408

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.08732

Collected Steps per Second: 10,813.89820
Overall Steps per Second: 9,324.40784

Timestep Collection Time: 4.62386
Timestep Consumption Time: 0.73862
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.36249

Cumulative Model Updates: 40,066
Cumulative Timesteps: 668,364,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 668364126...
Checkpoint 668364126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,555.08243
Policy Entropy: 1.09343
Value Function Loss: 6.70558

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.09355

Collected Steps per Second: 10,589.88030
Overall Steps per Second: 9,117.22813

Timestep Collection Time: 4.72281
Timestep Consumption Time: 0.76285
PPO Batch Consumption Time: 0.04007
Total Iteration Time: 5.48566

Cumulative Model Updates: 40,069
Cumulative Timesteps: 668,414,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,276.21861
Policy Entropy: 1.09625
Value Function Loss: 6.49334

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.09225

Collected Steps per Second: 10,544.78405
Overall Steps per Second: 9,072.71215

Timestep Collection Time: 4.74339
Timestep Consumption Time: 0.76963
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 5.51302

Cumulative Model Updates: 40,072
Cumulative Timesteps: 668,464,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 668464158...
Checkpoint 668464158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,053.97914
Policy Entropy: 1.09891
Value Function Loss: 6.19116

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.04380
Value Function Update Magnitude: 0.08117

Collected Steps per Second: 10,850.69638
Overall Steps per Second: 9,403.34885

Timestep Collection Time: 4.60818
Timestep Consumption Time: 0.70928
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.31747

Cumulative Model Updates: 40,075
Cumulative Timesteps: 668,514,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,573.64766
Policy Entropy: 1.08357
Value Function Loss: 5.89309

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 10,760.62301
Overall Steps per Second: 9,207.24840

Timestep Collection Time: 4.64862
Timestep Consumption Time: 0.78428
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 5.43289

Cumulative Model Updates: 40,078
Cumulative Timesteps: 668,564,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 668564182...
Checkpoint 668564182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,699.23184
Policy Entropy: 1.08627
Value Function Loss: 5.84044

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.07999

Collected Steps per Second: 10,677.62074
Overall Steps per Second: 9,299.00564

Timestep Collection Time: 4.68419
Timestep Consumption Time: 0.69445
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.37864

Cumulative Model Updates: 40,081
Cumulative Timesteps: 668,614,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,948.08959
Policy Entropy: 1.09774
Value Function Loss: 6.43726

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 10,453.75501
Overall Steps per Second: 8,936.19821

Timestep Collection Time: 4.78374
Timestep Consumption Time: 0.81238
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.59612

Cumulative Model Updates: 40,084
Cumulative Timesteps: 668,664,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 668664206...
Checkpoint 668664206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,443.74641
Policy Entropy: 1.11133
Value Function Loss: 6.72687

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.07453

Collected Steps per Second: 11,432.93615
Overall Steps per Second: 9,723.13062

Timestep Collection Time: 4.37560
Timestep Consumption Time: 0.76945
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.14505

Cumulative Model Updates: 40,087
Cumulative Timesteps: 668,714,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,689.26628
Policy Entropy: 1.09790
Value Function Loss: 6.38734

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.09801

Collected Steps per Second: 11,262.67538
Overall Steps per Second: 9,723.03865

Timestep Collection Time: 4.43962
Timestep Consumption Time: 0.70301
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.14263

Cumulative Model Updates: 40,090
Cumulative Timesteps: 668,764,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 668764234...
Checkpoint 668764234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,845.26367
Policy Entropy: 1.09877
Value Function Loss: 6.27040

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.08644

Collected Steps per Second: 11,245.14876
Overall Steps per Second: 9,582.31028

Timestep Collection Time: 4.44796
Timestep Consumption Time: 0.77186
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.21983

Cumulative Model Updates: 40,093
Cumulative Timesteps: 668,814,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451,044.50307
Policy Entropy: 1.10850
Value Function Loss: 6.27895

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.07860

Collected Steps per Second: 11,096.54844
Overall Steps per Second: 9,557.46905

Timestep Collection Time: 4.50879
Timestep Consumption Time: 0.72607
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 5.23486

Cumulative Model Updates: 40,096
Cumulative Timesteps: 668,864,284

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 668864284...
Checkpoint 668864284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,777.96340
Policy Entropy: 1.11359
Value Function Loss: 6.79102

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.07372

Collected Steps per Second: 11,492.43818
Overall Steps per Second: 9,795.84546

Timestep Collection Time: 4.35208
Timestep Consumption Time: 0.75376
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.10584

Cumulative Model Updates: 40,099
Cumulative Timesteps: 668,914,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,802.21060
Policy Entropy: 1.08614
Value Function Loss: 6.83765

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.07190

Collected Steps per Second: 11,084.98847
Overall Steps per Second: 9,482.21169

Timestep Collection Time: 4.51060
Timestep Consumption Time: 0.76243
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.27303

Cumulative Model Updates: 40,102
Cumulative Timesteps: 668,964,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 668964300...
Checkpoint 668964300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,055.58419
Policy Entropy: 1.09498
Value Function Loss: 6.84894

Mean KL Divergence: 0.02334
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.08225

Collected Steps per Second: 10,980.09256
Overall Steps per Second: 9,525.74775

Timestep Collection Time: 4.55570
Timestep Consumption Time: 0.69554
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.25124

Cumulative Model Updates: 40,105
Cumulative Timesteps: 669,014,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,790.96170
Policy Entropy: 1.10054
Value Function Loss: 6.43713

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.07719

Collected Steps per Second: 11,320.95302
Overall Steps per Second: 9,648.16393

Timestep Collection Time: 4.41853
Timestep Consumption Time: 0.76608
PPO Batch Consumption Time: 0.03804
Total Iteration Time: 5.18461

Cumulative Model Updates: 40,108
Cumulative Timesteps: 669,064,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 669064344...
Checkpoint 669064344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421,141.51753
Policy Entropy: 1.09472
Value Function Loss: 6.27775

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.06992

Collected Steps per Second: 10,938.20839
Overall Steps per Second: 9,359.51460

Timestep Collection Time: 4.57351
Timestep Consumption Time: 0.77143
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.34494

Cumulative Model Updates: 40,111
Cumulative Timesteps: 669,114,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398,931.66637
Policy Entropy: 1.07893
Value Function Loss: 5.98079

Mean KL Divergence: 0.02911
SB3 Clip Fraction: 0.16620
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.07045

Collected Steps per Second: 11,436.44367
Overall Steps per Second: 9,721.33583

Timestep Collection Time: 4.37269
Timestep Consumption Time: 0.77146
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.14415

Cumulative Model Updates: 40,114
Cumulative Timesteps: 669,164,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 669164378...
Checkpoint 669164378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,371.12962
Policy Entropy: 1.09543
Value Function Loss: 5.87612

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.06754

Collected Steps per Second: 11,103.91590
Overall Steps per Second: 9,463.09221

Timestep Collection Time: 4.50454
Timestep Consumption Time: 0.78105
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.28559

Cumulative Model Updates: 40,117
Cumulative Timesteps: 669,214,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,662.46055
Policy Entropy: 1.09157
Value Function Loss: 5.69674

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.11608
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.06858

Collected Steps per Second: 10,433.72038
Overall Steps per Second: 9,156.08037

Timestep Collection Time: 4.79484
Timestep Consumption Time: 0.66907
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.46391

Cumulative Model Updates: 40,120
Cumulative Timesteps: 669,264,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 669264424...
Checkpoint 669264424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,956.40614
Policy Entropy: 1.07561
Value Function Loss: 5.74278

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.06301

Collected Steps per Second: 10,888.42185
Overall Steps per Second: 9,338.99644

Timestep Collection Time: 4.59295
Timestep Consumption Time: 0.76201
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.35497

Cumulative Model Updates: 40,123
Cumulative Timesteps: 669,314,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,920.68165
Policy Entropy: 1.09060
Value Function Loss: 5.88415

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.07669

Collected Steps per Second: 10,838.84214
Overall Steps per Second: 9,441.74899

Timestep Collection Time: 4.61507
Timestep Consumption Time: 0.68289
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.29796

Cumulative Model Updates: 40,126
Cumulative Timesteps: 669,364,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 669364456...
Checkpoint 669364456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,576.92703
Policy Entropy: 1.09244
Value Function Loss: 6.12673

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.07256

Collected Steps per Second: 10,925.67992
Overall Steps per Second: 9,341.54353

Timestep Collection Time: 4.57729
Timestep Consumption Time: 0.77622
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.35350

Cumulative Model Updates: 40,129
Cumulative Timesteps: 669,414,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,307.43054
Policy Entropy: 1.10112
Value Function Loss: 5.90290

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.07506

Collected Steps per Second: 10,928.78621
Overall Steps per Second: 9,421.93712

Timestep Collection Time: 4.57599
Timestep Consumption Time: 0.73184
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 5.30783

Cumulative Model Updates: 40,132
Cumulative Timesteps: 669,464,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 669464476...
Checkpoint 669464476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,213.66469
Policy Entropy: 1.08946
Value Function Loss: 5.97322

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.06638
Value Function Update Magnitude: 0.07598

Collected Steps per Second: 10,744.38853
Overall Steps per Second: 9,122.56621

Timestep Collection Time: 4.65508
Timestep Consumption Time: 0.82759
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.48267

Cumulative Model Updates: 40,135
Cumulative Timesteps: 669,514,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,591.91340
Policy Entropy: 1.11119
Value Function Loss: 5.97418

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.07997

Collected Steps per Second: 10,618.85998
Overall Steps per Second: 9,099.01734

Timestep Collection Time: 4.70955
Timestep Consumption Time: 0.78665
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 5.49620

Cumulative Model Updates: 40,138
Cumulative Timesteps: 669,564,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 669564502...
Checkpoint 669564502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,919.05792
Policy Entropy: 1.10715
Value Function Loss: 6.15358

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.08181

Collected Steps per Second: 10,582.50120
Overall Steps per Second: 9,142.11180

Timestep Collection Time: 4.72573
Timestep Consumption Time: 0.74456
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.47029

Cumulative Model Updates: 40,141
Cumulative Timesteps: 669,614,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,927.60427
Policy Entropy: 1.08308
Value Function Loss: 5.99736

Mean KL Divergence: 0.02618
SB3 Clip Fraction: 0.15413
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.08188

Collected Steps per Second: 10,690.91017
Overall Steps per Second: 9,126.22232

Timestep Collection Time: 4.67893
Timestep Consumption Time: 0.80220
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.48113

Cumulative Model Updates: 40,144
Cumulative Timesteps: 669,664,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 669664534...
Checkpoint 669664534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,452.38637
Policy Entropy: 1.07874
Value Function Loss: 5.89437

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.07536

Collected Steps per Second: 10,793.79332
Overall Steps per Second: 9,221.97271

Timestep Collection Time: 4.63396
Timestep Consumption Time: 0.78983
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.42379

Cumulative Model Updates: 40,147
Cumulative Timesteps: 669,714,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,144.56846
Policy Entropy: 1.08699
Value Function Loss: 5.93905

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.07124

Collected Steps per Second: 10,960.01058
Overall Steps per Second: 9,231.21411

Timestep Collection Time: 4.56295
Timestep Consumption Time: 0.85454
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.41749

Cumulative Model Updates: 40,150
Cumulative Timesteps: 669,764,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 669764562...
Checkpoint 669764562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,550.86340
Policy Entropy: 1.10286
Value Function Loss: 6.13144

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.06464

Collected Steps per Second: 10,624.74413
Overall Steps per Second: 9,081.65421

Timestep Collection Time: 4.70750
Timestep Consumption Time: 0.79987
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.50737

Cumulative Model Updates: 40,153
Cumulative Timesteps: 669,814,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,499.34397
Policy Entropy: 1.07894
Value Function Loss: 5.90548

Mean KL Divergence: 0.02915
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.06288

Collected Steps per Second: 11,983.46890
Overall Steps per Second: 10,240.95244

Timestep Collection Time: 4.17492
Timestep Consumption Time: 0.71037
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.88529

Cumulative Model Updates: 40,156
Cumulative Timesteps: 669,864,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 669864608...
Checkpoint 669864608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,270.20096
Policy Entropy: 1.09846
Value Function Loss: 5.67035

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.08169

Collected Steps per Second: 11,887.95368
Overall Steps per Second: 10,008.14938

Timestep Collection Time: 4.20762
Timestep Consumption Time: 0.79031
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 4.99793

Cumulative Model Updates: 40,159
Cumulative Timesteps: 669,914,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,321.33098
Policy Entropy: 1.10081
Value Function Loss: 5.48800

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.07369

Collected Steps per Second: 11,836.44645
Overall Steps per Second: 10,018.05594

Timestep Collection Time: 4.22424
Timestep Consumption Time: 0.76675
PPO Batch Consumption Time: 0.03775
Total Iteration Time: 4.99099

Cumulative Model Updates: 40,162
Cumulative Timesteps: 669,964,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 669964628...
Checkpoint 669964628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,725.98752
Policy Entropy: 1.08926
Value Function Loss: 5.59655

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.12064
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 12,008.44336
Overall Steps per Second: 10,068.39423

Timestep Collection Time: 4.16540
Timestep Consumption Time: 0.80262
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 4.96802

Cumulative Model Updates: 40,165
Cumulative Timesteps: 670,014,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,255.32933
Policy Entropy: 1.08181
Value Function Loss: 6.07532

Mean KL Divergence: 0.03039
SB3 Clip Fraction: 0.15664
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.07629

Collected Steps per Second: 11,826.32301
Overall Steps per Second: 9,959.09783

Timestep Collection Time: 4.23039
Timestep Consumption Time: 0.79315
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 5.02355

Cumulative Model Updates: 40,168
Cumulative Timesteps: 670,064,678

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 670064678...
Checkpoint 670064678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,754.93371
Policy Entropy: 1.09754
Value Function Loss: 6.40900

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.07154

Collected Steps per Second: 10,670.32373
Overall Steps per Second: 9,191.20586

Timestep Collection Time: 4.68777
Timestep Consumption Time: 0.75439
PPO Batch Consumption Time: 0.03769
Total Iteration Time: 5.44216

Cumulative Model Updates: 40,171
Cumulative Timesteps: 670,114,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420,274.84084
Policy Entropy: 1.10812
Value Function Loss: 6.22859

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.07647

Collected Steps per Second: 11,019.43185
Overall Steps per Second: 9,411.42484

Timestep Collection Time: 4.53871
Timestep Consumption Time: 0.77547
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.31418

Cumulative Model Updates: 40,174
Cumulative Timesteps: 670,164,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 670164712...
Checkpoint 670164712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,904.08356
Policy Entropy: 1.08566
Value Function Loss: 5.99125

Mean KL Divergence: 0.02451
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.07214

Collected Steps per Second: 11,228.28344
Overall Steps per Second: 9,594.50418

Timestep Collection Time: 4.45536
Timestep Consumption Time: 0.75867
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.21403

Cumulative Model Updates: 40,177
Cumulative Timesteps: 670,214,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,577.99219
Policy Entropy: 1.09295
Value Function Loss: 5.98896

Mean KL Divergence: 0.02455
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.08060

Collected Steps per Second: 11,054.95978
Overall Steps per Second: 9,374.81789

Timestep Collection Time: 4.52412
Timestep Consumption Time: 0.81081
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.33493

Cumulative Model Updates: 40,180
Cumulative Timesteps: 670,264,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 670264752...
Checkpoint 670264752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,387.44548
Policy Entropy: 1.09318
Value Function Loss: 6.13579

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.16260
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.08220

Collected Steps per Second: 10,868.83059
Overall Steps per Second: 9,308.51207

Timestep Collection Time: 4.60307
Timestep Consumption Time: 0.77158
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 5.37465

Cumulative Model Updates: 40,183
Cumulative Timesteps: 670,314,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592,922.86331
Policy Entropy: 1.08128
Value Function Loss: 5.94631

Mean KL Divergence: 0.02641
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.07317

Collected Steps per Second: 10,602.96506
Overall Steps per Second: 9,272.74581

Timestep Collection Time: 4.71811
Timestep Consumption Time: 0.67684
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 5.39495

Cumulative Model Updates: 40,186
Cumulative Timesteps: 670,364,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 670364808...
Checkpoint 670364808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,569.58477
Policy Entropy: 1.07723
Value Function Loss: 5.56919

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.06776

Collected Steps per Second: 10,897.06843
Overall Steps per Second: 9,307.25468

Timestep Collection Time: 4.58986
Timestep Consumption Time: 0.78401
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.37387

Cumulative Model Updates: 40,189
Cumulative Timesteps: 670,414,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,390.95529
Policy Entropy: 1.08544
Value Function Loss: 5.78035

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.06194

Collected Steps per Second: 10,823.88395
Overall Steps per Second: 9,359.13813

Timestep Collection Time: 4.62182
Timestep Consumption Time: 0.72333
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.34515

Cumulative Model Updates: 40,192
Cumulative Timesteps: 670,464,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 670464850...
Checkpoint 670464850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,028.12359
Policy Entropy: 1.09537
Value Function Loss: 5.80765

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.07842

Collected Steps per Second: 10,604.28185
Overall Steps per Second: 9,089.10436

Timestep Collection Time: 4.71602
Timestep Consumption Time: 0.78617
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.50219

Cumulative Model Updates: 40,195
Cumulative Timesteps: 670,514,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,363.52693
Policy Entropy: 1.07630
Value Function Loss: 5.83741

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.09499

Collected Steps per Second: 10,863.80267
Overall Steps per Second: 9,331.28723

Timestep Collection Time: 4.60281
Timestep Consumption Time: 0.75594
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.35875

Cumulative Model Updates: 40,198
Cumulative Timesteps: 670,564,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 670564864...
Checkpoint 670564864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,216.39537
Policy Entropy: 1.09285
Value Function Loss: 5.89086

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.08512

Collected Steps per Second: 10,957.70600
Overall Steps per Second: 9,545.78562

Timestep Collection Time: 4.56336
Timestep Consumption Time: 0.67497
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.23833

Cumulative Model Updates: 40,201
Cumulative Timesteps: 670,614,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,861.58003
Policy Entropy: 1.10016
Value Function Loss: 6.21007

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.07986

Collected Steps per Second: 10,280.76955
Overall Steps per Second: 8,864.24319

Timestep Collection Time: 4.86520
Timestep Consumption Time: 0.77747
PPO Batch Consumption Time: 0.03874
Total Iteration Time: 5.64267

Cumulative Model Updates: 40,204
Cumulative Timesteps: 670,664,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 670664886...
Checkpoint 670664886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349,358.71972
Policy Entropy: 1.10632
Value Function Loss: 6.06945

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.06757
Value Function Update Magnitude: 0.07014

Collected Steps per Second: 10,709.45013
Overall Steps per Second: 9,175.63978

Timestep Collection Time: 4.67176
Timestep Consumption Time: 0.78094
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.45270

Cumulative Model Updates: 40,207
Cumulative Timesteps: 670,714,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469,754.26006
Policy Entropy: 1.10251
Value Function Loss: 6.05280

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.07282
Value Function Update Magnitude: 0.06655

Collected Steps per Second: 11,046.27104
Overall Steps per Second: 9,415.72745

Timestep Collection Time: 4.52714
Timestep Consumption Time: 0.78398
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.31111

Cumulative Model Updates: 40,210
Cumulative Timesteps: 670,764,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 670764926...
Checkpoint 670764926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,816.89497
Policy Entropy: 1.09669
Value Function Loss: 5.97169

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.07255
Value Function Update Magnitude: 0.06896

Collected Steps per Second: 10,766.54851
Overall Steps per Second: 9,149.34418

Timestep Collection Time: 4.64643
Timestep Consumption Time: 0.82129
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.46771

Cumulative Model Updates: 40,213
Cumulative Timesteps: 670,814,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,782.09819
Policy Entropy: 1.08263
Value Function Loss: 6.08903

Mean KL Divergence: 0.03377
SB3 Clip Fraction: 0.16127
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.06975

Collected Steps per Second: 10,959.83875
Overall Steps per Second: 9,489.17805

Timestep Collection Time: 4.56467
Timestep Consumption Time: 0.70745
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.27211

Cumulative Model Updates: 40,216
Cumulative Timesteps: 670,864,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 670864980...
Checkpoint 670864980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,201.69118
Policy Entropy: 1.09418
Value Function Loss: 5.75518

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.11419
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.07547

Collected Steps per Second: 10,394.36546
Overall Steps per Second: 8,898.23691

Timestep Collection Time: 4.81280
Timestep Consumption Time: 0.80921
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.62201

Cumulative Model Updates: 40,219
Cumulative Timesteps: 670,915,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,146.63991
Policy Entropy: 1.09968
Value Function Loss: 5.74833

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.06869

Collected Steps per Second: 10,961.39749
Overall Steps per Second: 9,385.92645

Timestep Collection Time: 4.56310
Timestep Consumption Time: 0.76594
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.32904

Cumulative Model Updates: 40,222
Cumulative Timesteps: 670,965,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 670965024...
Checkpoint 670965024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,933.58368
Policy Entropy: 1.07654
Value Function Loss: 6.01040

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.06536

Collected Steps per Second: 11,376.31640
Overall Steps per Second: 9,638.64578

Timestep Collection Time: 4.39685
Timestep Consumption Time: 0.79267
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.18953

Cumulative Model Updates: 40,225
Cumulative Timesteps: 671,015,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,989.15353
Policy Entropy: 1.06560
Value Function Loss: 6.28389

Mean KL Divergence: 0.04072
SB3 Clip Fraction: 0.17833
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.07215

Collected Steps per Second: 11,419.35040
Overall Steps per Second: 9,652.87541

Timestep Collection Time: 4.37906
Timestep Consumption Time: 0.80137
PPO Batch Consumption Time: 0.03823
Total Iteration Time: 5.18043

Cumulative Model Updates: 40,228
Cumulative Timesteps: 671,065,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 671065050...
Checkpoint 671065050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,621.09526
Policy Entropy: 1.09283
Value Function Loss: 6.25953

Mean KL Divergence: 0.03019
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.07464

Collected Steps per Second: 11,376.28705
Overall Steps per Second: 9,841.32826

Timestep Collection Time: 4.39511
Timestep Consumption Time: 0.68551
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.08061

Cumulative Model Updates: 40,231
Cumulative Timesteps: 671,115,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,610.27138
Policy Entropy: 1.07838
Value Function Loss: 6.31240

Mean KL Divergence: 0.03176
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.07252

Collected Steps per Second: 11,438.79148
Overall Steps per Second: 9,607.00594

Timestep Collection Time: 4.37336
Timestep Consumption Time: 0.83388
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.20724

Cumulative Model Updates: 40,234
Cumulative Timesteps: 671,165,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 671165076...
Checkpoint 671165076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,393.26070
Policy Entropy: 1.08280
Value Function Loss: 5.89052

Mean KL Divergence: 0.03218
SB3 Clip Fraction: 0.15102
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.05949

Collected Steps per Second: 10,764.18320
Overall Steps per Second: 9,321.57185

Timestep Collection Time: 4.64726
Timestep Consumption Time: 0.71921
PPO Batch Consumption Time: 0.04112
Total Iteration Time: 5.36648

Cumulative Model Updates: 40,237
Cumulative Timesteps: 671,215,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,621.30003
Policy Entropy: 1.09195
Value Function Loss: 5.95113

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.05247

Collected Steps per Second: 11,245.37821
Overall Steps per Second: 9,394.72898

Timestep Collection Time: 4.44876
Timestep Consumption Time: 0.87635
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.32511

Cumulative Model Updates: 40,240
Cumulative Timesteps: 671,265,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 671265128...
Checkpoint 671265128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,979.95856
Policy Entropy: 1.09578
Value Function Loss: 6.00915

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.05513

Collected Steps per Second: 10,966.65216
Overall Steps per Second: 9,500.61960

Timestep Collection Time: 4.56147
Timestep Consumption Time: 0.70388
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.26534

Cumulative Model Updates: 40,243
Cumulative Timesteps: 671,315,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,038.05692
Policy Entropy: 1.10663
Value Function Loss: 6.24430

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.04938

Collected Steps per Second: 10,839.17580
Overall Steps per Second: 9,232.87914

Timestep Collection Time: 4.61456
Timestep Consumption Time: 0.80282
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.41738

Cumulative Model Updates: 40,246
Cumulative Timesteps: 671,365,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 671365170...
Checkpoint 671365170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,916.71242
Policy Entropy: 1.08575
Value Function Loss: 6.12582

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.04652

Collected Steps per Second: 10,991.43712
Overall Steps per Second: 9,397.88938

Timestep Collection Time: 4.55118
Timestep Consumption Time: 0.77172
PPO Batch Consumption Time: 0.03737
Total Iteration Time: 5.32290

Cumulative Model Updates: 40,249
Cumulative Timesteps: 671,415,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,377.28601
Policy Entropy: 1.07214
Value Function Loss: 5.80734

Mean KL Divergence: 0.03343
SB3 Clip Fraction: 0.17505
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.05743

Collected Steps per Second: 11,064.67325
Overall Steps per Second: 9,559.68963

Timestep Collection Time: 4.51997
Timestep Consumption Time: 0.71158
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.23155

Cumulative Model Updates: 40,252
Cumulative Timesteps: 671,465,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 671465206...
Checkpoint 671465206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,991.62342
Policy Entropy: 1.08099
Value Function Loss: 5.71878

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.05820

Collected Steps per Second: 10,535.44634
Overall Steps per Second: 9,068.56540

Timestep Collection Time: 4.74797
Timestep Consumption Time: 0.76801
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.51598

Cumulative Model Updates: 40,255
Cumulative Timesteps: 671,515,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,591.15768
Policy Entropy: 1.08477
Value Function Loss: 5.84675

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.05443

Collected Steps per Second: 10,821.52580
Overall Steps per Second: 9,468.52991

Timestep Collection Time: 4.62116
Timestep Consumption Time: 0.66034
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.28150

Cumulative Model Updates: 40,258
Cumulative Timesteps: 671,565,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 671565236...
Checkpoint 671565236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,112.22945
Policy Entropy: 1.06991
Value Function Loss: 6.00302

Mean KL Divergence: 0.02675
SB3 Clip Fraction: 0.15057
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.06071

Collected Steps per Second: 10,847.80553
Overall Steps per Second: 9,292.94171

Timestep Collection Time: 4.61144
Timestep Consumption Time: 0.77157
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.38301

Cumulative Model Updates: 40,261
Cumulative Timesteps: 671,615,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,078.44643
Policy Entropy: 1.09085
Value Function Loss: 6.28280

Mean KL Divergence: 0.03089
SB3 Clip Fraction: 0.17209
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.05749

Collected Steps per Second: 10,863.98621
Overall Steps per Second: 9,321.01881

Timestep Collection Time: 4.60402
Timestep Consumption Time: 0.76213
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 5.36615

Cumulative Model Updates: 40,264
Cumulative Timesteps: 671,665,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 671665278...
Checkpoint 671665278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,775.53264
Policy Entropy: 1.07938
Value Function Loss: 6.38407

Mean KL Divergence: 0.02681
SB3 Clip Fraction: 0.15982
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.05405

Collected Steps per Second: 10,791.39453
Overall Steps per Second: 9,380.82908

Timestep Collection Time: 4.63517
Timestep Consumption Time: 0.69698
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.33215

Cumulative Model Updates: 40,267
Cumulative Timesteps: 671,715,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,544.46273
Policy Entropy: 1.07409
Value Function Loss: 6.24789

Mean KL Divergence: 0.03249
SB3 Clip Fraction: 0.16423
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.05924

Collected Steps per Second: 10,518.07204
Overall Steps per Second: 9,043.76849

Timestep Collection Time: 4.75524
Timestep Consumption Time: 0.77519
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.53044

Cumulative Model Updates: 40,270
Cumulative Timesteps: 671,765,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 671765314...
Checkpoint 671765314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,215.11885
Policy Entropy: 1.07014
Value Function Loss: 6.23746

Mean KL Divergence: 0.02303
SB3 Clip Fraction: 0.15319
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.06357

Collected Steps per Second: 10,548.90365
Overall Steps per Second: 9,046.79377

Timestep Collection Time: 4.74135
Timestep Consumption Time: 0.78724
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 5.52859

Cumulative Model Updates: 40,273
Cumulative Timesteps: 671,815,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,240.78014
Policy Entropy: 1.08932
Value Function Loss: 6.05341

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.09257

Collected Steps per Second: 11,052.54419
Overall Steps per Second: 9,360.73794

Timestep Collection Time: 4.52656
Timestep Consumption Time: 0.81810
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.34466

Cumulative Model Updates: 40,276
Cumulative Timesteps: 671,865,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 671865360...
Checkpoint 671865360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,896.82307
Policy Entropy: 1.10185
Value Function Loss: 6.12434

Mean KL Divergence: 0.03479
SB3 Clip Fraction: 0.16390
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.10585

Collected Steps per Second: 10,832.47902
Overall Steps per Second: 9,233.53416

Timestep Collection Time: 4.61815
Timestep Consumption Time: 0.79971
PPO Batch Consumption Time: 0.03296
Total Iteration Time: 5.41786

Cumulative Model Updates: 40,279
Cumulative Timesteps: 671,915,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,513.99830
Policy Entropy: 1.08162
Value Function Loss: 5.87574

Mean KL Divergence: 0.05076
SB3 Clip Fraction: 0.19255
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.10728

Collected Steps per Second: 10,903.88665
Overall Steps per Second: 9,503.01673

Timestep Collection Time: 4.58827
Timestep Consumption Time: 0.67637
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.26464

Cumulative Model Updates: 40,282
Cumulative Timesteps: 671,965,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 671965416...
Checkpoint 671965416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,558.38184
Policy Entropy: 1.09830
Value Function Loss: 5.99458

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.10019

Collected Steps per Second: 10,845.59609
Overall Steps per Second: 9,226.23312

Timestep Collection Time: 4.61146
Timestep Consumption Time: 0.80939
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.42085

Cumulative Model Updates: 40,285
Cumulative Timesteps: 672,015,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399,307.54682
Policy Entropy: 1.09395
Value Function Loss: 6.19296

Mean KL Divergence: 0.02685
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.08766

Collected Steps per Second: 10,643.20305
Overall Steps per Second: 9,160.83032

Timestep Collection Time: 4.69934
Timestep Consumption Time: 0.76043
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.45977

Cumulative Model Updates: 40,288
Cumulative Timesteps: 672,065,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 672065446...
Checkpoint 672065446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,455.04513
Policy Entropy: 1.07773
Value Function Loss: 6.27943

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.07674

Collected Steps per Second: 11,518.07007
Overall Steps per Second: 9,515.91974

Timestep Collection Time: 4.34135
Timestep Consumption Time: 0.91342
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 5.25477

Cumulative Model Updates: 40,291
Cumulative Timesteps: 672,115,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,228.79256
Policy Entropy: 1.08290
Value Function Loss: 6.22004

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.07395

Collected Steps per Second: 11,595.60899
Overall Steps per Second: 9,670.63394

Timestep Collection Time: 4.31249
Timestep Consumption Time: 0.85842
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.17091

Cumulative Model Updates: 40,294
Cumulative Timesteps: 672,165,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 672165456...
Checkpoint 672165456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,312.51236
Policy Entropy: 1.08779
Value Function Loss: 6.13316

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.07511

Collected Steps per Second: 12,022.10042
Overall Steps per Second: 10,138.27130

Timestep Collection Time: 4.16117
Timestep Consumption Time: 0.77320
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 4.93437

Cumulative Model Updates: 40,297
Cumulative Timesteps: 672,215,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,273.38346
Policy Entropy: 1.09911
Value Function Loss: 6.31666

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.07849

Collected Steps per Second: 11,960.22623
Overall Steps per Second: 10,082.65699

Timestep Collection Time: 4.18270
Timestep Consumption Time: 0.77889
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 4.96159

Cumulative Model Updates: 40,300
Cumulative Timesteps: 672,265,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 672265508...
Checkpoint 672265508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,215.70936
Policy Entropy: 1.10244
Value Function Loss: 6.28851

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.06941
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 11,747.19624
Overall Steps per Second: 10,105.98839

Timestep Collection Time: 4.25702
Timestep Consumption Time: 0.69134
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 4.94835

Cumulative Model Updates: 40,303
Cumulative Timesteps: 672,315,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,642.83599
Policy Entropy: 1.10613
Value Function Loss: 6.37184

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.06870
Value Function Update Magnitude: 0.09543

Collected Steps per Second: 11,078.67266
Overall Steps per Second: 9,362.07998

Timestep Collection Time: 4.51426
Timestep Consumption Time: 0.82772
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 5.34198

Cumulative Model Updates: 40,306
Cumulative Timesteps: 672,365,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 672365528...
Checkpoint 672365528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,555.37614
Policy Entropy: 1.11120
Value Function Loss: 6.30292

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.06458
Value Function Update Magnitude: 0.08137

Collected Steps per Second: 11,218.51047
Overall Steps per Second: 9,700.82407

Timestep Collection Time: 4.45745
Timestep Consumption Time: 0.69737
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 5.15482

Cumulative Model Updates: 40,309
Cumulative Timesteps: 672,415,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,678.00974
Policy Entropy: 1.11439
Value Function Loss: 6.13481

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11720
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.07492

Collected Steps per Second: 11,177.78065
Overall Steps per Second: 9,516.65987

Timestep Collection Time: 4.47531
Timestep Consumption Time: 0.78116
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 5.25647

Cumulative Model Updates: 40,312
Cumulative Timesteps: 672,465,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 672465558...
Checkpoint 672465558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,666.90119
Policy Entropy: 1.12206
Value Function Loss: 6.16215

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.09052

Collected Steps per Second: 11,169.69432
Overall Steps per Second: 9,546.20323

Timestep Collection Time: 4.47819
Timestep Consumption Time: 0.76159
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.23978

Cumulative Model Updates: 40,315
Cumulative Timesteps: 672,515,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,337.19858
Policy Entropy: 1.12102
Value Function Loss: 6.33336

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 11,249.91565
Overall Steps per Second: 9,525.26651

Timestep Collection Time: 4.44590
Timestep Consumption Time: 0.80498
PPO Batch Consumption Time: 0.03949
Total Iteration Time: 5.25088

Cumulative Model Updates: 40,318
Cumulative Timesteps: 672,565,594

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 672565594...
Checkpoint 672565594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419,993.30635
Policy Entropy: 1.12320
Value Function Loss: 6.60396

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.08472

Collected Steps per Second: 10,669.80801
Overall Steps per Second: 9,116.83263

Timestep Collection Time: 4.68724
Timestep Consumption Time: 0.79843
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.48568

Cumulative Model Updates: 40,321
Cumulative Timesteps: 672,615,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,021.34823
Policy Entropy: 1.12919
Value Function Loss: 6.69254

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.08349

Collected Steps per Second: 11,090.45138
Overall Steps per Second: 9,578.40981

Timestep Collection Time: 4.51055
Timestep Consumption Time: 0.71203
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.22258

Cumulative Model Updates: 40,324
Cumulative Timesteps: 672,665,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 672665630...
Checkpoint 672665630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,768.26370
Policy Entropy: 1.12880
Value Function Loss: 6.61589

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.08992

Collected Steps per Second: 10,922.79781
Overall Steps per Second: 9,378.57448

Timestep Collection Time: 4.57996
Timestep Consumption Time: 0.75411
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.33407

Cumulative Model Updates: 40,327
Cumulative Timesteps: 672,715,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,999.57832
Policy Entropy: 1.13491
Value Function Loss: 6.48473

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.10316

Collected Steps per Second: 10,959.89641
Overall Steps per Second: 9,408.93727

Timestep Collection Time: 4.56227
Timestep Consumption Time: 0.75204
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 5.31431

Cumulative Model Updates: 40,330
Cumulative Timesteps: 672,765,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 672765658...
Checkpoint 672765658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,257.76957
Policy Entropy: 1.13391
Value Function Loss: 6.30859

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.10933

Collected Steps per Second: 11,030.43378
Overall Steps per Second: 9,540.49867

Timestep Collection Time: 4.53291
Timestep Consumption Time: 0.70790
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 5.24082

Cumulative Model Updates: 40,333
Cumulative Timesteps: 672,815,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,300.85933
Policy Entropy: 1.14761
Value Function Loss: 6.14452

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.10583

Collected Steps per Second: 11,017.01718
Overall Steps per Second: 9,447.35182

Timestep Collection Time: 4.54079
Timestep Consumption Time: 0.75445
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.29524

Cumulative Model Updates: 40,336
Cumulative Timesteps: 672,865,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 672865684...
Checkpoint 672865684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403,472.90748
Policy Entropy: 1.13311
Value Function Loss: 6.18005

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.08957

Collected Steps per Second: 10,762.57142
Overall Steps per Second: 9,262.88318

Timestep Collection Time: 4.64629
Timestep Consumption Time: 0.75225
PPO Batch Consumption Time: 0.03919
Total Iteration Time: 5.39854

Cumulative Model Updates: 40,339
Cumulative Timesteps: 672,915,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327,588.84845
Policy Entropy: 1.13471
Value Function Loss: 6.44581

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.09019

Collected Steps per Second: 10,944.53638
Overall Steps per Second: 9,349.09488

Timestep Collection Time: 4.56922
Timestep Consumption Time: 0.77975
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.34897

Cumulative Model Updates: 40,342
Cumulative Timesteps: 672,965,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 672965698...
Checkpoint 672965698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,232.21252
Policy Entropy: 1.14108
Value Function Loss: 6.47430

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.10274

Collected Steps per Second: 10,828.57597
Overall Steps per Second: 9,262.99609

Timestep Collection Time: 4.61797
Timestep Consumption Time: 0.78050
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.39847

Cumulative Model Updates: 40,345
Cumulative Timesteps: 673,015,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,689.24311
Policy Entropy: 1.13477
Value Function Loss: 6.44632

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.11667

Collected Steps per Second: 10,849.35264
Overall Steps per Second: 9,412.61581

Timestep Collection Time: 4.60986
Timestep Consumption Time: 0.70365
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.31351

Cumulative Model Updates: 40,348
Cumulative Timesteps: 673,065,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 673065718...
Checkpoint 673065718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,659.84053
Policy Entropy: 1.12685
Value Function Loss: 6.42352

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.10080

Collected Steps per Second: 10,906.36448
Overall Steps per Second: 9,343.68359

Timestep Collection Time: 4.58448
Timestep Consumption Time: 0.76673
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.35121

Cumulative Model Updates: 40,351
Cumulative Timesteps: 673,115,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,391.52690
Policy Entropy: 1.11966
Value Function Loss: 6.61221

Mean KL Divergence: 0.02759
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.08571

Collected Steps per Second: 10,876.26355
Overall Steps per Second: 9,258.92170

Timestep Collection Time: 4.60011
Timestep Consumption Time: 0.80354
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 5.40365

Cumulative Model Updates: 40,354
Cumulative Timesteps: 673,165,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 673165750...
Checkpoint 673165750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,961.38847
Policy Entropy: 1.14418
Value Function Loss: 6.52978

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.08842

Collected Steps per Second: 11,254.53905
Overall Steps per Second: 9,543.17971

Timestep Collection Time: 4.44372
Timestep Consumption Time: 0.79688
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.24060

Cumulative Model Updates: 40,357
Cumulative Timesteps: 673,215,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,780.07771
Policy Entropy: 1.14071
Value Function Loss: 6.46011

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.09684

Collected Steps per Second: 11,544.90815
Overall Steps per Second: 9,825.71851

Timestep Collection Time: 4.33317
Timestep Consumption Time: 0.75817
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.09133

Cumulative Model Updates: 40,360
Cumulative Timesteps: 673,265,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 673265788...
Checkpoint 673265788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,453.93788
Policy Entropy: 1.12322
Value Function Loss: 6.48693

Mean KL Divergence: 0.05174
SB3 Clip Fraction: 0.15121
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.09361

Collected Steps per Second: 11,134.62863
Overall Steps per Second: 9,668.56881

Timestep Collection Time: 4.49211
Timestep Consumption Time: 0.68115
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.17326

Cumulative Model Updates: 40,363
Cumulative Timesteps: 673,315,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,298.57019
Policy Entropy: 1.13872
Value Function Loss: 6.76321

Mean KL Divergence: 0.03719
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.08966

Collected Steps per Second: 11,102.88757
Overall Steps per Second: 9,476.32542

Timestep Collection Time: 4.50549
Timestep Consumption Time: 0.77334
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 5.27884

Cumulative Model Updates: 40,366
Cumulative Timesteps: 673,365,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 673365830...
Checkpoint 673365830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,001.03092
Policy Entropy: 1.11526
Value Function Loss: 6.61089

Mean KL Divergence: 0.04496
SB3 Clip Fraction: 0.16169
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.09042

Collected Steps per Second: 11,353.96343
Overall Steps per Second: 9,694.88972

Timestep Collection Time: 4.40498
Timestep Consumption Time: 0.75382
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.15880

Cumulative Model Updates: 40,369
Cumulative Timesteps: 673,415,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,852.64664
Policy Entropy: 1.12903
Value Function Loss: 6.32917

Mean KL Divergence: 0.04090
SB3 Clip Fraction: 0.15369
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.07841

Collected Steps per Second: 11,284.47284
Overall Steps per Second: 9,580.88759

Timestep Collection Time: 4.43317
Timestep Consumption Time: 0.78827
PPO Batch Consumption Time: 0.03803
Total Iteration Time: 5.22144

Cumulative Model Updates: 40,372
Cumulative Timesteps: 673,465,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 673465870...
Checkpoint 673465870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,468.79096
Policy Entropy: 1.12828
Value Function Loss: 6.10163

Mean KL Divergence: 0.03396
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.08706

Collected Steps per Second: 11,058.10630
Overall Steps per Second: 9,449.54172

Timestep Collection Time: 4.52374
Timestep Consumption Time: 0.77006
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.29380

Cumulative Model Updates: 40,375
Cumulative Timesteps: 673,515,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414,781.24351
Policy Entropy: 1.11777
Value Function Loss: 6.24673

Mean KL Divergence: 0.03070
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.09077

Collected Steps per Second: 11,124.20463
Overall Steps per Second: 9,670.19191

Timestep Collection Time: 4.49722
Timestep Consumption Time: 0.67620
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.17342

Cumulative Model Updates: 40,378
Cumulative Timesteps: 673,565,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 673565922...
Checkpoint 673565922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,261.92526
Policy Entropy: 1.11457
Value Function Loss: 6.12988

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.09648

Collected Steps per Second: 11,124.91650
Overall Steps per Second: 9,454.87527

Timestep Collection Time: 4.49639
Timestep Consumption Time: 0.79421
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.29060

Cumulative Model Updates: 40,381
Cumulative Timesteps: 673,615,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,814.38182
Policy Entropy: 1.12664
Value Function Loss: 6.00267

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.11254

Collected Steps per Second: 10,967.59982
Overall Steps per Second: 9,387.18012

Timestep Collection Time: 4.56052
Timestep Consumption Time: 0.76781
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.32833

Cumulative Model Updates: 40,384
Cumulative Timesteps: 673,665,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 673665962...
Checkpoint 673665962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,491.98286
Policy Entropy: 1.13127
Value Function Loss: 6.01334

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.12274

Collected Steps per Second: 11,360.77534
Overall Steps per Second: 9,623.23711

Timestep Collection Time: 4.40322
Timestep Consumption Time: 0.79503
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.19825

Cumulative Model Updates: 40,387
Cumulative Timesteps: 673,715,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,996.58442
Policy Entropy: 1.10312
Value Function Loss: 6.31335

Mean KL Divergence: 0.03334
SB3 Clip Fraction: 0.16035
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.11725

Collected Steps per Second: 10,624.32530
Overall Steps per Second: 9,200.14797

Timestep Collection Time: 4.70618
Timestep Consumption Time: 0.72851
PPO Batch Consumption Time: 0.03856
Total Iteration Time: 5.43470

Cumulative Model Updates: 40,390
Cumulative Timesteps: 673,765,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 673765986...
Checkpoint 673765986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,787.64803
Policy Entropy: 1.11814
Value Function Loss: 6.69088

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.12460

Collected Steps per Second: 10,867.74246
Overall Steps per Second: 9,436.00220

Timestep Collection Time: 4.60243
Timestep Consumption Time: 0.69833
PPO Batch Consumption Time: 0.03780
Total Iteration Time: 5.30076

Cumulative Model Updates: 40,393
Cumulative Timesteps: 673,816,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341,187.83097
Policy Entropy: 1.11743
Value Function Loss: 6.29375

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.11606

Collected Steps per Second: 10,749.77868
Overall Steps per Second: 9,228.29061

Timestep Collection Time: 4.65182
Timestep Consumption Time: 0.76696
PPO Batch Consumption Time: 0.03906
Total Iteration Time: 5.41877

Cumulative Model Updates: 40,396
Cumulative Timesteps: 673,866,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 673866010...
Checkpoint 673866010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,552.29069
Policy Entropy: 1.11798
Value Function Loss: 6.17999

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.11824

Collected Steps per Second: 11,028.85308
Overall Steps per Second: 9,404.02932

Timestep Collection Time: 4.53538
Timestep Consumption Time: 0.78362
PPO Batch Consumption Time: 0.03929
Total Iteration Time: 5.31900

Cumulative Model Updates: 40,399
Cumulative Timesteps: 673,916,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388,239.46571
Policy Entropy: 1.11227
Value Function Loss: 5.95305

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.10827

Collected Steps per Second: 11,418.08705
Overall Steps per Second: 9,721.22617

Timestep Collection Time: 4.38007
Timestep Consumption Time: 0.76455
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.14462

Cumulative Model Updates: 40,402
Cumulative Timesteps: 673,966,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 673966042...
Checkpoint 673966042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,973.72277
Policy Entropy: 1.12861
Value Function Loss: 6.07981

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.09676

Collected Steps per Second: 11,002.07062
Overall Steps per Second: 9,353.43191

Timestep Collection Time: 4.54551
Timestep Consumption Time: 0.80119
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.34670

Cumulative Model Updates: 40,405
Cumulative Timesteps: 674,016,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,641.70976
Policy Entropy: 1.12519
Value Function Loss: 6.13129

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.06364
Value Function Update Magnitude: 0.09193

Collected Steps per Second: 10,692.95304
Overall Steps per Second: 9,245.13412

Timestep Collection Time: 4.67803
Timestep Consumption Time: 0.73260
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 5.41063

Cumulative Model Updates: 40,408
Cumulative Timesteps: 674,066,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 674066074...
Checkpoint 674066074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,080.61402
Policy Entropy: 1.12596
Value Function Loss: 6.18228

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.06244
Value Function Update Magnitude: 0.08760

Collected Steps per Second: 10,859.53207
Overall Steps per Second: 9,280.91865

Timestep Collection Time: 4.60517
Timestep Consumption Time: 0.78330
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.38848

Cumulative Model Updates: 40,411
Cumulative Timesteps: 674,116,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371,604.22885
Policy Entropy: 1.11775
Value Function Loss: 6.21285

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.06453
Value Function Update Magnitude: 0.08814

Collected Steps per Second: 10,805.97793
Overall Steps per Second: 9,423.67063

Timestep Collection Time: 4.62910
Timestep Consumption Time: 0.67902
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 5.30812

Cumulative Model Updates: 40,414
Cumulative Timesteps: 674,166,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 674166106...
Checkpoint 674166106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432,196.23665
Policy Entropy: 1.11702
Value Function Loss: 6.17137

Mean KL Divergence: 0.02556
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.10803

Collected Steps per Second: 10,718.13727
Overall Steps per Second: 9,113.68369

Timestep Collection Time: 4.66648
Timestep Consumption Time: 0.82153
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.48801

Cumulative Model Updates: 40,417
Cumulative Timesteps: 674,216,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,099.46407
Policy Entropy: 1.13576
Value Function Loss: 6.21206

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.10462

Collected Steps per Second: 10,979.99627
Overall Steps per Second: 9,504.27901

Timestep Collection Time: 4.55592
Timestep Consumption Time: 0.70739
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 5.26331

Cumulative Model Updates: 40,420
Cumulative Timesteps: 674,266,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 674266146...
Checkpoint 674266146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,165.52888
Policy Entropy: 1.13349
Value Function Loss: 6.20486

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.09055

Collected Steps per Second: 10,523.16295
Overall Steps per Second: 9,007.67073

Timestep Collection Time: 4.75161
Timestep Consumption Time: 0.79943
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.55105

Cumulative Model Updates: 40,423
Cumulative Timesteps: 674,316,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,817.10977
Policy Entropy: 1.12166
Value Function Loss: 6.09551

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.11608
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.08282

Collected Steps per Second: 11,872.14155
Overall Steps per Second: 10,061.53487

Timestep Collection Time: 4.21322
Timestep Consumption Time: 0.75818
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 4.97141

Cumulative Model Updates: 40,426
Cumulative Timesteps: 674,366,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 674366168...
Checkpoint 674366168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,927.48867
Policy Entropy: 1.11099
Value Function Loss: 6.27480

Mean KL Divergence: 0.03236
SB3 Clip Fraction: 0.15073
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.07581

Collected Steps per Second: 11,909.75608
Overall Steps per Second: 10,232.77989

Timestep Collection Time: 4.19941
Timestep Consumption Time: 0.68821
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 4.88763

Cumulative Model Updates: 40,429
Cumulative Timesteps: 674,416,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,215.52134
Policy Entropy: 1.11851
Value Function Loss: 6.35973

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.07078

Collected Steps per Second: 12,034.36161
Overall Steps per Second: 10,106.54968

Timestep Collection Time: 4.15510
Timestep Consumption Time: 0.79258
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.94768

Cumulative Model Updates: 40,432
Cumulative Timesteps: 674,466,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 674466186...
Checkpoint 674466186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418,683.35386
Policy Entropy: 1.12513
Value Function Loss: 6.55088

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.07518

Collected Steps per Second: 11,962.19602
Overall Steps per Second: 10,148.29724

Timestep Collection Time: 4.18067
Timestep Consumption Time: 0.74725
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 4.92792

Cumulative Model Updates: 40,435
Cumulative Timesteps: 674,516,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,801.25200
Policy Entropy: 1.09112
Value Function Loss: 6.26427

Mean KL Divergence: 0.05905
SB3 Clip Fraction: 0.20631
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.07933

Collected Steps per Second: 12,083.21738
Overall Steps per Second: 10,130.37423

Timestep Collection Time: 4.13847
Timestep Consumption Time: 0.79778
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.93624

Cumulative Model Updates: 40,438
Cumulative Timesteps: 674,566,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 674566202...
Checkpoint 674566202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,062.48761
Policy Entropy: 1.10113
Value Function Loss: 6.25155

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.14877
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.07958

Collected Steps per Second: 11,079.00937
Overall Steps per Second: 9,440.46791

Timestep Collection Time: 4.51322
Timestep Consumption Time: 0.78334
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.29656

Cumulative Model Updates: 40,441
Cumulative Timesteps: 674,616,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,052.47590
Policy Entropy: 1.09297
Value Function Loss: 6.24875

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.07854

Collected Steps per Second: 11,167.59282
Overall Steps per Second: 9,645.04796

Timestep Collection Time: 4.47724
Timestep Consumption Time: 0.70677
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.18401

Cumulative Model Updates: 40,444
Cumulative Timesteps: 674,666,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 674666204...
Checkpoint 674666204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,862.01542
Policy Entropy: 1.06548
Value Function Loss: 6.12670

Mean KL Divergence: 0.03801
SB3 Clip Fraction: 0.18931
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.08506

Collected Steps per Second: 11,020.45111
Overall Steps per Second: 9,389.31135

Timestep Collection Time: 4.53756
Timestep Consumption Time: 0.78828
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.32584

Cumulative Model Updates: 40,447
Cumulative Timesteps: 674,716,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,811.95567
Policy Entropy: 1.08794
Value Function Loss: 6.59934

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.07990

Collected Steps per Second: 11,076.70910
Overall Steps per Second: 9,493.32730

Timestep Collection Time: 4.51524
Timestep Consumption Time: 0.75309
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.26833

Cumulative Model Updates: 40,450
Cumulative Timesteps: 674,766,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 674766224...
Checkpoint 674766224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447,855.80738
Policy Entropy: 1.08381
Value Function Loss: 6.37167

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.07624

Collected Steps per Second: 10,856.38091
Overall Steps per Second: 9,405.24813

Timestep Collection Time: 4.60577
Timestep Consumption Time: 0.71062
PPO Batch Consumption Time: 0.04087
Total Iteration Time: 5.31639

Cumulative Model Updates: 40,453
Cumulative Timesteps: 674,816,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,696.41988
Policy Entropy: 1.07595
Value Function Loss: 6.55230

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.15165
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.07471

Collected Steps per Second: 11,291.40858
Overall Steps per Second: 9,580.72858

Timestep Collection Time: 4.42956
Timestep Consumption Time: 0.79092
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.22048

Cumulative Model Updates: 40,456
Cumulative Timesteps: 674,866,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 674866242...
Checkpoint 674866242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,695.09899
Policy Entropy: 1.07129
Value Function Loss: 5.77417

Mean KL Divergence: 0.02870
SB3 Clip Fraction: 0.16935
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.07827

Collected Steps per Second: 10,434.45075
Overall Steps per Second: 9,063.42122

Timestep Collection Time: 4.79297
Timestep Consumption Time: 0.72504
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 5.51800

Cumulative Model Updates: 40,459
Cumulative Timesteps: 674,916,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,735.65188
Policy Entropy: 1.08409
Value Function Loss: 6.08851

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.08096

Collected Steps per Second: 11,235.32893
Overall Steps per Second: 9,583.98597

Timestep Collection Time: 4.45043
Timestep Consumption Time: 0.76682
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.21724

Cumulative Model Updates: 40,462
Cumulative Timesteps: 674,966,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 674966256...
Checkpoint 674966256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,501.53901
Policy Entropy: 1.09724
Value Function Loss: 6.10475

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.08148

Collected Steps per Second: 10,852.11500
Overall Steps per Second: 9,245.17741

Timestep Collection Time: 4.60777
Timestep Consumption Time: 0.80089
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 5.40866

Cumulative Model Updates: 40,465
Cumulative Timesteps: 675,016,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,081.18700
Policy Entropy: 1.07595
Value Function Loss: 6.15732

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.07709

Collected Steps per Second: 11,010.05608
Overall Steps per Second: 9,594.01421

Timestep Collection Time: 4.54257
Timestep Consumption Time: 0.67047
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 5.21304

Cumulative Model Updates: 40,468
Cumulative Timesteps: 675,066,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 675066274...
Checkpoint 675066274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,147.04684
Policy Entropy: 1.09652
Value Function Loss: 5.75422

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.15589
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.08528

Collected Steps per Second: 10,971.86825
Overall Steps per Second: 9,419.94208

Timestep Collection Time: 4.55875
Timestep Consumption Time: 0.75105
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 5.30980

Cumulative Model Updates: 40,471
Cumulative Timesteps: 675,116,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,236.86477
Policy Entropy: 1.09653
Value Function Loss: 5.86701

Mean KL Divergence: 0.02636
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.08304

Collected Steps per Second: 10,601.45114
Overall Steps per Second: 9,039.48284

Timestep Collection Time: 4.71822
Timestep Consumption Time: 0.81528
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.53350

Cumulative Model Updates: 40,474
Cumulative Timesteps: 675,166,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 675166312...
Checkpoint 675166312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,168.00200
Policy Entropy: 1.08653
Value Function Loss: 6.12752

Mean KL Divergence: 0.02521
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.07956

Collected Steps per Second: 10,896.01010
Overall Steps per Second: 9,439.58771

Timestep Collection Time: 4.58957
Timestep Consumption Time: 0.70812
PPO Batch Consumption Time: 0.04565
Total Iteration Time: 5.29769

Cumulative Model Updates: 40,477
Cumulative Timesteps: 675,216,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,931.89421
Policy Entropy: 1.07712
Value Function Loss: 6.17656

Mean KL Divergence: 0.03089
SB3 Clip Fraction: 0.15843
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.07309

Collected Steps per Second: 10,877.85494
Overall Steps per Second: 9,311.85922

Timestep Collection Time: 4.59907
Timestep Consumption Time: 0.77344
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.37250

Cumulative Model Updates: 40,480
Cumulative Timesteps: 675,266,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 675266348...
Checkpoint 675266348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,549.56315
Policy Entropy: 1.08471
Value Function Loss: 6.18087

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.07457

Collected Steps per Second: 10,868.83092
Overall Steps per Second: 9,291.23282

Timestep Collection Time: 4.60068
Timestep Consumption Time: 0.78117
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.38185

Cumulative Model Updates: 40,483
Cumulative Timesteps: 675,316,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,498.14282
Policy Entropy: 1.09584
Value Function Loss: 6.58105

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.07300

Collected Steps per Second: 10,912.02747
Overall Steps per Second: 9,308.67661

Timestep Collection Time: 4.58210
Timestep Consumption Time: 0.78923
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 5.37133

Cumulative Model Updates: 40,486
Cumulative Timesteps: 675,366,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 675366352...
Checkpoint 675366352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,406.77609
Policy Entropy: 1.06701
Value Function Loss: 6.70904

Mean KL Divergence: 0.02479
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.07917

Collected Steps per Second: 11,009.95958
Overall Steps per Second: 9,362.68405

Timestep Collection Time: 4.54189
Timestep Consumption Time: 0.79910
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.34099

Cumulative Model Updates: 40,489
Cumulative Timesteps: 675,416,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,415.67313
Policy Entropy: 1.05817
Value Function Loss: 6.50349

Mean KL Divergence: 0.03743
SB3 Clip Fraction: 0.16231
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.07740

Collected Steps per Second: 10,230.19849
Overall Steps per Second: 8,866.17353

Timestep Collection Time: 4.88827
Timestep Consumption Time: 0.75204
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.64031

Cumulative Model Updates: 40,492
Cumulative Timesteps: 675,466,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 675466366...
Checkpoint 675466366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,927.42779
Policy Entropy: 1.06827
Value Function Loss: 5.77012

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.09249

Collected Steps per Second: 11,381.48321
Overall Steps per Second: 9,675.59709

Timestep Collection Time: 4.39503
Timestep Consumption Time: 0.77488
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.16991

Cumulative Model Updates: 40,495
Cumulative Timesteps: 675,516,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,132.35011
Policy Entropy: 1.07942
Value Function Loss: 5.99705

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.09295

Collected Steps per Second: 11,632.04352
Overall Steps per Second: 9,911.90124

Timestep Collection Time: 4.30002
Timestep Consumption Time: 0.74624
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.04626

Cumulative Model Updates: 40,498
Cumulative Timesteps: 675,566,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 675566406...
Checkpoint 675566406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,730.18514
Policy Entropy: 1.06703
Value Function Loss: 6.14155

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.09068

Collected Steps per Second: 11,683.80414
Overall Steps per Second: 9,939.19919

Timestep Collection Time: 4.28182
Timestep Consumption Time: 0.75158
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.03340

Cumulative Model Updates: 40,501
Cumulative Timesteps: 675,616,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,744.91282
Policy Entropy: 1.06147
Value Function Loss: 6.66060

Mean KL Divergence: 0.02753
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.08914

Collected Steps per Second: 11,269.80469
Overall Steps per Second: 9,580.00221

Timestep Collection Time: 4.43930
Timestep Consumption Time: 0.78304
PPO Batch Consumption Time: 0.03822
Total Iteration Time: 5.22234

Cumulative Model Updates: 40,504
Cumulative Timesteps: 675,666,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 675666464...
Checkpoint 675666464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427,231.40899
Policy Entropy: 1.07127
Value Function Loss: 6.19137

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.08435

Collected Steps per Second: 11,280.12077
Overall Steps per Second: 9,795.50153

Timestep Collection Time: 4.43524
Timestep Consumption Time: 0.67221
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 5.10745

Cumulative Model Updates: 40,507
Cumulative Timesteps: 675,716,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,544.05085
Policy Entropy: 1.06912
Value Function Loss: 6.05915

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.08053

Collected Steps per Second: 10,808.69661
Overall Steps per Second: 9,259.66558

Timestep Collection Time: 4.62868
Timestep Consumption Time: 0.77432
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.40300

Cumulative Model Updates: 40,510
Cumulative Timesteps: 675,766,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 675766524...
Checkpoint 675766524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,518.86047
Policy Entropy: 1.08556
Value Function Loss: 5.64095

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.07955

Collected Steps per Second: 10,998.97368
Overall Steps per Second: 9,430.08985

Timestep Collection Time: 4.54752
Timestep Consumption Time: 0.75657
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.30409

Cumulative Model Updates: 40,513
Cumulative Timesteps: 675,816,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,030.52076
Policy Entropy: 1.06390
Value Function Loss: 5.83109

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.11265
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.07870

Collected Steps per Second: 11,493.92985
Overall Steps per Second: 9,802.24970

Timestep Collection Time: 4.35186
Timestep Consumption Time: 0.75105
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.10291

Cumulative Model Updates: 40,516
Cumulative Timesteps: 675,866,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 675866562...
Checkpoint 675866562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,711.36793
Policy Entropy: 1.04979
Value Function Loss: 5.73370

Mean KL Divergence: 0.04104
SB3 Clip Fraction: 0.17899
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 10,969.15544
Overall Steps per Second: 9,346.33943

Timestep Collection Time: 4.55842
Timestep Consumption Time: 0.79148
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.34990

Cumulative Model Updates: 40,519
Cumulative Timesteps: 675,916,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,894.83858
Policy Entropy: 1.06460
Value Function Loss: 5.80523

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.04646
Value Function Update Magnitude: 0.07786

Collected Steps per Second: 10,980.54834
Overall Steps per Second: 9,560.43692

Timestep Collection Time: 4.55369
Timestep Consumption Time: 0.67641
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 5.23010

Cumulative Model Updates: 40,522
Cumulative Timesteps: 675,966,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 675966566...
Checkpoint 675966566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,456.76168
Policy Entropy: 1.07953
Value Function Loss: 5.88984

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.08415

Collected Steps per Second: 10,983.20359
Overall Steps per Second: 9,304.32125

Timestep Collection Time: 4.55368
Timestep Consumption Time: 0.82167
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.37535

Cumulative Model Updates: 40,525
Cumulative Timesteps: 676,016,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,859.28680
Policy Entropy: 1.05463
Value Function Loss: 6.07988

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.08416

Collected Steps per Second: 11,065.25203
Overall Steps per Second: 9,629.40478

Timestep Collection Time: 4.52100
Timestep Consumption Time: 0.67413
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.19513

Cumulative Model Updates: 40,528
Cumulative Timesteps: 676,066,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 676066606...
Checkpoint 676066606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,884.42343
Policy Entropy: 1.04232
Value Function Loss: 6.26043

Mean KL Divergence: 0.02846
SB3 Clip Fraction: 0.17107
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.10203

Collected Steps per Second: 10,928.43266
Overall Steps per Second: 9,341.67817

Timestep Collection Time: 4.57742
Timestep Consumption Time: 0.77751
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.35493

Cumulative Model Updates: 40,531
Cumulative Timesteps: 676,116,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,810.63276
Policy Entropy: 1.05996
Value Function Loss: 6.44692

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.09896

Collected Steps per Second: 10,838.56736
Overall Steps per Second: 9,295.26688

Timestep Collection Time: 4.61519
Timestep Consumption Time: 0.76626
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.38145

Cumulative Model Updates: 40,534
Cumulative Timesteps: 676,166,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 676166652...
Checkpoint 676166652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,711.14801
Policy Entropy: 1.06508
Value Function Loss: 6.07226

Mean KL Divergence: 0.02449
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.08965

Collected Steps per Second: 10,846.15865
Overall Steps per Second: 9,481.97639

Timestep Collection Time: 4.61232
Timestep Consumption Time: 0.66358
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 5.27590

Cumulative Model Updates: 40,537
Cumulative Timesteps: 676,216,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,145.05641
Policy Entropy: 1.04985
Value Function Loss: 6.15858

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.09433

Collected Steps per Second: 10,929.08283
Overall Steps per Second: 9,403.04961

Timestep Collection Time: 4.57623
Timestep Consumption Time: 0.74268
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.31891

Cumulative Model Updates: 40,540
Cumulative Timesteps: 676,266,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 676266692...
Checkpoint 676266692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624,021.22018
Policy Entropy: 1.05550
Value Function Loss: 5.94526

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.08349

Collected Steps per Second: 10,660.73363
Overall Steps per Second: 9,126.06882

Timestep Collection Time: 4.69255
Timestep Consumption Time: 0.78911
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.48166

Cumulative Model Updates: 40,543
Cumulative Timesteps: 676,316,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,361.46159
Policy Entropy: 1.06555
Value Function Loss: 6.36942

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.07291

Collected Steps per Second: 11,047.65877
Overall Steps per Second: 9,430.08174

Timestep Collection Time: 4.52693
Timestep Consumption Time: 0.77652
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.30345

Cumulative Model Updates: 40,546
Cumulative Timesteps: 676,366,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 676366730...
Checkpoint 676366730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,739.42961
Policy Entropy: 1.07403
Value Function Loss: 6.34513

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 10,983.04101
Overall Steps per Second: 9,273.39703

Timestep Collection Time: 4.55448
Timestep Consumption Time: 0.83966
PPO Batch Consumption Time: 0.04625
Total Iteration Time: 5.39414

Cumulative Model Updates: 40,549
Cumulative Timesteps: 676,416,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481,329.96771
Policy Entropy: 1.07869
Value Function Loss: 6.29361

Mean KL Divergence: 0.03078
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.06735
Value Function Update Magnitude: 0.06320

Collected Steps per Second: 10,842.27595
Overall Steps per Second: 9,406.42682

Timestep Collection Time: 4.61250
Timestep Consumption Time: 0.70408
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.31658

Cumulative Model Updates: 40,552
Cumulative Timesteps: 676,466,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 676466762...
Checkpoint 676466762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,751.33877
Policy Entropy: 1.06881
Value Function Loss: 5.98036

Mean KL Divergence: 0.03392
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.06761
Value Function Update Magnitude: 0.08020

Collected Steps per Second: 10,886.80533
Overall Steps per Second: 9,297.08643

Timestep Collection Time: 4.59400
Timestep Consumption Time: 0.78553
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.37953

Cumulative Model Updates: 40,555
Cumulative Timesteps: 676,516,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,264.89518
Policy Entropy: 1.08983
Value Function Loss: 5.82596

Mean KL Divergence: 0.03704
SB3 Clip Fraction: 0.15959
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.07831

Collected Steps per Second: 10,986.57883
Overall Steps per Second: 9,307.49533

Timestep Collection Time: 4.55301
Timestep Consumption Time: 0.82137
PPO Batch Consumption Time: 0.04452
Total Iteration Time: 5.37438

Cumulative Model Updates: 40,558
Cumulative Timesteps: 676,566,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 676566798...
Checkpoint 676566798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,756.34286
Policy Entropy: 1.08380
Value Function Loss: 5.88473

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.07035
Value Function Update Magnitude: 0.08269

Collected Steps per Second: 11,207.88687
Overall Steps per Second: 9,727.23166

Timestep Collection Time: 4.46293
Timestep Consumption Time: 0.67934
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.14226

Cumulative Model Updates: 40,561
Cumulative Timesteps: 676,616,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,455.62209
Policy Entropy: 1.07864
Value Function Loss: 5.94971

Mean KL Divergence: 0.02692
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.07174
Value Function Update Magnitude: 0.08089

Collected Steps per Second: 11,754.33938
Overall Steps per Second: 9,885.60268

Timestep Collection Time: 4.25409
Timestep Consumption Time: 0.80418
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 5.05827

Cumulative Model Updates: 40,564
Cumulative Timesteps: 676,666,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 676666822...
Checkpoint 676666822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,365.36102
Policy Entropy: 1.09139
Value Function Loss: 5.80616

Mean KL Divergence: 0.02539
SB3 Clip Fraction: 0.15762
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.07984

Collected Steps per Second: 11,752.09731
Overall Steps per Second: 9,900.33967

Timestep Collection Time: 4.25490
Timestep Consumption Time: 0.79584
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.05074

Cumulative Model Updates: 40,567
Cumulative Timesteps: 676,716,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,256.16338
Policy Entropy: 1.09516
Value Function Loss: 6.11260

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.14890
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 12,340.45989
Overall Steps per Second: 10,365.13118

Timestep Collection Time: 4.05252
Timestep Consumption Time: 0.77231
PPO Batch Consumption Time: 0.03732
Total Iteration Time: 4.82483

Cumulative Model Updates: 40,570
Cumulative Timesteps: 676,766,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 676766836...
Checkpoint 676766836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,838.05158
Policy Entropy: 1.07767
Value Function Loss: 5.91051

Mean KL Divergence: 0.02581
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.08337

Collected Steps per Second: 11,894.00357
Overall Steps per Second: 9,931.58171

Timestep Collection Time: 4.20615
Timestep Consumption Time: 0.83111
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 5.03726

Cumulative Model Updates: 40,573
Cumulative Timesteps: 676,816,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,989.90860
Policy Entropy: 1.07391
Value Function Loss: 6.03741

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 11,892.93581
Overall Steps per Second: 10,100.40396

Timestep Collection Time: 4.20619
Timestep Consumption Time: 0.74648
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 4.95267

Cumulative Model Updates: 40,576
Cumulative Timesteps: 676,866,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 676866888...
Checkpoint 676866888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,561.63075
Policy Entropy: 1.08970
Value Function Loss: 5.62784

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 11,137.36400
Overall Steps per Second: 9,468.85981

Timestep Collection Time: 4.49119
Timestep Consumption Time: 0.79139
PPO Batch Consumption Time: 0.03851
Total Iteration Time: 5.28258

Cumulative Model Updates: 40,579
Cumulative Timesteps: 676,916,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,375.78828
Policy Entropy: 1.09142
Value Function Loss: 5.79490

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.10039

Collected Steps per Second: 10,943.96177
Overall Steps per Second: 9,491.57538

Timestep Collection Time: 4.57129
Timestep Consumption Time: 0.69949
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.27078

Cumulative Model Updates: 40,582
Cumulative Timesteps: 676,966,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 676966936...
Checkpoint 676966936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,119.26493
Policy Entropy: 1.08039
Value Function Loss: 5.77821

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.09407

Collected Steps per Second: 11,230.33078
Overall Steps per Second: 9,499.01327

Timestep Collection Time: 4.45401
Timestep Consumption Time: 0.81180
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.26581

Cumulative Model Updates: 40,585
Cumulative Timesteps: 677,016,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,406.46231
Policy Entropy: 1.07635
Value Function Loss: 6.14666

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.08832

Collected Steps per Second: 10,849.13491
Overall Steps per Second: 9,297.57112

Timestep Collection Time: 4.61069
Timestep Consumption Time: 0.76942
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.38011

Cumulative Model Updates: 40,588
Cumulative Timesteps: 677,066,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 677066978...
Checkpoint 677066978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,082.08156
Policy Entropy: 1.09433
Value Function Loss: 6.41305

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.08300

Collected Steps per Second: 11,169.24098
Overall Steps per Second: 9,669.67274

Timestep Collection Time: 4.47819
Timestep Consumption Time: 0.69448
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 5.17267

Cumulative Model Updates: 40,591
Cumulative Timesteps: 677,116,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,271.09980
Policy Entropy: 1.09309
Value Function Loss: 6.62022

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.08127

Collected Steps per Second: 10,567.47506
Overall Steps per Second: 9,000.80258

Timestep Collection Time: 4.73301
Timestep Consumption Time: 0.82382
PPO Batch Consumption Time: 0.04400
Total Iteration Time: 5.55684

Cumulative Model Updates: 40,594
Cumulative Timesteps: 677,167,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 677167012...
Checkpoint 677167012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,105.00447
Policy Entropy: 1.09258
Value Function Loss: 6.26679

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.06834
Value Function Update Magnitude: 0.08166

Collected Steps per Second: 11,056.74918
Overall Steps per Second: 9,502.12108

Timestep Collection Time: 4.52249
Timestep Consumption Time: 0.73992
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.26240

Cumulative Model Updates: 40,597
Cumulative Timesteps: 677,217,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,960.70353
Policy Entropy: 1.08280
Value Function Loss: 6.17791

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.07090
Value Function Update Magnitude: 0.07801

Collected Steps per Second: 10,866.77749
Overall Steps per Second: 9,263.17494

Timestep Collection Time: 4.60247
Timestep Consumption Time: 0.79676
PPO Batch Consumption Time: 0.03910
Total Iteration Time: 5.39923

Cumulative Model Updates: 40,600
Cumulative Timesteps: 677,267,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 677267030...
Checkpoint 677267030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,773.88122
Policy Entropy: 1.08940
Value Function Loss: 5.80554

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.07607

Collected Steps per Second: 10,979.26580
Overall Steps per Second: 9,379.03542

Timestep Collection Time: 4.55440
Timestep Consumption Time: 0.77706
PPO Batch Consumption Time: 0.03864
Total Iteration Time: 5.33147

Cumulative Model Updates: 40,603
Cumulative Timesteps: 677,317,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,158.74706
Policy Entropy: 1.11082
Value Function Loss: 5.89637

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.08777

Collected Steps per Second: 10,780.24282
Overall Steps per Second: 9,414.46416

Timestep Collection Time: 4.63849
Timestep Consumption Time: 0.67292
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.31140

Cumulative Model Updates: 40,606
Cumulative Timesteps: 677,367,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 677367038...
Checkpoint 677367038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,236.82848
Policy Entropy: 1.11362
Value Function Loss: 5.77927

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.10115

Collected Steps per Second: 10,999.93443
Overall Steps per Second: 9,418.08475

Timestep Collection Time: 4.54603
Timestep Consumption Time: 0.76355
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.30957

Cumulative Model Updates: 40,609
Cumulative Timesteps: 677,417,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,523.82842
Policy Entropy: 1.09977
Value Function Loss: 5.81294

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.09632

Collected Steps per Second: 10,474.14419
Overall Steps per Second: 9,037.71164

Timestep Collection Time: 4.77366
Timestep Consumption Time: 0.75871
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.53237

Cumulative Model Updates: 40,612
Cumulative Timesteps: 677,467,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 677467044...
Checkpoint 677467044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422,286.14677
Policy Entropy: 1.08903
Value Function Loss: 5.93165

Mean KL Divergence: 0.03333
SB3 Clip Fraction: 0.16984
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.11009

Collected Steps per Second: 10,726.03828
Overall Steps per Second: 9,348.48690

Timestep Collection Time: 4.66342
Timestep Consumption Time: 0.68718
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.35060

Cumulative Model Updates: 40,615
Cumulative Timesteps: 677,517,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,298.07144
Policy Entropy: 1.09565
Value Function Loss: 5.89086

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.09715

Collected Steps per Second: 10,842.27261
Overall Steps per Second: 9,204.52562

Timestep Collection Time: 4.61361
Timestep Consumption Time: 0.82089
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.43450

Cumulative Model Updates: 40,618
Cumulative Timesteps: 677,567,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 677567086...
Checkpoint 677567086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,419.34752
Policy Entropy: 1.11261
Value Function Loss: 6.08427

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.08794

Collected Steps per Second: 10,841.98091
Overall Steps per Second: 9,319.63446

Timestep Collection Time: 4.61447
Timestep Consumption Time: 0.75377
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.36824

Cumulative Model Updates: 40,621
Cumulative Timesteps: 677,617,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451,483.79728
Policy Entropy: 1.07780
Value Function Loss: 5.98099

Mean KL Divergence: 0.04200
SB3 Clip Fraction: 0.18956
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.07547

Collected Steps per Second: 11,138.37357
Overall Steps per Second: 9,442.77884

Timestep Collection Time: 4.49132
Timestep Consumption Time: 0.80648
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 5.29780

Cumulative Model Updates: 40,624
Cumulative Timesteps: 677,667,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 677667142...
Checkpoint 677667142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,433.29586
Policy Entropy: 1.09984
Value Function Loss: 5.87436

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.07566

Collected Steps per Second: 10,360.55867
Overall Steps per Second: 8,859.44567

Timestep Collection Time: 4.82657
Timestep Consumption Time: 0.81780
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.64437

Cumulative Model Updates: 40,627
Cumulative Timesteps: 677,717,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,366.71130
Policy Entropy: 1.08995
Value Function Loss: 5.77947

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.08388

Collected Steps per Second: 11,453.17833
Overall Steps per Second: 9,905.56834

Timestep Collection Time: 4.36700
Timestep Consumption Time: 0.68228
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.04928

Cumulative Model Updates: 40,630
Cumulative Timesteps: 677,767,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 677767164...
Checkpoint 677767164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,800.14312
Policy Entropy: 1.09019
Value Function Loss: 6.34735

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.11543
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.07702

Collected Steps per Second: 11,634.37629
Overall Steps per Second: 9,864.51412

Timestep Collection Time: 4.29847
Timestep Consumption Time: 0.77122
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.06969

Cumulative Model Updates: 40,633
Cumulative Timesteps: 677,817,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,382.51583
Policy Entropy: 1.07435
Value Function Loss: 6.70038

Mean KL Divergence: 0.02909
SB3 Clip Fraction: 0.15326
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.07252

Collected Steps per Second: 11,395.24985
Overall Steps per Second: 9,668.34899

Timestep Collection Time: 4.38902
Timestep Consumption Time: 0.78394
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.17296

Cumulative Model Updates: 40,636
Cumulative Timesteps: 677,867,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 677867188...
Checkpoint 677867188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,762.35610
Policy Entropy: 1.09547
Value Function Loss: 6.67417

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 11,932.53118
Overall Steps per Second: 10,014.62393

Timestep Collection Time: 4.19207
Timestep Consumption Time: 0.80283
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.99490

Cumulative Model Updates: 40,639
Cumulative Timesteps: 677,917,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,947.97524
Policy Entropy: 1.09752
Value Function Loss: 6.19094

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.07116

Collected Steps per Second: 11,299.55555
Overall Steps per Second: 9,527.99569

Timestep Collection Time: 4.42513
Timestep Consumption Time: 0.82277
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.24790

Cumulative Model Updates: 40,642
Cumulative Timesteps: 677,967,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 677967212...
Checkpoint 677967212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380,994.24862
Policy Entropy: 1.08440
Value Function Loss: 5.92914

Mean KL Divergence: 0.02383
SB3 Clip Fraction: 0.14392
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.06771

Collected Steps per Second: 10,870.02756
Overall Steps per Second: 9,418.02049

Timestep Collection Time: 4.60091
Timestep Consumption Time: 0.70934
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.31025

Cumulative Model Updates: 40,645
Cumulative Timesteps: 678,017,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,104.82534
Policy Entropy: 1.07560
Value Function Loss: 5.92422

Mean KL Divergence: 0.03086
SB3 Clip Fraction: 0.16267
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.06963

Collected Steps per Second: 11,085.42741
Overall Steps per Second: 9,462.01129

Timestep Collection Time: 4.51151
Timestep Consumption Time: 0.77405
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 5.28556

Cumulative Model Updates: 40,648
Cumulative Timesteps: 678,067,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 678067236...
Checkpoint 678067236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,704.63234
Policy Entropy: 1.08742
Value Function Loss: 5.94556

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.06836

Collected Steps per Second: 11,179.85333
Overall Steps per Second: 9,538.67686

Timestep Collection Time: 4.47466
Timestep Consumption Time: 0.76989
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.24454

Cumulative Model Updates: 40,651
Cumulative Timesteps: 678,117,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,508.32123
Policy Entropy: 1.09751
Value Function Loss: 6.06129

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.06782

Collected Steps per Second: 11,428.86437
Overall Steps per Second: 9,611.08957

Timestep Collection Time: 4.37734
Timestep Consumption Time: 0.82790
PPO Batch Consumption Time: 0.03949
Total Iteration Time: 5.20524

Cumulative Model Updates: 40,654
Cumulative Timesteps: 678,167,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 678167290...
Checkpoint 678167290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280,019.26839
Policy Entropy: 1.09971
Value Function Loss: 5.83427

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.06626

Collected Steps per Second: 10,979.13203
Overall Steps per Second: 9,291.97198

Timestep Collection Time: 4.55592
Timestep Consumption Time: 0.82723
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.38314

Cumulative Model Updates: 40,657
Cumulative Timesteps: 678,217,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427,105.55925
Policy Entropy: 1.08633
Value Function Loss: 5.81514

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.06773

Collected Steps per Second: 10,967.52839
Overall Steps per Second: 9,487.52260

Timestep Collection Time: 4.56055
Timestep Consumption Time: 0.71142
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.27198

Cumulative Model Updates: 40,660
Cumulative Timesteps: 678,267,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 678267328...
Checkpoint 678267328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,840.65819
Policy Entropy: 1.10074
Value Function Loss: 5.45349

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.07383

Collected Steps per Second: 10,575.17607
Overall Steps per Second: 9,040.18838

Timestep Collection Time: 4.72919
Timestep Consumption Time: 0.80300
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.53219

Cumulative Model Updates: 40,663
Cumulative Timesteps: 678,317,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,394.82428
Policy Entropy: 1.09351
Value Function Loss: 5.51742

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.08048

Collected Steps per Second: 10,981.52894
Overall Steps per Second: 9,558.03511

Timestep Collection Time: 4.55346
Timestep Consumption Time: 0.67815
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.23162

Cumulative Model Updates: 40,666
Cumulative Timesteps: 678,367,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 678367344...
Checkpoint 678367344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,544.79610
Policy Entropy: 1.09271
Value Function Loss: 5.30721

Mean KL Divergence: 0.02690
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.08158

Collected Steps per Second: 10,992.03211
Overall Steps per Second: 9,390.93462

Timestep Collection Time: 4.54930
Timestep Consumption Time: 0.77563
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.32492

Cumulative Model Updates: 40,669
Cumulative Timesteps: 678,417,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,136.22812
Policy Entropy: 1.08919
Value Function Loss: 5.33515

Mean KL Divergence: 0.03051
SB3 Clip Fraction: 0.16392
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.08067

Collected Steps per Second: 10,951.81519
Overall Steps per Second: 9,396.05489

Timestep Collection Time: 4.56618
Timestep Consumption Time: 0.75605
PPO Batch Consumption Time: 0.03961
Total Iteration Time: 5.32223

Cumulative Model Updates: 40,672
Cumulative Timesteps: 678,467,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 678467358...
Checkpoint 678467358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,556.13553
Policy Entropy: 1.09749
Value Function Loss: 5.45261

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.07700

Collected Steps per Second: 10,967.70081
Overall Steps per Second: 9,555.55201

Timestep Collection Time: 4.56012
Timestep Consumption Time: 0.67391
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.23403

Cumulative Model Updates: 40,675
Cumulative Timesteps: 678,517,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,612.80846
Policy Entropy: 1.09576
Value Function Loss: 5.49373

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.07600

Collected Steps per Second: 10,518.77764
Overall Steps per Second: 9,029.90962

Timestep Collection Time: 4.75588
Timestep Consumption Time: 0.78416
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.54003

Cumulative Model Updates: 40,678
Cumulative Timesteps: 678,567,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 678567398...
Checkpoint 678567398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392,654.92004
Policy Entropy: 1.09588
Value Function Loss: 5.82905

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.07984

Collected Steps per Second: 10,605.54876
Overall Steps per Second: 9,093.54532

Timestep Collection Time: 4.71583
Timestep Consumption Time: 0.78411
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.49995

Cumulative Model Updates: 40,681
Cumulative Timesteps: 678,617,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,714.81755
Policy Entropy: 1.08828
Value Function Loss: 5.69291

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.07577

Collected Steps per Second: 10,899.96055
Overall Steps per Second: 9,357.51500

Timestep Collection Time: 4.58809
Timestep Consumption Time: 0.75628
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 5.34437

Cumulative Model Updates: 40,684
Cumulative Timesteps: 678,667,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 678667422...
Checkpoint 678667422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379,860.71136
Policy Entropy: 1.10276
Value Function Loss: 5.71783

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.07536

Collected Steps per Second: 10,865.13213
Overall Steps per Second: 9,351.12467

Timestep Collection Time: 4.60372
Timestep Consumption Time: 0.74537
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.34909

Cumulative Model Updates: 40,687
Cumulative Timesteps: 678,717,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,950.16623
Policy Entropy: 1.11305
Value Function Loss: 5.47280

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.05989
Value Function Update Magnitude: 0.09152

Collected Steps per Second: 10,787.38974
Overall Steps per Second: 9,370.26356

Timestep Collection Time: 4.63727
Timestep Consumption Time: 0.70132
PPO Batch Consumption Time: 0.03983
Total Iteration Time: 5.33859

Cumulative Model Updates: 40,690
Cumulative Timesteps: 678,767,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 678767466...
Checkpoint 678767466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378,815.75282
Policy Entropy: 1.10129
Value Function Loss: 5.37846

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.09861

Collected Steps per Second: 11,015.57034
Overall Steps per Second: 9,309.49364

Timestep Collection Time: 4.53957
Timestep Consumption Time: 0.83193
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 5.37151

Cumulative Model Updates: 40,693
Cumulative Timesteps: 678,817,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,716.20092
Policy Entropy: 1.09098
Value Function Loss: 5.49452

Mean KL Divergence: 0.02720
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.09433

Collected Steps per Second: 10,579.41342
Overall Steps per Second: 9,108.25093

Timestep Collection Time: 4.72881
Timestep Consumption Time: 0.76380
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.49260

Cumulative Model Updates: 40,696
Cumulative Timesteps: 678,867,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 678867500...
Checkpoint 678867500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,414.17841
Policy Entropy: 1.09347
Value Function Loss: 5.46745

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.08807

Collected Steps per Second: 12,157.25286
Overall Steps per Second: 10,270.87297

Timestep Collection Time: 4.11359
Timestep Consumption Time: 0.75552
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.86911

Cumulative Model Updates: 40,699
Cumulative Timesteps: 678,917,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404,586.42746
Policy Entropy: 1.10030
Value Function Loss: 5.59362

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.07608
Value Function Update Magnitude: 0.09371

Collected Steps per Second: 11,789.31700
Overall Steps per Second: 9,935.10836

Timestep Collection Time: 4.24265
Timestep Consumption Time: 0.79181
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.03447

Cumulative Model Updates: 40,702
Cumulative Timesteps: 678,967,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 678967528...
Checkpoint 678967528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,081.33257
Policy Entropy: 1.09671
Value Function Loss: 5.74757

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.07047
Value Function Update Magnitude: 0.08038

Collected Steps per Second: 11,490.25966
Overall Steps per Second: 9,886.19293

Timestep Collection Time: 4.35221
Timestep Consumption Time: 0.70616
PPO Batch Consumption Time: 0.03751
Total Iteration Time: 5.05837

Cumulative Model Updates: 40,705
Cumulative Timesteps: 679,017,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,476.79790
Policy Entropy: 1.11321
Value Function Loss: 5.86362

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.07150
Value Function Update Magnitude: 0.07498

Collected Steps per Second: 11,706.35663
Overall Steps per Second: 9,816.19285

Timestep Collection Time: 4.27323
Timestep Consumption Time: 0.82284
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 5.09607

Cumulative Model Updates: 40,708
Cumulative Timesteps: 679,067,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 679067560...
Checkpoint 679067560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,328.24462
Policy Entropy: 1.10588
Value Function Loss: 5.78002

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.08093
Value Function Update Magnitude: 0.06492

Collected Steps per Second: 11,695.53129
Overall Steps per Second: 9,925.05067

Timestep Collection Time: 4.27753
Timestep Consumption Time: 0.76305
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.04058

Cumulative Model Updates: 40,711
Cumulative Timesteps: 679,117,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,843.13798
Policy Entropy: 1.10591
Value Function Loss: 5.59566

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.08430
Value Function Update Magnitude: 0.05905

Collected Steps per Second: 11,185.03651
Overall Steps per Second: 9,503.87312

Timestep Collection Time: 4.47205
Timestep Consumption Time: 0.79107
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.26312

Cumulative Model Updates: 40,714
Cumulative Timesteps: 679,167,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 679167608...
Checkpoint 679167608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,876.10926
Policy Entropy: 1.10299
Value Function Loss: 5.61445

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.07826
Value Function Update Magnitude: 0.05545

Collected Steps per Second: 11,103.35753
Overall Steps per Second: 9,438.66723

Timestep Collection Time: 4.50530
Timestep Consumption Time: 0.79460
PPO Batch Consumption Time: 0.03825
Total Iteration Time: 5.29990

Cumulative Model Updates: 40,717
Cumulative Timesteps: 679,217,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,187.56042
Policy Entropy: 1.10275
Value Function Loss: 5.87625

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.06673
Value Function Update Magnitude: 0.04868

Collected Steps per Second: 10,942.83045
Overall Steps per Second: 9,515.85528

Timestep Collection Time: 4.57176
Timestep Consumption Time: 0.68557
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.25733

Cumulative Model Updates: 40,720
Cumulative Timesteps: 679,267,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 679267660...
Checkpoint 679267660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,041.81152
Policy Entropy: 1.11167
Value Function Loss: 5.98600

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.05004

Collected Steps per Second: 10,856.72420
Overall Steps per Second: 9,261.99997

Timestep Collection Time: 4.60599
Timestep Consumption Time: 0.79306
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.39905

Cumulative Model Updates: 40,723
Cumulative Timesteps: 679,317,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,404.34917
Policy Entropy: 1.11714
Value Function Loss: 6.22566

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.05876
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 11,215.26722
Overall Steps per Second: 9,575.45969

Timestep Collection Time: 4.46053
Timestep Consumption Time: 0.76387
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.22440

Cumulative Model Updates: 40,726
Cumulative Timesteps: 679,367,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 679367692...
Checkpoint 679367692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,938.84215
Policy Entropy: 1.10489
Value Function Loss: 6.01624

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.05123

Collected Steps per Second: 10,675.64770
Overall Steps per Second: 9,217.84418

Timestep Collection Time: 4.68543
Timestep Consumption Time: 0.74100
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 5.42643

Cumulative Model Updates: 40,729
Cumulative Timesteps: 679,417,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,991.86703
Policy Entropy: 1.09890
Value Function Loss: 6.00068

Mean KL Divergence: 0.02981
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.05427

Collected Steps per Second: 10,884.25414
Overall Steps per Second: 9,243.76745

Timestep Collection Time: 4.59508
Timestep Consumption Time: 0.81549
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.41056

Cumulative Model Updates: 40,732
Cumulative Timesteps: 679,467,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 679467726...
Checkpoint 679467726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,460.87992
Policy Entropy: 1.10891
Value Function Loss: 5.94072

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.05260

Collected Steps per Second: 10,728.29032
Overall Steps per Second: 9,226.24298

Timestep Collection Time: 4.66263
Timestep Consumption Time: 0.75908
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 5.42171

Cumulative Model Updates: 40,735
Cumulative Timesteps: 679,517,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,679.92356
Policy Entropy: 1.11892
Value Function Loss: 5.99769

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.05452

Collected Steps per Second: 11,089.96941
Overall Steps per Second: 9,463.81231

Timestep Collection Time: 4.50894
Timestep Consumption Time: 0.77477
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.28371

Cumulative Model Updates: 40,738
Cumulative Timesteps: 679,567,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 679567752...
Checkpoint 679567752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417,866.44120
Policy Entropy: 1.11681
Value Function Loss: 6.23739

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.06966
Value Function Update Magnitude: 0.04956

Collected Steps per Second: 10,897.33223
Overall Steps per Second: 9,160.85186

Timestep Collection Time: 4.58920
Timestep Consumption Time: 0.86990
PPO Batch Consumption Time: 0.03835
Total Iteration Time: 5.45910

Cumulative Model Updates: 40,741
Cumulative Timesteps: 679,617,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,586.07690
Policy Entropy: 1.10424
Value Function Loss: 5.94759

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.06973
Value Function Update Magnitude: 0.05264

Collected Steps per Second: 10,951.91988
Overall Steps per Second: 9,527.62712

Timestep Collection Time: 4.56778
Timestep Consumption Time: 0.68284
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.25063

Cumulative Model Updates: 40,744
Cumulative Timesteps: 679,667,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 679667788...
Checkpoint 679667788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,425.77139
Policy Entropy: 1.09900
Value Function Loss: 5.81026

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.06464
Value Function Update Magnitude: 0.06248

Collected Steps per Second: 10,535.61364
Overall Steps per Second: 9,039.40935

Timestep Collection Time: 4.74847
Timestep Consumption Time: 0.78597
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.53443

Cumulative Model Updates: 40,747
Cumulative Timesteps: 679,717,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,450.86516
Policy Entropy: 1.10869
Value Function Loss: 5.57633

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.06979

Collected Steps per Second: 10,879.19283
Overall Steps per Second: 9,283.97389

Timestep Collection Time: 4.59593
Timestep Consumption Time: 0.78970
PPO Batch Consumption Time: 0.03864
Total Iteration Time: 5.38562

Cumulative Model Updates: 40,750
Cumulative Timesteps: 679,767,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 679767816...
Checkpoint 679767816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414,832.87202
Policy Entropy: 1.11368
Value Function Loss: 5.59068

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.07638

Collected Steps per Second: 10,674.76528
Overall Steps per Second: 9,289.60091

Timestep Collection Time: 4.68544
Timestep Consumption Time: 0.69864
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 5.38408

Cumulative Model Updates: 40,753
Cumulative Timesteps: 679,817,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,505.98147
Policy Entropy: 1.09878
Value Function Loss: 6.01765

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.07314

Collected Steps per Second: 11,014.18531
Overall Steps per Second: 9,419.44292

Timestep Collection Time: 4.54069
Timestep Consumption Time: 0.76875
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.30944

Cumulative Model Updates: 40,756
Cumulative Timesteps: 679,867,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 679867844...
Checkpoint 679867844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,473.21145
Policy Entropy: 1.08485
Value Function Loss: 6.13064

Mean KL Divergence: 0.03102
SB3 Clip Fraction: 0.16300
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.08565

Collected Steps per Second: 10,763.31886
Overall Steps per Second: 9,241.33056

Timestep Collection Time: 4.64541
Timestep Consumption Time: 0.76507
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.41048

Cumulative Model Updates: 40,759
Cumulative Timesteps: 679,917,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,043.24732
Policy Entropy: 1.09031
Value Function Loss: 6.43442

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.08806

Collected Steps per Second: 11,008.69732
Overall Steps per Second: 9,269.10363

Timestep Collection Time: 4.54223
Timestep Consumption Time: 0.85247
PPO Batch Consumption Time: 0.03937
Total Iteration Time: 5.39470

Cumulative Model Updates: 40,762
Cumulative Timesteps: 679,967,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 679967848...
Checkpoint 679967848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558,651.82441
Policy Entropy: 1.10623
Value Function Loss: 6.31257

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.07718

Collected Steps per Second: 11,149.39406
Overall Steps per Second: 9,521.63910

Timestep Collection Time: 4.48598
Timestep Consumption Time: 0.76689
PPO Batch Consumption Time: 0.03814
Total Iteration Time: 5.25288

Cumulative Model Updates: 40,765
Cumulative Timesteps: 680,017,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,154.43069
Policy Entropy: 1.08747
Value Function Loss: 6.18790

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.07800

Collected Steps per Second: 11,358.10931
Overall Steps per Second: 9,816.55405

Timestep Collection Time: 4.40478
Timestep Consumption Time: 0.69171
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 5.09649

Cumulative Model Updates: 40,768
Cumulative Timesteps: 680,067,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 680067894...
Checkpoint 680067894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,426.64173
Policy Entropy: 1.09951
Value Function Loss: 5.96100

Mean KL Divergence: 0.02562
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.07953

Collected Steps per Second: 11,367.24597
Overall Steps per Second: 9,663.15562

Timestep Collection Time: 4.40019
Timestep Consumption Time: 0.77597
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.17616

Cumulative Model Updates: 40,771
Cumulative Timesteps: 680,117,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418,745.11049
Policy Entropy: 1.09210
Value Function Loss: 5.71532

Mean KL Divergence: 0.02632
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.07575

Collected Steps per Second: 11,255.95719
Overall Steps per Second: 9,643.43600

Timestep Collection Time: 4.44351
Timestep Consumption Time: 0.74302
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.18653

Cumulative Model Updates: 40,774
Cumulative Timesteps: 680,167,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 680167928...
Checkpoint 680167928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,687.10934
Policy Entropy: 1.08135
Value Function Loss: 5.86213

Mean KL Divergence: 0.02619
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.08483

Collected Steps per Second: 11,464.41454
Overall Steps per Second: 9,703.90878

Timestep Collection Time: 4.36394
Timestep Consumption Time: 0.79172
PPO Batch Consumption Time: 0.03974
Total Iteration Time: 5.15565

Cumulative Model Updates: 40,777
Cumulative Timesteps: 680,217,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,801.16801
Policy Entropy: 1.07655
Value Function Loss: 5.82818

Mean KL Divergence: 0.03208
SB3 Clip Fraction: 0.15455
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.08369

Collected Steps per Second: 10,838.38410
Overall Steps per Second: 9,298.85904

Timestep Collection Time: 4.61379
Timestep Consumption Time: 0.76386
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.37765

Cumulative Model Updates: 40,780
Cumulative Timesteps: 680,267,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 680267964...
Checkpoint 680267964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,447.87557
Policy Entropy: 1.09237
Value Function Loss: 5.56631

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.07564

Collected Steps per Second: 11,007.96057
Overall Steps per Second: 9,569.74488

Timestep Collection Time: 4.54398
Timestep Consumption Time: 0.68291
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.22689

Cumulative Model Updates: 40,783
Cumulative Timesteps: 680,317,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,317.92666
Policy Entropy: 1.09631
Value Function Loss: 5.55377

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.07672

Collected Steps per Second: 11,270.53991
Overall Steps per Second: 9,545.37486

Timestep Collection Time: 4.43865
Timestep Consumption Time: 0.80221
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.24086

Cumulative Model Updates: 40,786
Cumulative Timesteps: 680,368,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 680368010...
Checkpoint 680368010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,682.68070
Policy Entropy: 1.07967
Value Function Loss: 5.62938

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.07064

Collected Steps per Second: 10,920.78616
Overall Steps per Second: 9,482.23684

Timestep Collection Time: 4.58007
Timestep Consumption Time: 0.69484
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.27492

Cumulative Model Updates: 40,789
Cumulative Timesteps: 680,418,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445,582.86434
Policy Entropy: 1.08117
Value Function Loss: 5.96599

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.07085

Collected Steps per Second: 11,205.47642
Overall Steps per Second: 9,596.17749

Timestep Collection Time: 4.46317
Timestep Consumption Time: 0.74848
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 5.21166

Cumulative Model Updates: 40,792
Cumulative Timesteps: 680,468,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 680468040...
Checkpoint 680468040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435,541.73759
Policy Entropy: 1.10220
Value Function Loss: 5.75746

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.08996

Collected Steps per Second: 10,744.26079
Overall Steps per Second: 9,248.59639

Timestep Collection Time: 4.65495
Timestep Consumption Time: 0.75279
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.40774

Cumulative Model Updates: 40,795
Cumulative Timesteps: 680,518,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,161.00907
Policy Entropy: 1.09844
Value Function Loss: 5.68103

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.09487

Collected Steps per Second: 10,425.33521
Overall Steps per Second: 9,182.00845

Timestep Collection Time: 4.79812
Timestep Consumption Time: 0.64971
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.44783

Cumulative Model Updates: 40,798
Cumulative Timesteps: 680,568,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 680568076...
Checkpoint 680568076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,627.14308
Policy Entropy: 1.10124
Value Function Loss: 5.78626

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.08865

Collected Steps per Second: 10,888.21216
Overall Steps per Second: 9,327.99452

Timestep Collection Time: 4.59249
Timestep Consumption Time: 0.76815
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.36064

Cumulative Model Updates: 40,801
Cumulative Timesteps: 680,618,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,831.61126
Policy Entropy: 1.08194
Value Function Loss: 5.78294

Mean KL Divergence: 0.02894
SB3 Clip Fraction: 0.16706
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.09308

Collected Steps per Second: 10,163.91591
Overall Steps per Second: 8,814.81415

Timestep Collection Time: 4.92015
Timestep Consumption Time: 0.75303
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 5.67318

Cumulative Model Updates: 40,804
Cumulative Timesteps: 680,668,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 680668088...
Checkpoint 680668088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407,408.55236
Policy Entropy: 1.09519
Value Function Loss: 5.79788

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.09039

Collected Steps per Second: 10,869.51490
Overall Steps per Second: 9,343.46364

Timestep Collection Time: 4.60149
Timestep Consumption Time: 0.75155
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.35305

Cumulative Model Updates: 40,807
Cumulative Timesteps: 680,718,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,372.14643
Policy Entropy: 1.10102
Value Function Loss: 5.44086

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.11964
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.08345

Collected Steps per Second: 10,743.79587
Overall Steps per Second: 9,269.94048

Timestep Collection Time: 4.65571
Timestep Consumption Time: 0.74023
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.39594

Cumulative Model Updates: 40,810
Cumulative Timesteps: 680,768,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 680768124...
Checkpoint 680768124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,230.70025
Policy Entropy: 1.09231
Value Function Loss: 5.48192

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.08074

Collected Steps per Second: 10,885.89772
Overall Steps per Second: 9,445.43126

Timestep Collection Time: 4.59420
Timestep Consumption Time: 0.70063
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.29484

Cumulative Model Updates: 40,813
Cumulative Timesteps: 680,818,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,949.98917
Policy Entropy: 1.07875
Value Function Loss: 5.52623

Mean KL Divergence: 0.03341
SB3 Clip Fraction: 0.15905
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 10,765.77640
Overall Steps per Second: 9,169.18150

Timestep Collection Time: 4.64490
Timestep Consumption Time: 0.80880
PPO Batch Consumption Time: 0.03771
Total Iteration Time: 5.45370

Cumulative Model Updates: 40,816
Cumulative Timesteps: 680,868,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 680868142...
Checkpoint 680868142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,865.93090
Policy Entropy: 1.09267
Value Function Loss: 5.60654

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.08844

Collected Steps per Second: 10,802.92195
Overall Steps per Second: 9,307.27443

Timestep Collection Time: 4.62986
Timestep Consumption Time: 0.74400
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.37386

Cumulative Model Updates: 40,819
Cumulative Timesteps: 680,918,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,711.70754
Policy Entropy: 1.09137
Value Function Loss: 5.58313

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.08634

Collected Steps per Second: 10,705.08562
Overall Steps per Second: 9,199.40846

Timestep Collection Time: 4.67161
Timestep Consumption Time: 0.76461
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.43622

Cumulative Model Updates: 40,822
Cumulative Timesteps: 680,968,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 680968168...
Checkpoint 680968168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,537.99571
Policy Entropy: 1.08095
Value Function Loss: 5.67397

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.08302

Collected Steps per Second: 10,783.08558
Overall Steps per Second: 9,309.02320

Timestep Collection Time: 4.63763
Timestep Consumption Time: 0.73436
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.37199

Cumulative Model Updates: 40,825
Cumulative Timesteps: 681,018,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,260.10561
Policy Entropy: 1.08968
Value Function Loss: 5.80186

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 10,782.26613
Overall Steps per Second: 9,301.12016

Timestep Collection Time: 4.63724
Timestep Consumption Time: 0.73845
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 5.37570

Cumulative Model Updates: 40,828
Cumulative Timesteps: 681,068,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 681068176...
Checkpoint 681068176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,467.79984
Policy Entropy: 1.09726
Value Function Loss: 5.74688

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 10,523.40170
Overall Steps per Second: 8,805.51441

Timestep Collection Time: 4.75151
Timestep Consumption Time: 0.92698
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.67849

Cumulative Model Updates: 40,831
Cumulative Timesteps: 681,118,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,076.70012
Policy Entropy: 1.10181
Value Function Loss: 5.62896

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.08439

Collected Steps per Second: 11,975.87873
Overall Steps per Second: 10,101.49967

Timestep Collection Time: 4.17673
Timestep Consumption Time: 0.77501
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 4.95174

Cumulative Model Updates: 40,834
Cumulative Timesteps: 681,168,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 681168198...
Checkpoint 681168198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,224.90402
Policy Entropy: 1.09157
Value Function Loss: 5.49771

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.08046

Collected Steps per Second: 12,248.76641
Overall Steps per Second: 10,322.30885

Timestep Collection Time: 4.08400
Timestep Consumption Time: 0.76220
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.84620

Cumulative Model Updates: 40,837
Cumulative Timesteps: 681,218,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,685.05975
Policy Entropy: 1.09281
Value Function Loss: 5.90990

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.06648
Value Function Update Magnitude: 0.09424

Collected Steps per Second: 12,004.25940
Overall Steps per Second: 10,199.80550

Timestep Collection Time: 4.16669
Timestep Consumption Time: 0.73713
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.90382

Cumulative Model Updates: 40,840
Cumulative Timesteps: 681,268,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 681268240...
Checkpoint 681268240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,658.15333
Policy Entropy: 1.07967
Value Function Loss: 5.95532

Mean KL Divergence: 0.02630
SB3 Clip Fraction: 0.17300
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.10393

Collected Steps per Second: 11,850.68984
Overall Steps per Second: 10,180.36710

Timestep Collection Time: 4.22051
Timestep Consumption Time: 0.69247
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 4.91299

Cumulative Model Updates: 40,843
Cumulative Timesteps: 681,318,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,446.08884
Policy Entropy: 1.09427
Value Function Loss: 6.25105

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.11101

Collected Steps per Second: 12,035.42900
Overall Steps per Second: 10,110.17201

Timestep Collection Time: 4.15540
Timestep Consumption Time: 0.79130
PPO Batch Consumption Time: 0.03911
Total Iteration Time: 4.94670

Cumulative Model Updates: 40,846
Cumulative Timesteps: 681,368,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 681368268...
Checkpoint 681368268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,071.47331
Policy Entropy: 1.09693
Value Function Loss: 5.84493

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.11816

Collected Steps per Second: 11,227.95008
Overall Steps per Second: 9,621.53494

Timestep Collection Time: 4.45495
Timestep Consumption Time: 0.74380
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 5.19875

Cumulative Model Updates: 40,849
Cumulative Timesteps: 681,418,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,580.89599
Policy Entropy: 1.07720
Value Function Loss: 5.56837

Mean KL Divergence: 0.02730
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.10481

Collected Steps per Second: 11,339.29813
Overall Steps per Second: 9,612.68813

Timestep Collection Time: 4.41015
Timestep Consumption Time: 0.79214
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.20229

Cumulative Model Updates: 40,852
Cumulative Timesteps: 681,468,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 681468296...
Checkpoint 681468296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,947.76051
Policy Entropy: 1.09473
Value Function Loss: 5.48237

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.15655
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.08749

Collected Steps per Second: 10,807.92398
Overall Steps per Second: 9,265.51551

Timestep Collection Time: 4.62753
Timestep Consumption Time: 0.77033
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.39786

Cumulative Model Updates: 40,855
Cumulative Timesteps: 681,518,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,567.11435
Policy Entropy: 1.09644
Value Function Loss: 5.74101

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.07464

Collected Steps per Second: 11,103.53593
Overall Steps per Second: 9,607.19087

Timestep Collection Time: 4.50433
Timestep Consumption Time: 0.70156
PPO Batch Consumption Time: 0.04114
Total Iteration Time: 5.20589

Cumulative Model Updates: 40,858
Cumulative Timesteps: 681,568,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 681568324...
Checkpoint 681568324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,332.69292
Policy Entropy: 1.08240
Value Function Loss: 5.84313

Mean KL Divergence: 0.03176
SB3 Clip Fraction: 0.14238
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.07383

Collected Steps per Second: 11,163.63234
Overall Steps per Second: 9,528.16713

Timestep Collection Time: 4.48026
Timestep Consumption Time: 0.76902
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.24928

Cumulative Model Updates: 40,861
Cumulative Timesteps: 681,618,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,759.07949
Policy Entropy: 1.08692
Value Function Loss: 5.88048

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 11,134.00004
Overall Steps per Second: 9,510.04468

Timestep Collection Time: 4.49290
Timestep Consumption Time: 0.76722
PPO Batch Consumption Time: 0.04163
Total Iteration Time: 5.26012

Cumulative Model Updates: 40,864
Cumulative Timesteps: 681,668,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 681668364...
Checkpoint 681668364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,628.32588
Policy Entropy: 1.08970
Value Function Loss: 5.62338

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.07315

Collected Steps per Second: 10,823.49243
Overall Steps per Second: 9,299.52012

Timestep Collection Time: 4.62180
Timestep Consumption Time: 0.75740
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.37920

Cumulative Model Updates: 40,867
Cumulative Timesteps: 681,718,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,110.79991
Policy Entropy: 1.09713
Value Function Loss: 5.53854

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.07625

Collected Steps per Second: 11,023.50130
Overall Steps per Second: 9,307.62422

Timestep Collection Time: 4.53595
Timestep Consumption Time: 0.83621
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 5.37215

Cumulative Model Updates: 40,870
Cumulative Timesteps: 681,768,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 681768390...
Checkpoint 681768390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,133.54767
Policy Entropy: 1.08165
Value Function Loss: 5.52455

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.07313

Collected Steps per Second: 10,618.05376
Overall Steps per Second: 9,281.24422

Timestep Collection Time: 4.71122
Timestep Consumption Time: 0.67857
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.38979

Cumulative Model Updates: 40,873
Cumulative Timesteps: 681,818,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370,118.47875
Policy Entropy: 1.07067
Value Function Loss: 5.75525

Mean KL Divergence: 0.02909
SB3 Clip Fraction: 0.16577
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 10,646.57897
Overall Steps per Second: 9,171.40994

Timestep Collection Time: 4.69860
Timestep Consumption Time: 0.75574
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 5.45434

Cumulative Model Updates: 40,876
Cumulative Timesteps: 681,868,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 681868438...
Checkpoint 681868438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,836.70472
Policy Entropy: 1.08442
Value Function Loss: 5.90237

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.08165

Collected Steps per Second: 11,074.47767
Overall Steps per Second: 9,546.49382

Timestep Collection Time: 4.51579
Timestep Consumption Time: 0.72278
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.23857

Cumulative Model Updates: 40,879
Cumulative Timesteps: 681,918,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,756.96331
Policy Entropy: 1.08923
Value Function Loss: 5.50553

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.04326
Value Function Update Magnitude: 0.09781

Collected Steps per Second: 10,717.33400
Overall Steps per Second: 9,193.01562

Timestep Collection Time: 4.66609
Timestep Consumption Time: 0.77370
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 5.43978

Cumulative Model Updates: 40,882
Cumulative Timesteps: 681,968,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 681968456...
Checkpoint 681968456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,181.22746
Policy Entropy: 1.06161
Value Function Loss: 5.39108

Mean KL Divergence: 0.04580
SB3 Clip Fraction: 0.16093
Policy Update Magnitude: 0.06743
Value Function Update Magnitude: 0.08703

Collected Steps per Second: 10,669.02867
Overall Steps per Second: 9,113.79025

Timestep Collection Time: 4.68665
Timestep Consumption Time: 0.79976
PPO Batch Consumption Time: 0.03763
Total Iteration Time: 5.48641

Cumulative Model Updates: 40,885
Cumulative Timesteps: 682,018,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,706.69096
Policy Entropy: 1.08108
Value Function Loss: 5.47474

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.15348
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.07603

Collected Steps per Second: 11,149.44754
Overall Steps per Second: 9,680.95435

Timestep Collection Time: 4.48578
Timestep Consumption Time: 0.68044
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.16623

Cumulative Model Updates: 40,888
Cumulative Timesteps: 682,068,472

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 682068472...
Checkpoint 682068472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,218.87474
Policy Entropy: 1.08254
Value Function Loss: 5.64973

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.07201

Collected Steps per Second: 10,909.58989
Overall Steps per Second: 9,208.77913

Timestep Collection Time: 4.58532
Timestep Consumption Time: 0.84688
PPO Batch Consumption Time: 0.04324
Total Iteration Time: 5.43221

Cumulative Model Updates: 40,891
Cumulative Timesteps: 682,118,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,538.59260
Policy Entropy: 1.07578
Value Function Loss: 5.92921

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.06932

Collected Steps per Second: 10,823.46308
Overall Steps per Second: 9,343.25332

Timestep Collection Time: 4.62107
Timestep Consumption Time: 0.73210
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 5.35317

Cumulative Model Updates: 40,894
Cumulative Timesteps: 682,168,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 682168512...
Checkpoint 682168512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,868.90559
Policy Entropy: 1.06814
Value Function Loss: 5.48769

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.05955
Value Function Update Magnitude: 0.08258

Collected Steps per Second: 10,927.40713
Overall Steps per Second: 9,236.15065

Timestep Collection Time: 4.57583
Timestep Consumption Time: 0.83789
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.41373

Cumulative Model Updates: 40,897
Cumulative Timesteps: 682,218,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,570.29632
Policy Entropy: 1.07933
Value Function Loss: 5.56166

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.08206

Collected Steps per Second: 10,393.80504
Overall Steps per Second: 8,969.34161

Timestep Collection Time: 4.81133
Timestep Consumption Time: 0.76411
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 5.57544

Cumulative Model Updates: 40,900
Cumulative Timesteps: 682,268,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 682268522...
Checkpoint 682268522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,688.55259
Policy Entropy: 1.07942
Value Function Loss: 5.13626

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.09245

Collected Steps per Second: 11,235.02186
Overall Steps per Second: 9,760.72183

Timestep Collection Time: 4.45251
Timestep Consumption Time: 0.67252
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 5.12503

Cumulative Model Updates: 40,903
Cumulative Timesteps: 682,318,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,113.14386
Policy Entropy: 1.06121
Value Function Loss: 5.45664

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.10097

Collected Steps per Second: 11,430.99579
Overall Steps per Second: 9,568.87007

Timestep Collection Time: 4.37652
Timestep Consumption Time: 0.85168
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.22820

Cumulative Model Updates: 40,906
Cumulative Timesteps: 682,368,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 682368574...
Checkpoint 682368574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,862.15702
Policy Entropy: 1.05292
Value Function Loss: 5.25838

Mean KL Divergence: 0.03036
SB3 Clip Fraction: 0.16535
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.10180

Collected Steps per Second: 11,334.44964
Overall Steps per Second: 9,610.67742

Timestep Collection Time: 4.41133
Timestep Consumption Time: 0.79122
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 5.20255

Cumulative Model Updates: 40,909
Cumulative Timesteps: 682,418,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,566.93111
Policy Entropy: 1.06296
Value Function Loss: 5.45434

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.10033

Collected Steps per Second: 11,586.26969
Overall Steps per Second: 9,676.74241

Timestep Collection Time: 4.31735
Timestep Consumption Time: 0.85195
PPO Batch Consumption Time: 0.03870
Total Iteration Time: 5.16930

Cumulative Model Updates: 40,912
Cumulative Timesteps: 682,468,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 682468596...
Checkpoint 682468596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,710.49754
Policy Entropy: 1.07960
Value Function Loss: 5.64539

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.10496

Collected Steps per Second: 11,184.45273
Overall Steps per Second: 9,329.65067

Timestep Collection Time: 4.47210
Timestep Consumption Time: 0.88909
PPO Batch Consumption Time: 0.03881
Total Iteration Time: 5.36119

Cumulative Model Updates: 40,915
Cumulative Timesteps: 682,518,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,887.86000
Policy Entropy: 1.05326
Value Function Loss: 5.90736

Mean KL Divergence: 0.03182
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.10953

Collected Steps per Second: 11,300.67221
Overall Steps per Second: 9,714.68027

Timestep Collection Time: 4.42505
Timestep Consumption Time: 0.72242
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 5.14747

Cumulative Model Updates: 40,918
Cumulative Timesteps: 682,568,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 682568620...
Checkpoint 682568620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,290.94761
Policy Entropy: 1.06595
Value Function Loss: 5.95719

Mean KL Divergence: 0.02457
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.09190

Collected Steps per Second: 11,246.86824
Overall Steps per Second: 9,505.71986

Timestep Collection Time: 4.44746
Timestep Consumption Time: 0.81463
PPO Batch Consumption Time: 0.03831
Total Iteration Time: 5.26209

Cumulative Model Updates: 40,921
Cumulative Timesteps: 682,618,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481,605.37323
Policy Entropy: 1.06574
Value Function Loss: 5.42332

Mean KL Divergence: 0.02766
SB3 Clip Fraction: 0.15685
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.10260

Collected Steps per Second: 10,819.75979
Overall Steps per Second: 9,269.23423

Timestep Collection Time: 4.62321
Timestep Consumption Time: 0.77335
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 5.39656

Cumulative Model Updates: 40,924
Cumulative Timesteps: 682,668,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 682668662...
Checkpoint 682668662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,973.30949
Policy Entropy: 1.05030
Value Function Loss: 5.26883

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.11580

Collected Steps per Second: 11,226.74098
Overall Steps per Second: 9,588.47157

Timestep Collection Time: 4.45508
Timestep Consumption Time: 0.76119
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 5.21626

Cumulative Model Updates: 40,927
Cumulative Timesteps: 682,718,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,243.03358
Policy Entropy: 1.04005
Value Function Loss: 5.21141

Mean KL Divergence: 0.02734
SB3 Clip Fraction: 0.16667
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 11,179.65401
Overall Steps per Second: 9,582.61221

Timestep Collection Time: 4.47348
Timestep Consumption Time: 0.74555
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.21904

Cumulative Model Updates: 40,930
Cumulative Timesteps: 682,768,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 682768690...
Checkpoint 682768690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,263.37748
Policy Entropy: 1.05076
Value Function Loss: 5.32550

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.09893

Collected Steps per Second: 10,457.65123
Overall Steps per Second: 9,107.38920

Timestep Collection Time: 4.78348
Timestep Consumption Time: 0.70920
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.49268

Cumulative Model Updates: 40,933
Cumulative Timesteps: 682,818,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,333.30571
Policy Entropy: 1.06527
Value Function Loss: 5.47363

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 10,860.89703
Overall Steps per Second: 9,337.11506

Timestep Collection Time: 4.60404
Timestep Consumption Time: 0.75136
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 5.35540

Cumulative Model Updates: 40,936
Cumulative Timesteps: 682,868,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 682868718...
Checkpoint 682868718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,151.80684
Policy Entropy: 1.03663
Value Function Loss: 5.41658

Mean KL Divergence: 0.03877
SB3 Clip Fraction: 0.16060
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.07570

Collected Steps per Second: 10,714.18167
Overall Steps per Second: 9,217.73449

Timestep Collection Time: 4.66839
Timestep Consumption Time: 0.75789
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.42628

Cumulative Model Updates: 40,939
Cumulative Timesteps: 682,918,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,058.86146
Policy Entropy: 1.05725
Value Function Loss: 5.83936

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 11,265.57692
Overall Steps per Second: 9,540.20875

Timestep Collection Time: 4.43936
Timestep Consumption Time: 0.80287
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 5.24223

Cumulative Model Updates: 40,942
Cumulative Timesteps: 682,968,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 682968748...
Checkpoint 682968748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,707.59637
Policy Entropy: 1.06104
Value Function Loss: 5.70980

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.07331

Collected Steps per Second: 11,030.79628
Overall Steps per Second: 9,451.54041

Timestep Collection Time: 4.53385
Timestep Consumption Time: 0.75756
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 5.29141

Cumulative Model Updates: 40,945
Cumulative Timesteps: 683,018,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,186.41904
Policy Entropy: 1.05482
Value Function Loss: 6.06649

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.07456

Collected Steps per Second: 11,052.18479
Overall Steps per Second: 9,554.16885

Timestep Collection Time: 4.52399
Timestep Consumption Time: 0.70933
PPO Batch Consumption Time: 0.03960
Total Iteration Time: 5.23332

Cumulative Model Updates: 40,948
Cumulative Timesteps: 683,068,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 683068760...
Checkpoint 683068760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,916.92000
Policy Entropy: 1.04464
Value Function Loss: 5.65263

Mean KL Divergence: 0.02642
SB3 Clip Fraction: 0.15331
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.07147

Collected Steps per Second: 10,566.43333
Overall Steps per Second: 9,040.55309

Timestep Collection Time: 4.73367
Timestep Consumption Time: 0.79896
PPO Batch Consumption Time: 0.04172
Total Iteration Time: 5.53263

Cumulative Model Updates: 40,951
Cumulative Timesteps: 683,118,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,256.73100
Policy Entropy: 1.05669
Value Function Loss: 5.50976

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.08092

Collected Steps per Second: 10,865.78541
Overall Steps per Second: 9,339.29511

Timestep Collection Time: 4.60197
Timestep Consumption Time: 0.75218
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.35415

Cumulative Model Updates: 40,954
Cumulative Timesteps: 683,168,782

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 683168782...
Checkpoint 683168782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,135.31143
Policy Entropy: 1.05163
Value Function Loss: 5.41398

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.07702

Collected Steps per Second: 10,796.72342
Overall Steps per Second: 9,349.15940

Timestep Collection Time: 4.63270
Timestep Consumption Time: 0.71730
PPO Batch Consumption Time: 0.03788
Total Iteration Time: 5.35000

Cumulative Model Updates: 40,957
Cumulative Timesteps: 683,218,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,013.67136
Policy Entropy: 1.05567
Value Function Loss: 5.61111

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.07819

Collected Steps per Second: 10,702.87620
Overall Steps per Second: 9,038.13435

Timestep Collection Time: 4.67351
Timestep Consumption Time: 0.86082
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.53433

Cumulative Model Updates: 40,960
Cumulative Timesteps: 683,268,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 683268820...
Checkpoint 683268820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,737.39565
Policy Entropy: 1.05922
Value Function Loss: 5.62603

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.06572
Value Function Update Magnitude: 0.10101

Collected Steps per Second: 10,791.14901
Overall Steps per Second: 9,285.65642

Timestep Collection Time: 4.63398
Timestep Consumption Time: 0.75131
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.38530

Cumulative Model Updates: 40,963
Cumulative Timesteps: 683,318,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,334.36259
Policy Entropy: 1.05605
Value Function Loss: 5.31108

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.07476
Value Function Update Magnitude: 0.11081

Collected Steps per Second: 10,522.47094
Overall Steps per Second: 9,028.09183

Timestep Collection Time: 4.75250
Timestep Consumption Time: 0.78666
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.53916

Cumulative Model Updates: 40,966
Cumulative Timesteps: 683,368,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 683368834...
Checkpoint 683368834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,933.02707
Policy Entropy: 1.04498
Value Function Loss: 5.22490

Mean KL Divergence: 0.02597
SB3 Clip Fraction: 0.15843
Policy Update Magnitude: 0.06589
Value Function Update Magnitude: 0.10606

Collected Steps per Second: 12,240.20104
Overall Steps per Second: 10,294.32202

Timestep Collection Time: 4.08604
Timestep Consumption Time: 0.77236
PPO Batch Consumption Time: 0.03852
Total Iteration Time: 4.85841

Cumulative Model Updates: 40,969
Cumulative Timesteps: 683,418,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,999.36290
Policy Entropy: 1.05859
Value Function Loss: 5.35147

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.10109

Collected Steps per Second: 11,942.51793
Overall Steps per Second: 10,232.08996

Timestep Collection Time: 4.18773
Timestep Consumption Time: 0.70003
PPO Batch Consumption Time: 0.04002
Total Iteration Time: 4.88776

Cumulative Model Updates: 40,972
Cumulative Timesteps: 683,468,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 683468860...
Checkpoint 683468860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,175.50071
Policy Entropy: 1.06597
Value Function Loss: 5.24744

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.15006
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.09386

Collected Steps per Second: 11,978.89702
Overall Steps per Second: 10,112.16700

Timestep Collection Time: 4.17484
Timestep Consumption Time: 0.77069
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.94553

Cumulative Model Updates: 40,975
Cumulative Timesteps: 683,518,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,003.02608
Policy Entropy: 1.05107
Value Function Loss: 5.21842

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.08554

Collected Steps per Second: 11,703.42559
Overall Steps per Second: 9,914.92702

Timestep Collection Time: 4.27260
Timestep Consumption Time: 0.77071
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.04330

Cumulative Model Updates: 40,978
Cumulative Timesteps: 683,568,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 683568874...
Checkpoint 683568874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453,628.19946
Policy Entropy: 1.04122
Value Function Loss: 5.06079

Mean KL Divergence: 0.02867
SB3 Clip Fraction: 0.16126
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.07923

Collected Steps per Second: 11,877.55018
Overall Steps per Second: 10,028.00873

Timestep Collection Time: 4.21063
Timestep Consumption Time: 0.77660
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.98723

Cumulative Model Updates: 40,981
Cumulative Timesteps: 683,618,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,069.50557
Policy Entropy: 1.04858
Value Function Loss: 5.42266

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.06912

Collected Steps per Second: 11,110.66790
Overall Steps per Second: 9,522.21769

Timestep Collection Time: 4.50252
Timestep Consumption Time: 0.75109
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.25361

Cumulative Model Updates: 40,984
Cumulative Timesteps: 683,668,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 683668912...
Checkpoint 683668912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,098.69908
Policy Entropy: 1.05837
Value Function Loss: 5.65487

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.07154

Collected Steps per Second: 10,919.83428
Overall Steps per Second: 9,473.36094

Timestep Collection Time: 4.58102
Timestep Consumption Time: 0.69947
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.28049

Cumulative Model Updates: 40,987
Cumulative Timesteps: 683,718,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,333.83875
Policy Entropy: 1.04889
Value Function Loss: 5.58535

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.06958

Collected Steps per Second: 11,121.95124
Overall Steps per Second: 9,408.65956

Timestep Collection Time: 4.49615
Timestep Consumption Time: 0.81874
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.31489

Cumulative Model Updates: 40,990
Cumulative Timesteps: 683,768,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 683768942...
Checkpoint 683768942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,579.46139
Policy Entropy: 1.04113
Value Function Loss: 5.56600

Mean KL Divergence: 0.04371
SB3 Clip Fraction: 0.19368
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.08093

Collected Steps per Second: 10,773.17623
Overall Steps per Second: 9,174.74354

Timestep Collection Time: 4.64320
Timestep Consumption Time: 0.80894
PPO Batch Consumption Time: 0.03945
Total Iteration Time: 5.45214

Cumulative Model Updates: 40,993
Cumulative Timesteps: 683,818,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,336.82770
Policy Entropy: 1.05816
Value Function Loss: 5.27074

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.08741

Collected Steps per Second: 11,113.55467
Overall Steps per Second: 9,419.23427

Timestep Collection Time: 4.50117
Timestep Consumption Time: 0.80966
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 5.31084

Cumulative Model Updates: 40,996
Cumulative Timesteps: 683,868,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 683868988...
Checkpoint 683868988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,956.60006
Policy Entropy: 1.05406
Value Function Loss: 5.63595

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.08151

Collected Steps per Second: 11,240.01676
Overall Steps per Second: 9,554.37439

Timestep Collection Time: 4.45017
Timestep Consumption Time: 0.78513
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.23530

Cumulative Model Updates: 40,999
Cumulative Timesteps: 683,919,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,288.75605
Policy Entropy: 1.04339
Value Function Loss: 5.56504

Mean KL Divergence: 0.02595
SB3 Clip Fraction: 0.15755
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.07238

Collected Steps per Second: 10,534.66854
Overall Steps per Second: 9,049.35914

Timestep Collection Time: 4.74927
Timestep Consumption Time: 0.77952
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.52879

Cumulative Model Updates: 41,002
Cumulative Timesteps: 683,969,040

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 683969040...
Checkpoint 683969040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,427.07401
Policy Entropy: 1.05717
Value Function Loss: 5.68459

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.08074

Collected Steps per Second: 10,849.86856
Overall Steps per Second: 9,289.99461

Timestep Collection Time: 4.61019
Timestep Consumption Time: 0.77409
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.38429

Cumulative Model Updates: 41,005
Cumulative Timesteps: 684,019,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,772.90144
Policy Entropy: 1.05988
Value Function Loss: 5.36956

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.07388

Collected Steps per Second: 11,081.26538
Overall Steps per Second: 9,639.58607

Timestep Collection Time: 4.51302
Timestep Consumption Time: 0.67496
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.18798

Cumulative Model Updates: 41,008
Cumulative Timesteps: 684,069,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 684069070...
Checkpoint 684069070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,310.46721
Policy Entropy: 1.04824
Value Function Loss: 5.43396

Mean KL Divergence: 0.03154
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.07161

Collected Steps per Second: 11,017.64402
Overall Steps per Second: 9,456.01934

Timestep Collection Time: 4.54017
Timestep Consumption Time: 0.74979
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 5.28996

Cumulative Model Updates: 41,011
Cumulative Timesteps: 684,119,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,060.26295
Policy Entropy: 1.05572
Value Function Loss: 5.49698

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.15863
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.08261

Collected Steps per Second: 10,947.94932
Overall Steps per Second: 9,400.65866

Timestep Collection Time: 4.56761
Timestep Consumption Time: 0.75180
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.31941

Cumulative Model Updates: 41,014
Cumulative Timesteps: 684,169,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 684169098...
Checkpoint 684169098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,992.29097
Policy Entropy: 1.06165
Value Function Loss: 5.84775

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.07305

Collected Steps per Second: 10,816.65765
Overall Steps per Second: 9,409.21939

Timestep Collection Time: 4.62250
Timestep Consumption Time: 0.69144
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.31394

Cumulative Model Updates: 41,017
Cumulative Timesteps: 684,219,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,669.23392
Policy Entropy: 1.06571
Value Function Loss: 5.94590

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.07327

Collected Steps per Second: 10,816.08040
Overall Steps per Second: 9,150.34476

Timestep Collection Time: 4.62460
Timestep Consumption Time: 0.84186
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.46646

Cumulative Model Updates: 41,020
Cumulative Timesteps: 684,269,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 684269118...
Checkpoint 684269118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,061.23881
Policy Entropy: 1.07407
Value Function Loss: 6.16849

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11128
Policy Update Magnitude: 0.06541
Value Function Update Magnitude: 0.07287

Collected Steps per Second: 10,632.61237
Overall Steps per Second: 9,172.25776

Timestep Collection Time: 4.70308
Timestep Consumption Time: 0.74880
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.45187

Cumulative Model Updates: 41,023
Cumulative Timesteps: 684,319,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,426.26271
Policy Entropy: 1.08229
Value Function Loss: 5.86729

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.06747
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 10,787.91616
Overall Steps per Second: 9,234.26294

Timestep Collection Time: 4.63741
Timestep Consumption Time: 0.78024
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.41765

Cumulative Model Updates: 41,026
Cumulative Timesteps: 684,369,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 684369152...
Checkpoint 684369152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,699.38841
Policy Entropy: 1.08203
Value Function Loss: 5.99458

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.07200

Collected Steps per Second: 10,788.55855
Overall Steps per Second: 9,292.86800

Timestep Collection Time: 4.63584
Timestep Consumption Time: 0.74614
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.38198

Cumulative Model Updates: 41,029
Cumulative Timesteps: 684,419,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,537.84336
Policy Entropy: 1.09281
Value Function Loss: 5.73675

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.07970

Collected Steps per Second: 10,842.67302
Overall Steps per Second: 9,447.76997

Timestep Collection Time: 4.61270
Timestep Consumption Time: 0.68104
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.29374

Cumulative Model Updates: 41,032
Cumulative Timesteps: 684,469,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 684469180...
Checkpoint 684469180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,095.51423
Policy Entropy: 1.09179
Value Function Loss: 5.95905

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.07891

Collected Steps per Second: 10,283.59778
Overall Steps per Second: 8,884.18890

Timestep Collection Time: 4.86328
Timestep Consumption Time: 0.76605
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.62933

Cumulative Model Updates: 41,035
Cumulative Timesteps: 684,519,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,462.86453
Policy Entropy: 1.09061
Value Function Loss: 5.72657

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.08234

Collected Steps per Second: 11,375.92831
Overall Steps per Second: 9,861.97320

Timestep Collection Time: 4.39525
Timestep Consumption Time: 0.67473
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.06998

Cumulative Model Updates: 41,038
Cumulative Timesteps: 684,569,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 684569192...
Checkpoint 684569192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,347.72180
Policy Entropy: 1.08958
Value Function Loss: 5.37819

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.08123

Collected Steps per Second: 11,258.70899
Overall Steps per Second: 9,585.69313

Timestep Collection Time: 4.44225
Timestep Consumption Time: 0.77532
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 5.21757

Cumulative Model Updates: 41,041
Cumulative Timesteps: 684,619,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,912.37115
Policy Entropy: 1.08826
Value Function Loss: 5.31341

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.08715

Collected Steps per Second: 11,080.21140
Overall Steps per Second: 9,390.70180

Timestep Collection Time: 4.51399
Timestep Consumption Time: 0.81213
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.32612

Cumulative Model Updates: 41,044
Cumulative Timesteps: 684,669,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 684669222...
Checkpoint 684669222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,673.06702
Policy Entropy: 1.09790
Value Function Loss: 5.41336

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.09153

Collected Steps per Second: 11,184.98132
Overall Steps per Second: 9,721.57348

Timestep Collection Time: 4.47260
Timestep Consumption Time: 0.67327
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.14587

Cumulative Model Updates: 41,047
Cumulative Timesteps: 684,719,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,395.87825
Policy Entropy: 1.09805
Value Function Loss: 5.65066

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.11389
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.09443

Collected Steps per Second: 11,466.64392
Overall Steps per Second: 9,736.09544

Timestep Collection Time: 4.36169
Timestep Consumption Time: 0.77527
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 5.13697

Cumulative Model Updates: 41,050
Cumulative Timesteps: 684,769,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 684769262...
Checkpoint 684769262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,798.77190
Policy Entropy: 1.10115
Value Function Loss: 5.83601

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.09360

Collected Steps per Second: 10,703.14088
Overall Steps per Second: 9,118.41356

Timestep Collection Time: 4.67209
Timestep Consumption Time: 0.81198
PPO Batch Consumption Time: 0.04056
Total Iteration Time: 5.48407

Cumulative Model Updates: 41,053
Cumulative Timesteps: 684,819,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,637.17203
Policy Entropy: 1.09761
Value Function Loss: 5.79159

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.09752

Collected Steps per Second: 11,366.69443
Overall Steps per Second: 9,686.66383

Timestep Collection Time: 4.39970
Timestep Consumption Time: 0.76307
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.16277

Cumulative Model Updates: 41,056
Cumulative Timesteps: 684,869,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 684869278...
Checkpoint 684869278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,903.63278
Policy Entropy: 1.10641
Value Function Loss: 5.88768

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.09377

Collected Steps per Second: 11,261.00037
Overall Steps per Second: 9,610.20455

Timestep Collection Time: 4.44170
Timestep Consumption Time: 0.76297
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.20468

Cumulative Model Updates: 41,059
Cumulative Timesteps: 684,919,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,278.20641
Policy Entropy: 1.10398
Value Function Loss: 5.71114

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.10286

Collected Steps per Second: 11,179.73718
Overall Steps per Second: 9,652.80564

Timestep Collection Time: 4.47417
Timestep Consumption Time: 0.70775
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.18191

Cumulative Model Updates: 41,062
Cumulative Timesteps: 684,969,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 684969316...
Checkpoint 684969316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,288.39123
Policy Entropy: 1.10625
Value Function Loss: 5.71441

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.11466

Collected Steps per Second: 10,997.57842
Overall Steps per Second: 9,356.10087

Timestep Collection Time: 4.54827
Timestep Consumption Time: 0.79797
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.34624

Cumulative Model Updates: 41,065
Cumulative Timesteps: 685,019,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,469.32380
Policy Entropy: 1.10238
Value Function Loss: 5.44809

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.06730
Value Function Update Magnitude: 0.10471

Collected Steps per Second: 10,587.43255
Overall Steps per Second: 9,078.04489

Timestep Collection Time: 4.72466
Timestep Consumption Time: 0.78556
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 5.51022

Cumulative Model Updates: 41,068
Cumulative Timesteps: 685,069,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 685069358...
Checkpoint 685069358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,714.45570
Policy Entropy: 1.09563
Value Function Loss: 5.52831

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.07178
Value Function Update Magnitude: 0.08970

Collected Steps per Second: 11,285.14688
Overall Steps per Second: 9,623.37238

Timestep Collection Time: 4.43060
Timestep Consumption Time: 0.76508
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.19568

Cumulative Model Updates: 41,071
Cumulative Timesteps: 685,119,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,956.90403
Policy Entropy: 1.09289
Value Function Loss: 5.74444

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.06920
Value Function Update Magnitude: 0.09694

Collected Steps per Second: 10,815.54639
Overall Steps per Second: 9,314.96806

Timestep Collection Time: 4.62445
Timestep Consumption Time: 0.74497
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.36942

Cumulative Model Updates: 41,074
Cumulative Timesteps: 685,169,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 685169374...
Checkpoint 685169374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,686.81868
Policy Entropy: 1.09561
Value Function Loss: 6.05421

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.11010

Collected Steps per Second: 10,776.78611
Overall Steps per Second: 9,303.67623

Timestep Collection Time: 4.64016
Timestep Consumption Time: 0.73471
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.37486

Cumulative Model Updates: 41,077
Cumulative Timesteps: 685,219,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,782.35318
Policy Entropy: 1.09999
Value Function Loss: 6.01451

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.10340

Collected Steps per Second: 11,081.64909
Overall Steps per Second: 9,318.48332

Timestep Collection Time: 4.51232
Timestep Consumption Time: 0.85378
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.36611

Cumulative Model Updates: 41,080
Cumulative Timesteps: 685,269,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 685269384...
Checkpoint 685269384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,395.14485
Policy Entropy: 1.08722
Value Function Loss: 5.85563

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.08976

Collected Steps per Second: 11,053.24617
Overall Steps per Second: 9,391.95637

Timestep Collection Time: 4.52446
Timestep Consumption Time: 0.80031
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.32477

Cumulative Model Updates: 41,083
Cumulative Timesteps: 685,319,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,765.23342
Policy Entropy: 1.09024
Value Function Loss: 5.72917

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.07789

Collected Steps per Second: 10,673.99397
Overall Steps per Second: 9,154.16758

Timestep Collection Time: 4.68691
Timestep Consumption Time: 0.77815
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.46505

Cumulative Model Updates: 41,086
Cumulative Timesteps: 685,369,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 685369422...
Checkpoint 685369422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,228.15360
Policy Entropy: 1.10425
Value Function Loss: 5.77608

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.07070

Collected Steps per Second: 10,833.15193
Overall Steps per Second: 9,272.35027

Timestep Collection Time: 4.61546
Timestep Consumption Time: 0.77691
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.39238

Cumulative Model Updates: 41,089
Cumulative Timesteps: 685,419,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,361.22410
Policy Entropy: 1.11279
Value Function Loss: 5.63625

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.06698

Collected Steps per Second: 10,911.01427
Overall Steps per Second: 9,472.94299

Timestep Collection Time: 4.58289
Timestep Consumption Time: 0.69572
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 5.27861

Cumulative Model Updates: 41,092
Cumulative Timesteps: 685,469,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 685469426...
Checkpoint 685469426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435,225.37813
Policy Entropy: 1.09779
Value Function Loss: 5.60926

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.11677
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.08651

Collected Steps per Second: 10,697.71783
Overall Steps per Second: 9,167.75022

Timestep Collection Time: 4.67632
Timestep Consumption Time: 0.78041
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.45674

Cumulative Model Updates: 41,095
Cumulative Timesteps: 685,519,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,642.76465
Policy Entropy: 1.10359
Value Function Loss: 5.59684

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.09466

Collected Steps per Second: 10,855.62910
Overall Steps per Second: 9,283.48962

Timestep Collection Time: 4.60775
Timestep Consumption Time: 0.78031
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.38806

Cumulative Model Updates: 41,098
Cumulative Timesteps: 685,569,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 685569472...
Checkpoint 685569472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,177.26970
Policy Entropy: 1.11018
Value Function Loss: 5.85020

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.09729

Collected Steps per Second: 11,097.59098
Overall Steps per Second: 9,319.82620

Timestep Collection Time: 4.50620
Timestep Consumption Time: 0.85956
PPO Batch Consumption Time: 0.04018
Total Iteration Time: 5.36577

Cumulative Model Updates: 41,101
Cumulative Timesteps: 685,619,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585,751.32175
Policy Entropy: 1.10715
Value Function Loss: 5.73313

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.06489
Value Function Update Magnitude: 0.09067

Collected Steps per Second: 11,504.22108
Overall Steps per Second: 9,764.87146

Timestep Collection Time: 4.34623
Timestep Consumption Time: 0.77416
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.12040

Cumulative Model Updates: 41,104
Cumulative Timesteps: 685,669,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 685669480...
Checkpoint 685669480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,896.60104
Policy Entropy: 1.10430
Value Function Loss: 5.73404

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.07157
Value Function Update Magnitude: 0.08253

Collected Steps per Second: 11,946.32727
Overall Steps per Second: 10,263.85313

Timestep Collection Time: 4.18689
Timestep Consumption Time: 0.68633
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.87322

Cumulative Model Updates: 41,107
Cumulative Timesteps: 685,719,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,085.24043
Policy Entropy: 1.08403
Value Function Loss: 5.48467

Mean KL Divergence: 0.03339
SB3 Clip Fraction: 0.16936
Policy Update Magnitude: 0.08124
Value Function Update Magnitude: 0.08508

Collected Steps per Second: 11,909.39490
Overall Steps per Second: 10,003.12183

Timestep Collection Time: 4.20072
Timestep Consumption Time: 0.80052
PPO Batch Consumption Time: 0.03337
Total Iteration Time: 5.00124

Cumulative Model Updates: 41,110
Cumulative Timesteps: 685,769,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 685769526...
Checkpoint 685769526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,843.63317
Policy Entropy: 1.10612
Value Function Loss: 6.19600

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.07009
Value Function Update Magnitude: 0.07635

Collected Steps per Second: 11,760.75087
Overall Steps per Second: 9,944.85266

Timestep Collection Time: 4.25194
Timestep Consumption Time: 0.77639
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.02833

Cumulative Model Updates: 41,113
Cumulative Timesteps: 685,819,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382,577.09812
Policy Entropy: 1.10760
Value Function Loss: 6.14043

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.07456

Collected Steps per Second: 12,116.29238
Overall Steps per Second: 10,188.29318

Timestep Collection Time: 4.12833
Timestep Consumption Time: 0.78123
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.90956

Cumulative Model Updates: 41,116
Cumulative Timesteps: 685,869,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 685869552...
Checkpoint 685869552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,709.58739
Policy Entropy: 1.10621
Value Function Loss: 6.38275

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.08015
Value Function Update Magnitude: 0.08035

Collected Steps per Second: 11,805.26153
Overall Steps per Second: 9,791.87930

Timestep Collection Time: 4.23642
Timestep Consumption Time: 0.87108
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.10750

Cumulative Model Updates: 41,119
Cumulative Timesteps: 685,919,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,622.07674
Policy Entropy: 1.09280
Value Function Loss: 5.90818

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.07146
Value Function Update Magnitude: 0.07514

Collected Steps per Second: 11,276.14855
Overall Steps per Second: 9,615.48537

Timestep Collection Time: 4.43520
Timestep Consumption Time: 0.76599
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.20119

Cumulative Model Updates: 41,122
Cumulative Timesteps: 685,969,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 685969576...
Checkpoint 685969576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,984.49206
Policy Entropy: 1.09947
Value Function Loss: 5.92088

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.07378

Collected Steps per Second: 11,183.23591
Overall Steps per Second: 9,526.97787

Timestep Collection Time: 4.47259
Timestep Consumption Time: 0.77756
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.25014

Cumulative Model Updates: 41,125
Cumulative Timesteps: 686,019,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,749.30346
Policy Entropy: 1.10431
Value Function Loss: 5.79276

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.07042

Collected Steps per Second: 11,104.27493
Overall Steps per Second: 9,588.42896

Timestep Collection Time: 4.50511
Timestep Consumption Time: 0.71222
PPO Batch Consumption Time: 0.03965
Total Iteration Time: 5.21733

Cumulative Model Updates: 41,128
Cumulative Timesteps: 686,069,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 686069620...
Checkpoint 686069620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,573.41185
Policy Entropy: 1.11066
Value Function Loss: 5.61974

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.06815

Collected Steps per Second: 11,029.04995
Overall Steps per Second: 9,353.08484

Timestep Collection Time: 4.53602
Timestep Consumption Time: 0.81280
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.34882

Cumulative Model Updates: 41,131
Cumulative Timesteps: 686,119,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,145.02750
Policy Entropy: 1.10727
Value Function Loss: 5.51501

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.06236

Collected Steps per Second: 11,095.01665
Overall Steps per Second: 9,345.52774

Timestep Collection Time: 4.50797
Timestep Consumption Time: 0.84389
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 5.35186

Cumulative Model Updates: 41,134
Cumulative Timesteps: 686,169,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 686169664...
Checkpoint 686169664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,260.22639
Policy Entropy: 1.11491
Value Function Loss: 5.56536

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.06227

Collected Steps per Second: 10,722.48673
Overall Steps per Second: 9,363.89647

Timestep Collection Time: 4.66310
Timestep Consumption Time: 0.67656
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 5.33966

Cumulative Model Updates: 41,137
Cumulative Timesteps: 686,219,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,688.60598
Policy Entropy: 1.11510
Value Function Loss: 5.59973

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.06343

Collected Steps per Second: 10,882.05895
Overall Steps per Second: 9,329.29751

Timestep Collection Time: 4.59674
Timestep Consumption Time: 0.76508
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.36182

Cumulative Model Updates: 41,140
Cumulative Timesteps: 686,269,686

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 686269686...
Checkpoint 686269686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,563.03758
Policy Entropy: 1.10777
Value Function Loss: 5.57178

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.06839

Collected Steps per Second: 10,872.59272
Overall Steps per Second: 9,349.20171

Timestep Collection Time: 4.60129
Timestep Consumption Time: 0.74975
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.35105

Cumulative Model Updates: 41,143
Cumulative Timesteps: 686,319,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,416.99528
Policy Entropy: 1.09849
Value Function Loss: 5.74341

Mean KL Divergence: 0.02744
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.06943

Collected Steps per Second: 11,258.91504
Overall Steps per Second: 9,627.51893

Timestep Collection Time: 4.44217
Timestep Consumption Time: 0.75273
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.19490

Cumulative Model Updates: 41,146
Cumulative Timesteps: 686,369,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 686369728...
Checkpoint 686369728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,132.03857
Policy Entropy: 1.10885
Value Function Loss: 6.13182

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.07337

Collected Steps per Second: 11,104.86750
Overall Steps per Second: 9,450.19401

Timestep Collection Time: 4.50469
Timestep Consumption Time: 0.78875
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.29344

Cumulative Model Updates: 41,149
Cumulative Timesteps: 686,419,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481,548.37812
Policy Entropy: 1.11486
Value Function Loss: 6.22437

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.08803

Collected Steps per Second: 10,968.95514
Overall Steps per Second: 9,568.38354

Timestep Collection Time: 4.56051
Timestep Consumption Time: 0.66754
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.22805

Cumulative Model Updates: 41,152
Cumulative Timesteps: 686,469,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 686469776...
Checkpoint 686469776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,034.40944
Policy Entropy: 1.07847
Value Function Loss: 6.04588

Mean KL Divergence: 0.06070
SB3 Clip Fraction: 0.20444
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.08235

Collected Steps per Second: 10,398.62656
Overall Steps per Second: 8,928.25698

Timestep Collection Time: 4.81006
Timestep Consumption Time: 0.79216
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.60221

Cumulative Model Updates: 41,155
Cumulative Timesteps: 686,519,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,282.54363
Policy Entropy: 1.11073
Value Function Loss: 5.74846

Mean KL Divergence: 0.03360
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.08474

Collected Steps per Second: 10,724.89138
Overall Steps per Second: 9,253.94499

Timestep Collection Time: 4.66392
Timestep Consumption Time: 0.74135
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.40526

Cumulative Model Updates: 41,158
Cumulative Timesteps: 686,569,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 686569814...
Checkpoint 686569814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,198.37909
Policy Entropy: 1.08787
Value Function Loss: 5.93354

Mean KL Divergence: 0.03513
SB3 Clip Fraction: 0.15463
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.07899

Collected Steps per Second: 10,788.15537
Overall Steps per Second: 9,386.68578

Timestep Collection Time: 4.63527
Timestep Consumption Time: 0.69206
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.32733

Cumulative Model Updates: 41,161
Cumulative Timesteps: 686,619,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383,131.48709
Policy Entropy: 1.10999
Value Function Loss: 5.85109

Mean KL Divergence: 0.02916
SB3 Clip Fraction: 0.14798
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.07473

Collected Steps per Second: 10,868.90607
Overall Steps per Second: 9,249.36106

Timestep Collection Time: 4.60083
Timestep Consumption Time: 0.80560
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.40643

Cumulative Model Updates: 41,164
Cumulative Timesteps: 686,669,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 686669826...
Checkpoint 686669826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,479.84865
Policy Entropy: 1.11048
Value Function Loss: 5.53269

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.08089

Collected Steps per Second: 10,639.27374
Overall Steps per Second: 9,148.85578

Timestep Collection Time: 4.69957
Timestep Consumption Time: 0.76560
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.46516

Cumulative Model Updates: 41,167
Cumulative Timesteps: 686,719,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,037.92263
Policy Entropy: 1.09548
Value Function Loss: 5.42919

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.08491

Collected Steps per Second: 10,650.52084
Overall Steps per Second: 9,113.50355

Timestep Collection Time: 4.69686
Timestep Consumption Time: 0.79214
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.48900

Cumulative Model Updates: 41,170
Cumulative Timesteps: 686,769,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 686769850...
Checkpoint 686769850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,372.56478
Policy Entropy: 1.09357
Value Function Loss: 5.66159

Mean KL Divergence: 0.02852
SB3 Clip Fraction: 0.16199
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.07057

Collected Steps per Second: 10,939.92263
Overall Steps per Second: 9,284.58372

Timestep Collection Time: 4.57115
Timestep Consumption Time: 0.81499
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.38613

Cumulative Model Updates: 41,173
Cumulative Timesteps: 686,819,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,843.23799
Policy Entropy: 1.10518
Value Function Loss: 6.32463

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.07021

Collected Steps per Second: 11,335.58460
Overall Steps per Second: 9,810.64321

Timestep Collection Time: 4.41177
Timestep Consumption Time: 0.68575
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.09753

Cumulative Model Updates: 41,176
Cumulative Timesteps: 686,869,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 686869868...
Checkpoint 686869868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,210.35177
Policy Entropy: 1.10790
Value Function Loss: 5.98901

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.06901

Collected Steps per Second: 11,475.04153
Overall Steps per Second: 9,778.50849

Timestep Collection Time: 4.35937
Timestep Consumption Time: 0.75633
PPO Batch Consumption Time: 0.03854
Total Iteration Time: 5.11571

Cumulative Model Updates: 41,179
Cumulative Timesteps: 686,919,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,357.72346
Policy Entropy: 1.09449
Value Function Loss: 5.88420

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.11247
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.06733

Collected Steps per Second: 11,391.26829
Overall Steps per Second: 9,695.55906

Timestep Collection Time: 4.39108
Timestep Consumption Time: 0.76798
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 5.15906

Cumulative Model Updates: 41,182
Cumulative Timesteps: 686,969,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 686969912...
Checkpoint 686969912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,400.22220
Policy Entropy: 1.08539
Value Function Loss: 5.30234

Mean KL Divergence: 0.03468
SB3 Clip Fraction: 0.16091
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.06335

Collected Steps per Second: 11,417.40030
Overall Steps per Second: 9,761.02335

Timestep Collection Time: 4.38068
Timestep Consumption Time: 0.74337
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.12405

Cumulative Model Updates: 41,185
Cumulative Timesteps: 687,019,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,957.54321
Policy Entropy: 1.11132
Value Function Loss: 5.68330

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.07152

Collected Steps per Second: 10,889.00798
Overall Steps per Second: 9,266.52153

Timestep Collection Time: 4.59381
Timestep Consumption Time: 0.80434
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 5.39814

Cumulative Model Updates: 41,188
Cumulative Timesteps: 687,069,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 687069950...
Checkpoint 687069950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,335.95209
Policy Entropy: 1.09894
Value Function Loss: 5.55377

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.06545

Collected Steps per Second: 11,117.13666
Overall Steps per Second: 9,483.00341

Timestep Collection Time: 4.49936
Timestep Consumption Time: 0.77534
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.27470

Cumulative Model Updates: 41,191
Cumulative Timesteps: 687,119,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,640.80130
Policy Entropy: 1.09011
Value Function Loss: 5.95899

Mean KL Divergence: 0.02630
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.07702

Collected Steps per Second: 11,469.00361
Overall Steps per Second: 9,709.16560

Timestep Collection Time: 4.36184
Timestep Consumption Time: 0.79061
PPO Batch Consumption Time: 0.04352
Total Iteration Time: 5.15245

Cumulative Model Updates: 41,194
Cumulative Timesteps: 687,169,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 687169996...
Checkpoint 687169996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,139.43588
Policy Entropy: 1.10173
Value Function Loss: 5.69166

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.07945

Collected Steps per Second: 11,037.81019
Overall Steps per Second: 9,368.78135

Timestep Collection Time: 4.53061
Timestep Consumption Time: 0.80712
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.33773

Cumulative Model Updates: 41,197
Cumulative Timesteps: 687,220,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387,262.24154
Policy Entropy: 1.10799
Value Function Loss: 5.74164

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.07248

Collected Steps per Second: 11,133.91030
Overall Steps per Second: 9,657.24990

Timestep Collection Time: 4.49114
Timestep Consumption Time: 0.68673
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.17787

Cumulative Model Updates: 41,200
Cumulative Timesteps: 687,270,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 687270008...
Checkpoint 687270008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,123.75350
Policy Entropy: 1.08497
Value Function Loss: 5.56285

Mean KL Divergence: 0.03418
SB3 Clip Fraction: 0.15331
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.07223

Collected Steps per Second: 11,137.53819
Overall Steps per Second: 9,497.61813

Timestep Collection Time: 4.48950
Timestep Consumption Time: 0.77519
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.26469

Cumulative Model Updates: 41,203
Cumulative Timesteps: 687,320,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,849.98423
Policy Entropy: 1.09769
Value Function Loss: 5.66461

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.08024

Collected Steps per Second: 10,528.44586
Overall Steps per Second: 9,104.93748

Timestep Collection Time: 4.74904
Timestep Consumption Time: 0.74249
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.49153

Cumulative Model Updates: 41,206
Cumulative Timesteps: 687,370,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 687370010...
Checkpoint 687370010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,998.88967
Policy Entropy: 1.10484
Value Function Loss: 5.81898

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.07633

Collected Steps per Second: 11,362.16071
Overall Steps per Second: 9,689.74491

Timestep Collection Time: 4.40251
Timestep Consumption Time: 0.75986
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 5.16237

Cumulative Model Updates: 41,209
Cumulative Timesteps: 687,420,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399,760.75248
Policy Entropy: 1.09685
Value Function Loss: 5.73773

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.08599

Collected Steps per Second: 10,776.77410
Overall Steps per Second: 9,317.10906

Timestep Collection Time: 4.64221
Timestep Consumption Time: 0.72727
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.36948

Cumulative Model Updates: 41,212
Cumulative Timesteps: 687,470,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 687470060...
Checkpoint 687470060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,495.89915
Policy Entropy: 1.10300
Value Function Loss: 5.71253

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.09057

Collected Steps per Second: 10,850.50118
Overall Steps per Second: 9,449.25954

Timestep Collection Time: 4.61066
Timestep Consumption Time: 0.68372
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.29438

Cumulative Model Updates: 41,215
Cumulative Timesteps: 687,520,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397,531.03912
Policy Entropy: 1.10945
Value Function Loss: 5.81898

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.09718

Collected Steps per Second: 10,842.71520
Overall Steps per Second: 9,314.47394

Timestep Collection Time: 4.61250
Timestep Consumption Time: 0.75678
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.36928

Cumulative Model Updates: 41,218
Cumulative Timesteps: 687,570,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 687570100...
Checkpoint 687570100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,872.30320
Policy Entropy: 1.10288
Value Function Loss: 5.91397

Mean KL Divergence: 0.02340
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.08735

Collected Steps per Second: 10,721.97237
Overall Steps per Second: 9,304.51434

Timestep Collection Time: 4.66444
Timestep Consumption Time: 0.71059
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.37503

Cumulative Model Updates: 41,221
Cumulative Timesteps: 687,620,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,934.90598
Policy Entropy: 1.07434
Value Function Loss: 5.95058

Mean KL Divergence: 0.05276
SB3 Clip Fraction: 0.18879
Policy Update Magnitude: 0.06743
Value Function Update Magnitude: 0.08879

Collected Steps per Second: 10,811.88636
Overall Steps per Second: 9,247.85579

Timestep Collection Time: 4.62565
Timestep Consumption Time: 0.78231
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 5.40796

Cumulative Model Updates: 41,224
Cumulative Timesteps: 687,670,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 687670124...
Checkpoint 687670124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,586.24147
Policy Entropy: 1.09141
Value Function Loss: 5.77616

Mean KL Divergence: 0.02607
SB3 Clip Fraction: 0.15663
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.10721

Collected Steps per Second: 10,593.65888
Overall Steps per Second: 8,994.54950

Timestep Collection Time: 4.72245
Timestep Consumption Time: 0.83959
PPO Batch Consumption Time: 0.03889
Total Iteration Time: 5.56204

Cumulative Model Updates: 41,227
Cumulative Timesteps: 687,720,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,872.84511
Policy Entropy: 1.09758
Value Function Loss: 5.80064

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.16022
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.11477

Collected Steps per Second: 11,049.97819
Overall Steps per Second: 9,481.83994

Timestep Collection Time: 4.52526
Timestep Consumption Time: 0.74840
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 5.27366

Cumulative Model Updates: 41,230
Cumulative Timesteps: 687,770,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 687770156...
Checkpoint 687770156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,451.22821
Policy Entropy: 1.10159
Value Function Loss: 5.72022

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.11798

Collected Steps per Second: 10,821.30723
Overall Steps per Second: 9,142.45612

Timestep Collection Time: 4.62181
Timestep Consumption Time: 0.84871
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.47052

Cumulative Model Updates: 41,233
Cumulative Timesteps: 687,820,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,535.30267
Policy Entropy: 1.08441
Value Function Loss: 5.87415

Mean KL Divergence: 0.02650
SB3 Clip Fraction: 0.16648
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.10137

Collected Steps per Second: 10,883.76309
Overall Steps per Second: 9,247.34933

Timestep Collection Time: 4.59584
Timestep Consumption Time: 0.81328
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.40912

Cumulative Model Updates: 41,236
Cumulative Timesteps: 687,870,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 687870190...
Checkpoint 687870190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,001.68514
Policy Entropy: 1.09454
Value Function Loss: 5.68198

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.08807

Collected Steps per Second: 10,395.15626
Overall Steps per Second: 8,927.51392

Timestep Collection Time: 4.81032
Timestep Consumption Time: 0.79079
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.60111

Cumulative Model Updates: 41,239
Cumulative Timesteps: 687,920,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,666.56425
Policy Entropy: 1.09681
Value Function Loss: 5.79803

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.09077

Collected Steps per Second: 11,962.77757
Overall Steps per Second: 10,057.41341

Timestep Collection Time: 4.18231
Timestep Consumption Time: 0.79233
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 4.97464

Cumulative Model Updates: 41,242
Cumulative Timesteps: 687,970,226

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 687970226...
Checkpoint 687970226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,927.01020
Policy Entropy: 1.08606
Value Function Loss: 5.53651

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.08293

Collected Steps per Second: 12,281.33784
Overall Steps per Second: 10,232.90941

Timestep Collection Time: 4.07122
Timestep Consumption Time: 0.81498
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 4.88620

Cumulative Model Updates: 41,245
Cumulative Timesteps: 688,020,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,169.26621
Policy Entropy: 1.09457
Value Function Loss: 5.86325

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.07799

Collected Steps per Second: 12,196.28494
Overall Steps per Second: 10,117.68336

Timestep Collection Time: 4.10108
Timestep Consumption Time: 0.84254
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 4.94362

Cumulative Model Updates: 41,248
Cumulative Timesteps: 688,070,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 688070244...
Checkpoint 688070244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,294.92477
Policy Entropy: 1.09572
Value Function Loss: 5.92949

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.08072

Collected Steps per Second: 11,910.96419
Overall Steps per Second: 10,141.74436

Timestep Collection Time: 4.19949
Timestep Consumption Time: 0.73260
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 4.93209

Cumulative Model Updates: 41,251
Cumulative Timesteps: 688,120,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,699.54930
Policy Entropy: 1.11678
Value Function Loss: 5.72526

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.07883

Collected Steps per Second: 11,687.38789
Overall Steps per Second: 9,945.13671

Timestep Collection Time: 4.27948
Timestep Consumption Time: 0.74971
PPO Batch Consumption Time: 0.03367
Total Iteration Time: 5.02919

Cumulative Model Updates: 41,254
Cumulative Timesteps: 688,170,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 688170280...
Checkpoint 688170280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,166.71927
Policy Entropy: 1.06689
Value Function Loss: 5.69595

Mean KL Divergence: 0.10662
SB3 Clip Fraction: 0.25191
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 10,896.57469
Overall Steps per Second: 9,306.29627

Timestep Collection Time: 4.58933
Timestep Consumption Time: 0.78423
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 5.37357

Cumulative Model Updates: 41,257
Cumulative Timesteps: 688,220,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451,810.25228
Policy Entropy: 1.09322
Value Function Loss: 5.79350

Mean KL Divergence: 0.04677
SB3 Clip Fraction: 0.17471
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 11,299.30537
Overall Steps per Second: 9,594.65885

Timestep Collection Time: 4.42717
Timestep Consumption Time: 0.78656
PPO Batch Consumption Time: 0.03854
Total Iteration Time: 5.21373

Cumulative Model Updates: 41,260
Cumulative Timesteps: 688,270,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 688270312...
Checkpoint 688270312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379,928.29311
Policy Entropy: 1.06312
Value Function Loss: 5.96189

Mean KL Divergence: 0.06232
SB3 Clip Fraction: 0.25309
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.07345

Collected Steps per Second: 10,799.95972
Overall Steps per Second: 9,216.31786

Timestep Collection Time: 4.63224
Timestep Consumption Time: 0.79596
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.42820

Cumulative Model Updates: 41,263
Cumulative Timesteps: 688,320,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,637.02914
Policy Entropy: 1.09261
Value Function Loss: 5.73847

Mean KL Divergence: 0.04862
SB3 Clip Fraction: 0.22336
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.08338

Collected Steps per Second: 11,177.73327
Overall Steps per Second: 9,646.38571

Timestep Collection Time: 4.47550
Timestep Consumption Time: 0.71048
PPO Batch Consumption Time: 0.03971
Total Iteration Time: 5.18598

Cumulative Model Updates: 41,266
Cumulative Timesteps: 688,370,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 688370366...
Checkpoint 688370366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,243.35388
Policy Entropy: 1.06928
Value Function Loss: 5.66338

Mean KL Divergence: 0.05903
SB3 Clip Fraction: 0.24047
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.09617

Collected Steps per Second: 11,234.50065
Overall Steps per Second: 9,519.97898

Timestep Collection Time: 4.45218
Timestep Consumption Time: 0.80182
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.25400

Cumulative Model Updates: 41,269
Cumulative Timesteps: 688,420,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,621.57560
Policy Entropy: 1.08850
Value Function Loss: 5.51248

Mean KL Divergence: 0.02915
SB3 Clip Fraction: 0.18705
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.10415

Collected Steps per Second: 10,962.38127
Overall Steps per Second: 9,258.67497

Timestep Collection Time: 4.56269
Timestep Consumption Time: 0.83959
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.40228

Cumulative Model Updates: 41,272
Cumulative Timesteps: 688,470,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 688470402...
Checkpoint 688470402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,490.99744
Policy Entropy: 1.06994
Value Function Loss: 5.43354

Mean KL Divergence: 0.03001
SB3 Clip Fraction: 0.17187
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.10183

Collected Steps per Second: 11,061.71425
Overall Steps per Second: 9,406.70293

Timestep Collection Time: 4.52172
Timestep Consumption Time: 0.79555
PPO Batch Consumption Time: 0.04406
Total Iteration Time: 5.31727

Cumulative Model Updates: 41,275
Cumulative Timesteps: 688,520,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,773.08340
Policy Entropy: 1.07616
Value Function Loss: 5.29539

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.10084

Collected Steps per Second: 11,115.12872
Overall Steps per Second: 9,503.89403

Timestep Collection Time: 4.49963
Timestep Consumption Time: 0.76284
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 5.26247

Cumulative Model Updates: 41,278
Cumulative Timesteps: 688,570,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 688570434...
Checkpoint 688570434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,728.11323
Policy Entropy: 1.09448
Value Function Loss: 5.32079

Mean KL Divergence: 0.02538
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.08493

Collected Steps per Second: 10,800.41997
Overall Steps per Second: 9,296.00522

Timestep Collection Time: 4.63038
Timestep Consumption Time: 0.74935
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.37973

Cumulative Model Updates: 41,281
Cumulative Timesteps: 688,620,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,415.70776
Policy Entropy: 1.09349
Value Function Loss: 5.34085

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.08778

Collected Steps per Second: 11,240.51772
Overall Steps per Second: 9,526.57270

Timestep Collection Time: 4.44891
Timestep Consumption Time: 0.80041
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 5.24932

Cumulative Model Updates: 41,284
Cumulative Timesteps: 688,670,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 688670452...
Checkpoint 688670452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432,778.49692
Policy Entropy: 1.08279
Value Function Loss: 5.41282

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.09078

Collected Steps per Second: 10,955.66958
Overall Steps per Second: 9,271.42718

Timestep Collection Time: 4.56512
Timestep Consumption Time: 0.82930
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.39442

Cumulative Model Updates: 41,287
Cumulative Timesteps: 688,720,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,946.82859
Policy Entropy: 1.06754
Value Function Loss: 5.46851

Mean KL Divergence: 0.03573
SB3 Clip Fraction: 0.17563
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.08223

Collected Steps per Second: 10,731.97752
Overall Steps per Second: 9,312.86945

Timestep Collection Time: 4.65991
Timestep Consumption Time: 0.71008
PPO Batch Consumption Time: 0.03898
Total Iteration Time: 5.36999

Cumulative Model Updates: 41,290
Cumulative Timesteps: 688,770,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 688770476...
Checkpoint 688770476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,764.95228
Policy Entropy: 1.08590
Value Function Loss: 5.60625

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.09075

Collected Steps per Second: 10,754.78118
Overall Steps per Second: 9,229.99214

Timestep Collection Time: 4.65040
Timestep Consumption Time: 0.76824
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.41864

Cumulative Model Updates: 41,293
Cumulative Timesteps: 688,820,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566,815.13192
Policy Entropy: 1.07983
Value Function Loss: 5.60602

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.06617
Value Function Update Magnitude: 0.08615

Collected Steps per Second: 10,629.97493
Overall Steps per Second: 9,282.91738

Timestep Collection Time: 4.70387
Timestep Consumption Time: 0.68259
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.38645

Cumulative Model Updates: 41,296
Cumulative Timesteps: 688,870,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 688870492...
Checkpoint 688870492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442,305.36134
Policy Entropy: 1.06551
Value Function Loss: 5.75161

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.07082
Value Function Update Magnitude: 0.07893

Collected Steps per Second: 10,984.26121
Overall Steps per Second: 9,355.35563

Timestep Collection Time: 4.55452
Timestep Consumption Time: 0.79301
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 5.34753

Cumulative Model Updates: 41,299
Cumulative Timesteps: 688,920,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,541.05347
Policy Entropy: 1.08154
Value Function Loss: 5.52197

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.07826

Collected Steps per Second: 10,702.36346
Overall Steps per Second: 9,184.41705

Timestep Collection Time: 4.67448
Timestep Consumption Time: 0.77257
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.44705

Cumulative Model Updates: 41,302
Cumulative Timesteps: 688,970,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 688970548...
Checkpoint 688970548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,699.08281
Policy Entropy: 1.08592
Value Function Loss: 5.44747

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.06868
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 11,100.67646
Overall Steps per Second: 9,384.17681

Timestep Collection Time: 4.50603
Timestep Consumption Time: 0.82422
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.33025

Cumulative Model Updates: 41,305
Cumulative Timesteps: 689,020,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,386.07816
Policy Entropy: 1.08385
Value Function Loss: 5.38947

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.07561
Value Function Update Magnitude: 0.08320

Collected Steps per Second: 10,905.26642
Overall Steps per Second: 9,314.14695

Timestep Collection Time: 4.58604
Timestep Consumption Time: 0.78343
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.36947

Cumulative Model Updates: 41,308
Cumulative Timesteps: 689,070,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 689070580...
Checkpoint 689070580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,392.15311
Policy Entropy: 1.07217
Value Function Loss: 5.43177

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.07399
Value Function Update Magnitude: 0.08542

Collected Steps per Second: 11,074.17137
Overall Steps per Second: 9,613.81683

Timestep Collection Time: 4.51609
Timestep Consumption Time: 0.68600
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.20210

Cumulative Model Updates: 41,311
Cumulative Timesteps: 689,120,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,438.44616
Policy Entropy: 1.08427
Value Function Loss: 5.44135

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.07600

Collected Steps per Second: 11,365.91611
Overall Steps per Second: 9,654.94225

Timestep Collection Time: 4.40141
Timestep Consumption Time: 0.77998
PPO Batch Consumption Time: 0.03896
Total Iteration Time: 5.18139

Cumulative Model Updates: 41,314
Cumulative Timesteps: 689,170,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 689170618...
Checkpoint 689170618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,389.46454
Policy Entropy: 1.08619
Value Function Loss: 5.42932

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.07801

Collected Steps per Second: 10,476.23216
Overall Steps per Second: 8,924.54377

Timestep Collection Time: 4.77538
Timestep Consumption Time: 0.83028
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 5.60566

Cumulative Model Updates: 41,317
Cumulative Timesteps: 689,220,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,788.80386
Policy Entropy: 1.07315
Value Function Loss: 5.53222

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.08550

Collected Steps per Second: 11,155.14543
Overall Steps per Second: 9,687.64438

Timestep Collection Time: 4.48224
Timestep Consumption Time: 0.67898
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.16121

Cumulative Model Updates: 41,320
Cumulative Timesteps: 689,270,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 689270646...
Checkpoint 689270646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,574.75104
Policy Entropy: 1.06948
Value Function Loss: 5.39331

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.07991

Collected Steps per Second: 10,649.32046
Overall Steps per Second: 9,061.44113

Timestep Collection Time: 4.69645
Timestep Consumption Time: 0.82298
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 5.51943

Cumulative Model Updates: 41,323
Cumulative Timesteps: 689,320,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,706.21111
Policy Entropy: 1.07766
Value Function Loss: 5.44718

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.08038

Collected Steps per Second: 10,924.43098
Overall Steps per Second: 9,356.66903

Timestep Collection Time: 4.57708
Timestep Consumption Time: 0.76692
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 5.34400

Cumulative Model Updates: 41,326
Cumulative Timesteps: 689,370,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 689370662...
Checkpoint 689370662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,252.02553
Policy Entropy: 1.07755
Value Function Loss: 5.82534

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.06106
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 11,326.28651
Overall Steps per Second: 9,653.31318

Timestep Collection Time: 4.41681
Timestep Consumption Time: 0.76546
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.18226

Cumulative Model Updates: 41,329
Cumulative Timesteps: 689,420,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,456.81082
Policy Entropy: 1.07318
Value Function Loss: 5.78888

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08057
Policy Update Magnitude: 0.07823
Value Function Update Magnitude: 0.08371

Collected Steps per Second: 11,127.26636
Overall Steps per Second: 9,524.84883

Timestep Collection Time: 4.49383
Timestep Consumption Time: 0.75602
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.24985

Cumulative Model Updates: 41,332
Cumulative Timesteps: 689,470,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 689470692...
Checkpoint 689470692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,916.07502
Policy Entropy: 1.07700
Value Function Loss: 5.82984

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.08513
Value Function Update Magnitude: 0.09090

Collected Steps per Second: 11,134.37296
Overall Steps per Second: 9,660.23176

Timestep Collection Time: 4.49186
Timestep Consumption Time: 0.68545
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 5.17731

Cumulative Model Updates: 41,335
Cumulative Timesteps: 689,520,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,092.58413
Policy Entropy: 1.08270
Value Function Loss: 5.70887

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.07777
Value Function Update Magnitude: 0.10214

Collected Steps per Second: 11,102.83318
Overall Steps per Second: 9,406.54684

Timestep Collection Time: 4.50462
Timestep Consumption Time: 0.81232
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 5.31694

Cumulative Model Updates: 41,338
Cumulative Timesteps: 689,570,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 689570720...
Checkpoint 689570720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,739.96198
Policy Entropy: 1.08649
Value Function Loss: 5.70580

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.07943
Value Function Update Magnitude: 0.10686

Collected Steps per Second: 10,670.80445
Overall Steps per Second: 9,217.73617

Timestep Collection Time: 4.68606
Timestep Consumption Time: 0.73870
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.42476

Cumulative Model Updates: 41,341
Cumulative Timesteps: 689,620,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,995.94487
Policy Entropy: 1.08233
Value Function Loss: 5.73289

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.08226
Value Function Update Magnitude: 0.10114

Collected Steps per Second: 11,060.74299
Overall Steps per Second: 9,474.27367

Timestep Collection Time: 4.52158
Timestep Consumption Time: 0.75714
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.27872

Cumulative Model Updates: 41,344
Cumulative Timesteps: 689,670,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 689670736...
Checkpoint 689670736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,630.16247
Policy Entropy: 1.07894
Value Function Loss: 5.53372

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.07936
Value Function Update Magnitude: 0.09543

Collected Steps per Second: 10,967.04918
Overall Steps per Second: 9,387.63085

Timestep Collection Time: 4.56166
Timestep Consumption Time: 0.76748
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 5.32914

Cumulative Model Updates: 41,347
Cumulative Timesteps: 689,720,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,557.49617
Policy Entropy: 1.06891
Value Function Loss: 5.85531

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.15458
Policy Update Magnitude: 0.07382
Value Function Update Magnitude: 0.09997

Collected Steps per Second: 10,921.57625
Overall Steps per Second: 9,433.76257

Timestep Collection Time: 4.57846
Timestep Consumption Time: 0.72208
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.30054

Cumulative Model Updates: 41,350
Cumulative Timesteps: 689,770,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 689770768...
Checkpoint 689770768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,358.76208
Policy Entropy: 1.08532
Value Function Loss: 5.53261

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.10635

Collected Steps per Second: 10,859.94901
Overall Steps per Second: 9,330.88790

Timestep Collection Time: 4.60647
Timestep Consumption Time: 0.75487
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 5.36133

Cumulative Model Updates: 41,353
Cumulative Timesteps: 689,820,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,900.44633
Policy Entropy: 1.08976
Value Function Loss: 5.52830

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.10744

Collected Steps per Second: 11,120.95707
Overall Steps per Second: 9,516.20460

Timestep Collection Time: 4.49638
Timestep Consumption Time: 0.75824
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.25462

Cumulative Model Updates: 41,356
Cumulative Timesteps: 689,870,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 689870798...
Checkpoint 689870798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,680.42549
Policy Entropy: 1.07169
Value Function Loss: 5.23479

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.09980

Collected Steps per Second: 10,680.88164
Overall Steps per Second: 9,155.73916

Timestep Collection Time: 4.68201
Timestep Consumption Time: 0.77992
PPO Batch Consumption Time: 0.03872
Total Iteration Time: 5.46193

Cumulative Model Updates: 41,359
Cumulative Timesteps: 689,920,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,503.42485
Policy Entropy: 1.06947
Value Function Loss: 5.44452

Mean KL Divergence: 0.02684
SB3 Clip Fraction: 0.14517
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.08297

Collected Steps per Second: 10,780.71466
Overall Steps per Second: 9,368.64373

Timestep Collection Time: 4.63958
Timestep Consumption Time: 0.69929
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.33887

Cumulative Model Updates: 41,362
Cumulative Timesteps: 689,970,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 689970824...
Checkpoint 689970824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,824.95959
Policy Entropy: 1.08362
Value Function Loss: 5.38636

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.07806

Collected Steps per Second: 10,949.02392
Overall Steps per Second: 9,357.74583

Timestep Collection Time: 4.56771
Timestep Consumption Time: 0.77674
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 5.34445

Cumulative Model Updates: 41,365
Cumulative Timesteps: 690,020,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,101.12847
Policy Entropy: 1.09525
Value Function Loss: 5.46942

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.08164

Collected Steps per Second: 10,710.65289
Overall Steps per Second: 9,152.15498

Timestep Collection Time: 4.66825
Timestep Consumption Time: 0.79494
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.46319

Cumulative Model Updates: 41,368
Cumulative Timesteps: 690,070,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 690070836...
Checkpoint 690070836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,767.53538
Policy Entropy: 1.05409
Value Function Loss: 5.41212

Mean KL Divergence: 0.07460
SB3 Clip Fraction: 0.19617
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.08625

Collected Steps per Second: 10,946.80709
Overall Steps per Second: 9,470.89055

Timestep Collection Time: 4.56809
Timestep Consumption Time: 0.71188
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 5.27997

Cumulative Model Updates: 41,371
Cumulative Timesteps: 690,120,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,422.26020
Policy Entropy: 1.08880
Value Function Loss: 5.47797

Mean KL Divergence: 0.03812
SB3 Clip Fraction: 0.16795
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.08998

Collected Steps per Second: 10,382.50338
Overall Steps per Second: 8,906.47110

Timestep Collection Time: 4.81676
Timestep Consumption Time: 0.79826
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.61502

Cumulative Model Updates: 41,374
Cumulative Timesteps: 690,170,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 690170852...
Checkpoint 690170852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,427.52647
Policy Entropy: 1.05666
Value Function Loss: 5.37140

Mean KL Divergence: 0.05731
SB3 Clip Fraction: 0.19507
Policy Update Magnitude: 0.04513
Value Function Update Magnitude: 0.08699

Collected Steps per Second: 11,643.21954
Overall Steps per Second: 9,855.60126

Timestep Collection Time: 4.29606
Timestep Consumption Time: 0.77922
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.07529

Cumulative Model Updates: 41,377
Cumulative Timesteps: 690,220,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,917.76831
Policy Entropy: 1.09201
Value Function Loss: 5.15251

Mean KL Divergence: 0.03338
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.08843

Collected Steps per Second: 12,082.62644
Overall Steps per Second: 10,139.42623

Timestep Collection Time: 4.14049
Timestep Consumption Time: 0.79352
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 4.93401

Cumulative Model Updates: 41,380
Cumulative Timesteps: 690,270,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 690270900...
Checkpoint 690270900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,247.50021
Policy Entropy: 1.06755
Value Function Loss: 5.07813

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.07910

Collected Steps per Second: 11,592.77231
Overall Steps per Second: 9,840.65120

Timestep Collection Time: 4.31320
Timestep Consumption Time: 0.76796
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.08117

Cumulative Model Updates: 41,383
Cumulative Timesteps: 690,320,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,063.86372
Policy Entropy: 1.07718
Value Function Loss: 5.01128

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.09807

Collected Steps per Second: 11,714.79683
Overall Steps per Second: 10,021.17248

Timestep Collection Time: 4.26981
Timestep Consumption Time: 0.72162
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 4.99143

Cumulative Model Updates: 41,386
Cumulative Timesteps: 690,370,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 690370922...
Checkpoint 690370922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,408.03037
Policy Entropy: 1.08392
Value Function Loss: 5.38185

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.10107

Collected Steps per Second: 11,820.43267
Overall Steps per Second: 9,927.66876

Timestep Collection Time: 4.23081
Timestep Consumption Time: 0.80663
PPO Batch Consumption Time: 0.03898
Total Iteration Time: 5.03744

Cumulative Model Updates: 41,389
Cumulative Timesteps: 690,420,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,383.32826
Policy Entropy: 1.08655
Value Function Loss: 5.67620

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.09683

Collected Steps per Second: 11,106.26622
Overall Steps per Second: 9,520.86044

Timestep Collection Time: 4.50394
Timestep Consumption Time: 0.74999
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 5.25394

Cumulative Model Updates: 41,392
Cumulative Timesteps: 690,470,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 690470954...
Checkpoint 690470954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,710.46558
Policy Entropy: 1.08107
Value Function Loss: 5.81946

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.09878

Collected Steps per Second: 10,884.32260
Overall Steps per Second: 9,440.00312

Timestep Collection Time: 4.59542
Timestep Consumption Time: 0.70310
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.29852

Cumulative Model Updates: 41,395
Cumulative Timesteps: 690,520,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,158.82053
Policy Entropy: 1.08133
Value Function Loss: 5.44922

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.09474

Collected Steps per Second: 11,343.53124
Overall Steps per Second: 9,508.17446

Timestep Collection Time: 4.40780
Timestep Consumption Time: 0.85083
PPO Batch Consumption Time: 0.03976
Total Iteration Time: 5.25863

Cumulative Model Updates: 41,398
Cumulative Timesteps: 690,570,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 690570972...
Checkpoint 690570972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,670.75922
Policy Entropy: 1.08727
Value Function Loss: 5.47426

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.08517

Collected Steps per Second: 11,270.69948
Overall Steps per Second: 9,629.78231

Timestep Collection Time: 4.43735
Timestep Consumption Time: 0.75612
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 5.19347

Cumulative Model Updates: 41,401
Cumulative Timesteps: 690,620,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,481.28804
Policy Entropy: 1.09899
Value Function Loss: 5.65220

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.07496

Collected Steps per Second: 11,156.78673
Overall Steps per Second: 9,487.33151

Timestep Collection Time: 4.48355
Timestep Consumption Time: 0.78896
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.27250

Cumulative Model Updates: 41,404
Cumulative Timesteps: 690,671,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 690671006...
Checkpoint 690671006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,636.57209
Policy Entropy: 1.10084
Value Function Loss: 5.82255

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.06387
Value Function Update Magnitude: 0.09600

Collected Steps per Second: 11,076.90329
Overall Steps per Second: 9,366.23268

Timestep Collection Time: 4.51534
Timestep Consumption Time: 0.82469
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.34003

Cumulative Model Updates: 41,407
Cumulative Timesteps: 690,721,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,351.59777
Policy Entropy: 1.10466
Value Function Loss: 5.39781

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.09663

Collected Steps per Second: 10,728.86777
Overall Steps per Second: 9,266.90708

Timestep Collection Time: 4.66312
Timestep Consumption Time: 0.73566
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 5.39878

Cumulative Model Updates: 41,410
Cumulative Timesteps: 690,771,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 690771052...
Checkpoint 690771052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,728.17384
Policy Entropy: 1.11725
Value Function Loss: 5.18266

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.08909

Collected Steps per Second: 10,739.37573
Overall Steps per Second: 9,256.61581

Timestep Collection Time: 4.65576
Timestep Consumption Time: 0.74578
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 5.40154

Cumulative Model Updates: 41,413
Cumulative Timesteps: 690,821,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353,980.63683
Policy Entropy: 1.11895
Value Function Loss: 5.42475

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.07513

Collected Steps per Second: 11,064.79748
Overall Steps per Second: 9,499.36071

Timestep Collection Time: 4.51974
Timestep Consumption Time: 0.74483
PPO Batch Consumption Time: 0.03746
Total Iteration Time: 5.26456

Cumulative Model Updates: 41,416
Cumulative Timesteps: 690,871,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 690871062...
Checkpoint 690871062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,910.52540
Policy Entropy: 1.12428
Value Function Loss: 5.42422

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.08923

Collected Steps per Second: 11,231.02553
Overall Steps per Second: 9,547.04631

Timestep Collection Time: 4.45356
Timestep Consumption Time: 0.78555
PPO Batch Consumption Time: 0.03931
Total Iteration Time: 5.23911

Cumulative Model Updates: 41,419
Cumulative Timesteps: 690,921,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,409.52034
Policy Entropy: 1.11832
Value Function Loss: 5.68338

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.08632

Collected Steps per Second: 10,707.12982
Overall Steps per Second: 9,205.03878

Timestep Collection Time: 4.67277
Timestep Consumption Time: 0.76251
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.43528

Cumulative Model Updates: 41,422
Cumulative Timesteps: 690,971,112

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 690971112...
Checkpoint 690971112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,141.59629
Policy Entropy: 1.13106
Value Function Loss: 5.59896

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.07511

Collected Steps per Second: 10,600.28956
Overall Steps per Second: 9,249.26908

Timestep Collection Time: 4.71817
Timestep Consumption Time: 0.68917
PPO Batch Consumption Time: 0.03816
Total Iteration Time: 5.40735

Cumulative Model Updates: 41,425
Cumulative Timesteps: 691,021,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,006.76468
Policy Entropy: 1.12192
Value Function Loss: 5.89659

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.06482

Collected Steps per Second: 10,685.27806
Overall Steps per Second: 9,120.14306

Timestep Collection Time: 4.68083
Timestep Consumption Time: 0.80329
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.48412

Cumulative Model Updates: 41,428
Cumulative Timesteps: 691,071,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 691071142...
Checkpoint 691071142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,233.15203
Policy Entropy: 1.10460
Value Function Loss: 5.73130

Mean KL Divergence: 0.02651
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.05773
Value Function Update Magnitude: 0.05961

Collected Steps per Second: 10,793.81559
Overall Steps per Second: 9,370.31920

Timestep Collection Time: 4.63265
Timestep Consumption Time: 0.70377
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.33642

Cumulative Model Updates: 41,431
Cumulative Timesteps: 691,121,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400,291.45503
Policy Entropy: 1.10059
Value Function Loss: 5.61029

Mean KL Divergence: 0.02602
SB3 Clip Fraction: 0.16393
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.06252

Collected Steps per Second: 10,646.42044
Overall Steps per Second: 9,078.52895

Timestep Collection Time: 4.69679
Timestep Consumption Time: 0.81115
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.50794

Cumulative Model Updates: 41,434
Cumulative Timesteps: 691,171,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 691171150...
Checkpoint 691171150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,376.84721
Policy Entropy: 1.10368
Value Function Loss: 5.47456

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.06335

Collected Steps per Second: 10,901.56700
Overall Steps per Second: 9,477.43239

Timestep Collection Time: 4.58650
Timestep Consumption Time: 0.68919
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.27569

Cumulative Model Updates: 41,437
Cumulative Timesteps: 691,221,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,584.75463
Policy Entropy: 1.11435
Value Function Loss: 5.36806

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.06367

Collected Steps per Second: 10,892.43526
Overall Steps per Second: 9,316.46259

Timestep Collection Time: 4.59144
Timestep Consumption Time: 0.77669
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.36813

Cumulative Model Updates: 41,440
Cumulative Timesteps: 691,271,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 691271162...
Checkpoint 691271162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575,396.49104
Policy Entropy: 1.10067
Value Function Loss: 5.51220

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.06122

Collected Steps per Second: 10,792.55177
Overall Steps per Second: 9,274.23914

Timestep Collection Time: 4.63338
Timestep Consumption Time: 0.75854
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.39192

Cumulative Model Updates: 41,443
Cumulative Timesteps: 691,321,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,739.66591
Policy Entropy: 1.11348
Value Function Loss: 5.34935

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.06572

Collected Steps per Second: 11,266.70205
Overall Steps per Second: 9,808.94855

Timestep Collection Time: 4.43803
Timestep Consumption Time: 0.65956
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 5.09759

Cumulative Model Updates: 41,446
Cumulative Timesteps: 691,371,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 691371170...
Checkpoint 691371170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,982.61331
Policy Entropy: 1.12054
Value Function Loss: 5.74166

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.06852

Collected Steps per Second: 11,360.51904
Overall Steps per Second: 9,531.18246

Timestep Collection Time: 4.40209
Timestep Consumption Time: 0.84490
PPO Batch Consumption Time: 0.03802
Total Iteration Time: 5.24699

Cumulative Model Updates: 41,449
Cumulative Timesteps: 691,421,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,677.21376
Policy Entropy: 1.11719
Value Function Loss: 5.71680

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.09119

Collected Steps per Second: 11,098.54858
Overall Steps per Second: 9,480.32940

Timestep Collection Time: 4.50581
Timestep Consumption Time: 0.76911
PPO Batch Consumption Time: 0.03835
Total Iteration Time: 5.27492

Cumulative Model Updates: 41,452
Cumulative Timesteps: 691,471,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 691471188...
Checkpoint 691471188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,361.27577
Policy Entropy: 1.11370
Value Function Loss: 5.60137

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.06224
Value Function Update Magnitude: 0.08651

Collected Steps per Second: 11,619.10687
Overall Steps per Second: 9,869.53142

Timestep Collection Time: 4.30584
Timestep Consumption Time: 0.76330
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.06914

Cumulative Model Updates: 41,455
Cumulative Timesteps: 691,521,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,385.04235
Policy Entropy: 1.10368
Value Function Loss: 5.32681

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.07728

Collected Steps per Second: 10,893.25497
Overall Steps per Second: 9,186.65113

Timestep Collection Time: 4.59147
Timestep Consumption Time: 0.85296
PPO Batch Consumption Time: 0.03854
Total Iteration Time: 5.44442

Cumulative Model Updates: 41,458
Cumulative Timesteps: 691,571,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 691571234...
Checkpoint 691571234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,354.93988
Policy Entropy: 1.11866
Value Function Loss: 5.24701

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.06985

Collected Steps per Second: 11,059.55561
Overall Steps per Second: 9,545.16552

Timestep Collection Time: 4.52369
Timestep Consumption Time: 0.71771
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.24140

Cumulative Model Updates: 41,461
Cumulative Timesteps: 691,621,264

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,120.26425
Policy Entropy: 1.12005
Value Function Loss: 5.17807

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.07935

Collected Steps per Second: 11,355.09432
Overall Steps per Second: 9,664.97156

Timestep Collection Time: 4.40349
Timestep Consumption Time: 0.77004
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 5.17353

Cumulative Model Updates: 41,464
Cumulative Timesteps: 691,671,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 691671266...
Checkpoint 691671266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,095.25991
Policy Entropy: 1.12219
Value Function Loss: 5.15488

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.06516

Collected Steps per Second: 11,034.38366
Overall Steps per Second: 9,417.81596

Timestep Collection Time: 4.53202
Timestep Consumption Time: 0.77792
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 5.30994

Cumulative Model Updates: 41,467
Cumulative Timesteps: 691,721,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,200.55777
Policy Entropy: 1.10788
Value Function Loss: 5.22428

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.05766

Collected Steps per Second: 11,277.61953
Overall Steps per Second: 9,622.71849

Timestep Collection Time: 4.43587
Timestep Consumption Time: 0.76287
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.19874

Cumulative Model Updates: 41,470
Cumulative Timesteps: 691,771,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 691771300...
Checkpoint 691771300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,682.63599
Policy Entropy: 1.09901
Value Function Loss: 5.22941

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.05640

Collected Steps per Second: 11,119.10061
Overall Steps per Second: 9,437.20984

Timestep Collection Time: 4.49785
Timestep Consumption Time: 0.80160
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.29945

Cumulative Model Updates: 41,473
Cumulative Timesteps: 691,821,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,302.84886
Policy Entropy: 1.11662
Value Function Loss: 5.50987

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.05511

Collected Steps per Second: 10,641.41471
Overall Steps per Second: 9,260.54577

Timestep Collection Time: 4.69994
Timestep Consumption Time: 0.70082
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.40076

Cumulative Model Updates: 41,476
Cumulative Timesteps: 691,871,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 691871326...
Checkpoint 691871326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,848.97626
Policy Entropy: 1.12006
Value Function Loss: 5.42309

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.05798

Collected Steps per Second: 11,170.30771
Overall Steps per Second: 9,523.52681

Timestep Collection Time: 4.47758
Timestep Consumption Time: 0.77425
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.25184

Cumulative Model Updates: 41,479
Cumulative Timesteps: 691,921,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,197.14489
Policy Entropy: 1.10610
Value Function Loss: 5.70841

Mean KL Divergence: 0.02414
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 10,805.81700
Overall Steps per Second: 9,310.71889

Timestep Collection Time: 4.62973
Timestep Consumption Time: 0.74343
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.37316

Cumulative Model Updates: 41,482
Cumulative Timesteps: 691,971,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 691971370...
Checkpoint 691971370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,153.50685
Policy Entropy: 1.11153
Value Function Loss: 5.69118

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.06102

Collected Steps per Second: 10,869.97367
Overall Steps per Second: 9,374.87166

Timestep Collection Time: 4.60112
Timestep Consumption Time: 0.73378
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.33490

Cumulative Model Updates: 41,485
Cumulative Timesteps: 692,021,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,426.49851
Policy Entropy: 1.10802
Value Function Loss: 5.71710

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.06064

Collected Steps per Second: 11,233.41822
Overall Steps per Second: 9,572.13890

Timestep Collection Time: 4.45172
Timestep Consumption Time: 0.77261
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.22433

Cumulative Model Updates: 41,488
Cumulative Timesteps: 692,071,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 692071392...
Checkpoint 692071392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,504.82457
Policy Entropy: 1.11383
Value Function Loss: 5.74861

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 10,991.53391
Overall Steps per Second: 9,468.04725

Timestep Collection Time: 4.54950
Timestep Consumption Time: 0.73205
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.28155

Cumulative Model Updates: 41,491
Cumulative Timesteps: 692,121,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,448.57057
Policy Entropy: 1.10120
Value Function Loss: 5.39379

Mean KL Divergence: 0.02742
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.08887

Collected Steps per Second: 10,638.43817
Overall Steps per Second: 9,092.85392

Timestep Collection Time: 4.70125
Timestep Consumption Time: 0.79911
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.50036

Cumulative Model Updates: 41,494
Cumulative Timesteps: 692,171,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 692171412...
Checkpoint 692171412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,306.60528
Policy Entropy: 1.11091
Value Function Loss: 5.30088

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.09914

Collected Steps per Second: 10,781.18325
Overall Steps per Second: 9,264.76513

Timestep Collection Time: 4.63827
Timestep Consumption Time: 0.75917
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.39744

Cumulative Model Updates: 41,497
Cumulative Timesteps: 692,221,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,772.65234
Policy Entropy: 1.11511
Value Function Loss: 5.05080

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.08426

Collected Steps per Second: 11,122.45416
Overall Steps per Second: 9,687.33443

Timestep Collection Time: 4.49595
Timestep Consumption Time: 0.66605
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.16200

Cumulative Model Updates: 41,500
Cumulative Timesteps: 692,271,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 692271424...
Checkpoint 692271424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,534.14896
Policy Entropy: 1.11363
Value Function Loss: 5.01173

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.06297
Value Function Update Magnitude: 0.08080

Collected Steps per Second: 10,806.02269
Overall Steps per Second: 9,229.11550

Timestep Collection Time: 4.62834
Timestep Consumption Time: 0.79081
PPO Batch Consumption Time: 0.03781
Total Iteration Time: 5.41915

Cumulative Model Updates: 41,503
Cumulative Timesteps: 692,321,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427,312.69019
Policy Entropy: 1.11096
Value Function Loss: 5.36022

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.06359
Value Function Update Magnitude: 0.07279

Collected Steps per Second: 10,932.95783
Overall Steps per Second: 9,291.62883

Timestep Collection Time: 4.57552
Timestep Consumption Time: 0.80825
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.38377

Cumulative Model Updates: 41,506
Cumulative Timesteps: 692,371,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 692371462...
Checkpoint 692371462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,787.56709
Policy Entropy: 1.12631
Value Function Loss: 5.41123

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.07214

Collected Steps per Second: 10,785.68449
Overall Steps per Second: 9,082.39967

Timestep Collection Time: 4.63818
Timestep Consumption Time: 0.86983
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.50802

Cumulative Model Updates: 41,509
Cumulative Timesteps: 692,421,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,357.55532
Policy Entropy: 1.12870
Value Function Loss: 5.41732

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.07090

Collected Steps per Second: 11,516.28323
Overall Steps per Second: 9,663.54605

Timestep Collection Time: 4.34359
Timestep Consumption Time: 0.83277
PPO Batch Consumption Time: 0.03966
Total Iteration Time: 5.17636

Cumulative Model Updates: 41,512
Cumulative Timesteps: 692,471,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 692471510...
Checkpoint 692471510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,827.79547
Policy Entropy: 1.11811
Value Function Loss: 5.43792

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.06671

Collected Steps per Second: 11,669.79802
Overall Steps per Second: 9,961.23148

Timestep Collection Time: 4.28456
Timestep Consumption Time: 0.73490
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.01946

Cumulative Model Updates: 41,515
Cumulative Timesteps: 692,521,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,142.27708
Policy Entropy: 1.11500
Value Function Loss: 5.59988

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.06552
Value Function Update Magnitude: 0.07424

Collected Steps per Second: 12,165.11748
Overall Steps per Second: 9,966.91017

Timestep Collection Time: 4.11077
Timestep Consumption Time: 0.90663
PPO Batch Consumption Time: 0.04652
Total Iteration Time: 5.01740

Cumulative Model Updates: 41,518
Cumulative Timesteps: 692,571,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 692571518...
Checkpoint 692571518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,000.52681
Policy Entropy: 1.11427
Value Function Loss: 5.73096

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.08296

Collected Steps per Second: 12,235.32792
Overall Steps per Second: 10,438.79877

Timestep Collection Time: 4.08767
Timestep Consumption Time: 0.70349
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.79116

Cumulative Model Updates: 41,521
Cumulative Timesteps: 692,621,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,385.35151
Policy Entropy: 1.12548
Value Function Loss: 5.51100

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.08916

Collected Steps per Second: 12,101.69001
Overall Steps per Second: 10,207.20812

Timestep Collection Time: 4.13281
Timestep Consumption Time: 0.76706
PPO Batch Consumption Time: 0.03280
Total Iteration Time: 4.89987

Cumulative Model Updates: 41,524
Cumulative Timesteps: 692,671,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 692671546...
Checkpoint 692671546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410,155.30819
Policy Entropy: 1.12668
Value Function Loss: 5.31642

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.09143

Collected Steps per Second: 11,385.72601
Overall Steps per Second: 9,780.34821

Timestep Collection Time: 4.39181
Timestep Consumption Time: 0.72089
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.11270

Cumulative Model Updates: 41,527
Cumulative Timesteps: 692,721,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,189.36244
Policy Entropy: 1.12905
Value Function Loss: 5.15598

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.09916

Collected Steps per Second: 11,183.74532
Overall Steps per Second: 9,539.03917

Timestep Collection Time: 4.47310
Timestep Consumption Time: 0.77124
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.24434

Cumulative Model Updates: 41,530
Cumulative Timesteps: 692,771,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 692771576...
Checkpoint 692771576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,399.50765
Policy Entropy: 1.12814
Value Function Loss: 5.25465

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.09781

Collected Steps per Second: 11,352.02989
Overall Steps per Second: 9,712.39248

Timestep Collection Time: 4.40732
Timestep Consumption Time: 0.74404
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.15136

Cumulative Model Updates: 41,533
Cumulative Timesteps: 692,821,608

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,646.51519
Policy Entropy: 1.14562
Value Function Loss: 5.52887

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.08985

Collected Steps per Second: 11,108.23625
Overall Steps per Second: 9,523.72102

Timestep Collection Time: 4.50224
Timestep Consumption Time: 0.74906
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.25131

Cumulative Model Updates: 41,536
Cumulative Timesteps: 692,871,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 692871620...
Checkpoint 692871620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,216.06964
Policy Entropy: 1.14774
Value Function Loss: 5.54782

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.07814

Collected Steps per Second: 11,206.76264
Overall Steps per Second: 9,516.78598

Timestep Collection Time: 4.46391
Timestep Consumption Time: 0.79269
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.25661

Cumulative Model Updates: 41,539
Cumulative Timesteps: 692,921,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,177.14442
Policy Entropy: 1.13591
Value Function Loss: 5.57119

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.06387

Collected Steps per Second: 11,144.64270
Overall Steps per Second: 9,644.99695

Timestep Collection Time: 4.48933
Timestep Consumption Time: 0.69802
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.18735

Cumulative Model Updates: 41,542
Cumulative Timesteps: 692,971,678

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 692971678...
Checkpoint 692971678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,999.49487
Policy Entropy: 1.12599
Value Function Loss: 5.41995

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.05630

Collected Steps per Second: 10,922.16061
Overall Steps per Second: 9,382.92679

Timestep Collection Time: 4.57895
Timestep Consumption Time: 0.75116
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.33011

Cumulative Model Updates: 41,545
Cumulative Timesteps: 693,021,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427,038.11227
Policy Entropy: 1.13600
Value Function Loss: 5.55829

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.05718

Collected Steps per Second: 11,035.89756
Overall Steps per Second: 9,367.71168

Timestep Collection Time: 4.53139
Timestep Consumption Time: 0.80694
PPO Batch Consumption Time: 0.04104
Total Iteration Time: 5.33834

Cumulative Model Updates: 41,548
Cumulative Timesteps: 693,071,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 693071698...
Checkpoint 693071698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,180.49221
Policy Entropy: 1.14483
Value Function Loss: 5.60395

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.11422
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 10,948.61654
Overall Steps per Second: 9,485.83587

Timestep Collection Time: 4.56825
Timestep Consumption Time: 0.70446
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.27270

Cumulative Model Updates: 41,551
Cumulative Timesteps: 693,121,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451,524.26186
Policy Entropy: 1.11958
Value Function Loss: 5.65054

Mean KL Divergence: 0.03038
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.08436

Collected Steps per Second: 10,636.25361
Overall Steps per Second: 9,142.33792

Timestep Collection Time: 4.70335
Timestep Consumption Time: 0.76856
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 5.47190

Cumulative Model Updates: 41,554
Cumulative Timesteps: 693,171,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 693171740...
Checkpoint 693171740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,457.59088
Policy Entropy: 1.13927
Value Function Loss: 5.68955

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.10901

Collected Steps per Second: 10,845.53680
Overall Steps per Second: 9,343.06059

Timestep Collection Time: 4.61130
Timestep Consumption Time: 0.74155
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.35285

Cumulative Model Updates: 41,557
Cumulative Timesteps: 693,221,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,435.41152
Policy Entropy: 1.14250
Value Function Loss: 5.50509

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.11020

Collected Steps per Second: 11,440.77552
Overall Steps per Second: 9,744.99689

Timestep Collection Time: 4.37156
Timestep Consumption Time: 0.76072
PPO Batch Consumption Time: 0.04016
Total Iteration Time: 5.13227

Cumulative Model Updates: 41,560
Cumulative Timesteps: 693,271,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 693271766...
Checkpoint 693271766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,105.32262
Policy Entropy: 1.13434
Value Function Loss: 5.27154

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.10808

Collected Steps per Second: 10,661.79715
Overall Steps per Second: 9,178.56708

Timestep Collection Time: 4.68964
Timestep Consumption Time: 0.75783
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.44747

Cumulative Model Updates: 41,563
Cumulative Timesteps: 693,321,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,576.72506
Policy Entropy: 1.11949
Value Function Loss: 5.08430

Mean KL Divergence: 0.02764
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.11116

Collected Steps per Second: 10,645.77245
Overall Steps per Second: 9,244.02172

Timestep Collection Time: 4.69877
Timestep Consumption Time: 0.71251
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 5.41128

Cumulative Model Updates: 41,566
Cumulative Timesteps: 693,371,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 693371788...
Checkpoint 693371788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,399.55928
Policy Entropy: 1.13110
Value Function Loss: 5.07052

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.10784

Collected Steps per Second: 10,961.83554
Overall Steps per Second: 9,314.78022

Timestep Collection Time: 4.56310
Timestep Consumption Time: 0.80686
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.36996

Cumulative Model Updates: 41,569
Cumulative Timesteps: 693,421,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437,784.55191
Policy Entropy: 1.13509
Value Function Loss: 5.26142

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.08926

Collected Steps per Second: 10,905.47541
Overall Steps per Second: 9,288.42211

Timestep Collection Time: 4.58632
Timestep Consumption Time: 0.79845
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.38477

Cumulative Model Updates: 41,572
Cumulative Timesteps: 693,471,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 693471824...
Checkpoint 693471824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,359.45907
Policy Entropy: 1.12855
Value Function Loss: 5.14653

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.10096

Collected Steps per Second: 11,333.85579
Overall Steps per Second: 9,385.80509

Timestep Collection Time: 4.41174
Timestep Consumption Time: 0.91567
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.32741

Cumulative Model Updates: 41,575
Cumulative Timesteps: 693,521,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,519.06144
Policy Entropy: 1.12004
Value Function Loss: 5.10364

Mean KL Divergence: 0.02725
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.10579

Collected Steps per Second: 10,419.51179
Overall Steps per Second: 8,975.86075

Timestep Collection Time: 4.80061
Timestep Consumption Time: 0.77212
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.57272

Cumulative Model Updates: 41,578
Cumulative Timesteps: 693,571,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 693571846...
Checkpoint 693571846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,952.14301
Policy Entropy: 1.12775
Value Function Loss: 5.27580

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.11581

Collected Steps per Second: 11,272.68923
Overall Steps per Second: 9,767.70150

Timestep Collection Time: 4.43692
Timestep Consumption Time: 0.68363
PPO Batch Consumption Time: 0.03382
Total Iteration Time: 5.12055

Cumulative Model Updates: 41,581
Cumulative Timesteps: 693,621,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,551.18391
Policy Entropy: 1.13628
Value Function Loss: 5.38551

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.06228
Value Function Update Magnitude: 0.11753

Collected Steps per Second: 11,379.15588
Overall Steps per Second: 9,636.95746

Timestep Collection Time: 4.39593
Timestep Consumption Time: 0.79471
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.19064

Cumulative Model Updates: 41,584
Cumulative Timesteps: 693,671,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 693671884...
Checkpoint 693671884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,462.60362
Policy Entropy: 1.11844
Value Function Loss: 5.36886

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.11310

Collected Steps per Second: 11,302.39255
Overall Steps per Second: 9,606.44656

Timestep Collection Time: 4.42384
Timestep Consumption Time: 0.78100
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.20484

Cumulative Model Updates: 41,587
Cumulative Timesteps: 693,721,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,596.68420
Policy Entropy: 1.12924
Value Function Loss: 5.25970

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.11200

Collected Steps per Second: 11,841.04090
Overall Steps per Second: 9,790.32469

Timestep Collection Time: 4.22480
Timestep Consumption Time: 0.88494
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.10974

Cumulative Model Updates: 41,590
Cumulative Timesteps: 693,771,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 693771910...
Checkpoint 693771910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,471.89059
Policy Entropy: 1.12932
Value Function Loss: 5.31406

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.11046

Collected Steps per Second: 11,489.72498
Overall Steps per Second: 9,816.15544

Timestep Collection Time: 4.35258
Timestep Consumption Time: 0.74208
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 5.09466

Cumulative Model Updates: 41,593
Cumulative Timesteps: 693,821,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,957.40153
Policy Entropy: 1.12505
Value Function Loss: 5.37212

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.11322

Collected Steps per Second: 11,028.56315
Overall Steps per Second: 9,569.52522

Timestep Collection Time: 4.53423
Timestep Consumption Time: 0.69132
PPO Batch Consumption Time: 0.03927
Total Iteration Time: 5.22555

Cumulative Model Updates: 41,596
Cumulative Timesteps: 693,871,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 693871926...
Checkpoint 693871926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,383.84635
Policy Entropy: 1.11566
Value Function Loss: 5.43113

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.06345
Value Function Update Magnitude: 0.09938

Collected Steps per Second: 11,017.50005
Overall Steps per Second: 9,351.81141

Timestep Collection Time: 4.54005
Timestep Consumption Time: 0.80865
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.34870

Cumulative Model Updates: 41,599
Cumulative Timesteps: 693,921,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,732.79305
Policy Entropy: 1.10956
Value Function Loss: 5.35062

Mean KL Divergence: 0.02216
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 11,308.19268
Overall Steps per Second: 9,476.58254

Timestep Collection Time: 4.42228
Timestep Consumption Time: 0.85473
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.27701

Cumulative Model Updates: 41,602
Cumulative Timesteps: 693,971,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 693971954...
Checkpoint 693971954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,304.19468
Policy Entropy: 1.12756
Value Function Loss: 5.51632

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.08070

Collected Steps per Second: 10,775.73302
Overall Steps per Second: 9,222.53230

Timestep Collection Time: 4.64265
Timestep Consumption Time: 0.78189
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.42454

Cumulative Model Updates: 41,605
Cumulative Timesteps: 694,021,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,915.15504
Policy Entropy: 1.12907
Value Function Loss: 5.22847

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.08504

Collected Steps per Second: 11,224.97588
Overall Steps per Second: 9,566.90071

Timestep Collection Time: 4.45542
Timestep Consumption Time: 0.77219
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 5.22761

Cumulative Model Updates: 41,608
Cumulative Timesteps: 694,071,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 694071994...
Checkpoint 694071994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,199.40669
Policy Entropy: 1.11236
Value Function Loss: 5.18930

Mean KL Divergence: 0.02517
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.08756

Collected Steps per Second: 11,161.97051
Overall Steps per Second: 9,552.24811

Timestep Collection Time: 4.47950
Timestep Consumption Time: 0.75487
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.23437

Cumulative Model Updates: 41,611
Cumulative Timesteps: 694,121,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,063.96514
Policy Entropy: 1.11938
Value Function Loss: 5.09605

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.08328

Collected Steps per Second: 10,944.69279
Overall Steps per Second: 9,337.35991

Timestep Collection Time: 4.57062
Timestep Consumption Time: 0.78679
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.35740

Cumulative Model Updates: 41,614
Cumulative Timesteps: 694,172,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 694172018...
Checkpoint 694172018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,512.15482
Policy Entropy: 1.12312
Value Function Loss: 5.46258

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.08566

Collected Steps per Second: 10,768.64110
Overall Steps per Second: 9,228.41467

Timestep Collection Time: 4.64404
Timestep Consumption Time: 0.77509
PPO Batch Consumption Time: 0.04172
Total Iteration Time: 5.41913

Cumulative Model Updates: 41,617
Cumulative Timesteps: 694,222,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,095.84547
Policy Entropy: 1.10769
Value Function Loss: 5.76406

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.07672

Collected Steps per Second: 11,017.43246
Overall Steps per Second: 9,443.63221

Timestep Collection Time: 4.53917
Timestep Consumption Time: 0.75646
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.29563

Cumulative Model Updates: 41,620
Cumulative Timesteps: 694,272,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 694272038...
Checkpoint 694272038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,295.72747
Policy Entropy: 1.10839
Value Function Loss: 5.51978

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.08980

Collected Steps per Second: 10,833.41059
Overall Steps per Second: 9,335.71444

Timestep Collection Time: 4.61535
Timestep Consumption Time: 0.74042
PPO Batch Consumption Time: 0.03895
Total Iteration Time: 5.35578

Cumulative Model Updates: 41,623
Cumulative Timesteps: 694,322,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,758.87744
Policy Entropy: 1.10988
Value Function Loss: 5.50291

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.15571
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.09036

Collected Steps per Second: 10,952.94400
Overall Steps per Second: 9,486.09640

Timestep Collection Time: 4.56754
Timestep Consumption Time: 0.70628
PPO Batch Consumption Time: 0.03916
Total Iteration Time: 5.27382

Cumulative Model Updates: 41,626
Cumulative Timesteps: 694,372,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 694372066...
Checkpoint 694372066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,054.69402
Policy Entropy: 1.10505
Value Function Loss: 5.38574

Mean KL Divergence: 0.03515
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.10821

Collected Steps per Second: 10,557.08299
Overall Steps per Second: 9,066.49463

Timestep Collection Time: 4.73673
Timestep Consumption Time: 0.77875
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 5.51547

Cumulative Model Updates: 41,629
Cumulative Timesteps: 694,422,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,413.46712
Policy Entropy: 1.11831
Value Function Loss: 5.62365

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.11694

Collected Steps per Second: 10,700.80149
Overall Steps per Second: 9,280.84392

Timestep Collection Time: 4.67292
Timestep Consumption Time: 0.71495
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.38787

Cumulative Model Updates: 41,632
Cumulative Timesteps: 694,472,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 694472076...
Checkpoint 694472076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,208.12879
Policy Entropy: 1.10948
Value Function Loss: 5.40141

Mean KL Divergence: 0.02816
SB3 Clip Fraction: 0.14418
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 10,737.03242
Overall Steps per Second: 9,168.94277

Timestep Collection Time: 4.65939
Timestep Consumption Time: 0.79686
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.45625

Cumulative Model Updates: 41,635
Cumulative Timesteps: 694,522,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,528.91217
Policy Entropy: 1.11717
Value Function Loss: 5.40501

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.12557

Collected Steps per Second: 10,830.95778
Overall Steps per Second: 9,249.22118

Timestep Collection Time: 4.61769
Timestep Consumption Time: 0.78968
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.40737

Cumulative Model Updates: 41,638
Cumulative Timesteps: 694,572,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 694572118...
Checkpoint 694572118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,198.94383
Policy Entropy: 1.11879
Value Function Loss: 5.05386

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.11331

Collected Steps per Second: 10,929.98864
Overall Steps per Second: 9,228.77973

Timestep Collection Time: 4.57640
Timestep Consumption Time: 0.84360
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.42000

Cumulative Model Updates: 41,641
Cumulative Timesteps: 694,622,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,319.27826
Policy Entropy: 1.12618
Value Function Loss: 5.18503

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.06649
Value Function Update Magnitude: 0.09874

Collected Steps per Second: 10,789.86878
Overall Steps per Second: 9,165.87412

Timestep Collection Time: 4.63602
Timestep Consumption Time: 0.82140
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.45742

Cumulative Model Updates: 41,644
Cumulative Timesteps: 694,672,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 694672160...
Checkpoint 694672160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,269.90676
Policy Entropy: 1.12589
Value Function Loss: 5.08314

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12026
Policy Update Magnitude: 0.07160
Value Function Update Magnitude: 0.09139

Collected Steps per Second: 10,977.74933
Overall Steps per Second: 9,283.84729

Timestep Collection Time: 4.55704
Timestep Consumption Time: 0.83146
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 5.38850

Cumulative Model Updates: 41,647
Cumulative Timesteps: 694,722,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,522.35577
Policy Entropy: 1.12357
Value Function Loss: 5.33354

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.10632

Collected Steps per Second: 12,286.09160
Overall Steps per Second: 10,266.71245

Timestep Collection Time: 4.07143
Timestep Consumption Time: 0.80082
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 4.87225

Cumulative Model Updates: 41,650
Cumulative Timesteps: 694,772,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 694772208...
Checkpoint 694772208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,611.87617
Policy Entropy: 1.12789
Value Function Loss: 5.27605

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.11095

Collected Steps per Second: 11,816.31786
Overall Steps per Second: 9,903.72143

Timestep Collection Time: 4.23347
Timestep Consumption Time: 0.81756
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 5.05103

Cumulative Model Updates: 41,653
Cumulative Timesteps: 694,822,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,182.17957
Policy Entropy: 1.12428
Value Function Loss: 5.45079

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.09674

Collected Steps per Second: 11,865.77737
Overall Steps per Second: 10,196.54681

Timestep Collection Time: 4.21532
Timestep Consumption Time: 0.69007
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.90539

Cumulative Model Updates: 41,656
Cumulative Timesteps: 694,872,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 694872250...
Checkpoint 694872250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,184.66555
Policy Entropy: 1.13008
Value Function Loss: 5.26569

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.08472

Collected Steps per Second: 11,624.56032
Overall Steps per Second: 9,786.56723

Timestep Collection Time: 4.30141
Timestep Consumption Time: 0.80784
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.10925

Cumulative Model Updates: 41,659
Cumulative Timesteps: 694,922,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,178.64130
Policy Entropy: 1.12185
Value Function Loss: 5.63132

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 11,919.99280
Overall Steps per Second: 10,053.54415

Timestep Collection Time: 4.19698
Timestep Consumption Time: 0.77917
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.97616

Cumulative Model Updates: 41,662
Cumulative Timesteps: 694,972,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 694972280...
Checkpoint 694972280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,865.23060
Policy Entropy: 1.12152
Value Function Loss: 5.60895

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.07636

Collected Steps per Second: 11,425.44282
Overall Steps per Second: 9,685.86512

Timestep Collection Time: 4.37620
Timestep Consumption Time: 0.78596
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.16216

Cumulative Model Updates: 41,665
Cumulative Timesteps: 695,022,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,966.32753
Policy Entropy: 1.12890
Value Function Loss: 5.64552

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.07714

Collected Steps per Second: 11,272.23163
Overall Steps per Second: 9,540.71841

Timestep Collection Time: 4.43763
Timestep Consumption Time: 0.80537
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.24300

Cumulative Model Updates: 41,668
Cumulative Timesteps: 695,072,302

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 695072302...
Checkpoint 695072302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,940.25798
Policy Entropy: 1.13269
Value Function Loss: 5.44716

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.07105

Collected Steps per Second: 11,292.64285
Overall Steps per Second: 9,789.26819

Timestep Collection Time: 4.42766
Timestep Consumption Time: 0.67997
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 5.10763

Cumulative Model Updates: 41,671
Cumulative Timesteps: 695,122,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,044.34319
Policy Entropy: 1.14274
Value Function Loss: 5.24903

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.08540

Collected Steps per Second: 11,187.76003
Overall Steps per Second: 9,511.78720

Timestep Collection Time: 4.47167
Timestep Consumption Time: 0.78791
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.25958

Cumulative Model Updates: 41,674
Cumulative Timesteps: 695,172,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 695172330...
Checkpoint 695172330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,143.80588
Policy Entropy: 1.13247
Value Function Loss: 5.37401

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.08037

Collected Steps per Second: 11,022.78128
Overall Steps per Second: 9,251.23952

Timestep Collection Time: 4.53842
Timestep Consumption Time: 0.86907
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 5.40749

Cumulative Model Updates: 41,677
Cumulative Timesteps: 695,222,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,687.78701
Policy Entropy: 1.14460
Value Function Loss: 5.44951

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.07854

Collected Steps per Second: 10,688.31268
Overall Steps per Second: 9,118.71695

Timestep Collection Time: 4.68025
Timestep Consumption Time: 0.80561
PPO Batch Consumption Time: 0.04001
Total Iteration Time: 5.48586

Cumulative Model Updates: 41,680
Cumulative Timesteps: 695,272,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 695272380...
Checkpoint 695272380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,050.57869
Policy Entropy: 1.14928
Value Function Loss: 5.52387

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.07261

Collected Steps per Second: 11,024.24348
Overall Steps per Second: 9,292.99607

Timestep Collection Time: 4.53637
Timestep Consumption Time: 0.84511
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 5.38147

Cumulative Model Updates: 41,683
Cumulative Timesteps: 695,322,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,685.33760
Policy Entropy: 1.13345
Value Function Loss: 5.49440

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.06052

Collected Steps per Second: 10,993.43404
Overall Steps per Second: 9,548.28981

Timestep Collection Time: 4.54835
Timestep Consumption Time: 0.68840
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.23675

Cumulative Model Updates: 41,686
Cumulative Timesteps: 695,372,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 695372392...
Checkpoint 695372392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,210.09374
Policy Entropy: 1.12316
Value Function Loss: 5.54388

Mean KL Divergence: 0.02741
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.05319

Collected Steps per Second: 11,056.13800
Overall Steps per Second: 9,407.37949

Timestep Collection Time: 4.52274
Timestep Consumption Time: 0.79267
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.31540

Cumulative Model Updates: 41,689
Cumulative Timesteps: 695,422,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439,541.00475
Policy Entropy: 1.13301
Value Function Loss: 5.51938

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.05355

Collected Steps per Second: 10,864.71932
Overall Steps per Second: 9,350.94860

Timestep Collection Time: 4.60205
Timestep Consumption Time: 0.74500
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.34705

Cumulative Model Updates: 41,692
Cumulative Timesteps: 695,472,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 695472396...
Checkpoint 695472396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,499.28089
Policy Entropy: 1.14202
Value Function Loss: 5.47752

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.05431

Collected Steps per Second: 10,934.37180
Overall Steps per Second: 9,421.79701

Timestep Collection Time: 4.57457
Timestep Consumption Time: 0.73440
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 5.30897

Cumulative Model Updates: 41,695
Cumulative Timesteps: 695,522,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,450.24959
Policy Entropy: 1.13024
Value Function Loss: 5.18149

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.05789

Collected Steps per Second: 10,545.32303
Overall Steps per Second: 9,061.24212

Timestep Collection Time: 4.74163
Timestep Consumption Time: 0.77660
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.51823

Cumulative Model Updates: 41,698
Cumulative Timesteps: 695,572,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 695572418...
Checkpoint 695572418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380,705.07940
Policy Entropy: 1.12779
Value Function Loss: 5.14731

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.06141

Collected Steps per Second: 10,825.37933
Overall Steps per Second: 9,407.47485

Timestep Collection Time: 4.62025
Timestep Consumption Time: 0.69637
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.31662

Cumulative Model Updates: 41,701
Cumulative Timesteps: 695,622,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,720.06862
Policy Entropy: 1.13113
Value Function Loss: 5.20596

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.06225

Collected Steps per Second: 10,998.20941
Overall Steps per Second: 9,358.63739

Timestep Collection Time: 4.54856
Timestep Consumption Time: 0.79688
PPO Batch Consumption Time: 0.04374
Total Iteration Time: 5.34544

Cumulative Model Updates: 41,704
Cumulative Timesteps: 695,672,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 695672460...
Checkpoint 695672460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338,709.18677
Policy Entropy: 1.13152
Value Function Loss: 5.21360

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.07651

Collected Steps per Second: 10,729.79353
Overall Steps per Second: 9,232.24325

Timestep Collection Time: 4.66085
Timestep Consumption Time: 0.75603
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.41688

Cumulative Model Updates: 41,707
Cumulative Timesteps: 695,722,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,440.05769
Policy Entropy: 1.12832
Value Function Loss: 5.20698

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.06355
Value Function Update Magnitude: 0.08278

Collected Steps per Second: 11,125.53046
Overall Steps per Second: 9,387.89946

Timestep Collection Time: 4.49435
Timestep Consumption Time: 0.83187
PPO Batch Consumption Time: 0.04051
Total Iteration Time: 5.32622

Cumulative Model Updates: 41,710
Cumulative Timesteps: 695,772,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 695772472...
Checkpoint 695772472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,851.32849
Policy Entropy: 1.12088
Value Function Loss: 5.23645

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.07693

Collected Steps per Second: 10,522.47315
Overall Steps per Second: 8,919.74755

Timestep Collection Time: 4.75249
Timestep Consumption Time: 0.85394
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.60644

Cumulative Model Updates: 41,713
Cumulative Timesteps: 695,822,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,609.13113
Policy Entropy: 1.12478
Value Function Loss: 5.44463

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.08284

Collected Steps per Second: 11,008.43848
Overall Steps per Second: 9,546.32122

Timestep Collection Time: 4.54233
Timestep Consumption Time: 0.69571
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.23804

Cumulative Model Updates: 41,716
Cumulative Timesteps: 695,872,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 695872484...
Checkpoint 695872484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,523.53604
Policy Entropy: 1.12328
Value Function Loss: 5.49267

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.08040

Collected Steps per Second: 11,492.08355
Overall Steps per Second: 9,717.30390

Timestep Collection Time: 4.35221
Timestep Consumption Time: 0.79489
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.14711

Cumulative Model Updates: 41,719
Cumulative Timesteps: 695,922,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,758.28499
Policy Entropy: 1.12725
Value Function Loss: 5.62518

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.08168

Collected Steps per Second: 11,482.99024
Overall Steps per Second: 9,932.67713

Timestep Collection Time: 4.35618
Timestep Consumption Time: 0.67992
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.03610

Cumulative Model Updates: 41,722
Cumulative Timesteps: 695,972,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 695972522...
Checkpoint 695972522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,927.08127
Policy Entropy: 1.12058
Value Function Loss: 5.45392

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.06844

Collected Steps per Second: 10,985.66520
Overall Steps per Second: 9,367.92861

Timestep Collection Time: 4.55157
Timestep Consumption Time: 0.78600
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.33757

Cumulative Model Updates: 41,725
Cumulative Timesteps: 696,022,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,869.15478
Policy Entropy: 1.11888
Value Function Loss: 5.49913

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.05742

Collected Steps per Second: 11,372.83470
Overall Steps per Second: 9,718.06250

Timestep Collection Time: 4.39679
Timestep Consumption Time: 0.74868
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.14547

Cumulative Model Updates: 41,728
Cumulative Timesteps: 696,072,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 696072528...
Checkpoint 696072528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,347.58832
Policy Entropy: 1.12972
Value Function Loss: 5.52556

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 10,995.31252
Overall Steps per Second: 9,352.59222

Timestep Collection Time: 4.54939
Timestep Consumption Time: 0.79907
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.34846

Cumulative Model Updates: 41,731
Cumulative Timesteps: 696,122,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,961.17865
Policy Entropy: 1.14055
Value Function Loss: 5.78701

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.06100

Collected Steps per Second: 11,397.53603
Overall Steps per Second: 9,681.59110

Timestep Collection Time: 4.38832
Timestep Consumption Time: 0.77778
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.16609

Cumulative Model Updates: 41,734
Cumulative Timesteps: 696,172,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 696172566...
Checkpoint 696172566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417,426.03188
Policy Entropy: 1.12657
Value Function Loss: 5.95528

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 11,269.69730
Overall Steps per Second: 9,747.67531

Timestep Collection Time: 4.43774
Timestep Consumption Time: 0.69292
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.13066

Cumulative Model Updates: 41,737
Cumulative Timesteps: 696,222,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,229.80600
Policy Entropy: 1.11654
Value Function Loss: 5.68975

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.05075

Collected Steps per Second: 11,247.93981
Overall Steps per Second: 9,522.34566

Timestep Collection Time: 4.44704
Timestep Consumption Time: 0.80587
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.25291

Cumulative Model Updates: 41,740
Cumulative Timesteps: 696,272,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 696272598...
Checkpoint 696272598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,211.86879
Policy Entropy: 1.12746
Value Function Loss: 5.34716

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.05095

Collected Steps per Second: 11,120.27761
Overall Steps per Second: 9,526.70595

Timestep Collection Time: 4.49863
Timestep Consumption Time: 0.75250
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.25113

Cumulative Model Updates: 41,743
Cumulative Timesteps: 696,322,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,613.08523
Policy Entropy: 1.13538
Value Function Loss: 5.19409

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.06397

Collected Steps per Second: 11,248.71231
Overall Steps per Second: 9,553.18866

Timestep Collection Time: 4.44673
Timestep Consumption Time: 0.78922
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.23595

Cumulative Model Updates: 41,746
Cumulative Timesteps: 696,372,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 696372644...
Checkpoint 696372644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,995.22380
Policy Entropy: 1.11507
Value Function Loss: 5.39741

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.07964

Collected Steps per Second: 10,521.43803
Overall Steps per Second: 9,106.33497

Timestep Collection Time: 4.75391
Timestep Consumption Time: 0.73875
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.49266

Cumulative Model Updates: 41,749
Cumulative Timesteps: 696,422,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,994.00225
Policy Entropy: 1.12560
Value Function Loss: 5.61127

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 11,170.29658
Overall Steps per Second: 9,711.17137

Timestep Collection Time: 4.47813
Timestep Consumption Time: 0.67285
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.15097

Cumulative Model Updates: 41,752
Cumulative Timesteps: 696,472,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 696472684...
Checkpoint 696472684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,302.12803
Policy Entropy: 1.12930
Value Function Loss: 5.62446

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.07872

Collected Steps per Second: 10,877.71623
Overall Steps per Second: 9,347.51857

Timestep Collection Time: 4.59692
Timestep Consumption Time: 0.75252
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.34944

Cumulative Model Updates: 41,755
Cumulative Timesteps: 696,522,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,171.53371
Policy Entropy: 1.13704
Value Function Loss: 5.52498

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.07038
Value Function Update Magnitude: 0.08249

Collected Steps per Second: 11,209.54340
Overall Steps per Second: 9,700.08859

Timestep Collection Time: 4.46156
Timestep Consumption Time: 0.69427
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.15583

Cumulative Model Updates: 41,758
Cumulative Timesteps: 696,572,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 696572700...
Checkpoint 696572700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398,136.70472
Policy Entropy: 1.13008
Value Function Loss: 5.39581

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.07412

Collected Steps per Second: 10,866.78281
Overall Steps per Second: 9,319.37742

Timestep Collection Time: 4.60228
Timestep Consumption Time: 0.76417
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.36645

Cumulative Model Updates: 41,761
Cumulative Timesteps: 696,622,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,986.54829
Policy Entropy: 1.12326
Value Function Loss: 5.21792

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.07542
Value Function Update Magnitude: 0.08976

Collected Steps per Second: 11,104.31429
Overall Steps per Second: 9,416.68919

Timestep Collection Time: 4.50456
Timestep Consumption Time: 0.80729
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.31185

Cumulative Model Updates: 41,764
Cumulative Timesteps: 696,672,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 696672732...
Checkpoint 696672732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,298.58630
Policy Entropy: 1.11347
Value Function Loss: 5.24098

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.06667
Value Function Update Magnitude: 0.09879

Collected Steps per Second: 10,691.91170
Overall Steps per Second: 9,213.60641

Timestep Collection Time: 4.67812
Timestep Consumption Time: 0.75059
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.42871

Cumulative Model Updates: 41,767
Cumulative Timesteps: 696,722,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,159.07237
Policy Entropy: 1.13068
Value Function Loss: 5.24400

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.08487

Collected Steps per Second: 10,653.00747
Overall Steps per Second: 9,049.80584

Timestep Collection Time: 4.69595
Timestep Consumption Time: 0.83190
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.52785

Cumulative Model Updates: 41,770
Cumulative Timesteps: 696,772,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 696772776...
Checkpoint 696772776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,025.02127
Policy Entropy: 1.13629
Value Function Loss: 5.14458

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.07772

Collected Steps per Second: 10,817.26715
Overall Steps per Second: 9,392.98025

Timestep Collection Time: 4.62483
Timestep Consumption Time: 0.70128
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.32611

Cumulative Model Updates: 41,773
Cumulative Timesteps: 696,822,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,668.30497
Policy Entropy: 1.12569
Value Function Loss: 5.25443

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.06150
Value Function Update Magnitude: 0.07713

Collected Steps per Second: 11,097.77081
Overall Steps per Second: 9,444.55034

Timestep Collection Time: 4.50631
Timestep Consumption Time: 0.78881
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.29512

Cumulative Model Updates: 41,776
Cumulative Timesteps: 696,872,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 696872814...
Checkpoint 696872814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,293.25351
Policy Entropy: 1.11237
Value Function Loss: 5.15731

Mean KL Divergence: 0.03005
SB3 Clip Fraction: 0.16398
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.08062

Collected Steps per Second: 10,897.66550
Overall Steps per Second: 9,329.67326

Timestep Collection Time: 4.58869
Timestep Consumption Time: 0.77120
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.35989

Cumulative Model Updates: 41,779
Cumulative Timesteps: 696,922,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,509.78358
Policy Entropy: 1.12379
Value Function Loss: 5.38658

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.08041

Collected Steps per Second: 10,532.36977
Overall Steps per Second: 9,181.42487

Timestep Collection Time: 4.74955
Timestep Consumption Time: 0.69884
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.44839

Cumulative Model Updates: 41,782
Cumulative Timesteps: 696,972,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 696972844...
Checkpoint 696972844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,842.83250
Policy Entropy: 1.13380
Value Function Loss: 5.07720

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.07758

Collected Steps per Second: 11,854.67429
Overall Steps per Second: 9,991.70880

Timestep Collection Time: 4.21994
Timestep Consumption Time: 0.78681
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.00675

Cumulative Model Updates: 41,785
Cumulative Timesteps: 697,022,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374,621.11725
Policy Entropy: 1.10887
Value Function Loss: 5.36529

Mean KL Divergence: 0.02679
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.07216

Collected Steps per Second: 11,937.20685
Overall Steps per Second: 10,102.75626

Timestep Collection Time: 4.19076
Timestep Consumption Time: 0.76096
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 4.95172

Cumulative Model Updates: 41,788
Cumulative Timesteps: 697,072,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 697072896...
Checkpoint 697072896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,521.29372
Policy Entropy: 1.12239
Value Function Loss: 5.30002

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 12,228.90274
Overall Steps per Second: 10,200.40115

Timestep Collection Time: 4.08982
Timestep Consumption Time: 0.81332
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 4.90314

Cumulative Model Updates: 41,791
Cumulative Timesteps: 697,122,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,231.61593
Policy Entropy: 1.12346
Value Function Loss: 5.55355

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.07799

Collected Steps per Second: 11,977.13561
Overall Steps per Second: 10,057.26604

Timestep Collection Time: 4.17512
Timestep Consumption Time: 0.79700
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 4.97213

Cumulative Model Updates: 41,794
Cumulative Timesteps: 697,172,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 697172916...
Checkpoint 697172916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,325.72686
Policy Entropy: 1.11382
Value Function Loss: 5.53573

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.07072

Collected Steps per Second: 11,747.85152
Overall Steps per Second: 10,077.03359

Timestep Collection Time: 4.25814
Timestep Consumption Time: 0.70602
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.96416

Cumulative Model Updates: 41,797
Cumulative Timesteps: 697,222,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,541.62180
Policy Entropy: 1.10648
Value Function Loss: 5.23755

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.15734
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.06653

Collected Steps per Second: 11,440.47639
Overall Steps per Second: 9,671.76751

Timestep Collection Time: 4.37167
Timestep Consumption Time: 0.79946
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.17113

Cumulative Model Updates: 41,800
Cumulative Timesteps: 697,272,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 697272954...
Checkpoint 697272954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,050.58332
Policy Entropy: 1.11864
Value Function Loss: 5.24823

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.06487

Collected Steps per Second: 11,086.69465
Overall Steps per Second: 9,420.10450

Timestep Collection Time: 4.51226
Timestep Consumption Time: 0.79830
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.31056

Cumulative Model Updates: 41,803
Cumulative Timesteps: 697,322,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,267.39172
Policy Entropy: 1.12142
Value Function Loss: 5.19485

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.06761

Collected Steps per Second: 11,577.13723
Overall Steps per Second: 9,785.80778

Timestep Collection Time: 4.32145
Timestep Consumption Time: 0.79106
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.11251

Cumulative Model Updates: 41,806
Cumulative Timesteps: 697,373,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 697373010...
Checkpoint 697373010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,148.73974
Policy Entropy: 1.10673
Value Function Loss: 5.58411

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.08244

Collected Steps per Second: 11,197.07624
Overall Steps per Second: 9,568.21324

Timestep Collection Time: 4.46724
Timestep Consumption Time: 0.76049
PPO Batch Consumption Time: 0.03769
Total Iteration Time: 5.22773

Cumulative Model Updates: 41,809
Cumulative Timesteps: 697,423,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,418.13346
Policy Entropy: 1.10330
Value Function Loss: 5.54199

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.08774

Collected Steps per Second: 11,340.28353
Overall Steps per Second: 9,839.84258

Timestep Collection Time: 4.41065
Timestep Consumption Time: 0.67256
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.08321

Cumulative Model Updates: 41,812
Cumulative Timesteps: 697,473,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 697473048...
Checkpoint 697473048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,087.08256
Policy Entropy: 1.11404
Value Function Loss: 5.56626

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.09141

Collected Steps per Second: 10,930.14794
Overall Steps per Second: 9,268.84307

Timestep Collection Time: 4.57450
Timestep Consumption Time: 0.81991
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.39442

Cumulative Model Updates: 41,815
Cumulative Timesteps: 697,523,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,745.79040
Policy Entropy: 1.12451
Value Function Loss: 5.19755

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.09776

Collected Steps per Second: 10,566.90651
Overall Steps per Second: 9,149.54855

Timestep Collection Time: 4.73365
Timestep Consumption Time: 0.73329
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.46694

Cumulative Model Updates: 41,818
Cumulative Timesteps: 697,573,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 697573068...
Checkpoint 697573068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,624.19826
Policy Entropy: 1.10158
Value Function Loss: 5.02060

Mean KL Divergence: 0.02785
SB3 Clip Fraction: 0.16496
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.09865

Collected Steps per Second: 11,137.03573
Overall Steps per Second: 9,539.74534

Timestep Collection Time: 4.49114
Timestep Consumption Time: 0.75198
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.24312

Cumulative Model Updates: 41,821
Cumulative Timesteps: 697,623,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,762.60094
Policy Entropy: 1.11426
Value Function Loss: 4.80081

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.09040

Collected Steps per Second: 11,168.99714
Overall Steps per Second: 9,550.39421

Timestep Collection Time: 4.47918
Timestep Consumption Time: 0.75913
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.23832

Cumulative Model Updates: 41,824
Cumulative Timesteps: 697,673,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 697673114...
Checkpoint 697673114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,241.91523
Policy Entropy: 1.10168
Value Function Loss: 4.93861

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.08402

Collected Steps per Second: 11,062.20939
Overall Steps per Second: 9,594.83285

Timestep Collection Time: 4.52188
Timestep Consumption Time: 0.69155
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.21343

Cumulative Model Updates: 41,827
Cumulative Timesteps: 697,723,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,960.01933
Policy Entropy: 1.09700
Value Function Loss: 5.22924

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.09891

Collected Steps per Second: 10,301.53575
Overall Steps per Second: 8,797.58227

Timestep Collection Time: 4.85559
Timestep Consumption Time: 0.83007
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.68565

Cumulative Model Updates: 41,830
Cumulative Timesteps: 697,773,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 697773156...
Checkpoint 697773156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,290.56469
Policy Entropy: 1.08476
Value Function Loss: 5.49782

Mean KL Divergence: 0.02979
SB3 Clip Fraction: 0.19189
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.09872

Collected Steps per Second: 10,643.42653
Overall Steps per Second: 9,021.39657

Timestep Collection Time: 4.69867
Timestep Consumption Time: 0.84481
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 5.54349

Cumulative Model Updates: 41,833
Cumulative Timesteps: 697,823,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,640.09597
Policy Entropy: 1.09282
Value Function Loss: 5.58894

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.08696

Collected Steps per Second: 11,105.98336
Overall Steps per Second: 9,504.52620

Timestep Collection Time: 4.50208
Timestep Consumption Time: 0.75857
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.26065

Cumulative Model Updates: 41,836
Cumulative Timesteps: 697,873,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 697873166...
Checkpoint 697873166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,832.68578
Policy Entropy: 1.10067
Value Function Loss: 5.55456

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.08813

Collected Steps per Second: 11,051.99517
Overall Steps per Second: 9,414.78833

Timestep Collection Time: 4.52660
Timestep Consumption Time: 0.78716
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.31377

Cumulative Model Updates: 41,839
Cumulative Timesteps: 697,923,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,229.43106
Policy Entropy: 1.07779
Value Function Loss: 5.64251

Mean KL Divergence: 0.02568
SB3 Clip Fraction: 0.15392
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.10361

Collected Steps per Second: 10,772.25832
Overall Steps per Second: 9,286.48098

Timestep Collection Time: 4.64285
Timestep Consumption Time: 0.74283
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 5.38568

Cumulative Model Updates: 41,842
Cumulative Timesteps: 697,973,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 697973208...
Checkpoint 697973208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,264.32403
Policy Entropy: 1.08677
Value Function Loss: 5.62655

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.14932
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.09380

Collected Steps per Second: 10,875.03339
Overall Steps per Second: 9,322.09535

Timestep Collection Time: 4.59934
Timestep Consumption Time: 0.76619
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.36553

Cumulative Model Updates: 41,845
Cumulative Timesteps: 698,023,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,031.47096
Policy Entropy: 1.08803
Value Function Loss: 5.46107

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.08538

Collected Steps per Second: 10,824.12800
Overall Steps per Second: 9,298.10204

Timestep Collection Time: 4.62097
Timestep Consumption Time: 0.75840
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.37938

Cumulative Model Updates: 41,848
Cumulative Timesteps: 698,073,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 698073244...
Checkpoint 698073244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,480.31826
Policy Entropy: 1.08620
Value Function Loss: 5.26984

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09874
Policy Update Magnitude: 0.07222
Value Function Update Magnitude: 0.09933

Collected Steps per Second: 10,458.77134
Overall Steps per Second: 9,146.92946

Timestep Collection Time: 4.78087
Timestep Consumption Time: 0.68567
PPO Batch Consumption Time: 0.03319
Total Iteration Time: 5.46653

Cumulative Model Updates: 41,851
Cumulative Timesteps: 698,123,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,532.34530
Policy Entropy: 1.06529
Value Function Loss: 5.13521

Mean KL Divergence: 0.03193
SB3 Clip Fraction: 0.17742
Policy Update Magnitude: 0.06741
Value Function Update Magnitude: 0.11116

Collected Steps per Second: 11,572.01771
Overall Steps per Second: 9,823.35573

Timestep Collection Time: 4.32319
Timestep Consumption Time: 0.76957
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 5.09276

Cumulative Model Updates: 41,854
Cumulative Timesteps: 698,173,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 698173274...
Checkpoint 698173274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,223.74674
Policy Entropy: 1.08847
Value Function Loss: 5.03181

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.10362

Collected Steps per Second: 11,467.88333
Overall Steps per Second: 9,801.89954

Timestep Collection Time: 4.36053
Timestep Consumption Time: 0.74114
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.10166

Cumulative Model Updates: 41,857
Cumulative Timesteps: 698,223,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,027.66276
Policy Entropy: 1.08235
Value Function Loss: 5.04765

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.10458

Collected Steps per Second: 11,522.51514
Overall Steps per Second: 9,718.62061

Timestep Collection Time: 4.33985
Timestep Consumption Time: 0.80553
PPO Batch Consumption Time: 0.04478
Total Iteration Time: 5.14538

Cumulative Model Updates: 41,860
Cumulative Timesteps: 698,273,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 698273286...
Checkpoint 698273286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,300.98671
Policy Entropy: 1.07954
Value Function Loss: 4.98812

Mean KL Divergence: 0.03060
SB3 Clip Fraction: 0.17337
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.09703

Collected Steps per Second: 11,125.48607
Overall Steps per Second: 9,511.86646

Timestep Collection Time: 4.49508
Timestep Consumption Time: 0.76256
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.25764

Cumulative Model Updates: 41,863
Cumulative Timesteps: 698,323,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,845.39653
Policy Entropy: 1.09362
Value Function Loss: 5.11311

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.09103

Collected Steps per Second: 11,302.88784
Overall Steps per Second: 9,769.62176

Timestep Collection Time: 4.42577
Timestep Consumption Time: 0.69459
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.12036

Cumulative Model Updates: 41,866
Cumulative Timesteps: 698,373,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 698373320...
Checkpoint 698373320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,841.11723
Policy Entropy: 1.09867
Value Function Loss: 5.05642

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.08337

Collected Steps per Second: 10,782.91854
Overall Steps per Second: 9,235.51020

Timestep Collection Time: 4.63808
Timestep Consumption Time: 0.77711
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.41519

Cumulative Model Updates: 41,869
Cumulative Timesteps: 698,423,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,665.20828
Policy Entropy: 1.07911
Value Function Loss: 5.25300

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.07378

Collected Steps per Second: 11,059.09110
Overall Steps per Second: 9,462.76336

Timestep Collection Time: 4.52153
Timestep Consumption Time: 0.76276
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.28429

Cumulative Model Updates: 41,872
Cumulative Timesteps: 698,473,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 698473336...
Checkpoint 698473336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,494.36975
Policy Entropy: 1.06868
Value Function Loss: 5.27595

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.07655

Collected Steps per Second: 11,359.77729
Overall Steps per Second: 9,676.07706

Timestep Collection Time: 4.40167
Timestep Consumption Time: 0.76592
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.16759

Cumulative Model Updates: 41,875
Cumulative Timesteps: 698,523,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,235.30108
Policy Entropy: 1.09005
Value Function Loss: 5.39627

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.11185
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.07849

Collected Steps per Second: 11,180.29246
Overall Steps per Second: 9,478.67981

Timestep Collection Time: 4.47251
Timestep Consumption Time: 0.80291
PPO Batch Consumption Time: 0.03838
Total Iteration Time: 5.27542

Cumulative Model Updates: 41,878
Cumulative Timesteps: 698,573,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 698573342...
Checkpoint 698573342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,247.81309
Policy Entropy: 1.09916
Value Function Loss: 5.57822

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.07449

Collected Steps per Second: 11,061.64448
Overall Steps per Second: 9,594.50230

Timestep Collection Time: 4.52103
Timestep Consumption Time: 0.69133
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.21236

Cumulative Model Updates: 41,881
Cumulative Timesteps: 698,623,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,731.90936
Policy Entropy: 1.07724
Value Function Loss: 5.65637

Mean KL Divergence: 0.02802
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.07460

Collected Steps per Second: 10,657.90923
Overall Steps per Second: 9,131.89065

Timestep Collection Time: 4.69398
Timestep Consumption Time: 0.78440
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 5.47838

Cumulative Model Updates: 41,884
Cumulative Timesteps: 698,673,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 698673380...
Checkpoint 698673380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,357.21006
Policy Entropy: 1.08678
Value Function Loss: 5.51915

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.07541

Collected Steps per Second: 10,698.33955
Overall Steps per Second: 9,380.59513

Timestep Collection Time: 4.67587
Timestep Consumption Time: 0.65684
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.33271

Cumulative Model Updates: 41,887
Cumulative Timesteps: 698,723,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,608.83738
Policy Entropy: 1.08504
Value Function Loss: 5.34134

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.07201

Collected Steps per Second: 11,065.98151
Overall Steps per Second: 9,492.77302

Timestep Collection Time: 4.51980
Timestep Consumption Time: 0.74905
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.26885

Cumulative Model Updates: 41,890
Cumulative Timesteps: 698,773,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 698773420...
Checkpoint 698773420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,793.46760
Policy Entropy: 1.07353
Value Function Loss: 5.18955

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.07845

Collected Steps per Second: 11,019.70941
Overall Steps per Second: 9,484.73451

Timestep Collection Time: 4.53805
Timestep Consumption Time: 0.73442
PPO Batch Consumption Time: 0.03401
Total Iteration Time: 5.27247

Cumulative Model Updates: 41,893
Cumulative Timesteps: 698,823,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,297.65932
Policy Entropy: 1.07075
Value Function Loss: 5.37484

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.15511
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.07998

Collected Steps per Second: 10,972.39271
Overall Steps per Second: 9,410.75871

Timestep Collection Time: 4.55853
Timestep Consumption Time: 0.75645
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.31498

Cumulative Model Updates: 41,896
Cumulative Timesteps: 698,873,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 698873446...
Checkpoint 698873446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,326.34072
Policy Entropy: 1.07901
Value Function Loss: 5.33834

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.07619

Collected Steps per Second: 11,192.50698
Overall Steps per Second: 9,626.51650

Timestep Collection Time: 4.46745
Timestep Consumption Time: 0.72674
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.19419

Cumulative Model Updates: 41,899
Cumulative Timesteps: 698,923,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,830.79992
Policy Entropy: 1.08426
Value Function Loss: 5.31428

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 10,423.07505
Overall Steps per Second: 9,092.38823

Timestep Collection Time: 4.79954
Timestep Consumption Time: 0.70242
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.50196

Cumulative Model Updates: 41,902
Cumulative Timesteps: 698,973,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 698973474...
Checkpoint 698973474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,124.91748
Policy Entropy: 1.05453
Value Function Loss: 5.13221

Mean KL Divergence: 0.02936
SB3 Clip Fraction: 0.17741
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.07671

Collected Steps per Second: 10,860.67271
Overall Steps per Second: 9,275.37539

Timestep Collection Time: 4.60671
Timestep Consumption Time: 0.78735
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.39407

Cumulative Model Updates: 41,905
Cumulative Timesteps: 699,023,506

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,590.79136
Policy Entropy: 1.07779
Value Function Loss: 5.22513

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.08008

Collected Steps per Second: 10,934.85775
Overall Steps per Second: 9,465.53778

Timestep Collection Time: 4.57381
Timestep Consumption Time: 0.70999
PPO Batch Consumption Time: 0.03400
Total Iteration Time: 5.28380

Cumulative Model Updates: 41,908
Cumulative Timesteps: 699,073,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 699073520...
Checkpoint 699073520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,721.66512
Policy Entropy: 1.07613
Value Function Loss: 5.12957

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.07361

Collected Steps per Second: 10,883.84012
Overall Steps per Second: 9,307.33036

Timestep Collection Time: 4.59433
Timestep Consumption Time: 0.77821
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.37254

Cumulative Model Updates: 41,911
Cumulative Timesteps: 699,123,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,287.80474
Policy Entropy: 1.08094
Value Function Loss: 5.01575

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.09205

Collected Steps per Second: 10,864.47660
Overall Steps per Second: 9,304.29642

Timestep Collection Time: 4.60363
Timestep Consumption Time: 0.77195
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 5.37558

Cumulative Model Updates: 41,914
Cumulative Timesteps: 699,173,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 699173540...
Checkpoint 699173540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,851.01760
Policy Entropy: 1.07019
Value Function Loss: 4.86880

Mean KL Divergence: 0.03011
SB3 Clip Fraction: 0.19210
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.09778

Collected Steps per Second: 11,012.03571
Overall Steps per Second: 9,059.02801

Timestep Collection Time: 4.54285
Timestep Consumption Time: 0.97938
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 5.52223

Cumulative Model Updates: 41,917
Cumulative Timesteps: 699,223,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,812.68106
Policy Entropy: 1.08508
Value Function Loss: 5.11278

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.09415

Collected Steps per Second: 11,486.76569
Overall Steps per Second: 9,703.61797

Timestep Collection Time: 4.35318
Timestep Consumption Time: 0.79995
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 5.15313

Cumulative Model Updates: 41,920
Cumulative Timesteps: 699,273,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 699273570...
Checkpoint 699273570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,842.21343
Policy Entropy: 1.08702
Value Function Loss: 5.39836

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.09023

Collected Steps per Second: 11,681.16706
Overall Steps per Second: 10,072.84149

Timestep Collection Time: 4.28125
Timestep Consumption Time: 0.68359
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.96484

Cumulative Model Updates: 41,923
Cumulative Timesteps: 699,323,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,759.62157
Policy Entropy: 1.08463
Value Function Loss: 5.44286

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.06662
Value Function Update Magnitude: 0.08202

Collected Steps per Second: 11,817.38999
Overall Steps per Second: 9,957.89997

Timestep Collection Time: 4.23139
Timestep Consumption Time: 0.79015
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.02154

Cumulative Model Updates: 41,926
Cumulative Timesteps: 699,373,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 699373584...
Checkpoint 699373584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,027.81363
Policy Entropy: 1.08558
Value Function Loss: 5.42967

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.06640
Value Function Update Magnitude: 0.09845

Collected Steps per Second: 11,760.31007
Overall Steps per Second: 9,841.23535

Timestep Collection Time: 4.25244
Timestep Consumption Time: 0.82924
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.08168

Cumulative Model Updates: 41,929
Cumulative Timesteps: 699,423,594

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,605.52091
Policy Entropy: 1.08765
Value Function Loss: 5.45644

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.10970

Collected Steps per Second: 12,225.46513
Overall Steps per Second: 10,223.11313

Timestep Collection Time: 4.09081
Timestep Consumption Time: 0.80125
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 4.89205

Cumulative Model Updates: 41,932
Cumulative Timesteps: 699,473,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 699473606...
Checkpoint 699473606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,459.20705
Policy Entropy: 1.09816
Value Function Loss: 5.63254

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.05857
Value Function Update Magnitude: 0.11133

Collected Steps per Second: 11,660.72689
Overall Steps per Second: 9,640.22335

Timestep Collection Time: 4.28944
Timestep Consumption Time: 0.89903
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 5.18847

Cumulative Model Updates: 41,935
Cumulative Timesteps: 699,523,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,778.29472
Policy Entropy: 1.10125
Value Function Loss: 5.79725

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.10573

Collected Steps per Second: 10,981.25009
Overall Steps per Second: 9,525.57478

Timestep Collection Time: 4.55595
Timestep Consumption Time: 0.69623
PPO Batch Consumption Time: 0.03903
Total Iteration Time: 5.25218

Cumulative Model Updates: 41,938
Cumulative Timesteps: 699,573,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 699573654...
Checkpoint 699573654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,915.00794
Policy Entropy: 1.09751
Value Function Loss: 5.60285

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.06945
Value Function Update Magnitude: 0.09395

Collected Steps per Second: 11,047.02676
Overall Steps per Second: 9,426.70309

Timestep Collection Time: 4.52683
Timestep Consumption Time: 0.77810
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.30493

Cumulative Model Updates: 41,941
Cumulative Timesteps: 699,623,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,497.70459
Policy Entropy: 1.08144
Value Function Loss: 5.49254

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.16777
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.10098

Collected Steps per Second: 11,208.62952
Overall Steps per Second: 9,571.52918

Timestep Collection Time: 4.46156
Timestep Consumption Time: 0.76310
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.22466

Cumulative Model Updates: 41,944
Cumulative Timesteps: 699,673,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 699673670...
Checkpoint 699673670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,459.22777
Policy Entropy: 1.09628
Value Function Loss: 5.35529

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.09466

Collected Steps per Second: 10,859.46096
Overall Steps per Second: 9,406.77790

Timestep Collection Time: 4.60557
Timestep Consumption Time: 0.71124
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.31680

Cumulative Model Updates: 41,947
Cumulative Timesteps: 699,723,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,665.88573
Policy Entropy: 1.09878
Value Function Loss: 5.18640

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.08085

Collected Steps per Second: 11,215.12251
Overall Steps per Second: 9,554.45186

Timestep Collection Time: 4.45969
Timestep Consumption Time: 0.77514
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.23484

Cumulative Model Updates: 41,950
Cumulative Timesteps: 699,773,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 699773700...
Checkpoint 699773700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,745.22835
Policy Entropy: 1.09222
Value Function Loss: 5.04472

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.07833

Collected Steps per Second: 10,463.42848
Overall Steps per Second: 9,055.67220

Timestep Collection Time: 4.78103
Timestep Consumption Time: 0.74324
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.52427

Cumulative Model Updates: 41,953
Cumulative Timesteps: 699,823,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,033.68573
Policy Entropy: 1.08362
Value Function Loss: 5.03008

Mean KL Divergence: 0.02829
SB3 Clip Fraction: 0.16753
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.07943

Collected Steps per Second: 10,931.95926
Overall Steps per Second: 9,381.68958

Timestep Collection Time: 4.57393
Timestep Consumption Time: 0.75582
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.32974

Cumulative Model Updates: 41,956
Cumulative Timesteps: 699,873,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 699873728...
Checkpoint 699873728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,092.92421
Policy Entropy: 1.09816
Value Function Loss: 5.34527

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.07782

Collected Steps per Second: 10,827.03239
Overall Steps per Second: 9,308.49629

Timestep Collection Time: 4.62047
Timestep Consumption Time: 0.75376
PPO Batch Consumption Time: 0.03761
Total Iteration Time: 5.37423

Cumulative Model Updates: 41,959
Cumulative Timesteps: 699,923,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,296.99971
Policy Entropy: 1.10384
Value Function Loss: 5.18737

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.08297

Collected Steps per Second: 11,001.86670
Overall Steps per Second: 9,597.12073

Timestep Collection Time: 4.54487
Timestep Consumption Time: 0.66524
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.21010

Cumulative Model Updates: 41,962
Cumulative Timesteps: 699,973,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 699973756...
Checkpoint 699973756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,122.35455
Policy Entropy: 1.09069
Value Function Loss: 5.18074

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.07444

Collected Steps per Second: 10,835.65401
Overall Steps per Second: 9,311.92370

Timestep Collection Time: 4.61698
Timestep Consumption Time: 0.75549
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.37247

Cumulative Model Updates: 41,965
Cumulative Timesteps: 700,023,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,193.19367
Policy Entropy: 1.07742
Value Function Loss: 5.19581

Mean KL Divergence: 0.03304
SB3 Clip Fraction: 0.16131
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.07841

Collected Steps per Second: 11,080.58425
Overall Steps per Second: 9,481.80334

Timestep Collection Time: 4.51420
Timestep Consumption Time: 0.76117
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.27537

Cumulative Model Updates: 41,968
Cumulative Timesteps: 700,073,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 700073804...
Checkpoint 700073804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,012.30908
Policy Entropy: 1.09722
Value Function Loss: 5.33328

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.07413

Collected Steps per Second: 10,667.81908
Overall Steps per Second: 9,098.02237

Timestep Collection Time: 4.68812
Timestep Consumption Time: 0.80890
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 5.49702

Cumulative Model Updates: 41,971
Cumulative Timesteps: 700,123,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,263.99926
Policy Entropy: 1.08738
Value Function Loss: 5.48875

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.09254

Collected Steps per Second: 10,594.45382
Overall Steps per Second: 9,107.37855

Timestep Collection Time: 4.72002
Timestep Consumption Time: 0.77070
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.49071

Cumulative Model Updates: 41,974
Cumulative Timesteps: 700,173,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 700173822...
Checkpoint 700173822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,400.82307
Policy Entropy: 1.07626
Value Function Loss: 5.35676

Mean KL Divergence: 0.02723
SB3 Clip Fraction: 0.17209
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.09448

Collected Steps per Second: 11,187.45674
Overall Steps per Second: 9,696.06662

Timestep Collection Time: 4.47072
Timestep Consumption Time: 0.68766
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.15838

Cumulative Model Updates: 41,977
Cumulative Timesteps: 700,223,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,424.05351
Policy Entropy: 1.09339
Value Function Loss: 5.55378

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.08854

Collected Steps per Second: 10,969.81798
Overall Steps per Second: 9,362.50555

Timestep Collection Time: 4.55924
Timestep Consumption Time: 0.78271
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 5.34195

Cumulative Model Updates: 41,980
Cumulative Timesteps: 700,273,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 700273852...
Checkpoint 700273852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,370.87486
Policy Entropy: 1.09948
Value Function Loss: 5.25582

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.15515
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.07845

Collected Steps per Second: 10,945.97064
Overall Steps per Second: 9,352.85365

Timestep Collection Time: 4.56990
Timestep Consumption Time: 0.77841
PPO Batch Consumption Time: 0.03918
Total Iteration Time: 5.34831

Cumulative Model Updates: 41,983
Cumulative Timesteps: 700,323,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,909.95751
Policy Entropy: 1.07794
Value Function Loss: 5.18550

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.06792

Collected Steps per Second: 10,572.32898
Overall Steps per Second: 9,051.96551

Timestep Collection Time: 4.73084
Timestep Consumption Time: 0.79459
PPO Batch Consumption Time: 0.03732
Total Iteration Time: 5.52543

Cumulative Model Updates: 41,986
Cumulative Timesteps: 700,373,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 700373890...
Checkpoint 700373890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,041.67268
Policy Entropy: 1.08553
Value Function Loss: 5.15973

Mean KL Divergence: 0.02515
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.06889

Collected Steps per Second: 11,452.64476
Overall Steps per Second: 9,736.12814

Timestep Collection Time: 4.36580
Timestep Consumption Time: 0.76971
PPO Batch Consumption Time: 0.03943
Total Iteration Time: 5.13551

Cumulative Model Updates: 41,989
Cumulative Timesteps: 700,423,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,512.74847
Policy Entropy: 1.09511
Value Function Loss: 5.05914

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.06361

Collected Steps per Second: 11,523.25530
Overall Steps per Second: 9,923.78086

Timestep Collection Time: 4.34113
Timestep Consumption Time: 0.69969
PPO Batch Consumption Time: 0.03907
Total Iteration Time: 5.04082

Cumulative Model Updates: 41,992
Cumulative Timesteps: 700,473,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 700473914...
Checkpoint 700473914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,260.37756
Policy Entropy: 1.08419
Value Function Loss: 5.19084

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.06433

Collected Steps per Second: 11,559.21468
Overall Steps per Second: 9,821.47858

Timestep Collection Time: 4.32815
Timestep Consumption Time: 0.76579
PPO Batch Consumption Time: 0.03781
Total Iteration Time: 5.09394

Cumulative Model Updates: 41,995
Cumulative Timesteps: 700,523,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,620.66091
Policy Entropy: 1.08042
Value Function Loss: 5.34760

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.06276

Collected Steps per Second: 11,138.53368
Overall Steps per Second: 9,487.31472

Timestep Collection Time: 4.49018
Timestep Consumption Time: 0.78149
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.27167

Cumulative Model Updates: 41,998
Cumulative Timesteps: 700,573,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 700573958...
Checkpoint 700573958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,950.95466
Policy Entropy: 1.08111
Value Function Loss: 5.51693

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.07468

Collected Steps per Second: 11,253.35261
Overall Steps per Second: 9,612.36267

Timestep Collection Time: 4.44561
Timestep Consumption Time: 0.75894
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.20455

Cumulative Model Updates: 42,001
Cumulative Timesteps: 700,623,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,121.11258
Policy Entropy: 1.08857
Value Function Loss: 5.44392

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.07370

Collected Steps per Second: 10,806.04323
Overall Steps per Second: 9,211.08462

Timestep Collection Time: 4.62834
Timestep Consumption Time: 0.80143
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.42976

Cumulative Model Updates: 42,004
Cumulative Timesteps: 700,674,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 700674000...
Checkpoint 700674000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,692.69030
Policy Entropy: 1.08188
Value Function Loss: 5.24496

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.07695

Collected Steps per Second: 11,292.03246
Overall Steps per Second: 9,745.20839

Timestep Collection Time: 4.42967
Timestep Consumption Time: 0.70311
PPO Batch Consumption Time: 0.03857
Total Iteration Time: 5.13278

Cumulative Model Updates: 42,007
Cumulative Timesteps: 700,724,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,523.53035
Policy Entropy: 1.07952
Value Function Loss: 5.42683

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.06272
Value Function Update Magnitude: 0.07005

Collected Steps per Second: 11,459.12797
Overall Steps per Second: 9,715.17900

Timestep Collection Time: 4.36508
Timestep Consumption Time: 0.78357
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.14864

Cumulative Model Updates: 42,010
Cumulative Timesteps: 700,774,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 700774040...
Checkpoint 700774040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,922.16073
Policy Entropy: 1.07370
Value Function Loss: 5.56219

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.07194

Collected Steps per Second: 10,673.81851
Overall Steps per Second: 9,239.84093

Timestep Collection Time: 4.68586
Timestep Consumption Time: 0.72722
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.41308

Cumulative Model Updates: 42,013
Cumulative Timesteps: 700,824,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,519.73118
Policy Entropy: 1.08567
Value Function Loss: 5.68135

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.06734

Collected Steps per Second: 11,249.28539
Overall Steps per Second: 9,590.21146

Timestep Collection Time: 4.44597
Timestep Consumption Time: 0.76914
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 5.21511

Cumulative Model Updates: 42,016
Cumulative Timesteps: 700,874,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 700874070...
Checkpoint 700874070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,104.17091
Policy Entropy: 1.09306
Value Function Loss: 5.68662

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.16064
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 11,276.88632
Overall Steps per Second: 9,595.27665

Timestep Collection Time: 4.43544
Timestep Consumption Time: 0.77733
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.21277

Cumulative Model Updates: 42,019
Cumulative Timesteps: 700,924,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,724.36586
Policy Entropy: 1.08277
Value Function Loss: 5.60940

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.07620

Collected Steps per Second: 10,468.92728
Overall Steps per Second: 9,168.86825

Timestep Collection Time: 4.77776
Timestep Consumption Time: 0.67744
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.45520

Cumulative Model Updates: 42,022
Cumulative Timesteps: 700,974,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 700974106...
Checkpoint 700974106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,641.80901
Policy Entropy: 1.08072
Value Function Loss: 5.52204

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.07754

Collected Steps per Second: 11,054.17247
Overall Steps per Second: 9,437.19098

Timestep Collection Time: 4.52499
Timestep Consumption Time: 0.77532
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.30031

Cumulative Model Updates: 42,025
Cumulative Timesteps: 701,024,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,387.30341
Policy Entropy: 1.09382
Value Function Loss: 5.44883

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.09083

Collected Steps per Second: 10,909.98492
Overall Steps per Second: 9,423.30365

Timestep Collection Time: 4.58442
Timestep Consumption Time: 0.72327
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.30769

Cumulative Model Updates: 42,028
Cumulative Timesteps: 701,074,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 701074142...
Checkpoint 701074142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,844.64895
Policy Entropy: 1.09751
Value Function Loss: 5.18799

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.08119

Collected Steps per Second: 11,063.98289
Overall Steps per Second: 9,458.09645

Timestep Collection Time: 4.52098
Timestep Consumption Time: 0.76761
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.28859

Cumulative Model Updates: 42,031
Cumulative Timesteps: 701,124,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,900.66339
Policy Entropy: 1.07130
Value Function Loss: 5.22494

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.07424

Collected Steps per Second: 10,978.32236
Overall Steps per Second: 9,294.42212

Timestep Collection Time: 4.55552
Timestep Consumption Time: 0.82534
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.38086

Cumulative Model Updates: 42,034
Cumulative Timesteps: 701,174,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 701174174...
Checkpoint 701174174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,706.37701
Policy Entropy: 1.08745
Value Function Loss: 5.33124

Mean KL Divergence: 0.02497
SB3 Clip Fraction: 0.15415
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 10,988.83353
Overall Steps per Second: 9,415.40206

Timestep Collection Time: 4.55135
Timestep Consumption Time: 0.76059
PPO Batch Consumption Time: 0.04034
Total Iteration Time: 5.31193

Cumulative Model Updates: 42,037
Cumulative Timesteps: 701,224,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,099.01467
Policy Entropy: 1.07906
Value Function Loss: 5.67902

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.06867

Collected Steps per Second: 11,000.31824
Overall Steps per Second: 9,322.87200

Timestep Collection Time: 4.54750
Timestep Consumption Time: 0.81822
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 5.36573

Cumulative Model Updates: 42,040
Cumulative Timesteps: 701,274,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 701274212...
Checkpoint 701274212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,003.08512
Policy Entropy: 1.07718
Value Function Loss: 5.58210

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 11,006.07486
Overall Steps per Second: 9,390.25681

Timestep Collection Time: 4.54440
Timestep Consumption Time: 0.78197
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 5.32637

Cumulative Model Updates: 42,043
Cumulative Timesteps: 701,324,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,617.81267
Policy Entropy: 1.05424
Value Function Loss: 5.16092

Mean KL Divergence: 0.05159
SB3 Clip Fraction: 0.20727
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.07900

Collected Steps per Second: 10,806.61454
Overall Steps per Second: 9,300.41580

Timestep Collection Time: 4.62754
Timestep Consumption Time: 0.74943
PPO Batch Consumption Time: 0.03854
Total Iteration Time: 5.37696

Cumulative Model Updates: 42,046
Cumulative Timesteps: 701,374,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 701374236...
Checkpoint 701374236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,854.32827
Policy Entropy: 1.08418
Value Function Loss: 5.09340

Mean KL Divergence: 0.04925
SB3 Clip Fraction: 0.20502
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 11,077.88739
Overall Steps per Second: 9,356.37174

Timestep Collection Time: 4.51368
Timestep Consumption Time: 0.83049
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.34417

Cumulative Model Updates: 42,049
Cumulative Timesteps: 701,424,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,052.27584
Policy Entropy: 1.05729
Value Function Loss: 5.38283

Mean KL Divergence: 0.05545
SB3 Clip Fraction: 0.21741
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.07299

Collected Steps per Second: 10,741.28041
Overall Steps per Second: 9,191.66593

Timestep Collection Time: 4.65680
Timestep Consumption Time: 0.78509
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.44189

Cumulative Model Updates: 42,052
Cumulative Timesteps: 701,474,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 701474258...
Checkpoint 701474258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,193.03445
Policy Entropy: 1.08661
Value Function Loss: 5.74873

Mean KL Divergence: 0.03669
SB3 Clip Fraction: 0.19192
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.07852

Collected Steps per Second: 10,839.40242
Overall Steps per Second: 9,289.09729

Timestep Collection Time: 4.61409
Timestep Consumption Time: 0.77007
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 5.38416

Cumulative Model Updates: 42,055
Cumulative Timesteps: 701,524,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,686.42565
Policy Entropy: 1.06327
Value Function Loss: 5.65148

Mean KL Divergence: 0.02944
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.07895

Collected Steps per Second: 12,033.35903
Overall Steps per Second: 9,999.68086

Timestep Collection Time: 4.15578
Timestep Consumption Time: 0.84518
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 5.00096

Cumulative Model Updates: 42,058
Cumulative Timesteps: 701,574,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 701574280...
Checkpoint 701574280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,766.35020
Policy Entropy: 1.08693
Value Function Loss: 5.34061

Mean KL Divergence: 0.03635
SB3 Clip Fraction: 0.17916
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.08146

Collected Steps per Second: 11,902.32904
Overall Steps per Second: 10,194.61134

Timestep Collection Time: 4.20237
Timestep Consumption Time: 0.70395
PPO Batch Consumption Time: 0.03380
Total Iteration Time: 4.90632

Cumulative Model Updates: 42,061
Cumulative Timesteps: 701,624,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,814.77385
Policy Entropy: 1.07710
Value Function Loss: 5.20507

Mean KL Divergence: 0.02653
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.08528

Collected Steps per Second: 11,717.09976
Overall Steps per Second: 9,734.04957

Timestep Collection Time: 4.26880
Timestep Consumption Time: 0.86965
PPO Batch Consumption Time: 0.03991
Total Iteration Time: 5.13846

Cumulative Model Updates: 42,064
Cumulative Timesteps: 701,674,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 701674316...
Checkpoint 701674316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,115.69408
Policy Entropy: 1.07639
Value Function Loss: 5.12574

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.07817

Collected Steps per Second: 11,870.64511
Overall Steps per Second: 9,839.83872

Timestep Collection Time: 4.21207
Timestep Consumption Time: 0.86931
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.08138

Cumulative Model Updates: 42,067
Cumulative Timesteps: 701,724,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,320.59750
Policy Entropy: 1.06441
Value Function Loss: 5.23316

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.08876

Collected Steps per Second: 12,255.17794
Overall Steps per Second: 10,322.76004

Timestep Collection Time: 4.08089
Timestep Consumption Time: 0.76394
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 4.84483

Cumulative Model Updates: 42,070
Cumulative Timesteps: 701,774,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 701774328...
Checkpoint 701774328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,135.55015
Policy Entropy: 1.07739
Value Function Loss: 5.20539

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 11,178.50184
Overall Steps per Second: 9,569.12240

Timestep Collection Time: 4.47412
Timestep Consumption Time: 0.75248
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.22660

Cumulative Model Updates: 42,073
Cumulative Timesteps: 701,824,342

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,717.89599
Policy Entropy: 1.08296
Value Function Loss: 5.28513

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.06840
Value Function Update Magnitude: 0.07255

Collected Steps per Second: 10,744.93382
Overall Steps per Second: 9,320.28665

Timestep Collection Time: 4.65559
Timestep Consumption Time: 0.71163
PPO Batch Consumption Time: 0.04028
Total Iteration Time: 5.36722

Cumulative Model Updates: 42,076
Cumulative Timesteps: 701,874,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 701874366...
Checkpoint 701874366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,723.43869
Policy Entropy: 1.08148
Value Function Loss: 5.26815

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 11,282.42911
Overall Steps per Second: 9,535.71677

Timestep Collection Time: 4.43202
Timestep Consumption Time: 0.81184
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 5.24386

Cumulative Model Updates: 42,079
Cumulative Timesteps: 701,924,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,687.51352
Policy Entropy: 1.08181
Value Function Loss: 5.21721

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.07318

Collected Steps per Second: 10,946.64922
Overall Steps per Second: 9,368.05382

Timestep Collection Time: 4.56907
Timestep Consumption Time: 0.76993
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.33900

Cumulative Model Updates: 42,082
Cumulative Timesteps: 701,974,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 701974386...
Checkpoint 701974386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,598.34520
Policy Entropy: 1.08907
Value Function Loss: 5.41455

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 11,411.24178
Overall Steps per Second: 9,620.76442

Timestep Collection Time: 4.38410
Timestep Consumption Time: 0.81590
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.20000

Cumulative Model Updates: 42,085
Cumulative Timesteps: 702,024,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,280.81826
Policy Entropy: 1.10117
Value Function Loss: 5.29527

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.07334

Collected Steps per Second: 11,209.46842
Overall Steps per Second: 9,371.26158

Timestep Collection Time: 4.46123
Timestep Consumption Time: 0.87509
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 5.33631

Cumulative Model Updates: 42,088
Cumulative Timesteps: 702,074,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 702074422...
Checkpoint 702074422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,651.67403
Policy Entropy: 1.10230
Value Function Loss: 5.47302

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.07498

Collected Steps per Second: 10,879.13008
Overall Steps per Second: 9,394.04061

Timestep Collection Time: 4.59687
Timestep Consumption Time: 0.72671
PPO Batch Consumption Time: 0.04465
Total Iteration Time: 5.32359

Cumulative Model Updates: 42,091
Cumulative Timesteps: 702,124,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,350.09349
Policy Entropy: 1.10921
Value Function Loss: 5.45528

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.11876
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.07254

Collected Steps per Second: 10,967.98883
Overall Steps per Second: 9,316.55960

Timestep Collection Time: 4.55982
Timestep Consumption Time: 0.80826
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.36808

Cumulative Model Updates: 42,094
Cumulative Timesteps: 702,174,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 702174444...
Checkpoint 702174444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,942.73983
Policy Entropy: 1.10778
Value Function Loss: 5.48072

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.07084
Value Function Update Magnitude: 0.06887

Collected Steps per Second: 10,637.79454
Overall Steps per Second: 9,141.96036

Timestep Collection Time: 4.70060
Timestep Consumption Time: 0.76913
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.46972

Cumulative Model Updates: 42,097
Cumulative Timesteps: 702,224,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418,323.52876
Policy Entropy: 1.11099
Value Function Loss: 5.70672

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.06468

Collected Steps per Second: 11,046.28368
Overall Steps per Second: 9,427.53909

Timestep Collection Time: 4.52804
Timestep Consumption Time: 0.77748
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.30552

Cumulative Model Updates: 42,100
Cumulative Timesteps: 702,274,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 702274466...
Checkpoint 702274466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,173.50620
Policy Entropy: 1.11332
Value Function Loss: 5.58859

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.05790

Collected Steps per Second: 10,942.09983
Overall Steps per Second: 9,407.00762

Timestep Collection Time: 4.57170
Timestep Consumption Time: 0.74604
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.31774

Cumulative Model Updates: 42,103
Cumulative Timesteps: 702,324,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,333.53094
Policy Entropy: 1.12244
Value Function Loss: 5.64381

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.05311

Collected Steps per Second: 10,466.37025
Overall Steps per Second: 9,114.55437

Timestep Collection Time: 4.77969
Timestep Consumption Time: 0.70889
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.48858

Cumulative Model Updates: 42,106
Cumulative Timesteps: 702,374,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 702374516...
Checkpoint 702374516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,743.42214
Policy Entropy: 1.12089
Value Function Loss: 5.65859

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 10,910.73375
Overall Steps per Second: 9,386.53840

Timestep Collection Time: 4.58539
Timestep Consumption Time: 0.74458
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.32997

Cumulative Model Updates: 42,109
Cumulative Timesteps: 702,424,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,425.66259
Policy Entropy: 1.12120
Value Function Loss: 5.65010

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.07078

Collected Steps per Second: 10,879.88332
Overall Steps per Second: 9,371.08381

Timestep Collection Time: 4.59692
Timestep Consumption Time: 0.74013
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.33706

Cumulative Model Updates: 42,112
Cumulative Timesteps: 702,474,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 702474560...
Checkpoint 702474560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,475.55425
Policy Entropy: 1.11832
Value Function Loss: 5.58991

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.06860
Value Function Update Magnitude: 0.07956

Collected Steps per Second: 10,844.84866
Overall Steps per Second: 9,194.24792

Timestep Collection Time: 4.61251
Timestep Consumption Time: 0.82806
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 5.44058

Cumulative Model Updates: 42,115
Cumulative Timesteps: 702,524,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387,256.91584
Policy Entropy: 1.10856
Value Function Loss: 5.17782

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.14871
Policy Update Magnitude: 0.06857
Value Function Update Magnitude: 0.08344

Collected Steps per Second: 10,821.76692
Overall Steps per Second: 9,319.88486

Timestep Collection Time: 4.62198
Timestep Consumption Time: 0.74482
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.36680

Cumulative Model Updates: 42,118
Cumulative Timesteps: 702,574,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 702574600...
Checkpoint 702574600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,018.83634
Policy Entropy: 1.12485
Value Function Loss: 5.11057

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.09573

Collected Steps per Second: 10,614.38286
Overall Steps per Second: 9,228.45319

Timestep Collection Time: 4.71172
Timestep Consumption Time: 0.70761
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 5.41933

Cumulative Model Updates: 42,121
Cumulative Timesteps: 702,624,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,123.14265
Policy Entropy: 1.12786
Value Function Loss: 5.14055

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.06826
Value Function Update Magnitude: 0.10510

Collected Steps per Second: 10,741.71637
Overall Steps per Second: 9,231.46793

Timestep Collection Time: 4.65661
Timestep Consumption Time: 0.76181
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.41842

Cumulative Model Updates: 42,124
Cumulative Timesteps: 702,674,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 702674632...
Checkpoint 702674632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,679.93757
Policy Entropy: 1.11521
Value Function Loss: 5.34208

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.10004

Collected Steps per Second: 11,438.83635
Overall Steps per Second: 9,940.59133

Timestep Collection Time: 4.37317
Timestep Consumption Time: 0.65912
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 5.03230

Cumulative Model Updates: 42,127
Cumulative Timesteps: 702,724,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,423.22781
Policy Entropy: 1.10501
Value Function Loss: 5.59917

Mean KL Divergence: 0.02449
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.09825

Collected Steps per Second: 11,281.13345
Overall Steps per Second: 9,589.45850

Timestep Collection Time: 4.43431
Timestep Consumption Time: 0.78226
PPO Batch Consumption Time: 0.03843
Total Iteration Time: 5.21656

Cumulative Model Updates: 42,130
Cumulative Timesteps: 702,774,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 702774680...
Checkpoint 702774680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367,972.07962
Policy Entropy: 1.11688
Value Function Loss: 5.35510

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.08730

Collected Steps per Second: 11,245.03596
Overall Steps per Second: 9,559.90591

Timestep Collection Time: 4.44890
Timestep Consumption Time: 0.78421
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.23311

Cumulative Model Updates: 42,133
Cumulative Timesteps: 702,824,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,743.93783
Policy Entropy: 1.12854
Value Function Loss: 5.38064

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.11755
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.07894

Collected Steps per Second: 11,215.11553
Overall Steps per Second: 9,742.42101

Timestep Collection Time: 4.46041
Timestep Consumption Time: 0.67425
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.13466

Cumulative Model Updates: 42,136
Cumulative Timesteps: 702,874,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 702874732...
Checkpoint 702874732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,357.29724
Policy Entropy: 1.10693
Value Function Loss: 5.27230

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.08778

Collected Steps per Second: 10,968.09573
Overall Steps per Second: 9,286.58552

Timestep Collection Time: 4.56032
Timestep Consumption Time: 0.82573
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.38605

Cumulative Model Updates: 42,139
Cumulative Timesteps: 702,924,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,453.27563
Policy Entropy: 1.10895
Value Function Loss: 5.32606

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.09682

Collected Steps per Second: 11,122.73238
Overall Steps per Second: 9,449.76756

Timestep Collection Time: 4.49674
Timestep Consumption Time: 0.79609
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 5.29283

Cumulative Model Updates: 42,142
Cumulative Timesteps: 702,974,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 702974766...
Checkpoint 702974766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,742.06903
Policy Entropy: 1.11782
Value Function Loss: 5.10761

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.08357

Collected Steps per Second: 11,422.06489
Overall Steps per Second: 9,709.09353

Timestep Collection Time: 4.37854
Timestep Consumption Time: 0.77250
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.15105

Cumulative Model Updates: 42,145
Cumulative Timesteps: 703,024,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,779.22309
Policy Entropy: 1.12931
Value Function Loss: 5.21092

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.07273

Collected Steps per Second: 11,230.86751
Overall Steps per Second: 9,556.17697

Timestep Collection Time: 4.45326
Timestep Consumption Time: 0.78042
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.23368

Cumulative Model Updates: 42,148
Cumulative Timesteps: 703,074,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 703074792...
Checkpoint 703074792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,397.71798
Policy Entropy: 1.11739
Value Function Loss: 5.31300

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.08963

Collected Steps per Second: 11,258.29962
Overall Steps per Second: 9,728.29892

Timestep Collection Time: 4.44117
Timestep Consumption Time: 0.69848
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 5.13964

Cumulative Model Updates: 42,151
Cumulative Timesteps: 703,124,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,672.74049
Policy Entropy: 1.10053
Value Function Loss: 5.29059

Mean KL Divergence: 0.03416
SB3 Clip Fraction: 0.16965
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.10095

Collected Steps per Second: 11,010.43784
Overall Steps per Second: 9,387.13887

Timestep Collection Time: 4.54242
Timestep Consumption Time: 0.78551
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.32793

Cumulative Model Updates: 42,154
Cumulative Timesteps: 703,174,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 703174806...
Checkpoint 703174806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,938.78685
Policy Entropy: 1.10758
Value Function Loss: 5.00494

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.08843

Collected Steps per Second: 10,405.20866
Overall Steps per Second: 9,031.60794

Timestep Collection Time: 4.80586
Timestep Consumption Time: 0.73091
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 5.53678

Cumulative Model Updates: 42,157
Cumulative Timesteps: 703,224,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,416.97915
Policy Entropy: 1.10865
Value Function Loss: 4.97224

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.09161

Collected Steps per Second: 10,917.69937
Overall Steps per Second: 9,330.14487

Timestep Collection Time: 4.58192
Timestep Consumption Time: 0.77963
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.36155

Cumulative Model Updates: 42,160
Cumulative Timesteps: 703,274,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 703274836...
Checkpoint 703274836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,854.94543
Policy Entropy: 1.08938
Value Function Loss: 5.21815

Mean KL Divergence: 0.02629
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.08305

Collected Steps per Second: 11,032.26399
Overall Steps per Second: 9,462.47447

Timestep Collection Time: 4.53361
Timestep Consumption Time: 0.75211
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 5.28572

Cumulative Model Updates: 42,163
Cumulative Timesteps: 703,324,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,286.31055
Policy Entropy: 1.10668
Value Function Loss: 5.42355

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.07979

Collected Steps per Second: 10,833.93126
Overall Steps per Second: 9,466.70121

Timestep Collection Time: 4.61550
Timestep Consumption Time: 0.66659
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.28209

Cumulative Model Updates: 42,166
Cumulative Timesteps: 703,374,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 703374856...
Checkpoint 703374856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,103.69644
Policy Entropy: 1.10777
Value Function Loss: 5.19074

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.08011

Collected Steps per Second: 10,819.59515
Overall Steps per Second: 9,262.87627

Timestep Collection Time: 4.62383
Timestep Consumption Time: 0.77708
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.40091

Cumulative Model Updates: 42,169
Cumulative Timesteps: 703,424,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,205.74423
Policy Entropy: 1.10028
Value Function Loss: 5.16083

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.07572

Collected Steps per Second: 10,768.33505
Overall Steps per Second: 9,278.85859

Timestep Collection Time: 4.64361
Timestep Consumption Time: 0.74541
PPO Batch Consumption Time: 0.03993
Total Iteration Time: 5.38902

Cumulative Model Updates: 42,172
Cumulative Timesteps: 703,474,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 703474888...
Checkpoint 703474888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,411.61442
Policy Entropy: 1.08555
Value Function Loss: 5.14955

Mean KL Divergence: 0.03541
SB3 Clip Fraction: 0.17465
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.07974

Collected Steps per Second: 10,863.07160
Overall Steps per Second: 9,211.29833

Timestep Collection Time: 4.60385
Timestep Consumption Time: 0.82556
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.42942

Cumulative Model Updates: 42,175
Cumulative Timesteps: 703,524,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,845.79701
Policy Entropy: 1.10809
Value Function Loss: 5.39063

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.08282

Collected Steps per Second: 11,026.95046
Overall Steps per Second: 9,400.08597

Timestep Collection Time: 4.53580
Timestep Consumption Time: 0.78501
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.32080

Cumulative Model Updates: 42,178
Cumulative Timesteps: 703,574,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 703574916...
Checkpoint 703574916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,461.10776
Policy Entropy: 1.10516
Value Function Loss: 5.30202

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.07906

Collected Steps per Second: 10,926.30688
Overall Steps per Second: 9,462.16241

Timestep Collection Time: 4.57886
Timestep Consumption Time: 0.70852
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.28737

Cumulative Model Updates: 42,181
Cumulative Timesteps: 703,624,946

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,952.50168
Policy Entropy: 1.09790
Value Function Loss: 5.16081

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.09800

Collected Steps per Second: 10,809.34693
Overall Steps per Second: 9,247.22427

Timestep Collection Time: 4.62600
Timestep Consumption Time: 0.78146
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.40746

Cumulative Model Updates: 42,184
Cumulative Timesteps: 703,674,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 703674950...
Checkpoint 703674950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368,456.10462
Policy Entropy: 1.09146
Value Function Loss: 4.96610

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.10955

Collected Steps per Second: 10,815.96566
Overall Steps per Second: 9,193.03938

Timestep Collection Time: 4.62372
Timestep Consumption Time: 0.81627
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 5.43999

Cumulative Model Updates: 42,187
Cumulative Timesteps: 703,724,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,169.37727
Policy Entropy: 1.10448
Value Function Loss: 5.03916

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.10883

Collected Steps per Second: 10,716.47134
Overall Steps per Second: 9,123.53617

Timestep Collection Time: 4.66702
Timestep Consumption Time: 0.81484
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 5.48187

Cumulative Model Updates: 42,190
Cumulative Timesteps: 703,774,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 703774974...
Checkpoint 703774974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,195.93515
Policy Entropy: 1.10385
Value Function Loss: 4.99132

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.10391

Collected Steps per Second: 11,619.37446
Overall Steps per Second: 9,831.77505

Timestep Collection Time: 4.30419
Timestep Consumption Time: 0.78258
PPO Batch Consumption Time: 0.03844
Total Iteration Time: 5.08677

Cumulative Model Updates: 42,193
Cumulative Timesteps: 703,824,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,133.06772
Policy Entropy: 1.09102
Value Function Loss: 5.31153

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.10303

Collected Steps per Second: 11,867.88962
Overall Steps per Second: 10,179.00785

Timestep Collection Time: 4.21490
Timestep Consumption Time: 0.69933
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.91423

Cumulative Model Updates: 42,196
Cumulative Timesteps: 703,875,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 703875008...
Checkpoint 703875008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,226.78861
Policy Entropy: 1.07787
Value Function Loss: 5.12268

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.09989

Collected Steps per Second: 11,962.30210
Overall Steps per Second: 10,086.97841

Timestep Collection Time: 4.18113
Timestep Consumption Time: 0.77734
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.95847

Cumulative Model Updates: 42,199
Cumulative Timesteps: 703,925,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,874.93438
Policy Entropy: 1.08712
Value Function Loss: 5.03009

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.08867

Collected Steps per Second: 11,726.70999
Overall Steps per Second: 9,978.43292

Timestep Collection Time: 4.26616
Timestep Consumption Time: 0.74745
PPO Batch Consumption Time: 0.03804
Total Iteration Time: 5.01361

Cumulative Model Updates: 42,202
Cumulative Timesteps: 703,975,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 703975052...
Checkpoint 703975052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,784.65757
Policy Entropy: 1.09590
Value Function Loss: 4.95090

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.09058

Collected Steps per Second: 12,102.46313
Overall Steps per Second: 10,143.22823

Timestep Collection Time: 4.13288
Timestep Consumption Time: 0.79829
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 4.93117

Cumulative Model Updates: 42,205
Cumulative Timesteps: 704,025,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,829.10203
Policy Entropy: 1.08321
Value Function Loss: 5.01847

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.08605

Collected Steps per Second: 11,231.66080
Overall Steps per Second: 9,509.24449

Timestep Collection Time: 4.45277
Timestep Consumption Time: 0.80653
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 5.25930

Cumulative Model Updates: 42,208
Cumulative Timesteps: 704,075,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 704075082...
Checkpoint 704075082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,158.63845
Policy Entropy: 1.08581
Value Function Loss: 5.48711

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.07444

Collected Steps per Second: 11,146.59287
Overall Steps per Second: 9,641.57103

Timestep Collection Time: 4.48747
Timestep Consumption Time: 0.70048
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 5.18795

Cumulative Model Updates: 42,211
Cumulative Timesteps: 704,125,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,610.86335
Policy Entropy: 1.09698
Value Function Loss: 5.54960

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.07918

Collected Steps per Second: 11,029.94468
Overall Steps per Second: 9,408.56547

Timestep Collection Time: 4.53529
Timestep Consumption Time: 0.78157
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.31686

Cumulative Model Updates: 42,214
Cumulative Timesteps: 704,175,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 704175126...
Checkpoint 704175126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,514.54815
Policy Entropy: 1.10168
Value Function Loss: 5.43801

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.08104

Collected Steps per Second: 10,895.10476
Overall Steps per Second: 9,369.89306

Timestep Collection Time: 4.58922
Timestep Consumption Time: 0.74702
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.33624

Cumulative Model Updates: 42,217
Cumulative Timesteps: 704,225,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,745.60120
Policy Entropy: 1.09094
Value Function Loss: 5.36237

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.08017

Collected Steps per Second: 11,167.54868
Overall Steps per Second: 9,427.11380

Timestep Collection Time: 4.47905
Timestep Consumption Time: 0.82692
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.30597

Cumulative Model Updates: 42,220
Cumulative Timesteps: 704,275,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 704275146...
Checkpoint 704275146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,562.74327
Policy Entropy: 1.08221
Value Function Loss: 5.14147

Mean KL Divergence: 0.02963
SB3 Clip Fraction: 0.16452
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.07782

Collected Steps per Second: 10,974.30902
Overall Steps per Second: 9,331.27788

Timestep Collection Time: 4.55774
Timestep Consumption Time: 0.80252
PPO Batch Consumption Time: 0.03932
Total Iteration Time: 5.36025

Cumulative Model Updates: 42,223
Cumulative Timesteps: 704,325,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,383.40656
Policy Entropy: 1.09443
Value Function Loss: 5.37605

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.10912
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 10,809.51491
Overall Steps per Second: 9,359.23032

Timestep Collection Time: 4.62666
Timestep Consumption Time: 0.71694
PPO Batch Consumption Time: 0.04104
Total Iteration Time: 5.34360

Cumulative Model Updates: 42,226
Cumulative Timesteps: 704,375,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 704375176...
Checkpoint 704375176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618,777.93366
Policy Entropy: 1.09521
Value Function Loss: 5.43598

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.07422

Collected Steps per Second: 11,098.66361
Overall Steps per Second: 9,439.55457

Timestep Collection Time: 4.50577
Timestep Consumption Time: 0.79194
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.29771

Cumulative Model Updates: 42,229
Cumulative Timesteps: 704,425,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,701.20363
Policy Entropy: 1.09985
Value Function Loss: 5.31386

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.06515
Value Function Update Magnitude: 0.09790

Collected Steps per Second: 10,899.69131
Overall Steps per Second: 9,420.23393

Timestep Collection Time: 4.58894
Timestep Consumption Time: 0.72070
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.30963

Cumulative Model Updates: 42,232
Cumulative Timesteps: 704,475,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 704475202...
Checkpoint 704475202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,498.79973
Policy Entropy: 1.10096
Value Function Loss: 4.99522

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.07108
Value Function Update Magnitude: 0.11176

Collected Steps per Second: 10,216.13430
Overall Steps per Second: 8,808.66689

Timestep Collection Time: 4.89696
Timestep Consumption Time: 0.78245
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.67941

Cumulative Model Updates: 42,235
Cumulative Timesteps: 704,525,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,608.54415
Policy Entropy: 1.10924
Value Function Loss: 4.72498

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.06771
Value Function Update Magnitude: 0.11037

Collected Steps per Second: 10,950.19810
Overall Steps per Second: 9,415.66939

Timestep Collection Time: 4.56759
Timestep Consumption Time: 0.74441
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.31200

Cumulative Model Updates: 42,238
Cumulative Timesteps: 704,575,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 704575246...
Checkpoint 704575246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,915.43972
Policy Entropy: 1.10248
Value Function Loss: 5.09097

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.07145
Value Function Update Magnitude: 0.10372

Collected Steps per Second: 10,810.12214
Overall Steps per Second: 9,207.50061

Timestep Collection Time: 4.62622
Timestep Consumption Time: 0.80522
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.43144

Cumulative Model Updates: 42,241
Cumulative Timesteps: 704,625,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,511.97936
Policy Entropy: 1.11245
Value Function Loss: 5.46901

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.09716

Collected Steps per Second: 10,700.24643
Overall Steps per Second: 9,197.17816

Timestep Collection Time: 4.67316
Timestep Consumption Time: 0.76372
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 5.43689

Cumulative Model Updates: 42,244
Cumulative Timesteps: 704,675,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 704675260...
Checkpoint 704675260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,741.17085
Policy Entropy: 1.11709
Value Function Loss: 5.60999

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.09513

Collected Steps per Second: 10,663.22087
Overall Steps per Second: 9,311.80826

Timestep Collection Time: 4.69070
Timestep Consumption Time: 0.68076
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.37146

Cumulative Model Updates: 42,247
Cumulative Timesteps: 704,725,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,490.78453
Policy Entropy: 1.11589
Value Function Loss: 5.72029

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.08260

Collected Steps per Second: 10,940.76229
Overall Steps per Second: 9,284.11872

Timestep Collection Time: 4.57189
Timestep Consumption Time: 0.81580
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.38770

Cumulative Model Updates: 42,250
Cumulative Timesteps: 704,775,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 704775298...
Checkpoint 704775298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,824.11888
Policy Entropy: 1.11915
Value Function Loss: 5.36108

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.06370
Value Function Update Magnitude: 0.07638

Collected Steps per Second: 10,969.68945
Overall Steps per Second: 9,369.24782

Timestep Collection Time: 4.56002
Timestep Consumption Time: 0.77894
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 5.33896

Cumulative Model Updates: 42,253
Cumulative Timesteps: 704,825,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,559.09143
Policy Entropy: 1.12025
Value Function Loss: 5.53862

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.07924
Value Function Update Magnitude: 0.07668

Collected Steps per Second: 10,940.40081
Overall Steps per Second: 9,277.83297

Timestep Collection Time: 4.57076
Timestep Consumption Time: 0.81907
PPO Batch Consumption Time: 0.04329
Total Iteration Time: 5.38984

Cumulative Model Updates: 42,256
Cumulative Timesteps: 704,875,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 704875326...
Checkpoint 704875326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,931.46695
Policy Entropy: 1.11454
Value Function Loss: 5.30961

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.07311
Value Function Update Magnitude: 0.08627

Collected Steps per Second: 10,680.21561
Overall Steps per Second: 9,165.78311

Timestep Collection Time: 4.68418
Timestep Consumption Time: 0.77395
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.45813

Cumulative Model Updates: 42,259
Cumulative Timesteps: 704,925,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464,488.80709
Policy Entropy: 1.12080
Value Function Loss: 5.39957

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.07764

Collected Steps per Second: 11,146.40285
Overall Steps per Second: 9,684.67796

Timestep Collection Time: 4.48755
Timestep Consumption Time: 0.67731
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.16486

Cumulative Model Updates: 42,262
Cumulative Timesteps: 704,975,374

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 704975374...
Checkpoint 704975374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422,756.49033
Policy Entropy: 1.11990
Value Function Loss: 5.28526

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.07159

Collected Steps per Second: 11,342.13383
Overall Steps per Second: 9,728.46924

Timestep Collection Time: 4.40852
Timestep Consumption Time: 0.73124
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 5.13976

Cumulative Model Updates: 42,265
Cumulative Timesteps: 705,025,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,197.29608
Policy Entropy: 1.12106
Value Function Loss: 5.21233

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.06029
Value Function Update Magnitude: 0.07419

Collected Steps per Second: 11,411.67830
Overall Steps per Second: 9,842.55899

Timestep Collection Time: 4.38393
Timestep Consumption Time: 0.69889
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 5.08282

Cumulative Model Updates: 42,268
Cumulative Timesteps: 705,075,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 705075404...
Checkpoint 705075404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,587.74656
Policy Entropy: 1.13111
Value Function Loss: 5.40086

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.07608

Collected Steps per Second: 11,244.68234
Overall Steps per Second: 9,470.73622

Timestep Collection Time: 4.44815
Timestep Consumption Time: 0.83317
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 5.28132

Cumulative Model Updates: 42,271
Cumulative Timesteps: 705,125,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,282.15861
Policy Entropy: 1.13067
Value Function Loss: 5.35118

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 11,442.82740
Overall Steps per Second: 9,751.15054

Timestep Collection Time: 4.37182
Timestep Consumption Time: 0.75844
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 5.13027

Cumulative Model Updates: 42,274
Cumulative Timesteps: 705,175,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 705175448...
Checkpoint 705175448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,443.21651
Policy Entropy: 1.13415
Value Function Loss: 5.24476

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.06430
Value Function Update Magnitude: 0.07026

Collected Steps per Second: 10,670.59819
Overall Steps per Second: 9,308.04463

Timestep Collection Time: 4.68690
Timestep Consumption Time: 0.68609
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.37299

Cumulative Model Updates: 42,277
Cumulative Timesteps: 705,225,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,790.35712
Policy Entropy: 1.11853
Value Function Loss: 5.07807

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.08022

Collected Steps per Second: 11,452.85837
Overall Steps per Second: 9,628.10413

Timestep Collection Time: 4.36590
Timestep Consumption Time: 0.82744
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 5.19334

Cumulative Model Updates: 42,280
Cumulative Timesteps: 705,275,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 705275462...
Checkpoint 705275462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,501.08827
Policy Entropy: 1.12790
Value Function Loss: 5.15334

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.08702

Collected Steps per Second: 11,124.79931
Overall Steps per Second: 9,478.89437

Timestep Collection Time: 4.49446
Timestep Consumption Time: 0.78041
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.27488

Cumulative Model Updates: 42,283
Cumulative Timesteps: 705,325,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,934.52558
Policy Entropy: 1.12882
Value Function Loss: 5.45668

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.08335

Collected Steps per Second: 11,300.26977
Overall Steps per Second: 9,593.95531

Timestep Collection Time: 4.42644
Timestep Consumption Time: 0.78726
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.21370

Cumulative Model Updates: 42,286
Cumulative Timesteps: 705,375,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 705375482...
Checkpoint 705375482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,188.65857
Policy Entropy: 1.11875
Value Function Loss: 5.50699

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.07701

Collected Steps per Second: 11,252.13379
Overall Steps per Second: 9,563.26946

Timestep Collection Time: 4.44591
Timestep Consumption Time: 0.78514
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.23106

Cumulative Model Updates: 42,289
Cumulative Timesteps: 705,425,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464,931.06891
Policy Entropy: 1.11215
Value Function Loss: 5.38632

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.08275

Collected Steps per Second: 10,817.22645
Overall Steps per Second: 9,414.60627

Timestep Collection Time: 4.62300
Timestep Consumption Time: 0.68875
PPO Batch Consumption Time: 0.03391
Total Iteration Time: 5.31175

Cumulative Model Updates: 42,292
Cumulative Timesteps: 705,475,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 705475516...
Checkpoint 705475516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398,908.86467
Policy Entropy: 1.12417
Value Function Loss: 5.24568

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.08086

Collected Steps per Second: 10,949.86308
Overall Steps per Second: 9,349.75139

Timestep Collection Time: 4.56864
Timestep Consumption Time: 0.78188
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.35052

Cumulative Model Updates: 42,295
Cumulative Timesteps: 705,525,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,391.80977
Policy Entropy: 1.12073
Value Function Loss: 5.07127

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.08023

Collected Steps per Second: 10,880.53737
Overall Steps per Second: 9,300.56332

Timestep Collection Time: 4.59830
Timestep Consumption Time: 0.78116
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.37946

Cumulative Model Updates: 42,298
Cumulative Timesteps: 705,575,574

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 705575574...
Checkpoint 705575574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352,325.85403
Policy Entropy: 1.10617
Value Function Loss: 5.13931

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.07929

Collected Steps per Second: 11,188.80042
Overall Steps per Second: 9,572.54366

Timestep Collection Time: 4.46947
Timestep Consumption Time: 0.75464
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.22411

Cumulative Model Updates: 42,301
Cumulative Timesteps: 705,625,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,286.19898
Policy Entropy: 1.11307
Value Function Loss: 5.30462

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.14118
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.07340

Collected Steps per Second: 10,595.23534
Overall Steps per Second: 9,111.72090

Timestep Collection Time: 4.72042
Timestep Consumption Time: 0.76855
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 5.48897

Cumulative Model Updates: 42,304
Cumulative Timesteps: 705,675,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 705675596...
Checkpoint 705675596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,452.47270
Policy Entropy: 1.12192
Value Function Loss: 5.44884

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.08969

Collected Steps per Second: 10,918.53788
Overall Steps per Second: 9,476.42227

Timestep Collection Time: 4.58175
Timestep Consumption Time: 0.69725
PPO Batch Consumption Time: 0.03758
Total Iteration Time: 5.27900

Cumulative Model Updates: 42,307
Cumulative Timesteps: 705,725,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,378.94348
Policy Entropy: 1.10524
Value Function Loss: 5.20365

Mean KL Divergence: 0.02707
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.08124

Collected Steps per Second: 10,324.06726
Overall Steps per Second: 8,808.10550

Timestep Collection Time: 4.84460
Timestep Consumption Time: 0.83380
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.67841

Cumulative Model Updates: 42,310
Cumulative Timesteps: 705,775,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 705775638...
Checkpoint 705775638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481,582.57286
Policy Entropy: 1.09964
Value Function Loss: 5.27814

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.07576

Collected Steps per Second: 10,665.26880
Overall Steps per Second: 9,304.91043

Timestep Collection Time: 4.68830
Timestep Consumption Time: 0.68542
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.37372

Cumulative Model Updates: 42,313
Cumulative Timesteps: 705,825,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,883.06694
Policy Entropy: 1.10582
Value Function Loss: 5.17669

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 10,830.82215
Overall Steps per Second: 9,237.29509

Timestep Collection Time: 4.61830
Timestep Consumption Time: 0.79670
PPO Batch Consumption Time: 0.03302
Total Iteration Time: 5.41501

Cumulative Model Updates: 42,316
Cumulative Timesteps: 705,875,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 705875660...
Checkpoint 705875660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,288.93243
Policy Entropy: 1.11304
Value Function Loss: 5.48170

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.07518

Collected Steps per Second: 10,788.71559
Overall Steps per Second: 9,232.98222

Timestep Collection Time: 4.63595
Timestep Consumption Time: 0.78115
PPO Batch Consumption Time: 0.03955
Total Iteration Time: 5.41710

Cumulative Model Updates: 42,319
Cumulative Timesteps: 705,925,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,875.24181
Policy Entropy: 1.09011
Value Function Loss: 5.35181

Mean KL Divergence: 0.03116
SB3 Clip Fraction: 0.15595
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.08075

Collected Steps per Second: 11,049.47823
Overall Steps per Second: 9,268.77145

Timestep Collection Time: 4.52745
Timestep Consumption Time: 0.86981
PPO Batch Consumption Time: 0.04363
Total Iteration Time: 5.39726

Cumulative Model Updates: 42,322
Cumulative Timesteps: 705,975,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 705975702...
Checkpoint 705975702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,710.94145
Policy Entropy: 1.10711
Value Function Loss: 5.23314

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.07723

Collected Steps per Second: 10,779.54585
Overall Steps per Second: 9,104.33129

Timestep Collection Time: 4.64027
Timestep Consumption Time: 0.85382
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.49409

Cumulative Model Updates: 42,325
Cumulative Timesteps: 706,025,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,367.78830
Policy Entropy: 1.10264
Value Function Loss: 5.26058

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.08095

Collected Steps per Second: 11,914.77551
Overall Steps per Second: 9,973.84841

Timestep Collection Time: 4.19798
Timestep Consumption Time: 0.81693
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 5.01491

Cumulative Model Updates: 42,328
Cumulative Timesteps: 706,075,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 706075740...
Checkpoint 706075740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,105.71897
Policy Entropy: 1.09579
Value Function Loss: 5.20052

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.07852

Collected Steps per Second: 11,784.06115
Overall Steps per Second: 9,676.45621

Timestep Collection Time: 4.24472
Timestep Consumption Time: 0.92453
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 5.16925

Cumulative Model Updates: 42,331
Cumulative Timesteps: 706,125,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,626.65385
Policy Entropy: 1.08857
Value Function Loss: 5.14780

Mean KL Divergence: 0.02636
SB3 Clip Fraction: 0.17031
Policy Update Magnitude: 0.04618
Value Function Update Magnitude: 0.08584

Collected Steps per Second: 12,508.55135
Overall Steps per Second: 10,479.25031

Timestep Collection Time: 3.99791
Timestep Consumption Time: 0.77419
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 4.77210

Cumulative Model Updates: 42,334
Cumulative Timesteps: 706,175,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 706175768...
Checkpoint 706175768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,150.21349
Policy Entropy: 1.10026
Value Function Loss: 5.04206

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.09564

Collected Steps per Second: 11,923.35210
Overall Steps per Second: 10,058.84725

Timestep Collection Time: 4.19563
Timestep Consumption Time: 0.77770
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 4.97333

Cumulative Model Updates: 42,337
Cumulative Timesteps: 706,225,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,328.13092
Policy Entropy: 1.10693
Value Function Loss: 5.22269

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.10037

Collected Steps per Second: 11,702.33321
Overall Steps per Second: 10,067.39212

Timestep Collection Time: 4.27487
Timestep Consumption Time: 0.69424
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 4.96911

Cumulative Model Updates: 42,340
Cumulative Timesteps: 706,275,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 706275820...
Checkpoint 706275820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,064.99074
Policy Entropy: 1.06555
Value Function Loss: 5.53919

Mean KL Divergence: 0.07630
SB3 Clip Fraction: 0.20307
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.10575

Collected Steps per Second: 10,310.72338
Overall Steps per Second: 8,697.74194

Timestep Collection Time: 4.85204
Timestep Consumption Time: 0.89980
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.75184

Cumulative Model Updates: 42,343
Cumulative Timesteps: 706,325,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,179.01563
Policy Entropy: 1.09624
Value Function Loss: 5.52099

Mean KL Divergence: 0.03945
SB3 Clip Fraction: 0.18504
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.11139

Collected Steps per Second: 11,146.39912
Overall Steps per Second: 9,633.99156

Timestep Collection Time: 4.48575
Timestep Consumption Time: 0.70420
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.18996

Cumulative Model Updates: 42,346
Cumulative Timesteps: 706,375,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 706375848...
Checkpoint 706375848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,581.12785
Policy Entropy: 1.07669
Value Function Loss: 5.20446

Mean KL Divergence: 0.03365
SB3 Clip Fraction: 0.17337
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.11411

Collected Steps per Second: 11,141.44910
Overall Steps per Second: 9,445.50669

Timestep Collection Time: 4.49008
Timestep Consumption Time: 0.80619
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 5.29627

Cumulative Model Updates: 42,349
Cumulative Timesteps: 706,425,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,851.10828
Policy Entropy: 1.09451
Value Function Loss: 5.04586

Mean KL Divergence: 0.02884
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.11044

Collected Steps per Second: 10,918.27199
Overall Steps per Second: 9,354.60029

Timestep Collection Time: 4.58076
Timestep Consumption Time: 0.76570
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.34646

Cumulative Model Updates: 42,352
Cumulative Timesteps: 706,475,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 706475888...
Checkpoint 706475888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,787.37789
Policy Entropy: 1.09495
Value Function Loss: 5.04598

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 11,124.18516
Overall Steps per Second: 9,673.81695

Timestep Collection Time: 4.49525
Timestep Consumption Time: 0.67396
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.16921

Cumulative Model Updates: 42,355
Cumulative Timesteps: 706,525,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,028.29709
Policy Entropy: 1.08021
Value Function Loss: 5.22685

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 11,099.62941
Overall Steps per Second: 9,309.48306

Timestep Collection Time: 4.50465
Timestep Consumption Time: 0.86621
PPO Batch Consumption Time: 0.04985
Total Iteration Time: 5.37087

Cumulative Model Updates: 42,358
Cumulative Timesteps: 706,575,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 706575894...
Checkpoint 706575894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,682.86641
Policy Entropy: 1.06927
Value Function Loss: 5.17844

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.16450
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.11374

Collected Steps per Second: 10,696.76307
Overall Steps per Second: 9,180.22605

Timestep Collection Time: 4.67469
Timestep Consumption Time: 0.77224
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 5.44692

Cumulative Model Updates: 42,361
Cumulative Timesteps: 706,625,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,234.59423
Policy Entropy: 1.07670
Value Function Loss: 4.89447

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.09651

Collected Steps per Second: 11,106.21519
Overall Steps per Second: 9,389.02006

Timestep Collection Time: 4.50216
Timestep Consumption Time: 0.82342
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.32558

Cumulative Model Updates: 42,364
Cumulative Timesteps: 706,675,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 706675900...
Checkpoint 706675900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,724.21678
Policy Entropy: 1.09482
Value Function Loss: 4.83882

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.08210

Collected Steps per Second: 11,016.08458
Overall Steps per Second: 9,273.21704

Timestep Collection Time: 4.54009
Timestep Consumption Time: 0.85329
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.39338

Cumulative Model Updates: 42,367
Cumulative Timesteps: 706,725,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,416.44699
Policy Entropy: 1.06634
Value Function Loss: 5.05095

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.16777
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.07216

Collected Steps per Second: 11,117.18802
Overall Steps per Second: 9,553.46210

Timestep Collection Time: 4.49772
Timestep Consumption Time: 0.73619
PPO Batch Consumption Time: 0.04046
Total Iteration Time: 5.23391

Cumulative Model Updates: 42,370
Cumulative Timesteps: 706,775,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 706775916...
Checkpoint 706775916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,989.53914
Policy Entropy: 1.08355
Value Function Loss: 5.22646

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.06211

Collected Steps per Second: 11,218.42262
Overall Steps per Second: 9,487.24383

Timestep Collection Time: 4.45838
Timestep Consumption Time: 0.81354
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.27192

Cumulative Model Updates: 42,373
Cumulative Timesteps: 706,825,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,976.26389
Policy Entropy: 1.08170
Value Function Loss: 5.07222

Mean KL Divergence: 0.02441
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.06034

Collected Steps per Second: 10,978.95346
Overall Steps per Second: 9,216.99457

Timestep Collection Time: 4.55599
Timestep Consumption Time: 0.87094
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.42693

Cumulative Model Updates: 42,376
Cumulative Timesteps: 706,875,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 706875952...
Checkpoint 706875952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,331.58741
Policy Entropy: 1.07452
Value Function Loss: 5.24025

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.05792

Collected Steps per Second: 10,821.78866
Overall Steps per Second: 9,298.53213

Timestep Collection Time: 4.62179
Timestep Consumption Time: 0.75713
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.37891

Cumulative Model Updates: 42,379
Cumulative Timesteps: 706,925,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,808.60078
Policy Entropy: 1.06324
Value Function Loss: 5.24173

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.17595
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.04907

Collected Steps per Second: 10,865.10080
Overall Steps per Second: 9,253.93759

Timestep Collection Time: 4.60355
Timestep Consumption Time: 0.80150
PPO Batch Consumption Time: 0.03991
Total Iteration Time: 5.40505

Cumulative Model Updates: 42,382
Cumulative Timesteps: 706,975,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 706975986...
Checkpoint 706975986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,586.19440
Policy Entropy: 1.07973
Value Function Loss: 5.39577

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.05369

Collected Steps per Second: 10,990.32673
Overall Steps per Second: 9,343.80441

Timestep Collection Time: 4.55182
Timestep Consumption Time: 0.80210
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.35392

Cumulative Model Updates: 42,385
Cumulative Timesteps: 707,026,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,273.78062
Policy Entropy: 1.08956
Value Function Loss: 5.31207

Mean KL Divergence: 0.02291
SB3 Clip Fraction: 0.15253
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.04972

Collected Steps per Second: 10,733.27189
Overall Steps per Second: 9,269.55709

Timestep Collection Time: 4.66065
Timestep Consumption Time: 0.73594
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.39659

Cumulative Model Updates: 42,388
Cumulative Timesteps: 707,076,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 707076036...
Checkpoint 707076036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,237.93373
Policy Entropy: 1.07067
Value Function Loss: 5.04665

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.04546

Collected Steps per Second: 10,648.17883
Overall Steps per Second: 9,303.88966

Timestep Collection Time: 4.69827
Timestep Consumption Time: 0.67884
PPO Batch Consumption Time: 0.03737
Total Iteration Time: 5.37711

Cumulative Model Updates: 42,391
Cumulative Timesteps: 707,126,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,055.36011
Policy Entropy: 1.06588
Value Function Loss: 5.20602

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.05044

Collected Steps per Second: 10,628.83272
Overall Steps per Second: 9,133.83440

Timestep Collection Time: 4.70550
Timestep Consumption Time: 0.77018
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 5.47569

Cumulative Model Updates: 42,394
Cumulative Timesteps: 707,176,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 707176078...
Checkpoint 707176078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,484.38448
Policy Entropy: 1.07366
Value Function Loss: 5.05287

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.04941

Collected Steps per Second: 11,338.63611
Overall Steps per Second: 9,794.49515

Timestep Collection Time: 4.41182
Timestep Consumption Time: 0.69554
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 5.10736

Cumulative Model Updates: 42,397
Cumulative Timesteps: 707,226,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,383.97333
Policy Entropy: 1.07701
Value Function Loss: 5.07463

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.04505

Collected Steps per Second: 11,265.61100
Overall Steps per Second: 9,629.96901

Timestep Collection Time: 4.43953
Timestep Consumption Time: 0.75405
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.19358

Cumulative Model Updates: 42,400
Cumulative Timesteps: 707,276,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 707276116...
Checkpoint 707276116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,012.24292
Policy Entropy: 1.06027
Value Function Loss: 4.93494

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.05406

Collected Steps per Second: 10,890.63926
Overall Steps per Second: 9,452.18423

Timestep Collection Time: 4.59183
Timestep Consumption Time: 0.69880
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.29063

Cumulative Model Updates: 42,403
Cumulative Timesteps: 707,326,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,718.43555
Policy Entropy: 1.05988
Value Function Loss: 4.99287

Mean KL Divergence: 0.03270
SB3 Clip Fraction: 0.15939
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.04989

Collected Steps per Second: 11,169.79119
Overall Steps per Second: 9,521.29117

Timestep Collection Time: 4.47761
Timestep Consumption Time: 0.77525
PPO Batch Consumption Time: 0.03852
Total Iteration Time: 5.25286

Cumulative Model Updates: 42,406
Cumulative Timesteps: 707,376,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 707376138...
Checkpoint 707376138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,115.02607
Policy Entropy: 1.07632
Value Function Loss: 5.21632

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.04742

Collected Steps per Second: 11,399.07069
Overall Steps per Second: 9,768.92935

Timestep Collection Time: 4.38773
Timestep Consumption Time: 0.73218
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.11991

Cumulative Model Updates: 42,409
Cumulative Timesteps: 707,426,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,623.48198
Policy Entropy: 1.08235
Value Function Loss: 5.27100

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.04968

Collected Steps per Second: 11,032.39591
Overall Steps per Second: 9,430.36677

Timestep Collection Time: 4.53229
Timestep Consumption Time: 0.76994
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.30223

Cumulative Model Updates: 42,412
Cumulative Timesteps: 707,476,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 707476156...
Checkpoint 707476156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,210.77173
Policy Entropy: 1.07189
Value Function Loss: 5.32903

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.04457

Collected Steps per Second: 11,293.38829
Overall Steps per Second: 9,586.95827

Timestep Collection Time: 4.42896
Timestep Consumption Time: 0.78833
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 5.21730

Cumulative Model Updates: 42,415
Cumulative Timesteps: 707,526,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,614.89652
Policy Entropy: 1.05999
Value Function Loss: 5.30954

Mean KL Divergence: 0.02989
SB3 Clip Fraction: 0.17819
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.04361

Collected Steps per Second: 11,261.24529
Overall Steps per Second: 9,770.48233

Timestep Collection Time: 4.44267
Timestep Consumption Time: 0.67785
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.12053

Cumulative Model Updates: 42,418
Cumulative Timesteps: 707,576,204

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 707576204...
Checkpoint 707576204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,879.20731
Policy Entropy: 1.08147
Value Function Loss: 5.33690

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.05248

Collected Steps per Second: 11,118.37942
Overall Steps per Second: 9,492.40152

Timestep Collection Time: 4.49868
Timestep Consumption Time: 0.77059
PPO Batch Consumption Time: 0.03341
Total Iteration Time: 5.26927

Cumulative Model Updates: 42,421
Cumulative Timesteps: 707,626,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,158.01651
Policy Entropy: 1.06580
Value Function Loss: 5.13218

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.04922

Collected Steps per Second: 10,953.85296
Overall Steps per Second: 9,361.49079

Timestep Collection Time: 4.56698
Timestep Consumption Time: 0.77683
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.34381

Cumulative Model Updates: 42,424
Cumulative Timesteps: 707,676,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 707676248...
Checkpoint 707676248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,882.71684
Policy Entropy: 1.06742
Value Function Loss: 5.10385

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.04703

Collected Steps per Second: 10,761.85930
Overall Steps per Second: 9,327.72412

Timestep Collection Time: 4.64771
Timestep Consumption Time: 0.71458
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.36229

Cumulative Model Updates: 42,427
Cumulative Timesteps: 707,726,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,908.73185
Policy Entropy: 1.07819
Value Function Loss: 5.29020

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 11,012.78883
Overall Steps per Second: 9,439.95098

Timestep Collection Time: 4.54163
Timestep Consumption Time: 0.75670
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 5.29833

Cumulative Model Updates: 42,430
Cumulative Timesteps: 707,776,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 707776282...
Checkpoint 707776282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,056.64933
Policy Entropy: 1.08016
Value Function Loss: 5.32106

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.15668
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.07011

Collected Steps per Second: 10,619.61375
Overall Steps per Second: 9,155.27391

Timestep Collection Time: 4.71091
Timestep Consumption Time: 0.75349
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 5.46439

Cumulative Model Updates: 42,433
Cumulative Timesteps: 707,826,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,537.31323
Policy Entropy: 1.06697
Value Function Loss: 5.36796

Mean KL Divergence: 0.02614
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.08693

Collected Steps per Second: 11,045.86113
Overall Steps per Second: 9,434.62703

Timestep Collection Time: 4.52731
Timestep Consumption Time: 0.77317
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.30047

Cumulative Model Updates: 42,436
Cumulative Timesteps: 707,876,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 707876318...
Checkpoint 707876318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,985.16956
Policy Entropy: 1.05776
Value Function Loss: 5.39302

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.08785

Collected Steps per Second: 10,784.11185
Overall Steps per Second: 9,297.25067

Timestep Collection Time: 4.63701
Timestep Consumption Time: 0.74157
PPO Batch Consumption Time: 0.03916
Total Iteration Time: 5.37858

Cumulative Model Updates: 42,439
Cumulative Timesteps: 707,926,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,276.17722
Policy Entropy: 1.06781
Value Function Loss: 5.67371

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.07747

Collected Steps per Second: 10,898.95026
Overall Steps per Second: 9,432.03193

Timestep Collection Time: 4.58852
Timestep Consumption Time: 0.71363
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.30214

Cumulative Model Updates: 42,442
Cumulative Timesteps: 707,976,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 707976334...
Checkpoint 707976334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,282.05290
Policy Entropy: 1.07841
Value Function Loss: 5.49474

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.07383

Collected Steps per Second: 10,281.40943
Overall Steps per Second: 8,701.34232

Timestep Collection Time: 4.86412
Timestep Consumption Time: 0.88327
PPO Batch Consumption Time: 0.04578
Total Iteration Time: 5.74739

Cumulative Model Updates: 42,445
Cumulative Timesteps: 708,026,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,375.52037
Policy Entropy: 1.04611
Value Function Loss: 5.21207

Mean KL Divergence: 0.05503
SB3 Clip Fraction: 0.18135
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.08465

Collected Steps per Second: 10,651.49879
Overall Steps per Second: 9,176.75271

Timestep Collection Time: 4.69624
Timestep Consumption Time: 0.75471
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 5.45095

Cumulative Model Updates: 42,448
Cumulative Timesteps: 708,076,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 708076366...
Checkpoint 708076366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,256.40134
Policy Entropy: 1.07418
Value Function Loss: 4.93860

Mean KL Divergence: 0.02863
SB3 Clip Fraction: 0.15222
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.09546

Collected Steps per Second: 11,135.17634
Overall Steps per Second: 9,481.69035

Timestep Collection Time: 4.49117
Timestep Consumption Time: 0.78320
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.27438

Cumulative Model Updates: 42,451
Cumulative Timesteps: 708,126,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,427.36630
Policy Entropy: 1.04757
Value Function Loss: 4.95405

Mean KL Divergence: 0.03177
SB3 Clip Fraction: 0.16059
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.08834

Collected Steps per Second: 10,974.35271
Overall Steps per Second: 9,329.21386

Timestep Collection Time: 4.55790
Timestep Consumption Time: 0.80375
PPO Batch Consumption Time: 0.03732
Total Iteration Time: 5.36165

Cumulative Model Updates: 42,454
Cumulative Timesteps: 708,176,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 708176396...
Checkpoint 708176396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,119.26165
Policy Entropy: 1.06386
Value Function Loss: 5.32883

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.07924

Collected Steps per Second: 10,938.38271
Overall Steps per Second: 9,450.64102

Timestep Collection Time: 4.57380
Timestep Consumption Time: 0.72002
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 5.29382

Cumulative Model Updates: 42,457
Cumulative Timesteps: 708,226,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,463.30847
Policy Entropy: 1.05806
Value Function Loss: 5.32160

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.08411

Collected Steps per Second: 10,765.88881
Overall Steps per Second: 9,075.43799

Timestep Collection Time: 4.64486
Timestep Consumption Time: 0.86518
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.51004

Cumulative Model Updates: 42,460
Cumulative Timesteps: 708,276,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 708276432...
Checkpoint 708276432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,619.88564
Policy Entropy: 1.07844
Value Function Loss: 5.50451

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.10060

Collected Steps per Second: 11,248.94960
Overall Steps per Second: 9,491.34439

Timestep Collection Time: 4.44664
Timestep Consumption Time: 0.82343
PPO Batch Consumption Time: 0.04043
Total Iteration Time: 5.27006

Cumulative Model Updates: 42,463
Cumulative Timesteps: 708,326,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,568.95925
Policy Entropy: 1.06792
Value Function Loss: 5.46878

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.10464

Collected Steps per Second: 11,674.44648
Overall Steps per Second: 10,109.69895

Timestep Collection Time: 4.28406
Timestep Consumption Time: 0.66307
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 4.94713

Cumulative Model Updates: 42,466
Cumulative Timesteps: 708,376,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 708376466...
Checkpoint 708376466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,838.99513
Policy Entropy: 1.06420
Value Function Loss: 5.36775

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.10486

Collected Steps per Second: 11,825.14879
Overall Steps per Second: 9,997.41218

Timestep Collection Time: 4.22878
Timestep Consumption Time: 0.77311
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.00189

Cumulative Model Updates: 42,469
Cumulative Timesteps: 708,426,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,417.16612
Policy Entropy: 1.07959
Value Function Loss: 5.41604

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.16317
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.10619

Collected Steps per Second: 11,708.42697
Overall Steps per Second: 9,925.26778

Timestep Collection Time: 4.27162
Timestep Consumption Time: 0.76743
PPO Batch Consumption Time: 0.03976
Total Iteration Time: 5.03906

Cumulative Model Updates: 42,472
Cumulative Timesteps: 708,476,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 708476486...
Checkpoint 708476486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,669.97618
Policy Entropy: 1.08867
Value Function Loss: 5.23770

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.11903

Collected Steps per Second: 12,049.10538
Overall Steps per Second: 10,119.14273

Timestep Collection Time: 4.15068
Timestep Consumption Time: 0.79163
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 4.94232

Cumulative Model Updates: 42,475
Cumulative Timesteps: 708,526,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,824.28074
Policy Entropy: 1.08382
Value Function Loss: 5.20049

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.11698

Collected Steps per Second: 11,092.68123
Overall Steps per Second: 9,388.82779

Timestep Collection Time: 4.50802
Timestep Consumption Time: 0.81810
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.32612

Cumulative Model Updates: 42,478
Cumulative Timesteps: 708,576,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 708576504...
Checkpoint 708576504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,346.64513
Policy Entropy: 1.07670
Value Function Loss: 5.02843

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.10544

Collected Steps per Second: 11,176.02816
Overall Steps per Second: 9,712.49760

Timestep Collection Time: 4.47547
Timestep Consumption Time: 0.67439
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.14986

Cumulative Model Updates: 42,481
Cumulative Timesteps: 708,626,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,973.68992
Policy Entropy: 1.08133
Value Function Loss: 5.05411

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.09844

Collected Steps per Second: 10,967.59479
Overall Steps per Second: 9,384.61136

Timestep Collection Time: 4.56089
Timestep Consumption Time: 0.76932
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.33022

Cumulative Model Updates: 42,484
Cumulative Timesteps: 708,676,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 708676544...
Checkpoint 708676544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,906.01642
Policy Entropy: 1.09081
Value Function Loss: 5.22300

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.15311
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.08081

Collected Steps per Second: 11,290.40740
Overall Steps per Second: 9,494.07239

Timestep Collection Time: 4.42872
Timestep Consumption Time: 0.83794
PPO Batch Consumption Time: 0.04584
Total Iteration Time: 5.26665

Cumulative Model Updates: 42,487
Cumulative Timesteps: 708,726,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,602.61856
Policy Entropy: 1.06228
Value Function Loss: 5.46136

Mean KL Divergence: 0.04080
SB3 Clip Fraction: 0.17754
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.09613

Collected Steps per Second: 11,429.53549
Overall Steps per Second: 9,712.13906

Timestep Collection Time: 4.37673
Timestep Consumption Time: 0.77394
PPO Batch Consumption Time: 0.03842
Total Iteration Time: 5.15067

Cumulative Model Updates: 42,490
Cumulative Timesteps: 708,776,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 708776570...
Checkpoint 708776570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,903.64900
Policy Entropy: 1.08049
Value Function Loss: 5.10611

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.09587

Collected Steps per Second: 10,957.42716
Overall Steps per Second: 9,347.31363

Timestep Collection Time: 4.56549
Timestep Consumption Time: 0.78642
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.35191

Cumulative Model Updates: 42,493
Cumulative Timesteps: 708,826,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,235.95020
Policy Entropy: 1.07602
Value Function Loss: 5.17659

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.08584

Collected Steps per Second: 10,693.40052
Overall Steps per Second: 9,350.74789

Timestep Collection Time: 4.67821
Timestep Consumption Time: 0.67173
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.34995

Cumulative Model Updates: 42,496
Cumulative Timesteps: 708,876,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 708876622...
Checkpoint 708876622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,620.39547
Policy Entropy: 1.07841
Value Function Loss: 4.68091

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.07642

Collected Steps per Second: 10,763.26516
Overall Steps per Second: 9,193.73097

Timestep Collection Time: 4.64785
Timestep Consumption Time: 0.79347
PPO Batch Consumption Time: 0.04437
Total Iteration Time: 5.44132

Cumulative Model Updates: 42,499
Cumulative Timesteps: 708,926,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,853.32244
Policy Entropy: 1.07172
Value Function Loss: 5.16926

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.07207

Collected Steps per Second: 10,691.57905
Overall Steps per Second: 9,201.05379

Timestep Collection Time: 4.67751
Timestep Consumption Time: 0.75773
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.43525

Cumulative Model Updates: 42,502
Cumulative Timesteps: 708,976,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 708976658...
Checkpoint 708976658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481,007.01547
Policy Entropy: 1.08827
Value Function Loss: 5.20473

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.07101

Collected Steps per Second: 11,039.90598
Overall Steps per Second: 9,376.62015

Timestep Collection Time: 4.52939
Timestep Consumption Time: 0.80345
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.33284

Cumulative Model Updates: 42,505
Cumulative Timesteps: 709,026,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,512.76736
Policy Entropy: 1.08622
Value Function Loss: 5.34367

Mean KL Divergence: 0.02338
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.07268

Collected Steps per Second: 11,014.97832
Overall Steps per Second: 9,437.10834

Timestep Collection Time: 4.54036
Timestep Consumption Time: 0.75914
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 5.29950

Cumulative Model Updates: 42,508
Cumulative Timesteps: 709,076,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 709076674...
Checkpoint 709076674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,471.51815
Policy Entropy: 1.07412
Value Function Loss: 5.12440

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 10,986.14478
Overall Steps per Second: 9,564.61275

Timestep Collection Time: 4.55210
Timestep Consumption Time: 0.67655
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 5.22865

Cumulative Model Updates: 42,511
Cumulative Timesteps: 709,126,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,010.78112
Policy Entropy: 1.06392
Value Function Loss: 4.79834

Mean KL Divergence: 0.02749
SB3 Clip Fraction: 0.16399
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.07250

Collected Steps per Second: 10,362.12625
Overall Steps per Second: 8,877.77555

Timestep Collection Time: 4.82700
Timestep Consumption Time: 0.80707
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.63407

Cumulative Model Updates: 42,514
Cumulative Timesteps: 709,176,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 709176702...
Checkpoint 709176702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,419.54779
Policy Entropy: 1.09111
Value Function Loss: 4.90446

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 10,750.24440
Overall Steps per Second: 9,266.65226

Timestep Collection Time: 4.65348
Timestep Consumption Time: 0.74502
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.39850

Cumulative Model Updates: 42,517
Cumulative Timesteps: 709,226,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,329.62772
Policy Entropy: 1.08370
Value Function Loss: 4.85590

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.07699

Collected Steps per Second: 11,059.82967
Overall Steps per Second: 9,440.57676

Timestep Collection Time: 4.52304
Timestep Consumption Time: 0.77579
PPO Batch Consumption Time: 0.03359
Total Iteration Time: 5.29883

Cumulative Model Updates: 42,520
Cumulative Timesteps: 709,276,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 709276752...
Checkpoint 709276752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,554.07773
Policy Entropy: 1.06984
Value Function Loss: 5.19736

Mean KL Divergence: 0.03306
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.08086

Collected Steps per Second: 10,614.49228
Overall Steps per Second: 9,087.37509

Timestep Collection Time: 4.71318
Timestep Consumption Time: 0.79204
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.50522

Cumulative Model Updates: 42,523
Cumulative Timesteps: 709,326,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,324.03560
Policy Entropy: 1.08481
Value Function Loss: 5.16281

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.08607

Collected Steps per Second: 11,168.24749
Overall Steps per Second: 9,548.15072

Timestep Collection Time: 4.47913
Timestep Consumption Time: 0.76000
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.23913

Cumulative Model Updates: 42,526
Cumulative Timesteps: 709,376,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 709376804...
Checkpoint 709376804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,950.35825
Policy Entropy: 1.08067
Value Function Loss: 5.27801

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.08078

Collected Steps per Second: 10,573.48591
Overall Steps per Second: 9,083.58084

Timestep Collection Time: 4.72938
Timestep Consumption Time: 0.77572
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.50510

Cumulative Model Updates: 42,529
Cumulative Timesteps: 709,426,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,292.18754
Policy Entropy: 1.06874
Value Function Loss: 5.19667

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.06424
Value Function Update Magnitude: 0.07706

Collected Steps per Second: 11,370.21759
Overall Steps per Second: 9,880.33607

Timestep Collection Time: 4.39974
Timestep Consumption Time: 0.66345
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.06319

Cumulative Model Updates: 42,532
Cumulative Timesteps: 709,476,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 709476836...
Checkpoint 709476836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,882.61125
Policy Entropy: 1.06046
Value Function Loss: 5.29587

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.06755
Value Function Update Magnitude: 0.09231

Collected Steps per Second: 11,315.07907
Overall Steps per Second: 9,642.18903

Timestep Collection Time: 4.41994
Timestep Consumption Time: 0.76685
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.18679

Cumulative Model Updates: 42,535
Cumulative Timesteps: 709,526,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,678.81554
Policy Entropy: 1.07980
Value Function Loss: 5.20989

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.14266
Policy Update Magnitude: 0.05900
Value Function Update Magnitude: 0.08829

Collected Steps per Second: 11,574.32367
Overall Steps per Second: 9,985.43466

Timestep Collection Time: 4.32181
Timestep Consumption Time: 0.68769
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.00950

Cumulative Model Updates: 42,538
Cumulative Timesteps: 709,576,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 709576870...
Checkpoint 709576870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,067.34951
Policy Entropy: 1.09233
Value Function Loss: 5.06195

Mean KL Divergence: 0.02390
SB3 Clip Fraction: 0.15359
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 11,308.47743
Overall Steps per Second: 9,645.22577

Timestep Collection Time: 4.42323
Timestep Consumption Time: 0.76276
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.18599

Cumulative Model Updates: 42,541
Cumulative Timesteps: 709,626,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,139.89332
Policy Entropy: 1.07604
Value Function Loss: 5.04876

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.09828

Collected Steps per Second: 11,301.25111
Overall Steps per Second: 9,721.29546

Timestep Collection Time: 4.42624
Timestep Consumption Time: 0.71937
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 5.14561

Cumulative Model Updates: 42,544
Cumulative Timesteps: 709,676,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 709676912...
Checkpoint 709676912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,358.16079
Policy Entropy: 1.06618
Value Function Loss: 4.81244

Mean KL Divergence: 0.03286
SB3 Clip Fraction: 0.15202
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.10134

Collected Steps per Second: 10,988.37910
Overall Steps per Second: 9,399.85630

Timestep Collection Time: 4.55117
Timestep Consumption Time: 0.76912
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 5.32029

Cumulative Model Updates: 42,547
Cumulative Timesteps: 709,726,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408,832.91072
Policy Entropy: 1.07929
Value Function Loss: 4.96199

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 11,357.42435
Overall Steps per Second: 9,632.81769

Timestep Collection Time: 4.40276
Timestep Consumption Time: 0.78825
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.19100

Cumulative Model Updates: 42,550
Cumulative Timesteps: 709,776,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 709776926...
Checkpoint 709776926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,453.90846
Policy Entropy: 1.07399
Value Function Loss: 5.06761

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.09986

Collected Steps per Second: 11,027.68040
Overall Steps per Second: 9,541.44207

Timestep Collection Time: 4.53677
Timestep Consumption Time: 0.70668
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.24344

Cumulative Model Updates: 42,553
Cumulative Timesteps: 709,826,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,258.17307
Policy Entropy: 1.05528
Value Function Loss: 5.35500

Mean KL Divergence: 0.04043
SB3 Clip Fraction: 0.18291
Policy Update Magnitude: 0.06755
Value Function Update Magnitude: 0.08452

Collected Steps per Second: 11,032.27529
Overall Steps per Second: 9,379.04389

Timestep Collection Time: 4.53433
Timestep Consumption Time: 0.79926
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.33359

Cumulative Model Updates: 42,556
Cumulative Timesteps: 709,876,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 709876980...
Checkpoint 709876980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,297.17460
Policy Entropy: 1.07201
Value Function Loss: 5.25459

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.07331

Collected Steps per Second: 11,366.48322
Overall Steps per Second: 9,810.50388

Timestep Collection Time: 4.40119
Timestep Consumption Time: 0.69804
PPO Batch Consumption Time: 0.03843
Total Iteration Time: 5.09923

Cumulative Model Updates: 42,559
Cumulative Timesteps: 709,927,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,059.45781
Policy Entropy: 1.07320
Value Function Loss: 5.20307

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.07139

Collected Steps per Second: 11,107.29892
Overall Steps per Second: 9,446.78919

Timestep Collection Time: 4.50280
Timestep Consumption Time: 0.79148
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.29429

Cumulative Model Updates: 42,562
Cumulative Timesteps: 709,977,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 709977020...
Checkpoint 709977020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,625.93773
Policy Entropy: 1.06628
Value Function Loss: 4.89669

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.07196

Collected Steps per Second: 10,260.21671
Overall Steps per Second: 8,919.66494

Timestep Collection Time: 4.87378
Timestep Consumption Time: 0.73249
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.60626

Cumulative Model Updates: 42,565
Cumulative Timesteps: 710,027,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,446.45056
Policy Entropy: 1.05189
Value Function Loss: 5.10965

Mean KL Divergence: 0.03031
SB3 Clip Fraction: 0.16033
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.07186

Collected Steps per Second: 10,983.43291
Overall Steps per Second: 9,285.89413

Timestep Collection Time: 4.55413
Timestep Consumption Time: 0.83253
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.38666

Cumulative Model Updates: 42,568
Cumulative Timesteps: 710,077,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 710077046...
Checkpoint 710077046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,735.42400
Policy Entropy: 1.07515
Value Function Loss: 5.15145

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.07961

Collected Steps per Second: 11,023.46184
Overall Steps per Second: 9,475.90330

Timestep Collection Time: 4.53632
Timestep Consumption Time: 0.74085
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.27718

Cumulative Model Updates: 42,571
Cumulative Timesteps: 710,127,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,935.46831
Policy Entropy: 1.07372
Value Function Loss: 5.45138

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.07554

Collected Steps per Second: 10,716.02994
Overall Steps per Second: 9,367.71870

Timestep Collection Time: 4.66703
Timestep Consumption Time: 0.67173
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.33876

Cumulative Model Updates: 42,574
Cumulative Timesteps: 710,177,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 710177064...
Checkpoint 710177064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,010.08141
Policy Entropy: 1.06812
Value Function Loss: 5.40278

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.07663

Collected Steps per Second: 10,947.30191
Overall Steps per Second: 9,284.72028

Timestep Collection Time: 4.56843
Timestep Consumption Time: 0.81805
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.38648

Cumulative Model Updates: 42,577
Cumulative Timesteps: 710,227,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,018.73519
Policy Entropy: 1.07030
Value Function Loss: 5.19592

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.08639

Collected Steps per Second: 10,600.26362
Overall Steps per Second: 9,110.60128

Timestep Collection Time: 4.71705
Timestep Consumption Time: 0.77128
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.48833

Cumulative Model Updates: 42,580
Cumulative Timesteps: 710,277,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 710277078...
Checkpoint 710277078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,376.02443
Policy Entropy: 1.06829
Value Function Loss: 5.08563

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.08979

Collected Steps per Second: 11,041.08430
Overall Steps per Second: 9,440.85263

Timestep Collection Time: 4.52927
Timestep Consumption Time: 0.76771
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.29698

Cumulative Model Updates: 42,583
Cumulative Timesteps: 710,327,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,925.13418
Policy Entropy: 1.08506
Value Function Loss: 4.94130

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.08193

Collected Steps per Second: 10,788.95414
Overall Steps per Second: 9,179.08606

Timestep Collection Time: 4.63437
Timestep Consumption Time: 0.81280
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.44717

Cumulative Model Updates: 42,586
Cumulative Timesteps: 710,377,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 710377086...
Checkpoint 710377086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,640.26339
Policy Entropy: 1.07568
Value Function Loss: 4.93877

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.09003

Collected Steps per Second: 10,781.62094
Overall Steps per Second: 9,360.77636

Timestep Collection Time: 4.63752
Timestep Consumption Time: 0.70392
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.34144

Cumulative Model Updates: 42,589
Cumulative Timesteps: 710,427,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,621.53553
Policy Entropy: 1.08741
Value Function Loss: 4.90058

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.10054

Collected Steps per Second: 10,931.36874
Overall Steps per Second: 9,327.78283

Timestep Collection Time: 4.57637
Timestep Consumption Time: 0.78675
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.36312

Cumulative Model Updates: 42,592
Cumulative Timesteps: 710,477,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 710477112...
Checkpoint 710477112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,508.11089
Policy Entropy: 1.08137
Value Function Loss: 4.86507

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.06960
Value Function Update Magnitude: 0.09128

Collected Steps per Second: 10,720.21286
Overall Steps per Second: 9,157.27577

Timestep Collection Time: 4.66558
Timestep Consumption Time: 0.79631
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.46189

Cumulative Model Updates: 42,595
Cumulative Timesteps: 710,527,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,236.32770
Policy Entropy: 1.08605
Value Function Loss: 4.78035

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.07228
Value Function Update Magnitude: 0.08763

Collected Steps per Second: 11,084.57829
Overall Steps per Second: 9,421.68112

Timestep Collection Time: 4.51185
Timestep Consumption Time: 0.79633
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 5.30818

Cumulative Model Updates: 42,598
Cumulative Timesteps: 710,577,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 710577140...
Checkpoint 710577140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,150.77617
Policy Entropy: 1.09426
Value Function Loss: 4.93578

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.08803

Collected Steps per Second: 11,769.15822
Overall Steps per Second: 9,943.92875

Timestep Collection Time: 4.25077
Timestep Consumption Time: 0.78024
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.03101

Cumulative Model Updates: 42,601
Cumulative Timesteps: 710,627,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,713.09355
Policy Entropy: 1.10158
Value Function Loss: 5.16663

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.08367

Collected Steps per Second: 11,635.01256
Overall Steps per Second: 9,959.94182

Timestep Collection Time: 4.29944
Timestep Consumption Time: 0.72308
PPO Batch Consumption Time: 0.03969
Total Iteration Time: 5.02252

Cumulative Model Updates: 42,604
Cumulative Timesteps: 710,677,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 710677192...
Checkpoint 710677192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,571.32640
Policy Entropy: 1.10934
Value Function Loss: 5.21862

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.14551
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.07014

Collected Steps per Second: 11,762.52845
Overall Steps per Second: 9,925.03946

Timestep Collection Time: 4.25164
Timestep Consumption Time: 0.78713
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.03877

Cumulative Model Updates: 42,607
Cumulative Timesteps: 710,727,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,574.18416
Policy Entropy: 1.09065
Value Function Loss: 5.11933

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.06143

Collected Steps per Second: 11,626.31778
Overall Steps per Second: 10,043.46963

Timestep Collection Time: 4.30231
Timestep Consumption Time: 0.67804
PPO Batch Consumption Time: 0.03350
Total Iteration Time: 4.98035

Cumulative Model Updates: 42,610
Cumulative Timesteps: 710,777,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 710777222...
Checkpoint 710777222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,911.16333
Policy Entropy: 1.08917
Value Function Loss: 5.09787

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.05715

Collected Steps per Second: 11,739.98862
Overall Steps per Second: 9,922.43871

Timestep Collection Time: 4.25980
Timestep Consumption Time: 0.78029
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 5.04009

Cumulative Model Updates: 42,613
Cumulative Timesteps: 710,827,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,199.04215
Policy Entropy: 1.10507
Value Function Loss: 5.52573

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.05202

Collected Steps per Second: 10,909.70203
Overall Steps per Second: 9,380.69555

Timestep Collection Time: 4.58473
Timestep Consumption Time: 0.74729
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.33201

Cumulative Model Updates: 42,616
Cumulative Timesteps: 710,877,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 710877250...
Checkpoint 710877250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450,653.28707
Policy Entropy: 1.10420
Value Function Loss: 5.64951

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.04956

Collected Steps per Second: 11,130.85399
Overall Steps per Second: 9,585.89222

Timestep Collection Time: 4.49310
Timestep Consumption Time: 0.72415
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.21725

Cumulative Model Updates: 42,619
Cumulative Timesteps: 710,927,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,820.50568
Policy Entropy: 1.09843
Value Function Loss: 5.64411

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.11113
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 11,028.68315
Overall Steps per Second: 9,387.92853

Timestep Collection Time: 4.53472
Timestep Consumption Time: 0.79255
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.32727

Cumulative Model Updates: 42,622
Cumulative Timesteps: 710,977,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 710977274...
Checkpoint 710977274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,634.74057
Policy Entropy: 1.07585
Value Function Loss: 5.30615

Mean KL Divergence: 0.03264
SB3 Clip Fraction: 0.17446
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.07345

Collected Steps per Second: 11,014.24680
Overall Steps per Second: 9,560.41583

Timestep Collection Time: 4.54121
Timestep Consumption Time: 0.69057
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.23178

Cumulative Model Updates: 42,625
Cumulative Timesteps: 711,027,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,815.28746
Policy Entropy: 1.08864
Value Function Loss: 4.98010

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.07077

Collected Steps per Second: 11,256.35051
Overall Steps per Second: 9,553.46908

Timestep Collection Time: 4.44442
Timestep Consumption Time: 0.79221
PPO Batch Consumption Time: 0.03926
Total Iteration Time: 5.23663

Cumulative Model Updates: 42,628
Cumulative Timesteps: 711,077,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 711077320...
Checkpoint 711077320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,414.49834
Policy Entropy: 1.09503
Value Function Loss: 4.90779

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 10,863.21380
Overall Steps per Second: 9,256.11950

Timestep Collection Time: 4.60287
Timestep Consumption Time: 0.79917
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.40205

Cumulative Model Updates: 42,631
Cumulative Timesteps: 711,127,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,947.96279
Policy Entropy: 1.08757
Value Function Loss: 5.00339

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.07277

Collected Steps per Second: 11,268.70126
Overall Steps per Second: 9,581.28449

Timestep Collection Time: 4.43760
Timestep Consumption Time: 0.78153
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 5.21913

Cumulative Model Updates: 42,634
Cumulative Timesteps: 711,177,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 711177328...
Checkpoint 711177328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,217.77109
Policy Entropy: 1.08721
Value Function Loss: 5.40018

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.08419

Collected Steps per Second: 10,703.84890
Overall Steps per Second: 9,142.37103

Timestep Collection Time: 4.67309
Timestep Consumption Time: 0.79814
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.47123

Cumulative Model Updates: 42,637
Cumulative Timesteps: 711,227,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,322.17910
Policy Entropy: 1.09594
Value Function Loss: 5.36106

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.07600

Collected Steps per Second: 10,704.19622
Overall Steps per Second: 9,328.85951

Timestep Collection Time: 4.67219
Timestep Consumption Time: 0.68881
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.36100

Cumulative Model Updates: 42,640
Cumulative Timesteps: 711,277,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 711277360...
Checkpoint 711277360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397,592.18192
Policy Entropy: 1.10480
Value Function Loss: 5.30691

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.07425

Collected Steps per Second: 10,470.17370
Overall Steps per Second: 8,997.26746

Timestep Collection Time: 4.77585
Timestep Consumption Time: 0.78184
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.55769

Cumulative Model Updates: 42,643
Cumulative Timesteps: 711,327,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,100.34194
Policy Entropy: 1.08255
Value Function Loss: 5.17994

Mean KL Divergence: 0.03069
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.07426

Collected Steps per Second: 10,715.47774
Overall Steps per Second: 9,373.67891

Timestep Collection Time: 4.66764
Timestep Consumption Time: 0.66815
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.33579

Cumulative Model Updates: 42,646
Cumulative Timesteps: 711,377,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 711377380...
Checkpoint 711377380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,912.57836
Policy Entropy: 1.10652
Value Function Loss: 5.04712

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.07966

Collected Steps per Second: 10,459.70408
Overall Steps per Second: 8,956.37669

Timestep Collection Time: 4.78101
Timestep Consumption Time: 0.80249
PPO Batch Consumption Time: 0.03993
Total Iteration Time: 5.58351

Cumulative Model Updates: 42,649
Cumulative Timesteps: 711,427,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,181.80940
Policy Entropy: 1.10980
Value Function Loss: 5.05860

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.08614

Collected Steps per Second: 10,726.42429
Overall Steps per Second: 9,194.03516

Timestep Collection Time: 4.66400
Timestep Consumption Time: 0.77736
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.44135

Cumulative Model Updates: 42,652
Cumulative Timesteps: 711,477,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 711477416...
Checkpoint 711477416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,486.19916
Policy Entropy: 1.09949
Value Function Loss: 5.15373

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.07992

Collected Steps per Second: 10,904.21092
Overall Steps per Second: 9,189.28882

Timestep Collection Time: 4.58630
Timestep Consumption Time: 0.85590
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.44221

Cumulative Model Updates: 42,655
Cumulative Timesteps: 711,527,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,090.69165
Policy Entropy: 1.09206
Value Function Loss: 5.27287

Mean KL Divergence: 0.03014
SB3 Clip Fraction: 0.15775
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.07162

Collected Steps per Second: 10,997.70393
Overall Steps per Second: 9,361.35968

Timestep Collection Time: 4.54695
Timestep Consumption Time: 0.79480
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.34175

Cumulative Model Updates: 42,658
Cumulative Timesteps: 711,577,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 711577432...
Checkpoint 711577432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,291.11686
Policy Entropy: 1.10156
Value Function Loss: 5.12366

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.06860

Collected Steps per Second: 10,972.51725
Overall Steps per Second: 9,494.67047

Timestep Collection Time: 4.55684
Timestep Consumption Time: 0.70927
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.26611

Cumulative Model Updates: 42,661
Cumulative Timesteps: 711,627,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,614.23541
Policy Entropy: 1.10520
Value Function Loss: 5.11198

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.04424
Value Function Update Magnitude: 0.07037

Collected Steps per Second: 10,548.24796
Overall Steps per Second: 9,017.71859

Timestep Collection Time: 4.74069
Timestep Consumption Time: 0.80461
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 5.54530

Cumulative Model Updates: 42,664
Cumulative Timesteps: 711,677,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 711677438...
Checkpoint 711677438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,313.27090
Policy Entropy: 1.08661
Value Function Loss: 4.93032

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.07101

Collected Steps per Second: 10,921.41921
Overall Steps per Second: 9,362.43562

Timestep Collection Time: 4.58036
Timestep Consumption Time: 0.76270
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 5.34305

Cumulative Model Updates: 42,667
Cumulative Timesteps: 711,727,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,325.47646
Policy Entropy: 1.09748
Value Function Loss: 5.12606

Mean KL Divergence: 0.02608
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.07719

Collected Steps per Second: 11,526.12754
Overall Steps per Second: 9,775.66661

Timestep Collection Time: 4.33988
Timestep Consumption Time: 0.77711
PPO Batch Consumption Time: 0.03991
Total Iteration Time: 5.11699

Cumulative Model Updates: 42,670
Cumulative Timesteps: 711,777,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 711777484...
Checkpoint 711777484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,324.11335
Policy Entropy: 1.09216
Value Function Loss: 4.90386

Mean KL Divergence: 0.02639
SB3 Clip Fraction: 0.14588
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 11,169.53666
Overall Steps per Second: 9,498.01565

Timestep Collection Time: 4.47700
Timestep Consumption Time: 0.78789
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.26489

Cumulative Model Updates: 42,673
Cumulative Timesteps: 711,827,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,182.00869
Policy Entropy: 1.09345
Value Function Loss: 4.99088

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.07892

Collected Steps per Second: 11,331.47171
Overall Steps per Second: 9,767.32863

Timestep Collection Time: 4.41478
Timestep Consumption Time: 0.70698
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.12177

Cumulative Model Updates: 42,676
Cumulative Timesteps: 711,877,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 711877516...
Checkpoint 711877516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,195.79432
Policy Entropy: 1.08614
Value Function Loss: 5.05997

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.08956

Collected Steps per Second: 11,276.65104
Overall Steps per Second: 9,582.93173

Timestep Collection Time: 4.43571
Timestep Consumption Time: 0.78398
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.21970

Cumulative Model Updates: 42,679
Cumulative Timesteps: 711,927,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,918.27445
Policy Entropy: 1.09899
Value Function Loss: 5.35242

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.08312

Collected Steps per Second: 10,710.10662
Overall Steps per Second: 9,172.03772

Timestep Collection Time: 4.66942
Timestep Consumption Time: 0.78302
PPO Batch Consumption Time: 0.03816
Total Iteration Time: 5.45244

Cumulative Model Updates: 42,682
Cumulative Timesteps: 711,977,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 711977546...
Checkpoint 711977546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,457.88968
Policy Entropy: 1.10341
Value Function Loss: 5.38063

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.08546

Collected Steps per Second: 11,059.24410
Overall Steps per Second: 9,411.04772

Timestep Collection Time: 4.52291
Timestep Consumption Time: 0.79212
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.31503

Cumulative Model Updates: 42,685
Cumulative Timesteps: 712,027,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,589.69969
Policy Entropy: 1.07739
Value Function Loss: 5.16515

Mean KL Divergence: 0.04265
SB3 Clip Fraction: 0.15703
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.07806

Collected Steps per Second: 11,077.37430
Overall Steps per Second: 9,409.48414

Timestep Collection Time: 4.51587
Timestep Consumption Time: 0.80047
PPO Batch Consumption Time: 0.03746
Total Iteration Time: 5.31634

Cumulative Model Updates: 42,688
Cumulative Timesteps: 712,077,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 712077590...
Checkpoint 712077590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,449.28811
Policy Entropy: 1.08844
Value Function Loss: 5.06152

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.07615

Collected Steps per Second: 11,062.38312
Overall Steps per Second: 9,624.64019

Timestep Collection Time: 4.52145
Timestep Consumption Time: 0.67542
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.19687

Cumulative Model Updates: 42,691
Cumulative Timesteps: 712,127,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,914.57466
Policy Entropy: 1.08479
Value Function Loss: 5.13431

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.07577

Collected Steps per Second: 11,052.27797
Overall Steps per Second: 9,412.57086

Timestep Collection Time: 4.52594
Timestep Consumption Time: 0.78844
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.31438

Cumulative Model Updates: 42,694
Cumulative Timesteps: 712,177,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 712177630...
Checkpoint 712177630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,720.70308
Policy Entropy: 1.08651
Value Function Loss: 4.95011

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.07195

Collected Steps per Second: 10,818.28638
Overall Steps per Second: 9,293.67097

Timestep Collection Time: 4.62291
Timestep Consumption Time: 0.75838
PPO Batch Consumption Time: 0.03325
Total Iteration Time: 5.38130

Cumulative Model Updates: 42,697
Cumulative Timesteps: 712,227,642

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,769.45013
Policy Entropy: 1.08423
Value Function Loss: 4.79725

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.07551

Collected Steps per Second: 10,661.86247
Overall Steps per Second: 9,167.70954

Timestep Collection Time: 4.69168
Timestep Consumption Time: 0.76465
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.45632

Cumulative Model Updates: 42,700
Cumulative Timesteps: 712,277,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 712277664...
Checkpoint 712277664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,778.73397
Policy Entropy: 1.10516
Value Function Loss: 4.87324

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.07559

Collected Steps per Second: 10,879.41629
Overall Steps per Second: 9,327.35802

Timestep Collection Time: 4.59694
Timestep Consumption Time: 0.76492
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.36186

Cumulative Model Updates: 42,703
Cumulative Timesteps: 712,327,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,447.99568
Policy Entropy: 1.09726
Value Function Loss: 5.29555

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.07052

Collected Steps per Second: 11,114.75636
Overall Steps per Second: 9,641.12651

Timestep Collection Time: 4.49870
Timestep Consumption Time: 0.68762
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.18632

Cumulative Model Updates: 42,706
Cumulative Timesteps: 712,377,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 712377678...
Checkpoint 712377678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,866.35355
Policy Entropy: 1.10088
Value Function Loss: 5.36251

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.07691

Collected Steps per Second: 10,749.81104
Overall Steps per Second: 9,264.44680

Timestep Collection Time: 4.65143
Timestep Consumption Time: 0.74576
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.39719

Cumulative Model Updates: 42,709
Cumulative Timesteps: 712,427,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,581.47830
Policy Entropy: 1.09988
Value Function Loss: 5.24478

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.08070

Collected Steps per Second: 10,726.22905
Overall Steps per Second: 9,225.26869

Timestep Collection Time: 4.66315
Timestep Consumption Time: 0.75870
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 5.42185

Cumulative Model Updates: 42,712
Cumulative Timesteps: 712,477,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 712477698...
Checkpoint 712477698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,570.46389
Policy Entropy: 1.09728
Value Function Loss: 4.87502

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.07649

Collected Steps per Second: 10,995.19387
Overall Steps per Second: 9,359.28879

Timestep Collection Time: 4.54890
Timestep Consumption Time: 0.79510
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.34400

Cumulative Model Updates: 42,715
Cumulative Timesteps: 712,527,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,608.58573
Policy Entropy: 1.08220
Value Function Loss: 4.81798

Mean KL Divergence: 0.03089
SB3 Clip Fraction: 0.15579
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.07184

Collected Steps per Second: 10,701.94376
Overall Steps per Second: 9,182.62606

Timestep Collection Time: 4.67485
Timestep Consumption Time: 0.77348
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.44833

Cumulative Model Updates: 42,718
Cumulative Timesteps: 712,577,744

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 712577744...
Checkpoint 712577744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,939.56828
Policy Entropy: 1.09616
Value Function Loss: 4.85404

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.07254

Collected Steps per Second: 10,832.16530
Overall Steps per Second: 9,413.44360

Timestep Collection Time: 4.61644
Timestep Consumption Time: 0.69575
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.31219

Cumulative Model Updates: 42,721
Cumulative Timesteps: 712,627,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,180.61746
Policy Entropy: 1.11060
Value Function Loss: 4.77680

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.08403

Collected Steps per Second: 10,978.79826
Overall Steps per Second: 9,334.66431

Timestep Collection Time: 4.55551
Timestep Consumption Time: 0.80237
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 5.35788

Cumulative Model Updates: 42,724
Cumulative Timesteps: 712,677,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 712677764...
Checkpoint 712677764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,738.42826
Policy Entropy: 1.09438
Value Function Loss: 4.87485

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.07895

Collected Steps per Second: 10,803.47312
Overall Steps per Second: 9,302.35689

Timestep Collection Time: 4.63110
Timestep Consumption Time: 0.74732
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.37842

Cumulative Model Updates: 42,727
Cumulative Timesteps: 712,727,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,415.21755
Policy Entropy: 1.09075
Value Function Loss: 4.97558

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.08259

Collected Steps per Second: 11,037.16946
Overall Steps per Second: 9,393.13958

Timestep Collection Time: 4.53051
Timestep Consumption Time: 0.79295
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.32346

Cumulative Model Updates: 42,730
Cumulative Timesteps: 712,777,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 712777800...
Checkpoint 712777800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,811.80077
Policy Entropy: 1.10129
Value Function Loss: 5.37324

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.08395

Collected Steps per Second: 11,003.28339
Overall Steps per Second: 9,441.34210

Timestep Collection Time: 4.54701
Timestep Consumption Time: 0.75224
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 5.29925

Cumulative Model Updates: 42,733
Cumulative Timesteps: 712,827,832

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,947.98015
Policy Entropy: 1.10257
Value Function Loss: 5.30998

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.08219

Collected Steps per Second: 12,042.84695
Overall Steps per Second: 10,303.87914

Timestep Collection Time: 4.15300
Timestep Consumption Time: 0.70090
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 4.85390

Cumulative Model Updates: 42,736
Cumulative Timesteps: 712,877,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 712877846...
Checkpoint 712877846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,530.35454
Policy Entropy: 1.10979
Value Function Loss: 5.14635

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.08279

Collected Steps per Second: 12,008.91378
Overall Steps per Second: 10,052.15581

Timestep Collection Time: 4.16357
Timestep Consumption Time: 0.81048
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.97406

Cumulative Model Updates: 42,739
Cumulative Timesteps: 712,927,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,426.15853
Policy Entropy: 1.10754
Value Function Loss: 5.20435

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.06651
Value Function Update Magnitude: 0.08601

Collected Steps per Second: 11,668.58476
Overall Steps per Second: 9,854.64031

Timestep Collection Time: 4.28672
Timestep Consumption Time: 0.78906
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.07578

Cumulative Model Updates: 42,742
Cumulative Timesteps: 712,977,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 712977866...
Checkpoint 712977866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,302.28357
Policy Entropy: 1.10212
Value Function Loss: 5.19497

Mean KL Divergence: 0.02977
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.09471

Collected Steps per Second: 11,780.73236
Overall Steps per Second: 9,997.84653

Timestep Collection Time: 4.24592
Timestep Consumption Time: 0.75716
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 5.00308

Cumulative Model Updates: 42,745
Cumulative Timesteps: 713,027,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,367.35184
Policy Entropy: 1.10445
Value Function Loss: 5.29148

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.08405

Collected Steps per Second: 11,906.04742
Overall Steps per Second: 10,017.40671

Timestep Collection Time: 4.20156
Timestep Consumption Time: 0.79215
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 4.99371

Cumulative Model Updates: 42,748
Cumulative Timesteps: 713,077,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 713077910...
Checkpoint 713077910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,589.85304
Policy Entropy: 1.11426
Value Function Loss: 4.89808

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.07950

Collected Steps per Second: 11,013.43466
Overall Steps per Second: 9,554.94375

Timestep Collection Time: 4.54009
Timestep Consumption Time: 0.69301
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.23310

Cumulative Model Updates: 42,751
Cumulative Timesteps: 713,127,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,659.81554
Policy Entropy: 1.08760
Value Function Loss: 4.69807

Mean KL Divergence: 0.02718
SB3 Clip Fraction: 0.14558
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.08792

Collected Steps per Second: 10,744.29867
Overall Steps per Second: 9,195.90178

Timestep Collection Time: 4.65456
Timestep Consumption Time: 0.78373
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.43829

Cumulative Model Updates: 42,754
Cumulative Timesteps: 713,177,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 713177922...
Checkpoint 713177922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,124.54610
Policy Entropy: 1.10550
Value Function Loss: 4.78225

Mean KL Divergence: 0.02632
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.08558

Collected Steps per Second: 10,741.11711
Overall Steps per Second: 9,250.99322

Timestep Collection Time: 4.65669
Timestep Consumption Time: 0.75009
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.40677

Cumulative Model Updates: 42,757
Cumulative Timesteps: 713,227,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,488.71569
Policy Entropy: 1.10092
Value Function Loss: 5.08574

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.11417
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.08520

Collected Steps per Second: 11,300.88048
Overall Steps per Second: 9,543.15457

Timestep Collection Time: 4.42691
Timestep Consumption Time: 0.81538
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.24229

Cumulative Model Updates: 42,760
Cumulative Timesteps: 713,277,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 713277968...
Checkpoint 713277968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,439.87935
Policy Entropy: 1.10896
Value Function Loss: 5.24351

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.08262

Collected Steps per Second: 11,072.42329
Overall Steps per Second: 9,445.13059

Timestep Collection Time: 4.51627
Timestep Consumption Time: 0.77810
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.29437

Cumulative Model Updates: 42,763
Cumulative Timesteps: 713,327,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,688.22035
Policy Entropy: 1.09767
Value Function Loss: 5.10489

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.07591

Collected Steps per Second: 11,036.78525
Overall Steps per Second: 9,415.17811

Timestep Collection Time: 4.53194
Timestep Consumption Time: 0.78055
PPO Batch Consumption Time: 0.04341
Total Iteration Time: 5.31249

Cumulative Model Updates: 42,766
Cumulative Timesteps: 713,377,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 713377992...
Checkpoint 713377992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,490.62737
Policy Entropy: 1.09737
Value Function Loss: 4.87556

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 11,030.47729
Overall Steps per Second: 9,380.16204

Timestep Collection Time: 4.53380
Timestep Consumption Time: 0.79766
PPO Batch Consumption Time: 0.03811
Total Iteration Time: 5.33146

Cumulative Model Updates: 42,769
Cumulative Timesteps: 713,428,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,301.19097
Policy Entropy: 1.11250
Value Function Loss: 4.98859

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.08228

Collected Steps per Second: 10,977.87606
Overall Steps per Second: 9,419.17912

Timestep Collection Time: 4.55571
Timestep Consumption Time: 0.75388
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 5.30959

Cumulative Model Updates: 42,772
Cumulative Timesteps: 713,478,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 713478014...
Checkpoint 713478014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,910.06254
Policy Entropy: 1.11069
Value Function Loss: 5.13761

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.08876

Collected Steps per Second: 11,071.91673
Overall Steps per Second: 9,406.29464

Timestep Collection Time: 4.51828
Timestep Consumption Time: 0.80008
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.31835

Cumulative Model Updates: 42,775
Cumulative Timesteps: 713,528,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,665.72594
Policy Entropy: 1.10615
Value Function Loss: 5.24870

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.08274

Collected Steps per Second: 10,731.88020
Overall Steps per Second: 9,250.34000

Timestep Collection Time: 4.66069
Timestep Consumption Time: 0.74646
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 5.40715

Cumulative Model Updates: 42,778
Cumulative Timesteps: 713,578,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 713578058...
Checkpoint 713578058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,644.03731
Policy Entropy: 1.10489
Value Function Loss: 4.97845

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.09647

Collected Steps per Second: 10,807.87598
Overall Steps per Second: 9,392.55666

Timestep Collection Time: 4.62885
Timestep Consumption Time: 0.69750
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.32635

Cumulative Model Updates: 42,781
Cumulative Timesteps: 713,628,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,411.66111
Policy Entropy: 1.10747
Value Function Loss: 4.94040

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.10014

Collected Steps per Second: 10,516.66756
Overall Steps per Second: 9,004.76714

Timestep Collection Time: 4.75702
Timestep Consumption Time: 0.79870
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.55572

Cumulative Model Updates: 42,784
Cumulative Timesteps: 713,678,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 713678114...
Checkpoint 713678114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417,303.97710
Policy Entropy: 1.12301
Value Function Loss: 5.06962

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 10,851.30882
Overall Steps per Second: 9,335.51374

Timestep Collection Time: 4.60958
Timestep Consumption Time: 0.74845
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 5.35803

Cumulative Model Updates: 42,787
Cumulative Timesteps: 713,728,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,299.44541
Policy Entropy: 1.12066
Value Function Loss: 5.20888

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.09759

Collected Steps per Second: 11,386.38916
Overall Steps per Second: 9,544.13040

Timestep Collection Time: 4.39332
Timestep Consumption Time: 0.84802
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 5.24134

Cumulative Model Updates: 42,790
Cumulative Timesteps: 713,778,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 713778158...
Checkpoint 713778158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,447.94949
Policy Entropy: 1.12377
Value Function Loss: 5.11281

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.08604

Collected Steps per Second: 10,833.94333
Overall Steps per Second: 9,223.66537

Timestep Collection Time: 4.61697
Timestep Consumption Time: 0.80604
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.42301

Cumulative Model Updates: 42,793
Cumulative Timesteps: 713,828,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,521.52758
Policy Entropy: 1.11245
Value Function Loss: 5.08544

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.07889

Collected Steps per Second: 10,877.00165
Overall Steps per Second: 9,392.73006

Timestep Collection Time: 4.59722
Timestep Consumption Time: 0.72647
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 5.32369

Cumulative Model Updates: 42,796
Cumulative Timesteps: 713,878,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 713878182...
Checkpoint 713878182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,233.09597
Policy Entropy: 1.10107
Value Function Loss: 4.99265

Mean KL Divergence: 0.02710
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.07609

Collected Steps per Second: 10,719.96295
Overall Steps per Second: 9,195.02108

Timestep Collection Time: 4.66550
Timestep Consumption Time: 0.77375
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.43925

Cumulative Model Updates: 42,799
Cumulative Timesteps: 713,928,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,832.44988
Policy Entropy: 1.11438
Value Function Loss: 5.03150

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.07257

Collected Steps per Second: 10,908.69875
Overall Steps per Second: 9,456.12549

Timestep Collection Time: 4.58441
Timestep Consumption Time: 0.70422
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 5.28864

Cumulative Model Updates: 42,802
Cumulative Timesteps: 713,978,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 713978206...
Checkpoint 713978206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,745.72874
Policy Entropy: 1.12353
Value Function Loss: 4.88249

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.07956

Collected Steps per Second: 11,245.13766
Overall Steps per Second: 9,574.03711

Timestep Collection Time: 4.44637
Timestep Consumption Time: 0.77609
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.22246

Cumulative Model Updates: 42,805
Cumulative Timesteps: 714,028,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,837.81818
Policy Entropy: 1.11839
Value Function Loss: 4.78389

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.08954

Collected Steps per Second: 11,231.43519
Overall Steps per Second: 9,607.26100

Timestep Collection Time: 4.45375
Timestep Consumption Time: 0.75294
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 5.20669

Cumulative Model Updates: 42,808
Cumulative Timesteps: 714,078,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 714078228...
Checkpoint 714078228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,193.57003
Policy Entropy: 1.10641
Value Function Loss: 4.90788

Mean KL Divergence: 0.03037
SB3 Clip Fraction: 0.15267
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 11,582.25589
Overall Steps per Second: 9,753.11932

Timestep Collection Time: 4.31781
Timestep Consumption Time: 0.80978
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.12759

Cumulative Model Updates: 42,811
Cumulative Timesteps: 714,128,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,401.87973
Policy Entropy: 1.11587
Value Function Loss: 4.93343

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.09565

Collected Steps per Second: 11,574.13006
Overall Steps per Second: 9,852.69966

Timestep Collection Time: 4.32102
Timestep Consumption Time: 0.75495
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.07597

Cumulative Model Updates: 42,814
Cumulative Timesteps: 714,178,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 714178250...
Checkpoint 714178250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,168.62646
Policy Entropy: 1.11987
Value Function Loss: 5.19743

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.08548

Collected Steps per Second: 11,000.26109
Overall Steps per Second: 9,487.79003

Timestep Collection Time: 4.54716
Timestep Consumption Time: 0.72487
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.27204

Cumulative Model Updates: 42,817
Cumulative Timesteps: 714,228,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,863.37766
Policy Entropy: 1.11097
Value Function Loss: 4.97488

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.09185

Collected Steps per Second: 11,169.85873
Overall Steps per Second: 9,405.81100

Timestep Collection Time: 4.47884
Timestep Consumption Time: 0.84000
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.31884

Cumulative Model Updates: 42,820
Cumulative Timesteps: 714,278,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 714278298...
Checkpoint 714278298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,716.13032
Policy Entropy: 1.10459
Value Function Loss: 5.01204

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.11853
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.09989

Collected Steps per Second: 11,168.33027
Overall Steps per Second: 9,626.46131

Timestep Collection Time: 4.47748
Timestep Consumption Time: 0.71716
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 5.19464

Cumulative Model Updates: 42,823
Cumulative Timesteps: 714,328,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,103.44709
Policy Entropy: 1.10607
Value Function Loss: 5.13737

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.10104

Collected Steps per Second: 11,230.55472
Overall Steps per Second: 9,538.26651

Timestep Collection Time: 4.45374
Timestep Consumption Time: 0.79019
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.24393

Cumulative Model Updates: 42,826
Cumulative Timesteps: 714,378,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 714378322...
Checkpoint 714378322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385,780.17877
Policy Entropy: 1.11949
Value Function Loss: 5.14999

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 11,133.29169
Overall Steps per Second: 9,563.62560

Timestep Collection Time: 4.49337
Timestep Consumption Time: 0.73749
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.23086

Cumulative Model Updates: 42,829
Cumulative Timesteps: 714,428,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,222.12182
Policy Entropy: 1.12155
Value Function Loss: 5.20714

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.11432

Collected Steps per Second: 11,231.71899
Overall Steps per Second: 9,536.92563

Timestep Collection Time: 4.45346
Timestep Consumption Time: 0.79142
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.24488

Cumulative Model Updates: 42,832
Cumulative Timesteps: 714,478,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 714478368...
Checkpoint 714478368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,296.05744
Policy Entropy: 1.12369
Value Function Loss: 5.06720

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.06501
Value Function Update Magnitude: 0.11032

Collected Steps per Second: 10,592.54001
Overall Steps per Second: 9,137.24007

Timestep Collection Time: 4.72257
Timestep Consumption Time: 0.75217
PPO Batch Consumption Time: 0.03375
Total Iteration Time: 5.47474

Cumulative Model Updates: 42,835
Cumulative Timesteps: 714,528,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,952.68040
Policy Entropy: 1.11646
Value Function Loss: 5.31232

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.06124
Value Function Update Magnitude: 0.10663

Collected Steps per Second: 10,835.51720
Overall Steps per Second: 9,417.48546

Timestep Collection Time: 4.61612
Timestep Consumption Time: 0.69507
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 5.31118

Cumulative Model Updates: 42,838
Cumulative Timesteps: 714,578,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 714578410...
Checkpoint 714578410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,995.68844
Policy Entropy: 1.11551
Value Function Loss: 5.13607

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.10076

Collected Steps per Second: 11,050.36742
Overall Steps per Second: 9,460.67889

Timestep Collection Time: 4.52691
Timestep Consumption Time: 0.76066
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.28757

Cumulative Model Updates: 42,841
Cumulative Timesteps: 714,628,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,731.89106
Policy Entropy: 1.12641
Value Function Loss: 5.24792

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.10243

Collected Steps per Second: 10,868.71955
Overall Steps per Second: 9,381.43600

Timestep Collection Time: 4.60146
Timestep Consumption Time: 0.72949
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.33095

Cumulative Model Updates: 42,844
Cumulative Timesteps: 714,678,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 714678446...
Checkpoint 714678446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,744.10510
Policy Entropy: 1.12338
Value Function Loss: 4.94377

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.06406
Value Function Update Magnitude: 0.10538

Collected Steps per Second: 10,999.77425
Overall Steps per Second: 9,445.27688

Timestep Collection Time: 4.54609
Timestep Consumption Time: 0.74819
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 5.29429

Cumulative Model Updates: 42,847
Cumulative Timesteps: 714,728,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,698.79702
Policy Entropy: 1.13019
Value Function Loss: 5.14060

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.06298
Value Function Update Magnitude: 0.10340

Collected Steps per Second: 10,861.32421
Overall Steps per Second: 9,265.77566

Timestep Collection Time: 4.60423
Timestep Consumption Time: 0.79284
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 5.39707

Cumulative Model Updates: 42,850
Cumulative Timesteps: 714,778,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 714778460...
Checkpoint 714778460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,958.92599
Policy Entropy: 1.12165
Value Function Loss: 5.00711

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.07352
Value Function Update Magnitude: 0.09816

Collected Steps per Second: 9,808.36689
Overall Steps per Second: 8,498.82302

Timestep Collection Time: 5.09789
Timestep Consumption Time: 0.78551
PPO Batch Consumption Time: 0.04971
Total Iteration Time: 5.88340

Cumulative Model Updates: 42,853
Cumulative Timesteps: 714,828,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419,336.31776
Policy Entropy: 1.12606
Value Function Loss: 5.15666

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.06743
Value Function Update Magnitude: 0.09581

Collected Steps per Second: 10,993.02011
Overall Steps per Second: 9,233.85869

Timestep Collection Time: 4.55034
Timestep Consumption Time: 0.86690
PPO Batch Consumption Time: 0.04293
Total Iteration Time: 5.41724

Cumulative Model Updates: 42,856
Cumulative Timesteps: 714,878,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 714878484...
Checkpoint 714878484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,273.38703
Policy Entropy: 1.12779
Value Function Loss: 5.19831

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.06761
Value Function Update Magnitude: 0.08557

Collected Steps per Second: 10,917.09966
Overall Steps per Second: 9,346.42510

Timestep Collection Time: 4.58217
Timestep Consumption Time: 0.77004
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.35221

Cumulative Model Updates: 42,859
Cumulative Timesteps: 714,928,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,433.88610
Policy Entropy: 1.12543
Value Function Loss: 5.33298

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.08663
Policy Update Magnitude: 0.06727
Value Function Update Magnitude: 0.09688

Collected Steps per Second: 11,216.05768
Overall Steps per Second: 9,476.52651

Timestep Collection Time: 4.45861
Timestep Consumption Time: 0.81843
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 5.27704

Cumulative Model Updates: 42,862
Cumulative Timesteps: 714,978,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 714978516...
Checkpoint 714978516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,997.70841
Policy Entropy: 1.12247
Value Function Loss: 5.49016

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.10655

Collected Steps per Second: 10,643.23857
Overall Steps per Second: 9,055.06896

Timestep Collection Time: 4.69913
Timestep Consumption Time: 0.82418
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.52332

Cumulative Model Updates: 42,865
Cumulative Timesteps: 715,028,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,892.81528
Policy Entropy: 1.13641
Value Function Loss: 5.35235

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.10661

Collected Steps per Second: 10,418.69219
Overall Steps per Second: 8,864.61878

Timestep Collection Time: 4.80175
Timestep Consumption Time: 0.84180
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 5.64356

Cumulative Model Updates: 42,868
Cumulative Timesteps: 715,078,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 715078558...
Checkpoint 715078558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,635.41191
Policy Entropy: 1.14598
Value Function Loss: 5.46794

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.10962

Collected Steps per Second: 11,936.64969
Overall Steps per Second: 10,004.88101

Timestep Collection Time: 4.18962
Timestep Consumption Time: 0.80894
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 4.99856

Cumulative Model Updates: 42,871
Cumulative Timesteps: 715,128,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,176.62639
Policy Entropy: 1.12218
Value Function Loss: 5.40395

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.11640

Collected Steps per Second: 11,808.87235
Overall Steps per Second: 9,942.40381

Timestep Collection Time: 4.23665
Timestep Consumption Time: 0.79534
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.03198

Cumulative Model Updates: 42,874
Cumulative Timesteps: 715,178,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 715178598...
Checkpoint 715178598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,393.38655
Policy Entropy: 1.13965
Value Function Loss: 5.22052

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.10194

Collected Steps per Second: 12,027.67529
Overall Steps per Second: 10,150.36636

Timestep Collection Time: 4.15808
Timestep Consumption Time: 0.76904
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.92711

Cumulative Model Updates: 42,877
Cumulative Timesteps: 715,228,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,051.50728
Policy Entropy: 1.11962
Value Function Loss: 5.16978

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.09008

Collected Steps per Second: 11,511.17903
Overall Steps per Second: 9,756.40164

Timestep Collection Time: 4.34551
Timestep Consumption Time: 0.78158
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.12710

Cumulative Model Updates: 42,880
Cumulative Timesteps: 715,278,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 715278632...
Checkpoint 715278632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,901.71611
Policy Entropy: 1.13231
Value Function Loss: 5.20817

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.06653
Value Function Update Magnitude: 0.09348

Collected Steps per Second: 11,870.34503
Overall Steps per Second: 10,240.29391

Timestep Collection Time: 4.21319
Timestep Consumption Time: 0.67066
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 4.88384

Cumulative Model Updates: 42,883
Cumulative Timesteps: 715,328,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,162.65455
Policy Entropy: 1.11844
Value Function Loss: 5.22193

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.10091

Collected Steps per Second: 11,186.57146
Overall Steps per Second: 9,561.39395

Timestep Collection Time: 4.46982
Timestep Consumption Time: 0.75975
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.22957

Cumulative Model Updates: 42,886
Cumulative Timesteps: 715,378,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 715378646...
Checkpoint 715378646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,135.03935
Policy Entropy: 1.14007
Value Function Loss: 5.02137

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.10202

Collected Steps per Second: 11,214.28536
Overall Steps per Second: 9,536.10981

Timestep Collection Time: 4.45913
Timestep Consumption Time: 0.78472
PPO Batch Consumption Time: 0.03831
Total Iteration Time: 5.24386

Cumulative Model Updates: 42,889
Cumulative Timesteps: 715,428,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,983.13590
Policy Entropy: 1.12942
Value Function Loss: 4.71564

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.06640
Value Function Update Magnitude: 0.10248

Collected Steps per Second: 11,272.75914
Overall Steps per Second: 9,572.05757

Timestep Collection Time: 4.43707
Timestep Consumption Time: 0.78835
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.22542

Cumulative Model Updates: 42,892
Cumulative Timesteps: 715,478,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 715478670...
Checkpoint 715478670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,708.40853
Policy Entropy: 1.13686
Value Function Loss: 5.11416

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.10136

Collected Steps per Second: 11,004.13599
Overall Steps per Second: 9,405.45006

Timestep Collection Time: 4.54411
Timestep Consumption Time: 0.77238
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.31649

Cumulative Model Updates: 42,895
Cumulative Timesteps: 715,528,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,750.54343
Policy Entropy: 1.12820
Value Function Loss: 5.34281

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.07114
Value Function Update Magnitude: 0.09327

Collected Steps per Second: 10,841.91449
Overall Steps per Second: 9,192.06814

Timestep Collection Time: 4.61431
Timestep Consumption Time: 0.82820
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 5.44252

Cumulative Model Updates: 42,898
Cumulative Timesteps: 715,578,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 715578702...
Checkpoint 715578702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,950.17908
Policy Entropy: 1.14307
Value Function Loss: 5.43546

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.08344

Collected Steps per Second: 4,933.15240
Overall Steps per Second: 3,861.32162

Timestep Collection Time: 10.14240
Timestep Consumption Time: 2.81534
PPO Batch Consumption Time: 0.04921
Total Iteration Time: 12.95774

Cumulative Model Updates: 42,901
Cumulative Timesteps: 715,628,736

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,304.49170
Policy Entropy: 1.14283
Value Function Loss: 4.99461

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.09038

Collected Steps per Second: 4,254.71163
Overall Steps per Second: 3,504.56738

Timestep Collection Time: 11.76108
Timestep Consumption Time: 2.51743
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 14.27851

Cumulative Model Updates: 42,904
Cumulative Timesteps: 715,678,776

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 715678776...
Checkpoint 715678776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427,922.56683
Policy Entropy: 1.12669
Value Function Loss: 4.71361

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.10150

Collected Steps per Second: 4,127.53867
Overall Steps per Second: 3,374.83167

Timestep Collection Time: 12.11957
Timestep Consumption Time: 2.70309
PPO Batch Consumption Time: 0.05911
Total Iteration Time: 14.82267

Cumulative Model Updates: 42,907
Cumulative Timesteps: 715,728,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,396.72686
Policy Entropy: 1.12430
Value Function Loss: 4.73571

Mean KL Divergence: 0.02963
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.10328

Collected Steps per Second: 4,008.36978
Overall Steps per Second: 3,315.67727

Timestep Collection Time: 12.47889
Timestep Consumption Time: 2.60702
PPO Batch Consumption Time: 0.05411
Total Iteration Time: 15.08591

Cumulative Model Updates: 42,910
Cumulative Timesteps: 715,778,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 715778820...
Checkpoint 715778820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,954.86639
Policy Entropy: 1.13476
Value Function Loss: 4.77007

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.10965

Collected Steps per Second: 4,151.54548
Overall Steps per Second: 3,473.48382

Timestep Collection Time: 12.05431
Timestep Consumption Time: 2.35313
PPO Batch Consumption Time: 0.05888
Total Iteration Time: 14.40744

Cumulative Model Updates: 42,913
Cumulative Timesteps: 715,828,864

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,390.31401
Policy Entropy: 1.13997
Value Function Loss: 4.84656

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.10871

Collected Steps per Second: 3,975.20778
Overall Steps per Second: 3,286.35372

Timestep Collection Time: 12.58903
Timestep Consumption Time: 2.63879
PPO Batch Consumption Time: 0.05906
Total Iteration Time: 15.22782

Cumulative Model Updates: 42,916
Cumulative Timesteps: 715,878,908

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 715878908...
Checkpoint 715878908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,019.72906
Policy Entropy: 1.12161
Value Function Loss: 4.94730

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.10722

Collected Steps per Second: 3,953.97997
Overall Steps per Second: 3,305.98420

Timestep Collection Time: 12.65004
Timestep Consumption Time: 2.47950
PPO Batch Consumption Time: 0.06242
Total Iteration Time: 15.12953

Cumulative Model Updates: 42,919
Cumulative Timesteps: 715,928,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,469.27844
Policy Entropy: 1.13490
Value Function Loss: 5.29683

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.09322

Collected Steps per Second: 3,974.53568
Overall Steps per Second: 3,303.69332

Timestep Collection Time: 12.58914
Timestep Consumption Time: 2.55633
PPO Batch Consumption Time: 0.06762
Total Iteration Time: 15.14547

Cumulative Model Updates: 42,922
Cumulative Timesteps: 715,978,962

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 715978962...
Checkpoint 715978962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,613.01807
Policy Entropy: 1.13002
Value Function Loss: 5.49682

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.12629
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.09002

Collected Steps per Second: 4,069.12603
Overall Steps per Second: 3,344.39315

Timestep Collection Time: 12.29109
Timestep Consumption Time: 2.66349
PPO Batch Consumption Time: 0.06209
Total Iteration Time: 14.95458

Cumulative Model Updates: 42,925
Cumulative Timesteps: 716,028,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,922.10682
Policy Entropy: 1.12370
Value Function Loss: 5.48771

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.08753

Collected Steps per Second: 3,911.41570
Overall Steps per Second: 3,319.83115

Timestep Collection Time: 12.78361
Timestep Consumption Time: 2.27800
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 15.06161

Cumulative Model Updates: 42,928
Cumulative Timesteps: 716,078,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 716078978...
Checkpoint 716078978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,201.82497
Policy Entropy: 1.10493
Value Function Loss: 5.38572

Mean KL Divergence: 0.03111
SB3 Clip Fraction: 0.16533
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.08349

Collected Steps per Second: 3,985.47806
Overall Steps per Second: 3,273.48009

Timestep Collection Time: 12.55408
Timestep Consumption Time: 2.73057
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 15.28465

Cumulative Model Updates: 42,931
Cumulative Timesteps: 716,129,012

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,882.70505
Policy Entropy: 1.11686
Value Function Loss: 5.27630

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.07529

Collected Steps per Second: 3,925.70360
Overall Steps per Second: 3,315.38858

Timestep Collection Time: 12.74676
Timestep Consumption Time: 2.34649
PPO Batch Consumption Time: 0.05847
Total Iteration Time: 15.09325

Cumulative Model Updates: 42,934
Cumulative Timesteps: 716,179,052

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 716179052...
Checkpoint 716179052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,004.15085
Policy Entropy: 1.11746
Value Function Loss: 5.51706

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.09026

Collected Steps per Second: 3,989.40870
Overall Steps per Second: 3,259.76740

Timestep Collection Time: 12.54071
Timestep Consumption Time: 2.80702
PPO Batch Consumption Time: 0.06267
Total Iteration Time: 15.34772

Cumulative Model Updates: 42,937
Cumulative Timesteps: 716,229,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,686.17408
Policy Entropy: 1.10898
Value Function Loss: 5.67519

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.10698

Collected Steps per Second: 3,860.14690
Overall Steps per Second: 3,211.88196

Timestep Collection Time: 12.95909
Timestep Consumption Time: 2.61558
PPO Batch Consumption Time: 0.06218
Total Iteration Time: 15.57467

Cumulative Model Updates: 42,940
Cumulative Timesteps: 716,279,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 716279106...
Checkpoint 716279106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,239.36966
Policy Entropy: 1.09739
Value Function Loss: 5.74382

Mean KL Divergence: 0.03268
SB3 Clip Fraction: 0.16655
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.10742

Collected Steps per Second: 3,932.35989
Overall Steps per Second: 3,296.56920

Timestep Collection Time: 12.72111
Timestep Consumption Time: 2.45345
PPO Batch Consumption Time: 0.06431
Total Iteration Time: 15.17456

Cumulative Model Updates: 42,943
Cumulative Timesteps: 716,329,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,130.99876
Policy Entropy: 1.11922
Value Function Loss: 5.61854

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.09813

Collected Steps per Second: 3,853.61485
Overall Steps per Second: 3,185.40467

Timestep Collection Time: 12.97743
Timestep Consumption Time: 2.72231
PPO Batch Consumption Time: 0.05929
Total Iteration Time: 15.69973

Cumulative Model Updates: 42,946
Cumulative Timesteps: 716,379,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 716379140...
Checkpoint 716379140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442,673.35652
Policy Entropy: 1.12239
Value Function Loss: 5.62033

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.08953

Collected Steps per Second: 3,905.81385
Overall Steps per Second: 3,276.12125

Timestep Collection Time: 12.80553
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.05376
Total Iteration Time: 15.26683

Cumulative Model Updates: 42,949
Cumulative Timesteps: 716,429,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,159.59689
Policy Entropy: 1.11447
Value Function Loss: 5.65210

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.08018

Collected Steps per Second: 3,755.75405
Overall Steps per Second: 3,128.33836

Timestep Collection Time: 13.32143
Timestep Consumption Time: 2.67173
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 15.99315

Cumulative Model Updates: 42,952
Cumulative Timesteps: 716,479,188

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 716479188...
Checkpoint 716479188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,649.14124
Policy Entropy: 1.10351
Value Function Loss: 5.75858

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.06143
Value Function Update Magnitude: 0.11214

Collected Steps per Second: 3,950.44124
Overall Steps per Second: 3,272.79658

Timestep Collection Time: 12.66441
Timestep Consumption Time: 2.62221
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 15.28662

Cumulative Model Updates: 42,955
Cumulative Timesteps: 716,529,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,330.13179
Policy Entropy: 1.10964
Value Function Loss: 5.70307

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.11061

Collected Steps per Second: 3,949.90533
Overall Steps per Second: 3,238.16930

Timestep Collection Time: 12.66916
Timestep Consumption Time: 2.78463
PPO Batch Consumption Time: 0.06251
Total Iteration Time: 15.45379

Cumulative Model Updates: 42,958
Cumulative Timesteps: 716,579,260

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 716579260...
Checkpoint 716579260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,514.16965
Policy Entropy: 1.11437
Value Function Loss: 5.60059

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.10582

Collected Steps per Second: 3,965.35665
Overall Steps per Second: 3,282.89549

Timestep Collection Time: 12.61072
Timestep Consumption Time: 2.62157
PPO Batch Consumption Time: 0.05819
Total Iteration Time: 15.23229

Cumulative Model Updates: 42,961
Cumulative Timesteps: 716,629,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,339.11146
Policy Entropy: 1.09190
Value Function Loss: 5.46036

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.11474

Collected Steps per Second: 4,004.27166
Overall Steps per Second: 3,367.67376

Timestep Collection Time: 12.48816
Timestep Consumption Time: 2.36066
PPO Batch Consumption Time: 0.06466
Total Iteration Time: 14.84883

Cumulative Model Updates: 42,964
Cumulative Timesteps: 716,679,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 716679272...
Checkpoint 716679272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,434.86968
Policy Entropy: 1.08304
Value Function Loss: 5.28626

Mean KL Divergence: 0.02372
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.11700

Collected Steps per Second: 4,041.16802
Overall Steps per Second: 3,323.74521

Timestep Collection Time: 12.37909
Timestep Consumption Time: 2.67200
PPO Batch Consumption Time: 0.06652
Total Iteration Time: 15.05109

Cumulative Model Updates: 42,967
Cumulative Timesteps: 716,729,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,354.33436
Policy Entropy: 1.09766
Value Function Loss: 5.66391

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.10054

Collected Steps per Second: 3,839.86112
Overall Steps per Second: 3,265.43593

Timestep Collection Time: 13.02755
Timestep Consumption Time: 2.29169
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 15.31924

Cumulative Model Updates: 42,970
Cumulative Timesteps: 716,779,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 716779322...
Checkpoint 716779322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,007.33048
Policy Entropy: 1.11325
Value Function Loss: 5.70499

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.08891

Collected Steps per Second: 4,069.95860
Overall Steps per Second: 3,316.18275

Timestep Collection Time: 12.28858
Timestep Consumption Time: 2.79322
PPO Batch Consumption Time: 0.05827
Total Iteration Time: 15.08180

Cumulative Model Updates: 42,973
Cumulative Timesteps: 716,829,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445,308.91747
Policy Entropy: 1.10233
Value Function Loss: 5.69872

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.09766

Collected Steps per Second: 3,948.38541
Overall Steps per Second: 3,263.96550

Timestep Collection Time: 12.66746
Timestep Consumption Time: 2.65623
PPO Batch Consumption Time: 0.06233
Total Iteration Time: 15.32369

Cumulative Model Updates: 42,976
Cumulative Timesteps: 716,879,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 716879352...
Checkpoint 716879352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,166.39010
Policy Entropy: 1.09611
Value Function Loss: 5.31045

Mean KL Divergence: 0.02602
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.10974

Collected Steps per Second: 4,029.89559
Overall Steps per Second: 3,305.80441

Timestep Collection Time: 12.41471
Timestep Consumption Time: 2.71927
PPO Batch Consumption Time: 0.06040
Total Iteration Time: 15.13399

Cumulative Model Updates: 42,979
Cumulative Timesteps: 716,929,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,744.22079
Policy Entropy: 1.10484
Value Function Loss: 5.29923

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.12899

Collected Steps per Second: 9,093.34718
Overall Steps per Second: 7,848.83014

Timestep Collection Time: 5.49984
Timestep Consumption Time: 0.87206
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 6.37190

Cumulative Model Updates: 42,982
Cumulative Timesteps: 716,979,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 716979394...
Checkpoint 716979394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,685.94952
Policy Entropy: 1.11154
Value Function Loss: 5.37759

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.12943

Collected Steps per Second: 11,677.86124
Overall Steps per Second: 10,060.71884

Timestep Collection Time: 4.28178
Timestep Consumption Time: 0.68825
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 4.97002

Cumulative Model Updates: 42,985
Cumulative Timesteps: 717,029,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,160.01610
Policy Entropy: 1.08925
Value Function Loss: 6.00099

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.12975

Collected Steps per Second: 12,525.84482
Overall Steps per Second: 10,489.17746

Timestep Collection Time: 3.99239
Timestep Consumption Time: 0.77520
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.76758

Cumulative Model Updates: 42,988
Cumulative Timesteps: 717,079,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 717079404...
Checkpoint 717079404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,478.89021
Policy Entropy: 1.11147
Value Function Loss: 6.14385

Mean KL Divergence: 0.03142
SB3 Clip Fraction: 0.15809
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.11832

Collected Steps per Second: 12,172.76270
Overall Steps per Second: 10,359.43254

Timestep Collection Time: 4.10917
Timestep Consumption Time: 0.71928
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 4.82845

Cumulative Model Updates: 42,991
Cumulative Timesteps: 717,129,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,400.74951
Policy Entropy: 1.10675
Value Function Loss: 6.29542

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.10421

Collected Steps per Second: 12,537.61963
Overall Steps per Second: 10,693.88830

Timestep Collection Time: 3.98927
Timestep Consumption Time: 0.68779
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.67706

Cumulative Model Updates: 42,994
Cumulative Timesteps: 717,179,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 717179440...
Checkpoint 717179440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,200.18079
Policy Entropy: 1.09799
Value Function Loss: 5.89542

Mean KL Divergence: 0.02737
SB3 Clip Fraction: 0.15124
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 11,479.17162
Overall Steps per Second: 9,679.67103

Timestep Collection Time: 4.35572
Timestep Consumption Time: 0.80975
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.16546

Cumulative Model Updates: 42,997
Cumulative Timesteps: 717,229,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,551.37425
Policy Entropy: 1.09145
Value Function Loss: 5.74319

Mean KL Divergence: 0.03388
SB3 Clip Fraction: 0.17984
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.09036

Collected Steps per Second: 12,811.24339
Overall Steps per Second: 10,730.09751

Timestep Collection Time: 3.90282
Timestep Consumption Time: 0.75697
PPO Batch Consumption Time: 0.03341
Total Iteration Time: 4.65979

Cumulative Model Updates: 43,000
Cumulative Timesteps: 717,279,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 717279440...
Checkpoint 717279440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,899.75326
Policy Entropy: 1.11700
Value Function Loss: 5.66440

Mean KL Divergence: 0.03130
SB3 Clip Fraction: 0.19053
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.09460

Collected Steps per Second: 12,996.82437
Overall Steps per Second: 10,853.56265

Timestep Collection Time: 3.84909
Timestep Consumption Time: 0.76008
PPO Batch Consumption Time: 0.03328
Total Iteration Time: 4.60918

Cumulative Model Updates: 43,003
Cumulative Timesteps: 717,329,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,273.80495
Policy Entropy: 1.09241
Value Function Loss: 5.56121

Mean KL Divergence: 0.03478
SB3 Clip Fraction: 0.18301
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.11607

Collected Steps per Second: 13,122.69317
Overall Steps per Second: 10,936.11447

Timestep Collection Time: 3.81050
Timestep Consumption Time: 0.76188
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.57237

Cumulative Model Updates: 43,006
Cumulative Timesteps: 717,379,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 717379470...
Checkpoint 717379470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,190.20465
Policy Entropy: 1.10940
Value Function Loss: 5.59603

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.14007
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.10358

Collected Steps per Second: 12,402.59113
Overall Steps per Second: 10,553.05251

Timestep Collection Time: 4.03383
Timestep Consumption Time: 0.70697
PPO Batch Consumption Time: 0.03775
Total Iteration Time: 4.74081

Cumulative Model Updates: 43,009
Cumulative Timesteps: 717,429,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,730.78839
Policy Entropy: 1.11927
Value Function Loss: 5.53599

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.08497

Collected Steps per Second: 12,466.25985
Overall Steps per Second: 10,420.72609

Timestep Collection Time: 4.01243
Timestep Consumption Time: 0.78762
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 4.80005

Cumulative Model Updates: 43,012
Cumulative Timesteps: 717,479,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 717479520...
Checkpoint 717479520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,791.76195
Policy Entropy: 1.10930
Value Function Loss: 5.91096

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.06861

Collected Steps per Second: 12,230.50720
Overall Steps per Second: 10,323.14341

Timestep Collection Time: 4.08879
Timestep Consumption Time: 0.75547
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 4.84426

Cumulative Model Updates: 43,015
Cumulative Timesteps: 717,529,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,622.39702
Policy Entropy: 1.10053
Value Function Loss: 5.76804

Mean KL Divergence: 0.02422
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.06281

Collected Steps per Second: 12,287.81925
Overall Steps per Second: 10,517.29445

Timestep Collection Time: 4.07070
Timestep Consumption Time: 0.68528
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.75598

Cumulative Model Updates: 43,018
Cumulative Timesteps: 717,579,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 717579548...
Checkpoint 717579548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,687.72522
Policy Entropy: 1.11528
Value Function Loss: 5.68608

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.06996

Collected Steps per Second: 12,221.48268
Overall Steps per Second: 10,212.92833

Timestep Collection Time: 4.09279
Timestep Consumption Time: 0.80492
PPO Batch Consumption Time: 0.03819
Total Iteration Time: 4.89771

Cumulative Model Updates: 43,021
Cumulative Timesteps: 717,629,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,164.88924
Policy Entropy: 1.12089
Value Function Loss: 5.39657

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.06687

Collected Steps per Second: 12,138.89653
Overall Steps per Second: 10,412.53215

Timestep Collection Time: 4.11998
Timestep Consumption Time: 0.68308
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.80306

Cumulative Model Updates: 43,024
Cumulative Timesteps: 717,679,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 717679580...
Checkpoint 717679580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,025.54025
Policy Entropy: 1.11416
Value Function Loss: 5.41206

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.07400

Collected Steps per Second: 11,843.66616
Overall Steps per Second: 9,986.47410

Timestep Collection Time: 4.22403
Timestep Consumption Time: 0.78555
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 5.00958

Cumulative Model Updates: 43,027
Cumulative Timesteps: 717,729,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,549.49450
Policy Entropy: 1.09988
Value Function Loss: 5.61157

Mean KL Divergence: 0.03580
SB3 Clip Fraction: 0.16481
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 12,045.06094
Overall Steps per Second: 10,401.91055

Timestep Collection Time: 4.15208
Timestep Consumption Time: 0.65589
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 4.80796

Cumulative Model Updates: 43,030
Cumulative Timesteps: 717,779,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 717779620...
Checkpoint 717779620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,297.65908
Policy Entropy: 1.11226
Value Function Loss: 5.47178

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.08115

Collected Steps per Second: 12,027.87870
Overall Steps per Second: 10,192.74208

Timestep Collection Time: 4.15784
Timestep Consumption Time: 0.74859
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.90643

Cumulative Model Updates: 43,033
Cumulative Timesteps: 717,829,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,150.66826
Policy Entropy: 1.10692
Value Function Loss: 5.18401

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.07964

Collected Steps per Second: 12,251.14224
Overall Steps per Second: 10,376.52723

Timestep Collection Time: 4.08354
Timestep Consumption Time: 0.73773
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 4.82127

Cumulative Model Updates: 43,036
Cumulative Timesteps: 717,879,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 717879658...
Checkpoint 717879658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,375.62403
Policy Entropy: 1.10360
Value Function Loss: 5.28769

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.08360

Collected Steps per Second: 12,009.39550
Overall Steps per Second: 10,330.76120

Timestep Collection Time: 4.16391
Timestep Consumption Time: 0.67659
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 4.84050

Cumulative Model Updates: 43,039
Cumulative Timesteps: 717,929,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,185.24090
Policy Entropy: 1.11267
Value Function Loss: 5.03428

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.08723

Collected Steps per Second: 9,212.78207
Overall Steps per Second: 7,805.70049

Timestep Collection Time: 5.42811
Timestep Consumption Time: 0.97849
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.40660

Cumulative Model Updates: 43,042
Cumulative Timesteps: 717,979,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 717979672...
Checkpoint 717979672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,430.74542
Policy Entropy: 1.11507
Value Function Loss: 4.89108

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.08351

Collected Steps per Second: 7,926.38442
Overall Steps per Second: 6,948.37853

Timestep Collection Time: 6.30906
Timestep Consumption Time: 0.88802
PPO Batch Consumption Time: 0.04096
Total Iteration Time: 7.19707

Cumulative Model Updates: 43,045
Cumulative Timesteps: 718,029,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,781.51409
Policy Entropy: 1.11538
Value Function Loss: 4.54398

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.06580
Value Function Update Magnitude: 0.07989

Collected Steps per Second: 9,588.33327
Overall Steps per Second: 8,123.06580

Timestep Collection Time: 5.21530
Timestep Consumption Time: 0.94075
PPO Batch Consumption Time: 0.04840
Total Iteration Time: 6.15605

Cumulative Model Updates: 43,048
Cumulative Timesteps: 718,079,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 718079686...
Checkpoint 718079686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,987.05859
Policy Entropy: 1.11101
Value Function Loss: 4.55326

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.07293
Value Function Update Magnitude: 0.08201

Collected Steps per Second: 9,693.19664
Overall Steps per Second: 8,338.36462

Timestep Collection Time: 5.15991
Timestep Consumption Time: 0.83839
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.99830

Cumulative Model Updates: 43,051
Cumulative Timesteps: 718,129,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,434.51316
Policy Entropy: 1.11200
Value Function Loss: 4.91976

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.06829
Value Function Update Magnitude: 0.08319

Collected Steps per Second: 10,184.32787
Overall Steps per Second: 8,736.02535

Timestep Collection Time: 4.91206
Timestep Consumption Time: 0.81435
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.72640

Cumulative Model Updates: 43,054
Cumulative Timesteps: 718,179,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 718179728...
Checkpoint 718179728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,067.15976
Policy Entropy: 1.09778
Value Function Loss: 4.97837

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.06682
Value Function Update Magnitude: 0.08432

Collected Steps per Second: 8,821.89471
Overall Steps per Second: 7,591.99258

Timestep Collection Time: 5.67021
Timestep Consumption Time: 0.91857
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 6.58878

Cumulative Model Updates: 43,057
Cumulative Timesteps: 718,229,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,991.92751
Policy Entropy: 1.10673
Value Function Loss: 5.22720

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.07762

Collected Steps per Second: 8,448.69191
Overall Steps per Second: 7,524.09656

Timestep Collection Time: 5.91808
Timestep Consumption Time: 0.72724
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 6.64532

Cumulative Model Updates: 43,060
Cumulative Timesteps: 718,279,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 718279750...
Checkpoint 718279750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,267.12446
Policy Entropy: 1.10976
Value Function Loss: 5.37304

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 9,370.31825
Overall Steps per Second: 7,990.89203

Timestep Collection Time: 5.33621
Timestep Consumption Time: 0.92116
PPO Batch Consumption Time: 0.04469
Total Iteration Time: 6.25737

Cumulative Model Updates: 43,063
Cumulative Timesteps: 718,329,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437,086.95308
Policy Entropy: 1.12242
Value Function Loss: 5.66139

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.06779

Collected Steps per Second: 8,343.87923
Overall Steps per Second: 7,245.53442

Timestep Collection Time: 5.99601
Timestep Consumption Time: 0.90893
PPO Batch Consumption Time: 0.04481
Total Iteration Time: 6.90494

Cumulative Model Updates: 43,066
Cumulative Timesteps: 718,379,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 718379782...
Checkpoint 718379782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,579.87727
Policy Entropy: 1.12121
Value Function Loss: 5.89755

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.09830

Collected Steps per Second: 8,995.70271
Overall Steps per Second: 7,757.67526

Timestep Collection Time: 5.55999
Timestep Consumption Time: 0.88730
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 6.44729

Cumulative Model Updates: 43,069
Cumulative Timesteps: 718,429,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,125.09339
Policy Entropy: 1.12243
Value Function Loss: 5.86461

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.06199
Value Function Update Magnitude: 0.09841

Collected Steps per Second: 9,428.25212
Overall Steps per Second: 8,095.90928

Timestep Collection Time: 5.30469
Timestep Consumption Time: 0.87299
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 6.17769

Cumulative Model Updates: 43,072
Cumulative Timesteps: 718,479,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 718479812...
Checkpoint 718479812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,134.52125
Policy Entropy: 1.11818
Value Function Loss: 5.71555

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.09746

Collected Steps per Second: 9,819.42079
Overall Steps per Second: 8,525.63256

Timestep Collection Time: 5.09317
Timestep Consumption Time: 0.77290
PPO Batch Consumption Time: 0.03827
Total Iteration Time: 5.86608

Cumulative Model Updates: 43,075
Cumulative Timesteps: 718,529,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,667.30656
Policy Entropy: 1.12229
Value Function Loss: 5.48350

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.09022

Collected Steps per Second: 10,528.17185
Overall Steps per Second: 8,960.51167

Timestep Collection Time: 4.75087
Timestep Consumption Time: 0.83117
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.58205

Cumulative Model Updates: 43,078
Cumulative Timesteps: 718,579,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 718579842...
Checkpoint 718579842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,353.32627
Policy Entropy: 1.12456
Value Function Loss: 5.43652

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.09126

Collected Steps per Second: 10,338.57318
Overall Steps per Second: 8,987.98280

Timestep Collection Time: 4.83626
Timestep Consumption Time: 0.72673
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.56298

Cumulative Model Updates: 43,081
Cumulative Timesteps: 718,629,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,835.93042
Policy Entropy: 1.14247
Value Function Loss: 5.64957

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.08002

Collected Steps per Second: 9,901.07514
Overall Steps per Second: 8,445.65111

Timestep Collection Time: 5.05319
Timestep Consumption Time: 0.87081
PPO Batch Consumption Time: 0.03800
Total Iteration Time: 5.92400

Cumulative Model Updates: 43,084
Cumulative Timesteps: 718,679,874

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 718679874...
Checkpoint 718679874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,970.34350
Policy Entropy: 1.13432
Value Function Loss: 5.70588

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.07062

Collected Steps per Second: 10,236.14315
Overall Steps per Second: 8,741.83782

Timestep Collection Time: 4.88719
Timestep Consumption Time: 0.83540
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 5.72260

Cumulative Model Updates: 43,087
Cumulative Timesteps: 718,729,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,043.19380
Policy Entropy: 1.13872
Value Function Loss: 5.55275

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.06258
Value Function Update Magnitude: 0.07684

Collected Steps per Second: 9,909.77452
Overall Steps per Second: 8,548.77303

Timestep Collection Time: 5.04573
Timestep Consumption Time: 0.80330
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.84903

Cumulative Model Updates: 43,090
Cumulative Timesteps: 718,779,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 718779902...
Checkpoint 718779902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,408.01112
Policy Entropy: 1.13065
Value Function Loss: 5.37777

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.07039
Value Function Update Magnitude: 0.07743

Collected Steps per Second: 10,322.35870
Overall Steps per Second: 8,819.76399

Timestep Collection Time: 4.84405
Timestep Consumption Time: 0.82526
PPO Batch Consumption Time: 0.03888
Total Iteration Time: 5.66931

Cumulative Model Updates: 43,093
Cumulative Timesteps: 718,829,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,397.55450
Policy Entropy: 1.13707
Value Function Loss: 5.29784

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.07344
Value Function Update Magnitude: 0.07796

Collected Steps per Second: 9,975.68594
Overall Steps per Second: 8,695.41057

Timestep Collection Time: 5.01319
Timestep Consumption Time: 0.73812
PPO Batch Consumption Time: 0.03843
Total Iteration Time: 5.75131

Cumulative Model Updates: 43,096
Cumulative Timesteps: 718,879,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 718879914...
Checkpoint 718879914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,879.48621
Policy Entropy: 1.12703
Value Function Loss: 5.53780

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.07024
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 10,368.92454
Overall Steps per Second: 8,817.53082

Timestep Collection Time: 4.82287
Timestep Consumption Time: 0.84856
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 5.67143

Cumulative Model Updates: 43,099
Cumulative Timesteps: 718,929,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,302.88171
Policy Entropy: 1.13820
Value Function Loss: 5.57702

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.06704

Collected Steps per Second: 10,525.95541
Overall Steps per Second: 9,108.56880

Timestep Collection Time: 4.75225
Timestep Consumption Time: 0.73950
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.49175

Cumulative Model Updates: 43,102
Cumulative Timesteps: 718,979,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 718979944...
Checkpoint 718979944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,671.34617
Policy Entropy: 1.13504
Value Function Loss: 5.51532

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.06344

Collected Steps per Second: 9,902.80270
Overall Steps per Second: 8,475.48318

Timestep Collection Time: 5.05211
Timestep Consumption Time: 0.85080
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.90291

Cumulative Model Updates: 43,105
Cumulative Timesteps: 719,029,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,216.53035
Policy Entropy: 1.12391
Value Function Loss: 5.31339

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.06435

Collected Steps per Second: 10,176.33079
Overall Steps per Second: 8,705.14032

Timestep Collection Time: 4.91454
Timestep Consumption Time: 0.83057
PPO Batch Consumption Time: 0.03925
Total Iteration Time: 5.74511

Cumulative Model Updates: 43,108
Cumulative Timesteps: 719,079,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 719079986...
Checkpoint 719079986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,092.59403
Policy Entropy: 1.11239
Value Function Loss: 5.30382

Mean KL Divergence: 0.03408
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 10,221.71430
Overall Steps per Second: 8,672.83237

Timestep Collection Time: 4.89155
Timestep Consumption Time: 0.87358
PPO Batch Consumption Time: 0.03910
Total Iteration Time: 5.76513

Cumulative Model Updates: 43,111
Cumulative Timesteps: 719,129,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,152.09806
Policy Entropy: 1.13144
Value Function Loss: 5.39190

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.07590

Collected Steps per Second: 10,318.13046
Overall Steps per Second: 8,735.38310

Timestep Collection Time: 4.84758
Timestep Consumption Time: 0.87832
PPO Batch Consumption Time: 0.04343
Total Iteration Time: 5.72591

Cumulative Model Updates: 43,114
Cumulative Timesteps: 719,180,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 719180004...
Checkpoint 719180004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,548.48962
Policy Entropy: 1.12533
Value Function Loss: 5.38268

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.08270

Collected Steps per Second: 10,083.32170
Overall Steps per Second: 8,827.40750

Timestep Collection Time: 4.95908
Timestep Consumption Time: 0.70555
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.66463

Cumulative Model Updates: 43,117
Cumulative Timesteps: 719,230,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,517.38184
Policy Entropy: 1.11943
Value Function Loss: 5.45923

Mean KL Divergence: 0.03313
SB3 Clip Fraction: 0.15651
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.08061

Collected Steps per Second: 10,297.01422
Overall Steps per Second: 8,807.61727

Timestep Collection Time: 4.85869
Timestep Consumption Time: 0.82162
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.68031

Cumulative Model Updates: 43,120
Cumulative Timesteps: 719,280,038

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 719280038...
Checkpoint 719280038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,002.96462
Policy Entropy: 1.13117
Value Function Loss: 5.48652

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.07995

Collected Steps per Second: 11,096.02031
Overall Steps per Second: 9,390.85842

Timestep Collection Time: 4.50738
Timestep Consumption Time: 0.81844
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 5.32582

Cumulative Model Updates: 43,123
Cumulative Timesteps: 719,330,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,219.05863
Policy Entropy: 1.13311
Value Function Loss: 5.64943

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.07293

Collected Steps per Second: 10,821.89711
Overall Steps per Second: 9,096.32256

Timestep Collection Time: 4.62026
Timestep Consumption Time: 0.87646
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.49673

Cumulative Model Updates: 43,126
Cumulative Timesteps: 719,380,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 719380052...
Checkpoint 719380052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412,389.82891
Policy Entropy: 1.11814
Value Function Loss: 5.49128

Mean KL Divergence: 0.02599
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.07138

Collected Steps per Second: 9,961.51320
Overall Steps per Second: 8,528.44218

Timestep Collection Time: 5.02112
Timestep Consumption Time: 0.84372
PPO Batch Consumption Time: 0.04015
Total Iteration Time: 5.86485

Cumulative Model Updates: 43,129
Cumulative Timesteps: 719,430,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,742.08546
Policy Entropy: 1.12504
Value Function Loss: 5.21474

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 10,160.73482
Overall Steps per Second: 8,822.86350

Timestep Collection Time: 4.92287
Timestep Consumption Time: 0.74649
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.66936

Cumulative Model Updates: 43,132
Cumulative Timesteps: 719,480,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 719480090...
Checkpoint 719480090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,745.76873
Policy Entropy: 1.12722
Value Function Loss: 5.11617

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.07691

Collected Steps per Second: 10,263.75574
Overall Steps per Second: 8,672.02616

Timestep Collection Time: 4.87249
Timestep Consumption Time: 0.89433
PPO Batch Consumption Time: 0.03849
Total Iteration Time: 5.76682

Cumulative Model Updates: 43,135
Cumulative Timesteps: 719,530,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,378.44677
Policy Entropy: 1.13199
Value Function Loss: 5.13214

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.07032
Value Function Update Magnitude: 0.10187

Collected Steps per Second: 9,702.24321
Overall Steps per Second: 8,392.27609

Timestep Collection Time: 5.15510
Timestep Consumption Time: 0.80467
PPO Batch Consumption Time: 0.03897
Total Iteration Time: 5.95977

Cumulative Model Updates: 43,138
Cumulative Timesteps: 719,580,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 719580116...
Checkpoint 719580116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,416.52570
Policy Entropy: 1.11782
Value Function Loss: 5.13015

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.07121
Value Function Update Magnitude: 0.10925

Collected Steps per Second: 9,828.05385
Overall Steps per Second: 8,434.44222

Timestep Collection Time: 5.09033
Timestep Consumption Time: 0.84107
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.93139

Cumulative Model Updates: 43,141
Cumulative Timesteps: 719,630,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,636.61300
Policy Entropy: 1.12990
Value Function Loss: 5.12081

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.10044

Collected Steps per Second: 10,202.97144
Overall Steps per Second: 8,693.24450

Timestep Collection Time: 4.90171
Timestep Consumption Time: 0.85126
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.75297

Cumulative Model Updates: 43,144
Cumulative Timesteps: 719,680,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 719680156...
Checkpoint 719680156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,343.23353
Policy Entropy: 1.13687
Value Function Loss: 5.08761

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.08712

Collected Steps per Second: 9,556.32446
Overall Steps per Second: 8,246.28835

Timestep Collection Time: 5.23256
Timestep Consumption Time: 0.83126
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.06382

Cumulative Model Updates: 43,147
Cumulative Timesteps: 719,730,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,493.41044
Policy Entropy: 1.12296
Value Function Loss: 5.34277

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.10680

Collected Steps per Second: 9,716.54973
Overall Steps per Second: 8,236.89759

Timestep Collection Time: 5.14689
Timestep Consumption Time: 0.92457
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 6.07146

Cumulative Model Updates: 43,150
Cumulative Timesteps: 719,780,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 719780170...
Checkpoint 719780170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,525.27465
Policy Entropy: 1.11174
Value Function Loss: 5.35582

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.12595

Collected Steps per Second: 9,404.40852
Overall Steps per Second: 8,183.05965

Timestep Collection Time: 5.31708
Timestep Consumption Time: 0.79359
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 6.11067

Cumulative Model Updates: 43,153
Cumulative Timesteps: 719,830,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,177.67062
Policy Entropy: 1.12865
Value Function Loss: 5.51452

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.12107

Collected Steps per Second: 9,435.61905
Overall Steps per Second: 8,095.80870

Timestep Collection Time: 5.30182
Timestep Consumption Time: 0.87742
PPO Batch Consumption Time: 0.04562
Total Iteration Time: 6.17925

Cumulative Model Updates: 43,156
Cumulative Timesteps: 719,880,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 719880200...
Checkpoint 719880200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,580.33305
Policy Entropy: 1.12656
Value Function Loss: 5.33723

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.06264
Value Function Update Magnitude: 0.10931

Collected Steps per Second: 8,917.09360
Overall Steps per Second: 7,718.71597

Timestep Collection Time: 5.61035
Timestep Consumption Time: 0.87104
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 6.48139

Cumulative Model Updates: 43,159
Cumulative Timesteps: 719,930,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,114.01235
Policy Entropy: 1.12869
Value Function Loss: 5.43773

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.07487
Value Function Update Magnitude: 0.10022

Collected Steps per Second: 9,197.75703
Overall Steps per Second: 8,059.12391

Timestep Collection Time: 5.43937
Timestep Consumption Time: 0.76850
PPO Batch Consumption Time: 0.04468
Total Iteration Time: 6.20787

Cumulative Model Updates: 43,162
Cumulative Timesteps: 719,980,258

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 719980258...
Checkpoint 719980258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,812.56355
Policy Entropy: 1.11794
Value Function Loss: 5.18412

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.06872
Value Function Update Magnitude: 0.10012

Collected Steps per Second: 9,437.97515
Overall Steps per Second: 8,011.30899

Timestep Collection Time: 5.29944
Timestep Consumption Time: 0.94373
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.24317

Cumulative Model Updates: 43,165
Cumulative Timesteps: 720,030,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,033.01654
Policy Entropy: 1.13248
Value Function Loss: 5.44289

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.08989

Collected Steps per Second: 9,755.87478
Overall Steps per Second: 8,380.65165

Timestep Collection Time: 5.12799
Timestep Consumption Time: 0.84148
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 5.96946

Cumulative Model Updates: 43,168
Cumulative Timesteps: 720,080,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 720080302...
Checkpoint 720080302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,727.03922
Policy Entropy: 1.13380
Value Function Loss: 5.55338

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.07864

Collected Steps per Second: 10,149.51168
Overall Steps per Second: 8,604.02099

Timestep Collection Time: 4.92713
Timestep Consumption Time: 0.88503
PPO Batch Consumption Time: 0.03940
Total Iteration Time: 5.81217

Cumulative Model Updates: 43,171
Cumulative Timesteps: 720,130,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,905.82927
Policy Entropy: 1.13577
Value Function Loss: 5.66347

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.06769
Value Function Update Magnitude: 0.09272

Collected Steps per Second: 10,090.03102
Overall Steps per Second: 8,589.33553

Timestep Collection Time: 4.95598
Timestep Consumption Time: 0.86589
PPO Batch Consumption Time: 0.04421
Total Iteration Time: 5.82187

Cumulative Model Updates: 43,174
Cumulative Timesteps: 720,180,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 720180316...
Checkpoint 720180316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,749.71315
Policy Entropy: 1.12713
Value Function Loss: 5.62250

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.10675

Collected Steps per Second: 10,066.42630
Overall Steps per Second: 8,724.41140

Timestep Collection Time: 4.96820
Timestep Consumption Time: 0.76422
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 5.73242

Cumulative Model Updates: 43,177
Cumulative Timesteps: 720,230,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,309.26297
Policy Entropy: 1.13037
Value Function Loss: 5.41164

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.11483

Collected Steps per Second: 9,627.70723
Overall Steps per Second: 8,253.55782

Timestep Collection Time: 5.19605
Timestep Consumption Time: 0.86510
PPO Batch Consumption Time: 0.04400
Total Iteration Time: 6.06114

Cumulative Model Updates: 43,180
Cumulative Timesteps: 720,280,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 720280354...
Checkpoint 720280354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,806.51637
Policy Entropy: 1.12052
Value Function Loss: 5.27043

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.07052
Value Function Update Magnitude: 0.12047

Collected Steps per Second: 9,759.87739
Overall Steps per Second: 8,382.89156

Timestep Collection Time: 5.12322
Timestep Consumption Time: 0.84155
PPO Batch Consumption Time: 0.04572
Total Iteration Time: 5.96477

Cumulative Model Updates: 43,183
Cumulative Timesteps: 720,330,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,157.85528
Policy Entropy: 1.13624
Value Function Loss: 5.13552

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 10,073.31869
Overall Steps per Second: 8,564.45459

Timestep Collection Time: 4.96460
Timestep Consumption Time: 0.87465
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 5.83925

Cumulative Model Updates: 43,186
Cumulative Timesteps: 720,380,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 720380366...
Checkpoint 720380366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,065.83732
Policy Entropy: 1.13742
Value Function Loss: 5.21582

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.09206

Collected Steps per Second: 9,989.54391
Overall Steps per Second: 8,556.91755

Timestep Collection Time: 5.00704
Timestep Consumption Time: 0.83829
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 5.84533

Cumulative Model Updates: 43,189
Cumulative Timesteps: 720,430,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,926.08494
Policy Entropy: 1.13058
Value Function Loss: 5.11251

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.09414

Collected Steps per Second: 9,502.67432
Overall Steps per Second: 8,320.67713

Timestep Collection Time: 5.26483
Timestep Consumption Time: 0.74790
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 6.01273

Cumulative Model Updates: 43,192
Cumulative Timesteps: 720,480,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 720480414...
Checkpoint 720480414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,065.44858
Policy Entropy: 1.12682
Value Function Loss: 5.09143

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.08311

Collected Steps per Second: 9,603.70488
Overall Steps per Second: 8,207.20572

Timestep Collection Time: 5.20757
Timestep Consumption Time: 0.88610
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 6.09367

Cumulative Model Updates: 43,195
Cumulative Timesteps: 720,530,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727,533.07006
Policy Entropy: 1.13455
Value Function Loss: 4.99769

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.07541

Collected Steps per Second: 9,555.67761
Overall Steps per Second: 8,150.57074

Timestep Collection Time: 5.23396
Timestep Consumption Time: 0.90230
PPO Batch Consumption Time: 0.04391
Total Iteration Time: 6.13626

Cumulative Model Updates: 43,198
Cumulative Timesteps: 720,580,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 720580440...
Checkpoint 720580440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,287.20069
Policy Entropy: 1.14619
Value Function Loss: 5.06303

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.07720

Collected Steps per Second: 9,602.90698
Overall Steps per Second: 8,238.58774

Timestep Collection Time: 5.21009
Timestep Consumption Time: 0.86280
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 6.07289

Cumulative Model Updates: 43,201
Cumulative Timesteps: 720,630,472

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,157.95162
Policy Entropy: 1.12171
Value Function Loss: 4.94537

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.08592

Collected Steps per Second: 10,074.92330
Overall Steps per Second: 8,612.44622

Timestep Collection Time: 4.96381
Timestep Consumption Time: 0.84290
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 5.80671

Cumulative Model Updates: 43,204
Cumulative Timesteps: 720,680,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 720680482...
Checkpoint 720680482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,862.49553
Policy Entropy: 1.12953
Value Function Loss: 4.93670

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.08084

Collected Steps per Second: 9,991.53055
Overall Steps per Second: 8,696.94728

Timestep Collection Time: 5.00564
Timestep Consumption Time: 0.74511
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 5.75075

Cumulative Model Updates: 43,207
Cumulative Timesteps: 720,730,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,083.02414
Policy Entropy: 1.12874
Value Function Loss: 5.14635

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.07586

Collected Steps per Second: 9,869.40429
Overall Steps per Second: 8,354.75823

Timestep Collection Time: 5.06920
Timestep Consumption Time: 0.91900
PPO Batch Consumption Time: 0.04727
Total Iteration Time: 5.98820

Cumulative Model Updates: 43,210
Cumulative Timesteps: 720,780,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 720780526...
Checkpoint 720780526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,098.80804
Policy Entropy: 1.11457
Value Function Loss: 5.33023

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.07660

Collected Steps per Second: 9,946.81895
Overall Steps per Second: 8,521.61064

Timestep Collection Time: 5.02734
Timestep Consumption Time: 0.84080
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 5.86814

Cumulative Model Updates: 43,213
Cumulative Timesteps: 720,830,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,254.73308
Policy Entropy: 1.10381
Value Function Loss: 5.42927

Mean KL Divergence: 0.02925
SB3 Clip Fraction: 0.15289
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.06952

Collected Steps per Second: 10,288.28511
Overall Steps per Second: 8,760.63731

Timestep Collection Time: 4.86106
Timestep Consumption Time: 0.84765
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.70872

Cumulative Model Updates: 43,216
Cumulative Timesteps: 720,880,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 720880544...
Checkpoint 720880544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,040.41148
Policy Entropy: 1.10998
Value Function Loss: 5.46100

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.06419

Collected Steps per Second: 9,996.06618
Overall Steps per Second: 8,584.97565

Timestep Collection Time: 5.00277
Timestep Consumption Time: 0.82229
PPO Batch Consumption Time: 0.04007
Total Iteration Time: 5.82506

Cumulative Model Updates: 43,219
Cumulative Timesteps: 720,930,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,169.71344
Policy Entropy: 1.12323
Value Function Loss: 5.29278

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.05647

Collected Steps per Second: 10,006.51404
Overall Steps per Second: 8,620.64046

Timestep Collection Time: 4.99675
Timestep Consumption Time: 0.80329
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 5.80003

Cumulative Model Updates: 43,222
Cumulative Timesteps: 720,980,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 720980552...
Checkpoint 720980552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,098.78730
Policy Entropy: 1.08987
Value Function Loss: 5.11297

Mean KL Divergence: 0.05051
SB3 Clip Fraction: 0.20568
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 9,802.39451
Overall Steps per Second: 8,246.93582

Timestep Collection Time: 5.10079
Timestep Consumption Time: 0.96206
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 6.06286

Cumulative Model Updates: 43,225
Cumulative Timesteps: 721,030,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,974.35902
Policy Entropy: 1.11584
Value Function Loss: 4.94046

Mean KL Divergence: 0.02509
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.07165

Collected Steps per Second: 10,020.92150
Overall Steps per Second: 8,566.34089

Timestep Collection Time: 4.99056
Timestep Consumption Time: 0.84741
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 5.83797

Cumulative Model Updates: 43,228
Cumulative Timesteps: 721,080,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 721080562...
Checkpoint 721080562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,443.34001
Policy Entropy: 1.10380
Value Function Loss: 4.88264

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.07914

Collected Steps per Second: 10,070.71057
Overall Steps per Second: 8,557.95162

Timestep Collection Time: 4.96767
Timestep Consumption Time: 0.87812
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 5.84579

Cumulative Model Updates: 43,231
Cumulative Timesteps: 721,130,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,675.48005
Policy Entropy: 1.10244
Value Function Loss: 4.95323

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.07558

Collected Steps per Second: 10,148.00297
Overall Steps per Second: 8,621.71885

Timestep Collection Time: 4.92806
Timestep Consumption Time: 0.87240
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 5.80047

Cumulative Model Updates: 43,234
Cumulative Timesteps: 721,180,600

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 721180600...
Checkpoint 721180600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,122.34218
Policy Entropy: 1.11985
Value Function Loss: 5.04489

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.06925

Collected Steps per Second: 9,342.98774
Overall Steps per Second: 8,132.26516

Timestep Collection Time: 5.35311
Timestep Consumption Time: 0.79696
PPO Batch Consumption Time: 0.04951
Total Iteration Time: 6.15007

Cumulative Model Updates: 43,237
Cumulative Timesteps: 721,230,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,099.77750
Policy Entropy: 1.11671
Value Function Loss: 5.08406

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.07218

Collected Steps per Second: 8,798.58944
Overall Steps per Second: 7,286.40979

Timestep Collection Time: 5.68591
Timestep Consumption Time: 1.18002
PPO Batch Consumption Time: 0.04552
Total Iteration Time: 6.86593

Cumulative Model Updates: 43,240
Cumulative Timesteps: 721,280,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 721280642...
Checkpoint 721280642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,970.63575
Policy Entropy: 1.10225
Value Function Loss: 5.25454

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.07435

Collected Steps per Second: 9,696.66951
Overall Steps per Second: 8,401.38592

Timestep Collection Time: 5.15888
Timestep Consumption Time: 0.79537
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.95426

Cumulative Model Updates: 43,243
Cumulative Timesteps: 721,330,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,112.72180
Policy Entropy: 1.09023
Value Function Loss: 5.22338

Mean KL Divergence: 0.02777
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.07673

Collected Steps per Second: 11,839.39999
Overall Steps per Second: 9,954.43172

Timestep Collection Time: 4.22386
Timestep Consumption Time: 0.79983
PPO Batch Consumption Time: 0.03352
Total Iteration Time: 5.02369

Cumulative Model Updates: 43,246
Cumulative Timesteps: 721,380,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 721380674...
Checkpoint 721380674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,408.08085
Policy Entropy: 1.10510
Value Function Loss: 5.57430

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.07987

Collected Steps per Second: 12,165.96878
Overall Steps per Second: 10,291.93193

Timestep Collection Time: 4.11180
Timestep Consumption Time: 0.74871
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 4.86051

Cumulative Model Updates: 43,249
Cumulative Timesteps: 721,430,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,650.53881
Policy Entropy: 1.11213
Value Function Loss: 5.37558

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.08364

Collected Steps per Second: 12,108.62812
Overall Steps per Second: 10,378.67189

Timestep Collection Time: 4.13011
Timestep Consumption Time: 0.68842
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 4.81854

Cumulative Model Updates: 43,252
Cumulative Timesteps: 721,480,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 721480708...
Checkpoint 721480708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,618.00438
Policy Entropy: 1.09757
Value Function Loss: 5.36963

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.07725

Collected Steps per Second: 12,393.46516
Overall Steps per Second: 10,346.88032

Timestep Collection Time: 4.03568
Timestep Consumption Time: 0.79825
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.83392

Cumulative Model Updates: 43,255
Cumulative Timesteps: 721,530,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,032.27327
Policy Entropy: 1.10659
Value Function Loss: 5.12942

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.08417

Collected Steps per Second: 11,796.59034
Overall Steps per Second: 10,003.76446

Timestep Collection Time: 4.24072
Timestep Consumption Time: 0.76000
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.00072

Cumulative Model Updates: 43,258
Cumulative Timesteps: 721,580,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 721580750...
Checkpoint 721580750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,322.11469
Policy Entropy: 1.10705
Value Function Loss: 5.32861

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.08613

Collected Steps per Second: 12,022.59937
Overall Steps per Second: 10,172.48361

Timestep Collection Time: 4.16066
Timestep Consumption Time: 0.75672
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 4.91738

Cumulative Model Updates: 43,261
Cumulative Timesteps: 721,630,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,653.23222
Policy Entropy: 1.11097
Value Function Loss: 5.44351

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.09191

Collected Steps per Second: 11,735.01175
Overall Steps per Second: 10,012.34997

Timestep Collection Time: 4.26161
Timestep Consumption Time: 0.73323
PPO Batch Consumption Time: 0.03917
Total Iteration Time: 4.99483

Cumulative Model Updates: 43,264
Cumulative Timesteps: 721,680,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 721680782...
Checkpoint 721680782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,056.55912
Policy Entropy: 1.11588
Value Function Loss: 5.54602

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.06436
Value Function Update Magnitude: 0.08679

Collected Steps per Second: 12,049.84931
Overall Steps per Second: 10,299.14999

Timestep Collection Time: 4.15076
Timestep Consumption Time: 0.70557
PPO Batch Consumption Time: 0.03771
Total Iteration Time: 4.85632

Cumulative Model Updates: 43,267
Cumulative Timesteps: 721,730,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551,349.60017
Policy Entropy: 1.11983
Value Function Loss: 5.42117

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.07246
Value Function Update Magnitude: 0.08710

Collected Steps per Second: 12,027.98837
Overall Steps per Second: 10,097.03980

Timestep Collection Time: 4.15930
Timestep Consumption Time: 0.79542
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.95472

Cumulative Model Updates: 43,270
Cumulative Timesteps: 721,780,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 721780826...
Checkpoint 721780826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,588.31107
Policy Entropy: 1.11966
Value Function Loss: 5.11680

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.06893
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 11,920.00954
Overall Steps per Second: 10,095.68061

Timestep Collection Time: 4.19480
Timestep Consumption Time: 0.75802
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.95281

Cumulative Model Updates: 43,273
Cumulative Timesteps: 721,830,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,697.83414
Policy Entropy: 1.10997
Value Function Loss: 5.09958

Mean KL Divergence: 0.02941
SB3 Clip Fraction: 0.15587
Policy Update Magnitude: 0.06007
Value Function Update Magnitude: 0.08513

Collected Steps per Second: 11,869.52635
Overall Steps per Second: 9,997.19026

Timestep Collection Time: 4.21348
Timestep Consumption Time: 0.78913
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.00261

Cumulative Model Updates: 43,276
Cumulative Timesteps: 721,880,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 721880840...
Checkpoint 721880840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,107.15619
Policy Entropy: 1.12055
Value Function Loss: 5.08167

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.09772

Collected Steps per Second: 11,792.46451
Overall Steps per Second: 10,023.27536

Timestep Collection Time: 4.24169
Timestep Consumption Time: 0.74869
PPO Batch Consumption Time: 0.03358
Total Iteration Time: 4.99038

Cumulative Model Updates: 43,279
Cumulative Timesteps: 721,930,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,961.92001
Policy Entropy: 1.12033
Value Function Loss: 5.29125

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.10082

Collected Steps per Second: 11,665.01441
Overall Steps per Second: 10,103.93041

Timestep Collection Time: 4.28786
Timestep Consumption Time: 0.66249
PPO Batch Consumption Time: 0.03401
Total Iteration Time: 4.95035

Cumulative Model Updates: 43,282
Cumulative Timesteps: 721,980,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 721980878...
Checkpoint 721980878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,192.39835
Policy Entropy: 1.09749
Value Function Loss: 5.20027

Mean KL Divergence: 0.03213
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.09139

Collected Steps per Second: 12,022.78747
Overall Steps per Second: 10,126.32597

Timestep Collection Time: 4.15960
Timestep Consumption Time: 0.77901
PPO Batch Consumption Time: 0.03324
Total Iteration Time: 4.93861

Cumulative Model Updates: 43,285
Cumulative Timesteps: 722,030,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,564.36831
Policy Entropy: 1.11486
Value Function Loss: 5.33937

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.07861

Collected Steps per Second: 12,045.30550
Overall Steps per Second: 10,229.83285

Timestep Collection Time: 4.15116
Timestep Consumption Time: 0.73670
PPO Batch Consumption Time: 0.03338
Total Iteration Time: 4.88786

Cumulative Model Updates: 43,288
Cumulative Timesteps: 722,080,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 722080890...
Checkpoint 722080890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,626.05192
Policy Entropy: 1.11678
Value Function Loss: 5.29154

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.07717

Collected Steps per Second: 12,137.50414
Overall Steps per Second: 10,268.09911

Timestep Collection Time: 4.11996
Timestep Consumption Time: 0.75008
PPO Batch Consumption Time: 0.03347
Total Iteration Time: 4.87003

Cumulative Model Updates: 43,291
Cumulative Timesteps: 722,130,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,858.28602
Policy Entropy: 1.10577
Value Function Loss: 5.25259

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.07847

Collected Steps per Second: 11,387.78504
Overall Steps per Second: 9,767.43514

Timestep Collection Time: 4.39225
Timestep Consumption Time: 0.72864
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.12089

Cumulative Model Updates: 43,294
Cumulative Timesteps: 722,180,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 722180914...
Checkpoint 722180914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,982.96341
Policy Entropy: 1.09915
Value Function Loss: 5.13437

Mean KL Divergence: 0.02726
SB3 Clip Fraction: 0.15419
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.07726

Collected Steps per Second: 11,887.27976
Overall Steps per Second: 10,266.48354

Timestep Collection Time: 4.20735
Timestep Consumption Time: 0.66423
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 4.87158

Cumulative Model Updates: 43,297
Cumulative Timesteps: 722,230,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,655.79428
Policy Entropy: 1.11044
Value Function Loss: 4.93036

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.08892

Collected Steps per Second: 11,917.83892
Overall Steps per Second: 10,022.15438

Timestep Collection Time: 4.19657
Timestep Consumption Time: 0.79378
PPO Batch Consumption Time: 0.03775
Total Iteration Time: 4.99034

Cumulative Model Updates: 43,300
Cumulative Timesteps: 722,280,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 722280942...
Checkpoint 722280942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389,425.10902
Policy Entropy: 1.12640
Value Function Loss: 4.89687

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.08895

Collected Steps per Second: 11,656.80798
Overall Steps per Second: 9,906.34769

Timestep Collection Time: 4.29003
Timestep Consumption Time: 0.75805
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.04808

Cumulative Model Updates: 43,303
Cumulative Timesteps: 722,330,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,997.42465
Policy Entropy: 1.10622
Value Function Loss: 5.05964

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.10652

Collected Steps per Second: 12,096.81495
Overall Steps per Second: 10,231.04033

Timestep Collection Time: 4.13580
Timestep Consumption Time: 0.75422
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.89002

Cumulative Model Updates: 43,306
Cumulative Timesteps: 722,380,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 722380980...
Checkpoint 722380980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,511.83078
Policy Entropy: 1.12324
Value Function Loss: 5.07675

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.12910

Collected Steps per Second: 12,117.98244
Overall Steps per Second: 10,310.56097

Timestep Collection Time: 4.12725
Timestep Consumption Time: 0.72350
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.85075

Cumulative Model Updates: 43,309
Cumulative Timesteps: 722,430,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,907.82639
Policy Entropy: 1.12098
Value Function Loss: 5.16717

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.13264

Collected Steps per Second: 11,506.15495
Overall Steps per Second: 9,882.38172

Timestep Collection Time: 4.34793
Timestep Consumption Time: 0.71441
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.06234

Cumulative Model Updates: 43,312
Cumulative Timesteps: 722,481,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 722481022...
Checkpoint 722481022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,434.50990
Policy Entropy: 1.10492
Value Function Loss: 4.84999

Mean KL Divergence: 0.02703
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.13202

Collected Steps per Second: 11,879.41889
Overall Steps per Second: 10,062.18500

Timestep Collection Time: 4.21014
Timestep Consumption Time: 0.76035
PPO Batch Consumption Time: 0.03361
Total Iteration Time: 4.97049

Cumulative Model Updates: 43,315
Cumulative Timesteps: 722,531,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,786.58578
Policy Entropy: 1.10327
Value Function Loss: 4.81209

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.12750

Collected Steps per Second: 11,936.07127
Overall Steps per Second: 10,115.59022

Timestep Collection Time: 4.19116
Timestep Consumption Time: 0.75427
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.94544

Cumulative Model Updates: 43,318
Cumulative Timesteps: 722,581,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 722581062...
Checkpoint 722581062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,315.93043
Policy Entropy: 1.11150
Value Function Loss: 4.75936

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.11421

Collected Steps per Second: 11,655.45666
Overall Steps per Second: 9,872.33801

Timestep Collection Time: 4.29001
Timestep Consumption Time: 0.77485
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.06486

Cumulative Model Updates: 43,321
Cumulative Timesteps: 722,631,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,394.19049
Policy Entropy: 1.11688
Value Function Loss: 4.83571

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.10752

Collected Steps per Second: 11,972.68344
Overall Steps per Second: 10,218.49031

Timestep Collection Time: 4.17751
Timestep Consumption Time: 0.71715
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.89466

Cumulative Model Updates: 43,324
Cumulative Timesteps: 722,681,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 722681080...
Checkpoint 722681080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,726.98607
Policy Entropy: 1.10495
Value Function Loss: 5.04699

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 12,000.84627
Overall Steps per Second: 10,207.89965

Timestep Collection Time: 4.16654
Timestep Consumption Time: 0.73182
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 4.89836

Cumulative Model Updates: 43,327
Cumulative Timesteps: 722,731,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,453.42810
Policy Entropy: 1.09183
Value Function Loss: 5.06666

Mean KL Divergence: 0.02988
SB3 Clip Fraction: 0.17007
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 11,903.26308
Overall Steps per Second: 10,063.88861

Timestep Collection Time: 4.20170
Timestep Consumption Time: 0.76794
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 4.96965

Cumulative Model Updates: 43,330
Cumulative Timesteps: 722,781,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 722781096...
Checkpoint 722781096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,833.30143
Policy Entropy: 1.10691
Value Function Loss: 5.28334

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.09011

Collected Steps per Second: 11,991.36574
Overall Steps per Second: 10,128.80532

Timestep Collection Time: 4.17133
Timestep Consumption Time: 0.76706
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.93839

Cumulative Model Updates: 43,333
Cumulative Timesteps: 722,831,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,320.67259
Policy Entropy: 1.10124
Value Function Loss: 5.25832

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.07053
Value Function Update Magnitude: 0.08436

Collected Steps per Second: 12,062.28995
Overall Steps per Second: 10,188.92093

Timestep Collection Time: 4.14515
Timestep Consumption Time: 0.76214
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.90729

Cumulative Model Updates: 43,336
Cumulative Timesteps: 722,881,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 722881116...
Checkpoint 722881116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,157.80582
Policy Entropy: 1.09592
Value Function Loss: 5.07600

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.07183
Value Function Update Magnitude: 0.10059

Collected Steps per Second: 11,880.08725
Overall Steps per Second: 10,106.15321

Timestep Collection Time: 4.20872
Timestep Consumption Time: 0.73876
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.94748

Cumulative Model Updates: 43,339
Cumulative Timesteps: 722,931,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,992.89791
Policy Entropy: 1.09919
Value Function Loss: 4.78857

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.06798
Value Function Update Magnitude: 0.10096

Collected Steps per Second: 12,077.69449
Overall Steps per Second: 10,411.23526

Timestep Collection Time: 4.14152
Timestep Consumption Time: 0.66291
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 4.80443

Cumulative Model Updates: 43,342
Cumulative Timesteps: 722,981,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 722981136...
Checkpoint 722981136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,513.97040
Policy Entropy: 1.09863
Value Function Loss: 4.77556

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.11927

Collected Steps per Second: 11,914.52500
Overall Steps per Second: 10,113.79250

Timestep Collection Time: 4.19790
Timestep Consumption Time: 0.74742
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 4.94533

Cumulative Model Updates: 43,345
Cumulative Timesteps: 723,031,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,167.94779
Policy Entropy: 1.11530
Value Function Loss: 4.73023

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.12283

Collected Steps per Second: 12,074.77428
Overall Steps per Second: 10,060.24623

Timestep Collection Time: 4.14252
Timestep Consumption Time: 0.82952
PPO Batch Consumption Time: 0.03748
Total Iteration Time: 4.97205

Cumulative Model Updates: 43,348
Cumulative Timesteps: 723,081,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 723081172...
Checkpoint 723081172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,849.52334
Policy Entropy: 1.10547
Value Function Loss: 4.88499

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.11654
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 12,124.83561
Overall Steps per Second: 10,272.90166

Timestep Collection Time: 4.12393
Timestep Consumption Time: 0.74344
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 4.86737

Cumulative Model Updates: 43,351
Cumulative Timesteps: 723,131,174

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,671.57998
Policy Entropy: 1.10612
Value Function Loss: 4.93611

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.10115

Collected Steps per Second: 11,873.27957
Overall Steps per Second: 10,093.75823

Timestep Collection Time: 4.21181
Timestep Consumption Time: 0.74254
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 4.95435

Cumulative Model Updates: 43,354
Cumulative Timesteps: 723,181,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 723181182...
Checkpoint 723181182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,346.74904
Policy Entropy: 1.10528
Value Function Loss: 5.09074

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.11847
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.09023

Collected Steps per Second: 11,807.68487
Overall Steps per Second: 10,189.13783

Timestep Collection Time: 4.23504
Timestep Consumption Time: 0.67274
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.90778

Cumulative Model Updates: 43,357
Cumulative Timesteps: 723,231,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,926.43306
Policy Entropy: 1.11966
Value Function Loss: 5.19393

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.08940

Collected Steps per Second: 11,992.32616
Overall Steps per Second: 10,191.72386

Timestep Collection Time: 4.16933
Timestep Consumption Time: 0.73661
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 4.90594

Cumulative Model Updates: 43,360
Cumulative Timesteps: 723,281,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 723281188...
Checkpoint 723281188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,728.47912
Policy Entropy: 1.12669
Value Function Loss: 5.09924

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.07674

Collected Steps per Second: 11,735.33683
Overall Steps per Second: 10,010.62520

Timestep Collection Time: 4.26115
Timestep Consumption Time: 0.73415
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 4.99529

Cumulative Model Updates: 43,363
Cumulative Timesteps: 723,331,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,167.75036
Policy Entropy: 1.12367
Value Function Loss: 5.16242

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.06449
Value Function Update Magnitude: 0.07429

Collected Steps per Second: 11,952.92798
Overall Steps per Second: 9,906.71347

Timestep Collection Time: 4.18391
Timestep Consumption Time: 0.86418
PPO Batch Consumption Time: 0.03804
Total Iteration Time: 5.04809

Cumulative Model Updates: 43,366
Cumulative Timesteps: 723,381,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 723381204...
Checkpoint 723381204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,430.24138
Policy Entropy: 1.11665
Value Function Loss: 5.15120

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.07062

Collected Steps per Second: 11,726.51294
Overall Steps per Second: 9,991.29004

Timestep Collection Time: 4.26435
Timestep Consumption Time: 0.74061
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 5.00496

Cumulative Model Updates: 43,369
Cumulative Timesteps: 723,431,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,483.04820
Policy Entropy: 1.12200
Value Function Loss: 5.14996

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.08259

Collected Steps per Second: 11,837.67850
Overall Steps per Second: 10,150.65458

Timestep Collection Time: 4.22431
Timestep Consumption Time: 0.70207
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.92638

Cumulative Model Updates: 43,372
Cumulative Timesteps: 723,481,216

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 723481216...
Checkpoint 723481216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,135.34790
Policy Entropy: 1.12638
Value Function Loss: 5.25835

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.07166

Collected Steps per Second: 12,124.67871
Overall Steps per Second: 10,142.71555

Timestep Collection Time: 4.12597
Timestep Consumption Time: 0.80624
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 4.93221

Cumulative Model Updates: 43,375
Cumulative Timesteps: 723,531,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405,696.56885
Policy Entropy: 1.13569
Value Function Loss: 5.00042

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.08250

Collected Steps per Second: 11,678.49455
Overall Steps per Second: 9,851.15053

Timestep Collection Time: 4.28309
Timestep Consumption Time: 0.79449
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 5.07758

Cumulative Model Updates: 43,378
Cumulative Timesteps: 723,581,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 723581262...
Checkpoint 723581262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,809.10454
Policy Entropy: 1.11959
Value Function Loss: 4.98658

Mean KL Divergence: 0.02659
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 11,951.50595
Overall Steps per Second: 10,092.72693

Timestep Collection Time: 4.18357
Timestep Consumption Time: 0.77049
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.95406

Cumulative Model Updates: 43,381
Cumulative Timesteps: 723,631,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429,760.43892
Policy Entropy: 1.12787
Value Function Loss: 4.86086

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.07404

Collected Steps per Second: 11,526.67440
Overall Steps per Second: 9,710.59733

Timestep Collection Time: 4.33967
Timestep Consumption Time: 0.81161
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.15128

Cumulative Model Updates: 43,384
Cumulative Timesteps: 723,681,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 723681284...
Checkpoint 723681284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,093.96836
Policy Entropy: 1.12579
Value Function Loss: 4.99261

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.07425

Collected Steps per Second: 12,002.74447
Overall Steps per Second: 10,309.45982

Timestep Collection Time: 4.16721
Timestep Consumption Time: 0.68445
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.85166

Cumulative Model Updates: 43,387
Cumulative Timesteps: 723,731,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,321.34211
Policy Entropy: 1.12433
Value Function Loss: 4.93956

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.10538
Policy Update Magnitude: 0.07056
Value Function Update Magnitude: 0.06932

Collected Steps per Second: 12,720.38719
Overall Steps per Second: 10,601.47526

Timestep Collection Time: 3.93148
Timestep Consumption Time: 0.78578
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.71727

Cumulative Model Updates: 43,390
Cumulative Timesteps: 723,781,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 723781312...
Checkpoint 723781312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,470.07757
Policy Entropy: 1.10968
Value Function Loss: 4.75625

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.07363
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 12,090.98835
Overall Steps per Second: 10,243.19175

Timestep Collection Time: 4.13746
Timestep Consumption Time: 0.74637
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.88383

Cumulative Model Updates: 43,393
Cumulative Timesteps: 723,831,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,187.87906
Policy Entropy: 1.12415
Value Function Loss: 4.83364

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.09137

Collected Steps per Second: 13,091.07102
Overall Steps per Second: 10,810.89403

Timestep Collection Time: 3.81940
Timestep Consumption Time: 0.80557
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.62496

Cumulative Model Updates: 43,396
Cumulative Timesteps: 723,881,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 723881338...
Checkpoint 723881338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,103.84512
Policy Entropy: 1.11715
Value Function Loss: 4.97030

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.08299

Collected Steps per Second: 12,472.23320
Overall Steps per Second: 10,442.32482

Timestep Collection Time: 4.01131
Timestep Consumption Time: 0.77977
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.79108

Cumulative Model Updates: 43,399
Cumulative Timesteps: 723,931,368

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,664.08921
Policy Entropy: 1.11330
Value Function Loss: 5.14645

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.08849

Collected Steps per Second: 12,473.62284
Overall Steps per Second: 10,637.36223

Timestep Collection Time: 4.01038
Timestep Consumption Time: 0.69229
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.70267

Cumulative Model Updates: 43,402
Cumulative Timesteps: 723,981,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 723981392...
Checkpoint 723981392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,344.85987
Policy Entropy: 1.10436
Value Function Loss: 4.96774

Mean KL Divergence: 0.02741
SB3 Clip Fraction: 0.15514
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.08084

Collected Steps per Second: 11,655.65788
Overall Steps per Second: 9,857.65884

Timestep Collection Time: 4.29062
Timestep Consumption Time: 0.78259
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.07321

Cumulative Model Updates: 43,405
Cumulative Timesteps: 724,031,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,605.00270
Policy Entropy: 1.12377
Value Function Loss: 4.84537

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.06818

Collected Steps per Second: 11,753.42244
Overall Steps per Second: 9,909.62083

Timestep Collection Time: 4.25527
Timestep Consumption Time: 0.79174
PPO Batch Consumption Time: 0.03780
Total Iteration Time: 5.04701

Cumulative Model Updates: 43,408
Cumulative Timesteps: 724,081,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 724081416...
Checkpoint 724081416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,216.37555
Policy Entropy: 1.11416
Value Function Loss: 4.78355

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.06294

Collected Steps per Second: 11,834.87993
Overall Steps per Second: 9,970.67215

Timestep Collection Time: 4.22564
Timestep Consumption Time: 0.79007
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.01571

Cumulative Model Updates: 43,411
Cumulative Timesteps: 724,131,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,412.22241
Policy Entropy: 1.10348
Value Function Loss: 4.88119

Mean KL Divergence: 0.03328
SB3 Clip Fraction: 0.17535
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.06124

Collected Steps per Second: 11,932.83037
Overall Steps per Second: 10,110.83293

Timestep Collection Time: 4.19230
Timestep Consumption Time: 0.75546
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.94776

Cumulative Model Updates: 43,414
Cumulative Timesteps: 724,181,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 724181452...
Checkpoint 724181452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,624.94156
Policy Entropy: 1.10590
Value Function Loss: 4.89275

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.07163

Collected Steps per Second: 11,921.46514
Overall Steps per Second: 10,249.16495

Timestep Collection Time: 4.19579
Timestep Consumption Time: 0.68460
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.88040

Cumulative Model Updates: 43,417
Cumulative Timesteps: 724,231,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,669.08662
Policy Entropy: 1.11949
Value Function Loss: 4.94436

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.10279

Collected Steps per Second: 11,986.03924
Overall Steps per Second: 10,043.18610

Timestep Collection Time: 4.17152
Timestep Consumption Time: 0.80698
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 4.97850

Cumulative Model Updates: 43,420
Cumulative Timesteps: 724,281,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 724281472...
Checkpoint 724281472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,212.65025
Policy Entropy: 1.09136
Value Function Loss: 4.91241

Mean KL Divergence: 0.05035
SB3 Clip Fraction: 0.18632
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 11,007.59568
Overall Steps per Second: 9,605.50886

Timestep Collection Time: 4.54232
Timestep Consumption Time: 0.66303
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.20535

Cumulative Model Updates: 43,423
Cumulative Timesteps: 724,331,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,566.28763
Policy Entropy: 1.11536
Value Function Loss: 4.68974

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.11504

Collected Steps per Second: 11,680.62965
Overall Steps per Second: 9,872.41680

Timestep Collection Time: 4.28162
Timestep Consumption Time: 0.78421
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.06583

Cumulative Model Updates: 43,426
Cumulative Timesteps: 724,381,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 724381484...
Checkpoint 724381484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,210.10218
Policy Entropy: 1.09587
Value Function Loss: 4.60723

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.11076

Collected Steps per Second: 11,582.74722
Overall Steps per Second: 9,817.90791

Timestep Collection Time: 4.31728
Timestep Consumption Time: 0.77606
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.09335

Cumulative Model Updates: 43,429
Cumulative Timesteps: 724,431,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,154.70047
Policy Entropy: 1.08486
Value Function Loss: 4.62531

Mean KL Divergence: 0.02962
SB3 Clip Fraction: 0.17781
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.10361

Collected Steps per Second: 11,966.98320
Overall Steps per Second: 10,094.76481

Timestep Collection Time: 4.17967
Timestep Consumption Time: 0.77518
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 4.95485

Cumulative Model Updates: 43,432
Cumulative Timesteps: 724,481,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 724481508...
Checkpoint 724481508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,983.83941
Policy Entropy: 1.10372
Value Function Loss: 4.76057

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.09861

Collected Steps per Second: 11,842.86745
Overall Steps per Second: 10,031.43401

Timestep Collection Time: 4.22415
Timestep Consumption Time: 0.76278
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.98692

Cumulative Model Updates: 43,435
Cumulative Timesteps: 724,531,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,801.76300
Policy Entropy: 1.11916
Value Function Loss: 4.89286

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.09857

Collected Steps per Second: 11,719.22019
Overall Steps per Second: 10,118.69774

Timestep Collection Time: 4.26769
Timestep Consumption Time: 0.67504
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.94273

Cumulative Model Updates: 43,438
Cumulative Timesteps: 724,581,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 724581548...
Checkpoint 724581548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,431.32324
Policy Entropy: 1.10155
Value Function Loss: 4.99963

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.10317

Collected Steps per Second: 11,488.54850
Overall Steps per Second: 9,790.75941

Timestep Collection Time: 4.35460
Timestep Consumption Time: 0.75512
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.10972

Cumulative Model Updates: 43,441
Cumulative Timesteps: 724,631,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,583.08507
Policy Entropy: 1.10087
Value Function Loss: 5.09337

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.09958

Collected Steps per Second: 11,776.44912
Overall Steps per Second: 10,031.41622

Timestep Collection Time: 4.24695
Timestep Consumption Time: 0.73879
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.98574

Cumulative Model Updates: 43,444
Cumulative Timesteps: 724,681,590

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 724681590...
Checkpoint 724681590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,291.64036
Policy Entropy: 1.10381
Value Function Loss: 5.20043

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.09494

Collected Steps per Second: 11,999.27525
Overall Steps per Second: 10,188.05433

Timestep Collection Time: 4.16859
Timestep Consumption Time: 0.74109
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.90967

Cumulative Model Updates: 43,447
Cumulative Timesteps: 724,731,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,343.23193
Policy Entropy: 1.11029
Value Function Loss: 4.98764

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 11,808.75847
Overall Steps per Second: 9,957.09509

Timestep Collection Time: 4.23499
Timestep Consumption Time: 0.78756
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.02255

Cumulative Model Updates: 43,450
Cumulative Timesteps: 724,781,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 724781620...
Checkpoint 724781620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,114.43770
Policy Entropy: 1.10203
Value Function Loss: 4.95473

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.10278

Collected Steps per Second: 11,913.68848
Overall Steps per Second: 10,228.10402

Timestep Collection Time: 4.19920
Timestep Consumption Time: 0.69203
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 4.89123

Cumulative Model Updates: 43,453
Cumulative Timesteps: 724,831,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,031.43144
Policy Entropy: 1.09440
Value Function Loss: 4.68558

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.10267

Collected Steps per Second: 12,078.44638
Overall Steps per Second: 10,200.54497

Timestep Collection Time: 4.14010
Timestep Consumption Time: 0.76219
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 4.90229

Cumulative Model Updates: 43,456
Cumulative Timesteps: 724,881,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 724881654...
Checkpoint 724881654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,382.75744
Policy Entropy: 1.10862
Value Function Loss: 4.69312

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.10170

Collected Steps per Second: 11,469.97005
Overall Steps per Second: 9,793.16434

Timestep Collection Time: 4.36026
Timestep Consumption Time: 0.74657
PPO Batch Consumption Time: 0.03347
Total Iteration Time: 5.10683

Cumulative Model Updates: 43,459
Cumulative Timesteps: 724,931,666

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,013.47542
Policy Entropy: 1.11017
Value Function Loss: 4.83380

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.10811

Collected Steps per Second: 12,401.83892
Overall Steps per Second: 10,429.46974

Timestep Collection Time: 4.03295
Timestep Consumption Time: 0.76269
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.79564

Cumulative Model Updates: 43,462
Cumulative Timesteps: 724,981,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 724981682...
Checkpoint 724981682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,076.56273
Policy Entropy: 1.09520
Value Function Loss: 4.84976

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.11120

Collected Steps per Second: 11,804.61158
Overall Steps per Second: 10,040.88266

Timestep Collection Time: 4.23563
Timestep Consumption Time: 0.74401
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.97964

Cumulative Model Updates: 43,465
Cumulative Timesteps: 725,031,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489,594.08220
Policy Entropy: 1.11374
Value Function Loss: 5.04556

Mean KL Divergence: 0.02591
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.09887

Collected Steps per Second: 12,219.85457
Overall Steps per Second: 10,350.59875

Timestep Collection Time: 4.09285
Timestep Consumption Time: 0.73914
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 4.83199

Cumulative Model Updates: 43,468
Cumulative Timesteps: 725,081,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 725081696...
Checkpoint 725081696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,810.68683
Policy Entropy: 1.10809
Value Function Loss: 5.04685

Mean KL Divergence: 0.02422
SB3 Clip Fraction: 0.15592
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.08485

Collected Steps per Second: 12,114.15854
Overall Steps per Second: 10,244.41566

Timestep Collection Time: 4.12823
Timestep Consumption Time: 0.75346
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 4.88168

Cumulative Model Updates: 43,471
Cumulative Timesteps: 725,131,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,873.02573
Policy Entropy: 1.10686
Value Function Loss: 5.29722

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.07784

Collected Steps per Second: 11,887.43233
Overall Steps per Second: 10,289.39653

Timestep Collection Time: 4.20730
Timestep Consumption Time: 0.65343
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 4.86073

Cumulative Model Updates: 43,474
Cumulative Timesteps: 725,181,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 725181720...
Checkpoint 725181720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,600.93859
Policy Entropy: 1.08830
Value Function Loss: 5.17063

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.15175
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 11,520.31129
Overall Steps per Second: 9,789.23330

Timestep Collection Time: 4.34016
Timestep Consumption Time: 0.76749
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 5.10765

Cumulative Model Updates: 43,477
Cumulative Timesteps: 725,231,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,719.66100
Policy Entropy: 1.09958
Value Function Loss: 5.17926

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.06293

Collected Steps per Second: 11,692.57875
Overall Steps per Second: 10,048.94354

Timestep Collection Time: 4.27673
Timestep Consumption Time: 0.69951
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 4.97624

Cumulative Model Updates: 43,480
Cumulative Timesteps: 725,281,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 725281726...
Checkpoint 725281726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,617.24578
Policy Entropy: 1.09482
Value Function Loss: 5.14760

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.06832

Collected Steps per Second: 11,926.35168
Overall Steps per Second: 10,123.14803

Timestep Collection Time: 4.19307
Timestep Consumption Time: 0.74690
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.93997

Cumulative Model Updates: 43,483
Cumulative Timesteps: 725,331,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,255.51682
Policy Entropy: 1.10116
Value Function Loss: 5.10351

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.07341

Collected Steps per Second: 11,944.55428
Overall Steps per Second: 10,145.61619

Timestep Collection Time: 4.18718
Timestep Consumption Time: 0.74244
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.92962

Cumulative Model Updates: 43,486
Cumulative Timesteps: 725,381,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 725381748...
Checkpoint 725381748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,942.13439
Policy Entropy: 1.10253
Value Function Loss: 4.87197

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.07565

Collected Steps per Second: 12,043.06166
Overall Steps per Second: 10,237.69241

Timestep Collection Time: 4.15326
Timestep Consumption Time: 0.73241
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 4.88567

Cumulative Model Updates: 43,489
Cumulative Timesteps: 725,431,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,120.44039
Policy Entropy: 1.10216
Value Function Loss: 4.62797

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.06452
Value Function Update Magnitude: 0.08901

Collected Steps per Second: 11,904.51533
Overall Steps per Second: 10,098.27236

Timestep Collection Time: 4.20042
Timestep Consumption Time: 0.75132
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.95174

Cumulative Model Updates: 43,492
Cumulative Timesteps: 725,481,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 725481770...
Checkpoint 725481770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,535.11526
Policy Entropy: 1.09666
Value Function Loss: 4.58577

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.06934
Value Function Update Magnitude: 0.10557

Collected Steps per Second: 11,333.32331
Overall Steps per Second: 9,858.10364

Timestep Collection Time: 4.41424
Timestep Consumption Time: 0.66057
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.07481

Cumulative Model Updates: 43,495
Cumulative Timesteps: 725,531,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,876.39757
Policy Entropy: 1.10397
Value Function Loss: 4.71500

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.09862

Collected Steps per Second: 11,859.13837
Overall Steps per Second: 10,041.51241

Timestep Collection Time: 4.21869
Timestep Consumption Time: 0.76363
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.98232

Cumulative Model Updates: 43,498
Cumulative Timesteps: 725,581,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 725581828...
Checkpoint 725581828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,264.47876
Policy Entropy: 1.10789
Value Function Loss: 4.78597

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.08213

Collected Steps per Second: 11,446.89493
Overall Steps per Second: 9,622.96054

Timestep Collection Time: 4.37009
Timestep Consumption Time: 0.82831
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.19840

Cumulative Model Updates: 43,501
Cumulative Timesteps: 725,631,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,001.09756
Policy Entropy: 1.11016
Value Function Loss: 4.75245

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.07746

Collected Steps per Second: 8,865.99534
Overall Steps per Second: 7,634.95610

Timestep Collection Time: 5.64110
Timestep Consumption Time: 0.90956
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 6.55066

Cumulative Model Updates: 43,504
Cumulative Timesteps: 725,681,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 725681866...
Checkpoint 725681866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,307.75168
Policy Entropy: 1.11130
Value Function Loss: 4.72513

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.07490

Collected Steps per Second: 9,596.95163
Overall Steps per Second: 8,264.16990

Timestep Collection Time: 5.21165
Timestep Consumption Time: 0.84050
PPO Batch Consumption Time: 0.04178
Total Iteration Time: 6.05215

Cumulative Model Updates: 43,507
Cumulative Timesteps: 725,731,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,982.34533
Policy Entropy: 1.10922
Value Function Loss: 4.62626

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.07553

Collected Steps per Second: 9,107.77690
Overall Steps per Second: 7,993.27082

Timestep Collection Time: 5.49201
Timestep Consumption Time: 0.76575
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 6.25776

Cumulative Model Updates: 43,510
Cumulative Timesteps: 725,781,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 725781902...
Checkpoint 725781902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596,869.94993
Policy Entropy: 1.11174
Value Function Loss: 4.77158

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.07239

Collected Steps per Second: 9,706.36037
Overall Steps per Second: 8,333.18794

Timestep Collection Time: 5.15188
Timestep Consumption Time: 0.84895
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 6.00082

Cumulative Model Updates: 43,513
Cumulative Timesteps: 725,831,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,862.66835
Policy Entropy: 1.12763
Value Function Loss: 4.86475

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.08497

Collected Steps per Second: 9,701.48840
Overall Steps per Second: 8,316.92181

Timestep Collection Time: 5.15632
Timestep Consumption Time: 0.85840
PPO Batch Consumption Time: 0.04277
Total Iteration Time: 6.01473

Cumulative Model Updates: 43,516
Cumulative Timesteps: 725,881,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 725881932...
Checkpoint 725881932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,627.47426
Policy Entropy: 1.13061
Value Function Loss: 4.95838

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.10143

Collected Steps per Second: 9,877.84220
Overall Steps per Second: 8,408.24424

Timestep Collection Time: 5.06224
Timestep Consumption Time: 0.88478
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 5.94702

Cumulative Model Updates: 43,519
Cumulative Timesteps: 725,931,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,145.74636
Policy Entropy: 1.11979
Value Function Loss: 4.97065

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.09312

Collected Steps per Second: 9,775.27725
Overall Steps per Second: 8,370.66745

Timestep Collection Time: 5.11822
Timestep Consumption Time: 0.85884
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 5.97706

Cumulative Model Updates: 43,522
Cumulative Timesteps: 725,981,968

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 725981968...
Checkpoint 725981968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,495.79616
Policy Entropy: 1.11073
Value Function Loss: 5.11601

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.09491

Collected Steps per Second: 9,405.74443
Overall Steps per Second: 8,248.87703

Timestep Collection Time: 5.31803
Timestep Consumption Time: 0.74583
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.06386

Cumulative Model Updates: 43,525
Cumulative Timesteps: 726,031,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,542.76530
Policy Entropy: 1.12447
Value Function Loss: 5.02877

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.10882

Collected Steps per Second: 9,921.89883
Overall Steps per Second: 8,465.39515

Timestep Collection Time: 5.03996
Timestep Consumption Time: 0.86714
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 5.90711

Cumulative Model Updates: 43,528
Cumulative Timesteps: 726,081,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 726081994...
Checkpoint 726081994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,900.70180
Policy Entropy: 1.13053
Value Function Loss: 4.92244

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.10828

Collected Steps per Second: 9,827.81880
Overall Steps per Second: 8,423.18970

Timestep Collection Time: 5.08821
Timestep Consumption Time: 0.84850
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 5.93671

Cumulative Model Updates: 43,531
Cumulative Timesteps: 726,132,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585,567.05034
Policy Entropy: 1.12094
Value Function Loss: 4.77921

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.10044

Collected Steps per Second: 10,094.52015
Overall Steps per Second: 8,598.05664

Timestep Collection Time: 4.95358
Timestep Consumption Time: 0.86215
PPO Batch Consumption Time: 0.04424
Total Iteration Time: 5.81573

Cumulative Model Updates: 43,534
Cumulative Timesteps: 726,182,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 726182004...
Checkpoint 726182004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372,419.76189
Policy Entropy: 1.11767
Value Function Loss: 4.87111

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.09340

Collected Steps per Second: 10,012.97280
Overall Steps per Second: 8,543.47950

Timestep Collection Time: 4.99692
Timestep Consumption Time: 0.85948
PPO Batch Consumption Time: 0.04081
Total Iteration Time: 5.85640

Cumulative Model Updates: 43,537
Cumulative Timesteps: 726,232,038

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,037.97921
Policy Entropy: 1.12421
Value Function Loss: 5.08759

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.08540

Collected Steps per Second: 9,412.03944
Overall Steps per Second: 8,230.89062

Timestep Collection Time: 5.31341
Timestep Consumption Time: 0.76248
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 6.07589

Cumulative Model Updates: 43,540
Cumulative Timesteps: 726,282,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 726282048...
Checkpoint 726282048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,581.30734
Policy Entropy: 1.13134
Value Function Loss: 5.21929

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.09247

Collected Steps per Second: 9,263.43712
Overall Steps per Second: 8,011.34759

Timestep Collection Time: 5.40016
Timestep Consumption Time: 0.84399
PPO Batch Consumption Time: 0.04075
Total Iteration Time: 6.24414

Cumulative Model Updates: 43,543
Cumulative Timesteps: 726,332,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,136.82280
Policy Entropy: 1.11368
Value Function Loss: 5.24409

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.10134

Collected Steps per Second: 9,628.03275
Overall Steps per Second: 8,296.20887

Timestep Collection Time: 5.19338
Timestep Consumption Time: 0.83371
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 6.02709

Cumulative Model Updates: 43,546
Cumulative Timesteps: 726,382,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 726382074...
Checkpoint 726382074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,868.21063
Policy Entropy: 1.10687
Value Function Loss: 5.12289

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.10739

Collected Steps per Second: 9,802.38518
Overall Steps per Second: 8,416.77597

Timestep Collection Time: 5.10366
Timestep Consumption Time: 0.84019
PPO Batch Consumption Time: 0.03955
Total Iteration Time: 5.94384

Cumulative Model Updates: 43,549
Cumulative Timesteps: 726,432,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,973.17869
Policy Entropy: 1.11292
Value Function Loss: 5.20707

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11208

Collected Steps per Second: 9,856.48465
Overall Steps per Second: 8,420.18274

Timestep Collection Time: 5.07443
Timestep Consumption Time: 0.86559
PPO Batch Consumption Time: 0.04335
Total Iteration Time: 5.94001

Cumulative Model Updates: 43,552
Cumulative Timesteps: 726,482,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 726482118...
Checkpoint 726482118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,212.09552
Policy Entropy: 1.11964
Value Function Loss: 5.31186

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.11057

Collected Steps per Second: 9,275.01390
Overall Steps per Second: 8,144.79053

Timestep Collection Time: 5.39083
Timestep Consumption Time: 0.74807
PPO Batch Consumption Time: 0.04304
Total Iteration Time: 6.13889

Cumulative Model Updates: 43,555
Cumulative Timesteps: 726,532,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,061.78116
Policy Entropy: 1.10544
Value Function Loss: 5.34317

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.11204

Collected Steps per Second: 9,721.16158
Overall Steps per Second: 8,331.09458

Timestep Collection Time: 5.14362
Timestep Consumption Time: 0.85823
PPO Batch Consumption Time: 0.04475
Total Iteration Time: 6.00185

Cumulative Model Updates: 43,558
Cumulative Timesteps: 726,582,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 726582120...
Checkpoint 726582120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,867.91998
Policy Entropy: 1.10130
Value Function Loss: 4.95845

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.10623

Collected Steps per Second: 9,591.53655
Overall Steps per Second: 8,260.36430

Timestep Collection Time: 5.21293
Timestep Consumption Time: 0.84007
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.05300

Cumulative Model Updates: 43,561
Cumulative Timesteps: 726,632,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,762.44290
Policy Entropy: 1.11308
Value Function Loss: 4.79941

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.09421

Collected Steps per Second: 9,758.98324
Overall Steps per Second: 8,451.89125

Timestep Collection Time: 5.12471
Timestep Consumption Time: 0.79254
PPO Batch Consumption Time: 0.04635
Total Iteration Time: 5.91726

Cumulative Model Updates: 43,564
Cumulative Timesteps: 726,682,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 726682132...
Checkpoint 726682132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,933.65931
Policy Entropy: 1.12195
Value Function Loss: 4.83243

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.08097

Collected Steps per Second: 9,696.59828
Overall Steps per Second: 8,333.12552

Timestep Collection Time: 5.15892
Timestep Consumption Time: 0.84411
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 6.00303

Cumulative Model Updates: 43,567
Cumulative Timesteps: 726,732,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,442.87443
Policy Entropy: 1.10195
Value Function Loss: 4.98805

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.07605

Collected Steps per Second: 9,262.98325
Overall Steps per Second: 7,951.85573

Timestep Collection Time: 5.40042
Timestep Consumption Time: 0.89044
PPO Batch Consumption Time: 0.04459
Total Iteration Time: 6.29086

Cumulative Model Updates: 43,570
Cumulative Timesteps: 726,782,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 726782180...
Checkpoint 726782180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,119.03516
Policy Entropy: 1.10800
Value Function Loss: 5.08096

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.06959

Collected Steps per Second: 9,939.50934
Overall Steps per Second: 8,396.80762

Timestep Collection Time: 5.03164
Timestep Consumption Time: 0.92444
PPO Batch Consumption Time: 0.04434
Total Iteration Time: 5.95607

Cumulative Model Updates: 43,573
Cumulative Timesteps: 726,832,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,369.62447
Policy Entropy: 1.11074
Value Function Loss: 5.20089

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.06982

Collected Steps per Second: 9,620.66512
Overall Steps per Second: 8,212.27759

Timestep Collection Time: 5.19964
Timestep Consumption Time: 0.89173
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 6.09137

Cumulative Model Updates: 43,576
Cumulative Timesteps: 726,882,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 726882216...
Checkpoint 726882216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,122.39904
Policy Entropy: 1.11347
Value Function Loss: 5.24241

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.06726

Collected Steps per Second: 9,476.68506
Overall Steps per Second: 8,274.48588

Timestep Collection Time: 5.27927
Timestep Consumption Time: 0.76702
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 6.04630

Cumulative Model Updates: 43,579
Cumulative Timesteps: 726,932,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,985.21625
Policy Entropy: 1.10340
Value Function Loss: 5.17908

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.06260
Value Function Update Magnitude: 0.08089

Collected Steps per Second: 9,738.19406
Overall Steps per Second: 8,307.52800

Timestep Collection Time: 5.13463
Timestep Consumption Time: 0.88425
PPO Batch Consumption Time: 0.05003
Total Iteration Time: 6.01888

Cumulative Model Updates: 43,582
Cumulative Timesteps: 726,982,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 726982248...
Checkpoint 726982248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,515.61035
Policy Entropy: 1.10862
Value Function Loss: 5.05264

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.09422

Collected Steps per Second: 9,488.48528
Overall Steps per Second: 8,185.54781

Timestep Collection Time: 5.27165
Timestep Consumption Time: 0.83912
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 6.11077

Cumulative Model Updates: 43,585
Cumulative Timesteps: 727,032,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,040.21945
Policy Entropy: 1.11185
Value Function Loss: 4.93590

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.09400

Collected Steps per Second: 9,938.41457
Overall Steps per Second: 8,498.57452

Timestep Collection Time: 5.03340
Timestep Consumption Time: 0.85277
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 5.88616

Cumulative Model Updates: 43,588
Cumulative Timesteps: 727,082,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 727082292...
Checkpoint 727082292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,505.60139
Policy Entropy: 1.12202
Value Function Loss: 4.86671

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.08719

Collected Steps per Second: 9,193.98571
Overall Steps per Second: 7,948.44941

Timestep Collection Time: 5.43834
Timestep Consumption Time: 0.85220
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 6.29054

Cumulative Model Updates: 43,591
Cumulative Timesteps: 727,132,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,874.77410
Policy Entropy: 1.12930
Value Function Loss: 5.01777

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.08652

Collected Steps per Second: 9,303.63796
Overall Steps per Second: 8,171.80574

Timestep Collection Time: 5.37424
Timestep Consumption Time: 0.74436
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 6.11860

Cumulative Model Updates: 43,594
Cumulative Timesteps: 727,182,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 727182292...
Checkpoint 727182292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,968.14120
Policy Entropy: 1.12766
Value Function Loss: 5.18363

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.08897

Collected Steps per Second: 9,792.17373
Overall Steps per Second: 8,425.03718

Timestep Collection Time: 5.10632
Timestep Consumption Time: 0.82861
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 5.93493

Cumulative Model Updates: 43,597
Cumulative Timesteps: 727,232,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,311.20226
Policy Entropy: 1.12874
Value Function Loss: 5.30679

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.06323
Value Function Update Magnitude: 0.09592

Collected Steps per Second: 9,301.71652
Overall Steps per Second: 8,018.73635

Timestep Collection Time: 5.37772
Timestep Consumption Time: 0.86042
PPO Batch Consumption Time: 0.04029
Total Iteration Time: 6.23814

Cumulative Model Updates: 43,600
Cumulative Timesteps: 727,282,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 727282316...
Checkpoint 727282316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,591.89046
Policy Entropy: 1.11488
Value Function Loss: 5.28799

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.09172

Collected Steps per Second: 9,787.22943
Overall Steps per Second: 8,337.29011

Timestep Collection Time: 5.10972
Timestep Consumption Time: 0.88863
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 5.99835

Cumulative Model Updates: 43,603
Cumulative Timesteps: 727,332,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,221.68306
Policy Entropy: 1.12351
Value Function Loss: 5.36028

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.08440

Collected Steps per Second: 9,435.35625
Overall Steps per Second: 8,155.00881

Timestep Collection Time: 5.30176
Timestep Consumption Time: 0.83238
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 6.13414

Cumulative Model Updates: 43,606
Cumulative Timesteps: 727,382,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 727382350...
Checkpoint 727382350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,038.02567
Policy Entropy: 1.12343
Value Function Loss: 5.26886

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.08281

Collected Steps per Second: 9,587.42373
Overall Steps per Second: 8,371.31411

Timestep Collection Time: 5.21683
Timestep Consumption Time: 0.75785
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 5.97469

Cumulative Model Updates: 43,609
Cumulative Timesteps: 727,432,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,279.05952
Policy Entropy: 1.12919
Value Function Loss: 5.28821

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.06228
Value Function Update Magnitude: 0.07518

Collected Steps per Second: 9,640.82508
Overall Steps per Second: 8,284.75718

Timestep Collection Time: 5.18628
Timestep Consumption Time: 0.84890
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.03518

Cumulative Model Updates: 43,612
Cumulative Timesteps: 727,482,366

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 727482366...
Checkpoint 727482366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,708.46642
Policy Entropy: 1.12241
Value Function Loss: 5.27891

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.06932

Collected Steps per Second: 9,186.10311
Overall Steps per Second: 8,063.54680

Timestep Collection Time: 5.44366
Timestep Consumption Time: 0.75783
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.20149

Cumulative Model Updates: 43,615
Cumulative Timesteps: 727,532,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405,905.88880
Policy Entropy: 1.12926
Value Function Loss: 5.23379

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.10239
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.06941

Collected Steps per Second: 9,658.00936
Overall Steps per Second: 8,292.90525

Timestep Collection Time: 5.17788
Timestep Consumption Time: 0.85234
PPO Batch Consumption Time: 0.04543
Total Iteration Time: 6.03021

Cumulative Model Updates: 43,618
Cumulative Timesteps: 727,582,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 727582380...
Checkpoint 727582380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,738.50294
Policy Entropy: 1.13473
Value Function Loss: 5.16425

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.08258

Collected Steps per Second: 9,792.54536
Overall Steps per Second: 8,413.13280

Timestep Collection Time: 5.10715
Timestep Consumption Time: 0.83737
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 5.94452

Cumulative Model Updates: 43,621
Cumulative Timesteps: 727,632,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,152.16791
Policy Entropy: 1.11688
Value Function Loss: 5.01136

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.08112

Collected Steps per Second: 9,967.35774
Overall Steps per Second: 8,427.69522

Timestep Collection Time: 5.01718
Timestep Consumption Time: 0.91659
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 5.93377

Cumulative Model Updates: 43,624
Cumulative Timesteps: 727,682,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 727682400...
Checkpoint 727682400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,423.80053
Policy Entropy: 1.11759
Value Function Loss: 5.09319

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 9,457.82553
Overall Steps per Second: 8,185.09127

Timestep Collection Time: 5.28811
Timestep Consumption Time: 0.82227
PPO Batch Consumption Time: 0.03937
Total Iteration Time: 6.11038

Cumulative Model Updates: 43,627
Cumulative Timesteps: 727,732,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,944.05108
Policy Entropy: 1.12530
Value Function Loss: 5.20786

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.06945

Collected Steps per Second: 9,441.53222
Overall Steps per Second: 8,127.16246

Timestep Collection Time: 5.29850
Timestep Consumption Time: 0.85690
PPO Batch Consumption Time: 0.04336
Total Iteration Time: 6.15541

Cumulative Model Updates: 43,630
Cumulative Timesteps: 727,782,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 727782440...
Checkpoint 727782440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,155.11453
Policy Entropy: 1.13525
Value Function Loss: 5.15734

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.10737
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.09082

Collected Steps per Second: 9,715.24325
Overall Steps per Second: 8,288.27285

Timestep Collection Time: 5.14943
Timestep Consumption Time: 0.88656
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 6.03600

Cumulative Model Updates: 43,633
Cumulative Timesteps: 727,832,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,924.60269
Policy Entropy: 1.11966
Value Function Loss: 5.11718

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 9,667.87020
Overall Steps per Second: 8,385.00897

Timestep Collection Time: 5.17239
Timestep Consumption Time: 0.79135
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 5.96374

Cumulative Model Updates: 43,636
Cumulative Timesteps: 727,882,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 727882474...
Checkpoint 727882474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,764.16071
Policy Entropy: 1.11913
Value Function Loss: 5.01482

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 9,471.52515
Overall Steps per Second: 8,113.72743

Timestep Collection Time: 5.27983
Timestep Consumption Time: 0.88356
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.16338

Cumulative Model Updates: 43,639
Cumulative Timesteps: 727,932,482

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,094.98508
Policy Entropy: 1.12675
Value Function Loss: 5.26404

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.07159

Collected Steps per Second: 9,736.00298
Overall Steps per Second: 8,368.82732

Timestep Collection Time: 5.13804
Timestep Consumption Time: 0.83938
PPO Batch Consumption Time: 0.04459
Total Iteration Time: 5.97742

Cumulative Model Updates: 43,642
Cumulative Timesteps: 727,982,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 727982506...
Checkpoint 727982506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,859.24451
Policy Entropy: 1.13365
Value Function Loss: 5.15315

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.10440

Collected Steps per Second: 9,761.91892
Overall Steps per Second: 8,361.17103

Timestep Collection Time: 5.12461
Timestep Consumption Time: 0.85853
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 5.98313

Cumulative Model Updates: 43,645
Cumulative Timesteps: 728,032,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,550.38025
Policy Entropy: 1.10547
Value Function Loss: 5.13563

Mean KL Divergence: 0.03079
SB3 Clip Fraction: 0.15100
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.10650

Collected Steps per Second: 10,061.76031
Overall Steps per Second: 8,623.58429

Timestep Collection Time: 4.97070
Timestep Consumption Time: 0.82898
PPO Batch Consumption Time: 0.04145
Total Iteration Time: 5.79968

Cumulative Model Updates: 43,648
Cumulative Timesteps: 728,082,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 728082546...
Checkpoint 728082546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,662.86210
Policy Entropy: 1.11404
Value Function Loss: 5.16011

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.09814

Collected Steps per Second: 9,591.73253
Overall Steps per Second: 8,357.76559

Timestep Collection Time: 5.21303
Timestep Consumption Time: 0.76967
PPO Batch Consumption Time: 0.04105
Total Iteration Time: 5.98270

Cumulative Model Updates: 43,651
Cumulative Timesteps: 728,132,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,738.79095
Policy Entropy: 1.11414
Value Function Loss: 5.32887

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.05971
Value Function Update Magnitude: 0.08458

Collected Steps per Second: 9,951.34603
Overall Steps per Second: 8,435.52052

Timestep Collection Time: 5.02465
Timestep Consumption Time: 0.90291
PPO Batch Consumption Time: 0.04927
Total Iteration Time: 5.92755

Cumulative Model Updates: 43,654
Cumulative Timesteps: 728,182,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 728182550...
Checkpoint 728182550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,228.62549
Policy Entropy: 1.11193
Value Function Loss: 5.35006

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.09063

Collected Steps per Second: 9,694.71966
Overall Steps per Second: 8,370.93455

Timestep Collection Time: 5.15807
Timestep Consumption Time: 0.81570
PPO Batch Consumption Time: 0.04145
Total Iteration Time: 5.97377

Cumulative Model Updates: 43,657
Cumulative Timesteps: 728,232,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,745.51186
Policy Entropy: 1.09120
Value Function Loss: 5.19294

Mean KL Divergence: 0.03414
SB3 Clip Fraction: 0.18208
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.08429

Collected Steps per Second: 9,639.69315
Overall Steps per Second: 8,232.99088

Timestep Collection Time: 5.18855
Timestep Consumption Time: 0.88652
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.07507

Cumulative Model Updates: 43,660
Cumulative Timesteps: 728,282,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 728282572...
Checkpoint 728282572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,049.53861
Policy Entropy: 1.12026
Value Function Loss: 5.14799

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.08203

Collected Steps per Second: 9,585.73434
Overall Steps per Second: 8,242.52929

Timestep Collection Time: 5.21817
Timestep Consumption Time: 0.85035
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.06853

Cumulative Model Updates: 43,663
Cumulative Timesteps: 728,332,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,521.94062
Policy Entropy: 1.10879
Value Function Loss: 5.18556

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 9,709.84919
Overall Steps per Second: 8,466.25197

Timestep Collection Time: 5.15085
Timestep Consumption Time: 0.75660
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 5.90745

Cumulative Model Updates: 43,666
Cumulative Timesteps: 728,382,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 728382606...
Checkpoint 728382606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,114.17985
Policy Entropy: 1.11274
Value Function Loss: 5.10827

Mean KL Divergence: 0.02788
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.06791

Collected Steps per Second: 9,580.28530
Overall Steps per Second: 8,228.21360

Timestep Collection Time: 5.21989
Timestep Consumption Time: 0.85774
PPO Batch Consumption Time: 0.04046
Total Iteration Time: 6.07763

Cumulative Model Updates: 43,669
Cumulative Timesteps: 728,432,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,587.38274
Policy Entropy: 1.12229
Value Function Loss: 5.06602

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.06790

Collected Steps per Second: 9,721.36983
Overall Steps per Second: 8,474.33036

Timestep Collection Time: 5.14598
Timestep Consumption Time: 0.75726
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 5.90324

Cumulative Model Updates: 43,672
Cumulative Timesteps: 728,482,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 728482640...
Checkpoint 728482640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,347.91941
Policy Entropy: 1.12930
Value Function Loss: 5.00204

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.08456

Collected Steps per Second: 9,165.76964
Overall Steps per Second: 7,942.23372

Timestep Collection Time: 5.45682
Timestep Consumption Time: 0.84065
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 6.29747

Cumulative Model Updates: 43,675
Cumulative Timesteps: 728,532,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,370.28859
Policy Entropy: 1.11578
Value Function Loss: 4.96051

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.11054

Collected Steps per Second: 9,652.32184
Overall Steps per Second: 8,290.28931

Timestep Collection Time: 5.18052
Timestep Consumption Time: 0.85112
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 6.03164

Cumulative Model Updates: 43,678
Cumulative Timesteps: 728,582,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 728582660...
Checkpoint 728582660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447,414.15879
Policy Entropy: 1.10559
Value Function Loss: 5.04911

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.10922

Collected Steps per Second: 9,485.20988
Overall Steps per Second: 8,294.49256

Timestep Collection Time: 5.27389
Timestep Consumption Time: 0.75709
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 6.03099

Cumulative Model Updates: 43,681
Cumulative Timesteps: 728,632,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,743.07057
Policy Entropy: 1.11635
Value Function Loss: 5.10281

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.11048

Collected Steps per Second: 9,752.96347
Overall Steps per Second: 8,362.23213

Timestep Collection Time: 5.12788
Timestep Consumption Time: 0.85282
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 5.98070

Cumulative Model Updates: 43,684
Cumulative Timesteps: 728,682,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 728682696...
Checkpoint 728682696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,147.47969
Policy Entropy: 1.11036
Value Function Loss: 5.35586

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.10372
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.09816

Collected Steps per Second: 9,504.92948
Overall Steps per Second: 8,212.61568

Timestep Collection Time: 5.26043
Timestep Consumption Time: 0.82777
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 6.08819

Cumulative Model Updates: 43,687
Cumulative Timesteps: 728,732,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,712.79863
Policy Entropy: 1.10978
Value Function Loss: 5.42242

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.06295
Value Function Update Magnitude: 0.07782

Collected Steps per Second: 9,249.23651
Overall Steps per Second: 7,882.69975

Timestep Collection Time: 5.40585
Timestep Consumption Time: 0.93715
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 6.34300

Cumulative Model Updates: 43,690
Cumulative Timesteps: 728,782,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 728782696...
Checkpoint 728782696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,061.22393
Policy Entropy: 1.10673
Value Function Loss: 5.46907

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.08488

Collected Steps per Second: 9,642.27086
Overall Steps per Second: 8,214.40112

Timestep Collection Time: 5.18799
Timestep Consumption Time: 0.90180
PPO Batch Consumption Time: 0.04324
Total Iteration Time: 6.08979

Cumulative Model Updates: 43,693
Cumulative Timesteps: 728,832,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453,522.78898
Policy Entropy: 1.11790
Value Function Loss: 5.38093

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.08450

Collected Steps per Second: 9,638.17754
Overall Steps per Second: 8,375.29311

Timestep Collection Time: 5.18936
Timestep Consumption Time: 0.78249
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 5.97185

Cumulative Model Updates: 43,696
Cumulative Timesteps: 728,882,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 728882736...
Checkpoint 728882736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,453.22515
Policy Entropy: 1.11870
Value Function Loss: 5.50163

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.08431

Collected Steps per Second: 9,625.90837
Overall Steps per Second: 8,229.18514

Timestep Collection Time: 5.19639
Timestep Consumption Time: 0.88197
PPO Batch Consumption Time: 0.04200
Total Iteration Time: 6.07837

Cumulative Model Updates: 43,699
Cumulative Timesteps: 728,932,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,833.93992
Policy Entropy: 1.10853
Value Function Loss: 5.37501

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.09896

Collected Steps per Second: 9,666.75246
Overall Steps per Second: 8,364.78081

Timestep Collection Time: 5.17589
Timestep Consumption Time: 0.80562
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 5.98151

Cumulative Model Updates: 43,702
Cumulative Timesteps: 728,982,790

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 728982790...
Checkpoint 728982790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,467.95864
Policy Entropy: 1.09685
Value Function Loss: 5.31708

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.16497
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.10447

Collected Steps per Second: 9,342.95754
Overall Steps per Second: 8,050.00414

Timestep Collection Time: 5.35377
Timestep Consumption Time: 0.85990
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 6.21366

Cumulative Model Updates: 43,705
Cumulative Timesteps: 729,032,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,655.67704
Policy Entropy: 1.11058
Value Function Loss: 5.30153

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.10641

Collected Steps per Second: 9,213.99411
Overall Steps per Second: 7,981.91065

Timestep Collection Time: 5.43000
Timestep Consumption Time: 0.83817
PPO Batch Consumption Time: 0.04069
Total Iteration Time: 6.26817

Cumulative Model Updates: 43,708
Cumulative Timesteps: 729,082,842

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 729082842...
Checkpoint 729082842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,763.80404
Policy Entropy: 1.11637
Value Function Loss: 5.26334

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 9,704.47315
Overall Steps per Second: 8,333.39955

Timestep Collection Time: 5.15474
Timestep Consumption Time: 0.84810
PPO Batch Consumption Time: 0.04432
Total Iteration Time: 6.00283

Cumulative Model Updates: 43,711
Cumulative Timesteps: 729,132,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,744.21749
Policy Entropy: 1.09211
Value Function Loss: 5.21772

Mean KL Divergence: 0.03490
SB3 Clip Fraction: 0.16689
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.10031

Collected Steps per Second: 9,545.13006
Overall Steps per Second: 8,199.07833

Timestep Collection Time: 5.23890
Timestep Consumption Time: 0.86008
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 6.09898

Cumulative Model Updates: 43,714
Cumulative Timesteps: 729,182,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 729182872...
Checkpoint 729182872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,696.24190
Policy Entropy: 1.10101
Value Function Loss: 4.84548

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.08675

Collected Steps per Second: 10,010.13642
Overall Steps per Second: 8,541.85258

Timestep Collection Time: 4.99674
Timestep Consumption Time: 0.85890
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 5.85564

Cumulative Model Updates: 43,717
Cumulative Timesteps: 729,232,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,548.97270
Policy Entropy: 1.10588
Value Function Loss: 4.97246

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.07764

Collected Steps per Second: 9,733.60992
Overall Steps per Second: 8,352.57437

Timestep Collection Time: 5.13787
Timestep Consumption Time: 0.84951
PPO Batch Consumption Time: 0.03975
Total Iteration Time: 5.98738

Cumulative Model Updates: 43,720
Cumulative Timesteps: 729,282,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 729282900...
Checkpoint 729282900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624,913.53951
Policy Entropy: 1.09205
Value Function Loss: 5.08298

Mean KL Divergence: 0.02600
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.07731

Collected Steps per Second: 9,677.65322
Overall Steps per Second: 8,175.00297

Timestep Collection Time: 5.16985
Timestep Consumption Time: 0.95027
PPO Batch Consumption Time: 0.04662
Total Iteration Time: 6.12012

Cumulative Model Updates: 43,723
Cumulative Timesteps: 729,332,932

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,956.39143
Policy Entropy: 1.09063
Value Function Loss: 5.24481

Mean KL Divergence: 0.02834
SB3 Clip Fraction: 0.15986
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 9,641.00241
Overall Steps per Second: 8,262.21735

Timestep Collection Time: 5.18701
Timestep Consumption Time: 0.86560
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 6.05261

Cumulative Model Updates: 43,726
Cumulative Timesteps: 729,382,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 729382940...
Checkpoint 729382940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,873.10791
Policy Entropy: 1.09497
Value Function Loss: 5.50086

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.05977

Collected Steps per Second: 9,874.69714
Overall Steps per Second: 8,628.97862

Timestep Collection Time: 5.06648
Timestep Consumption Time: 0.73142
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 5.79791

Cumulative Model Updates: 43,729
Cumulative Timesteps: 729,432,970

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,921.62414
Policy Entropy: 1.10512
Value Function Loss: 5.25493

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.14475
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.05361

Collected Steps per Second: 9,523.94028
Overall Steps per Second: 8,000.36675

Timestep Collection Time: 5.25161
Timestep Consumption Time: 1.00011
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 6.25171

Cumulative Model Updates: 43,732
Cumulative Timesteps: 729,482,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 729482986...
Checkpoint 729482986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,450.68355
Policy Entropy: 1.08294
Value Function Loss: 5.30977

Mean KL Divergence: 0.02617
SB3 Clip Fraction: 0.16396
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 9,684.92874
Overall Steps per Second: 8,352.31281

Timestep Collection Time: 5.16596
Timestep Consumption Time: 0.82423
PPO Batch Consumption Time: 0.04440
Total Iteration Time: 5.99020

Cumulative Model Updates: 43,735
Cumulative Timesteps: 729,533,018

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420,681.43695
Policy Entropy: 1.10410
Value Function Loss: 5.30199

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.15847
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.05627

Collected Steps per Second: 10,259.79730
Overall Steps per Second: 8,767.98439

Timestep Collection Time: 4.87378
Timestep Consumption Time: 0.82924
PPO Batch Consumption Time: 0.04000
Total Iteration Time: 5.70302

Cumulative Model Updates: 43,738
Cumulative Timesteps: 729,583,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 729583022...
Checkpoint 729583022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440,215.56288
Policy Entropy: 1.10156
Value Function Loss: 5.42475

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.05770

Collected Steps per Second: 9,713.88533
Overall Steps per Second: 8,271.85945

Timestep Collection Time: 5.14892
Timestep Consumption Time: 0.89761
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 6.04652

Cumulative Model Updates: 43,741
Cumulative Timesteps: 729,633,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,538.42722
Policy Entropy: 1.09727
Value Function Loss: 5.50929

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.06219

Collected Steps per Second: 10,429.07991
Overall Steps per Second: 8,892.97960

Timestep Collection Time: 4.79620
Timestep Consumption Time: 0.82846
PPO Batch Consumption Time: 0.03959
Total Iteration Time: 5.62466

Cumulative Model Updates: 43,744
Cumulative Timesteps: 729,683,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 729683058...
Checkpoint 729683058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,146.96842
Policy Entropy: 1.08672
Value Function Loss: 5.19401

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.08125

Collected Steps per Second: 9,846.34678
Overall Steps per Second: 8,333.77730

Timestep Collection Time: 5.07904
Timestep Consumption Time: 0.92184
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 6.00088

Cumulative Model Updates: 43,747
Cumulative Timesteps: 729,733,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,403.80519
Policy Entropy: 1.10165
Value Function Loss: 5.28994

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.09269

Collected Steps per Second: 9,814.37015
Overall Steps per Second: 8,255.76234

Timestep Collection Time: 5.09498
Timestep Consumption Time: 0.96188
PPO Batch Consumption Time: 0.04351
Total Iteration Time: 6.05686

Cumulative Model Updates: 43,750
Cumulative Timesteps: 729,783,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 729783072...
Checkpoint 729783072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,977.14388
Policy Entropy: 1.10892
Value Function Loss: 4.99358

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.08995

Collected Steps per Second: 10,103.86573
Overall Steps per Second: 8,647.93842

Timestep Collection Time: 4.95177
Timestep Consumption Time: 0.83366
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 5.78543

Cumulative Model Updates: 43,753
Cumulative Timesteps: 729,833,104

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,511.49250
Policy Entropy: 1.09365
Value Function Loss: 4.80973

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.08403

Collected Steps per Second: 10,050.94105
Overall Steps per Second: 8,780.62630

Timestep Collection Time: 4.97565
Timestep Consumption Time: 0.71984
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 5.69549

Cumulative Model Updates: 43,756
Cumulative Timesteps: 729,883,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 729883114...
Checkpoint 729883114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,276.23482
Policy Entropy: 1.09878
Value Function Loss: 4.61173

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.07044

Collected Steps per Second: 10,178.64637
Overall Steps per Second: 8,697.80070

Timestep Collection Time: 4.91480
Timestep Consumption Time: 0.83677
PPO Batch Consumption Time: 0.04042
Total Iteration Time: 5.75157

Cumulative Model Updates: 43,759
Cumulative Timesteps: 729,933,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,311.34066
Policy Entropy: 1.10295
Value Function Loss: 4.92982

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.05762

Collected Steps per Second: 10,362.41811
Overall Steps per Second: 8,988.46106

Timestep Collection Time: 4.82513
Timestep Consumption Time: 0.73756
PPO Batch Consumption Time: 0.03816
Total Iteration Time: 5.56269

Cumulative Model Updates: 43,762
Cumulative Timesteps: 729,983,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 729983140...
Checkpoint 729983140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,716.68478
Policy Entropy: 1.10394
Value Function Loss: 5.45621

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.05826

Collected Steps per Second: 10,180.25025
Overall Steps per Second: 8,651.43167

Timestep Collection Time: 4.91442
Timestep Consumption Time: 0.86844
PPO Batch Consumption Time: 0.04160
Total Iteration Time: 5.78286

Cumulative Model Updates: 43,765
Cumulative Timesteps: 730,033,170

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,812.89053
Policy Entropy: 1.11198
Value Function Loss: 5.47457

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.07270

Collected Steps per Second: 10,686.12901
Overall Steps per Second: 9,154.88214

Timestep Collection Time: 4.68027
Timestep Consumption Time: 0.78282
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.46310

Cumulative Model Updates: 43,768
Cumulative Timesteps: 730,083,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 730083184...
Checkpoint 730083184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,827.63032
Policy Entropy: 1.09766
Value Function Loss: 5.39213

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.09003

Collected Steps per Second: 10,972.24040
Overall Steps per Second: 9,202.33107

Timestep Collection Time: 4.55841
Timestep Consumption Time: 0.87673
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 5.43514

Cumulative Model Updates: 43,771
Cumulative Timesteps: 730,133,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,039.54354
Policy Entropy: 1.09032
Value Function Loss: 5.35704

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.08431

Collected Steps per Second: 10,706.32633
Overall Steps per Second: 9,109.81295

Timestep Collection Time: 4.67014
Timestep Consumption Time: 0.81845
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.48859

Cumulative Model Updates: 43,774
Cumulative Timesteps: 730,183,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 730183200...
Checkpoint 730183200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,612.83665
Policy Entropy: 1.09601
Value Function Loss: 5.53135

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.08052

Collected Steps per Second: 10,768.56105
Overall Steps per Second: 9,302.24463

Timestep Collection Time: 4.64537
Timestep Consumption Time: 0.73225
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.37763

Cumulative Model Updates: 43,777
Cumulative Timesteps: 730,233,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,219.58610
Policy Entropy: 1.09841
Value Function Loss: 5.43048

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.04528
Value Function Update Magnitude: 0.07648

Collected Steps per Second: 10,257.10333
Overall Steps per Second: 8,754.70430

Timestep Collection Time: 4.87760
Timestep Consumption Time: 0.83705
PPO Batch Consumption Time: 0.04023
Total Iteration Time: 5.71464

Cumulative Model Updates: 43,780
Cumulative Timesteps: 730,283,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 730283254...
Checkpoint 730283254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,148.15463
Policy Entropy: 1.08085
Value Function Loss: 5.07176

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.07086

Collected Steps per Second: 10,252.71897
Overall Steps per Second: 8,778.34556

Timestep Collection Time: 4.87968
Timestep Consumption Time: 0.81957
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 5.69925

Cumulative Model Updates: 43,783
Cumulative Timesteps: 730,333,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445,421.14654
Policy Entropy: 1.09389
Value Function Loss: 4.91093

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.15183
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.06624

Collected Steps per Second: 10,069.50074
Overall Steps per Second: 8,793.57473

Timestep Collection Time: 4.96569
Timestep Consumption Time: 0.72051
PPO Batch Consumption Time: 0.04032
Total Iteration Time: 5.68620

Cumulative Model Updates: 43,786
Cumulative Timesteps: 730,383,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 730383286...
Checkpoint 730383286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,380.61311
Policy Entropy: 1.09260
Value Function Loss: 4.82061

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.06006

Collected Steps per Second: 10,251.11460
Overall Steps per Second: 8,744.51123

Timestep Collection Time: 4.87927
Timestep Consumption Time: 0.84066
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 5.71993

Cumulative Model Updates: 43,789
Cumulative Timesteps: 730,433,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,079.07978
Policy Entropy: 1.09217
Value Function Loss: 4.90627

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.06425

Collected Steps per Second: 10,240.88774
Overall Steps per Second: 8,955.01682

Timestep Collection Time: 4.88376
Timestep Consumption Time: 0.70127
PPO Batch Consumption Time: 0.03801
Total Iteration Time: 5.58503

Cumulative Model Updates: 43,792
Cumulative Timesteps: 730,483,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 730483318...
Checkpoint 730483318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,767.72202
Policy Entropy: 1.08628
Value Function Loss: 4.98062

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.06284

Collected Steps per Second: 10,464.58397
Overall Steps per Second: 8,746.54911

Timestep Collection Time: 4.77974
Timestep Consumption Time: 0.93886
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 5.71860

Cumulative Model Updates: 43,795
Cumulative Timesteps: 730,533,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,881.66272
Policy Entropy: 1.08626
Value Function Loss: 5.16270

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 10,327.66692
Overall Steps per Second: 8,864.92521

Timestep Collection Time: 4.84349
Timestep Consumption Time: 0.79919
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.64269

Cumulative Model Updates: 43,798
Cumulative Timesteps: 730,583,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 730583358...
Checkpoint 730583358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,125.70708
Policy Entropy: 1.11166
Value Function Loss: 5.14741

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.07142

Collected Steps per Second: 10,299.07850
Overall Steps per Second: 8,900.43251

Timestep Collection Time: 4.85655
Timestep Consumption Time: 0.76318
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 5.61973

Cumulative Model Updates: 43,801
Cumulative Timesteps: 730,633,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,303.13769
Policy Entropy: 1.10387
Value Function Loss: 5.12205

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.07869

Collected Steps per Second: 10,057.99658
Overall Steps per Second: 8,531.95916

Timestep Collection Time: 4.97236
Timestep Consumption Time: 0.88936
PPO Batch Consumption Time: 0.04747
Total Iteration Time: 5.86173

Cumulative Model Updates: 43,804
Cumulative Timesteps: 730,683,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 730683388...
Checkpoint 730683388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,494.45244
Policy Entropy: 1.11323
Value Function Loss: 5.27730

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.06234
Value Function Update Magnitude: 0.07751

Collected Steps per Second: 10,405.54626
Overall Steps per Second: 8,891.96144

Timestep Collection Time: 4.80667
Timestep Consumption Time: 0.81819
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 5.62486

Cumulative Model Updates: 43,807
Cumulative Timesteps: 730,733,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,503.91455
Policy Entropy: 1.11454
Value Function Loss: 5.42341

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.07706
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 10,136.27063
Overall Steps per Second: 8,664.97577

Timestep Collection Time: 4.93298
Timestep Consumption Time: 0.83761
PPO Batch Consumption Time: 0.03847
Total Iteration Time: 5.77059

Cumulative Model Updates: 43,810
Cumulative Timesteps: 730,783,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 730783406...
Checkpoint 730783406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,385.92319
Policy Entropy: 1.11676
Value Function Loss: 5.38686

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.06913
Value Function Update Magnitude: 0.10615

Collected Steps per Second: 9,890.29000
Overall Steps per Second: 8,411.86462

Timestep Collection Time: 5.05668
Timestep Consumption Time: 0.88874
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.94541

Cumulative Model Updates: 43,813
Cumulative Timesteps: 730,833,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,872.00838
Policy Entropy: 1.10844
Value Function Loss: 5.27925

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 10,181.88906
Overall Steps per Second: 8,918.19972

Timestep Collection Time: 4.91068
Timestep Consumption Time: 0.69583
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.60651

Cumulative Model Updates: 43,816
Cumulative Timesteps: 730,883,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 730883418...
Checkpoint 730883418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,474.14775
Policy Entropy: 1.12044
Value Function Loss: 5.07336

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.10249

Collected Steps per Second: 10,375.27767
Overall Steps per Second: 8,754.38244

Timestep Collection Time: 4.81934
Timestep Consumption Time: 0.89231
PPO Batch Consumption Time: 0.04255
Total Iteration Time: 5.71165

Cumulative Model Updates: 43,819
Cumulative Timesteps: 730,933,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,221.70006
Policy Entropy: 1.12058
Value Function Loss: 5.10927

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.08698

Collected Steps per Second: 10,397.35447
Overall Steps per Second: 8,924.79871

Timestep Collection Time: 4.81065
Timestep Consumption Time: 0.79374
PPO Batch Consumption Time: 0.03884
Total Iteration Time: 5.60438

Cumulative Model Updates: 43,822
Cumulative Timesteps: 730,983,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 730983438...
Checkpoint 730983438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,769.32103
Policy Entropy: 1.11297
Value Function Loss: 4.83093

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.07640

Collected Steps per Second: 10,567.44335
Overall Steps per Second: 8,948.66898

Timestep Collection Time: 4.73303
Timestep Consumption Time: 0.85618
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.58921

Cumulative Model Updates: 43,825
Cumulative Timesteps: 731,033,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,853.27209
Policy Entropy: 1.10955
Value Function Loss: 4.94783

Mean KL Divergence: 0.02536
SB3 Clip Fraction: 0.15073
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.07574

Collected Steps per Second: 10,036.79811
Overall Steps per Second: 8,644.41827

Timestep Collection Time: 4.98227
Timestep Consumption Time: 0.80251
PPO Batch Consumption Time: 0.03874
Total Iteration Time: 5.78477

Cumulative Model Updates: 43,828
Cumulative Timesteps: 731,083,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 731083460...
Checkpoint 731083460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,931.11578
Policy Entropy: 1.11717
Value Function Loss: 4.93489

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.09253

Collected Steps per Second: 10,391.45173
Overall Steps per Second: 9,069.55824

Timestep Collection Time: 4.81299
Timestep Consumption Time: 0.70150
PPO Batch Consumption Time: 0.03887
Total Iteration Time: 5.51449

Cumulative Model Updates: 43,831
Cumulative Timesteps: 731,133,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,176.32895
Policy Entropy: 1.12283
Value Function Loss: 5.06531

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.09476

Collected Steps per Second: 10,193.09290
Overall Steps per Second: 8,785.81493

Timestep Collection Time: 4.90567
Timestep Consumption Time: 0.78577
PPO Batch Consumption Time: 0.03876
Total Iteration Time: 5.69145

Cumulative Model Updates: 43,834
Cumulative Timesteps: 731,183,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 731183478...
Checkpoint 731183478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,129.93280
Policy Entropy: 1.10093
Value Function Loss: 4.96879

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.08364

Collected Steps per Second: 10,218.96095
Overall Steps per Second: 8,790.31103

Timestep Collection Time: 4.89482
Timestep Consumption Time: 0.79553
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.69036

Cumulative Model Updates: 43,837
Cumulative Timesteps: 731,233,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,208.22772
Policy Entropy: 1.11484
Value Function Loss: 4.88850

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.08045

Collected Steps per Second: 10,649.47578
Overall Steps per Second: 9,061.65570

Timestep Collection Time: 4.69619
Timestep Consumption Time: 0.82289
PPO Batch Consumption Time: 0.04420
Total Iteration Time: 5.51908

Cumulative Model Updates: 43,840
Cumulative Timesteps: 731,283,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 731283510...
Checkpoint 731283510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,271.26931
Policy Entropy: 1.11312
Value Function Loss: 4.84684

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.08923

Collected Steps per Second: 9,996.64786
Overall Steps per Second: 8,569.11756

Timestep Collection Time: 5.00308
Timestep Consumption Time: 0.83346
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 5.83654

Cumulative Model Updates: 43,843
Cumulative Timesteps: 731,333,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,723.51928
Policy Entropy: 1.09980
Value Function Loss: 5.04931

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.08159

Collected Steps per Second: 10,332.18004
Overall Steps per Second: 8,972.47056

Timestep Collection Time: 4.84041
Timestep Consumption Time: 0.73353
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 5.57394

Cumulative Model Updates: 43,846
Cumulative Timesteps: 731,383,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 731383536...
Checkpoint 731383536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,112.56244
Policy Entropy: 1.07492
Value Function Loss: 4.93794

Mean KL Divergence: 0.03551
SB3 Clip Fraction: 0.18634
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.07711

Collected Steps per Second: 10,303.84473
Overall Steps per Second: 8,766.60437

Timestep Collection Time: 4.85314
Timestep Consumption Time: 0.85101
PPO Batch Consumption Time: 0.03933
Total Iteration Time: 5.70415

Cumulative Model Updates: 43,849
Cumulative Timesteps: 731,433,542

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,442.14789
Policy Entropy: 1.10400
Value Function Loss: 4.82213

Mean KL Divergence: 0.03127
SB3 Clip Fraction: 0.17209
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.06900

Collected Steps per Second: 10,349.40958
Overall Steps per Second: 8,810.15569

Timestep Collection Time: 4.83293
Timestep Consumption Time: 0.84438
PPO Batch Consumption Time: 0.03900
Total Iteration Time: 5.67731

Cumulative Model Updates: 43,852
Cumulative Timesteps: 731,483,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 731483560...
Checkpoint 731483560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,889.10026
Policy Entropy: 1.07221
Value Function Loss: 4.72190

Mean KL Divergence: 0.06160
SB3 Clip Fraction: 0.22712
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.06596

Collected Steps per Second: 10,279.84906
Overall Steps per Second: 8,911.48619

Timestep Collection Time: 4.86583
Timestep Consumption Time: 0.74715
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 5.61298

Cumulative Model Updates: 43,855
Cumulative Timesteps: 731,533,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403,699.29926
Policy Entropy: 1.11028
Value Function Loss: 5.04060

Mean KL Divergence: 0.04093
SB3 Clip Fraction: 0.20078
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.06892

Collected Steps per Second: 10,426.64409
Overall Steps per Second: 8,824.25470

Timestep Collection Time: 4.79656
Timestep Consumption Time: 0.87100
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 5.66756

Cumulative Model Updates: 43,858
Cumulative Timesteps: 731,583,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 731583592...
Checkpoint 731583592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,822.44474
Policy Entropy: 1.09255
Value Function Loss: 5.21822

Mean KL Divergence: 0.04462
SB3 Clip Fraction: 0.20291
Policy Update Magnitude: 0.04394
Value Function Update Magnitude: 0.07309

Collected Steps per Second: 10,161.04971
Overall Steps per Second: 8,742.50644

Timestep Collection Time: 4.92115
Timestep Consumption Time: 0.79850
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 5.71964

Cumulative Model Updates: 43,861
Cumulative Timesteps: 731,633,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,244.63634
Policy Entropy: 1.11739
Value Function Loss: 5.11038

Mean KL Divergence: 0.03498
SB3 Clip Fraction: 0.18486
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 10,427.22656
Overall Steps per Second: 8,906.22001

Timestep Collection Time: 4.79763
Timestep Consumption Time: 0.81934
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.61697

Cumulative Model Updates: 43,864
Cumulative Timesteps: 731,683,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 731683622...
Checkpoint 731683622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,954.87413
Policy Entropy: 1.08798
Value Function Loss: 5.03845

Mean KL Divergence: 0.03404
SB3 Clip Fraction: 0.19127
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.07448

Collected Steps per Second: 10,529.27353
Overall Steps per Second: 8,907.18622

Timestep Collection Time: 4.75114
Timestep Consumption Time: 0.86523
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.61636

Cumulative Model Updates: 43,867
Cumulative Timesteps: 731,733,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,304.77810
Policy Entropy: 1.10455
Value Function Loss: 5.03072

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.14116
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 10,339.71165
Overall Steps per Second: 9,001.53349

Timestep Collection Time: 4.83843
Timestep Consumption Time: 0.71929
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 5.55772

Cumulative Model Updates: 43,870
Cumulative Timesteps: 731,783,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 731783676...
Checkpoint 731783676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,400.40586
Policy Entropy: 1.11030
Value Function Loss: 5.15963

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.07048

Collected Steps per Second: 10,301.25763
Overall Steps per Second: 8,745.93933

Timestep Collection Time: 4.85649
Timestep Consumption Time: 0.86365
PPO Batch Consumption Time: 0.03858
Total Iteration Time: 5.72014

Cumulative Model Updates: 43,873
Cumulative Timesteps: 731,833,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,151.77839
Policy Entropy: 1.09727
Value Function Loss: 5.10376

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.07434

Collected Steps per Second: 9,938.94249
Overall Steps per Second: 8,512.17789

Timestep Collection Time: 5.03353
Timestep Consumption Time: 0.84369
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 5.87723

Cumulative Model Updates: 43,876
Cumulative Timesteps: 731,883,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 731883732...
Checkpoint 731883732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,583.10898
Policy Entropy: 1.09093
Value Function Loss: 4.95719

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.16729
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.07156

Collected Steps per Second: 9,929.19171
Overall Steps per Second: 8,676.50640

Timestep Collection Time: 5.03626
Timestep Consumption Time: 0.72712
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.76338

Cumulative Model Updates: 43,879
Cumulative Timesteps: 731,933,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,122.50101
Policy Entropy: 1.10134
Value Function Loss: 5.01163

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12073
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 10,179.20671
Overall Steps per Second: 8,647.94143

Timestep Collection Time: 4.91315
Timestep Consumption Time: 0.86996
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.78311

Cumulative Model Updates: 43,882
Cumulative Timesteps: 731,983,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 731983750...
Checkpoint 731983750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,540.87476
Policy Entropy: 1.10794
Value Function Loss: 5.03673

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.08144

Collected Steps per Second: 10,138.18887
Overall Steps per Second: 8,638.28968

Timestep Collection Time: 4.93382
Timestep Consumption Time: 0.85668
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 5.79050

Cumulative Model Updates: 43,885
Cumulative Timesteps: 732,033,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,968.04487
Policy Entropy: 1.07242
Value Function Loss: 5.19524

Mean KL Divergence: 0.04203
SB3 Clip Fraction: 0.18697
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.07436

Collected Steps per Second: 10,428.80077
Overall Steps per Second: 8,883.85494

Timestep Collection Time: 4.79614
Timestep Consumption Time: 0.83407
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 5.63021

Cumulative Model Updates: 43,888
Cumulative Timesteps: 732,083,788

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 732083788...
Checkpoint 732083788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,697.19736
Policy Entropy: 1.09208
Value Function Loss: 5.04097

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 9,944.67887
Overall Steps per Second: 8,539.10938

Timestep Collection Time: 5.03043
Timestep Consumption Time: 0.82803
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 5.85846

Cumulative Model Updates: 43,891
Cumulative Timesteps: 732,133,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,229.10696
Policy Entropy: 1.08677
Value Function Loss: 4.87279

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.09414

Collected Steps per Second: 10,720.68693
Overall Steps per Second: 9,221.70573

Timestep Collection Time: 4.66575
Timestep Consumption Time: 0.75841
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.42416

Cumulative Model Updates: 43,894
Cumulative Timesteps: 732,183,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 732183834...
Checkpoint 732183834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,716.77353
Policy Entropy: 1.09202
Value Function Loss: 4.78779

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.11471
Policy Update Magnitude: 0.07237
Value Function Update Magnitude: 0.09140

Collected Steps per Second: 10,414.59691
Overall Steps per Second: 8,831.83207

Timestep Collection Time: 4.80230
Timestep Consumption Time: 0.86063
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.66292

Cumulative Model Updates: 43,897
Cumulative Timesteps: 732,233,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,809.37754
Policy Entropy: 1.09250
Value Function Loss: 4.73084

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.06884
Value Function Update Magnitude: 0.08885

Collected Steps per Second: 10,153.32293
Overall Steps per Second: 8,695.31725

Timestep Collection Time: 4.92725
Timestep Consumption Time: 0.82619
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 5.75344

Cumulative Model Updates: 43,900
Cumulative Timesteps: 732,283,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 732283876...
Checkpoint 732283876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,910.48447
Policy Entropy: 1.09184
Value Function Loss: 4.68765

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.09710

Collected Steps per Second: 10,875.57652
Overall Steps per Second: 9,245.54549

Timestep Collection Time: 4.59985
Timestep Consumption Time: 0.81097
PPO Batch Consumption Time: 0.03897
Total Iteration Time: 5.41082

Cumulative Model Updates: 43,903
Cumulative Timesteps: 732,333,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,308.86984
Policy Entropy: 1.09098
Value Function Loss: 4.78486

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.06775
Value Function Update Magnitude: 0.08917

Collected Steps per Second: 10,578.62306
Overall Steps per Second: 8,903.49946

Timestep Collection Time: 4.72821
Timestep Consumption Time: 0.88958
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.61779

Cumulative Model Updates: 43,906
Cumulative Timesteps: 732,383,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 732383920...
Checkpoint 732383920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,016.67871
Policy Entropy: 1.09580
Value Function Loss: 4.97210

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.07522
Value Function Update Magnitude: 0.07703

Collected Steps per Second: 10,276.34769
Overall Steps per Second: 8,846.73531

Timestep Collection Time: 4.86846
Timestep Consumption Time: 0.78673
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 5.65519

Cumulative Model Updates: 43,909
Cumulative Timesteps: 732,433,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,690.49990
Policy Entropy: 1.09026
Value Function Loss: 5.00545

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.08522
Value Function Update Magnitude: 0.06903

Collected Steps per Second: 10,088.25569
Overall Steps per Second: 8,653.90307

Timestep Collection Time: 4.95665
Timestep Consumption Time: 0.82155
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 5.77820

Cumulative Model Updates: 43,912
Cumulative Timesteps: 732,483,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 732483954...
Checkpoint 732483954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,313.81690
Policy Entropy: 1.08853
Value Function Loss: 4.94424

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.07786
Value Function Update Magnitude: 0.07180

Collected Steps per Second: 10,218.54591
Overall Steps per Second: 8,734.69124

Timestep Collection Time: 4.89580
Timestep Consumption Time: 0.83170
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 5.72751

Cumulative Model Updates: 43,915
Cumulative Timesteps: 732,533,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,377.98678
Policy Entropy: 1.10557
Value Function Loss: 4.74049

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.06538
Value Function Update Magnitude: 0.06808

Collected Steps per Second: 9,359.52753
Overall Steps per Second: 8,063.10405

Timestep Collection Time: 5.34365
Timestep Consumption Time: 0.85918
PPO Batch Consumption Time: 0.04461
Total Iteration Time: 6.20282

Cumulative Model Updates: 43,918
Cumulative Timesteps: 732,583,996

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 732583996...
Checkpoint 732583996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,935.41489
Policy Entropy: 1.10760
Value Function Loss: 4.62972

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.07709

Collected Steps per Second: 9,570.84823
Overall Steps per Second: 8,094.15721

Timestep Collection Time: 5.22650
Timestep Consumption Time: 0.95352
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 6.18001

Cumulative Model Updates: 43,921
Cumulative Timesteps: 732,634,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437,770.12812
Policy Entropy: 1.10018
Value Function Loss: 4.77422

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.11968
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.08289

Collected Steps per Second: 9,565.22125
Overall Steps per Second: 8,355.24443

Timestep Collection Time: 5.22999
Timestep Consumption Time: 0.75739
PPO Batch Consumption Time: 0.05056
Total Iteration Time: 5.98738

Cumulative Model Updates: 43,924
Cumulative Timesteps: 732,684,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 732684044...
Checkpoint 732684044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,166.29056
Policy Entropy: 1.09173
Value Function Loss: 4.85434

Mean KL Divergence: 0.02638
SB3 Clip Fraction: 0.15270
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.07684

Collected Steps per Second: 9,612.69324
Overall Steps per Second: 8,165.50045

Timestep Collection Time: 5.20395
Timestep Consumption Time: 0.92231
PPO Batch Consumption Time: 0.04961
Total Iteration Time: 6.12626

Cumulative Model Updates: 43,927
Cumulative Timesteps: 732,734,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,658.43568
Policy Entropy: 1.10052
Value Function Loss: 5.03650

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.07171

Collected Steps per Second: 9,212.13136
Overall Steps per Second: 7,850.86349

Timestep Collection Time: 5.42763
Timestep Consumption Time: 0.94110
PPO Batch Consumption Time: 0.04905
Total Iteration Time: 6.36873

Cumulative Model Updates: 43,930
Cumulative Timesteps: 732,784,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 732784068...
Checkpoint 732784068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,928.73213
Policy Entropy: 1.10899
Value Function Loss: 4.93915

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.08276

Collected Steps per Second: 9,649.85977
Overall Steps per Second: 8,303.22523

Timestep Collection Time: 5.18308
Timestep Consumption Time: 0.84060
PPO Batch Consumption Time: 0.04602
Total Iteration Time: 6.02368

Cumulative Model Updates: 43,933
Cumulative Timesteps: 732,834,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,620.77002
Policy Entropy: 1.09537
Value Function Loss: 4.99915

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.09042

Collected Steps per Second: 9,324.71022
Overall Steps per Second: 7,958.90299

Timestep Collection Time: 5.36510
Timestep Consumption Time: 0.92069
PPO Batch Consumption Time: 0.04615
Total Iteration Time: 6.28579

Cumulative Model Updates: 43,936
Cumulative Timesteps: 732,884,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 732884112...
Checkpoint 732884112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,461.69556
Policy Entropy: 1.10780
Value Function Loss: 5.25095

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.08792

Collected Steps per Second: 9,589.77426
Overall Steps per Second: 8,300.10038

Timestep Collection Time: 5.21514
Timestep Consumption Time: 0.81033
PPO Batch Consumption Time: 0.04657
Total Iteration Time: 6.02547

Cumulative Model Updates: 43,939
Cumulative Timesteps: 732,934,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,591.91711
Policy Entropy: 1.11031
Value Function Loss: 5.38228

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.08227

Collected Steps per Second: 9,728.70722
Overall Steps per Second: 8,343.16982

Timestep Collection Time: 5.14210
Timestep Consumption Time: 0.85394
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 5.99604

Cumulative Model Updates: 43,942
Cumulative Timesteps: 732,984,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 732984150...
Checkpoint 732984150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,433.22767
Policy Entropy: 1.09071
Value Function Loss: 5.54553

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.08400

Collected Steps per Second: 9,421.35543
Overall Steps per Second: 8,193.95161

Timestep Collection Time: 5.30837
Timestep Consumption Time: 0.79516
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.10353

Cumulative Model Updates: 43,945
Cumulative Timesteps: 733,034,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,556.80365
Policy Entropy: 1.08870
Value Function Loss: 5.39575

Mean KL Divergence: 0.02622
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.08895

Collected Steps per Second: 9,457.80180
Overall Steps per Second: 8,082.75952

Timestep Collection Time: 5.28854
Timestep Consumption Time: 0.89969
PPO Batch Consumption Time: 0.04474
Total Iteration Time: 6.18823

Cumulative Model Updates: 43,948
Cumulative Timesteps: 733,084,180

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 733084180...
Checkpoint 733084180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,468.78667
Policy Entropy: 1.09580
Value Function Loss: 5.39356

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.08362

Collected Steps per Second: 9,196.93053
Overall Steps per Second: 7,960.65508

Timestep Collection Time: 5.43877
Timestep Consumption Time: 0.84463
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 6.28340

Cumulative Model Updates: 43,951
Cumulative Timesteps: 733,134,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,056.67766
Policy Entropy: 1.10184
Value Function Loss: 5.36577

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.08093

Collected Steps per Second: 9,907.03072
Overall Steps per Second: 8,394.82119

Timestep Collection Time: 5.04833
Timestep Consumption Time: 0.90939
PPO Batch Consumption Time: 0.04946
Total Iteration Time: 5.95772

Cumulative Model Updates: 43,954
Cumulative Timesteps: 733,184,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 733184214...
Checkpoint 733184214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,997.72013
Policy Entropy: 1.08837
Value Function Loss: 5.33871

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.07094

Collected Steps per Second: 9,705.21755
Overall Steps per Second: 8,393.01951

Timestep Collection Time: 5.15372
Timestep Consumption Time: 0.80575
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 5.95948

Cumulative Model Updates: 43,957
Cumulative Timesteps: 733,234,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,126.03868
Policy Entropy: 1.07373
Value Function Loss: 5.32184

Mean KL Divergence: 0.04066
SB3 Clip Fraction: 0.16945
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.06425

Collected Steps per Second: 8,910.33893
Overall Steps per Second: 7,805.09095

Timestep Collection Time: 5.61483
Timestep Consumption Time: 0.79509
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 6.40992

Cumulative Model Updates: 43,960
Cumulative Timesteps: 733,284,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 733284262...
Checkpoint 733284262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,313.48620
Policy Entropy: 1.09679
Value Function Loss: 5.28100

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.14787
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.05808

Collected Steps per Second: 9,567.15675
Overall Steps per Second: 8,250.33835

Timestep Collection Time: 5.22747
Timestep Consumption Time: 0.83434
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 6.06181

Cumulative Model Updates: 43,963
Cumulative Timesteps: 733,334,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,645.51457
Policy Entropy: 1.07573
Value Function Loss: 5.19456

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.15635
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.05668

Collected Steps per Second: 9,371.86921
Overall Steps per Second: 8,023.24417

Timestep Collection Time: 5.33511
Timestep Consumption Time: 0.89678
PPO Batch Consumption Time: 0.04963
Total Iteration Time: 6.23189

Cumulative Model Updates: 43,966
Cumulative Timesteps: 733,384,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 733384274...
Checkpoint 733384274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,799.10588
Policy Entropy: 1.08824
Value Function Loss: 5.04982

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.05554

Collected Steps per Second: 9,604.08078
Overall Steps per Second: 8,213.37590

Timestep Collection Time: 5.20654
Timestep Consumption Time: 0.88158
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 6.08812

Cumulative Model Updates: 43,969
Cumulative Timesteps: 733,434,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,676.31425
Policy Entropy: 1.09430
Value Function Loss: 5.03283

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.05756

Collected Steps per Second: 9,507.30410
Overall Steps per Second: 8,171.99090

Timestep Collection Time: 5.26038
Timestep Consumption Time: 0.85955
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 6.11993

Cumulative Model Updates: 43,972
Cumulative Timesteps: 733,484,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 733484290...
Checkpoint 733484290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,755.05721
Policy Entropy: 1.09460
Value Function Loss: 4.87781

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 9,603.60547
Overall Steps per Second: 8,365.79783

Timestep Collection Time: 5.20950
Timestep Consumption Time: 0.77080
PPO Batch Consumption Time: 0.04534
Total Iteration Time: 5.98030

Cumulative Model Updates: 43,975
Cumulative Timesteps: 733,534,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,794.84321
Policy Entropy: 1.09925
Value Function Loss: 5.05045

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.06605
Value Function Update Magnitude: 0.07791

Collected Steps per Second: 9,784.91728
Overall Steps per Second: 8,322.07190

Timestep Collection Time: 5.11154
Timestep Consumption Time: 0.89850
PPO Batch Consumption Time: 0.04467
Total Iteration Time: 6.01004

Cumulative Model Updates: 43,978
Cumulative Timesteps: 733,584,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 733584336...
Checkpoint 733584336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,273.92394
Policy Entropy: 1.09047
Value Function Loss: 5.07234

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.06419
Value Function Update Magnitude: 0.08003

Collected Steps per Second: 9,397.40706
Overall Steps per Second: 8,103.12851

Timestep Collection Time: 5.32232
Timestep Consumption Time: 0.85011
PPO Batch Consumption Time: 0.04335
Total Iteration Time: 6.17243

Cumulative Model Updates: 43,981
Cumulative Timesteps: 733,634,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,019.95180
Policy Entropy: 1.09752
Value Function Loss: 5.14732

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.09234

Collected Steps per Second: 8,287.05324
Overall Steps per Second: 6,863.85026

Timestep Collection Time: 6.03616
Timestep Consumption Time: 1.25158
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 7.28775

Cumulative Model Updates: 43,984
Cumulative Timesteps: 733,684,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 733684374...
Checkpoint 733684374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,278.84531
Policy Entropy: 1.10507
Value Function Loss: 5.16978

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.09964

Collected Steps per Second: 9,451.29396
Overall Steps per Second: 8,258.61758

Timestep Collection Time: 5.29197
Timestep Consumption Time: 0.76425
PPO Batch Consumption Time: 0.03345
Total Iteration Time: 6.05622

Cumulative Model Updates: 43,987
Cumulative Timesteps: 733,734,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,210.51208
Policy Entropy: 1.11186
Value Function Loss: 5.23483

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.09193

Collected Steps per Second: 11,262.15771
Overall Steps per Second: 9,783.30178

Timestep Collection Time: 4.44071
Timestep Consumption Time: 0.67126
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.11198

Cumulative Model Updates: 43,990
Cumulative Timesteps: 733,784,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 733784402...
Checkpoint 733784402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,024.06369
Policy Entropy: 1.11128
Value Function Loss: 5.26782

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.08564

Collected Steps per Second: 11,471.95372
Overall Steps per Second: 9,181.12075

Timestep Collection Time: 4.36020
Timestep Consumption Time: 1.08794
PPO Batch Consumption Time: 0.04929
Total Iteration Time: 5.44814

Cumulative Model Updates: 43,993
Cumulative Timesteps: 733,834,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,283.25544
Policy Entropy: 1.10673
Value Function Loss: 5.08676

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.08056

Collected Steps per Second: 7,926.68723
Overall Steps per Second: 6,977.33231

Timestep Collection Time: 6.30907
Timestep Consumption Time: 0.85843
PPO Batch Consumption Time: 0.03960
Total Iteration Time: 7.16750

Cumulative Model Updates: 43,996
Cumulative Timesteps: 733,884,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 733884432...
Checkpoint 733884432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,129.17443
Policy Entropy: 1.10467
Value Function Loss: 5.09128

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.07356

Collected Steps per Second: 10,893.82513
Overall Steps per Second: 9,111.56834

Timestep Collection Time: 4.59104
Timestep Consumption Time: 0.89802
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.48907

Cumulative Model Updates: 43,999
Cumulative Timesteps: 733,934,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,114.36158
Policy Entropy: 1.11452
Value Function Loss: 5.09702

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.07425

Collected Steps per Second: 10,506.36207
Overall Steps per Second: 9,018.10646

Timestep Collection Time: 4.75959
Timestep Consumption Time: 0.78547
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.54507

Cumulative Model Updates: 44,002
Cumulative Timesteps: 733,984,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 733984452...
Checkpoint 733984452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,729.95651
Policy Entropy: 1.12480
Value Function Loss: 5.20673

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.07021

Collected Steps per Second: 11,258.95159
Overall Steps per Second: 9,675.39706

Timestep Collection Time: 4.44322
Timestep Consumption Time: 0.72721
PPO Batch Consumption Time: 0.03784
Total Iteration Time: 5.17043

Cumulative Model Updates: 44,005
Cumulative Timesteps: 734,034,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,717.67381
Policy Entropy: 1.11416
Value Function Loss: 5.16200

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.08395

Collected Steps per Second: 10,245.26628
Overall Steps per Second: 8,808.64781

Timestep Collection Time: 4.88304
Timestep Consumption Time: 0.79638
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.67942

Cumulative Model Updates: 44,008
Cumulative Timesteps: 734,084,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 734084506...
Checkpoint 734084506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,134.37642
Policy Entropy: 1.08891
Value Function Loss: 5.12401

Mean KL Divergence: 0.04897
SB3 Clip Fraction: 0.18753
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.08842

Collected Steps per Second: 8,682.48023
Overall Steps per Second: 7,582.51893

Timestep Collection Time: 5.76172
Timestep Consumption Time: 0.83583
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 6.59754

Cumulative Model Updates: 44,011
Cumulative Timesteps: 734,134,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,412.67928
Policy Entropy: 1.11672
Value Function Loss: 5.21901

Mean KL Divergence: 0.03280
SB3 Clip Fraction: 0.18491
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.09246

Collected Steps per Second: 12,806.88102
Overall Steps per Second: 10,605.03591

Timestep Collection Time: 3.90603
Timestep Consumption Time: 0.81098
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 4.71700

Cumulative Model Updates: 44,014
Cumulative Timesteps: 734,184,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 734184556...
Checkpoint 734184556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440,366.46367
Policy Entropy: 1.08490
Value Function Loss: 5.30094

Mean KL Divergence: 0.05029
SB3 Clip Fraction: 0.22381
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.09684

Collected Steps per Second: 11,837.44969
Overall Steps per Second: 9,973.23498

Timestep Collection Time: 4.22422
Timestep Consumption Time: 0.78960
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.01382

Cumulative Model Updates: 44,017
Cumulative Timesteps: 734,234,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,001.69253
Policy Entropy: 1.11032
Value Function Loss: 5.42455

Mean KL Divergence: 0.02619
SB3 Clip Fraction: 0.15263
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.10310

Collected Steps per Second: 11,835.56123
Overall Steps per Second: 10,078.91990

Timestep Collection Time: 4.22591
Timestep Consumption Time: 0.73653
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 4.96244

Cumulative Model Updates: 44,020
Cumulative Timesteps: 734,284,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 734284576...
Checkpoint 734284576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,627.88065
Policy Entropy: 1.09371
Value Function Loss: 5.17556

Mean KL Divergence: 0.03534
SB3 Clip Fraction: 0.16686
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.10843

Collected Steps per Second: 11,186.57489
Overall Steps per Second: 9,422.48173

Timestep Collection Time: 4.47018
Timestep Consumption Time: 0.83691
PPO Batch Consumption Time: 0.03717
Total Iteration Time: 5.30709

Cumulative Model Updates: 44,023
Cumulative Timesteps: 734,334,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,440.47698
Policy Entropy: 1.10146
Value Function Loss: 4.92358

Mean KL Divergence: 0.02815
SB3 Clip Fraction: 0.16149
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.10420

Collected Steps per Second: 11,448.42937
Overall Steps per Second: 9,683.19288

Timestep Collection Time: 4.36828
Timestep Consumption Time: 0.79633
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.16462

Cumulative Model Updates: 44,026
Cumulative Timesteps: 734,384,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 734384592...
Checkpoint 734384592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,443.29149
Policy Entropy: 1.10627
Value Function Loss: 4.57173

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.10367

Collected Steps per Second: 10,551.73095
Overall Steps per Second: 9,002.95763

Timestep Collection Time: 4.74064
Timestep Consumption Time: 0.81553
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.55617

Cumulative Model Updates: 44,029
Cumulative Timesteps: 734,434,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,248.64176
Policy Entropy: 1.11158
Value Function Loss: 4.54073

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.09058

Collected Steps per Second: 11,045.02210
Overall Steps per Second: 9,356.57523

Timestep Collection Time: 4.52856
Timestep Consumption Time: 0.81720
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.34576

Cumulative Model Updates: 44,032
Cumulative Timesteps: 734,484,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 734484632...
Checkpoint 734484632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,972.63802
Policy Entropy: 1.08589
Value Function Loss: 4.57785

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.08666

Collected Steps per Second: 10,079.46866
Overall Steps per Second: 8,858.29611

Timestep Collection Time: 4.96276
Timestep Consumption Time: 0.68415
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.64691

Cumulative Model Updates: 44,035
Cumulative Timesteps: 734,534,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,858.46555
Policy Entropy: 1.10114
Value Function Loss: 4.71868

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.08266

Collected Steps per Second: 9,796.71110
Overall Steps per Second: 8,064.74795

Timestep Collection Time: 5.10600
Timestep Consumption Time: 1.09655
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 6.20255

Cumulative Model Updates: 44,038
Cumulative Timesteps: 734,584,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 734584676...
Checkpoint 734584676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,499.82630
Policy Entropy: 1.11318
Value Function Loss: 4.79856

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.08678

Collected Steps per Second: 7,926.19221
Overall Steps per Second: 6,940.95004

Timestep Collection Time: 6.31198
Timestep Consumption Time: 0.89596
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 7.20795

Cumulative Model Updates: 44,041
Cumulative Timesteps: 734,634,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,853.30414
Policy Entropy: 1.10391
Value Function Loss: 4.78175

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.08210

Collected Steps per Second: 8,845.23922
Overall Steps per Second: 7,710.96397

Timestep Collection Time: 5.65344
Timestep Consumption Time: 0.83161
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 6.48505

Cumulative Model Updates: 44,044
Cumulative Timesteps: 734,684,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 734684712...
Checkpoint 734684712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,921.65194
Policy Entropy: 1.09421
Value Function Loss: 4.91204

Mean KL Divergence: 0.02663
SB3 Clip Fraction: 0.15541
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.09172

Collected Steps per Second: 10,173.38045
Overall Steps per Second: 8,734.06627

Timestep Collection Time: 4.91479
Timestep Consumption Time: 0.80992
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.72471

Cumulative Model Updates: 44,047
Cumulative Timesteps: 734,734,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,636.55044
Policy Entropy: 1.10237
Value Function Loss: 5.06018

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.08427

Collected Steps per Second: 11,448.05650
Overall Steps per Second: 9,722.95468

Timestep Collection Time: 4.37017
Timestep Consumption Time: 0.77538
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 5.14556

Cumulative Model Updates: 44,050
Cumulative Timesteps: 734,784,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 734784742...
Checkpoint 734784742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,470.05202
Policy Entropy: 1.11230
Value Function Loss: 5.20657

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.09877

Collected Steps per Second: 11,043.61694
Overall Steps per Second: 9,410.09427

Timestep Collection Time: 4.52968
Timestep Consumption Time: 0.78632
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.31599

Cumulative Model Updates: 44,053
Cumulative Timesteps: 734,834,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,346.51492
Policy Entropy: 1.09248
Value Function Loss: 5.30883

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.11208

Collected Steps per Second: 11,297.85039
Overall Steps per Second: 9,587.20957

Timestep Collection Time: 4.42810
Timestep Consumption Time: 0.79010
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 5.21820

Cumulative Model Updates: 44,056
Cumulative Timesteps: 734,884,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 734884794...
Checkpoint 734884794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,394.49785
Policy Entropy: 1.10134
Value Function Loss: 5.35653

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 10,871.55313
Overall Steps per Second: 9,442.97116

Timestep Collection Time: 4.60173
Timestep Consumption Time: 0.69617
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.29791

Cumulative Model Updates: 44,059
Cumulative Timesteps: 734,934,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,541.51727
Policy Entropy: 1.09679
Value Function Loss: 5.39038

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.10985

Collected Steps per Second: 11,618.92500
Overall Steps per Second: 9,847.46473

Timestep Collection Time: 4.30384
Timestep Consumption Time: 0.77422
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.07806

Cumulative Model Updates: 44,062
Cumulative Timesteps: 734,984,828

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 734984828...
Checkpoint 734984828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,246.86882
Policy Entropy: 1.10441
Value Function Loss: 5.27104

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.09656

Collected Steps per Second: 11,546.76094
Overall Steps per Second: 9,836.64380

Timestep Collection Time: 4.33247
Timestep Consumption Time: 0.75321
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.08568

Cumulative Model Updates: 44,065
Cumulative Timesteps: 735,034,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,521.42273
Policy Entropy: 1.09758
Value Function Loss: 5.11367

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.06132
Value Function Update Magnitude: 0.09891

Collected Steps per Second: 11,713.51546
Overall Steps per Second: 10,087.99647

Timestep Collection Time: 4.26994
Timestep Consumption Time: 0.68803
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.95797

Cumulative Model Updates: 44,068
Cumulative Timesteps: 735,084,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 735084870...
Checkpoint 735084870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,761.74456
Policy Entropy: 1.09445
Value Function Loss: 4.91748

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.10066

Collected Steps per Second: 10,843.86925
Overall Steps per Second: 9,261.29636

Timestep Collection Time: 4.61293
Timestep Consumption Time: 0.78826
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.40119

Cumulative Model Updates: 44,071
Cumulative Timesteps: 735,134,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,477.66959
Policy Entropy: 1.10128
Value Function Loss: 4.54313

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.10126

Collected Steps per Second: 11,364.60870
Overall Steps per Second: 9,723.30635

Timestep Collection Time: 4.40015
Timestep Consumption Time: 0.74275
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.14290

Cumulative Model Updates: 44,074
Cumulative Timesteps: 735,184,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 735184898...
Checkpoint 735184898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,673.76851
Policy Entropy: 1.09625
Value Function Loss: 4.72875

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.09652

Collected Steps per Second: 11,143.34771
Overall Steps per Second: 9,534.17072

Timestep Collection Time: 4.48824
Timestep Consumption Time: 0.75752
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.24576

Cumulative Model Updates: 44,077
Cumulative Timesteps: 735,234,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612,648.27295
Policy Entropy: 1.09736
Value Function Loss: 4.70943

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.07481
Value Function Update Magnitude: 0.08073

Collected Steps per Second: 10,639.97424
Overall Steps per Second: 9,105.22472

Timestep Collection Time: 4.70114
Timestep Consumption Time: 0.79241
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 5.49355

Cumulative Model Updates: 44,080
Cumulative Timesteps: 735,284,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 735284932...
Checkpoint 735284932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,338.55735
Policy Entropy: 1.09976
Value Function Loss: 4.97125

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.07135
Value Function Update Magnitude: 0.08107

Collected Steps per Second: 10,888.91980
Overall Steps per Second: 9,522.01811

Timestep Collection Time: 4.59182
Timestep Consumption Time: 0.65916
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.25099

Cumulative Model Updates: 44,083
Cumulative Timesteps: 735,334,932

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,283.17271
Policy Entropy: 1.10154
Value Function Loss: 4.68580

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.07383
Value Function Update Magnitude: 0.08768

Collected Steps per Second: 11,587.80851
Overall Steps per Second: 9,872.49089

Timestep Collection Time: 4.31574
Timestep Consumption Time: 0.74985
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.06559

Cumulative Model Updates: 44,086
Cumulative Timesteps: 735,384,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 735384942...
Checkpoint 735384942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,689.31071
Policy Entropy: 1.09792
Value Function Loss: 4.64429

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.07673
Value Function Update Magnitude: 0.09309

Collected Steps per Second: 11,421.80273
Overall Steps per Second: 9,803.83605

Timestep Collection Time: 4.37864
Timestep Consumption Time: 0.72263
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 5.10127

Cumulative Model Updates: 44,089
Cumulative Timesteps: 735,434,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,252.82522
Policy Entropy: 1.11229
Value Function Loss: 4.50344

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.11373

Collected Steps per Second: 11,442.78581
Overall Steps per Second: 9,770.04787

Timestep Collection Time: 4.36974
Timestep Consumption Time: 0.74815
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.11789

Cumulative Model Updates: 44,092
Cumulative Timesteps: 735,484,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 735484956...
Checkpoint 735484956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,050.65539
Policy Entropy: 1.12147
Value Function Loss: 4.48937

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.12237

Collected Steps per Second: 10,997.01158
Overall Steps per Second: 9,419.03979

Timestep Collection Time: 4.54705
Timestep Consumption Time: 0.76177
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 5.30882

Cumulative Model Updates: 44,095
Cumulative Timesteps: 735,534,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,095.20895
Policy Entropy: 1.10856
Value Function Loss: 4.53450

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.11552

Collected Steps per Second: 11,367.48994
Overall Steps per Second: 9,754.79109

Timestep Collection Time: 4.39851
Timestep Consumption Time: 0.72718
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.12569

Cumulative Model Updates: 44,098
Cumulative Timesteps: 735,584,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 735584960...
Checkpoint 735584960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,754.49398
Policy Entropy: 1.09976
Value Function Loss: 4.74407

Mean KL Divergence: 0.02679
SB3 Clip Fraction: 0.14787
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.09752

Collected Steps per Second: 11,292.60115
Overall Steps per Second: 9,623.15147

Timestep Collection Time: 4.42892
Timestep Consumption Time: 0.76834
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.19726

Cumulative Model Updates: 44,101
Cumulative Timesteps: 735,634,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,859.43580
Policy Entropy: 1.11399
Value Function Loss: 4.81238

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.08357

Collected Steps per Second: 11,433.45292
Overall Steps per Second: 9,599.00410

Timestep Collection Time: 4.37313
Timestep Consumption Time: 0.83574
PPO Batch Consumption Time: 0.04920
Total Iteration Time: 5.20887

Cumulative Model Updates: 44,104
Cumulative Timesteps: 735,684,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 735684974...
Checkpoint 735684974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,512.91709
Policy Entropy: 1.11454
Value Function Loss: 4.83027

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.09826

Collected Steps per Second: 11,257.26545
Overall Steps per Second: 9,724.10780

Timestep Collection Time: 4.44300
Timestep Consumption Time: 0.70051
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.14351

Cumulative Model Updates: 44,107
Cumulative Timesteps: 735,734,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,012.01501
Policy Entropy: 1.09956
Value Function Loss: 4.72199

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.10539

Collected Steps per Second: 10,789.47006
Overall Steps per Second: 9,231.19506

Timestep Collection Time: 4.63415
Timestep Consumption Time: 0.78227
PPO Batch Consumption Time: 0.03929
Total Iteration Time: 5.41642

Cumulative Model Updates: 44,110
Cumulative Timesteps: 735,784,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 735784990...
Checkpoint 735784990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,610.04765
Policy Entropy: 1.09323
Value Function Loss: 4.76390

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.09700

Collected Steps per Second: 6,954.37742
Overall Steps per Second: 6,133.76041

Timestep Collection Time: 7.18972
Timestep Consumption Time: 0.96189
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 8.15161

Cumulative Model Updates: 44,113
Cumulative Timesteps: 735,834,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,958.32528
Policy Entropy: 1.10525
Value Function Loss: 4.81608

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.08942

Collected Steps per Second: 9,882.77833
Overall Steps per Second: 8,596.76921

Timestep Collection Time: 5.05951
Timestep Consumption Time: 0.75686
PPO Batch Consumption Time: 0.03382
Total Iteration Time: 5.81637

Cumulative Model Updates: 44,116
Cumulative Timesteps: 735,884,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 735884992...
Checkpoint 735884992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,959.42487
Policy Entropy: 1.11034
Value Function Loss: 4.75980

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.07791

Collected Steps per Second: 7,977.65657
Overall Steps per Second: 6,475.51483

Timestep Collection Time: 6.27026
Timestep Consumption Time: 1.45453
PPO Batch Consumption Time: 0.06092
Total Iteration Time: 7.72479

Cumulative Model Updates: 44,119
Cumulative Timesteps: 735,935,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368,640.91009
Policy Entropy: 1.10339
Value Function Loss: 4.67123

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.07527

Collected Steps per Second: 9,121.56877
Overall Steps per Second: 7,732.50141

Timestep Collection Time: 5.48173
Timestep Consumption Time: 0.98474
PPO Batch Consumption Time: 0.03804
Total Iteration Time: 6.46647

Cumulative Model Updates: 44,122
Cumulative Timesteps: 735,985,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 735985016...
Checkpoint 735985016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,884.11618
Policy Entropy: 1.09203
Value Function Loss: 4.56444

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.15779
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.07634

Collected Steps per Second: 8,221.07473
Overall Steps per Second: 7,260.26492

Timestep Collection Time: 6.08485
Timestep Consumption Time: 0.80526
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 6.89011

Cumulative Model Updates: 44,125
Cumulative Timesteps: 736,035,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,249.28698
Policy Entropy: 1.10770
Value Function Loss: 4.90644

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.06950
Value Function Update Magnitude: 0.07326

Collected Steps per Second: 11,477.36580
Overall Steps per Second: 9,872.01953

Timestep Collection Time: 4.35884
Timestep Consumption Time: 0.70882
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 5.06766

Cumulative Model Updates: 44,128
Cumulative Timesteps: 736,085,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 736085068...
Checkpoint 736085068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482,781.76384
Policy Entropy: 1.10135
Value Function Loss: 5.06406

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.08127

Collected Steps per Second: 8,839.45047
Overall Steps per Second: 7,578.99646

Timestep Collection Time: 5.65985
Timestep Consumption Time: 0.94128
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 6.60114

Cumulative Model Updates: 44,131
Cumulative Timesteps: 736,135,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,167.64566
Policy Entropy: 1.08924
Value Function Loss: 5.32654

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.06974
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 9,024.08042
Overall Steps per Second: 7,938.26690

Timestep Collection Time: 5.54250
Timestep Consumption Time: 0.75812
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 6.30062

Cumulative Model Updates: 44,134
Cumulative Timesteps: 736,185,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 736185114...
Checkpoint 736185114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,569.67381
Policy Entropy: 1.09991
Value Function Loss: 5.13302

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.07442

Collected Steps per Second: 10,824.71527
Overall Steps per Second: 9,219.05764

Timestep Collection Time: 4.62072
Timestep Consumption Time: 0.80478
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 5.42550

Cumulative Model Updates: 44,137
Cumulative Timesteps: 736,235,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,208.85820
Policy Entropy: 1.10174
Value Function Loss: 5.20397

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.08586

Collected Steps per Second: 11,427.96989
Overall Steps per Second: 9,777.34436

Timestep Collection Time: 4.37733
Timestep Consumption Time: 0.73899
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 5.11632

Cumulative Model Updates: 44,140
Cumulative Timesteps: 736,285,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 736285156...
Checkpoint 736285156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,268.87058
Policy Entropy: 1.09227
Value Function Loss: 5.07851

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.09448

Collected Steps per Second: 12,493.69539
Overall Steps per Second: 10,656.29323

Timestep Collection Time: 4.00362
Timestep Consumption Time: 0.69032
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.69394

Cumulative Model Updates: 44,143
Cumulative Timesteps: 736,335,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,082.33450
Policy Entropy: 1.08402
Value Function Loss: 4.92259

Mean KL Divergence: 0.02923
SB3 Clip Fraction: 0.15671
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.10201

Collected Steps per Second: 11,760.10339
Overall Steps per Second: 9,810.01970

Timestep Collection Time: 4.25370
Timestep Consumption Time: 0.84557
PPO Batch Consumption Time: 0.03895
Total Iteration Time: 5.09928

Cumulative Model Updates: 44,146
Cumulative Timesteps: 736,385,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 736385200...
Checkpoint 736385200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,885.36643
Policy Entropy: 1.09587
Value Function Loss: 4.75692

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.10304

Collected Steps per Second: 11,949.89047
Overall Steps per Second: 9,842.93701

Timestep Collection Time: 4.18447
Timestep Consumption Time: 0.89572
PPO Batch Consumption Time: 0.04450
Total Iteration Time: 5.08019

Cumulative Model Updates: 44,149
Cumulative Timesteps: 736,435,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,092.79077
Policy Entropy: 1.10345
Value Function Loss: 4.59899

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.09145

Collected Steps per Second: 9,770.51120
Overall Steps per Second: 8,343.84685

Timestep Collection Time: 5.11805
Timestep Consumption Time: 0.87511
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.99316

Cumulative Model Updates: 44,152
Cumulative Timesteps: 736,485,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 736485210...
Checkpoint 736485210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,587.21692
Policy Entropy: 1.08614
Value Function Loss: 4.59555

Mean KL Divergence: 0.02408
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.08962

Collected Steps per Second: 10,236.25625
Overall Steps per Second: 8,622.95165

Timestep Collection Time: 4.88597
Timestep Consumption Time: 0.91414
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 5.80010

Cumulative Model Updates: 44,155
Cumulative Timesteps: 736,535,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,149.15467
Policy Entropy: 1.09229
Value Function Loss: 4.58335

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.09637

Collected Steps per Second: 10,628.50419
Overall Steps per Second: 9,289.96540

Timestep Collection Time: 4.70527
Timestep Consumption Time: 0.67796
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.38323

Cumulative Model Updates: 44,158
Cumulative Timesteps: 736,585,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 736585234...
Checkpoint 736585234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,331.62939
Policy Entropy: 1.09033
Value Function Loss: 4.81531

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.09383

Collected Steps per Second: 9,977.43703
Overall Steps per Second: 8,522.30531

Timestep Collection Time: 5.01171
Timestep Consumption Time: 0.85572
PPO Batch Consumption Time: 0.04472
Total Iteration Time: 5.86743

Cumulative Model Updates: 44,161
Cumulative Timesteps: 736,635,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,977.85703
Policy Entropy: 1.09247
Value Function Loss: 4.89578

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.07350
Value Function Update Magnitude: 0.11337

Collected Steps per Second: 10,054.64375
Overall Steps per Second: 8,702.19273

Timestep Collection Time: 4.97422
Timestep Consumption Time: 0.77307
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.74729

Cumulative Model Updates: 44,164
Cumulative Timesteps: 736,685,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 736685252...
Checkpoint 736685252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,175.30969
Policy Entropy: 1.08884
Value Function Loss: 4.81745

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.06877
Value Function Update Magnitude: 0.11148

Collected Steps per Second: 9,833.97390
Overall Steps per Second: 8,526.33984

Timestep Collection Time: 5.08747
Timestep Consumption Time: 0.78023
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.86770

Cumulative Model Updates: 44,167
Cumulative Timesteps: 736,735,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397,287.05723
Policy Entropy: 1.08104
Value Function Loss: 4.57291

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.07060
Value Function Update Magnitude: 0.10493

Collected Steps per Second: 9,827.06101
Overall Steps per Second: 8,426.68018

Timestep Collection Time: 5.09003
Timestep Consumption Time: 0.84588
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 5.93591

Cumulative Model Updates: 44,170
Cumulative Timesteps: 736,785,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 736785302...
Checkpoint 736785302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,029.94549
Policy Entropy: 1.07626
Value Function Loss: 4.53236

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.07351
Value Function Update Magnitude: 0.09142

Collected Steps per Second: 9,568.67241
Overall Steps per Second: 8,340.70517

Timestep Collection Time: 5.22831
Timestep Consumption Time: 0.76974
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.99805

Cumulative Model Updates: 44,173
Cumulative Timesteps: 736,835,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,580.64191
Policy Entropy: 1.06758
Value Function Loss: 4.79230

Mean KL Divergence: 0.02811
SB3 Clip Fraction: 0.15928
Policy Update Magnitude: 0.06784
Value Function Update Magnitude: 0.09105

Collected Steps per Second: 10,330.76006
Overall Steps per Second: 8,792.21866

Timestep Collection Time: 4.84243
Timestep Consumption Time: 0.84737
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.68980

Cumulative Model Updates: 44,176
Cumulative Timesteps: 736,885,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 736885356...
Checkpoint 736885356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,501.72661
Policy Entropy: 1.08020
Value Function Loss: 4.95530

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.08217

Collected Steps per Second: 10,799.94533
Overall Steps per Second: 9,075.24712

Timestep Collection Time: 4.63188
Timestep Consumption Time: 0.88026
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.51214

Cumulative Model Updates: 44,179
Cumulative Timesteps: 736,935,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,051.15501
Policy Entropy: 1.07918
Value Function Loss: 5.18034

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.09428

Collected Steps per Second: 11,303.05282
Overall Steps per Second: 9,831.58729

Timestep Collection Time: 4.42571
Timestep Consumption Time: 0.66238
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 5.08809

Cumulative Model Updates: 44,182
Cumulative Timesteps: 736,985,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 736985404...
Checkpoint 736985404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,098.38016
Policy Entropy: 1.06543
Value Function Loss: 4.98292

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.10827

Collected Steps per Second: 11,399.64886
Overall Steps per Second: 9,706.71639

Timestep Collection Time: 4.38645
Timestep Consumption Time: 0.76503
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.15148

Cumulative Model Updates: 44,185
Cumulative Timesteps: 737,035,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,627.82895
Policy Entropy: 1.06060
Value Function Loss: 4.77710

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.10784

Collected Steps per Second: 9,645.11161
Overall Steps per Second: 8,352.22314

Timestep Collection Time: 5.18542
Timestep Consumption Time: 0.80268
PPO Batch Consumption Time: 0.04056
Total Iteration Time: 5.98811

Cumulative Model Updates: 44,188
Cumulative Timesteps: 737,085,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 737085422...
Checkpoint 737085422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,577.22115
Policy Entropy: 1.07490
Value Function Loss: 4.60660

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.09233

Collected Steps per Second: 9,580.54373
Overall Steps per Second: 8,065.18972

Timestep Collection Time: 5.21975
Timestep Consumption Time: 0.98073
PPO Batch Consumption Time: 0.04289
Total Iteration Time: 6.20047

Cumulative Model Updates: 44,191
Cumulative Timesteps: 737,135,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,757.59405
Policy Entropy: 1.08101
Value Function Loss: 4.48614

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.14116
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.08224

Collected Steps per Second: 9,134.98297
Overall Steps per Second: 7,952.68912

Timestep Collection Time: 5.47543
Timestep Consumption Time: 0.81401
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 6.28944

Cumulative Model Updates: 44,194
Cumulative Timesteps: 737,185,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 737185448...
Checkpoint 737185448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,989.16843
Policy Entropy: 1.07255
Value Function Loss: 4.57266

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.07500

Collected Steps per Second: 9,943.49373
Overall Steps per Second: 8,628.23365

Timestep Collection Time: 5.03123
Timestep Consumption Time: 0.76694
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.79817

Cumulative Model Updates: 44,197
Cumulative Timesteps: 737,235,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,819.65661
Policy Entropy: 1.05808
Value Function Loss: 4.39376

Mean KL Divergence: 0.02985
SB3 Clip Fraction: 0.17152
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.07277

Collected Steps per Second: 9,230.90374
Overall Steps per Second: 8,054.09714

Timestep Collection Time: 5.41680
Timestep Consumption Time: 0.79146
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 6.20827

Cumulative Model Updates: 44,200
Cumulative Timesteps: 737,285,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 737285478...
Checkpoint 737285478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,012.33211
Policy Entropy: 1.07608
Value Function Loss: 4.49885

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.07705

Collected Steps per Second: 11,099.55902
Overall Steps per Second: 9,485.11592

Timestep Collection Time: 4.50703
Timestep Consumption Time: 0.76713
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.27416

Cumulative Model Updates: 44,203
Cumulative Timesteps: 737,335,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,089.27577
Policy Entropy: 1.06656
Value Function Loss: 4.56125

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.07669

Collected Steps per Second: 9,473.45844
Overall Steps per Second: 8,145.29527

Timestep Collection Time: 5.28107
Timestep Consumption Time: 0.86113
PPO Batch Consumption Time: 0.04438
Total Iteration Time: 6.14220

Cumulative Model Updates: 44,206
Cumulative Timesteps: 737,385,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 737385534...
Checkpoint 737385534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,702.66391
Policy Entropy: 1.06644
Value Function Loss: 4.85063

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.06857
Value Function Update Magnitude: 0.07752

Collected Steps per Second: 11,193.01212
Overall Steps per Second: 9,519.74033

Timestep Collection Time: 4.46707
Timestep Consumption Time: 0.78517
PPO Batch Consumption Time: 0.04074
Total Iteration Time: 5.25224

Cumulative Model Updates: 44,209
Cumulative Timesteps: 737,435,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,977.25151
Policy Entropy: 1.06123
Value Function Loss: 4.94232

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.06906
Value Function Update Magnitude: 0.08095

Collected Steps per Second: 11,051.89899
Overall Steps per Second: 9,618.18634

Timestep Collection Time: 4.52610
Timestep Consumption Time: 0.67467
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.20077

Cumulative Model Updates: 44,212
Cumulative Timesteps: 737,485,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 737485556...
Checkpoint 737485556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,538.83628
Policy Entropy: 1.07603
Value Function Loss: 5.03361

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.10027

Collected Steps per Second: 11,258.91017
Overall Steps per Second: 9,390.96329

Timestep Collection Time: 4.44110
Timestep Consumption Time: 0.88338
PPO Batch Consumption Time: 0.04453
Total Iteration Time: 5.32448

Cumulative Model Updates: 44,215
Cumulative Timesteps: 737,535,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,160.82446
Policy Entropy: 1.07649
Value Function Loss: 4.91559

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.11192

Collected Steps per Second: 10,910.32072
Overall Steps per Second: 9,384.87066

Timestep Collection Time: 4.58428
Timestep Consumption Time: 0.74515
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.32943

Cumulative Model Updates: 44,218
Cumulative Timesteps: 737,585,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 737585574...
Checkpoint 737585574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,129.93384
Policy Entropy: 1.07865
Value Function Loss: 5.16740

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.12144

Collected Steps per Second: 11,441.11341
Overall Steps per Second: 9,716.88612

Timestep Collection Time: 4.37160
Timestep Consumption Time: 0.77573
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.14733

Cumulative Model Updates: 44,221
Cumulative Timesteps: 737,635,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,472.30186
Policy Entropy: 1.08157
Value Function Loss: 5.08144

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.11307

Collected Steps per Second: 10,347.67304
Overall Steps per Second: 8,863.91394

Timestep Collection Time: 4.83432
Timestep Consumption Time: 0.80923
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 5.64356

Cumulative Model Updates: 44,224
Cumulative Timesteps: 737,685,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 737685614...
Checkpoint 737685614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,582.67806
Policy Entropy: 1.08083
Value Function Loss: 5.20682

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.06950
Value Function Update Magnitude: 0.09771

Collected Steps per Second: 11,276.78162
Overall Steps per Second: 9,790.18885

Timestep Collection Time: 4.43619
Timestep Consumption Time: 0.67361
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.10981

Cumulative Model Updates: 44,227
Cumulative Timesteps: 737,735,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,273.26919
Policy Entropy: 1.08414
Value Function Loss: 5.07799

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.07091
Value Function Update Magnitude: 0.09502

Collected Steps per Second: 11,033.07836
Overall Steps per Second: 9,379.00559

Timestep Collection Time: 4.53237
Timestep Consumption Time: 0.79932
PPO Batch Consumption Time: 0.03983
Total Iteration Time: 5.33170

Cumulative Model Updates: 44,230
Cumulative Timesteps: 737,785,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 737785646...
Checkpoint 737785646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,696.83411
Policy Entropy: 1.06874
Value Function Loss: 4.98207

Mean KL Divergence: 0.03185
SB3 Clip Fraction: 0.15945
Policy Update Magnitude: 0.07489
Value Function Update Magnitude: 0.08654

Collected Steps per Second: 10,630.17526
Overall Steps per Second: 9,214.97104

Timestep Collection Time: 4.70397
Timestep Consumption Time: 0.72242
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 5.42639

Cumulative Model Updates: 44,233
Cumulative Timesteps: 737,835,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,404.59257
Policy Entropy: 1.09668
Value Function Loss: 4.93470

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.08360

Collected Steps per Second: 11,250.52639
Overall Steps per Second: 9,692.34074

Timestep Collection Time: 4.44655
Timestep Consumption Time: 0.71485
PPO Batch Consumption Time: 0.03713
Total Iteration Time: 5.16140

Cumulative Model Updates: 44,236
Cumulative Timesteps: 737,885,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 737885676...
Checkpoint 737885676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,633.31837
Policy Entropy: 1.09116
Value Function Loss: 4.70197

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.07312
Value Function Update Magnitude: 0.07796

Collected Steps per Second: 9,855.59377
Overall Steps per Second: 8,561.08953

Timestep Collection Time: 5.07428
Timestep Consumption Time: 0.76727
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.84155

Cumulative Model Updates: 44,239
Cumulative Timesteps: 737,935,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,174.19472
Policy Entropy: 1.10034
Value Function Loss: 4.84387

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.08017
Value Function Update Magnitude: 0.07700

Collected Steps per Second: 11,197.41933
Overall Steps per Second: 9,568.89848

Timestep Collection Time: 4.46817
Timestep Consumption Time: 0.76043
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.22861

Cumulative Model Updates: 44,242
Cumulative Timesteps: 737,985,718

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 737985718...
Checkpoint 737985718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,610.42275
Policy Entropy: 1.09578
Value Function Loss: 4.77930

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.08353
Value Function Update Magnitude: 0.07689

Collected Steps per Second: 11,518.83691
Overall Steps per Second: 9,682.13211

Timestep Collection Time: 4.34176
Timestep Consumption Time: 0.82363
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.16539

Cumulative Model Updates: 44,245
Cumulative Timesteps: 738,035,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,259.95320
Policy Entropy: 1.09529
Value Function Loss: 4.81813

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.08087
Value Function Update Magnitude: 0.07880

Collected Steps per Second: 9,284.85926
Overall Steps per Second: 8,063.53770

Timestep Collection Time: 5.38791
Timestep Consumption Time: 0.81607
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 6.20398

Cumulative Model Updates: 44,248
Cumulative Timesteps: 738,085,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 738085756...
Checkpoint 738085756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,249.27005
Policy Entropy: 1.08616
Value Function Loss: 4.59630

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.07608
Value Function Update Magnitude: 0.07750

Collected Steps per Second: 11,012.04867
Overall Steps per Second: 9,579.51980

Timestep Collection Time: 4.54139
Timestep Consumption Time: 0.67912
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 5.22051

Cumulative Model Updates: 44,251
Cumulative Timesteps: 738,135,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566,803.38214
Policy Entropy: 1.09779
Value Function Loss: 4.50188

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.06595
Value Function Update Magnitude: 0.07095

Collected Steps per Second: 11,035.00707
Overall Steps per Second: 9,450.83103

Timestep Collection Time: 4.53321
Timestep Consumption Time: 0.75987
PPO Batch Consumption Time: 0.03339
Total Iteration Time: 5.29308

Cumulative Model Updates: 44,254
Cumulative Timesteps: 738,185,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 738185790...
Checkpoint 738185790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,561.97359
Policy Entropy: 1.10348
Value Function Loss: 4.46127

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.06682
Value Function Update Magnitude: 0.08302

Collected Steps per Second: 11,629.92047
Overall Steps per Second: 9,879.73786

Timestep Collection Time: 4.30063
Timestep Consumption Time: 0.76185
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 5.06248

Cumulative Model Updates: 44,257
Cumulative Timesteps: 738,235,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,233.05450
Policy Entropy: 1.10523
Value Function Loss: 4.66844

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.06593
Value Function Update Magnitude: 0.10612

Collected Steps per Second: 11,513.50911
Overall Steps per Second: 9,785.88970

Timestep Collection Time: 4.34533
Timestep Consumption Time: 0.76713
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 5.11246

Cumulative Model Updates: 44,260
Cumulative Timesteps: 738,285,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 738285836...
Checkpoint 738285836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653,888.26211
Policy Entropy: 1.09737
Value Function Loss: 4.78782

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.11461

Collected Steps per Second: 10,871.19233
Overall Steps per Second: 9,257.84561

Timestep Collection Time: 4.60005
Timestep Consumption Time: 0.80164
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 5.40169

Cumulative Model Updates: 44,263
Cumulative Timesteps: 738,335,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,623.37887
Policy Entropy: 1.09569
Value Function Loss: 4.81146

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.11500

Collected Steps per Second: 7,967.27635
Overall Steps per Second: 7,043.89955

Timestep Collection Time: 6.27893
Timestep Consumption Time: 0.82310
PPO Batch Consumption Time: 0.04172
Total Iteration Time: 7.10203

Cumulative Model Updates: 44,266
Cumulative Timesteps: 738,385,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 738385870...
Checkpoint 738385870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,864.59272
Policy Entropy: 1.10882
Value Function Loss: 4.78524

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.11062

Collected Steps per Second: 10,601.68123
Overall Steps per Second: 9,067.59820

Timestep Collection Time: 4.71812
Timestep Consumption Time: 0.79823
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.51635

Cumulative Model Updates: 44,269
Cumulative Timesteps: 738,435,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,690.54612
Policy Entropy: 1.11000
Value Function Loss: 4.80886

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.11936

Collected Steps per Second: 12,520.00923
Overall Steps per Second: 10,445.87991

Timestep Collection Time: 3.99441
Timestep Consumption Time: 0.79313
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.78753

Cumulative Model Updates: 44,272
Cumulative Timesteps: 738,485,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 738485900...
Checkpoint 738485900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,890.30659
Policy Entropy: 1.09738
Value Function Loss: 5.22933

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.11078

Collected Steps per Second: 12,238.45665
Overall Steps per Second: 10,346.88809

Timestep Collection Time: 4.08581
Timestep Consumption Time: 0.74695
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 4.83276

Cumulative Model Updates: 44,275
Cumulative Timesteps: 738,535,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,307.96089
Policy Entropy: 1.07640
Value Function Loss: 5.14867

Mean KL Divergence: 0.03021
SB3 Clip Fraction: 0.18377
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.11412

Collected Steps per Second: 12,115.05759
Overall Steps per Second: 9,960.96491

Timestep Collection Time: 4.12842
Timestep Consumption Time: 0.89278
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 5.02120

Cumulative Model Updates: 44,278
Cumulative Timesteps: 738,585,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 738585920...
Checkpoint 738585920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,890.98864
Policy Entropy: 1.09223
Value Function Loss: 4.95704

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.10830

Collected Steps per Second: 9,795.28992
Overall Steps per Second: 8,438.15750

Timestep Collection Time: 5.10694
Timestep Consumption Time: 0.82136
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.92831

Cumulative Model Updates: 44,281
Cumulative Timesteps: 738,635,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,333.27658
Policy Entropy: 1.08438
Value Function Loss: 4.52904

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.09831

Collected Steps per Second: 11,182.02278
Overall Steps per Second: 9,321.94306

Timestep Collection Time: 4.47361
Timestep Consumption Time: 0.89265
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.36626

Cumulative Model Updates: 44,284
Cumulative Timesteps: 738,685,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 738685968...
Checkpoint 738685968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,854.39492
Policy Entropy: 1.07476
Value Function Loss: 4.52054

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.08808

Collected Steps per Second: 10,558.87322
Overall Steps per Second: 9,110.15148

Timestep Collection Time: 4.73725
Timestep Consumption Time: 0.75333
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 5.49058

Cumulative Model Updates: 44,287
Cumulative Timesteps: 738,735,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551,051.18614
Policy Entropy: 1.07539
Value Function Loss: 4.66569

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.06214
Value Function Update Magnitude: 0.08188

Collected Steps per Second: 11,598.60442
Overall Steps per Second: 10,052.68877

Timestep Collection Time: 4.31155
Timestep Consumption Time: 0.66304
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.97459

Cumulative Model Updates: 44,290
Cumulative Timesteps: 738,785,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 738785996...
Checkpoint 738785996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,370.16526
Policy Entropy: 1.09022
Value Function Loss: 4.76976

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.09103

Collected Steps per Second: 11,426.00363
Overall Steps per Second: 9,668.87916

Timestep Collection Time: 4.37773
Timestep Consumption Time: 0.79557
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 5.17330

Cumulative Model Updates: 44,293
Cumulative Timesteps: 738,836,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,539.80043
Policy Entropy: 1.09827
Value Function Loss: 4.77509

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.09074

Collected Steps per Second: 11,649.54967
Overall Steps per Second: 9,914.14922

Timestep Collection Time: 4.29201
Timestep Consumption Time: 0.75129
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.04330

Cumulative Model Updates: 44,296
Cumulative Timesteps: 738,886,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 738886016...
Checkpoint 738886016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,408.94350
Policy Entropy: 1.09441
Value Function Loss: 4.61785

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.07999

Collected Steps per Second: 11,832.20556
Overall Steps per Second: 10,178.77665

Timestep Collection Time: 4.22660
Timestep Consumption Time: 0.68656
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.91316

Cumulative Model Updates: 44,299
Cumulative Timesteps: 738,936,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,903.71906
Policy Entropy: 1.08587
Value Function Loss: 4.80550

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 11,853.56123
Overall Steps per Second: 10,010.84044

Timestep Collection Time: 4.21865
Timestep Consumption Time: 0.77654
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 4.99518

Cumulative Model Updates: 44,302
Cumulative Timesteps: 738,986,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 738986032...
Checkpoint 738986032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,170.45786
Policy Entropy: 1.09917
Value Function Loss: 4.91366

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.07224

Collected Steps per Second: 11,252.19641
Overall Steps per Second: 9,687.07315

Timestep Collection Time: 4.44607
Timestep Consumption Time: 0.71834
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.16441

Cumulative Model Updates: 44,305
Cumulative Timesteps: 739,036,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,900.02581
Policy Entropy: 1.09590
Value Function Loss: 5.17397

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.06706
Value Function Update Magnitude: 0.07625

Collected Steps per Second: 12,002.27487
Overall Steps per Second: 10,102.18860

Timestep Collection Time: 4.16621
Timestep Consumption Time: 0.78361
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 4.94982

Cumulative Model Updates: 44,308
Cumulative Timesteps: 739,086,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 739086064...
Checkpoint 739086064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,331.98853
Policy Entropy: 1.09976
Value Function Loss: 5.15074

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.06454
Value Function Update Magnitude: 0.10110

Collected Steps per Second: 11,815.94845
Overall Steps per Second: 10,012.34923

Timestep Collection Time: 4.23157
Timestep Consumption Time: 0.76226
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 4.99383

Cumulative Model Updates: 44,311
Cumulative Timesteps: 739,136,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,436.40811
Policy Entropy: 1.09295
Value Function Loss: 4.97652

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.07241
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 11,748.65976
Overall Steps per Second: 10,141.25478

Timestep Collection Time: 4.25751
Timestep Consumption Time: 0.67482
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 4.93233

Cumulative Model Updates: 44,314
Cumulative Timesteps: 739,186,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 739186084...
Checkpoint 739186084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,190.47373
Policy Entropy: 1.10221
Value Function Loss: 4.78787

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.09578

Collected Steps per Second: 10,612.32103
Overall Steps per Second: 9,151.66593

Timestep Collection Time: 4.71226
Timestep Consumption Time: 0.75210
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.46436

Cumulative Model Updates: 44,317
Cumulative Timesteps: 739,236,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,619.18528
Policy Entropy: 1.08296
Value Function Loss: 4.64730

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.06505
Value Function Update Magnitude: 0.09836

Collected Steps per Second: 11,131.38838
Overall Steps per Second: 9,174.86700

Timestep Collection Time: 4.49288
Timestep Consumption Time: 0.95810
PPO Batch Consumption Time: 0.03931
Total Iteration Time: 5.45098

Cumulative Model Updates: 44,320
Cumulative Timesteps: 739,286,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 739286104...
Checkpoint 739286104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,154.37505
Policy Entropy: 1.09949
Value Function Loss: 4.66143

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 11,019.46312
Overall Steps per Second: 9,605.60178

Timestep Collection Time: 4.53979
Timestep Consumption Time: 0.66822
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.20800

Cumulative Model Updates: 44,323
Cumulative Timesteps: 739,336,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,571.17367
Policy Entropy: 1.09901
Value Function Loss: 4.73707

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.10520

Collected Steps per Second: 11,861.56772
Overall Steps per Second: 10,005.48120

Timestep Collection Time: 4.21529
Timestep Consumption Time: 0.78197
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 4.99726

Cumulative Model Updates: 44,326
Cumulative Timesteps: 739,386,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 739386130...
Checkpoint 739386130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,403.81443
Policy Entropy: 1.09090
Value Function Loss: 4.65355

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.09994

Collected Steps per Second: 9,978.40924
Overall Steps per Second: 8,685.03310

Timestep Collection Time: 5.01242
Timestep Consumption Time: 0.74645
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.75887

Cumulative Model Updates: 44,329
Cumulative Timesteps: 739,436,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,553.37006
Policy Entropy: 1.08961
Value Function Loss: 4.85850

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.10226

Collected Steps per Second: 11,858.56443
Overall Steps per Second: 9,994.78080

Timestep Collection Time: 4.21771
Timestep Consumption Time: 0.78650
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.00421

Cumulative Model Updates: 44,332
Cumulative Timesteps: 739,486,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 739486162...
Checkpoint 739486162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,390.59247
Policy Entropy: 1.09829
Value Function Loss: 4.83356

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.10428

Collected Steps per Second: 9,876.96872
Overall Steps per Second: 8,573.02541

Timestep Collection Time: 5.06228
Timestep Consumption Time: 0.76996
PPO Batch Consumption Time: 0.03927
Total Iteration Time: 5.83225

Cumulative Model Updates: 44,335
Cumulative Timesteps: 739,536,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,310.88382
Policy Entropy: 1.10966
Value Function Loss: 5.24976

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.09275

Collected Steps per Second: 10,607.09550
Overall Steps per Second: 9,259.58299

Timestep Collection Time: 4.71647
Timestep Consumption Time: 0.68637
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 5.40284

Cumulative Model Updates: 44,338
Cumulative Timesteps: 739,586,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 739586190...
Checkpoint 739586190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,713.56491
Policy Entropy: 1.08564
Value Function Loss: 5.11541

Mean KL Divergence: 0.02942
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.09576

Collected Steps per Second: 11,137.60252
Overall Steps per Second: 9,538.87895

Timestep Collection Time: 4.48930
Timestep Consumption Time: 0.75241
PPO Batch Consumption Time: 0.03378
Total Iteration Time: 5.24171

Cumulative Model Updates: 44,341
Cumulative Timesteps: 739,636,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,912.63177
Policy Entropy: 1.10490
Value Function Loss: 5.28704

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.09870

Collected Steps per Second: 11,274.41465
Overall Steps per Second: 9,625.12570

Timestep Collection Time: 4.43571
Timestep Consumption Time: 0.76007
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 5.19578

Cumulative Model Updates: 44,344
Cumulative Timesteps: 739,686,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 739686200...
Checkpoint 739686200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,520.74772
Policy Entropy: 1.10131
Value Function Loss: 4.94412

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.08410

Collected Steps per Second: 9,973.05195
Overall Steps per Second: 8,563.06167

Timestep Collection Time: 5.01632
Timestep Consumption Time: 0.82598
PPO Batch Consumption Time: 0.03971
Total Iteration Time: 5.84230

Cumulative Model Updates: 44,347
Cumulative Timesteps: 739,736,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,058.60720
Policy Entropy: 1.09063
Value Function Loss: 5.07617

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.08090

Collected Steps per Second: 10,727.97389
Overall Steps per Second: 9,112.61655

Timestep Collection Time: 4.66127
Timestep Consumption Time: 0.82629
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.48756

Cumulative Model Updates: 44,350
Cumulative Timesteps: 739,786,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 739786234...
Checkpoint 739786234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,303.02087
Policy Entropy: 1.07615
Value Function Loss: 4.72728

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.15413
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.07899

Collected Steps per Second: 10,085.51782
Overall Steps per Second: 8,497.47337

Timestep Collection Time: 4.95978
Timestep Consumption Time: 0.92691
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.88669

Cumulative Model Updates: 44,353
Cumulative Timesteps: 739,836,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,086.76985
Policy Entropy: 1.08638
Value Function Loss: 4.70379

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.08643

Collected Steps per Second: 8,789.60486
Overall Steps per Second: 7,295.36073

Timestep Collection Time: 5.69150
Timestep Consumption Time: 1.16574
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 6.85723

Cumulative Model Updates: 44,356
Cumulative Timesteps: 739,886,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 739886282...
Checkpoint 739886282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,130.40102
Policy Entropy: 1.08880
Value Function Loss: 4.41687

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.06758
Value Function Update Magnitude: 0.07875

Collected Steps per Second: 8,754.34191
Overall Steps per Second: 7,569.59880

Timestep Collection Time: 5.71465
Timestep Consumption Time: 0.89442
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 6.60907

Cumulative Model Updates: 44,359
Cumulative Timesteps: 739,936,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,554.92509
Policy Entropy: 1.09452
Value Function Loss: 4.33154

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07529
Policy Update Magnitude: 0.06970
Value Function Update Magnitude: 0.07860

Collected Steps per Second: 9,238.45144
Overall Steps per Second: 7,960.03530

Timestep Collection Time: 5.41303
Timestep Consumption Time: 0.86936
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 6.28238

Cumulative Model Updates: 44,362
Cumulative Timesteps: 739,986,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 739986318...
Checkpoint 739986318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,460.91301
Policy Entropy: 1.09164
Value Function Loss: 4.44984

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.08062
Value Function Update Magnitude: 0.09464

Collected Steps per Second: 9,024.69462
Overall Steps per Second: 7,817.33695

Timestep Collection Time: 5.54235
Timestep Consumption Time: 0.85599
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 6.39834

Cumulative Model Updates: 44,365
Cumulative Timesteps: 740,036,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,092.12157
Policy Entropy: 1.09430
Value Function Loss: 4.54403

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.08784
Value Function Update Magnitude: 0.09444

Collected Steps per Second: 8,279.18847
Overall Steps per Second: 7,306.78261

Timestep Collection Time: 6.04045
Timestep Consumption Time: 0.80388
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 6.84433

Cumulative Model Updates: 44,368
Cumulative Timesteps: 740,086,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 740086346...
Checkpoint 740086346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,786.93845
Policy Entropy: 1.09663
Value Function Loss: 4.89629

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.08844
Value Function Update Magnitude: 0.08874

Collected Steps per Second: 9,523.47684
Overall Steps per Second: 8,048.84057

Timestep Collection Time: 5.25312
Timestep Consumption Time: 0.96243
PPO Batch Consumption Time: 0.04453
Total Iteration Time: 6.21555

Cumulative Model Updates: 44,371
Cumulative Timesteps: 740,136,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,267.97473
Policy Entropy: 1.08663
Value Function Loss: 5.04048

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.08611
Value Function Update Magnitude: 0.09276

Collected Steps per Second: 9,680.56815
Overall Steps per Second: 8,395.36070

Timestep Collection Time: 5.16767
Timestep Consumption Time: 0.79110
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 5.95877

Cumulative Model Updates: 44,374
Cumulative Timesteps: 740,186,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 740186400...
Checkpoint 740186400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,795.57045
Policy Entropy: 1.09633
Value Function Loss: 5.07656

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.07311
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 10,136.11036
Overall Steps per Second: 8,667.61651

Timestep Collection Time: 4.93444
Timestep Consumption Time: 0.83601
PPO Batch Consumption Time: 0.03924
Total Iteration Time: 5.77044

Cumulative Model Updates: 44,377
Cumulative Timesteps: 740,236,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,125.77788
Policy Entropy: 1.09551
Value Function Loss: 5.03587

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.07848

Collected Steps per Second: 9,925.49883
Overall Steps per Second: 8,702.93927

Timestep Collection Time: 5.03914
Timestep Consumption Time: 0.70788
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 5.74702

Cumulative Model Updates: 44,380
Cumulative Timesteps: 740,286,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 740286432...
Checkpoint 740286432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,651.55985
Policy Entropy: 1.07753
Value Function Loss: 4.85810

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.08072

Collected Steps per Second: 9,014.01557
Overall Steps per Second: 7,696.30357

Timestep Collection Time: 5.54714
Timestep Consumption Time: 0.94975
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 6.49689

Cumulative Model Updates: 44,383
Cumulative Timesteps: 740,336,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585,773.03000
Policy Entropy: 1.07368
Value Function Loss: 4.97746

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.15300
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.08638

Collected Steps per Second: 11,246.72402
Overall Steps per Second: 9,597.34496

Timestep Collection Time: 4.44734
Timestep Consumption Time: 0.76431
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.21165

Cumulative Model Updates: 44,386
Cumulative Timesteps: 740,386,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 740386452...
Checkpoint 740386452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,905.48178
Policy Entropy: 1.07698
Value Function Loss: 4.97412

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.09086

Collected Steps per Second: 11,454.92140
Overall Steps per Second: 9,912.41928

Timestep Collection Time: 4.36529
Timestep Consumption Time: 0.67930
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 5.04458

Cumulative Model Updates: 44,389
Cumulative Timesteps: 740,436,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,827.16224
Policy Entropy: 1.09320
Value Function Loss: 5.02855

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.06478
Value Function Update Magnitude: 0.08452

Collected Steps per Second: 11,745.01957
Overall Steps per Second: 9,965.78586

Timestep Collection Time: 4.25712
Timestep Consumption Time: 0.76004
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.01717

Cumulative Model Updates: 44,392
Cumulative Timesteps: 740,486,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 740486456...
Checkpoint 740486456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,841.14306
Policy Entropy: 1.08958
Value Function Loss: 4.96508

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.07021
Value Function Update Magnitude: 0.08990

Collected Steps per Second: 11,379.84202
Overall Steps per Second: 9,657.79649

Timestep Collection Time: 4.39479
Timestep Consumption Time: 0.78362
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.17841

Cumulative Model Updates: 44,395
Cumulative Timesteps: 740,536,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,134.99565
Policy Entropy: 1.10472
Value Function Loss: 4.88257

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.09856

Collected Steps per Second: 11,949.75654
Overall Steps per Second: 9,923.46072

Timestep Collection Time: 4.18452
Timestep Consumption Time: 0.85445
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.03897

Cumulative Model Updates: 44,398
Cumulative Timesteps: 740,586,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 740586472...
Checkpoint 740586472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,740.03099
Policy Entropy: 1.10508
Value Function Loss: 4.73706

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.06764
Value Function Update Magnitude: 0.09125

Collected Steps per Second: 9,440.23343
Overall Steps per Second: 8,245.07149

Timestep Collection Time: 5.29648
Timestep Consumption Time: 0.76775
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 6.06423

Cumulative Model Updates: 44,401
Cumulative Timesteps: 740,636,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,186.53465
Policy Entropy: 1.10367
Value Function Loss: 4.75704

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.08767

Collected Steps per Second: 12,290.76273
Overall Steps per Second: 10,498.35663

Timestep Collection Time: 4.06891
Timestep Consumption Time: 0.69469
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.76360

Cumulative Model Updates: 44,404
Cumulative Timesteps: 740,686,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 740686482...
Checkpoint 740686482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,396.45679
Policy Entropy: 1.10395
Value Function Loss: 4.71617

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.07165
Value Function Update Magnitude: 0.07726

Collected Steps per Second: 12,325.22399
Overall Steps per Second: 10,251.67592

Timestep Collection Time: 4.05883
Timestep Consumption Time: 0.82096
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 4.87979

Cumulative Model Updates: 44,407
Cumulative Timesteps: 740,736,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,015.50844
Policy Entropy: 1.10245
Value Function Loss: 5.03333

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.07555

Collected Steps per Second: 11,176.41136
Overall Steps per Second: 9,481.58347

Timestep Collection Time: 4.47586
Timestep Consumption Time: 0.80006
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.27591

Cumulative Model Updates: 44,410
Cumulative Timesteps: 740,786,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 740786532...
Checkpoint 740786532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,733.25515
Policy Entropy: 1.10697
Value Function Loss: 5.13162

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.08111

Collected Steps per Second: 12,442.03907
Overall Steps per Second: 10,406.42046

Timestep Collection Time: 4.01863
Timestep Consumption Time: 0.78609
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.80473

Cumulative Model Updates: 44,413
Cumulative Timesteps: 740,836,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,917.38157
Policy Entropy: 1.10770
Value Function Loss: 5.18029

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.07594
Value Function Update Magnitude: 0.08295

Collected Steps per Second: 8,682.66520
Overall Steps per Second: 6,045.26471

Timestep Collection Time: 5.75975
Timestep Consumption Time: 2.51284
PPO Batch Consumption Time: 0.05438
Total Iteration Time: 8.27259

Cumulative Model Updates: 44,416
Cumulative Timesteps: 740,886,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 740886542...
Checkpoint 740886542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,149.06239
Policy Entropy: 1.11095
Value Function Loss: 4.92555

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.07384
Value Function Update Magnitude: 0.08670

Collected Steps per Second: 4,026.19320
Overall Steps per Second: 3,364.53596

Timestep Collection Time: 12.41918
Timestep Consumption Time: 2.44231
PPO Batch Consumption Time: 0.05873
Total Iteration Time: 14.86148

Cumulative Model Updates: 44,419
Cumulative Timesteps: 740,936,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633,149.79792
Policy Entropy: 1.10180
Value Function Loss: 4.54335

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.06649
Value Function Update Magnitude: 0.09201

Collected Steps per Second: 4,112.19841
Overall Steps per Second: 3,370.49784

Timestep Collection Time: 12.15895
Timestep Consumption Time: 2.67566
PPO Batch Consumption Time: 0.04949
Total Iteration Time: 14.83460

Cumulative Model Updates: 44,422
Cumulative Timesteps: 740,986,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 740986544...
Checkpoint 740986544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,710.17035
Policy Entropy: 1.11893
Value Function Loss: 4.44512

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.10518

Collected Steps per Second: 4,199.06419
Overall Steps per Second: 3,430.45941

Timestep Collection Time: 11.90837
Timestep Consumption Time: 2.66811
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 14.57647

Cumulative Model Updates: 44,425
Cumulative Timesteps: 741,036,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,043.29097
Policy Entropy: 1.11794
Value Function Loss: 4.65122

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.10608

Collected Steps per Second: 4,151.39566
Overall Steps per Second: 3,396.64849

Timestep Collection Time: 12.04944
Timestep Consumption Time: 2.67743
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 14.72687

Cumulative Model Updates: 44,428
Cumulative Timesteps: 741,086,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 741086570...
Checkpoint 741086570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,002.90848
Policy Entropy: 1.12239
Value Function Loss: 4.92224

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.06580
Value Function Update Magnitude: 0.09430

Collected Steps per Second: 3,954.71256
Overall Steps per Second: 3,277.00989

Timestep Collection Time: 12.64871
Timestep Consumption Time: 2.61582
PPO Batch Consumption Time: 0.05771
Total Iteration Time: 15.26453

Cumulative Model Updates: 44,431
Cumulative Timesteps: 741,136,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,746.00287
Policy Entropy: 1.11005
Value Function Loss: 4.90223

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.10017
Policy Update Magnitude: 0.06653
Value Function Update Magnitude: 0.08693

Collected Steps per Second: 3,977.47563
Overall Steps per Second: 3,343.88753

Timestep Collection Time: 12.57783
Timestep Consumption Time: 2.38320
PPO Batch Consumption Time: 0.06017
Total Iteration Time: 14.96103

Cumulative Model Updates: 44,434
Cumulative Timesteps: 741,186,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 741186620...
Checkpoint 741186620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,495.02719
Policy Entropy: 1.11558
Value Function Loss: 4.93552

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.07752
Value Function Update Magnitude: 0.08785

Collected Steps per Second: 3,978.41791
Overall Steps per Second: 3,232.65396

Timestep Collection Time: 12.56831
Timestep Consumption Time: 2.89947
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 15.46779

Cumulative Model Updates: 44,437
Cumulative Timesteps: 741,236,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,932.71815
Policy Entropy: 1.12054
Value Function Loss: 4.95277

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.07029
Value Function Update Magnitude: 0.08063

Collected Steps per Second: 4,067.08592
Overall Steps per Second: 3,346.39731

Timestep Collection Time: 12.29627
Timestep Consumption Time: 2.64816
PPO Batch Consumption Time: 0.06182
Total Iteration Time: 14.94443

Cumulative Model Updates: 44,440
Cumulative Timesteps: 741,286,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 741286632...
Checkpoint 741286632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,539.51914
Policy Entropy: 1.12266
Value Function Loss: 5.22355

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.06861
Value Function Update Magnitude: 0.08400

Collected Steps per Second: 4,222.02197
Overall Steps per Second: 3,448.98549

Timestep Collection Time: 11.84788
Timestep Consumption Time: 2.65552
PPO Batch Consumption Time: 0.04927
Total Iteration Time: 14.50340

Cumulative Model Updates: 44,443
Cumulative Timesteps: 741,336,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356,399.68452
Policy Entropy: 1.12908
Value Function Loss: 5.28518

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.08231

Collected Steps per Second: 4,057.95932
Overall Steps per Second: 3,318.66229

Timestep Collection Time: 12.32836
Timestep Consumption Time: 2.74638
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 15.07475

Cumulative Model Updates: 44,446
Cumulative Timesteps: 741,386,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 741386682...
Checkpoint 741386682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,233.28473
Policy Entropy: 1.12598
Value Function Loss: 5.45155

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.06667
Value Function Update Magnitude: 0.08097

Collected Steps per Second: 3,912.97486
Overall Steps per Second: 3,268.42691

Timestep Collection Time: 12.78925
Timestep Consumption Time: 2.52209
PPO Batch Consumption Time: 0.06748
Total Iteration Time: 15.31134

Cumulative Model Updates: 44,449
Cumulative Timesteps: 741,436,726

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,145.81504
Policy Entropy: 1.12294
Value Function Loss: 5.23900

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.08009

Collected Steps per Second: 3,987.76943
Overall Steps per Second: 3,231.70980

Timestep Collection Time: 12.54636
Timestep Consumption Time: 2.93523
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 15.48159

Cumulative Model Updates: 44,452
Cumulative Timesteps: 741,486,758

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 741486758...
Checkpoint 741486758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,293.27786
Policy Entropy: 1.12881
Value Function Loss: 4.95812

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.09041

Collected Steps per Second: 3,988.07536
Overall Steps per Second: 3,297.92893

Timestep Collection Time: 12.53888
Timestep Consumption Time: 2.62397
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 15.16285

Cumulative Model Updates: 44,455
Cumulative Timesteps: 741,536,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,794.95605
Policy Entropy: 1.12393
Value Function Loss: 4.91395

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.05933
Value Function Update Magnitude: 0.08627

Collected Steps per Second: 4,118.94079
Overall Steps per Second: 3,353.37902

Timestep Collection Time: 12.14875
Timestep Consumption Time: 2.77351
PPO Batch Consumption Time: 0.05399
Total Iteration Time: 14.92226

Cumulative Model Updates: 44,458
Cumulative Timesteps: 741,586,804

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 741586804...
Checkpoint 741586804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,797.84743
Policy Entropy: 1.12797
Value Function Loss: 5.01498

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.08246

Collected Steps per Second: 4,332.28104
Overall Steps per Second: 3,642.34419

Timestep Collection Time: 11.55142
Timestep Consumption Time: 2.18808
PPO Batch Consumption Time: 0.05040
Total Iteration Time: 13.73950

Cumulative Model Updates: 44,461
Cumulative Timesteps: 741,636,848

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375,858.09652
Policy Entropy: 1.12383
Value Function Loss: 5.09854

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.06495
Value Function Update Magnitude: 0.08993

Collected Steps per Second: 4,112.23549
Overall Steps per Second: 3,429.52703

Timestep Collection Time: 12.17100
Timestep Consumption Time: 2.42285
PPO Batch Consumption Time: 0.06274
Total Iteration Time: 14.59385

Cumulative Model Updates: 44,464
Cumulative Timesteps: 741,686,898

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 741686898...
Checkpoint 741686898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,210.80252
Policy Entropy: 1.12094
Value Function Loss: 5.20764

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.08475

Collected Steps per Second: 4,004.23146
Overall Steps per Second: 3,350.64857

Timestep Collection Time: 12.49129
Timestep Consumption Time: 2.43657
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 14.92786

Cumulative Model Updates: 44,467
Cumulative Timesteps: 741,736,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,417.43998
Policy Entropy: 1.12793
Value Function Loss: 5.28987

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.07449

Collected Steps per Second: 4,203.88249
Overall Steps per Second: 3,518.93058

Timestep Collection Time: 11.90423
Timestep Consumption Time: 2.31713
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 14.22137

Cumulative Model Updates: 44,470
Cumulative Timesteps: 741,786,960

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 741786960...
Checkpoint 741786960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,766.55816
Policy Entropy: 1.11459
Value Function Loss: 5.31319

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.07658

Collected Steps per Second: 4,051.44369
Overall Steps per Second: 3,308.52649

Timestep Collection Time: 12.34177
Timestep Consumption Time: 2.77130
PPO Batch Consumption Time: 0.06391
Total Iteration Time: 15.11307

Cumulative Model Updates: 44,473
Cumulative Timesteps: 741,836,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,923.49231
Policy Entropy: 1.11650
Value Function Loss: 5.22681

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 4,051.08552
Overall Steps per Second: 3,403.96745

Timestep Collection Time: 12.35126
Timestep Consumption Time: 2.34806
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 14.69932

Cumulative Model Updates: 44,476
Cumulative Timesteps: 741,886,998

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 741886998...
Checkpoint 741886998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,442.15500
Policy Entropy: 1.11560
Value Function Loss: 5.38383

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.10601
Policy Update Magnitude: 0.06172
Value Function Update Magnitude: 0.08256

Collected Steps per Second: 4,314.21261
Overall Steps per Second: 3,580.61940

Timestep Collection Time: 11.59377
Timestep Consumption Time: 2.37532
PPO Batch Consumption Time: 0.07115
Total Iteration Time: 13.96909

Cumulative Model Updates: 44,479
Cumulative Timesteps: 741,937,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,870.78913
Policy Entropy: 1.13462
Value Function Loss: 5.53016

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.09574

Collected Steps per Second: 4,128.58154
Overall Steps per Second: 3,389.89308

Timestep Collection Time: 12.11603
Timestep Consumption Time: 2.64019
PPO Batch Consumption Time: 0.05212
Total Iteration Time: 14.75622

Cumulative Model Updates: 44,482
Cumulative Timesteps: 741,987,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 741987038...
Checkpoint 741987038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,179.70282
Policy Entropy: 1.13621
Value Function Loss: 5.34123

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.10550

Collected Steps per Second: 3,924.00127
Overall Steps per Second: 3,266.96036

Timestep Collection Time: 12.75076
Timestep Consumption Time: 2.56439
PPO Batch Consumption Time: 0.06095
Total Iteration Time: 15.31515

Cumulative Model Updates: 44,485
Cumulative Timesteps: 742,037,072

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,682.08847
Policy Entropy: 1.12299
Value Function Loss: 5.23712

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 4,093.47236
Overall Steps per Second: 3,319.84824

Timestep Collection Time: 12.22483
Timestep Consumption Time: 2.84875
PPO Batch Consumption Time: 0.06707
Total Iteration Time: 15.07358

Cumulative Model Updates: 44,488
Cumulative Timesteps: 742,087,114

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 742087114...
Checkpoint 742087114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,114.52549
Policy Entropy: 1.12157
Value Function Loss: 5.25622

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.13443

Collected Steps per Second: 3,996.76868
Overall Steps per Second: 3,305.59020

Timestep Collection Time: 12.51711
Timestep Consumption Time: 2.61725
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 15.13436

Cumulative Model Updates: 44,491
Cumulative Timesteps: 742,137,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464,899.80156
Policy Entropy: 1.13466
Value Function Loss: 5.51949

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.13190

Collected Steps per Second: 4,014.91838
Overall Steps per Second: 3,321.66412

Timestep Collection Time: 12.45853
Timestep Consumption Time: 2.60018
PPO Batch Consumption Time: 0.06516
Total Iteration Time: 15.05872

Cumulative Model Updates: 44,494
Cumulative Timesteps: 742,187,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 742187162...
Checkpoint 742187162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,469.83500
Policy Entropy: 1.13418
Value Function Loss: 5.47123

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.13284

Collected Steps per Second: 3,983.60589
Overall Steps per Second: 3,256.07094

Timestep Collection Time: 12.56500
Timestep Consumption Time: 2.80752
PPO Batch Consumption Time: 0.06147
Total Iteration Time: 15.37252

Cumulative Model Updates: 44,497
Cumulative Timesteps: 742,237,216

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496,722.00498
Policy Entropy: 1.13404
Value Function Loss: 5.29675

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.07819
Value Function Update Magnitude: 0.11710

Collected Steps per Second: 3,963.99627
Overall Steps per Second: 3,310.51422

Timestep Collection Time: 12.62009
Timestep Consumption Time: 2.49116
PPO Batch Consumption Time: 0.06630
Total Iteration Time: 15.11125

Cumulative Model Updates: 44,500
Cumulative Timesteps: 742,287,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 742287242...
Checkpoint 742287242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,747.78158
Policy Entropy: 1.12361
Value Function Loss: 5.22033

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.07871
Value Function Update Magnitude: 0.10190

Collected Steps per Second: 4,021.76606
Overall Steps per Second: 3,294.29921

Timestep Collection Time: 12.43931
Timestep Consumption Time: 2.74692
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 15.18623

Cumulative Model Updates: 44,503
Cumulative Timesteps: 742,337,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,351.82198
Policy Entropy: 1.13826
Value Function Loss: 5.35189

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.06559
Value Function Update Magnitude: 0.08857

Collected Steps per Second: 4,072.44963
Overall Steps per Second: 3,305.32199

Timestep Collection Time: 12.27959
Timestep Consumption Time: 2.84995
PPO Batch Consumption Time: 0.05795
Total Iteration Time: 15.12954

Cumulative Model Updates: 44,506
Cumulative Timesteps: 742,387,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 742387278...
Checkpoint 742387278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,606.86784
Policy Entropy: 1.13438
Value Function Loss: 5.28296

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.07669

Collected Steps per Second: 4,083.89498
Overall Steps per Second: 3,339.20214

Timestep Collection Time: 12.24566
Timestep Consumption Time: 2.73097
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 14.97663

Cumulative Model Updates: 44,509
Cumulative Timesteps: 742,437,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,026.07418
Policy Entropy: 1.13438
Value Function Loss: 5.49183

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.06676
Value Function Update Magnitude: 0.07766

Collected Steps per Second: 4,215.77714
Overall Steps per Second: 3,440.24670

Timestep Collection Time: 11.86163
Timestep Consumption Time: 2.67395
PPO Batch Consumption Time: 0.07597
Total Iteration Time: 14.53559

Cumulative Model Updates: 44,512
Cumulative Timesteps: 742,487,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 742487294...
Checkpoint 742487294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,600.60724
Policy Entropy: 1.13831
Value Function Loss: 5.41040

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.07935

Collected Steps per Second: 4,080.70325
Overall Steps per Second: 3,411.96690

Timestep Collection Time: 12.25720
Timestep Consumption Time: 2.40238
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 14.65958

Cumulative Model Updates: 44,515
Cumulative Timesteps: 742,537,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,536.63289
Policy Entropy: 1.13848
Value Function Loss: 5.41509

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11051
Policy Update Magnitude: 0.06136
Value Function Update Magnitude: 0.08263

Collected Steps per Second: 4,238.43060
Overall Steps per Second: 3,488.45764

Timestep Collection Time: 11.80059
Timestep Consumption Time: 2.53697
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 14.33757

Cumulative Model Updates: 44,518
Cumulative Timesteps: 742,587,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 742587328...
Checkpoint 742587328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,019.24841
Policy Entropy: 1.14314
Value Function Loss: 5.25761

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.08041

Collected Steps per Second: 4,166.81506
Overall Steps per Second: 3,459.90645

Timestep Collection Time: 12.00341
Timestep Consumption Time: 2.45247
PPO Batch Consumption Time: 0.04977
Total Iteration Time: 14.45588

Cumulative Model Updates: 44,521
Cumulative Timesteps: 742,637,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,799.42411
Policy Entropy: 1.14303
Value Function Loss: 5.14192

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.07562
Value Function Update Magnitude: 0.08009

Collected Steps per Second: 4,364.16925
Overall Steps per Second: 3,545.75512

Timestep Collection Time: 11.46106
Timestep Consumption Time: 2.64539
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 14.10645

Cumulative Model Updates: 44,524
Cumulative Timesteps: 742,687,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 742687362...
Checkpoint 742687362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,446.81798
Policy Entropy: 1.14612
Value Function Loss: 5.19865

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.06885
Value Function Update Magnitude: 0.08206

Collected Steps per Second: 4,268.77963
Overall Steps per Second: 3,511.62571

Timestep Collection Time: 11.71951
Timestep Consumption Time: 2.52688
PPO Batch Consumption Time: 0.06954
Total Iteration Time: 14.24639

Cumulative Model Updates: 44,527
Cumulative Timesteps: 742,737,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,263.19490
Policy Entropy: 1.15452
Value Function Loss: 5.24092

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.09424

Collected Steps per Second: 4,325.66162
Overall Steps per Second: 4,079.16191

Timestep Collection Time: 11.55893
Timestep Consumption Time: 0.69849
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 12.25742

Cumulative Model Updates: 44,530
Cumulative Timesteps: 742,787,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 742787390...
Checkpoint 742787390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,472.39941
Policy Entropy: 1.15224
Value Function Loss: 5.33365

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.06631
Value Function Update Magnitude: 0.09512

Collected Steps per Second: 12,146.53342
Overall Steps per Second: 10,117.50458

Timestep Collection Time: 4.11755
Timestep Consumption Time: 0.82576
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 4.94331

Cumulative Model Updates: 44,533
Cumulative Timesteps: 742,837,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,526.43585
Policy Entropy: 1.15239
Value Function Loss: 5.53173

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.11110
Policy Update Magnitude: 0.07361
Value Function Update Magnitude: 0.09840

Collected Steps per Second: 12,026.04371
Overall Steps per Second: 10,354.40596

Timestep Collection Time: 4.15781
Timestep Consumption Time: 0.67125
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 4.82906

Cumulative Model Updates: 44,536
Cumulative Timesteps: 742,887,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 742887406...
Checkpoint 742887406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,998.64496
Policy Entropy: 1.14295
Value Function Loss: 5.56602

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.10333

Collected Steps per Second: 12,035.61981
Overall Steps per Second: 10,214.94632

Timestep Collection Time: 4.15483
Timestep Consumption Time: 0.74054
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 4.89538

Cumulative Model Updates: 44,539
Cumulative Timesteps: 742,937,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,063.68300
Policy Entropy: 1.15172
Value Function Loss: 5.48998

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.09433

Collected Steps per Second: 12,081.43056
Overall Steps per Second: 10,427.95439

Timestep Collection Time: 4.13958
Timestep Consumption Time: 0.65638
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.79595

Cumulative Model Updates: 44,542
Cumulative Timesteps: 742,987,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 742987424...
Checkpoint 742987424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,632.56356
Policy Entropy: 1.15191
Value Function Loss: 5.48197

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.06753
Value Function Update Magnitude: 0.08115

Collected Steps per Second: 12,024.65834
Overall Steps per Second: 10,204.86120

Timestep Collection Time: 4.16012
Timestep Consumption Time: 0.74186
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.90198

Cumulative Model Updates: 44,545
Cumulative Timesteps: 743,037,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,490.66440
Policy Entropy: 1.14588
Value Function Loss: 5.45663

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.07238
Value Function Update Magnitude: 0.07310

Collected Steps per Second: 12,052.67701
Overall Steps per Second: 10,213.43344

Timestep Collection Time: 4.15028
Timestep Consumption Time: 0.74739
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 4.89767

Cumulative Model Updates: 44,548
Cumulative Timesteps: 743,087,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 743087470...
Checkpoint 743087470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,228.38950
Policy Entropy: 1.14118
Value Function Loss: 5.40467

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.06793

Collected Steps per Second: 11,826.77662
Overall Steps per Second: 10,015.56239

Timestep Collection Time: 4.22922
Timestep Consumption Time: 0.76481
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.99403

Cumulative Model Updates: 44,551
Cumulative Timesteps: 743,137,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,014.40987
Policy Entropy: 1.14868
Value Function Loss: 5.07756

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.05531

Collected Steps per Second: 11,648.49529
Overall Steps per Second: 9,903.60406

Timestep Collection Time: 4.29240
Timestep Consumption Time: 0.75627
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.04867

Cumulative Model Updates: 44,554
Cumulative Timesteps: 743,187,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 743187488...
Checkpoint 743187488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,686.75053
Policy Entropy: 1.15070
Value Function Loss: 4.82179

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.05553

Collected Steps per Second: 11,796.46238
Overall Steps per Second: 10,012.35583

Timestep Collection Time: 4.24076
Timestep Consumption Time: 0.75566
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.99643

Cumulative Model Updates: 44,557
Cumulative Timesteps: 743,237,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,969.51893
Policy Entropy: 1.14975
Value Function Loss: 5.04922

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.06402
Value Function Update Magnitude: 0.06329

Collected Steps per Second: 12,136.30143
Overall Steps per Second: 10,263.19717

Timestep Collection Time: 4.12004
Timestep Consumption Time: 0.75193
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 4.87197

Cumulative Model Updates: 44,560
Cumulative Timesteps: 743,287,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 743287516...
Checkpoint 743287516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,322.51811
Policy Entropy: 1.15081
Value Function Loss: 5.18984

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.10941
Policy Update Magnitude: 0.06135
Value Function Update Magnitude: 0.07097

Collected Steps per Second: 11,700.85021
Overall Steps per Second: 9,894.48070

Timestep Collection Time: 4.27473
Timestep Consumption Time: 0.78041
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.05514

Cumulative Model Updates: 44,563
Cumulative Timesteps: 743,337,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,030.09443
Policy Entropy: 1.16124
Value Function Loss: 5.41712

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.07623

Collected Steps per Second: 11,501.73584
Overall Steps per Second: 9,937.81897

Timestep Collection Time: 4.34734
Timestep Consumption Time: 0.68414
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.03149

Cumulative Model Updates: 44,566
Cumulative Timesteps: 743,387,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 743387536...
Checkpoint 743387536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,953.09556
Policy Entropy: 1.16088
Value Function Loss: 5.26763

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.08359

Collected Steps per Second: 11,722.89245
Overall Steps per Second: 9,736.33053

Timestep Collection Time: 4.26567
Timestep Consumption Time: 0.87035
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.13602

Cumulative Model Updates: 44,569
Cumulative Timesteps: 743,437,542

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,565.51565
Policy Entropy: 1.16399
Value Function Loss: 5.14941

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.07950

Collected Steps per Second: 11,652.88886
Overall Steps per Second: 9,973.66769

Timestep Collection Time: 4.29130
Timestep Consumption Time: 0.72251
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.01380

Cumulative Model Updates: 44,572
Cumulative Timesteps: 743,487,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 743487548...
Checkpoint 743487548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,673.65769
Policy Entropy: 1.16439
Value Function Loss: 5.25812

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.10573
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.07781

Collected Steps per Second: 11,860.34570
Overall Steps per Second: 10,246.17886

Timestep Collection Time: 4.21792
Timestep Consumption Time: 0.66448
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 4.88241

Cumulative Model Updates: 44,575
Cumulative Timesteps: 743,537,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,190.16602
Policy Entropy: 1.16290
Value Function Loss: 5.22298

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.06214
Value Function Update Magnitude: 0.07901

Collected Steps per Second: 11,528.06555
Overall Steps per Second: 9,814.94192

Timestep Collection Time: 4.33932
Timestep Consumption Time: 0.75740
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.09672

Cumulative Model Updates: 44,578
Cumulative Timesteps: 743,587,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 743587598...
Checkpoint 743587598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,957.95114
Policy Entropy: 1.15990
Value Function Loss: 5.22811

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.06419
Value Function Update Magnitude: 0.08621

Collected Steps per Second: 11,686.98044
Overall Steps per Second: 9,997.46366

Timestep Collection Time: 4.27963
Timestep Consumption Time: 0.72323
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.00287

Cumulative Model Updates: 44,581
Cumulative Timesteps: 743,637,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,675.71715
Policy Entropy: 1.17375
Value Function Loss: 4.99737

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.08120

Collected Steps per Second: 11,812.63031
Overall Steps per Second: 10,015.68741

Timestep Collection Time: 4.23377
Timestep Consumption Time: 0.75959
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.99337

Cumulative Model Updates: 44,584
Cumulative Timesteps: 743,687,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 743687626...
Checkpoint 743687626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,539.95280
Policy Entropy: 1.17366
Value Function Loss: 4.88549

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.07779

Collected Steps per Second: 11,675.97132
Overall Steps per Second: 9,811.92753

Timestep Collection Time: 4.28384
Timestep Consumption Time: 0.81383
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.09767

Cumulative Model Updates: 44,587
Cumulative Timesteps: 743,737,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,106.38808
Policy Entropy: 1.16555
Value Function Loss: 4.99667

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.07081

Collected Steps per Second: 11,685.45472
Overall Steps per Second: 10,036.18744

Timestep Collection Time: 4.27899
Timestep Consumption Time: 0.70318
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.98217

Cumulative Model Updates: 44,590
Cumulative Timesteps: 743,787,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 743787646...
Checkpoint 743787646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,563.42957
Policy Entropy: 1.16909
Value Function Loss: 4.89698

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.07484

Collected Steps per Second: 11,577.60469
Overall Steps per Second: 9,758.42931

Timestep Collection Time: 4.31903
Timestep Consumption Time: 0.80516
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.12419

Cumulative Model Updates: 44,593
Cumulative Timesteps: 743,837,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,406.58041
Policy Entropy: 1.17638
Value Function Loss: 4.80294

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.06921

Collected Steps per Second: 11,852.88594
Overall Steps per Second: 10,008.01906

Timestep Collection Time: 4.22058
Timestep Consumption Time: 0.77802
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.99859

Cumulative Model Updates: 44,596
Cumulative Timesteps: 743,887,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 743887676...
Checkpoint 743887676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,667.52872
Policy Entropy: 1.17735
Value Function Loss: 4.61015

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.06575

Collected Steps per Second: 11,881.84731
Overall Steps per Second: 9,937.13441

Timestep Collection Time: 4.20978
Timestep Consumption Time: 0.82386
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 5.03364

Cumulative Model Updates: 44,599
Cumulative Timesteps: 743,937,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,705.67934
Policy Entropy: 1.16486
Value Function Loss: 4.64649

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.06491

Collected Steps per Second: 11,750.74655
Overall Steps per Second: 9,962.52695

Timestep Collection Time: 4.25505
Timestep Consumption Time: 0.76376
PPO Batch Consumption Time: 0.03352
Total Iteration Time: 5.01881

Cumulative Model Updates: 44,602
Cumulative Timesteps: 743,987,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 743987696...
Checkpoint 743987696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,588.26611
Policy Entropy: 1.17136
Value Function Loss: 4.63145

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.06846

Collected Steps per Second: 11,637.30168
Overall Steps per Second: 9,830.76476

Timestep Collection Time: 4.29893
Timestep Consumption Time: 0.78999
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.08892

Cumulative Model Updates: 44,605
Cumulative Timesteps: 744,037,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,140.79282
Policy Entropy: 1.16967
Value Function Loss: 4.70892

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.06521

Collected Steps per Second: 12,412.92855
Overall Steps per Second: 10,284.61259

Timestep Collection Time: 4.02870
Timestep Consumption Time: 0.83371
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.86241

Cumulative Model Updates: 44,608
Cumulative Timesteps: 744,087,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 744087732...
Checkpoint 744087732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,137.61940
Policy Entropy: 1.15172
Value Function Loss: 4.71860

Mean KL Divergence: 0.02995
SB3 Clip Fraction: 0.15112
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.06869

Collected Steps per Second: 12,231.57513
Overall Steps per Second: 10,265.47237

Timestep Collection Time: 4.08974
Timestep Consumption Time: 0.78329
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 4.87303

Cumulative Model Updates: 44,611
Cumulative Timesteps: 744,137,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,935.26500
Policy Entropy: 1.16701
Value Function Loss: 4.78739

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.11382
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.06446

Collected Steps per Second: 12,870.17977
Overall Steps per Second: 10,798.31425

Timestep Collection Time: 3.88635
Timestep Consumption Time: 0.74567
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.63202

Cumulative Model Updates: 44,614
Cumulative Timesteps: 744,187,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 744187774...
Checkpoint 744187774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,336.30724
Policy Entropy: 1.16305
Value Function Loss: 4.72776

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 12,450.47087
Overall Steps per Second: 10,488.77771

Timestep Collection Time: 4.01736
Timestep Consumption Time: 0.75136
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 4.76872

Cumulative Model Updates: 44,617
Cumulative Timesteps: 744,237,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,528.21406
Policy Entropy: 1.15935
Value Function Loss: 4.78234

Mean KL Divergence: 0.02676
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.07472

Collected Steps per Second: 12,335.85038
Overall Steps per Second: 10,516.34355

Timestep Collection Time: 4.05517
Timestep Consumption Time: 0.70161
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.75679

Cumulative Model Updates: 44,620
Cumulative Timesteps: 744,287,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 744287816...
Checkpoint 744287816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,007.51934
Policy Entropy: 1.15409
Value Function Loss: 4.76428

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.07432

Collected Steps per Second: 12,405.91725
Overall Steps per Second: 10,352.92743

Timestep Collection Time: 4.03275
Timestep Consumption Time: 0.79970
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.83245

Cumulative Model Updates: 44,623
Cumulative Timesteps: 744,337,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,674.10932
Policy Entropy: 1.15458
Value Function Loss: 4.72422

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.07639

Collected Steps per Second: 11,281.85898
Overall Steps per Second: 9,568.13702

Timestep Collection Time: 4.43207
Timestep Consumption Time: 0.79382
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.22589

Cumulative Model Updates: 44,626
Cumulative Timesteps: 744,387,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 744387848...
Checkpoint 744387848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,823.56454
Policy Entropy: 1.15683
Value Function Loss: 4.54958

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.07969

Collected Steps per Second: 11,695.88565
Overall Steps per Second: 9,899.19847

Timestep Collection Time: 4.27740
Timestep Consumption Time: 0.77634
PPO Batch Consumption Time: 0.03844
Total Iteration Time: 5.05374

Cumulative Model Updates: 44,629
Cumulative Timesteps: 744,437,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,279.05034
Policy Entropy: 1.13656
Value Function Loss: 4.33719

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.10322

Collected Steps per Second: 11,650.06501
Overall Steps per Second: 9,936.89304

Timestep Collection Time: 4.29337
Timestep Consumption Time: 0.74020
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 5.03357

Cumulative Model Updates: 44,632
Cumulative Timesteps: 744,487,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 744487894...
Checkpoint 744487894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383,726.86726
Policy Entropy: 1.12954
Value Function Loss: 4.31462

Mean KL Divergence: 0.02788
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.09643

Collected Steps per Second: 11,530.49132
Overall Steps per Second: 9,943.07478

Timestep Collection Time: 4.33841
Timestep Consumption Time: 0.69263
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.03104

Cumulative Model Updates: 44,635
Cumulative Timesteps: 744,537,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,625.46290
Policy Entropy: 1.13631
Value Function Loss: 4.52329

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.08282

Collected Steps per Second: 11,704.63215
Overall Steps per Second: 9,929.16122

Timestep Collection Time: 4.27318
Timestep Consumption Time: 0.76410
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 5.03728

Cumulative Model Updates: 44,638
Cumulative Timesteps: 744,587,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 744587934...
Checkpoint 744587934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,284.32809
Policy Entropy: 1.14405
Value Function Loss: 4.68831

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.08618

Collected Steps per Second: 11,423.36733
Overall Steps per Second: 9,626.57994

Timestep Collection Time: 4.37787
Timestep Consumption Time: 0.81712
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.19499

Cumulative Model Updates: 44,641
Cumulative Timesteps: 744,637,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,074.40013
Policy Entropy: 1.11489
Value Function Loss: 4.71944

Mean KL Divergence: 0.04306
SB3 Clip Fraction: 0.19345
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 11,650.10123
Overall Steps per Second: 9,866.25872

Timestep Collection Time: 4.29181
Timestep Consumption Time: 0.77597
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.06778

Cumulative Model Updates: 44,644
Cumulative Timesteps: 744,687,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 744687944...
Checkpoint 744687944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,085.56595
Policy Entropy: 1.13143
Value Function Loss: 4.73264

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.07773

Collected Steps per Second: 11,769.03657
Overall Steps per Second: 10,007.68751

Timestep Collection Time: 4.25065
Timestep Consumption Time: 0.74811
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.99876

Cumulative Model Updates: 44,647
Cumulative Timesteps: 744,737,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,148.65726
Policy Entropy: 1.13011
Value Function Loss: 4.88572

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.07505

Collected Steps per Second: 11,624.74712
Overall Steps per Second: 10,077.12100

Timestep Collection Time: 4.30289
Timestep Consumption Time: 0.66083
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.96372

Cumulative Model Updates: 44,650
Cumulative Timesteps: 744,787,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 744787990...
Checkpoint 744787990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,277.40193
Policy Entropy: 1.12227
Value Function Loss: 4.87794

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.07806

Collected Steps per Second: 11,620.61805
Overall Steps per Second: 9,885.11714

Timestep Collection Time: 4.30407
Timestep Consumption Time: 0.75565
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 5.05973

Cumulative Model Updates: 44,653
Cumulative Timesteps: 744,838,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592,150.09716
Policy Entropy: 1.11146
Value Function Loss: 4.68324

Mean KL Divergence: 0.02521
SB3 Clip Fraction: 0.15656
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.08203

Collected Steps per Second: 11,676.23840
Overall Steps per Second: 10,108.89045

Timestep Collection Time: 4.28391
Timestep Consumption Time: 0.66421
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.94812

Cumulative Model Updates: 44,656
Cumulative Timesteps: 744,888,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 744888026...
Checkpoint 744888026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,728.32451
Policy Entropy: 1.12331
Value Function Loss: 4.42076

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.08945

Collected Steps per Second: 11,521.58561
Overall Steps per Second: 9,709.35592

Timestep Collection Time: 4.34194
Timestep Consumption Time: 0.81041
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.15235

Cumulative Model Updates: 44,659
Cumulative Timesteps: 744,938,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519,779.09309
Policy Entropy: 1.12986
Value Function Loss: 4.45212

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.08944

Collected Steps per Second: 11,626.21428
Overall Steps per Second: 9,797.88156

Timestep Collection Time: 4.30097
Timestep Consumption Time: 0.80258
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.10355

Cumulative Model Updates: 44,662
Cumulative Timesteps: 744,988,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 744988056...
Checkpoint 744988056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,272.56153
Policy Entropy: 1.11351
Value Function Loss: 4.49855

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.09579

Collected Steps per Second: 11,476.41079
Overall Steps per Second: 9,909.45968

Timestep Collection Time: 4.35816
Timestep Consumption Time: 0.68914
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.04730

Cumulative Model Updates: 44,665
Cumulative Timesteps: 745,038,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,197.33620
Policy Entropy: 1.10470
Value Function Loss: 4.50305

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.09443

Collected Steps per Second: 11,638.72466
Overall Steps per Second: 9,815.91778

Timestep Collection Time: 4.29669
Timestep Consumption Time: 0.79789
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 5.09458

Cumulative Model Updates: 44,668
Cumulative Timesteps: 745,088,080

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 745088080...
Checkpoint 745088080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,373.79318
Policy Entropy: 1.11186
Value Function Loss: 4.39990

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.10267

Collected Steps per Second: 11,744.29444
Overall Steps per Second: 9,964.56585

Timestep Collection Time: 4.25926
Timestep Consumption Time: 0.76073
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.01999

Cumulative Model Updates: 44,671
Cumulative Timesteps: 745,138,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,237.97586
Policy Entropy: 1.11473
Value Function Loss: 4.52097

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.09738

Collected Steps per Second: 10,178.94556
Overall Steps per Second: 8,653.33163

Timestep Collection Time: 4.91269
Timestep Consumption Time: 0.86613
PPO Batch Consumption Time: 0.04311
Total Iteration Time: 5.77881

Cumulative Model Updates: 44,674
Cumulative Timesteps: 745,188,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 745188108...
Checkpoint 745188108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,227.57029
Policy Entropy: 1.10864
Value Function Loss: 4.59900

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.08281

Collected Steps per Second: 9,837.31652
Overall Steps per Second: 8,511.47459

Timestep Collection Time: 5.08492
Timestep Consumption Time: 0.79208
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.87701

Cumulative Model Updates: 44,677
Cumulative Timesteps: 745,238,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,469.31524
Policy Entropy: 1.10145
Value Function Loss: 4.67849

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.14903
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.07677

Collected Steps per Second: 11,107.65707
Overall Steps per Second: 9,647.19582

Timestep Collection Time: 4.50230
Timestep Consumption Time: 0.68159
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.18389

Cumulative Model Updates: 44,680
Cumulative Timesteps: 745,288,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 745288140...
Checkpoint 745288140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,880.17834
Policy Entropy: 1.10838
Value Function Loss: 4.52340

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.07523

Collected Steps per Second: 11,104.23907
Overall Steps per Second: 9,414.06118

Timestep Collection Time: 4.50441
Timestep Consumption Time: 0.80871
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.31312

Cumulative Model Updates: 44,683
Cumulative Timesteps: 745,338,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,652.81662
Policy Entropy: 1.12179
Value Function Loss: 4.62309

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.07676

Collected Steps per Second: 10,537.13874
Overall Steps per Second: 9,103.41384

Timestep Collection Time: 4.74664
Timestep Consumption Time: 0.74756
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.49420

Cumulative Model Updates: 44,686
Cumulative Timesteps: 745,388,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 745388174...
Checkpoint 745388174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,995.28934
Policy Entropy: 1.09801
Value Function Loss: 4.49058

Mean KL Divergence: 0.02995
SB3 Clip Fraction: 0.16565
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.07385

Collected Steps per Second: 11,042.64625
Overall Steps per Second: 9,527.00430

Timestep Collection Time: 4.52808
Timestep Consumption Time: 0.72037
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.24845

Cumulative Model Updates: 44,689
Cumulative Timesteps: 745,438,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,243.64393
Policy Entropy: 1.11950
Value Function Loss: 4.75640

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 11,078.60622
Overall Steps per Second: 9,442.18964

Timestep Collection Time: 4.51573
Timestep Consumption Time: 0.78262
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.29835

Cumulative Model Updates: 44,692
Cumulative Timesteps: 745,488,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 745488204...
Checkpoint 745488204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,188.34409
Policy Entropy: 1.11975
Value Function Loss: 4.51717

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.07333

Collected Steps per Second: 10,355.20763
Overall Steps per Second: 8,952.84882

Timestep Collection Time: 4.83139
Timestep Consumption Time: 0.75678
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.58817

Cumulative Model Updates: 44,695
Cumulative Timesteps: 745,538,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,326.00608
Policy Entropy: 1.10727
Value Function Loss: 4.34116

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.08557

Collected Steps per Second: 10,937.40364
Overall Steps per Second: 9,349.57683

Timestep Collection Time: 4.57257
Timestep Consumption Time: 0.77655
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.34912

Cumulative Model Updates: 44,698
Cumulative Timesteps: 745,588,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 745588246...
Checkpoint 745588246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,897.95242
Policy Entropy: 1.10217
Value Function Loss: 4.08898

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.09970

Collected Steps per Second: 10,981.67022
Overall Steps per Second: 9,338.94006

Timestep Collection Time: 4.55322
Timestep Consumption Time: 0.80092
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.35414

Cumulative Model Updates: 44,701
Cumulative Timesteps: 745,638,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,535.79760
Policy Entropy: 1.11294
Value Function Loss: 4.23432

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.11183

Collected Steps per Second: 10,617.91848
Overall Steps per Second: 9,194.01033

Timestep Collection Time: 4.70996
Timestep Consumption Time: 0.72945
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.43941

Cumulative Model Updates: 44,704
Cumulative Timesteps: 745,688,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 745688258...
Checkpoint 745688258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,753.46705
Policy Entropy: 1.11054
Value Function Loss: 4.56742

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.11469

Collected Steps per Second: 10,743.47991
Overall Steps per Second: 9,197.79710

Timestep Collection Time: 4.65547
Timestep Consumption Time: 0.78235
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.43782

Cumulative Model Updates: 44,707
Cumulative Timesteps: 745,738,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566,235.83408
Policy Entropy: 1.10091
Value Function Loss: 4.53446

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.10759

Collected Steps per Second: 11,033.47549
Overall Steps per Second: 9,486.27685

Timestep Collection Time: 4.53257
Timestep Consumption Time: 0.73926
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.27183

Cumulative Model Updates: 44,710
Cumulative Timesteps: 745,788,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 745788284...
Checkpoint 745788284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,929.39583
Policy Entropy: 1.08921
Value Function Loss: 4.41206

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.10200

Collected Steps per Second: 11,646.56516
Overall Steps per Second: 10,012.63748

Timestep Collection Time: 4.29552
Timestep Consumption Time: 0.70097
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.99649

Cumulative Model Updates: 44,713
Cumulative Timesteps: 745,838,312

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,268.96887
Policy Entropy: 1.11415
Value Function Loss: 4.44429

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.10867

Collected Steps per Second: 11,395.55223
Overall Steps per Second: 9,709.82999

Timestep Collection Time: 4.38803
Timestep Consumption Time: 0.76180
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.14983

Cumulative Model Updates: 44,716
Cumulative Timesteps: 745,888,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 745888316...
Checkpoint 745888316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,348.68092
Policy Entropy: 1.10924
Value Function Loss: 4.50243

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.09292

Collected Steps per Second: 11,647.62524
Overall Steps per Second: 9,977.77583

Timestep Collection Time: 4.29409
Timestep Consumption Time: 0.71865
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 5.01274

Cumulative Model Updates: 44,719
Cumulative Timesteps: 745,938,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,116.58377
Policy Entropy: 1.10524
Value Function Loss: 4.68389

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.08372

Collected Steps per Second: 11,925.76660
Overall Steps per Second: 10,104.52940

Timestep Collection Time: 4.19277
Timestep Consumption Time: 0.75570
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 4.94847

Cumulative Model Updates: 44,722
Cumulative Timesteps: 745,988,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 745988334...
Checkpoint 745988334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,629.72965
Policy Entropy: 1.09792
Value Function Loss: 4.55233

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.08037

Collected Steps per Second: 11,619.51745
Overall Steps per Second: 9,844.77857

Timestep Collection Time: 4.30603
Timestep Consumption Time: 0.77626
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.08229

Cumulative Model Updates: 44,725
Cumulative Timesteps: 746,038,368

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,345.97513
Policy Entropy: 1.10091
Value Function Loss: 4.76446

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.08135

Collected Steps per Second: 11,232.52485
Overall Steps per Second: 9,766.86758

Timestep Collection Time: 4.45350
Timestep Consumption Time: 0.66831
PPO Batch Consumption Time: 0.03361
Total Iteration Time: 5.12181

Cumulative Model Updates: 44,728
Cumulative Timesteps: 746,088,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 746088392...
Checkpoint 746088392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,450.05605
Policy Entropy: 1.10701
Value Function Loss: 4.54735

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.07377

Collected Steps per Second: 11,604.56906
Overall Steps per Second: 9,844.00826

Timestep Collection Time: 4.30934
Timestep Consumption Time: 0.77071
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.08004

Cumulative Model Updates: 44,731
Cumulative Timesteps: 746,138,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,443.39522
Policy Entropy: 1.07818
Value Function Loss: 4.50747

Mean KL Divergence: 0.03217
SB3 Clip Fraction: 0.17416
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.07209

Collected Steps per Second: 11,544.52482
Overall Steps per Second: 9,806.81200

Timestep Collection Time: 4.33175
Timestep Consumption Time: 0.76756
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.09931

Cumulative Model Updates: 44,734
Cumulative Timesteps: 746,188,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 746188408...
Checkpoint 746188408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,844.13736
Policy Entropy: 1.09734
Value Function Loss: 4.26278

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.11590
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.07576

Collected Steps per Second: 11,852.63435
Overall Steps per Second: 10,022.10732

Timestep Collection Time: 4.21898
Timestep Consumption Time: 0.77059
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 4.98957

Cumulative Model Updates: 44,737
Cumulative Timesteps: 746,238,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,714.63761
Policy Entropy: 1.09995
Value Function Loss: 4.54289

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.07517

Collected Steps per Second: 11,865.89292
Overall Steps per Second: 9,994.28222

Timestep Collection Time: 4.21578
Timestep Consumption Time: 0.78948
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.00526

Cumulative Model Updates: 44,740
Cumulative Timesteps: 746,288,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 746288438...
Checkpoint 746288438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,564.32599
Policy Entropy: 1.08655
Value Function Loss: 4.50826

Mean KL Divergence: 0.02767
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 11,771.14944
Overall Steps per Second: 9,952.70228

Timestep Collection Time: 4.24920
Timestep Consumption Time: 0.77637
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.02557

Cumulative Model Updates: 44,743
Cumulative Timesteps: 746,338,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,053.22029
Policy Entropy: 1.09702
Value Function Loss: 4.44692

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.06805

Collected Steps per Second: 11,091.29540
Overall Steps per Second: 9,495.50027

Timestep Collection Time: 4.50804
Timestep Consumption Time: 0.75761
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 5.26565

Cumulative Model Updates: 44,746
Cumulative Timesteps: 746,388,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 746388456...
Checkpoint 746388456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,362.74974
Policy Entropy: 1.09090
Value Function Loss: 4.41325

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.07153

Collected Steps per Second: 12,125.50582
Overall Steps per Second: 10,380.55348

Timestep Collection Time: 4.12585
Timestep Consumption Time: 0.69355
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 4.81940

Cumulative Model Updates: 44,749
Cumulative Timesteps: 746,438,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,130.41025
Policy Entropy: 1.10027
Value Function Loss: 4.52514

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.07854

Collected Steps per Second: 12,308.48667
Overall Steps per Second: 10,274.14838

Timestep Collection Time: 4.06403
Timestep Consumption Time: 0.80470
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.86872

Cumulative Model Updates: 44,752
Cumulative Timesteps: 746,488,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 746488506...
Checkpoint 746488506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,218.36737
Policy Entropy: 1.08423
Value Function Loss: 4.39048

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.07125

Collected Steps per Second: 12,290.20240
Overall Steps per Second: 10,507.03083

Timestep Collection Time: 4.06958
Timestep Consumption Time: 0.69066
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.76024

Cumulative Model Updates: 44,755
Cumulative Timesteps: 746,538,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,381.52713
Policy Entropy: 1.08109
Value Function Loss: 4.40607

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.06730

Collected Steps per Second: 12,425.65465
Overall Steps per Second: 10,441.46923

Timestep Collection Time: 4.02603
Timestep Consumption Time: 0.76506
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 4.79109

Cumulative Model Updates: 44,758
Cumulative Timesteps: 746,588,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 746588548...
Checkpoint 746588548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,652.13938
Policy Entropy: 1.09322
Value Function Loss: 4.38614

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.07029

Collected Steps per Second: 11,255.73983
Overall Steps per Second: 9,644.37500

Timestep Collection Time: 4.44236
Timestep Consumption Time: 0.74222
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.18458

Cumulative Model Updates: 44,761
Cumulative Timesteps: 746,638,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,219.33835
Policy Entropy: 1.09391
Value Function Loss: 4.52673

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.08006

Collected Steps per Second: 11,131.21668
Overall Steps per Second: 9,497.68093

Timestep Collection Time: 4.49439
Timestep Consumption Time: 0.77300
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.26739

Cumulative Model Updates: 44,764
Cumulative Timesteps: 746,688,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 746688578...
Checkpoint 746688578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,424.58785
Policy Entropy: 1.08398
Value Function Loss: 4.47624

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.08199

Collected Steps per Second: 11,478.08233
Overall Steps per Second: 9,730.85107

Timestep Collection Time: 4.35665
Timestep Consumption Time: 0.78226
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.13891

Cumulative Model Updates: 44,767
Cumulative Timesteps: 746,738,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,616.41520
Policy Entropy: 1.08307
Value Function Loss: 4.48170

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.08025

Collected Steps per Second: 11,754.88000
Overall Steps per Second: 10,133.42539

Timestep Collection Time: 4.25610
Timestep Consumption Time: 0.68102
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.93713

Cumulative Model Updates: 44,770
Cumulative Timesteps: 746,788,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 746788614...
Checkpoint 746788614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,067.13983
Policy Entropy: 1.08794
Value Function Loss: 4.54933

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.09064

Collected Steps per Second: 11,534.51910
Overall Steps per Second: 9,792.47691

Timestep Collection Time: 4.33585
Timestep Consumption Time: 0.77133
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.10719

Cumulative Model Updates: 44,773
Cumulative Timesteps: 746,838,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,454.82215
Policy Entropy: 1.09513
Value Function Loss: 4.51305

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.08435

Collected Steps per Second: 11,564.48412
Overall Steps per Second: 9,971.11687

Timestep Collection Time: 4.32358
Timestep Consumption Time: 0.69090
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.01448

Cumulative Model Updates: 44,776
Cumulative Timesteps: 746,888,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 746888626...
Checkpoint 746888626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,266.52742
Policy Entropy: 1.07930
Value Function Loss: 4.35887

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.07849

Collected Steps per Second: 11,669.69639
Overall Steps per Second: 9,771.41739

Timestep Collection Time: 4.28477
Timestep Consumption Time: 0.83240
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.11717

Cumulative Model Updates: 44,779
Cumulative Timesteps: 746,938,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,592.89709
Policy Entropy: 1.09161
Value Function Loss: 4.38487

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.07909

Collected Steps per Second: 11,157.27553
Overall Steps per Second: 9,705.07644

Timestep Collection Time: 4.48246
Timestep Consumption Time: 0.67072
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.15318

Cumulative Model Updates: 44,782
Cumulative Timesteps: 746,988,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 746988640...
Checkpoint 746988640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,176.14331
Policy Entropy: 1.08796
Value Function Loss: 4.58833

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.08669

Collected Steps per Second: 11,758.60157
Overall Steps per Second: 9,956.18340

Timestep Collection Time: 4.25408
Timestep Consumption Time: 0.77014
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.02421

Cumulative Model Updates: 44,785
Cumulative Timesteps: 747,038,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,972.76720
Policy Entropy: 1.07403
Value Function Loss: 4.81624

Mean KL Divergence: 0.02567
SB3 Clip Fraction: 0.15445
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.07895

Collected Steps per Second: 11,527.83433
Overall Steps per Second: 9,718.30141

Timestep Collection Time: 4.33785
Timestep Consumption Time: 0.80770
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 5.14555

Cumulative Model Updates: 44,788
Cumulative Timesteps: 747,088,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 747088668...
Checkpoint 747088668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,257.84181
Policy Entropy: 1.07404
Value Function Loss: 4.63985

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.15147
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.07230

Collected Steps per Second: 11,624.57192
Overall Steps per Second: 9,973.41499

Timestep Collection Time: 4.30313
Timestep Consumption Time: 0.71241
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.01553

Cumulative Model Updates: 44,791
Cumulative Timesteps: 747,138,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,192.68956
Policy Entropy: 1.08325
Value Function Loss: 4.37386

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.08148

Collected Steps per Second: 12,036.18878
Overall Steps per Second: 10,077.92575

Timestep Collection Time: 4.15414
Timestep Consumption Time: 0.80720
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.96134

Cumulative Model Updates: 44,794
Cumulative Timesteps: 747,188,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 747188690...
Checkpoint 747188690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,510.13514
Policy Entropy: 1.09430
Value Function Loss: 4.28549

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.07594

Collected Steps per Second: 11,877.36958
Overall Steps per Second: 10,131.92188

Timestep Collection Time: 4.20969
Timestep Consumption Time: 0.72521
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.93490

Cumulative Model Updates: 44,797
Cumulative Timesteps: 747,238,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,069.27918
Policy Entropy: 1.06496
Value Function Loss: 4.41564

Mean KL Divergence: 0.03470
SB3 Clip Fraction: 0.16345
Policy Update Magnitude: 0.07078
Value Function Update Magnitude: 0.07722

Collected Steps per Second: 11,466.56547
Overall Steps per Second: 9,720.63562

Timestep Collection Time: 4.36138
Timestep Consumption Time: 0.78335
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.14473

Cumulative Model Updates: 44,800
Cumulative Timesteps: 747,288,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 747288700...
Checkpoint 747288700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,125.88707
Policy Entropy: 1.08418
Value Function Loss: 4.51950

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.07515

Collected Steps per Second: 11,709.59913
Overall Steps per Second: 9,971.94300

Timestep Collection Time: 4.27171
Timestep Consumption Time: 0.74436
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.01607

Cumulative Model Updates: 44,803
Cumulative Timesteps: 747,338,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,502.11294
Policy Entropy: 1.08746
Value Function Loss: 4.39246

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.07772

Collected Steps per Second: 12,080.64695
Overall Steps per Second: 10,176.18903

Timestep Collection Time: 4.14133
Timestep Consumption Time: 0.77504
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 4.91638

Cumulative Model Updates: 44,806
Cumulative Timesteps: 747,388,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 747388750...
Checkpoint 747388750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,260.52897
Policy Entropy: 1.07699
Value Function Loss: 4.28106

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.08078

Collected Steps per Second: 11,726.37493
Overall Steps per Second: 9,943.76529

Timestep Collection Time: 4.26628
Timestep Consumption Time: 0.76481
PPO Batch Consumption Time: 0.03381
Total Iteration Time: 5.03109

Cumulative Model Updates: 44,809
Cumulative Timesteps: 747,438,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,454.93301
Policy Entropy: 1.06133
Value Function Loss: 4.14533

Mean KL Divergence: 0.02793
SB3 Clip Fraction: 0.16279
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.07852

Collected Steps per Second: 11,784.95353
Overall Steps per Second: 10,153.78239

Timestep Collection Time: 4.24473
Timestep Consumption Time: 0.68190
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.92664

Cumulative Model Updates: 44,812
Cumulative Timesteps: 747,488,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 747488802...
Checkpoint 747488802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,193.00982
Policy Entropy: 1.07649
Value Function Loss: 4.55903

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 11,652.21907
Overall Steps per Second: 9,842.51136

Timestep Collection Time: 4.29292
Timestep Consumption Time: 0.78932
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.08224

Cumulative Model Updates: 44,815
Cumulative Timesteps: 747,538,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,923.46957
Policy Entropy: 1.07900
Value Function Loss: 4.57896

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.10274

Collected Steps per Second: 11,009.18303
Overall Steps per Second: 9,491.58702

Timestep Collection Time: 4.54366
Timestep Consumption Time: 0.72648
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.27014

Cumulative Model Updates: 44,818
Cumulative Timesteps: 747,588,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 747588846...
Checkpoint 747588846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,926.45566
Policy Entropy: 1.06533
Value Function Loss: 4.64792

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.06191
Value Function Update Magnitude: 0.10416

Collected Steps per Second: 11,636.48153
Overall Steps per Second: 10,071.99361

Timestep Collection Time: 4.29855
Timestep Consumption Time: 0.66770
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.96625

Cumulative Model Updates: 44,821
Cumulative Timesteps: 747,638,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,154.06998
Policy Entropy: 1.06989
Value Function Loss: 4.42197

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.08806

Collected Steps per Second: 11,281.72359
Overall Steps per Second: 9,587.98763

Timestep Collection Time: 4.43283
Timestep Consumption Time: 0.78307
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.21590

Cumulative Model Updates: 44,824
Cumulative Timesteps: 747,688,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 747688876...
Checkpoint 747688876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,934.16376
Policy Entropy: 1.07477
Value Function Loss: 4.68104

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.08564

Collected Steps per Second: 11,978.16843
Overall Steps per Second: 10,201.17007

Timestep Collection Time: 4.17476
Timestep Consumption Time: 0.72722
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 4.90199

Cumulative Model Updates: 44,827
Cumulative Timesteps: 747,738,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,714.64484
Policy Entropy: 1.08388
Value Function Loss: 4.70349

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.08479

Collected Steps per Second: 11,883.68053
Overall Steps per Second: 10,103.57222

Timestep Collection Time: 4.20762
Timestep Consumption Time: 0.74132
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.94894

Cumulative Model Updates: 44,830
Cumulative Timesteps: 747,788,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 747788884...
Checkpoint 747788884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,389.60165
Policy Entropy: 1.07817
Value Function Loss: 4.70135

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.07075
Value Function Update Magnitude: 0.08429

Collected Steps per Second: 11,625.17853
Overall Steps per Second: 9,889.72475

Timestep Collection Time: 4.30307
Timestep Consumption Time: 0.75511
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.05818

Cumulative Model Updates: 44,833
Cumulative Timesteps: 747,838,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,092.87855
Policy Entropy: 1.07128
Value Function Loss: 4.70988

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.07053
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 11,358.17763
Overall Steps per Second: 9,841.07698

Timestep Collection Time: 4.40370
Timestep Consumption Time: 0.67887
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.08257

Cumulative Model Updates: 44,836
Cumulative Timesteps: 747,888,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 747888926...
Checkpoint 747888926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,260.59515
Policy Entropy: 1.09573
Value Function Loss: 4.83407

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.15436
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.08056

Collected Steps per Second: 11,512.48772
Overall Steps per Second: 9,804.26156

Timestep Collection Time: 4.34415
Timestep Consumption Time: 0.75689
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.10105

Cumulative Model Updates: 44,839
Cumulative Timesteps: 747,938,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,531.94115
Policy Entropy: 1.09664
Value Function Loss: 5.05360

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.07285

Collected Steps per Second: 11,434.84011
Overall Steps per Second: 9,748.34071

Timestep Collection Time: 4.37313
Timestep Consumption Time: 0.75657
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 5.12969

Cumulative Model Updates: 44,842
Cumulative Timesteps: 747,988,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 747988944...
Checkpoint 747988944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,399.70655
Policy Entropy: 1.08778
Value Function Loss: 5.08154

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.07312

Collected Steps per Second: 11,454.73929
Overall Steps per Second: 9,878.15748

Timestep Collection Time: 4.36658
Timestep Consumption Time: 0.69692
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.06349

Cumulative Model Updates: 44,845
Cumulative Timesteps: 748,038,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,514.90001
Policy Entropy: 1.06985
Value Function Loss: 5.02896

Mean KL Divergence: 0.02716
SB3 Clip Fraction: 0.15578
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 11,672.30297
Overall Steps per Second: 9,849.46048

Timestep Collection Time: 4.28399
Timestep Consumption Time: 0.79284
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.07683

Cumulative Model Updates: 44,848
Cumulative Timesteps: 748,088,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 748088966...
Checkpoint 748088966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,196.59618
Policy Entropy: 1.07849
Value Function Loss: 4.90952

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.07672

Collected Steps per Second: 10,425.05803
Overall Steps per Second: 8,968.68157

Timestep Collection Time: 4.79921
Timestep Consumption Time: 0.77932
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.57852

Cumulative Model Updates: 44,851
Cumulative Timesteps: 748,138,998

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,606.92435
Policy Entropy: 1.08824
Value Function Loss: 5.03718

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.06023
Value Function Update Magnitude: 0.09635

Collected Steps per Second: 10,354.24188
Overall Steps per Second: 8,957.16050

Timestep Collection Time: 4.83106
Timestep Consumption Time: 0.75352
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.58458

Cumulative Model Updates: 44,854
Cumulative Timesteps: 748,189,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 748189020...
Checkpoint 748189020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,164.36172
Policy Entropy: 1.06397
Value Function Loss: 5.07186

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.10629

Collected Steps per Second: 10,396.82418
Overall Steps per Second: 8,963.85378

Timestep Collection Time: 4.81012
Timestep Consumption Time: 0.76895
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.57907

Cumulative Model Updates: 44,857
Cumulative Timesteps: 748,239,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,869.36071
Policy Entropy: 1.06461
Value Function Loss: 4.88466

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.10637

Collected Steps per Second: 10,275.13397
Overall Steps per Second: 8,993.16500

Timestep Collection Time: 4.86612
Timestep Consumption Time: 0.69366
PPO Batch Consumption Time: 0.03825
Total Iteration Time: 5.55978

Cumulative Model Updates: 44,860
Cumulative Timesteps: 748,289,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 748289030...
Checkpoint 748289030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,048.90848
Policy Entropy: 1.07627
Value Function Loss: 4.51602

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.10963

Collected Steps per Second: 10,386.16041
Overall Steps per Second: 8,951.07343

Timestep Collection Time: 4.81448
Timestep Consumption Time: 0.77189
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.58637

Cumulative Model Updates: 44,863
Cumulative Timesteps: 748,339,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,453.02123
Policy Entropy: 1.08480
Value Function Loss: 4.50657

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.11446

Collected Steps per Second: 10,728.60248
Overall Steps per Second: 9,238.98937

Timestep Collection Time: 4.66212
Timestep Consumption Time: 0.75168
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.41380

Cumulative Model Updates: 44,866
Cumulative Timesteps: 748,389,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 748389052...
Checkpoint 748389052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558,092.52208
Policy Entropy: 1.07649
Value Function Loss: 4.58329

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.09337

Collected Steps per Second: 10,545.92525
Overall Steps per Second: 9,057.44552

Timestep Collection Time: 4.74325
Timestep Consumption Time: 0.77950
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 5.52275

Cumulative Model Updates: 44,869
Cumulative Timesteps: 748,439,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,554.92859
Policy Entropy: 1.06739
Value Function Loss: 4.55643

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.16014
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.07939

Collected Steps per Second: 10,574.24708
Overall Steps per Second: 9,131.69117

Timestep Collection Time: 4.72923
Timestep Consumption Time: 0.74709
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.47631

Cumulative Model Updates: 44,872
Cumulative Timesteps: 748,489,082

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 748489082...
Checkpoint 748489082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,577.82495
Policy Entropy: 1.07732
Value Function Loss: 4.65287

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.06616

Collected Steps per Second: 10,684.54494
Overall Steps per Second: 9,324.78294

Timestep Collection Time: 4.68078
Timestep Consumption Time: 0.68256
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 5.36334

Cumulative Model Updates: 44,875
Cumulative Timesteps: 748,539,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,449.05040
Policy Entropy: 1.09280
Value Function Loss: 4.48641

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.16654
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.05907

Collected Steps per Second: 10,699.96931
Overall Steps per Second: 9,069.91932

Timestep Collection Time: 4.67291
Timestep Consumption Time: 0.83982
PPO Batch Consumption Time: 0.04306
Total Iteration Time: 5.51273

Cumulative Model Updates: 44,878
Cumulative Timesteps: 748,589,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 748589094...
Checkpoint 748589094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,821.55761
Policy Entropy: 1.06713
Value Function Loss: 4.50864

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.15477
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.05697

Collected Steps per Second: 10,583.86856
Overall Steps per Second: 9,041.27906

Timestep Collection Time: 4.72436
Timestep Consumption Time: 0.80605
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 5.53041

Cumulative Model Updates: 44,881
Cumulative Timesteps: 748,639,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566,399.31711
Policy Entropy: 1.07871
Value Function Loss: 4.34395

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.06158

Collected Steps per Second: 10,764.96860
Overall Steps per Second: 9,045.53214

Timestep Collection Time: 4.64600
Timestep Consumption Time: 0.88314
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.52914

Cumulative Model Updates: 44,884
Cumulative Timesteps: 748,689,110

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 748689110...
Checkpoint 748689110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,143.13599
Policy Entropy: 1.07570
Value Function Loss: 4.64805

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.06062

Collected Steps per Second: 11,845.80102
Overall Steps per Second: 10,008.04165

Timestep Collection Time: 4.22259
Timestep Consumption Time: 0.77539
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 4.99798

Cumulative Model Updates: 44,887
Cumulative Timesteps: 748,739,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,887.61846
Policy Entropy: 1.08373
Value Function Loss: 4.69374

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.06845
Value Function Update Magnitude: 0.05923

Collected Steps per Second: 11,326.56980
Overall Steps per Second: 9,770.90567

Timestep Collection Time: 4.41616
Timestep Consumption Time: 0.70311
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.11928

Cumulative Model Updates: 44,890
Cumulative Timesteps: 748,789,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 748789150...
Checkpoint 748789150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,353.71806
Policy Entropy: 1.07647
Value Function Loss: 4.69086

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.07243
Value Function Update Magnitude: 0.06048

Collected Steps per Second: 11,747.47605
Overall Steps per Second: 9,898.69649

Timestep Collection Time: 4.25760
Timestep Consumption Time: 0.79519
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.05279

Cumulative Model Updates: 44,893
Cumulative Timesteps: 748,839,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,399.55953
Policy Entropy: 1.08445
Value Function Loss: 4.67033

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.06170

Collected Steps per Second: 11,560.58408
Overall Steps per Second: 9,997.37252

Timestep Collection Time: 4.32608
Timestep Consumption Time: 0.67644
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.00251

Cumulative Model Updates: 44,896
Cumulative Timesteps: 748,889,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 748889178...
Checkpoint 748889178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,785.97560
Policy Entropy: 1.08175
Value Function Loss: 4.64510

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.06280

Collected Steps per Second: 11,737.50118
Overall Steps per Second: 9,937.24731

Timestep Collection Time: 4.26207
Timestep Consumption Time: 0.77213
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 5.03419

Cumulative Model Updates: 44,899
Cumulative Timesteps: 748,939,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,163.52353
Policy Entropy: 1.09759
Value Function Loss: 4.66468

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.07235

Collected Steps per Second: 11,395.60922
Overall Steps per Second: 9,738.59662

Timestep Collection Time: 4.38923
Timestep Consumption Time: 0.74682
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 5.13606

Cumulative Model Updates: 44,902
Cumulative Timesteps: 748,989,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 748989222...
Checkpoint 748989222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,052.37732
Policy Entropy: 1.10103
Value Function Loss: 4.47634

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.07011
Value Function Update Magnitude: 0.07598

Collected Steps per Second: 10,983.96705
Overall Steps per Second: 9,358.43072

Timestep Collection Time: 4.55209
Timestep Consumption Time: 0.79069
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 5.34278

Cumulative Model Updates: 44,905
Cumulative Timesteps: 749,039,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,010.39958
Policy Entropy: 1.10583
Value Function Loss: 4.52414

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.06748
Value Function Update Magnitude: 0.08567

Collected Steps per Second: 10,757.90615
Overall Steps per Second: 9,239.46665

Timestep Collection Time: 4.64812
Timestep Consumption Time: 0.76388
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 5.41200

Cumulative Model Updates: 44,908
Cumulative Timesteps: 749,089,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 749089226...
Checkpoint 749089226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,928.56448
Policy Entropy: 1.11106
Value Function Loss: 4.46973

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.06530
Value Function Update Magnitude: 0.08754

Collected Steps per Second: 10,798.48837
Overall Steps per Second: 9,394.08579

Timestep Collection Time: 4.63176
Timestep Consumption Time: 0.69244
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 5.32420

Cumulative Model Updates: 44,911
Cumulative Timesteps: 749,139,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,594.37239
Policy Entropy: 1.11211
Value Function Loss: 4.63512

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.06722
Value Function Update Magnitude: 0.07539

Collected Steps per Second: 11,022.80372
Overall Steps per Second: 9,435.57776

Timestep Collection Time: 4.53641
Timestep Consumption Time: 0.76310
PPO Batch Consumption Time: 0.03372
Total Iteration Time: 5.29952

Cumulative Model Updates: 44,914
Cumulative Timesteps: 749,189,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 749189246...
Checkpoint 749189246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,224.61633
Policy Entropy: 1.10845
Value Function Loss: 4.83551

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.07512
Value Function Update Magnitude: 0.07686

Collected Steps per Second: 10,763.77851
Overall Steps per Second: 9,243.09224

Timestep Collection Time: 4.64688
Timestep Consumption Time: 0.76451
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 5.41139

Cumulative Model Updates: 44,917
Cumulative Timesteps: 749,239,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,465.75723
Policy Entropy: 1.10628
Value Function Loss: 5.05241

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.07546
Value Function Update Magnitude: 0.07244

Collected Steps per Second: 10,408.75043
Overall Steps per Second: 9,003.66071

Timestep Collection Time: 4.80500
Timestep Consumption Time: 0.74986
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.55485

Cumulative Model Updates: 44,920
Cumulative Timesteps: 749,289,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 749289278...
Checkpoint 749289278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,190.72130
Policy Entropy: 1.10978
Value Function Loss: 5.01556

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.07420
Value Function Update Magnitude: 0.07223

Collected Steps per Second: 10,565.69109
Overall Steps per Second: 9,107.17600

Timestep Collection Time: 4.73495
Timestep Consumption Time: 0.75830
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 5.49325

Cumulative Model Updates: 44,923
Cumulative Timesteps: 749,339,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,248.02503
Policy Entropy: 1.10708
Value Function Loss: 4.83749

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.07012
Value Function Update Magnitude: 0.08834

Collected Steps per Second: 10,676.77875
Overall Steps per Second: 9,166.69205

Timestep Collection Time: 4.68456
Timestep Consumption Time: 0.77172
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.45628

Cumulative Model Updates: 44,926
Cumulative Timesteps: 749,389,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 749389322...
Checkpoint 749389322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,612.44152
Policy Entropy: 1.09272
Value Function Loss: 4.63903

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.15663
Policy Update Magnitude: 0.06584
Value Function Update Magnitude: 0.08487

Collected Steps per Second: 10,567.68882
Overall Steps per Second: 9,077.17032

Timestep Collection Time: 4.73405
Timestep Consumption Time: 0.77736
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.51141

Cumulative Model Updates: 44,929
Cumulative Timesteps: 749,439,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,686.16132
Policy Entropy: 1.10483
Value Function Loss: 4.67788

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.07144

Collected Steps per Second: 10,689.34587
Overall Steps per Second: 9,338.24538

Timestep Collection Time: 4.67774
Timestep Consumption Time: 0.67680
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.35454

Cumulative Model Updates: 44,932
Cumulative Timesteps: 749,489,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 749489352...
Checkpoint 749489352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,931.09962
Policy Entropy: 1.10860
Value Function Loss: 4.61588

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.06147

Collected Steps per Second: 10,087.89363
Overall Steps per Second: 8,589.06989

Timestep Collection Time: 4.95683
Timestep Consumption Time: 0.86499
PPO Batch Consumption Time: 0.03995
Total Iteration Time: 5.82182

Cumulative Model Updates: 44,935
Cumulative Timesteps: 749,539,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,770.64890
Policy Entropy: 1.08780
Value Function Loss: 4.79029

Mean KL Divergence: 0.04138
SB3 Clip Fraction: 0.16089
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.06627

Collected Steps per Second: 10,556.09135
Overall Steps per Second: 9,107.87798

Timestep Collection Time: 4.73755
Timestep Consumption Time: 0.75330
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.49085

Cumulative Model Updates: 44,938
Cumulative Timesteps: 749,589,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 749589366...
Checkpoint 749589366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,114.53388
Policy Entropy: 1.10454
Value Function Loss: 4.88502

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.06989

Collected Steps per Second: 10,875.20601
Overall Steps per Second: 9,287.91046

Timestep Collection Time: 4.59945
Timestep Consumption Time: 0.78604
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.38550

Cumulative Model Updates: 44,941
Cumulative Timesteps: 749,639,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,944.71378
Policy Entropy: 1.10465
Value Function Loss: 4.97834

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.07224

Collected Steps per Second: 10,538.78728
Overall Steps per Second: 9,055.70293

Timestep Collection Time: 4.74666
Timestep Consumption Time: 0.77738
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.52403

Cumulative Model Updates: 44,944
Cumulative Timesteps: 749,689,410

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 749689410...
Checkpoint 749689410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,093.37758
Policy Entropy: 1.09217
Value Function Loss: 4.79896

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.09046

Collected Steps per Second: 10,699.02035
Overall Steps per Second: 9,327.66266

Timestep Collection Time: 4.67351
Timestep Consumption Time: 0.68710
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 5.36061

Cumulative Model Updates: 44,947
Cumulative Timesteps: 749,739,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,349.93739
Policy Entropy: 1.11059
Value Function Loss: 4.67204

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.11774
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.08623

Collected Steps per Second: 10,627.01220
Overall Steps per Second: 8,967.63073

Timestep Collection Time: 4.70725
Timestep Consumption Time: 0.87104
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 5.57828

Cumulative Model Updates: 44,950
Cumulative Timesteps: 749,789,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 749789436...
Checkpoint 749789436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,472.79481
Policy Entropy: 1.10590
Value Function Loss: 4.64908

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.08539

Collected Steps per Second: 10,405.25351
Overall Steps per Second: 8,964.78585

Timestep Collection Time: 4.80796
Timestep Consumption Time: 0.77255
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.58050

Cumulative Model Updates: 44,953
Cumulative Timesteps: 749,839,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,878.23840
Policy Entropy: 1.09386
Value Function Loss: 4.47387

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.09731

Collected Steps per Second: 11,190.54300
Overall Steps per Second: 9,508.87038

Timestep Collection Time: 4.47020
Timestep Consumption Time: 0.79057
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.26077

Cumulative Model Updates: 44,956
Cumulative Timesteps: 749,889,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 749889488...
Checkpoint 749889488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,332.98417
Policy Entropy: 1.08369
Value Function Loss: 4.64537

Mean KL Divergence: 0.02840
SB3 Clip Fraction: 0.17072
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.09224

Collected Steps per Second: 11,063.77720
Overall Steps per Second: 9,460.90439

Timestep Collection Time: 4.52016
Timestep Consumption Time: 0.76581
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.28596

Cumulative Model Updates: 44,959
Cumulative Timesteps: 749,939,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,179.70842
Policy Entropy: 1.10037
Value Function Loss: 4.52352

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.08298

Collected Steps per Second: 10,847.32998
Overall Steps per Second: 9,391.37736

Timestep Collection Time: 4.61219
Timestep Consumption Time: 0.71503
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.32723

Cumulative Model Updates: 44,962
Cumulative Timesteps: 749,989,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 749989528...
Checkpoint 749989528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,076.65561
Policy Entropy: 1.09753
Value Function Loss: 4.61779

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.08356

Collected Steps per Second: 11,171.67641
Overall Steps per Second: 9,552.65130

Timestep Collection Time: 4.47757
Timestep Consumption Time: 0.75888
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.23645

Cumulative Model Updates: 44,965
Cumulative Timesteps: 750,039,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,531.69404
Policy Entropy: 1.08274
Value Function Loss: 4.44300

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.09387

Collected Steps per Second: 10,935.01840
Overall Steps per Second: 9,218.96315

Timestep Collection Time: 4.57448
Timestep Consumption Time: 0.85151
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.42599

Cumulative Model Updates: 44,968
Cumulative Timesteps: 750,089,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 750089572...
Checkpoint 750089572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,065.19370
Policy Entropy: 1.06352
Value Function Loss: 4.71431

Mean KL Divergence: 0.03549
SB3 Clip Fraction: 0.16819
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.10469

Collected Steps per Second: 10,351.33159
Overall Steps per Second: 8,976.74592

Timestep Collection Time: 4.83146
Timestep Consumption Time: 0.73983
PPO Batch Consumption Time: 0.03823
Total Iteration Time: 5.57128

Cumulative Model Updates: 44,971
Cumulative Timesteps: 750,139,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,090.08271
Policy Entropy: 1.07559
Value Function Loss: 4.91095

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.09976

Collected Steps per Second: 10,831.15015
Overall Steps per Second: 9,226.92221

Timestep Collection Time: 4.61872
Timestep Consumption Time: 0.80303
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.42174

Cumulative Model Updates: 44,974
Cumulative Timesteps: 750,189,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 750189610...
Checkpoint 750189610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,097.89663
Policy Entropy: 1.07933
Value Function Loss: 4.98214

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.10334

Collected Steps per Second: 10,637.34761
Overall Steps per Second: 9,176.05171

Timestep Collection Time: 4.70305
Timestep Consumption Time: 0.74897
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.45202

Cumulative Model Updates: 44,977
Cumulative Timesteps: 750,239,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,400.53380
Policy Entropy: 1.08057
Value Function Loss: 4.69373

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.10518

Collected Steps per Second: 11,197.54155
Overall Steps per Second: 9,532.31228

Timestep Collection Time: 4.46759
Timestep Consumption Time: 0.78046
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 5.24804

Cumulative Model Updates: 44,980
Cumulative Timesteps: 750,289,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 750289664...
Checkpoint 750289664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,256.63137
Policy Entropy: 1.08991
Value Function Loss: 4.57114

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.11143

Collected Steps per Second: 10,712.29706
Overall Steps per Second: 9,170.87526

Timestep Collection Time: 4.66772
Timestep Consumption Time: 0.78454
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.45226

Cumulative Model Updates: 44,983
Cumulative Timesteps: 750,339,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,970.01670
Policy Entropy: 1.09007
Value Function Loss: 4.36578

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.10658

Collected Steps per Second: 10,233.06089
Overall Steps per Second: 8,980.22853

Timestep Collection Time: 4.88886
Timestep Consumption Time: 0.68205
PPO Batch Consumption Time: 0.03854
Total Iteration Time: 5.57091

Cumulative Model Updates: 44,986
Cumulative Timesteps: 750,389,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 750389694...
Checkpoint 750389694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,272.77802
Policy Entropy: 1.07636
Value Function Loss: 4.56615

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.09223

Collected Steps per Second: 10,525.83679
Overall Steps per Second: 9,069.93420

Timestep Collection Time: 4.75117
Timestep Consumption Time: 0.76266
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 5.51382

Cumulative Model Updates: 44,989
Cumulative Timesteps: 750,439,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,626.35063
Policy Entropy: 1.06809
Value Function Loss: 4.56697

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.17885
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.08338

Collected Steps per Second: 10,662.79602
Overall Steps per Second: 9,193.66247

Timestep Collection Time: 4.69145
Timestep Consumption Time: 0.74969
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.44114

Cumulative Model Updates: 44,992
Cumulative Timesteps: 750,489,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 750489728...
Checkpoint 750489728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,493.51449
Policy Entropy: 1.07859
Value Function Loss: 4.49124

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.08265

Collected Steps per Second: 10,865.42750
Overall Steps per Second: 9,330.52277

Timestep Collection Time: 4.60267
Timestep Consumption Time: 0.75716
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.35983

Cumulative Model Updates: 44,995
Cumulative Timesteps: 750,539,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,458.75810
Policy Entropy: 1.08794
Value Function Loss: 4.59252

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.08171

Collected Steps per Second: 10,673.04881
Overall Steps per Second: 9,169.66320

Timestep Collection Time: 4.68507
Timestep Consumption Time: 0.76813
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.45320

Cumulative Model Updates: 44,998
Cumulative Timesteps: 750,589,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 750589742...
Checkpoint 750589742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,137.79046
Policy Entropy: 1.06988
Value Function Loss: 4.56740

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.07504

Collected Steps per Second: 10,474.33862
Overall Steps per Second: 9,012.91371

Timestep Collection Time: 4.77586
Timestep Consumption Time: 0.77440
PPO Batch Consumption Time: 0.04408
Total Iteration Time: 5.55026

Cumulative Model Updates: 45,001
Cumulative Timesteps: 750,639,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,782.65303
Policy Entropy: 1.09092
Value Function Loss: 4.81914

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.08786

Collected Steps per Second: 10,580.82103
Overall Steps per Second: 9,113.18729

Timestep Collection Time: 4.72723
Timestep Consumption Time: 0.76130
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.48853

Cumulative Model Updates: 45,004
Cumulative Timesteps: 750,689,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 750689784...
Checkpoint 750689784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,913.46564
Policy Entropy: 1.08036
Value Function Loss: 4.66611

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.08113

Collected Steps per Second: 10,540.53664
Overall Steps per Second: 9,049.18429

Timestep Collection Time: 4.74359
Timestep Consumption Time: 0.78177
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.52536

Cumulative Model Updates: 45,007
Cumulative Timesteps: 750,739,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,373.56603
Policy Entropy: 1.07191
Value Function Loss: 4.52522

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.09943

Collected Steps per Second: 10,769.86581
Overall Steps per Second: 9,180.50914

Timestep Collection Time: 4.64388
Timestep Consumption Time: 0.80396
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.44785

Cumulative Model Updates: 45,010
Cumulative Timesteps: 750,789,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 750789798...
Checkpoint 750789798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,333.12992
Policy Entropy: 1.05313
Value Function Loss: 4.50686

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.17940
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.09910

Collected Steps per Second: 10,738.17756
Overall Steps per Second: 9,171.59790

Timestep Collection Time: 4.65703
Timestep Consumption Time: 0.79546
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.45248

Cumulative Model Updates: 45,013
Cumulative Timesteps: 750,839,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,842.85863
Policy Entropy: 1.06991
Value Function Loss: 4.50018

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.09295

Collected Steps per Second: 10,709.38154
Overall Steps per Second: 9,270.67112

Timestep Collection Time: 4.66992
Timestep Consumption Time: 0.72472
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.39465

Cumulative Model Updates: 45,016
Cumulative Timesteps: 750,889,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 750889818...
Checkpoint 750889818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447,203.50459
Policy Entropy: 1.07694
Value Function Loss: 4.59281

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12073
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.08531

Collected Steps per Second: 10,494.20846
Overall Steps per Second: 8,999.93259

Timestep Collection Time: 4.76720
Timestep Consumption Time: 0.79151
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.55871

Cumulative Model Updates: 45,019
Cumulative Timesteps: 750,939,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,688.44499
Policy Entropy: 1.06722
Value Function Loss: 4.36522

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.08841

Collected Steps per Second: 11,598.32590
Overall Steps per Second: 9,819.38471

Timestep Collection Time: 4.31373
Timestep Consumption Time: 0.78150
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.09523

Cumulative Model Updates: 45,022
Cumulative Timesteps: 750,989,878

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 750989878...
Checkpoint 750989878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,962.58733
Policy Entropy: 1.05585
Value Function Loss: 4.42840

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.10436

Collected Steps per Second: 11,626.17373
Overall Steps per Second: 9,788.51874

Timestep Collection Time: 4.30099
Timestep Consumption Time: 0.80745
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.10843

Cumulative Model Updates: 45,025
Cumulative Timesteps: 751,039,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,893.18928
Policy Entropy: 1.07167
Value Function Loss: 4.38141

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.11570

Collected Steps per Second: 11,171.97793
Overall Steps per Second: 9,504.03211

Timestep Collection Time: 4.47602
Timestep Consumption Time: 0.78554
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 5.26156

Cumulative Model Updates: 45,028
Cumulative Timesteps: 751,089,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 751089888...
Checkpoint 751089888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,493.41723
Policy Entropy: 1.07014
Value Function Loss: 4.41857

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.15975
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.10025

Collected Steps per Second: 11,521.07141
Overall Steps per Second: 9,894.74421

Timestep Collection Time: 4.34161
Timestep Consumption Time: 0.71360
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.05521

Cumulative Model Updates: 45,031
Cumulative Timesteps: 751,139,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,932.11958
Policy Entropy: 1.06404
Value Function Loss: 4.43844

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.09467

Collected Steps per Second: 10,948.71373
Overall Steps per Second: 9,319.94282

Timestep Collection Time: 4.56912
Timestep Consumption Time: 0.79851
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.36763

Cumulative Model Updates: 45,034
Cumulative Timesteps: 751,189,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 751189934...
Checkpoint 751189934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,432.09313
Policy Entropy: 1.04930
Value Function Loss: 4.43785

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.16527
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.08265

Collected Steps per Second: 10,288.15010
Overall Steps per Second: 8,871.70444

Timestep Collection Time: 4.85996
Timestep Consumption Time: 0.77594
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.63590

Cumulative Model Updates: 45,037
Cumulative Timesteps: 751,239,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,560.19074
Policy Entropy: 1.07209
Value Function Loss: 4.51275

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.07134

Collected Steps per Second: 10,938.34960
Overall Steps per Second: 9,290.65184

Timestep Collection Time: 4.57235
Timestep Consumption Time: 0.81091
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.38326

Cumulative Model Updates: 45,040
Cumulative Timesteps: 751,289,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 751289948...
Checkpoint 751289948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,996.01562
Policy Entropy: 1.06301
Value Function Loss: 4.16194

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.06938

Collected Steps per Second: 10,797.44923
Overall Steps per Second: 9,198.18891

Timestep Collection Time: 4.63183
Timestep Consumption Time: 0.80532
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.43716

Cumulative Model Updates: 45,043
Cumulative Timesteps: 751,339,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,348.20017
Policy Entropy: 1.05998
Value Function Loss: 4.16391

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.08495

Collected Steps per Second: 10,888.05393
Overall Steps per Second: 9,472.86741

Timestep Collection Time: 4.59311
Timestep Consumption Time: 0.68618
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.27929

Cumulative Model Updates: 45,046
Cumulative Timesteps: 751,389,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 751389970...
Checkpoint 751389970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,959.25953
Policy Entropy: 1.04551
Value Function Loss: 4.06002

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.09966

Collected Steps per Second: 10,461.43458
Overall Steps per Second: 8,960.44043

Timestep Collection Time: 4.78233
Timestep Consumption Time: 0.80110
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.58343

Cumulative Model Updates: 45,049
Cumulative Timesteps: 751,440,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,615.44719
Policy Entropy: 1.06692
Value Function Loss: 4.21520

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.11091

Collected Steps per Second: 10,278.90263
Overall Steps per Second: 8,875.01446

Timestep Collection Time: 4.86569
Timestep Consumption Time: 0.76968
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.63537

Cumulative Model Updates: 45,052
Cumulative Timesteps: 751,490,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 751490014...
Checkpoint 751490014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,771.20562
Policy Entropy: 1.06583
Value Function Loss: 4.30381

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.09680

Collected Steps per Second: 10,825.01172
Overall Steps per Second: 9,184.70421

Timestep Collection Time: 4.61912
Timestep Consumption Time: 0.82493
PPO Batch Consumption Time: 0.04195
Total Iteration Time: 5.44405

Cumulative Model Updates: 45,055
Cumulative Timesteps: 751,540,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,733.62903
Policy Entropy: 1.07419
Value Function Loss: 4.40291

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.08337

Collected Steps per Second: 10,614.72636
Overall Steps per Second: 9,111.22257

Timestep Collection Time: 4.71345
Timestep Consumption Time: 0.77780
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 5.49125

Cumulative Model Updates: 45,058
Cumulative Timesteps: 751,590,048

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 751590048...
Checkpoint 751590048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,144.19896
Policy Entropy: 1.08176
Value Function Loss: 4.51140

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.16072
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.07735

Collected Steps per Second: 10,621.14954
Overall Steps per Second: 9,257.67118

Timestep Collection Time: 4.70947
Timestep Consumption Time: 0.69362
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.40309

Cumulative Model Updates: 45,061
Cumulative Timesteps: 751,640,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,048.79776
Policy Entropy: 1.08042
Value Function Loss: 4.48345

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.08455

Collected Steps per Second: 10,734.68184
Overall Steps per Second: 9,180.66309

Timestep Collection Time: 4.65780
Timestep Consumption Time: 0.78843
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 5.44623

Cumulative Model Updates: 45,064
Cumulative Timesteps: 751,690,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 751690068...
Checkpoint 751690068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,372.38006
Policy Entropy: 1.08143
Value Function Loss: 4.34158

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.09027

Collected Steps per Second: 10,721.73300
Overall Steps per Second: 9,188.26248

Timestep Collection Time: 4.66436
Timestep Consumption Time: 0.77846
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 5.44281

Cumulative Model Updates: 45,067
Cumulative Timesteps: 751,740,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,965.15471
Policy Entropy: 1.09346
Value Function Loss: 4.35391

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.07724

Collected Steps per Second: 10,335.85090
Overall Steps per Second: 8,922.88000

Timestep Collection Time: 4.84005
Timestep Consumption Time: 0.76644
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.60649

Cumulative Model Updates: 45,070
Cumulative Timesteps: 751,790,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 751790104...
Checkpoint 751790104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,539.59690
Policy Entropy: 1.10661
Value Function Loss: 4.61295

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.08139

Collected Steps per Second: 10,825.03070
Overall Steps per Second: 9,239.20292

Timestep Collection Time: 4.62040
Timestep Consumption Time: 0.79305
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 5.41345

Cumulative Model Updates: 45,073
Cumulative Timesteps: 751,840,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,275.65404
Policy Entropy: 1.09857
Value Function Loss: 4.77853

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.08873

Collected Steps per Second: 10,556.62650
Overall Steps per Second: 9,029.37520

Timestep Collection Time: 4.73788
Timestep Consumption Time: 0.80138
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 5.53925

Cumulative Model Updates: 45,076
Cumulative Timesteps: 751,890,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 751890136...
Checkpoint 751890136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,649.32304
Policy Entropy: 1.07974
Value Function Loss: 4.83959

Mean KL Divergence: 0.04077
SB3 Clip Fraction: 0.17585
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.09767

Collected Steps per Second: 10,747.46916
Overall Steps per Second: 9,239.64922

Timestep Collection Time: 4.65337
Timestep Consumption Time: 0.75939
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 5.41276

Cumulative Model Updates: 45,079
Cumulative Timesteps: 751,940,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,111.54849
Policy Entropy: 1.10503
Value Function Loss: 4.71407

Mean KL Divergence: 0.02978
SB3 Clip Fraction: 0.16041
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.09386

Collected Steps per Second: 10,672.71434
Overall Steps per Second: 9,308.93984

Timestep Collection Time: 4.68597
Timestep Consumption Time: 0.68650
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.37247

Cumulative Model Updates: 45,082
Cumulative Timesteps: 751,990,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 751990160...
Checkpoint 751990160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,818.11033
Policy Entropy: 1.08376
Value Function Loss: 4.66192

Mean KL Divergence: 0.03382
SB3 Clip Fraction: 0.17705
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.08602

Collected Steps per Second: 10,401.33477
Overall Steps per Second: 8,957.08821

Timestep Collection Time: 4.80881
Timestep Consumption Time: 0.77537
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.58418

Cumulative Model Updates: 45,085
Cumulative Timesteps: 752,040,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,840.81704
Policy Entropy: 1.09314
Value Function Loss: 4.58665

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.15147
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.08075

Collected Steps per Second: 10,950.05175
Overall Steps per Second: 9,330.35236

Timestep Collection Time: 4.56747
Timestep Consumption Time: 0.79289
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 5.36035

Cumulative Model Updates: 45,088
Cumulative Timesteps: 752,090,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 752090192...
Checkpoint 752090192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,579.08114
Policy Entropy: 1.09445
Value Function Loss: 4.51820

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.08304

Collected Steps per Second: 11,023.03269
Overall Steps per Second: 9,378.75218

Timestep Collection Time: 4.53741
Timestep Consumption Time: 0.79550
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.33291

Cumulative Model Updates: 45,091
Cumulative Timesteps: 752,140,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474,629.49295
Policy Entropy: 1.07897
Value Function Loss: 4.48233

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.08032

Collected Steps per Second: 11,057.13319
Overall Steps per Second: 9,424.23955

Timestep Collection Time: 4.52432
Timestep Consumption Time: 0.78391
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 5.30823

Cumulative Model Updates: 45,094
Cumulative Timesteps: 752,190,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 752190234...
Checkpoint 752190234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624,469.93457
Policy Entropy: 1.07876
Value Function Loss: 4.46869

Mean KL Divergence: 0.02408
SB3 Clip Fraction: 0.14701
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.07451

Collected Steps per Second: 10,953.34639
Overall Steps per Second: 9,504.04970

Timestep Collection Time: 4.56755
Timestep Consumption Time: 0.69652
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.26407

Cumulative Model Updates: 45,097
Cumulative Timesteps: 752,240,264

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,723.04780
Policy Entropy: 1.08865
Value Function Loss: 4.46370

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.07627

Collected Steps per Second: 10,991.46921
Overall Steps per Second: 9,390.36352

Timestep Collection Time: 4.54898
Timestep Consumption Time: 0.77563
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.32461

Cumulative Model Updates: 45,100
Cumulative Timesteps: 752,290,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 752290264...
Checkpoint 752290264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,174.36273
Policy Entropy: 1.10016
Value Function Loss: 4.67939

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.07989

Collected Steps per Second: 10,385.48074
Overall Steps per Second: 8,964.54602

Timestep Collection Time: 4.81711
Timestep Consumption Time: 0.76354
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.58065

Cumulative Model Updates: 45,103
Cumulative Timesteps: 752,340,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,941.83015
Policy Entropy: 1.09095
Value Function Loss: 4.65163

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.08197

Collected Steps per Second: 11,046.73550
Overall Steps per Second: 9,425.49197

Timestep Collection Time: 4.52785
Timestep Consumption Time: 0.77882
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.30667

Cumulative Model Updates: 45,106
Cumulative Timesteps: 752,390,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 752390310...
Checkpoint 752390310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,456.16559
Policy Entropy: 1.07556
Value Function Loss: 4.75270

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.07722

Collected Steps per Second: 10,633.07550
Overall Steps per Second: 9,117.65340

Timestep Collection Time: 4.70419
Timestep Consumption Time: 0.78187
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.48606

Cumulative Model Updates: 45,109
Cumulative Timesteps: 752,440,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,635.97255
Policy Entropy: 1.08203
Value Function Loss: 4.93382

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 10,790.31437
Overall Steps per Second: 9,396.31512

Timestep Collection Time: 4.63527
Timestep Consumption Time: 0.68767
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 5.32294

Cumulative Model Updates: 45,112
Cumulative Timesteps: 752,490,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 752490346...
Checkpoint 752490346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,408.05077
Policy Entropy: 1.08566
Value Function Loss: 5.00889

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.05974

Collected Steps per Second: 10,747.48946
Overall Steps per Second: 9,207.32946

Timestep Collection Time: 4.65355
Timestep Consumption Time: 0.77842
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.43198

Cumulative Model Updates: 45,115
Cumulative Timesteps: 752,540,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,622.59260
Policy Entropy: 1.07701
Value Function Loss: 4.99633

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.05470

Collected Steps per Second: 10,377.78176
Overall Steps per Second: 8,978.07819

Timestep Collection Time: 4.81895
Timestep Consumption Time: 0.75129
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.57023

Cumulative Model Updates: 45,118
Cumulative Timesteps: 752,590,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 752590370...
Checkpoint 752590370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,963.47685
Policy Entropy: 1.08111
Value Function Loss: 4.53053

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.06368

Collected Steps per Second: 10,766.97175
Overall Steps per Second: 9,267.15417

Timestep Collection Time: 4.64606
Timestep Consumption Time: 0.75193
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 5.39799

Cumulative Model Updates: 45,121
Cumulative Timesteps: 752,640,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,386.75431
Policy Entropy: 1.08660
Value Function Loss: 4.33239

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.05813

Collected Steps per Second: 10,417.33888
Overall Steps per Second: 9,018.89450

Timestep Collection Time: 4.80065
Timestep Consumption Time: 0.74438
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 5.54503

Cumulative Model Updates: 45,124
Cumulative Timesteps: 752,690,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 752690404...
Checkpoint 752690404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,018.80682
Policy Entropy: 1.07920
Value Function Loss: 4.38022

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.05364

Collected Steps per Second: 10,629.25134
Overall Steps per Second: 9,306.01320

Timestep Collection Time: 4.70663
Timestep Consumption Time: 0.66924
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.37588

Cumulative Model Updates: 45,127
Cumulative Timesteps: 752,740,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,178.56663
Policy Entropy: 1.06475
Value Function Loss: 4.79526

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.06417
Value Function Update Magnitude: 0.05294

Collected Steps per Second: 10,518.34754
Overall Steps per Second: 8,981.13952

Timestep Collection Time: 4.75664
Timestep Consumption Time: 0.81414
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.57079

Cumulative Model Updates: 45,130
Cumulative Timesteps: 752,790,464

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 752790464...
Checkpoint 752790464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575,641.28163
Policy Entropy: 1.07068
Value Function Loss: 4.83280

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.04969

Collected Steps per Second: 10,680.86886
Overall Steps per Second: 9,117.93930

Timestep Collection Time: 4.68164
Timestep Consumption Time: 0.80249
PPO Batch Consumption Time: 0.03851
Total Iteration Time: 5.48413

Cumulative Model Updates: 45,133
Cumulative Timesteps: 752,840,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,793.87950
Policy Entropy: 1.07857
Value Function Loss: 4.91440

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.04636

Collected Steps per Second: 10,463.12379
Overall Steps per Second: 8,973.27297

Timestep Collection Time: 4.77945
Timestep Consumption Time: 0.79354
PPO Batch Consumption Time: 0.03843
Total Iteration Time: 5.57299

Cumulative Model Updates: 45,136
Cumulative Timesteps: 752,890,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 752890476...
Checkpoint 752890476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,970.74800
Policy Entropy: 1.07870
Value Function Loss: 4.70856

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.04988

Collected Steps per Second: 10,659.04954
Overall Steps per Second: 9,139.19088

Timestep Collection Time: 4.69216
Timestep Consumption Time: 0.78031
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 5.47248

Cumulative Model Updates: 45,139
Cumulative Timesteps: 752,940,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,835.94833
Policy Entropy: 1.07005
Value Function Loss: 4.78197

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.07027
Value Function Update Magnitude: 0.05545

Collected Steps per Second: 10,588.70704
Overall Steps per Second: 9,203.64341

Timestep Collection Time: 4.72333
Timestep Consumption Time: 0.71082
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.43415

Cumulative Model Updates: 45,142
Cumulative Timesteps: 752,990,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 752990504...
Checkpoint 752990504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,170.11687
Policy Entropy: 1.05901
Value Function Loss: 4.51654

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.15194
Policy Update Magnitude: 0.06950
Value Function Update Magnitude: 0.05788

Collected Steps per Second: 10,402.02232
Overall Steps per Second: 8,923.91782

Timestep Collection Time: 4.80945
Timestep Consumption Time: 0.79661
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 5.60606

Cumulative Model Updates: 45,145
Cumulative Timesteps: 753,040,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,511.24449
Policy Entropy: 1.07453
Value Function Loss: 4.55215

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.06970

Collected Steps per Second: 10,089.14180
Overall Steps per Second: 8,721.13313

Timestep Collection Time: 4.95761
Timestep Consumption Time: 0.77766
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.73526

Cumulative Model Updates: 45,148
Cumulative Timesteps: 753,090,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 753090550...
Checkpoint 753090550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,951.72119
Policy Entropy: 1.08594
Value Function Loss: 4.52167

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.16304
Policy Update Magnitude: 0.06721
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 10,522.87189
Overall Steps per Second: 9,011.40022

Timestep Collection Time: 4.75441
Timestep Consumption Time: 0.79745
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.55186

Cumulative Model Updates: 45,151
Cumulative Timesteps: 753,140,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,446.20559
Policy Entropy: 1.06579
Value Function Loss: 4.66657

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.06648
Value Function Update Magnitude: 0.07659

Collected Steps per Second: 11,544.28535
Overall Steps per Second: 9,781.65435

Timestep Collection Time: 4.33201
Timestep Consumption Time: 0.78062
PPO Batch Consumption Time: 0.04144
Total Iteration Time: 5.11263

Cumulative Model Updates: 45,154
Cumulative Timesteps: 753,190,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 753190590...
Checkpoint 753190590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,865.57198
Policy Entropy: 1.07697
Value Function Loss: 4.60865

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.08140

Collected Steps per Second: 11,469.28977
Overall Steps per Second: 9,808.64840

Timestep Collection Time: 4.36069
Timestep Consumption Time: 0.73828
PPO Batch Consumption Time: 0.03811
Total Iteration Time: 5.09897

Cumulative Model Updates: 45,157
Cumulative Timesteps: 753,240,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,270.92349
Policy Entropy: 1.08388
Value Function Loss: 4.56342

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.09102

Collected Steps per Second: 11,704.41926
Overall Steps per Second: 9,885.82190

Timestep Collection Time: 4.27343
Timestep Consumption Time: 0.78614
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 5.05957

Cumulative Model Updates: 45,160
Cumulative Timesteps: 753,290,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 753290622...
Checkpoint 753290622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,122.15298
Policy Entropy: 1.07237
Value Function Loss: 4.58067

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.08180

Collected Steps per Second: 11,290.18924
Overall Steps per Second: 9,771.41776

Timestep Collection Time: 4.42969
Timestep Consumption Time: 0.68851
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.11819

Cumulative Model Updates: 45,163
Cumulative Timesteps: 753,340,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,857.96723
Policy Entropy: 1.05498
Value Function Loss: 4.56216

Mean KL Divergence: 0.03259
SB3 Clip Fraction: 0.18844
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.07116

Collected Steps per Second: 11,601.97434
Overall Steps per Second: 9,803.50342

Timestep Collection Time: 4.31099
Timestep Consumption Time: 0.79086
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.10185

Cumulative Model Updates: 45,166
Cumulative Timesteps: 753,390,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 753390650...
Checkpoint 753390650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,786.36778
Policy Entropy: 1.06629
Value Function Loss: 4.60872

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.06787

Collected Steps per Second: 10,266.72488
Overall Steps per Second: 8,876.82156

Timestep Collection Time: 4.87225
Timestep Consumption Time: 0.76288
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.63513

Cumulative Model Updates: 45,169
Cumulative Timesteps: 753,440,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,436.18057
Policy Entropy: 1.06891
Value Function Loss: 4.57465

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.07066

Collected Steps per Second: 10,759.77198
Overall Steps per Second: 9,356.96581

Timestep Collection Time: 4.64880
Timestep Consumption Time: 0.69695
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.34575

Cumulative Model Updates: 45,172
Cumulative Timesteps: 753,490,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 753490692...
Checkpoint 753490692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,216.69267
Policy Entropy: 1.05841
Value Function Loss: 4.42508

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.08204

Collected Steps per Second: 10,447.13212
Overall Steps per Second: 8,988.58197

Timestep Collection Time: 4.78715
Timestep Consumption Time: 0.77680
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.56395

Cumulative Model Updates: 45,175
Cumulative Timesteps: 753,540,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,138.90626
Policy Entropy: 1.05862
Value Function Loss: 4.50021

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 10,621.64859
Overall Steps per Second: 9,135.61626

Timestep Collection Time: 4.71038
Timestep Consumption Time: 0.76621
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.47659

Cumulative Model Updates: 45,178
Cumulative Timesteps: 753,590,736

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 753590736...
Checkpoint 753590736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,905.50633
Policy Entropy: 1.06368
Value Function Loss: 4.25850

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 10,682.43236
Overall Steps per Second: 9,135.28005

Timestep Collection Time: 4.68264
Timestep Consumption Time: 0.79305
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.47569

Cumulative Model Updates: 45,181
Cumulative Timesteps: 753,640,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,246.75136
Policy Entropy: 1.07204
Value Function Loss: 4.30650

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.07361

Collected Steps per Second: 9,808.96717
Overall Steps per Second: 8,316.38528

Timestep Collection Time: 5.09860
Timestep Consumption Time: 0.91507
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 6.01367

Cumulative Model Updates: 45,184
Cumulative Timesteps: 753,690,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 753690770...
Checkpoint 753690770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,114.03597
Policy Entropy: 1.05328
Value Function Loss: 4.02992

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.07837

Collected Steps per Second: 10,626.69648
Overall Steps per Second: 9,296.38346

Timestep Collection Time: 4.70551
Timestep Consumption Time: 0.67336
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.37887

Cumulative Model Updates: 45,187
Cumulative Timesteps: 753,740,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,656.63399
Policy Entropy: 1.05871
Value Function Loss: 4.17436

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.07452

Collected Steps per Second: 10,576.62478
Overall Steps per Second: 9,143.58772

Timestep Collection Time: 4.73005
Timestep Consumption Time: 0.74132
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.47138

Cumulative Model Updates: 45,190
Cumulative Timesteps: 753,790,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 753790802...
Checkpoint 753790802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,718.89261
Policy Entropy: 1.06354
Value Function Loss: 4.14190

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.07741

Collected Steps per Second: 10,438.79125
Overall Steps per Second: 9,046.11585

Timestep Collection Time: 4.78983
Timestep Consumption Time: 0.73741
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 5.52723

Cumulative Model Updates: 45,193
Cumulative Timesteps: 753,840,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,440.35162
Policy Entropy: 1.07371
Value Function Loss: 4.33685

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.07422

Collected Steps per Second: 10,429.32896
Overall Steps per Second: 8,872.92212

Timestep Collection Time: 4.79590
Timestep Consumption Time: 0.84125
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 5.63715

Cumulative Model Updates: 45,196
Cumulative Timesteps: 753,890,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 753890820...
Checkpoint 753890820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,870.81813
Policy Entropy: 1.04940
Value Function Loss: 4.53351

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.07268

Collected Steps per Second: 10,399.78093
Overall Steps per Second: 8,839.26585

Timestep Collection Time: 4.80972
Timestep Consumption Time: 0.84912
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 5.65884

Cumulative Model Updates: 45,199
Cumulative Timesteps: 753,940,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,611.61553
Policy Entropy: 1.06403
Value Function Loss: 4.51031

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.15749
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.06527

Collected Steps per Second: 9,992.28880
Overall Steps per Second: 8,629.45954

Timestep Collection Time: 5.00506
Timestep Consumption Time: 0.79044
PPO Batch Consumption Time: 0.04450
Total Iteration Time: 5.79550

Cumulative Model Updates: 45,202
Cumulative Timesteps: 753,990,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 753990852...
Checkpoint 753990852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,340.30273
Policy Entropy: 1.05750
Value Function Loss: 4.43888

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.06249

Collected Steps per Second: 10,419.41934
Overall Steps per Second: 8,944.95865

Timestep Collection Time: 4.79988
Timestep Consumption Time: 0.79120
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.59108

Cumulative Model Updates: 45,205
Cumulative Timesteps: 754,040,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,556.38475
Policy Entropy: 1.05237
Value Function Loss: 4.60252

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.05944

Collected Steps per Second: 10,400.01907
Overall Steps per Second: 9,058.12870

Timestep Collection Time: 4.80788
Timestep Consumption Time: 0.71225
PPO Batch Consumption Time: 0.03803
Total Iteration Time: 5.52012

Cumulative Model Updates: 45,208
Cumulative Timesteps: 754,090,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 754090866...
Checkpoint 754090866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,058.60441
Policy Entropy: 1.04076
Value Function Loss: 4.79407

Mean KL Divergence: 0.02860
SB3 Clip Fraction: 0.16746
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.06201

Collected Steps per Second: 10,178.53579
Overall Steps per Second: 8,772.20253

Timestep Collection Time: 4.91230
Timestep Consumption Time: 0.78752
PPO Batch Consumption Time: 0.03960
Total Iteration Time: 5.69982

Cumulative Model Updates: 45,211
Cumulative Timesteps: 754,140,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,348.19978
Policy Entropy: 1.06200
Value Function Loss: 4.99195

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.07014

Collected Steps per Second: 10,448.42833
Overall Steps per Second: 9,003.55930

Timestep Collection Time: 4.78637
Timestep Consumption Time: 0.76810
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 5.55447

Cumulative Model Updates: 45,214
Cumulative Timesteps: 754,190,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 754190876...
Checkpoint 754190876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,932.24259
Policy Entropy: 1.05607
Value Function Loss: 4.80438

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 10,216.22463
Overall Steps per Second: 8,784.11944

Timestep Collection Time: 4.89515
Timestep Consumption Time: 0.79807
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.69323

Cumulative Model Updates: 45,217
Cumulative Timesteps: 754,240,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,798.76832
Policy Entropy: 1.04693
Value Function Loss: 4.82372

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.11105
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.09677

Collected Steps per Second: 10,729.10863
Overall Steps per Second: 9,255.77765

Timestep Collection Time: 4.66059
Timestep Consumption Time: 0.74187
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.40246

Cumulative Model Updates: 45,220
Cumulative Timesteps: 754,290,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 754290890...
Checkpoint 754290890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,560.42665
Policy Entropy: 1.04150
Value Function Loss: 4.73575

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.10516

Collected Steps per Second: 10,672.50185
Overall Steps per Second: 9,281.90447

Timestep Collection Time: 4.68587
Timestep Consumption Time: 0.70203
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.38790

Cumulative Model Updates: 45,223
Cumulative Timesteps: 754,340,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,108.07879
Policy Entropy: 1.06037
Value Function Loss: 4.75764

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.09567

Collected Steps per Second: 10,760.73920
Overall Steps per Second: 9,200.54069

Timestep Collection Time: 4.64671
Timestep Consumption Time: 0.78797
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.43468

Cumulative Model Updates: 45,226
Cumulative Timesteps: 754,390,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 754390902...
Checkpoint 754390902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,982.79427
Policy Entropy: 1.06808
Value Function Loss: 4.59667

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.10447

Collected Steps per Second: 10,812.71636
Overall Steps per Second: 9,270.29410

Timestep Collection Time: 4.62659
Timestep Consumption Time: 0.76979
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.39638

Cumulative Model Updates: 45,229
Cumulative Timesteps: 754,440,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,986.26690
Policy Entropy: 1.04024
Value Function Loss: 4.60309

Mean KL Divergence: 0.02912
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.09602

Collected Steps per Second: 10,406.29209
Overall Steps per Second: 8,922.66779

Timestep Collection Time: 4.80632
Timestep Consumption Time: 0.79918
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 5.60550

Cumulative Model Updates: 45,232
Cumulative Timesteps: 754,490,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 754490944...
Checkpoint 754490944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,844.64610
Policy Entropy: 1.05395
Value Function Loss: 4.73476

Mean KL Divergence: 0.02737
SB3 Clip Fraction: 0.16663
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.09125

Collected Steps per Second: 10,478.86239
Overall Steps per Second: 8,974.77304

Timestep Collection Time: 4.77304
Timestep Consumption Time: 0.79992
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.57295

Cumulative Model Updates: 45,235
Cumulative Timesteps: 754,540,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,837.56482
Policy Entropy: 1.05853
Value Function Loss: 4.97321

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.06792
Value Function Update Magnitude: 0.09168

Collected Steps per Second: 10,555.12009
Overall Steps per Second: 9,212.91337

Timestep Collection Time: 4.73836
Timestep Consumption Time: 0.69032
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.42868

Cumulative Model Updates: 45,238
Cumulative Timesteps: 754,590,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 754590974...
Checkpoint 754590974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498,101.33725
Policy Entropy: 1.05953
Value Function Loss: 4.86600

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.09600

Collected Steps per Second: 10,414.48063
Overall Steps per Second: 8,959.54073

Timestep Collection Time: 4.80178
Timestep Consumption Time: 0.77976
PPO Batch Consumption Time: 0.03713
Total Iteration Time: 5.58154

Cumulative Model Updates: 45,241
Cumulative Timesteps: 754,640,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,473.17854
Policy Entropy: 1.04539
Value Function Loss: 4.52489

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.06932
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 10,556.18081
Overall Steps per Second: 9,076.81419

Timestep Collection Time: 4.73675
Timestep Consumption Time: 0.77201
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 5.50876

Cumulative Model Updates: 45,244
Cumulative Timesteps: 754,690,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 754690984...
Checkpoint 754690984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,847.87342
Policy Entropy: 1.05530
Value Function Loss: 4.38721

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.09720

Collected Steps per Second: 10,706.78798
Overall Steps per Second: 9,106.15408

Timestep Collection Time: 4.67218
Timestep Consumption Time: 0.82125
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 5.49343

Cumulative Model Updates: 45,247
Cumulative Timesteps: 754,741,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,623.94235
Policy Entropy: 1.05617
Value Function Loss: 4.61308

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.14875
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.09917

Collected Steps per Second: 9,941.72236
Overall Steps per Second: 8,666.38049

Timestep Collection Time: 5.03172
Timestep Consumption Time: 0.74047
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.77219

Cumulative Model Updates: 45,250
Cumulative Timesteps: 754,791,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 754791032...
Checkpoint 754791032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,929.57057
Policy Entropy: 1.04082
Value Function Loss: 4.62980

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.08867

Collected Steps per Second: 10,466.18139
Overall Steps per Second: 9,148.28303

Timestep Collection Time: 4.77863
Timestep Consumption Time: 0.68841
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 5.46704

Cumulative Model Updates: 45,253
Cumulative Timesteps: 754,841,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,376.62789
Policy Entropy: 1.02843
Value Function Loss: 4.62397

Mean KL Divergence: 0.02847
SB3 Clip Fraction: 0.16889
Policy Update Magnitude: 0.06463
Value Function Update Magnitude: 0.08573

Collected Steps per Second: 10,432.17556
Overall Steps per Second: 8,880.86113

Timestep Collection Time: 4.79516
Timestep Consumption Time: 0.83762
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 5.63279

Cumulative Model Updates: 45,256
Cumulative Timesteps: 754,891,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 754891070...
Checkpoint 754891070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,726.85466
Policy Entropy: 1.04176
Value Function Loss: 4.34104

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.07428
Value Function Update Magnitude: 0.09813

Collected Steps per Second: 10,485.73500
Overall Steps per Second: 9,022.04311

Timestep Collection Time: 4.76972
Timestep Consumption Time: 0.77382
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.54353

Cumulative Model Updates: 45,259
Cumulative Timesteps: 754,941,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,871.42964
Policy Entropy: 1.04034
Value Function Loss: 4.45857

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.08424
Value Function Update Magnitude: 0.09760

Collected Steps per Second: 10,839.26765
Overall Steps per Second: 9,302.12265

Timestep Collection Time: 4.61452
Timestep Consumption Time: 0.76253
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.37705

Cumulative Model Updates: 45,262
Cumulative Timesteps: 754,991,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 754991102...
Checkpoint 754991102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650,546.81794
Policy Entropy: 1.04650
Value Function Loss: 4.38097

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.08425
Value Function Update Magnitude: 0.11473

Collected Steps per Second: 10,005.62151
Overall Steps per Second: 8,644.78854

Timestep Collection Time: 4.99919
Timestep Consumption Time: 0.78696
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.78615

Cumulative Model Updates: 45,265
Cumulative Timesteps: 755,041,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,259.68363
Policy Entropy: 1.04280
Value Function Loss: 4.43761

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.08397
Value Function Update Magnitude: 0.11037

Collected Steps per Second: 10,423.98654
Overall Steps per Second: 9,066.38105

Timestep Collection Time: 4.79701
Timestep Consumption Time: 0.71831
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.51532

Cumulative Model Updates: 45,268
Cumulative Timesteps: 755,091,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 755091126...
Checkpoint 755091126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,380.79007
Policy Entropy: 1.04151
Value Function Loss: 4.58887

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.08042
Value Function Update Magnitude: 0.11005

Collected Steps per Second: 10,428.57416
Overall Steps per Second: 8,940.98949

Timestep Collection Time: 4.79644
Timestep Consumption Time: 0.79802
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.59446

Cumulative Model Updates: 45,271
Cumulative Timesteps: 755,141,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,949.87883
Policy Entropy: 1.02816
Value Function Loss: 4.72557

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.17645
Policy Update Magnitude: 0.07254
Value Function Update Magnitude: 0.09629

Collected Steps per Second: 10,330.94221
Overall Steps per Second: 9,005.73269

Timestep Collection Time: 4.84293
Timestep Consumption Time: 0.71265
PPO Batch Consumption Time: 0.03737
Total Iteration Time: 5.55557

Cumulative Model Updates: 45,274
Cumulative Timesteps: 755,191,178

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 755191178...
Checkpoint 755191178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,687.60858
Policy Entropy: 1.04190
Value Function Loss: 4.95273

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.10234

Collected Steps per Second: 10,249.48363
Overall Steps per Second: 8,774.80219

Timestep Collection Time: 4.87868
Timestep Consumption Time: 0.81991
PPO Batch Consumption Time: 0.03924
Total Iteration Time: 5.69859

Cumulative Model Updates: 45,277
Cumulative Timesteps: 755,241,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633,095.48767
Policy Entropy: 1.04370
Value Function Loss: 4.90900

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.10662

Collected Steps per Second: 10,514.55134
Overall Steps per Second: 8,934.68173

Timestep Collection Time: 4.75760
Timestep Consumption Time: 0.84126
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.59886

Cumulative Model Updates: 45,280
Cumulative Timesteps: 755,291,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 755291206...
Checkpoint 755291206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,238.80059
Policy Entropy: 1.02988
Value Function Loss: 4.81355

Mean KL Divergence: 0.02523
SB3 Clip Fraction: 0.14994
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.09207

Collected Steps per Second: 11,310.98670
Overall Steps per Second: 9,788.79279

Timestep Collection Time: 4.42101
Timestep Consumption Time: 0.68748
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.10850

Cumulative Model Updates: 45,283
Cumulative Timesteps: 755,341,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,666.63190
Policy Entropy: 1.02894
Value Function Loss: 4.54355

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.15830
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.07778

Collected Steps per Second: 10,832.04859
Overall Steps per Second: 9,185.93517

Timestep Collection Time: 4.61630
Timestep Consumption Time: 0.82724
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.44354

Cumulative Model Updates: 45,286
Cumulative Timesteps: 755,391,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 755391216...
Checkpoint 755391216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,475.23504
Policy Entropy: 1.04197
Value Function Loss: 4.36962

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.07531

Collected Steps per Second: 11,231.86929
Overall Steps per Second: 9,509.96966

Timestep Collection Time: 4.45393
Timestep Consumption Time: 0.80644
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 5.26037

Cumulative Model Updates: 45,289
Cumulative Timesteps: 755,441,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,279.50140
Policy Entropy: 1.04872
Value Function Loss: 4.51838

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.16283
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.09399

Collected Steps per Second: 11,128.84278
Overall Steps per Second: 9,422.69991

Timestep Collection Time: 4.49535
Timestep Consumption Time: 0.81396
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.30931

Cumulative Model Updates: 45,292
Cumulative Timesteps: 755,491,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 755491270...
Checkpoint 755491270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,467.16498
Policy Entropy: 1.03442
Value Function Loss: 4.64044

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.10253

Collected Steps per Second: 11,232.73231
Overall Steps per Second: 9,557.47478

Timestep Collection Time: 4.45395
Timestep Consumption Time: 0.78070
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.23465

Cumulative Model Updates: 45,295
Cumulative Timesteps: 755,541,300

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,006.81714
Policy Entropy: 1.03594
Value Function Loss: 4.72138

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.15178
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.11212

Collected Steps per Second: 10,298.19110
Overall Steps per Second: 8,959.65540

Timestep Collection Time: 4.85716
Timestep Consumption Time: 0.72564
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 5.58280

Cumulative Model Updates: 45,298
Cumulative Timesteps: 755,591,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 755591320...
Checkpoint 755591320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,888.53842
Policy Entropy: 1.04312
Value Function Loss: 4.73486

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.11839

Collected Steps per Second: 10,643.99987
Overall Steps per Second: 9,091.71674

Timestep Collection Time: 4.69955
Timestep Consumption Time: 0.80238
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.50193

Cumulative Model Updates: 45,301
Cumulative Timesteps: 755,641,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,610.85053
Policy Entropy: 1.05198
Value Function Loss: 4.59518

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.16198
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.11308

Collected Steps per Second: 10,506.21754
Overall Steps per Second: 8,952.50212

Timestep Collection Time: 4.76004
Timestep Consumption Time: 0.82611
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 5.58615

Cumulative Model Updates: 45,304
Cumulative Timesteps: 755,691,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 755691352...
Checkpoint 755691352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,383.45701
Policy Entropy: 1.03198
Value Function Loss: 4.56677

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.09683

Collected Steps per Second: 10,492.73003
Overall Steps per Second: 9,132.68250

Timestep Collection Time: 4.76787
Timestep Consumption Time: 0.71004
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.47791

Cumulative Model Updates: 45,307
Cumulative Timesteps: 755,741,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,525.89620
Policy Entropy: 1.03650
Value Function Loss: 4.57234

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.09560

Collected Steps per Second: 10,450.64706
Overall Steps per Second: 8,936.26498

Timestep Collection Time: 4.78554
Timestep Consumption Time: 0.81098
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.59652

Cumulative Model Updates: 45,310
Cumulative Timesteps: 755,791,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 755791392...
Checkpoint 755791392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,674.82623
Policy Entropy: 1.04972
Value Function Loss: 4.51586

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.09556

Collected Steps per Second: 10,279.32003
Overall Steps per Second: 8,800.70320

Timestep Collection Time: 4.86452
Timestep Consumption Time: 0.81729
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.68182

Cumulative Model Updates: 45,313
Cumulative Timesteps: 755,841,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,787.20532
Policy Entropy: 1.05647
Value Function Loss: 4.42781

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.09147

Collected Steps per Second: 10,346.53381
Overall Steps per Second: 8,895.28159

Timestep Collection Time: 4.83544
Timestep Consumption Time: 0.78889
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.62433

Cumulative Model Updates: 45,316
Cumulative Timesteps: 755,891,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 755891426...
Checkpoint 755891426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,864.51716
Policy Entropy: 1.04359
Value Function Loss: 4.41848

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.08216

Collected Steps per Second: 10,166.86411
Overall Steps per Second: 8,768.57040

Timestep Collection Time: 4.91931
Timestep Consumption Time: 0.78447
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 5.70378

Cumulative Model Updates: 45,319
Cumulative Timesteps: 755,941,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,746.12626
Policy Entropy: 1.04541
Value Function Loss: 4.55900

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.08166

Collected Steps per Second: 10,464.60424
Overall Steps per Second: 9,136.78049

Timestep Collection Time: 4.77935
Timestep Consumption Time: 0.69457
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.47392

Cumulative Model Updates: 45,322
Cumulative Timesteps: 755,991,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 755991454...
Checkpoint 755991454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,594.03781
Policy Entropy: 1.03938
Value Function Loss: 4.53432

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.06694
Value Function Update Magnitude: 0.07998

Collected Steps per Second: 10,477.58261
Overall Steps per Second: 8,962.02332

Timestep Collection Time: 4.77362
Timestep Consumption Time: 0.80726
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 5.58088

Cumulative Model Updates: 45,325
Cumulative Timesteps: 756,041,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,805.98680
Policy Entropy: 1.05647
Value Function Loss: 4.40005

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.09801

Collected Steps per Second: 10,636.01964
Overall Steps per Second: 9,114.69995

Timestep Collection Time: 4.70176
Timestep Consumption Time: 0.78476
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 5.48652

Cumulative Model Updates: 45,328
Cumulative Timesteps: 756,091,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 756091478...
Checkpoint 756091478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,770.65086
Policy Entropy: 1.05941
Value Function Loss: 4.45748

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.09113

Collected Steps per Second: 9,950.31032
Overall Steps per Second: 8,698.80815

Timestep Collection Time: 5.02658
Timestep Consumption Time: 0.72318
PPO Batch Consumption Time: 0.03763
Total Iteration Time: 5.74975

Cumulative Model Updates: 45,331
Cumulative Timesteps: 756,141,494

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,969.19322
Policy Entropy: 1.06740
Value Function Loss: 4.62948

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.09132

Collected Steps per Second: 10,253.43979
Overall Steps per Second: 8,801.82973

Timestep Collection Time: 4.87914
Timestep Consumption Time: 0.80468
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.68382

Cumulative Model Updates: 45,334
Cumulative Timesteps: 756,191,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 756191522...
Checkpoint 756191522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,799.32129
Policy Entropy: 1.06349
Value Function Loss: 4.71093

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.09477

Collected Steps per Second: 10,367.33211
Overall Steps per Second: 9,029.67275

Timestep Collection Time: 4.82361
Timestep Consumption Time: 0.71457
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.53819

Cumulative Model Updates: 45,337
Cumulative Timesteps: 756,241,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,336.88614
Policy Entropy: 1.05950
Value Function Loss: 4.51815

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.06552
Value Function Update Magnitude: 0.09384

Collected Steps per Second: 10,358.73182
Overall Steps per Second: 8,889.21034

Timestep Collection Time: 4.82897
Timestep Consumption Time: 0.79830
PPO Batch Consumption Time: 0.03890
Total Iteration Time: 5.62727

Cumulative Model Updates: 45,340
Cumulative Timesteps: 756,291,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 756291552...
Checkpoint 756291552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534,427.39310
Policy Entropy: 1.05329
Value Function Loss: 4.29088

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.06309
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 10,428.63991
Overall Steps per Second: 8,904.42701

Timestep Collection Time: 4.79602
Timestep Consumption Time: 0.82096
PPO Batch Consumption Time: 0.03827
Total Iteration Time: 5.61698

Cumulative Model Updates: 45,343
Cumulative Timesteps: 756,341,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,032.94838
Policy Entropy: 1.04667
Value Function Loss: 4.12805

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.06465
Value Function Update Magnitude: 0.08479

Collected Steps per Second: 9,996.90092
Overall Steps per Second: 8,769.80723

Timestep Collection Time: 5.00375
Timestep Consumption Time: 0.70014
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 5.70389

Cumulative Model Updates: 45,346
Cumulative Timesteps: 756,391,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 756391590...
Checkpoint 756391590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,726.11824
Policy Entropy: 1.05732
Value Function Loss: 4.30888

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.09456

Collected Steps per Second: 10,649.88449
Overall Steps per Second: 9,084.91503

Timestep Collection Time: 4.69489
Timestep Consumption Time: 0.80874
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.50363

Cumulative Model Updates: 45,349
Cumulative Timesteps: 756,441,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,290.66562
Policy Entropy: 1.06556
Value Function Loss: 4.49614

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.11010

Collected Steps per Second: 10,523.54710
Overall Steps per Second: 9,021.11682

Timestep Collection Time: 4.75163
Timestep Consumption Time: 0.79136
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 5.54299

Cumulative Model Updates: 45,352
Cumulative Timesteps: 756,491,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 756491594...
Checkpoint 756491594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,907.06072
Policy Entropy: 1.07474
Value Function Loss: 4.63668

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.11184

Collected Steps per Second: 10,637.79230
Overall Steps per Second: 9,100.26436

Timestep Collection Time: 4.70079
Timestep Consumption Time: 0.79422
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.49501

Cumulative Model Updates: 45,355
Cumulative Timesteps: 756,541,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,505.12324
Policy Entropy: 1.06989
Value Function Loss: 4.66292

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.11105

Collected Steps per Second: 10,611.57225
Overall Steps per Second: 9,055.52621

Timestep Collection Time: 4.71410
Timestep Consumption Time: 0.81004
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 5.52414

Cumulative Model Updates: 45,358
Cumulative Timesteps: 756,591,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 756591624...
Checkpoint 756591624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,835.37909
Policy Entropy: 1.06879
Value Function Loss: 4.47792

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 10,845.80377
Overall Steps per Second: 9,257.06844

Timestep Collection Time: 4.61155
Timestep Consumption Time: 0.79145
PPO Batch Consumption Time: 0.03864
Total Iteration Time: 5.40301

Cumulative Model Updates: 45,361
Cumulative Timesteps: 756,641,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612,456.98384
Policy Entropy: 1.07390
Value Function Loss: 4.55152

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.10803

Collected Steps per Second: 10,364.95006
Overall Steps per Second: 8,885.56047

Timestep Collection Time: 4.82588
Timestep Consumption Time: 0.80348
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.62936

Cumulative Model Updates: 45,364
Cumulative Timesteps: 756,691,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 756691660...
Checkpoint 756691660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,269.89162
Policy Entropy: 1.07170
Value Function Loss: 4.50498

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.11042

Collected Steps per Second: 10,741.30049
Overall Steps per Second: 9,213.75887

Timestep Collection Time: 4.65642
Timestep Consumption Time: 0.77198
PPO Batch Consumption Time: 0.03826
Total Iteration Time: 5.42840

Cumulative Model Updates: 45,367
Cumulative Timesteps: 756,741,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,756.00306
Policy Entropy: 1.08485
Value Function Loss: 4.78493

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.12657

Collected Steps per Second: 10,432.95207
Overall Steps per Second: 8,869.34715

Timestep Collection Time: 4.79270
Timestep Consumption Time: 0.84492
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.63762

Cumulative Model Updates: 45,370
Cumulative Timesteps: 756,791,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 756791678...
Checkpoint 756791678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,753.40815
Policy Entropy: 1.08693
Value Function Loss: 4.73716

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.12078

Collected Steps per Second: 10,467.28381
Overall Steps per Second: 8,951.10103

Timestep Collection Time: 4.77889
Timestep Consumption Time: 0.80947
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 5.58836

Cumulative Model Updates: 45,373
Cumulative Timesteps: 756,841,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,095.47993
Policy Entropy: 1.08510
Value Function Loss: 4.63700

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.11293

Collected Steps per Second: 10,541.47436
Overall Steps per Second: 9,178.09297

Timestep Collection Time: 4.74507
Timestep Consumption Time: 0.70487
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.44993

Cumulative Model Updates: 45,376
Cumulative Timesteps: 756,891,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 756891720...
Checkpoint 756891720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,949.53531
Policy Entropy: 1.08437
Value Function Loss: 4.44731

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.06626
Value Function Update Magnitude: 0.10762

Collected Steps per Second: 10,224.52536
Overall Steps per Second: 8,799.02509

Timestep Collection Time: 4.89138
Timestep Consumption Time: 0.79244
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 5.68381

Cumulative Model Updates: 45,379
Cumulative Timesteps: 756,941,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,141.78399
Policy Entropy: 1.07347
Value Function Loss: 4.25305

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.06868
Value Function Update Magnitude: 0.11179

Collected Steps per Second: 10,563.93823
Overall Steps per Second: 9,204.05567

Timestep Collection Time: 4.73441
Timestep Consumption Time: 0.69950
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.43391

Cumulative Model Updates: 45,382
Cumulative Timesteps: 756,991,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 756991746...
Checkpoint 756991746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,367.90329
Policy Entropy: 1.09075
Value Function Loss: 4.48882

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.09824

Collected Steps per Second: 10,466.02393
Overall Steps per Second: 9,009.03124

Timestep Collection Time: 4.77851
Timestep Consumption Time: 0.77281
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 5.55132

Cumulative Model Updates: 45,385
Cumulative Timesteps: 757,041,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,589.86526
Policy Entropy: 1.08636
Value Function Loss: 4.57034

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.08680

Collected Steps per Second: 10,274.11830
Overall Steps per Second: 8,808.32366

Timestep Collection Time: 4.86796
Timestep Consumption Time: 0.81008
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 5.67804

Cumulative Model Updates: 45,388
Cumulative Timesteps: 757,091,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 757091772...
Checkpoint 757091772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,502.83052
Policy Entropy: 1.07276
Value Function Loss: 4.83645

Mean KL Divergence: 0.02602
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.10778

Collected Steps per Second: 10,384.09029
Overall Steps per Second: 8,904.83604

Timestep Collection Time: 4.81621
Timestep Consumption Time: 0.80006
PPO Batch Consumption Time: 0.03912
Total Iteration Time: 5.61627

Cumulative Model Updates: 45,391
Cumulative Timesteps: 757,141,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,296.25523
Policy Entropy: 1.07038
Value Function Loss: 4.71101

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.14870
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.12226

Collected Steps per Second: 10,006.20696
Overall Steps per Second: 8,624.03661

Timestep Collection Time: 4.99810
Timestep Consumption Time: 0.80104
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.79914

Cumulative Model Updates: 45,394
Cumulative Timesteps: 757,191,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 757191796...
Checkpoint 757191796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,069.15315
Policy Entropy: 1.08278
Value Function Loss: 4.75380

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.12575

Collected Steps per Second: 10,379.62591
Overall Steps per Second: 9,002.75040

Timestep Collection Time: 4.81963
Timestep Consumption Time: 0.73711
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.55675

Cumulative Model Updates: 45,397
Cumulative Timesteps: 757,241,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,984.17553
Policy Entropy: 1.09445
Value Function Loss: 4.61720

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.15137
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.10756

Collected Steps per Second: 10,481.84255
Overall Steps per Second: 8,928.51435

Timestep Collection Time: 4.77015
Timestep Consumption Time: 0.82988
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.60004

Cumulative Model Updates: 45,400
Cumulative Timesteps: 757,291,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 757291822...
Checkpoint 757291822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,513.83816
Policy Entropy: 1.08496
Value Function Loss: 4.50817

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.09608

Collected Steps per Second: 10,232.77915
Overall Steps per Second: 8,824.18354

Timestep Collection Time: 4.88704
Timestep Consumption Time: 0.78011
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.66715

Cumulative Model Updates: 45,403
Cumulative Timesteps: 757,341,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,864.71426
Policy Entropy: 1.07595
Value Function Loss: 4.50708

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.08492

Collected Steps per Second: 10,732.32253
Overall Steps per Second: 9,120.89908

Timestep Collection Time: 4.65976
Timestep Consumption Time: 0.82326
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.48301

Cumulative Model Updates: 45,406
Cumulative Timesteps: 757,391,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 757391840...
Checkpoint 757391840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,488.41325
Policy Entropy: 1.09073
Value Function Loss: 4.55376

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.08300

Collected Steps per Second: 10,375.08865
Overall Steps per Second: 8,795.45116

Timestep Collection Time: 4.81943
Timestep Consumption Time: 0.86556
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 5.68498

Cumulative Model Updates: 45,409
Cumulative Timesteps: 757,441,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,428.88688
Policy Entropy: 1.09501
Value Function Loss: 4.52613

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.06401
Value Function Update Magnitude: 0.08074

Collected Steps per Second: 11,063.83167
Overall Steps per Second: 9,506.40881

Timestep Collection Time: 4.51923
Timestep Consumption Time: 0.74038
PPO Batch Consumption Time: 0.03933
Total Iteration Time: 5.25961

Cumulative Model Updates: 45,412
Cumulative Timesteps: 757,491,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 757491842...
Checkpoint 757491842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,296.71832
Policy Entropy: 1.08993
Value Function Loss: 4.63797

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.06329
Value Function Update Magnitude: 0.07036

Collected Steps per Second: 11,295.52256
Overall Steps per Second: 9,554.99501

Timestep Collection Time: 4.42883
Timestep Consumption Time: 0.80675
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.23559

Cumulative Model Updates: 45,415
Cumulative Timesteps: 757,541,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,650.41701
Policy Entropy: 1.09885
Value Function Loss: 4.64436

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.05974

Collected Steps per Second: 11,335.54938
Overall Steps per Second: 9,628.52836

Timestep Collection Time: 4.41126
Timestep Consumption Time: 0.78206
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.19332

Cumulative Model Updates: 45,418
Cumulative Timesteps: 757,591,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 757591872...
Checkpoint 757591872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,678.27685
Policy Entropy: 1.09174
Value Function Loss: 4.71845

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.07172
Value Function Update Magnitude: 0.07492

Collected Steps per Second: 11,251.54682
Overall Steps per Second: 9,565.17805

Timestep Collection Time: 4.44437
Timestep Consumption Time: 0.78355
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.22792

Cumulative Model Updates: 45,421
Cumulative Timesteps: 757,641,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,235.92801
Policy Entropy: 1.09889
Value Function Loss: 4.61931

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.07686
Value Function Update Magnitude: 0.07400

Collected Steps per Second: 11,267.81432
Overall Steps per Second: 9,527.59658

Timestep Collection Time: 4.43831
Timestep Consumption Time: 0.81066
PPO Batch Consumption Time: 0.03788
Total Iteration Time: 5.24896

Cumulative Model Updates: 45,424
Cumulative Timesteps: 757,691,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 757691888...
Checkpoint 757691888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,608.61176
Policy Entropy: 1.09116
Value Function Loss: 4.60571

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.07367
Value Function Update Magnitude: 0.06951

Collected Steps per Second: 10,678.99910
Overall Steps per Second: 9,277.14210

Timestep Collection Time: 4.68471
Timestep Consumption Time: 0.70790
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.39261

Cumulative Model Updates: 45,427
Cumulative Timesteps: 757,741,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,133.61831
Policy Entropy: 1.10256
Value Function Loss: 4.53297

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.07289

Collected Steps per Second: 10,689.02681
Overall Steps per Second: 9,094.03536

Timestep Collection Time: 4.67957
Timestep Consumption Time: 0.82074
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.50031

Cumulative Model Updates: 45,430
Cumulative Timesteps: 757,791,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 757791936...
Checkpoint 757791936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,792.91660
Policy Entropy: 1.09991
Value Function Loss: 4.54325

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.06717

Collected Steps per Second: 10,774.23368
Overall Steps per Second: 9,209.38661

Timestep Collection Time: 4.64219
Timestep Consumption Time: 0.78879
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.43098

Cumulative Model Updates: 45,433
Cumulative Timesteps: 757,841,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,600.13310
Policy Entropy: 1.10206
Value Function Loss: 4.46705

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.11185
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 10,694.65529
Overall Steps per Second: 9,104.13823

Timestep Collection Time: 4.67523
Timestep Consumption Time: 0.81678
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 5.49201

Cumulative Model Updates: 45,436
Cumulative Timesteps: 757,891,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 757891952...
Checkpoint 757891952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,415.56086
Policy Entropy: 1.09621
Value Function Loss: 4.79012

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 10,381.25102
Overall Steps per Second: 8,966.21020

Timestep Collection Time: 4.81811
Timestep Consumption Time: 0.76039
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.57850

Cumulative Model Updates: 45,439
Cumulative Timesteps: 757,941,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,646.31327
Policy Entropy: 1.10070
Value Function Loss: 4.82526

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.07628

Collected Steps per Second: 10,248.84204
Overall Steps per Second: 8,897.68963

Timestep Collection Time: 4.87938
Timestep Consumption Time: 0.74095
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.62034

Cumulative Model Updates: 45,442
Cumulative Timesteps: 757,991,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 757991978...
Checkpoint 757991978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,150.48061
Policy Entropy: 1.10405
Value Function Loss: 4.86913

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.07946

Collected Steps per Second: 10,198.16089
Overall Steps per Second: 8,774.17022

Timestep Collection Time: 4.90441
Timestep Consumption Time: 0.79595
PPO Batch Consumption Time: 0.03856
Total Iteration Time: 5.70037

Cumulative Model Updates: 45,445
Cumulative Timesteps: 758,041,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,267.94894
Policy Entropy: 1.10924
Value Function Loss: 4.85328

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.07911

Collected Steps per Second: 10,262.56207
Overall Steps per Second: 8,842.73269

Timestep Collection Time: 4.87344
Timestep Consumption Time: 0.78250
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.65594

Cumulative Model Updates: 45,448
Cumulative Timesteps: 758,092,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 758092008...
Checkpoint 758092008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,791.69193
Policy Entropy: 1.09938
Value Function Loss: 4.77908

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.07694

Collected Steps per Second: 10,704.25203
Overall Steps per Second: 9,146.69477

Timestep Collection Time: 4.67198
Timestep Consumption Time: 0.79557
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.46755

Cumulative Model Updates: 45,451
Cumulative Timesteps: 758,142,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,073.89165
Policy Entropy: 1.09694
Value Function Loss: 4.51621

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.08192

Collected Steps per Second: 10,295.99652
Overall Steps per Second: 8,915.53416

Timestep Collection Time: 4.85742
Timestep Consumption Time: 0.75211
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.60953

Cumulative Model Updates: 45,454
Cumulative Timesteps: 758,192,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 758192030...
Checkpoint 758192030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481,628.80516
Policy Entropy: 1.10736
Value Function Loss: 4.18040

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.08333

Collected Steps per Second: 10,498.10255
Overall Steps per Second: 9,193.41214

Timestep Collection Time: 4.76562
Timestep Consumption Time: 0.67632
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.44194

Cumulative Model Updates: 45,457
Cumulative Timesteps: 758,242,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,172.96465
Policy Entropy: 1.10684
Value Function Loss: 4.23634

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.07690

Collected Steps per Second: 10,118.38236
Overall Steps per Second: 8,736.46747

Timestep Collection Time: 4.94170
Timestep Consumption Time: 0.78167
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.72337

Cumulative Model Updates: 45,460
Cumulative Timesteps: 758,292,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 758292062...
Checkpoint 758292062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,221.39247
Policy Entropy: 1.11470
Value Function Loss: 4.61340

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.06106
Value Function Update Magnitude: 0.07077

Collected Steps per Second: 10,706.45106
Overall Steps per Second: 9,157.72818

Timestep Collection Time: 4.67064
Timestep Consumption Time: 0.78988
PPO Batch Consumption Time: 0.03942
Total Iteration Time: 5.46052

Cumulative Model Updates: 45,463
Cumulative Timesteps: 758,342,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,036.48848
Policy Entropy: 1.10902
Value Function Loss: 4.82007

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.06868
Value Function Update Magnitude: 0.07274

Collected Steps per Second: 10,825.59443
Overall Steps per Second: 9,112.30523

Timestep Collection Time: 4.62016
Timestep Consumption Time: 0.86868
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 5.48884

Cumulative Model Updates: 45,466
Cumulative Timesteps: 758,392,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 758392084...
Checkpoint 758392084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,507.50353
Policy Entropy: 1.10933
Value Function Loss: 4.71120

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.06808
Value Function Update Magnitude: 0.10091

Collected Steps per Second: 10,642.47961
Overall Steps per Second: 9,181.87406

Timestep Collection Time: 4.70078
Timestep Consumption Time: 0.74778
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.44856

Cumulative Model Updates: 45,469
Cumulative Timesteps: 758,442,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,499.76734
Policy Entropy: 1.08840
Value Function Loss: 4.41914

Mean KL Divergence: 0.02926
SB3 Clip Fraction: 0.17715
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.11111

Collected Steps per Second: 10,369.80718
Overall Steps per Second: 9,062.33630

Timestep Collection Time: 4.82304
Timestep Consumption Time: 0.69585
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.51889

Cumulative Model Updates: 45,472
Cumulative Timesteps: 758,492,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 758492126...
Checkpoint 758492126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,506.81700
Policy Entropy: 1.10017
Value Function Loss: 4.56692

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.10715

Collected Steps per Second: 10,772.71807
Overall Steps per Second: 9,052.67467

Timestep Collection Time: 4.64247
Timestep Consumption Time: 0.88209
PPO Batch Consumption Time: 0.04589
Total Iteration Time: 5.52456

Cumulative Model Updates: 45,475
Cumulative Timesteps: 758,542,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,814.40077
Policy Entropy: 1.10052
Value Function Loss: 4.61385

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.10218

Collected Steps per Second: 10,980.74953
Overall Steps per Second: 9,530.90440

Timestep Collection Time: 4.55524
Timestep Consumption Time: 0.69295
PPO Batch Consumption Time: 0.03379
Total Iteration Time: 5.24819

Cumulative Model Updates: 45,478
Cumulative Timesteps: 758,592,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 758592158...
Checkpoint 758592158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,500.61303
Policy Entropy: 1.09585
Value Function Loss: 4.83561

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.10463

Collected Steps per Second: 10,711.77824
Overall Steps per Second: 9,168.96676

Timestep Collection Time: 4.67019
Timestep Consumption Time: 0.78583
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 5.45601

Cumulative Model Updates: 45,481
Cumulative Timesteps: 758,642,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,106.76191
Policy Entropy: 1.09019
Value Function Loss: 4.79005

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.10977

Collected Steps per Second: 11,127.73152
Overall Steps per Second: 9,488.80694

Timestep Collection Time: 4.49508
Timestep Consumption Time: 0.77640
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.27147

Cumulative Model Updates: 45,484
Cumulative Timesteps: 758,692,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 758692204...
Checkpoint 758692204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,555.02937
Policy Entropy: 1.09770
Value Function Loss: 4.65314

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.11255

Collected Steps per Second: 11,038.80668
Overall Steps per Second: 9,648.54648

Timestep Collection Time: 4.52948
Timestep Consumption Time: 0.65265
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 5.18213

Cumulative Model Updates: 45,487
Cumulative Timesteps: 758,742,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,145.78577
Policy Entropy: 1.09983
Value Function Loss: 4.45524

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.15089
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.10609

Collected Steps per Second: 11,070.35324
Overall Steps per Second: 9,419.94547

Timestep Collection Time: 4.51711
Timestep Consumption Time: 0.79141
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 5.30852

Cumulative Model Updates: 45,490
Cumulative Timesteps: 758,792,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 758792210...
Checkpoint 758792210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,294.38833
Policy Entropy: 1.08379
Value Function Loss: 4.36699

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.10945

Collected Steps per Second: 10,467.99291
Overall Steps per Second: 9,171.32152

Timestep Collection Time: 4.77799
Timestep Consumption Time: 0.67553
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.45352

Cumulative Model Updates: 45,493
Cumulative Timesteps: 758,842,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,777.20579
Policy Entropy: 1.07568
Value Function Loss: 4.44850

Mean KL Divergence: 0.02762
SB3 Clip Fraction: 0.15965
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.12984

Collected Steps per Second: 10,820.84450
Overall Steps per Second: 9,290.50402

Timestep Collection Time: 4.62237
Timestep Consumption Time: 0.76140
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.38378

Cumulative Model Updates: 45,496
Cumulative Timesteps: 758,892,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 758892244...
Checkpoint 758892244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,943.74193
Policy Entropy: 1.08690
Value Function Loss: 4.32730

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.11444
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.11780

Collected Steps per Second: 10,899.39015
Overall Steps per Second: 9,359.45955

Timestep Collection Time: 4.58888
Timestep Consumption Time: 0.75502
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.34390

Cumulative Model Updates: 45,499
Cumulative Timesteps: 758,942,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,972.00430
Policy Entropy: 1.09304
Value Function Loss: 4.23751

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 11,040.86347
Overall Steps per Second: 9,391.56540

Timestep Collection Time: 4.52899
Timestep Consumption Time: 0.79536
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 5.32435

Cumulative Model Updates: 45,502
Cumulative Timesteps: 758,992,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 758992264...
Checkpoint 758992264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,866.58499
Policy Entropy: 1.06795
Value Function Loss: 4.40769

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.10411

Collected Steps per Second: 10,826.38552
Overall Steps per Second: 9,251.78159

Timestep Collection Time: 4.61982
Timestep Consumption Time: 0.78627
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.40609

Cumulative Model Updates: 45,505
Cumulative Timesteps: 759,042,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,484.41687
Policy Entropy: 1.08739
Value Function Loss: 4.55432

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.14777
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.10435

Collected Steps per Second: 10,849.40112
Overall Steps per Second: 9,341.50339

Timestep Collection Time: 4.60984
Timestep Consumption Time: 0.74412
PPO Batch Consumption Time: 0.03850
Total Iteration Time: 5.35396

Cumulative Model Updates: 45,508
Cumulative Timesteps: 759,092,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 759092294...
Checkpoint 759092294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,246.95762
Policy Entropy: 1.08677
Value Function Loss: 4.63705

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.09479

Collected Steps per Second: 10,065.43418
Overall Steps per Second: 8,714.00203

Timestep Collection Time: 4.96988
Timestep Consumption Time: 0.77077
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.74065

Cumulative Model Updates: 45,511
Cumulative Timesteps: 759,142,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,970.10633
Policy Entropy: 1.07722
Value Function Loss: 4.37744

Mean KL Divergence: 0.02844
SB3 Clip Fraction: 0.14685
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.08528

Collected Steps per Second: 10,494.51677
Overall Steps per Second: 9,031.02281

Timestep Collection Time: 4.76744
Timestep Consumption Time: 0.77257
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.54001

Cumulative Model Updates: 45,514
Cumulative Timesteps: 759,192,350

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 759192350...
Checkpoint 759192350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,017.50651
Policy Entropy: 1.06672
Value Function Loss: 4.40633

Mean KL Divergence: 0.02661
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.08973

Collected Steps per Second: 10,456.56086
Overall Steps per Second: 9,160.26581

Timestep Collection Time: 4.78398
Timestep Consumption Time: 0.67699
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 5.46098

Cumulative Model Updates: 45,517
Cumulative Timesteps: 759,242,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,693.35813
Policy Entropy: 1.08070
Value Function Loss: 4.35650

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.08146

Collected Steps per Second: 10,547.53363
Overall Steps per Second: 9,078.78572

Timestep Collection Time: 4.74139
Timestep Consumption Time: 0.76705
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.50845

Cumulative Model Updates: 45,520
Cumulative Timesteps: 759,292,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 759292384...
Checkpoint 759292384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,351.68350
Policy Entropy: 1.07832
Value Function Loss: 4.62248

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.07692

Collected Steps per Second: 10,673.54234
Overall Steps per Second: 9,336.33146

Timestep Collection Time: 4.68729
Timestep Consumption Time: 0.67134
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.35864

Cumulative Model Updates: 45,523
Cumulative Timesteps: 759,342,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,186.75607
Policy Entropy: 1.06451
Value Function Loss: 4.68455

Mean KL Divergence: 0.02795
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.07779

Collected Steps per Second: 10,268.40642
Overall Steps per Second: 8,760.97833

Timestep Collection Time: 4.87164
Timestep Consumption Time: 0.83822
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.70986

Cumulative Model Updates: 45,526
Cumulative Timesteps: 759,392,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 759392438...
Checkpoint 759392438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,024.23730
Policy Entropy: 1.07687
Value Function Loss: 4.77969

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.07292

Collected Steps per Second: 10,428.60320
Overall Steps per Second: 9,001.92174

Timestep Collection Time: 4.79489
Timestep Consumption Time: 0.75992
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.55481

Cumulative Model Updates: 45,529
Cumulative Timesteps: 759,442,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,315.35926
Policy Entropy: 1.07273
Value Function Loss: 4.76580

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.06627

Collected Steps per Second: 10,690.61181
Overall Steps per Second: 9,299.71596

Timestep Collection Time: 4.67981
Timestep Consumption Time: 0.69993
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.37973

Cumulative Model Updates: 45,532
Cumulative Timesteps: 759,492,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 759492472...
Checkpoint 759492472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,737.67052
Policy Entropy: 1.06166
Value Function Loss: 4.51270

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.07508

Collected Steps per Second: 10,565.04394
Overall Steps per Second: 8,973.38162

Timestep Collection Time: 4.73353
Timestep Consumption Time: 0.83962
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.57315

Cumulative Model Updates: 45,535
Cumulative Timesteps: 759,542,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,521.42127
Policy Entropy: 1.04830
Value Function Loss: 4.29776

Mean KL Divergence: 0.02871
SB3 Clip Fraction: 0.17567
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.07454

Collected Steps per Second: 10,429.34803
Overall Steps per Second: 8,948.90175

Timestep Collection Time: 4.79608
Timestep Consumption Time: 0.79343
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.58951

Cumulative Model Updates: 45,538
Cumulative Timesteps: 759,592,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 759592502...
Checkpoint 759592502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,117.02888
Policy Entropy: 1.06293
Value Function Loss: 4.37028

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.07334

Collected Steps per Second: 10,580.58842
Overall Steps per Second: 8,916.75052

Timestep Collection Time: 4.72564
Timestep Consumption Time: 0.88179
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.60742

Cumulative Model Updates: 45,541
Cumulative Timesteps: 759,642,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469,020.18187
Policy Entropy: 1.06336
Value Function Loss: 4.67977

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.06649

Collected Steps per Second: 11,468.38503
Overall Steps per Second: 9,728.36755

Timestep Collection Time: 4.36138
Timestep Consumption Time: 0.78008
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.14146

Cumulative Model Updates: 45,544
Cumulative Timesteps: 759,692,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 759692520...
Checkpoint 759692520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,000.42440
Policy Entropy: 1.05663
Value Function Loss: 4.62514

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.06479

Collected Steps per Second: 11,345.53911
Overall Steps per Second: 9,714.15553

Timestep Collection Time: 4.40825
Timestep Consumption Time: 0.74032
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.14857

Cumulative Model Updates: 45,547
Cumulative Timesteps: 759,742,534

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,721.84977
Policy Entropy: 1.03543
Value Function Loss: 4.40878

Mean KL Divergence: 0.05200
SB3 Clip Fraction: 0.21547
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.07607

Collected Steps per Second: 11,764.69924
Overall Steps per Second: 9,928.23057

Timestep Collection Time: 4.25068
Timestep Consumption Time: 0.78627
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.03695

Cumulative Model Updates: 45,550
Cumulative Timesteps: 759,792,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 759792542...
Checkpoint 759792542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,508.16959
Policy Entropy: 1.07635
Value Function Loss: 3.91008

Mean KL Divergence: 0.04326
SB3 Clip Fraction: 0.19263
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.07867

Collected Steps per Second: 11,467.71712
Overall Steps per Second: 9,724.27318

Timestep Collection Time: 4.36041
Timestep Consumption Time: 0.78177
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.14218

Cumulative Model Updates: 45,553
Cumulative Timesteps: 759,842,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,655.17606
Policy Entropy: 1.04355
Value Function Loss: 4.15108

Mean KL Divergence: 0.05490
SB3 Clip Fraction: 0.23156
Policy Update Magnitude: 0.04374
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 11,803.77150
Overall Steps per Second: 9,994.33952

Timestep Collection Time: 4.23797
Timestep Consumption Time: 0.76727
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.00523

Cumulative Model Updates: 45,556
Cumulative Timesteps: 759,892,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 759892570...
Checkpoint 759892570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,733.06411
Policy Entropy: 1.06708
Value Function Loss: 4.36803

Mean KL Divergence: 0.03817
SB3 Clip Fraction: 0.18491
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.08892

Collected Steps per Second: 10,937.22241
Overall Steps per Second: 9,249.49824

Timestep Collection Time: 4.57392
Timestep Consumption Time: 0.83459
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 5.40851

Cumulative Model Updates: 45,559
Cumulative Timesteps: 759,942,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,565.86613
Policy Entropy: 1.03963
Value Function Loss: 4.93717

Mean KL Divergence: 0.03635
SB3 Clip Fraction: 0.18891
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.10070

Collected Steps per Second: 10,815.18857
Overall Steps per Second: 9,254.58085

Timestep Collection Time: 4.62461
Timestep Consumption Time: 0.77985
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 5.40446

Cumulative Model Updates: 45,562
Cumulative Timesteps: 759,992,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 759992612...
Checkpoint 759992612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,143.73114
Policy Entropy: 1.06222
Value Function Loss: 4.71649

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.10280

Collected Steps per Second: 10,476.14597
Overall Steps per Second: 8,982.11724

Timestep Collection Time: 4.77370
Timestep Consumption Time: 0.79403
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.56773

Cumulative Model Updates: 45,565
Cumulative Timesteps: 760,042,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,000.34173
Policy Entropy: 1.06484
Value Function Loss: 4.62796

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.10549

Collected Steps per Second: 10,820.99314
Overall Steps per Second: 9,244.68673

Timestep Collection Time: 4.62157
Timestep Consumption Time: 0.78802
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.40959

Cumulative Model Updates: 45,568
Cumulative Timesteps: 760,092,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 760092632...
Checkpoint 760092632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,571.31074
Policy Entropy: 1.05219
Value Function Loss: 4.40711

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.10624

Collected Steps per Second: 10,680.17234
Overall Steps per Second: 9,163.69116

Timestep Collection Time: 4.68307
Timestep Consumption Time: 0.77499
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.45806

Cumulative Model Updates: 45,571
Cumulative Timesteps: 760,142,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,827.26671
Policy Entropy: 1.05538
Value Function Loss: 4.40090

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.10787

Collected Steps per Second: 10,750.12402
Overall Steps per Second: 9,191.86941

Timestep Collection Time: 4.65223
Timestep Consumption Time: 0.78867
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.44090

Cumulative Model Updates: 45,574
Cumulative Timesteps: 760,192,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 760192660...
Checkpoint 760192660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,777.43895
Policy Entropy: 1.06582
Value Function Loss: 4.51211

Mean KL Divergence: 0.02143
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.10622

Collected Steps per Second: 10,288.13760
Overall Steps per Second: 8,985.64424

Timestep Collection Time: 4.86074
Timestep Consumption Time: 0.70458
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 5.56532

Cumulative Model Updates: 45,577
Cumulative Timesteps: 760,242,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,618.54416
Policy Entropy: 1.04332
Value Function Loss: 4.58798

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.09550

Collected Steps per Second: 10,633.91542
Overall Steps per Second: 9,088.15224

Timestep Collection Time: 4.70250
Timestep Consumption Time: 0.79983
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.50233

Cumulative Model Updates: 45,580
Cumulative Timesteps: 760,292,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 760292674...
Checkpoint 760292674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,729.07437
Policy Entropy: 1.04508
Value Function Loss: 4.58237

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.08369

Collected Steps per Second: 10,515.28867
Overall Steps per Second: 9,044.81476

Timestep Collection Time: 4.75688
Timestep Consumption Time: 0.77336
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.53024

Cumulative Model Updates: 45,583
Cumulative Timesteps: 760,342,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,991.08732
Policy Entropy: 1.04628
Value Function Loss: 4.32341

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.08631

Collected Steps per Second: 10,856.11324
Overall Steps per Second: 9,306.61096

Timestep Collection Time: 4.60681
Timestep Consumption Time: 0.76701
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.37381

Cumulative Model Updates: 45,586
Cumulative Timesteps: 760,392,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 760392706...
Checkpoint 760392706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,844.42185
Policy Entropy: 1.05439
Value Function Loss: 4.37992

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.09197

Collected Steps per Second: 10,693.49062
Overall Steps per Second: 9,266.21802

Timestep Collection Time: 4.67574
Timestep Consumption Time: 0.72020
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.39594

Cumulative Model Updates: 45,589
Cumulative Timesteps: 760,442,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,450.88895
Policy Entropy: 1.05021
Value Function Loss: 4.51480

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.08568

Collected Steps per Second: 10,199.47570
Overall Steps per Second: 8,943.37363

Timestep Collection Time: 4.90339
Timestep Consumption Time: 0.68868
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.59207

Cumulative Model Updates: 45,592
Cumulative Timesteps: 760,492,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 760492718...
Checkpoint 760492718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,924.32796
Policy Entropy: 1.05453
Value Function Loss: 4.70719

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.06295
Value Function Update Magnitude: 0.08376

Collected Steps per Second: 10,495.23374
Overall Steps per Second: 8,945.02767

Timestep Collection Time: 4.76464
Timestep Consumption Time: 0.82573
PPO Batch Consumption Time: 0.04007
Total Iteration Time: 5.59037

Cumulative Model Updates: 45,595
Cumulative Timesteps: 760,542,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,185.95168
Policy Entropy: 1.05895
Value Function Loss: 4.46660

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.07696

Collected Steps per Second: 10,570.97537
Overall Steps per Second: 9,241.32209

Timestep Collection Time: 4.73031
Timestep Consumption Time: 0.68060
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.41091

Cumulative Model Updates: 45,598
Cumulative Timesteps: 760,592,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 760592728...
Checkpoint 760592728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,002.07401
Policy Entropy: 1.06150
Value Function Loss: 4.41135

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.08281

Collected Steps per Second: 10,532.36413
Overall Steps per Second: 9,039.89082

Timestep Collection Time: 4.74841
Timestep Consumption Time: 0.78396
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.53237

Cumulative Model Updates: 45,601
Cumulative Timesteps: 760,642,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,231.02994
Policy Entropy: 1.07526
Value Function Loss: 4.44805

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.08484

Collected Steps per Second: 10,574.13292
Overall Steps per Second: 9,065.60677

Timestep Collection Time: 4.72947
Timestep Consumption Time: 0.78699
PPO Batch Consumption Time: 0.04056
Total Iteration Time: 5.51645

Cumulative Model Updates: 45,604
Cumulative Timesteps: 760,692,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 760692750...
Checkpoint 760692750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,416.80212
Policy Entropy: 1.08881
Value Function Loss: 4.55104

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.17539
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.08397

Collected Steps per Second: 10,535.86356
Overall Steps per Second: 9,191.81058

Timestep Collection Time: 4.74589
Timestep Consumption Time: 0.69396
PPO Batch Consumption Time: 0.04004
Total Iteration Time: 5.43984

Cumulative Model Updates: 45,607
Cumulative Timesteps: 760,742,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,728.10988
Policy Entropy: 1.07078
Value Function Loss: 4.52377

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.08994

Collected Steps per Second: 10,655.59662
Overall Steps per Second: 9,146.58325

Timestep Collection Time: 4.69312
Timestep Consumption Time: 0.77428
PPO Batch Consumption Time: 0.03802
Total Iteration Time: 5.46740

Cumulative Model Updates: 45,610
Cumulative Timesteps: 760,792,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 760792760...
Checkpoint 760792760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,628.92169
Policy Entropy: 1.07598
Value Function Loss: 4.16582

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.08560

Collected Steps per Second: 10,835.30224
Overall Steps per Second: 9,351.79667

Timestep Collection Time: 4.61602
Timestep Consumption Time: 0.73225
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.34828

Cumulative Model Updates: 45,613
Cumulative Timesteps: 760,842,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,640.13272
Policy Entropy: 1.08164
Value Function Loss: 4.29938

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.07471

Collected Steps per Second: 11,287.21941
Overall Steps per Second: 9,625.79677

Timestep Collection Time: 4.43121
Timestep Consumption Time: 0.76483
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.19604

Cumulative Model Updates: 45,616
Cumulative Timesteps: 760,892,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 760892792...
Checkpoint 760892792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,738.29765
Policy Entropy: 1.07516
Value Function Loss: 4.29004

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.06548
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 10,865.32211
Overall Steps per Second: 9,339.36148

Timestep Collection Time: 4.60235
Timestep Consumption Time: 0.75198
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.35433

Cumulative Model Updates: 45,619
Cumulative Timesteps: 760,942,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,790.24479
Policy Entropy: 1.06868
Value Function Loss: 4.57163

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.07359
Value Function Update Magnitude: 0.06954

Collected Steps per Second: 11,110.00238
Overall Steps per Second: 9,644.58186

Timestep Collection Time: 4.50063
Timestep Consumption Time: 0.68384
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.18447

Cumulative Model Updates: 45,622
Cumulative Timesteps: 760,992,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 760992800...
Checkpoint 760992800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,719.86192
Policy Entropy: 1.05765
Value Function Loss: 4.55635

Mean KL Divergence: 0.02811
SB3 Clip Fraction: 0.18686
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.06914

Collected Steps per Second: 10,657.68963
Overall Steps per Second: 9,048.02673

Timestep Collection Time: 4.69239
Timestep Consumption Time: 0.83479
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 5.52717

Cumulative Model Updates: 45,625
Cumulative Timesteps: 761,042,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,938.13841
Policy Entropy: 1.07672
Value Function Loss: 4.76336

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 10,734.09879
Overall Steps per Second: 9,267.26961

Timestep Collection Time: 4.65805
Timestep Consumption Time: 0.73728
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.39533

Cumulative Model Updates: 45,628
Cumulative Timesteps: 761,092,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 761092810...
Checkpoint 761092810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,917.86262
Policy Entropy: 1.07642
Value Function Loss: 4.88997

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.07302

Collected Steps per Second: 10,327.93059
Overall Steps per Second: 8,896.71486

Timestep Collection Time: 4.84279
Timestep Consumption Time: 0.77906
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.62185

Cumulative Model Updates: 45,631
Cumulative Timesteps: 761,142,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,368.70320
Policy Entropy: 1.06943
Value Function Loss: 4.65645

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.08717

Collected Steps per Second: 10,498.48649
Overall Steps per Second: 9,022.63630

Timestep Collection Time: 4.76469
Timestep Consumption Time: 0.77937
PPO Batch Consumption Time: 0.03761
Total Iteration Time: 5.54406

Cumulative Model Updates: 45,634
Cumulative Timesteps: 761,192,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 761192848...
Checkpoint 761192848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,973.23756
Policy Entropy: 1.06665
Value Function Loss: 4.57452

Mean KL Divergence: 0.02661
SB3 Clip Fraction: 0.17671
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.08343

Collected Steps per Second: 10,396.35069
Overall Steps per Second: 9,116.68884

Timestep Collection Time: 4.81246
Timestep Consumption Time: 0.67550
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.48796

Cumulative Model Updates: 45,637
Cumulative Timesteps: 761,242,880

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,487.60393
Policy Entropy: 1.07704
Value Function Loss: 4.52170

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.07217

Collected Steps per Second: 10,729.51131
Overall Steps per Second: 9,141.77494

Timestep Collection Time: 4.66154
Timestep Consumption Time: 0.80961
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 5.47115

Cumulative Model Updates: 45,640
Cumulative Timesteps: 761,292,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 761292896...
Checkpoint 761292896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,894.03207
Policy Entropy: 1.08925
Value Function Loss: 4.55788

Mean KL Divergence: 0.02316
SB3 Clip Fraction: 0.16993
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.07855

Collected Steps per Second: 10,111.68882
Overall Steps per Second: 8,915.64775

Timestep Collection Time: 4.94734
Timestep Consumption Time: 0.66369
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.61103

Cumulative Model Updates: 45,643
Cumulative Timesteps: 761,342,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,049.54972
Policy Entropy: 1.05642
Value Function Loss: 4.44264

Mean KL Divergence: 0.04892
SB3 Clip Fraction: 0.21357
Policy Update Magnitude: 0.05949
Value Function Update Magnitude: 0.08553

Collected Steps per Second: 10,695.54814
Overall Steps per Second: 9,123.12412

Timestep Collection Time: 4.67540
Timestep Consumption Time: 0.80583
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 5.48124

Cumulative Model Updates: 45,646
Cumulative Timesteps: 761,392,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 761392928...
Checkpoint 761392928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,642.32955
Policy Entropy: 1.07849
Value Function Loss: 4.44500

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.16491
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.08936

Collected Steps per Second: 10,545.06897
Overall Steps per Second: 9,137.53219

Timestep Collection Time: 4.74193
Timestep Consumption Time: 0.73044
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.47237

Cumulative Model Updates: 45,649
Cumulative Timesteps: 761,442,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,164.69466
Policy Entropy: 1.06477
Value Function Loss: 4.51342

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.15984
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.08768

Collected Steps per Second: 10,722.94954
Overall Steps per Second: 9,235.97482

Timestep Collection Time: 4.66364
Timestep Consumption Time: 0.75084
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 5.41448

Cumulative Model Updates: 45,652
Cumulative Timesteps: 761,492,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 761492940...
Checkpoint 761492940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,295.40701
Policy Entropy: 1.06243
Value Function Loss: 4.74181

Mean KL Divergence: 0.02602
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.09911

Collected Steps per Second: 10,658.00772
Overall Steps per Second: 9,186.31458

Timestep Collection Time: 4.69206
Timestep Consumption Time: 0.75169
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.44375

Cumulative Model Updates: 45,655
Cumulative Timesteps: 761,542,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,114.00865
Policy Entropy: 1.06837
Value Function Loss: 4.43975

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.09505

Collected Steps per Second: 10,214.17809
Overall Steps per Second: 8,918.96231

Timestep Collection Time: 4.89594
Timestep Consumption Time: 0.71099
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.60693

Cumulative Model Updates: 45,658
Cumulative Timesteps: 761,592,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 761592956...
Checkpoint 761592956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,505.64903
Policy Entropy: 1.07336
Value Function Loss: 4.35930

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.09009

Collected Steps per Second: 10,613.37674
Overall Steps per Second: 9,148.44652

Timestep Collection Time: 4.71236
Timestep Consumption Time: 0.75458
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.46694

Cumulative Model Updates: 45,661
Cumulative Timesteps: 761,642,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,259.55479
Policy Entropy: 1.08477
Value Function Loss: 4.26817

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.06140
Value Function Update Magnitude: 0.08987

Collected Steps per Second: 10,417.68535
Overall Steps per Second: 9,000.35201

Timestep Collection Time: 4.79991
Timestep Consumption Time: 0.75587
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.55578

Cumulative Model Updates: 45,664
Cumulative Timesteps: 761,692,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 761692974...
Checkpoint 761692974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,842.89694
Policy Entropy: 1.08417
Value Function Loss: 4.58741

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.08373

Collected Steps per Second: 10,736.58978
Overall Steps per Second: 9,177.71083

Timestep Collection Time: 4.65865
Timestep Consumption Time: 0.79129
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.44994

Cumulative Model Updates: 45,667
Cumulative Timesteps: 761,742,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,261.58834
Policy Entropy: 1.08646
Value Function Loss: 4.51707

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.09173

Collected Steps per Second: 10,609.37359
Overall Steps per Second: 9,080.27470

Timestep Collection Time: 4.71300
Timestep Consumption Time: 0.79366
PPO Batch Consumption Time: 0.03816
Total Iteration Time: 5.50666

Cumulative Model Updates: 45,670
Cumulative Timesteps: 761,792,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 761792994...
Checkpoint 761792994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,069.65371
Policy Entropy: 1.08526
Value Function Loss: 4.47233

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.06234
Value Function Update Magnitude: 0.09574

Collected Steps per Second: 10,579.57760
Overall Steps per Second: 9,080.98005

Timestep Collection Time: 4.72779
Timestep Consumption Time: 0.78021
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 5.50800

Cumulative Model Updates: 45,673
Cumulative Timesteps: 761,843,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,365.46233
Policy Entropy: 1.08711
Value Function Loss: 4.58686

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.09684

Collected Steps per Second: 10,585.28821
Overall Steps per Second: 9,015.31285

Timestep Collection Time: 4.72467
Timestep Consumption Time: 0.82278
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.54745

Cumulative Model Updates: 45,676
Cumulative Timesteps: 761,893,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 761893024...
Checkpoint 761893024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,249.37144
Policy Entropy: 1.08425
Value Function Loss: 4.99045

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.09251

Collected Steps per Second: 11,111.10001
Overall Steps per Second: 9,438.67400

Timestep Collection Time: 4.50216
Timestep Consumption Time: 0.79773
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 5.29990

Cumulative Model Updates: 45,679
Cumulative Timesteps: 761,943,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,925.77465
Policy Entropy: 1.09079
Value Function Loss: 5.14109

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.10246

Collected Steps per Second: 11,149.50764
Overall Steps per Second: 9,416.48222

Timestep Collection Time: 4.48504
Timestep Consumption Time: 0.82543
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.31048

Cumulative Model Updates: 45,682
Cumulative Timesteps: 761,993,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 761993054...
Checkpoint 761993054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506,046.88243
Policy Entropy: 1.09385
Value Function Loss: 4.94860

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.06378
Value Function Update Magnitude: 0.10899

Collected Steps per Second: 11,493.31103
Overall Steps per Second: 9,699.72707

Timestep Collection Time: 4.35070
Timestep Consumption Time: 0.80449
PPO Batch Consumption Time: 0.03821
Total Iteration Time: 5.15520

Cumulative Model Updates: 45,685
Cumulative Timesteps: 762,043,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,306.43494
Policy Entropy: 1.10402
Value Function Loss: 4.47058

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.06134
Value Function Update Magnitude: 0.09769

Collected Steps per Second: 11,587.05472
Overall Steps per Second: 9,787.62582

Timestep Collection Time: 4.31706
Timestep Consumption Time: 0.79368
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.11074

Cumulative Model Updates: 45,688
Cumulative Timesteps: 762,093,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 762093080...
Checkpoint 762093080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631,180.84067
Policy Entropy: 1.10016
Value Function Loss: 4.34924

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.08331

Collected Steps per Second: 10,748.02678
Overall Steps per Second: 9,155.56362

Timestep Collection Time: 4.65388
Timestep Consumption Time: 0.80947
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.46334

Cumulative Model Updates: 45,691
Cumulative Timesteps: 762,143,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,950.47236
Policy Entropy: 1.10428
Value Function Loss: 4.45936

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 10,752.38100
Overall Steps per Second: 9,344.14688

Timestep Collection Time: 4.65218
Timestep Consumption Time: 0.70112
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.35330

Cumulative Model Updates: 45,694
Cumulative Timesteps: 762,193,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 762193122...
Checkpoint 762193122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,266.17741
Policy Entropy: 1.11274
Value Function Loss: 4.85912

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.07321

Collected Steps per Second: 10,680.65593
Overall Steps per Second: 9,162.98286

Timestep Collection Time: 4.68230
Timestep Consumption Time: 0.77553
PPO Batch Consumption Time: 0.03890
Total Iteration Time: 5.45783

Cumulative Model Updates: 45,697
Cumulative Timesteps: 762,243,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,478.12632
Policy Entropy: 1.12193
Value Function Loss: 4.59976

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.07604

Collected Steps per Second: 10,395.04605
Overall Steps per Second: 8,975.18799

Timestep Collection Time: 4.81075
Timestep Consumption Time: 0.76105
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.57181

Cumulative Model Updates: 45,700
Cumulative Timesteps: 762,293,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 762293140...
Checkpoint 762293140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413,705.71538
Policy Entropy: 1.12343
Value Function Loss: 4.40380

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.09525

Collected Steps per Second: 10,869.69636
Overall Steps per Second: 9,252.28133

Timestep Collection Time: 4.59994
Timestep Consumption Time: 0.80413
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.40407

Cumulative Model Updates: 45,703
Cumulative Timesteps: 762,343,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,070.02456
Policy Entropy: 1.11621
Value Function Loss: 4.49716

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.06959
Value Function Update Magnitude: 0.08596

Collected Steps per Second: 10,776.29757
Overall Steps per Second: 9,241.39904

Timestep Collection Time: 4.64185
Timestep Consumption Time: 0.77096
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.41282

Cumulative Model Updates: 45,706
Cumulative Timesteps: 762,393,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 762393162...
Checkpoint 762393162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,391.09682
Policy Entropy: 1.12514
Value Function Loss: 4.56633

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.11843
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.08321

Collected Steps per Second: 10,292.56018
Overall Steps per Second: 9,055.80699

Timestep Collection Time: 4.85866
Timestep Consumption Time: 0.66355
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.52220

Cumulative Model Updates: 45,709
Cumulative Timesteps: 762,443,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,899.31122
Policy Entropy: 1.12244
Value Function Loss: 4.53928

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.09720

Collected Steps per Second: 10,544.12939
Overall Steps per Second: 9,049.95695

Timestep Collection Time: 4.74463
Timestep Consumption Time: 0.78335
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 5.52798

Cumulative Model Updates: 45,712
Cumulative Timesteps: 762,493,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 762493198...
Checkpoint 762493198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,847.40325
Policy Entropy: 1.10575
Value Function Loss: 4.38265

Mean KL Divergence: 0.02604
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.08707

Collected Steps per Second: 10,221.72009
Overall Steps per Second: 8,833.53296

Timestep Collection Time: 4.89272
Timestep Consumption Time: 0.76889
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.66161

Cumulative Model Updates: 45,715
Cumulative Timesteps: 762,543,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,992.68957
Policy Entropy: 1.11240
Value Function Loss: 4.55840

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.08711

Collected Steps per Second: 10,899.98393
Overall Steps per Second: 9,361.39308

Timestep Collection Time: 4.58753
Timestep Consumption Time: 0.75398
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 5.34151

Cumulative Model Updates: 45,718
Cumulative Timesteps: 762,593,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 762593214...
Checkpoint 762593214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,459.39207
Policy Entropy: 1.11123
Value Function Loss: 4.56460

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.08100

Collected Steps per Second: 10,366.18541
Overall Steps per Second: 8,993.22738

Timestep Collection Time: 4.82588
Timestep Consumption Time: 0.73675
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.56263

Cumulative Model Updates: 45,721
Cumulative Timesteps: 762,643,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,710.73015
Policy Entropy: 1.11195
Value Function Loss: 4.49102

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.06365
Value Function Update Magnitude: 0.08118

Collected Steps per Second: 10,286.31618
Overall Steps per Second: 9,009.47180

Timestep Collection Time: 4.86277
Timestep Consumption Time: 0.68916
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 5.55193

Cumulative Model Updates: 45,724
Cumulative Timesteps: 762,693,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 762693260...
Checkpoint 762693260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,461.58466
Policy Entropy: 1.11104
Value Function Loss: 4.49855

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.07541

Collected Steps per Second: 10,457.59101
Overall Steps per Second: 8,974.30646

Timestep Collection Time: 4.78294
Timestep Consumption Time: 0.79053
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.57347

Cumulative Model Updates: 45,727
Cumulative Timesteps: 762,743,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,845.71899
Policy Entropy: 1.11662
Value Function Loss: 4.44135

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.07577
Value Function Update Magnitude: 0.08084

Collected Steps per Second: 10,547.37222
Overall Steps per Second: 8,981.47434

Timestep Collection Time: 4.74184
Timestep Consumption Time: 0.82673
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 5.56857

Cumulative Model Updates: 45,730
Cumulative Timesteps: 762,793,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 762793292...
Checkpoint 762793292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,917.24981
Policy Entropy: 1.10807
Value Function Loss: 4.51381

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.07912
Value Function Update Magnitude: 0.07866

Collected Steps per Second: 10,698.51940
Overall Steps per Second: 9,195.66454

Timestep Collection Time: 4.67448
Timestep Consumption Time: 0.76395
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.43843

Cumulative Model Updates: 45,733
Cumulative Timesteps: 762,843,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,039.47571
Policy Entropy: 1.10822
Value Function Loss: 4.55756

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.08528
Value Function Update Magnitude: 0.08147

Collected Steps per Second: 10,703.49416
Overall Steps per Second: 9,167.07374

Timestep Collection Time: 4.67231
Timestep Consumption Time: 0.78309
PPO Batch Consumption Time: 0.03761
Total Iteration Time: 5.45539

Cumulative Model Updates: 45,736
Cumulative Timesteps: 762,893,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 762893312...
Checkpoint 762893312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,252.65844
Policy Entropy: 1.09910
Value Function Loss: 4.73487

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.08372
Value Function Update Magnitude: 0.08276

Collected Steps per Second: 10,377.53266
Overall Steps per Second: 8,973.06288

Timestep Collection Time: 4.81849
Timestep Consumption Time: 0.75419
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 5.57268

Cumulative Model Updates: 45,739
Cumulative Timesteps: 762,943,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417,642.10668
Policy Entropy: 1.11212
Value Function Loss: 4.69019

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.06796
Value Function Update Magnitude: 0.08677

Collected Steps per Second: 10,356.45123
Overall Steps per Second: 8,900.07895

Timestep Collection Time: 4.83023
Timestep Consumption Time: 0.79040
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.62062

Cumulative Model Updates: 45,742
Cumulative Timesteps: 762,993,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 762993340...
Checkpoint 762993340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,409.02580
Policy Entropy: 1.11418
Value Function Loss: 4.59032

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12237
Policy Update Magnitude: 0.06834
Value Function Update Magnitude: 0.08452

Collected Steps per Second: 10,765.36465
Overall Steps per Second: 9,249.24165

Timestep Collection Time: 4.64564
Timestep Consumption Time: 0.76151
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.40715

Cumulative Model Updates: 45,745
Cumulative Timesteps: 763,043,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494,139.77843
Policy Entropy: 1.10851
Value Function Loss: 4.45556

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.06328
Value Function Update Magnitude: 0.07773

Collected Steps per Second: 11,108.37634
Overall Steps per Second: 9,497.31615

Timestep Collection Time: 4.50129
Timestep Consumption Time: 0.76357
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.26486

Cumulative Model Updates: 45,748
Cumulative Timesteps: 763,093,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 763093354...
Checkpoint 763093354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,226.88520
Policy Entropy: 1.09439
Value Function Loss: 4.52103

Mean KL Divergence: 0.03702
SB3 Clip Fraction: 0.17023
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.08071

Collected Steps per Second: 11,056.99611
Overall Steps per Second: 9,427.16938

Timestep Collection Time: 4.52239
Timestep Consumption Time: 0.78186
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.30424

Cumulative Model Updates: 45,751
Cumulative Timesteps: 763,143,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,945.73680
Policy Entropy: 1.10793
Value Function Loss: 4.47328

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.07307

Collected Steps per Second: 11,099.74619
Overall Steps per Second: 9,473.27863

Timestep Collection Time: 4.50695
Timestep Consumption Time: 0.77380
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 5.28075

Cumulative Model Updates: 45,754
Cumulative Timesteps: 763,193,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 763193384...
Checkpoint 763193384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,054.65017
Policy Entropy: 1.09948
Value Function Loss: 4.47344

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.06973

Collected Steps per Second: 10,022.30526
Overall Steps per Second: 8,696.06985

Timestep Collection Time: 4.98927
Timestep Consumption Time: 0.76091
PPO Batch Consumption Time: 0.03391
Total Iteration Time: 5.75018

Cumulative Model Updates: 45,757
Cumulative Timesteps: 763,243,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,025.09022
Policy Entropy: 1.09414
Value Function Loss: 4.26892

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.09201

Collected Steps per Second: 10,462.33759
Overall Steps per Second: 9,112.82721

Timestep Collection Time: 4.78058
Timestep Consumption Time: 0.70795
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 5.48853

Cumulative Model Updates: 45,760
Cumulative Timesteps: 763,293,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 763293404...
Checkpoint 763293404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,330.63099
Policy Entropy: 1.08461
Value Function Loss: 4.41495

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.06399
Value Function Update Magnitude: 0.08673

Collected Steps per Second: 10,694.12217
Overall Steps per Second: 9,058.89010

Timestep Collection Time: 4.67677
Timestep Consumption Time: 0.84421
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.52099

Cumulative Model Updates: 45,763
Cumulative Timesteps: 763,343,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,986.87694
Policy Entropy: 1.10158
Value Function Loss: 4.48003

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.09216

Collected Steps per Second: 10,589.82120
Overall Steps per Second: 9,278.07293

Timestep Collection Time: 4.72359
Timestep Consumption Time: 0.66783
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 5.39142

Cumulative Model Updates: 45,766
Cumulative Timesteps: 763,393,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 763393440...
Checkpoint 763393440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521,003.65379
Policy Entropy: 1.09920
Value Function Loss: 4.39230

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.10978

Collected Steps per Second: 10,747.42860
Overall Steps per Second: 9,199.97851

Timestep Collection Time: 4.65469
Timestep Consumption Time: 0.78293
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.43762

Cumulative Model Updates: 45,769
Cumulative Timesteps: 763,443,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,798.63832
Policy Entropy: 1.09120
Value Function Loss: 4.24384

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.11370

Collected Steps per Second: 10,619.89695
Overall Steps per Second: 9,080.61290

Timestep Collection Time: 4.71097
Timestep Consumption Time: 0.79857
PPO Batch Consumption Time: 0.03781
Total Iteration Time: 5.50954

Cumulative Model Updates: 45,772
Cumulative Timesteps: 763,493,496

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 763493496...
Checkpoint 763493496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,475.83162
Policy Entropy: 1.07897
Value Function Loss: 4.33150

Mean KL Divergence: 0.02684
SB3 Clip Fraction: 0.16306
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.10636

Collected Steps per Second: 10,676.15309
Overall Steps per Second: 9,138.26882

Timestep Collection Time: 4.68408
Timestep Consumption Time: 0.78829
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.47237

Cumulative Model Updates: 45,775
Cumulative Timesteps: 763,543,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,778.77983
Policy Entropy: 1.08623
Value Function Loss: 4.33918

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.09294

Collected Steps per Second: 9,844.17793
Overall Steps per Second: 8,506.02073

Timestep Collection Time: 5.08138
Timestep Consumption Time: 0.79940
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.88078

Cumulative Model Updates: 45,778
Cumulative Timesteps: 763,593,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 763593526...
Checkpoint 763593526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,904.46694
Policy Entropy: 1.09592
Value Function Loss: 4.59730

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.08552

Collected Steps per Second: 10,305.19713
Overall Steps per Second: 9,035.88747

Timestep Collection Time: 4.85250
Timestep Consumption Time: 0.68165
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.53415

Cumulative Model Updates: 45,781
Cumulative Timesteps: 763,643,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,389.68165
Policy Entropy: 1.08188
Value Function Loss: 4.42864

Mean KL Divergence: 0.02735
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.09174

Collected Steps per Second: 10,436.10489
Overall Steps per Second: 8,833.44323

Timestep Collection Time: 4.79355
Timestep Consumption Time: 0.86970
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 5.66325

Cumulative Model Updates: 45,784
Cumulative Timesteps: 763,693,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 763693558...
Checkpoint 763693558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,626.01482
Policy Entropy: 1.09279
Value Function Loss: 4.42757

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.10535

Collected Steps per Second: 10,365.98150
Overall Steps per Second: 8,958.18065

Timestep Collection Time: 4.82386
Timestep Consumption Time: 0.75808
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.58194

Cumulative Model Updates: 45,787
Cumulative Timesteps: 763,743,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,392.61254
Policy Entropy: 1.09823
Value Function Loss: 4.18358

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.10309

Collected Steps per Second: 10,171.14281
Overall Steps per Second: 8,764.75676

Timestep Collection Time: 4.91842
Timestep Consumption Time: 0.78921
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.70763

Cumulative Model Updates: 45,790
Cumulative Timesteps: 763,793,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 763793588...
Checkpoint 763793588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,096.70970
Policy Entropy: 1.08096
Value Function Loss: 4.26048

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 10,318.37713
Overall Steps per Second: 8,734.62786

Timestep Collection Time: 4.84669
Timestep Consumption Time: 0.87879
PPO Batch Consumption Time: 0.04686
Total Iteration Time: 5.72549

Cumulative Model Updates: 45,793
Cumulative Timesteps: 763,843,598

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,026.46341
Policy Entropy: 1.08058
Value Function Loss: 4.25409

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.10908

Collected Steps per Second: 10,406.79950
Overall Steps per Second: 9,098.29989

Timestep Collection Time: 4.80455
Timestep Consumption Time: 0.69098
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.49553

Cumulative Model Updates: 45,796
Cumulative Timesteps: 763,893,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 763893598...
Checkpoint 763893598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,609.58127
Policy Entropy: 1.08413
Value Function Loss: 3.98067

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.11452

Collected Steps per Second: 10,289.97659
Overall Steps per Second: 8,853.92502

Timestep Collection Time: 4.85987
Timestep Consumption Time: 0.78824
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.64812

Cumulative Model Updates: 45,799
Cumulative Timesteps: 763,943,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,710.74240
Policy Entropy: 1.08817
Value Function Loss: 3.93524

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.10045

Collected Steps per Second: 10,346.53570
Overall Steps per Second: 8,905.21155

Timestep Collection Time: 4.83331
Timestep Consumption Time: 0.78228
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.61559

Cumulative Model Updates: 45,802
Cumulative Timesteps: 763,993,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 763993614...
Checkpoint 763993614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,638.25187
Policy Entropy: 1.06852
Value Function Loss: 3.95391

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.10831

Collected Steps per Second: 10,119.41501
Overall Steps per Second: 8,725.90513

Timestep Collection Time: 4.94159
Timestep Consumption Time: 0.78916
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.73075

Cumulative Model Updates: 45,805
Cumulative Timesteps: 764,043,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,733.73708
Policy Entropy: 1.06584
Value Function Loss: 4.35094

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.13513

Collected Steps per Second: 11,366.73539
Overall Steps per Second: 9,673.07834

Timestep Collection Time: 4.40021
Timestep Consumption Time: 0.77043
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.17064

Cumulative Model Updates: 45,808
Cumulative Timesteps: 764,093,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 764093636...
Checkpoint 764093636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,864.54695
Policy Entropy: 1.08003
Value Function Loss: 4.38254

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.12263

Collected Steps per Second: 11,475.50784
Overall Steps per Second: 9,888.33924

Timestep Collection Time: 4.35763
Timestep Consumption Time: 0.69944
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 5.05707

Cumulative Model Updates: 45,811
Cumulative Timesteps: 764,143,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,272.13534
Policy Entropy: 1.08065
Value Function Loss: 4.61188

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 11,403.87179
Overall Steps per Second: 9,663.24611

Timestep Collection Time: 4.38623
Timestep Consumption Time: 0.79008
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.17631

Cumulative Model Updates: 45,814
Cumulative Timesteps: 764,193,662

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 764193662...
Checkpoint 764193662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,462.59605
Policy Entropy: 1.09083
Value Function Loss: 4.41726

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.06359
Value Function Update Magnitude: 0.13076

Collected Steps per Second: 11,144.43419
Overall Steps per Second: 9,604.66868

Timestep Collection Time: 4.48798
Timestep Consumption Time: 0.71949
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.20747

Cumulative Model Updates: 45,817
Cumulative Timesteps: 764,243,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,574.25546
Policy Entropy: 1.09106
Value Function Loss: 4.40346

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.06303
Value Function Update Magnitude: 0.12032

Collected Steps per Second: 11,462.86947
Overall Steps per Second: 9,769.91588

Timestep Collection Time: 4.36313
Timestep Consumption Time: 0.75605
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.11918

Cumulative Model Updates: 45,820
Cumulative Timesteps: 764,293,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 764293692...
Checkpoint 764293692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,752.00541
Policy Entropy: 1.08671
Value Function Loss: 4.37091

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.06811
Value Function Update Magnitude: 0.10752

Collected Steps per Second: 10,392.67799
Overall Steps per Second: 8,987.47267

Timestep Collection Time: 4.81377
Timestep Consumption Time: 0.75264
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.56641

Cumulative Model Updates: 45,823
Cumulative Timesteps: 764,343,720

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,217.54978
Policy Entropy: 1.07628
Value Function Loss: 4.67476

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.06365
Value Function Update Magnitude: 0.09504

Collected Steps per Second: 10,905.16511
Overall Steps per Second: 9,465.79951

Timestep Collection Time: 4.58773
Timestep Consumption Time: 0.69761
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.28534

Cumulative Model Updates: 45,826
Cumulative Timesteps: 764,393,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 764393750...
Checkpoint 764393750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,157.11412
Policy Entropy: 1.08142
Value Function Loss: 4.61380

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.09146

Collected Steps per Second: 10,533.46796
Overall Steps per Second: 8,990.66824

Timestep Collection Time: 4.74791
Timestep Consumption Time: 0.81474
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.56266

Cumulative Model Updates: 45,829
Cumulative Timesteps: 764,443,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,239.37966
Policy Entropy: 1.08750
Value Function Loss: 4.65099

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.06492
Value Function Update Magnitude: 0.08391

Collected Steps per Second: 10,569.86003
Overall Steps per Second: 9,106.97583

Timestep Collection Time: 4.73251
Timestep Consumption Time: 0.76020
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.49271

Cumulative Model Updates: 45,832
Cumulative Timesteps: 764,493,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 764493784...
Checkpoint 764493784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,441.11079
Policy Entropy: 1.09750
Value Function Loss: 4.61039

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.06023
Value Function Update Magnitude: 0.07622

Collected Steps per Second: 10,622.36121
Overall Steps per Second: 9,086.86441

Timestep Collection Time: 4.70893
Timestep Consumption Time: 0.79571
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.50465

Cumulative Model Updates: 45,835
Cumulative Timesteps: 764,543,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,919.00949
Policy Entropy: 1.08045
Value Function Loss: 4.63882

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.08123

Collected Steps per Second: 10,180.18214
Overall Steps per Second: 8,795.74959

Timestep Collection Time: 4.91190
Timestep Consumption Time: 0.77312
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.68502

Cumulative Model Updates: 45,838
Cumulative Timesteps: 764,593,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 764593808...
Checkpoint 764593808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,978.69665
Policy Entropy: 1.07115
Value Function Loss: 4.39265

Mean KL Divergence: 0.02338
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.08902

Collected Steps per Second: 10,257.61787
Overall Steps per Second: 8,928.91997

Timestep Collection Time: 4.87677
Timestep Consumption Time: 0.72570
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.60247

Cumulative Model Updates: 45,841
Cumulative Timesteps: 764,643,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,285.92321
Policy Entropy: 1.07927
Value Function Loss: 4.18915

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.08922

Collected Steps per Second: 10,534.48746
Overall Steps per Second: 8,986.65863

Timestep Collection Time: 4.74670
Timestep Consumption Time: 0.81755
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 5.56425

Cumulative Model Updates: 45,844
Cumulative Timesteps: 764,693,836

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 764693836...
Checkpoint 764693836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,819.89208
Policy Entropy: 1.08781
Value Function Loss: 4.16462

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.08333

Collected Steps per Second: 9,638.00148
Overall Steps per Second: 8,368.60099

Timestep Collection Time: 5.18780
Timestep Consumption Time: 0.78692
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 5.97471

Cumulative Model Updates: 45,847
Cumulative Timesteps: 764,743,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,732.36529
Policy Entropy: 1.07396
Value Function Loss: 4.21170

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.08311

Collected Steps per Second: 10,300.91990
Overall Steps per Second: 8,868.23078

Timestep Collection Time: 4.85588
Timestep Consumption Time: 0.78448
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 5.64036

Cumulative Model Updates: 45,850
Cumulative Timesteps: 764,793,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 764793856...
Checkpoint 764793856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,185.72316
Policy Entropy: 1.06887
Value Function Loss: 4.19620

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.07598

Collected Steps per Second: 10,030.07941
Overall Steps per Second: 8,607.66471

Timestep Collection Time: 4.98640
Timestep Consumption Time: 0.82400
PPO Batch Consumption Time: 0.03976
Total Iteration Time: 5.81040

Cumulative Model Updates: 45,853
Cumulative Timesteps: 764,843,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,583.75090
Policy Entropy: 1.07839
Value Function Loss: 4.27470

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.07673

Collected Steps per Second: 9,887.77709
Overall Steps per Second: 8,627.04480

Timestep Collection Time: 5.05877
Timestep Consumption Time: 0.73927
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 5.79805

Cumulative Model Updates: 45,856
Cumulative Timesteps: 764,893,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 764893890...
Checkpoint 764893890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,262.12889
Policy Entropy: 1.08020
Value Function Loss: 4.16963

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.08961

Collected Steps per Second: 10,019.42117
Overall Steps per Second: 8,654.58592

Timestep Collection Time: 4.99290
Timestep Consumption Time: 0.78738
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.78029

Cumulative Model Updates: 45,859
Cumulative Timesteps: 764,943,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,628.20089
Policy Entropy: 1.07128
Value Function Loss: 4.22731

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.09367

Collected Steps per Second: 9,366.74012
Overall Steps per Second: 8,185.51088

Timestep Collection Time: 5.33974
Timestep Consumption Time: 0.77056
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 6.11031

Cumulative Model Updates: 45,862
Cumulative Timesteps: 764,993,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 764993932...
Checkpoint 764993932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,616.60618
Policy Entropy: 1.05687
Value Function Loss: 4.09124

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.16825
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.08951

Collected Steps per Second: 9,482.63218
Overall Steps per Second: 7,963.04307

Timestep Collection Time: 5.27491
Timestep Consumption Time: 1.00661
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 6.28152

Cumulative Model Updates: 45,865
Cumulative Timesteps: 765,043,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,691.97968
Policy Entropy: 1.06461
Value Function Loss: 4.24290

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.08743

Collected Steps per Second: 9,678.89402
Overall Steps per Second: 8,375.24808

Timestep Collection Time: 5.16836
Timestep Consumption Time: 0.80448
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 5.97284

Cumulative Model Updates: 45,868
Cumulative Timesteps: 765,093,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 765093976...
Checkpoint 765093976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,880.95565
Policy Entropy: 1.07139
Value Function Loss: 4.29606

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.14594
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.09260

Collected Steps per Second: 9,983.67998
Overall Steps per Second: 8,782.57509

Timestep Collection Time: 5.01078
Timestep Consumption Time: 0.68527
PPO Batch Consumption Time: 0.03915
Total Iteration Time: 5.69605

Cumulative Model Updates: 45,871
Cumulative Timesteps: 765,144,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,264.05411
Policy Entropy: 1.05089
Value Function Loss: 4.20164

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.11058
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.09091

Collected Steps per Second: 9,992.07203
Overall Steps per Second: 8,508.63105

Timestep Collection Time: 5.00557
Timestep Consumption Time: 0.87270
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 5.87827

Cumulative Model Updates: 45,874
Cumulative Timesteps: 765,194,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 765194018...
Checkpoint 765194018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,727.55310
Policy Entropy: 1.05051
Value Function Loss: 4.13934

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.08399

Collected Steps per Second: 10,394.35650
Overall Steps per Second: 8,940.29704

Timestep Collection Time: 4.81203
Timestep Consumption Time: 0.78263
PPO Batch Consumption Time: 0.04311
Total Iteration Time: 5.59467

Cumulative Model Updates: 45,877
Cumulative Timesteps: 765,244,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,209.64347
Policy Entropy: 1.06597
Value Function Loss: 4.27628

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.05971
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 10,672.44490
Overall Steps per Second: 9,029.09941

Timestep Collection Time: 4.68665
Timestep Consumption Time: 0.85300
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 5.53964

Cumulative Model Updates: 45,880
Cumulative Timesteps: 765,294,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 765294054...
Checkpoint 765294054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,941.19278
Policy Entropy: 1.07249
Value Function Loss: 4.38390

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.06344
Value Function Update Magnitude: 0.07746

Collected Steps per Second: 9,922.66553
Overall Steps per Second: 8,564.20322

Timestep Collection Time: 5.04139
Timestep Consumption Time: 0.79967
PPO Batch Consumption Time: 0.04045
Total Iteration Time: 5.84106

Cumulative Model Updates: 45,883
Cumulative Timesteps: 765,344,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,870.31230
Policy Entropy: 1.05043
Value Function Loss: 4.39148

Mean KL Divergence: 0.02554
SB3 Clip Fraction: 0.16477
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.08226

Collected Steps per Second: 10,031.73909
Overall Steps per Second: 8,758.41254

Timestep Collection Time: 4.98578
Timestep Consumption Time: 0.72485
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 5.71062

Cumulative Model Updates: 45,886
Cumulative Timesteps: 765,394,094

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 765394094...
Checkpoint 765394094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,504.88046
Policy Entropy: 1.06345
Value Function Loss: 4.17451

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.08606

Collected Steps per Second: 10,213.95548
Overall Steps per Second: 8,763.22140

Timestep Collection Time: 4.89781
Timestep Consumption Time: 0.81082
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 5.70863

Cumulative Model Updates: 45,889
Cumulative Timesteps: 765,444,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,789.79083
Policy Entropy: 1.07633
Value Function Loss: 4.33175

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.08547

Collected Steps per Second: 10,624.06876
Overall Steps per Second: 9,144.23592

Timestep Collection Time: 4.70724
Timestep Consumption Time: 0.76178
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.46902

Cumulative Model Updates: 45,892
Cumulative Timesteps: 765,494,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 765494130...
Checkpoint 765494130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,105.57467
Policy Entropy: 1.05872
Value Function Loss: 4.23654

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.09695

Collected Steps per Second: 10,972.47053
Overall Steps per Second: 9,340.72153

Timestep Collection Time: 4.55759
Timestep Consumption Time: 0.79617
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.35376

Cumulative Model Updates: 45,895
Cumulative Timesteps: 765,544,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,709.75513
Policy Entropy: 1.05099
Value Function Loss: 4.33218

Mean KL Divergence: 0.02542
SB3 Clip Fraction: 0.15614
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.09127

Collected Steps per Second: 10,941.81031
Overall Steps per Second: 9,355.84800

Timestep Collection Time: 4.57146
Timestep Consumption Time: 0.77493
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.34639

Cumulative Model Updates: 45,898
Cumulative Timesteps: 765,594,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 765594158...
Checkpoint 765594158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,563.79317
Policy Entropy: 1.05754
Value Function Loss: 4.24998

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.08281

Collected Steps per Second: 10,275.87536
Overall Steps per Second: 9,045.49908

Timestep Collection Time: 4.86693
Timestep Consumption Time: 0.66200
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.52894

Cumulative Model Updates: 45,901
Cumulative Timesteps: 765,644,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,969.10324
Policy Entropy: 1.07310
Value Function Loss: 4.20795

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.08434

Collected Steps per Second: 10,627.88788
Overall Steps per Second: 9,063.18201

Timestep Collection Time: 4.70743
Timestep Consumption Time: 0.81271
PPO Batch Consumption Time: 0.03850
Total Iteration Time: 5.52014

Cumulative Model Updates: 45,904
Cumulative Timesteps: 765,694,200

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 765694200...
Checkpoint 765694200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,170.16073
Policy Entropy: 1.05417
Value Function Loss: 4.02907

Mean KL Divergence: 0.03375
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.07935

Collected Steps per Second: 10,340.68709
Overall Steps per Second: 8,924.55062

Timestep Collection Time: 4.83817
Timestep Consumption Time: 0.76771
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.60588

Cumulative Model Updates: 45,907
Cumulative Timesteps: 765,744,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,246.05028
Policy Entropy: 1.06475
Value Function Loss: 3.88463

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.08179

Collected Steps per Second: 10,860.61739
Overall Steps per Second: 9,339.13231

Timestep Collection Time: 4.60508
Timestep Consumption Time: 0.75024
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.35532

Cumulative Model Updates: 45,910
Cumulative Timesteps: 765,794,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 765794244...
Checkpoint 765794244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,615.52420
Policy Entropy: 1.06094
Value Function Loss: 3.74772

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.07184
Value Function Update Magnitude: 0.07818

Collected Steps per Second: 10,718.00064
Overall Steps per Second: 9,255.46082

Timestep Collection Time: 4.66766
Timestep Consumption Time: 0.73758
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.40524

Cumulative Model Updates: 45,913
Cumulative Timesteps: 765,844,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,007.91415
Policy Entropy: 1.07216
Value Function Loss: 4.07222

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.07009
Value Function Update Magnitude: 0.08269

Collected Steps per Second: 10,798.85025
Overall Steps per Second: 9,418.14550

Timestep Collection Time: 4.63216
Timestep Consumption Time: 0.67908
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.31124

Cumulative Model Updates: 45,916
Cumulative Timesteps: 765,894,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 765894294...
Checkpoint 765894294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,774.09076
Policy Entropy: 1.06766
Value Function Loss: 4.11116

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.07093
Value Function Update Magnitude: 0.07276

Collected Steps per Second: 10,401.60106
Overall Steps per Second: 8,958.16094

Timestep Collection Time: 4.80772
Timestep Consumption Time: 0.77467
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.58240

Cumulative Model Updates: 45,919
Cumulative Timesteps: 765,944,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,028.41990
Policy Entropy: 1.07370
Value Function Loss: 4.56681

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.06887
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 10,529.29811
Overall Steps per Second: 9,108.15325

Timestep Collection Time: 4.74903
Timestep Consumption Time: 0.74099
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.49003

Cumulative Model Updates: 45,922
Cumulative Timesteps: 765,994,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 765994306...
Checkpoint 765994306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,463.42100
Policy Entropy: 1.06953
Value Function Loss: 4.47530

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 10,846.92425
Overall Steps per Second: 9,303.86119

Timestep Collection Time: 4.61145
Timestep Consumption Time: 0.76482
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.37626

Cumulative Model Updates: 45,925
Cumulative Timesteps: 766,044,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,135.47048
Policy Entropy: 1.07991
Value Function Loss: 4.65006

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.06703

Collected Steps per Second: 10,758.72734
Overall Steps per Second: 9,243.84884

Timestep Collection Time: 4.64851
Timestep Consumption Time: 0.76180
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.41030

Cumulative Model Updates: 45,928
Cumulative Timesteps: 766,094,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 766094338...
Checkpoint 766094338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,611.67162
Policy Entropy: 1.07852
Value Function Loss: 4.46191

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.09187

Collected Steps per Second: 10,620.88677
Overall Steps per Second: 9,269.03496

Timestep Collection Time: 4.70921
Timestep Consumption Time: 0.68682
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.39603

Cumulative Model Updates: 45,931
Cumulative Timesteps: 766,144,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,827.82871
Policy Entropy: 1.09156
Value Function Loss: 4.50183

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.06799
Value Function Update Magnitude: 0.10441

Collected Steps per Second: 10,328.21642
Overall Steps per Second: 8,937.89296

Timestep Collection Time: 4.84188
Timestep Consumption Time: 0.75317
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.59505

Cumulative Model Updates: 45,934
Cumulative Timesteps: 766,194,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 766194362...
Checkpoint 766194362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,179.13967
Policy Entropy: 1.08914
Value Function Loss: 4.49912

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.07002
Value Function Update Magnitude: 0.09944

Collected Steps per Second: 11,690.89287
Overall Steps per Second: 9,900.56454

Timestep Collection Time: 4.27752
Timestep Consumption Time: 0.77351
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.05103

Cumulative Model Updates: 45,937
Cumulative Timesteps: 766,244,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,824.47448
Policy Entropy: 1.08924
Value Function Loss: 4.53284

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.07158
Value Function Update Magnitude: 0.10558

Collected Steps per Second: 11,983.09802
Overall Steps per Second: 10,056.91526

Timestep Collection Time: 4.17371
Timestep Consumption Time: 0.79938
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.97310

Cumulative Model Updates: 45,940
Cumulative Timesteps: 766,294,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 766294384...
Checkpoint 766294384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,995.97421
Policy Entropy: 1.08954
Value Function Loss: 4.35510

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.06642
Value Function Update Magnitude: 0.10363

Collected Steps per Second: 11,588.45314
Overall Steps per Second: 9,906.29556

Timestep Collection Time: 4.31464
Timestep Consumption Time: 0.73266
PPO Batch Consumption Time: 0.03343
Total Iteration Time: 5.04730

Cumulative Model Updates: 45,943
Cumulative Timesteps: 766,344,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,364.09271
Policy Entropy: 1.10115
Value Function Loss: 4.32896

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.06456
Value Function Update Magnitude: 0.09465

Collected Steps per Second: 11,810.67815
Overall Steps per Second: 10,136.93786

Timestep Collection Time: 4.23363
Timestep Consumption Time: 0.69903
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.93265

Cumulative Model Updates: 45,946
Cumulative Timesteps: 766,394,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 766394386...
Checkpoint 766394386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,704.65206
Policy Entropy: 1.09790
Value Function Loss: 4.39144

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.10863
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.09788

Collected Steps per Second: 11,779.72651
Overall Steps per Second: 9,951.36683

Timestep Collection Time: 4.24475
Timestep Consumption Time: 0.77989
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.02464

Cumulative Model Updates: 45,949
Cumulative Timesteps: 766,444,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487,496.08965
Policy Entropy: 1.09380
Value Function Loss: 4.38845

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.08057
Value Function Update Magnitude: 0.10521

Collected Steps per Second: 10,514.04759
Overall Steps per Second: 9,178.63915

Timestep Collection Time: 4.75744
Timestep Consumption Time: 0.69216
PPO Batch Consumption Time: 0.03852
Total Iteration Time: 5.44961

Cumulative Model Updates: 45,952
Cumulative Timesteps: 766,494,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 766494408...
Checkpoint 766494408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,657.30767
Policy Entropy: 1.09311
Value Function Loss: 4.46821

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.07811
Value Function Update Magnitude: 0.10225

Collected Steps per Second: 10,599.30349
Overall Steps per Second: 9,042.09404

Timestep Collection Time: 4.71956
Timestep Consumption Time: 0.81279
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.53235

Cumulative Model Updates: 45,955
Cumulative Timesteps: 766,544,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,149.29594
Policy Entropy: 1.08954
Value Function Loss: 4.48316

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.07278
Value Function Update Magnitude: 0.11213

Collected Steps per Second: 10,923.52371
Overall Steps per Second: 9,377.70963

Timestep Collection Time: 4.57856
Timestep Consumption Time: 0.75473
PPO Batch Consumption Time: 0.04034
Total Iteration Time: 5.33329

Cumulative Model Updates: 45,958
Cumulative Timesteps: 766,594,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 766594446...
Checkpoint 766594446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,163.02469
Policy Entropy: 1.10256
Value Function Loss: 4.48928

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.10490

Collected Steps per Second: 10,683.22364
Overall Steps per Second: 9,333.65996

Timestep Collection Time: 4.68098
Timestep Consumption Time: 0.67683
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 5.35781

Cumulative Model Updates: 45,961
Cumulative Timesteps: 766,644,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,915.70278
Policy Entropy: 1.10198
Value Function Loss: 4.50613

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.06770
Value Function Update Magnitude: 0.09409

Collected Steps per Second: 11,044.29598
Overall Steps per Second: 9,441.58801

Timestep Collection Time: 4.52777
Timestep Consumption Time: 0.76859
PPO Batch Consumption Time: 0.03874
Total Iteration Time: 5.29635

Cumulative Model Updates: 45,964
Cumulative Timesteps: 766,694,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 766694460...
Checkpoint 766694460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,205.17113
Policy Entropy: 1.10844
Value Function Loss: 4.41281

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.08062

Collected Steps per Second: 10,949.63453
Overall Steps per Second: 9,326.25125

Timestep Collection Time: 4.56819
Timestep Consumption Time: 0.79517
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.36336

Cumulative Model Updates: 45,967
Cumulative Timesteps: 766,744,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,106.88542
Policy Entropy: 1.09678
Value Function Loss: 4.46308

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.07209
Value Function Update Magnitude: 0.07570

Collected Steps per Second: 10,700.31554
Overall Steps per Second: 9,234.78626

Timestep Collection Time: 4.67463
Timestep Consumption Time: 0.74185
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 5.41648

Cumulative Model Updates: 45,970
Cumulative Timesteps: 766,794,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 766794500...
Checkpoint 766794500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,977.00592
Policy Entropy: 1.10315
Value Function Loss: 4.41984

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.06849

Collected Steps per Second: 10,557.34547
Overall Steps per Second: 9,085.59039

Timestep Collection Time: 4.73737
Timestep Consumption Time: 0.76740
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.50476

Cumulative Model Updates: 45,973
Cumulative Timesteps: 766,844,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,231.75483
Policy Entropy: 1.10554
Value Function Loss: 4.32884

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.07665

Collected Steps per Second: 10,687.97085
Overall Steps per Second: 9,289.96481

Timestep Collection Time: 4.67834
Timestep Consumption Time: 0.70402
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.38237

Cumulative Model Updates: 45,976
Cumulative Timesteps: 766,894,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 766894516...
Checkpoint 766894516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,129.28344
Policy Entropy: 1.11048
Value Function Loss: 4.38675

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.06675
Value Function Update Magnitude: 0.07861

Collected Steps per Second: 10,677.25173
Overall Steps per Second: 9,181.87372

Timestep Collection Time: 4.68454
Timestep Consumption Time: 0.76293
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.44747

Cumulative Model Updates: 45,979
Cumulative Timesteps: 766,944,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,340.71910
Policy Entropy: 1.11708
Value Function Loss: 4.44527

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.06912
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 10,733.50159
Overall Steps per Second: 9,212.58947

Timestep Collection Time: 4.65850
Timestep Consumption Time: 0.76907
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.42757

Cumulative Model Updates: 45,982
Cumulative Timesteps: 766,994,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 766994536...
Checkpoint 766994536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,683.31893
Policy Entropy: 1.12523
Value Function Loss: 4.61262

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.10342
Policy Update Magnitude: 0.07040
Value Function Update Magnitude: 0.07832

Collected Steps per Second: 10,442.76549
Overall Steps per Second: 9,014.41739

Timestep Collection Time: 4.79068
Timestep Consumption Time: 0.75909
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 5.54978

Cumulative Model Updates: 45,985
Cumulative Timesteps: 767,044,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481,953.82728
Policy Entropy: 1.12521
Value Function Loss: 4.45966

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.07058
Value Function Update Magnitude: 0.07592

Collected Steps per Second: 10,388.74586
Overall Steps per Second: 8,972.22533

Timestep Collection Time: 4.81309
Timestep Consumption Time: 0.75988
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 5.57298

Cumulative Model Updates: 45,988
Cumulative Timesteps: 767,094,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 767094566...
Checkpoint 767094566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,550.65890
Policy Entropy: 1.12217
Value Function Loss: 4.32704

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.07093
Value Function Update Magnitude: 0.07388

Collected Steps per Second: 10,781.44146
Overall Steps per Second: 9,295.33324

Timestep Collection Time: 4.63760
Timestep Consumption Time: 0.74144
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.37904

Cumulative Model Updates: 45,991
Cumulative Timesteps: 767,144,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,533.57324
Policy Entropy: 1.12306
Value Function Loss: 4.29462

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.06404
Value Function Update Magnitude: 0.07263

Collected Steps per Second: 10,363.47849
Overall Steps per Second: 8,951.73981

Timestep Collection Time: 4.82463
Timestep Consumption Time: 0.76087
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.58551

Cumulative Model Updates: 45,994
Cumulative Timesteps: 767,194,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 767194566...
Checkpoint 767194566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,607.45557
Policy Entropy: 1.12250
Value Function Loss: 4.36090

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.06222
Value Function Update Magnitude: 0.07982

Collected Steps per Second: 10,856.80641
Overall Steps per Second: 9,480.21807

Timestep Collection Time: 4.60798
Timestep Consumption Time: 0.66911
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.27709

Cumulative Model Updates: 45,997
Cumulative Timesteps: 767,244,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,591.58550
Policy Entropy: 1.12439
Value Function Loss: 4.45033

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.06788
Value Function Update Magnitude: 0.07612

Collected Steps per Second: 10,769.97272
Overall Steps per Second: 9,204.08075

Timestep Collection Time: 4.64347
Timestep Consumption Time: 0.78999
PPO Batch Consumption Time: 0.03965
Total Iteration Time: 5.43346

Cumulative Model Updates: 46,000
Cumulative Timesteps: 767,294,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 767294604...
Checkpoint 767294604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,572.47249
Policy Entropy: 1.12244
Value Function Loss: 4.48160

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.11313
Policy Update Magnitude: 0.07653
Value Function Update Magnitude: 0.07352

Collected Steps per Second: 10,634.19322
Overall Steps per Second: 9,321.51974

Timestep Collection Time: 4.70275
Timestep Consumption Time: 0.66225
PPO Batch Consumption Time: 0.03802
Total Iteration Time: 5.36500

Cumulative Model Updates: 46,003
Cumulative Timesteps: 767,344,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,886.83130
Policy Entropy: 1.11807
Value Function Loss: 4.35237

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.15025
Policy Update Magnitude: 0.06925
Value Function Update Magnitude: 0.08077

Collected Steps per Second: 11,094.09924
Overall Steps per Second: 9,533.70559

Timestep Collection Time: 4.50744
Timestep Consumption Time: 0.73774
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.24518

Cumulative Model Updates: 46,006
Cumulative Timesteps: 767,394,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 767394620...
Checkpoint 767394620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,097.15764
Policy Entropy: 1.13228
Value Function Loss: 4.41009

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.06295
Value Function Update Magnitude: 0.07299

Collected Steps per Second: 10,505.19562
Overall Steps per Second: 9,088.01619

Timestep Collection Time: 4.75993
Timestep Consumption Time: 0.74226
PPO Batch Consumption Time: 0.04024
Total Iteration Time: 5.50219

Cumulative Model Updates: 46,009
Cumulative Timesteps: 767,444,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,645.77034
Policy Entropy: 1.13099
Value Function Loss: 4.33456

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.06193

Collected Steps per Second: 11,207.29267
Overall Steps per Second: 9,574.03141

Timestep Collection Time: 4.46245
Timestep Consumption Time: 0.76126
PPO Batch Consumption Time: 0.04016
Total Iteration Time: 5.22371

Cumulative Model Updates: 46,012
Cumulative Timesteps: 767,494,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 767494636...
Checkpoint 767494636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,802.60335
Policy Entropy: 1.12716
Value Function Loss: 4.53292

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.06735
Value Function Update Magnitude: 0.06636

Collected Steps per Second: 10,990.45902
Overall Steps per Second: 9,489.00053

Timestep Collection Time: 4.55031
Timestep Consumption Time: 0.72000
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.27031

Cumulative Model Updates: 46,015
Cumulative Timesteps: 767,544,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,924.56004
Policy Entropy: 1.12302
Value Function Loss: 4.42203

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.09926

Collected Steps per Second: 10,392.79107
Overall Steps per Second: 9,059.71014

Timestep Collection Time: 4.81314
Timestep Consumption Time: 0.70822
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.52137

Cumulative Model Updates: 46,018
Cumulative Timesteps: 767,594,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 767594668...
Checkpoint 767594668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,565.33299
Policy Entropy: 1.12908
Value Function Loss: 4.50424

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.06030
Value Function Update Magnitude: 0.10109

Collected Steps per Second: 10,710.51821
Overall Steps per Second: 9,231.35544

Timestep Collection Time: 4.66831
Timestep Consumption Time: 0.74801
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 5.41632

Cumulative Model Updates: 46,021
Cumulative Timesteps: 767,644,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,416.57805
Policy Entropy: 1.12356
Value Function Loss: 4.36095

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.11044

Collected Steps per Second: 10,933.24672
Overall Steps per Second: 9,378.51888

Timestep Collection Time: 4.57412
Timestep Consumption Time: 0.75828
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.33240

Cumulative Model Updates: 46,024
Cumulative Timesteps: 767,694,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 767694678...
Checkpoint 767694678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,330.16841
Policy Entropy: 1.12099
Value Function Loss: 4.34635

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.06881
Value Function Update Magnitude: 0.11333

Collected Steps per Second: 11,105.24942
Overall Steps per Second: 9,488.80739

Timestep Collection Time: 4.50382
Timestep Consumption Time: 0.76724
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.27105

Cumulative Model Updates: 46,027
Cumulative Timesteps: 767,744,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,836.43960
Policy Entropy: 1.11168
Value Function Loss: 4.31325

Mean KL Divergence: 0.03049
SB3 Clip Fraction: 0.17100
Policy Update Magnitude: 0.06655
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 10,987.76206
Overall Steps per Second: 9,478.93479

Timestep Collection Time: 4.55070
Timestep Consumption Time: 0.72437
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.27507

Cumulative Model Updates: 46,030
Cumulative Timesteps: 767,794,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 767794696...
Checkpoint 767794696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,503.93663
Policy Entropy: 1.12685
Value Function Loss: 4.17453

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.09501

Collected Steps per Second: 10,583.80456
Overall Steps per Second: 9,061.42108

Timestep Collection Time: 4.72420
Timestep Consumption Time: 0.79370
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 5.51790

Cumulative Model Updates: 46,033
Cumulative Timesteps: 767,844,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,864.46266
Policy Entropy: 1.12295
Value Function Loss: 4.06961

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.08360

Collected Steps per Second: 10,473.76312
Overall Steps per Second: 9,042.18783

Timestep Collection Time: 4.77498
Timestep Consumption Time: 0.75598
PPO Batch Consumption Time: 0.03917
Total Iteration Time: 5.53096

Cumulative Model Updates: 46,036
Cumulative Timesteps: 767,894,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 767894708...
Checkpoint 767894708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512,226.56512
Policy Entropy: 1.11248
Value Function Loss: 4.12140

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.06698
Value Function Update Magnitude: 0.07589

Collected Steps per Second: 10,529.80625
Overall Steps per Second: 9,147.96413

Timestep Collection Time: 4.74919
Timestep Consumption Time: 0.71739
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.46657

Cumulative Model Updates: 46,039
Cumulative Timesteps: 767,944,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,765.12568
Policy Entropy: 1.11710
Value Function Loss: 4.26188

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.06948

Collected Steps per Second: 10,947.81884
Overall Steps per Second: 9,413.24230

Timestep Collection Time: 4.56931
Timestep Consumption Time: 0.74490
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 5.31422

Cumulative Model Updates: 46,042
Cumulative Timesteps: 767,994,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 767994740...
Checkpoint 767994740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,571.52467
Policy Entropy: 1.12778
Value Function Loss: 4.46593

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.06756

Collected Steps per Second: 10,705.85173
Overall Steps per Second: 9,212.69278

Timestep Collection Time: 4.67128
Timestep Consumption Time: 0.75710
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.42838

Cumulative Model Updates: 46,045
Cumulative Timesteps: 768,044,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,134.82020
Policy Entropy: 1.12747
Value Function Loss: 4.34048

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.08723

Collected Steps per Second: 10,795.37063
Overall Steps per Second: 9,382.14115

Timestep Collection Time: 4.63291
Timestep Consumption Time: 0.69785
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 5.33077

Cumulative Model Updates: 46,048
Cumulative Timesteps: 768,094,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 768094764...
Checkpoint 768094764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,241.67925
Policy Entropy: 1.12103
Value Function Loss: 4.45666

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.09644

Collected Steps per Second: 10,596.50132
Overall Steps per Second: 9,028.26534

Timestep Collection Time: 4.71967
Timestep Consumption Time: 0.81982
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.53949

Cumulative Model Updates: 46,051
Cumulative Timesteps: 768,144,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,175.19137
Policy Entropy: 1.11952
Value Function Loss: 4.28216

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.10225

Collected Steps per Second: 10,495.60744
Overall Steps per Second: 9,172.60343

Timestep Collection Time: 4.76428
Timestep Consumption Time: 0.68717
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 5.45145

Cumulative Model Updates: 46,054
Cumulative Timesteps: 768,194,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 768194780...
Checkpoint 768194780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,141.08641
Policy Entropy: 1.12410
Value Function Loss: 4.28211

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.09403

Collected Steps per Second: 10,672.48456
Overall Steps per Second: 9,172.01716

Timestep Collection Time: 4.68513
Timestep Consumption Time: 0.76645
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.45158

Cumulative Model Updates: 46,057
Cumulative Timesteps: 768,244,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,346.88289
Policy Entropy: 1.13257
Value Function Loss: 4.27031

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.11759
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.09095

Collected Steps per Second: 10,640.53117
Overall Steps per Second: 9,280.10648

Timestep Collection Time: 4.70014
Timestep Consumption Time: 0.68902
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.38916

Cumulative Model Updates: 46,060
Cumulative Timesteps: 768,294,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 768294794...
Checkpoint 768294794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,693.24831
Policy Entropy: 1.13288
Value Function Loss: 4.34178

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.11933
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.09187

Collected Steps per Second: 10,869.88742
Overall Steps per Second: 9,323.64451

Timestep Collection Time: 4.60152
Timestep Consumption Time: 0.76312
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.36464

Cumulative Model Updates: 46,063
Cumulative Timesteps: 768,344,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,152.59004
Policy Entropy: 1.13413
Value Function Loss: 4.38259

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.06827
Value Function Update Magnitude: 0.09809

Collected Steps per Second: 10,700.05070
Overall Steps per Second: 9,217.33497

Timestep Collection Time: 4.67344
Timestep Consumption Time: 0.75178
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.42521

Cumulative Model Updates: 46,066
Cumulative Timesteps: 768,394,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 768394818...
Checkpoint 768394818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,667.95456
Policy Entropy: 1.12762
Value Function Loss: 4.26688

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.06508
Value Function Update Magnitude: 0.09256

Collected Steps per Second: 10,754.85770
Overall Steps per Second: 9,369.37233

Timestep Collection Time: 4.64943
Timestep Consumption Time: 0.68753
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.33696

Cumulative Model Updates: 46,069
Cumulative Timesteps: 768,444,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,128.46303
Policy Entropy: 1.13540
Value Function Loss: 4.33636

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.08430

Collected Steps per Second: 11,918.07020
Overall Steps per Second: 10,030.73311

Timestep Collection Time: 4.19699
Timestep Consumption Time: 0.78969
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.98667

Cumulative Model Updates: 46,072
Cumulative Timesteps: 768,494,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 768494842...
Checkpoint 768494842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,789.46110
Policy Entropy: 1.14192
Value Function Loss: 4.23197

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.08072

Collected Steps per Second: 11,446.62544
Overall Steps per Second: 9,886.21989

Timestep Collection Time: 4.36810
Timestep Consumption Time: 0.68945
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 5.05754

Cumulative Model Updates: 46,075
Cumulative Timesteps: 768,544,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497,621.34500
Policy Entropy: 1.15055
Value Function Loss: 4.28831

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.08218

Collected Steps per Second: 11,390.53134
Overall Steps per Second: 9,685.04756

Timestep Collection Time: 4.39137
Timestep Consumption Time: 0.77330
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.16466

Cumulative Model Updates: 46,078
Cumulative Timesteps: 768,594,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 768594862...
Checkpoint 768594862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,999.92673
Policy Entropy: 1.14659
Value Function Loss: 4.10876

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.06530
Value Function Update Magnitude: 0.08439

Collected Steps per Second: 11,378.37085
Overall Steps per Second: 9,738.32520

Timestep Collection Time: 4.39553
Timestep Consumption Time: 0.74026
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.13579

Cumulative Model Updates: 46,081
Cumulative Timesteps: 768,644,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,857.81286
Policy Entropy: 1.12876
Value Function Loss: 4.19101

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.06762
Value Function Update Magnitude: 0.07964

Collected Steps per Second: 11,347.27148
Overall Steps per Second: 9,663.47892

Timestep Collection Time: 4.40758
Timestep Consumption Time: 0.76799
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.17557

Cumulative Model Updates: 46,084
Cumulative Timesteps: 768,694,890

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 768694890...
Checkpoint 768694890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,786.34458
Policy Entropy: 1.14165
Value Function Loss: 4.06286

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.08129

Collected Steps per Second: 10,254.38973
Overall Steps per Second: 8,894.03718

Timestep Collection Time: 4.87713
Timestep Consumption Time: 0.74596
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.62309

Cumulative Model Updates: 46,087
Cumulative Timesteps: 768,744,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,764.38612
Policy Entropy: 1.13615
Value Function Loss: 4.19458

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.07402

Collected Steps per Second: 10,886.52398
Overall Steps per Second: 9,485.19642

Timestep Collection Time: 4.59375
Timestep Consumption Time: 0.67867
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.27243

Cumulative Model Updates: 46,090
Cumulative Timesteps: 768,794,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 768794912...
Checkpoint 768794912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,494.87691
Policy Entropy: 1.12915
Value Function Loss: 4.20354

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.07785

Collected Steps per Second: 10,827.86969
Overall Steps per Second: 9,264.90317

Timestep Collection Time: 4.61993
Timestep Consumption Time: 0.77937
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.39930

Cumulative Model Updates: 46,093
Cumulative Timesteps: 768,844,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,810.13666
Policy Entropy: 1.13485
Value Function Loss: 4.32515

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.06298
Value Function Update Magnitude: 0.06789

Collected Steps per Second: 10,956.07107
Overall Steps per Second: 9,394.73082

Timestep Collection Time: 4.56569
Timestep Consumption Time: 0.75879
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.32447

Cumulative Model Updates: 46,096
Cumulative Timesteps: 768,894,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 768894958...
Checkpoint 768894958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,396.91202
Policy Entropy: 1.13088
Value Function Loss: 4.25134

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.06038
Value Function Update Magnitude: 0.05698

Collected Steps per Second: 11,068.22655
Overall Steps per Second: 9,363.53981

Timestep Collection Time: 4.52033
Timestep Consumption Time: 0.82295
PPO Batch Consumption Time: 0.05164
Total Iteration Time: 5.34328

Cumulative Model Updates: 46,099
Cumulative Timesteps: 768,944,990

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,195.47232
Policy Entropy: 1.13524
Value Function Loss: 4.29966

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.05841

Collected Steps per Second: 10,488.67426
Overall Steps per Second: 8,993.77103

Timestep Collection Time: 4.76914
Timestep Consumption Time: 0.79271
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.56185

Cumulative Model Updates: 46,102
Cumulative Timesteps: 768,995,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 768995012...
Checkpoint 768995012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,793.59780
Policy Entropy: 1.13375
Value Function Loss: 4.07202

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.06472

Collected Steps per Second: 10,693.48062
Overall Steps per Second: 9,334.05679

Timestep Collection Time: 4.67780
Timestep Consumption Time: 0.68128
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.35908

Cumulative Model Updates: 46,105
Cumulative Timesteps: 769,045,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,162.96916
Policy Entropy: 1.13774
Value Function Loss: 4.16189

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.06906

Collected Steps per Second: 10,744.39631
Overall Steps per Second: 9,186.81276

Timestep Collection Time: 4.65452
Timestep Consumption Time: 0.78915
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.44367

Cumulative Model Updates: 46,108
Cumulative Timesteps: 769,095,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 769095044...
Checkpoint 769095044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,695.70018
Policy Entropy: 1.13667
Value Function Loss: 4.24670

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.07107
Value Function Update Magnitude: 0.06679

Collected Steps per Second: 10,649.32300
Overall Steps per Second: 9,172.69437

Timestep Collection Time: 4.69720
Timestep Consumption Time: 0.75616
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.45336

Cumulative Model Updates: 46,111
Cumulative Timesteps: 769,145,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,605.10316
Policy Entropy: 1.14040
Value Function Loss: 4.52973

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.06626
Value Function Update Magnitude: 0.06994

Collected Steps per Second: 10,984.92102
Overall Steps per Second: 9,415.54053

Timestep Collection Time: 4.55443
Timestep Consumption Time: 0.75913
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.31356

Cumulative Model Updates: 46,114
Cumulative Timesteps: 769,195,096

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 769195096...
Checkpoint 769195096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,241.25505
Policy Entropy: 1.14349
Value Function Loss: 4.57266

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.06425
Value Function Update Magnitude: 0.06737

Collected Steps per Second: 10,898.80837
Overall Steps per Second: 9,399.58343

Timestep Collection Time: 4.59041
Timestep Consumption Time: 0.73217
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.32258

Cumulative Model Updates: 46,117
Cumulative Timesteps: 769,245,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,215.74987
Policy Entropy: 1.14971
Value Function Loss: 4.36374

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.08151

Collected Steps per Second: 10,072.10691
Overall Steps per Second: 8,812.96905

Timestep Collection Time: 4.96579
Timestep Consumption Time: 0.70948
PPO Batch Consumption Time: 0.03860
Total Iteration Time: 5.67527

Cumulative Model Updates: 46,120
Cumulative Timesteps: 769,295,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 769295142...
Checkpoint 769295142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,680.58717
Policy Entropy: 1.14968
Value Function Loss: 4.28577

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.07338
Value Function Update Magnitude: 0.07789

Collected Steps per Second: 10,769.70862
Overall Steps per Second: 9,253.23524

Timestep Collection Time: 4.64451
Timestep Consumption Time: 0.76117
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.40568

Cumulative Model Updates: 46,123
Cumulative Timesteps: 769,345,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,691.92526
Policy Entropy: 1.13867
Value Function Loss: 4.18878

Mean KL Divergence: 0.02618
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.07252
Value Function Update Magnitude: 0.08789

Collected Steps per Second: 10,876.20993
Overall Steps per Second: 9,459.32430

Timestep Collection Time: 4.59829
Timestep Consumption Time: 0.68877
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.28706

Cumulative Model Updates: 46,126
Cumulative Timesteps: 769,395,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 769395174...
Checkpoint 769395174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,394.30092
Policy Entropy: 1.14872
Value Function Loss: 4.21041

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.06234
Value Function Update Magnitude: 0.08926

Collected Steps per Second: 10,914.90395
Overall Steps per Second: 9,301.63685

Timestep Collection Time: 4.58217
Timestep Consumption Time: 0.79473
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.37690

Cumulative Model Updates: 46,129
Cumulative Timesteps: 769,445,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,655.65327
Policy Entropy: 1.14740
Value Function Loss: 4.31167

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.10737
Policy Update Magnitude: 0.06871
Value Function Update Magnitude: 0.07516

Collected Steps per Second: 10,762.80191
Overall Steps per Second: 9,259.97991

Timestep Collection Time: 4.64619
Timestep Consumption Time: 0.75404
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.40023

Cumulative Model Updates: 46,132
Cumulative Timesteps: 769,495,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 769495194...
Checkpoint 769495194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,075.80930
Policy Entropy: 1.14085
Value Function Loss: 4.08341

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.06716
Value Function Update Magnitude: 0.07687

Collected Steps per Second: 10,271.10077
Overall Steps per Second: 8,877.27902

Timestep Collection Time: 4.87075
Timestep Consumption Time: 0.76476
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.63551

Cumulative Model Updates: 46,135
Cumulative Timesteps: 769,545,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,152.22552
Policy Entropy: 1.14579
Value Function Loss: 4.32322

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.08617

Collected Steps per Second: 10,527.70029
Overall Steps per Second: 9,040.19204

Timestep Collection Time: 4.75185
Timestep Consumption Time: 0.78189
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.53373

Cumulative Model Updates: 46,138
Cumulative Timesteps: 769,595,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 769595248...
Checkpoint 769595248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,032.65757
Policy Entropy: 1.15545
Value Function Loss: 4.35531

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.08142

Collected Steps per Second: 11,035.66004
Overall Steps per Second: 9,569.30346

Timestep Collection Time: 4.53131
Timestep Consumption Time: 0.69436
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.22567

Cumulative Model Updates: 46,141
Cumulative Timesteps: 769,645,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,488.58182
Policy Entropy: 1.16099
Value Function Loss: 4.70501

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.07410

Collected Steps per Second: 10,990.98165
Overall Steps per Second: 9,259.08117

Timestep Collection Time: 4.55082
Timestep Consumption Time: 0.85123
PPO Batch Consumption Time: 0.04469
Total Iteration Time: 5.40205

Cumulative Model Updates: 46,144
Cumulative Timesteps: 769,695,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 769695272...
Checkpoint 769695272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,222.81216
Policy Entropy: 1.15636
Value Function Loss: 4.58272

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.06231
Value Function Update Magnitude: 0.07144

Collected Steps per Second: 10,971.99389
Overall Steps per Second: 9,420.23872

Timestep Collection Time: 4.55870
Timestep Consumption Time: 0.75093
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.30963

Cumulative Model Updates: 46,147
Cumulative Timesteps: 769,745,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481,407.85759
Policy Entropy: 1.16604
Value Function Loss: 4.69781

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.09295

Collected Steps per Second: 11,178.92501
Overall Steps per Second: 9,540.25914

Timestep Collection Time: 4.47324
Timestep Consumption Time: 0.76834
PPO Batch Consumption Time: 0.03373
Total Iteration Time: 5.24158

Cumulative Model Updates: 46,150
Cumulative Timesteps: 769,795,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 769795296...
Checkpoint 769795296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,109.77306
Policy Entropy: 1.16227
Value Function Loss: 4.59265

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.10161

Collected Steps per Second: 10,283.03076
Overall Steps per Second: 8,886.04914

Timestep Collection Time: 4.86238
Timestep Consumption Time: 0.76442
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.62680

Cumulative Model Updates: 46,153
Cumulative Timesteps: 769,845,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,902.05297
Policy Entropy: 1.16349
Value Function Loss: 4.53881

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.07162
Value Function Update Magnitude: 0.08827

Collected Steps per Second: 10,490.00319
Overall Steps per Second: 9,209.10299

Timestep Collection Time: 4.76682
Timestep Consumption Time: 0.66302
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.42984

Cumulative Model Updates: 46,156
Cumulative Timesteps: 769,895,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 769895300...
Checkpoint 769895300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,713.22399
Policy Entropy: 1.15673
Value Function Loss: 4.28404

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.08369

Collected Steps per Second: 10,594.69476
Overall Steps per Second: 9,121.55760

Timestep Collection Time: 4.72104
Timestep Consumption Time: 0.76245
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.48349

Cumulative Model Updates: 46,159
Cumulative Timesteps: 769,945,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,954.29543
Policy Entropy: 1.16403
Value Function Loss: 4.15962

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.07568

Collected Steps per Second: 10,868.03643
Overall Steps per Second: 9,481.79278

Timestep Collection Time: 4.60083
Timestep Consumption Time: 0.67264
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 5.27348

Cumulative Model Updates: 46,162
Cumulative Timesteps: 769,995,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 769995320...
Checkpoint 769995320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427,043.91196
Policy Entropy: 1.16145
Value Function Loss: 4.17073

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.07016
Value Function Update Magnitude: 0.07464

Collected Steps per Second: 10,773.49994
Overall Steps per Second: 9,165.26684

Timestep Collection Time: 4.64176
Timestep Consumption Time: 0.81449
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.45625

Cumulative Model Updates: 46,165
Cumulative Timesteps: 770,045,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566,782.06957
Policy Entropy: 1.15732
Value Function Loss: 4.02902

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.08221
Value Function Update Magnitude: 0.07938

Collected Steps per Second: 10,301.08583
Overall Steps per Second: 8,777.87327

Timestep Collection Time: 4.85444
Timestep Consumption Time: 0.84238
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.69682

Cumulative Model Updates: 46,168
Cumulative Timesteps: 770,095,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 770095334...
Checkpoint 770095334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,921.63656
Policy Entropy: 1.14425
Value Function Loss: 4.07393

Mean KL Divergence: 0.02897
SB3 Clip Fraction: 0.16243
Policy Update Magnitude: 0.07350
Value Function Update Magnitude: 0.09066

Collected Steps per Second: 10,422.11438
Overall Steps per Second: 9,049.74920

Timestep Collection Time: 4.79979
Timestep Consumption Time: 0.72787
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 5.52767

Cumulative Model Updates: 46,171
Cumulative Timesteps: 770,145,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,289.53083
Policy Entropy: 1.15558
Value Function Loss: 4.20970

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.06792
Value Function Update Magnitude: 0.08125

Collected Steps per Second: 10,163.63538
Overall Steps per Second: 8,764.74056

Timestep Collection Time: 4.92127
Timestep Consumption Time: 0.78546
PPO Batch Consumption Time: 0.04339
Total Iteration Time: 5.70673

Cumulative Model Updates: 46,174
Cumulative Timesteps: 770,195,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 770195376...
Checkpoint 770195376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,068.99533
Policy Entropy: 1.15514
Value Function Loss: 4.32757

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.07547
Value Function Update Magnitude: 0.08223

Collected Steps per Second: 10,425.45197
Overall Steps per Second: 8,886.55675

Timestep Collection Time: 4.79826
Timestep Consumption Time: 0.83092
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 5.62918

Cumulative Model Updates: 46,177
Cumulative Timesteps: 770,245,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,737.22540
Policy Entropy: 1.15457
Value Function Loss: 4.30570

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.06984
Value Function Update Magnitude: 0.08113

Collected Steps per Second: 10,808.04056
Overall Steps per Second: 9,288.85874

Timestep Collection Time: 4.62637
Timestep Consumption Time: 0.75664
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.38301

Cumulative Model Updates: 46,180
Cumulative Timesteps: 770,295,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 770295402...
Checkpoint 770295402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,521.98022
Policy Entropy: 1.15455
Value Function Loss: 4.20826

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.09484

Collected Steps per Second: 10,669.39548
Overall Steps per Second: 9,152.84819

Timestep Collection Time: 4.68911
Timestep Consumption Time: 0.77695
PPO Batch Consumption Time: 0.03849
Total Iteration Time: 5.46606

Cumulative Model Updates: 46,183
Cumulative Timesteps: 770,345,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,908.87327
Policy Entropy: 1.15641
Value Function Loss: 4.38626

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.11451

Collected Steps per Second: 10,263.05995
Overall Steps per Second: 8,979.94164

Timestep Collection Time: 4.87379
Timestep Consumption Time: 0.69640
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.57019

Cumulative Model Updates: 46,186
Cumulative Timesteps: 770,395,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 770395452...
Checkpoint 770395452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,138.10712
Policy Entropy: 1.16218
Value Function Loss: 4.48942

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.09830

Collected Steps per Second: 10,837.76157
Overall Steps per Second: 9,253.75513

Timestep Collection Time: 4.61534
Timestep Consumption Time: 0.79003
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.40537

Cumulative Model Updates: 46,189
Cumulative Timesteps: 770,445,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,959.19402
Policy Entropy: 1.16567
Value Function Loss: 4.33179

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.09745

Collected Steps per Second: 10,578.11536
Overall Steps per Second: 9,074.52524

Timestep Collection Time: 4.72863
Timestep Consumption Time: 0.78350
PPO Batch Consumption Time: 0.03368
Total Iteration Time: 5.51213

Cumulative Model Updates: 46,192
Cumulative Timesteps: 770,495,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 770495492...
Checkpoint 770495492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,941.98257
Policy Entropy: 1.16380
Value Function Loss: 4.11152

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.06974
Value Function Update Magnitude: 0.09069

Collected Steps per Second: 10,637.53950
Overall Steps per Second: 9,282.32692

Timestep Collection Time: 4.70071
Timestep Consumption Time: 0.68630
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.38701

Cumulative Model Updates: 46,195
Cumulative Timesteps: 770,545,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,026.60307
Policy Entropy: 1.15950
Value Function Loss: 4.07988

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.06277
Value Function Update Magnitude: 0.08133

Collected Steps per Second: 10,693.16001
Overall Steps per Second: 9,167.27662

Timestep Collection Time: 4.67607
Timestep Consumption Time: 0.77833
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.45440

Cumulative Model Updates: 46,198
Cumulative Timesteps: 770,595,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 770595498...
Checkpoint 770595498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485,219.04139
Policy Entropy: 1.16947
Value Function Loss: 3.98527

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.09859

Collected Steps per Second: 10,412.27621
Overall Steps per Second: 8,944.14645

Timestep Collection Time: 4.80279
Timestep Consumption Time: 0.78835
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.59114

Cumulative Model Updates: 46,201
Cumulative Timesteps: 770,645,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,750.80769
Policy Entropy: 1.17389
Value Function Loss: 4.14538

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.10569

Collected Steps per Second: 11,916.98370
Overall Steps per Second: 9,978.86242

Timestep Collection Time: 4.19586
Timestep Consumption Time: 0.81493
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.01079

Cumulative Model Updates: 46,204
Cumulative Timesteps: 770,695,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 770695508...
Checkpoint 770695508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575,672.29561
Policy Entropy: 1.15095
Value Function Loss: 4.12223

Mean KL Divergence: 0.03054
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.09126

Collected Steps per Second: 11,312.03969
Overall Steps per Second: 9,665.00789

Timestep Collection Time: 4.42272
Timestep Consumption Time: 0.75368
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.17641

Cumulative Model Updates: 46,207
Cumulative Timesteps: 770,745,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,236.49748
Policy Entropy: 1.16225
Value Function Loss: 4.33745

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.08307

Collected Steps per Second: 11,715.19100
Overall Steps per Second: 10,070.83979

Timestep Collection Time: 4.26933
Timestep Consumption Time: 0.69709
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.96642

Cumulative Model Updates: 46,210
Cumulative Timesteps: 770,795,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 770795554...
Checkpoint 770795554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,541.32817
Policy Entropy: 1.16366
Value Function Loss: 4.30522

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.07963

Collected Steps per Second: 11,452.27215
Overall Steps per Second: 9,678.49515

Timestep Collection Time: 4.36804
Timestep Consumption Time: 0.80053
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.16857

Cumulative Model Updates: 46,213
Cumulative Timesteps: 770,845,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,966.10599
Policy Entropy: 1.15481
Value Function Loss: 4.20695

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.06617
Value Function Update Magnitude: 0.07404

Collected Steps per Second: 11,607.54201
Overall Steps per Second: 9,835.56735

Timestep Collection Time: 4.30978
Timestep Consumption Time: 0.77645
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 5.08623

Cumulative Model Updates: 46,216
Cumulative Timesteps: 770,895,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 770895604...
Checkpoint 770895604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,440.86284
Policy Entropy: 1.15698
Value Function Loss: 4.12312

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.08685

Collected Steps per Second: 10,519.40841
Overall Steps per Second: 9,020.31266

Timestep Collection Time: 4.75388
Timestep Consumption Time: 0.79005
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 5.54393

Cumulative Model Updates: 46,219
Cumulative Timesteps: 770,945,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,333.33432
Policy Entropy: 1.15230
Value Function Loss: 4.10752

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.08149

Collected Steps per Second: 11,003.98657
Overall Steps per Second: 9,391.58813

Timestep Collection Time: 4.54381
Timestep Consumption Time: 0.78011
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.32391

Cumulative Model Updates: 46,222
Cumulative Timesteps: 770,995,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 770995612...
Checkpoint 770995612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,605.60017
Policy Entropy: 1.15364
Value Function Loss: 4.27528

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.06647
Value Function Update Magnitude: 0.07484

Collected Steps per Second: 10,308.30089
Overall Steps per Second: 9,041.20949

Timestep Collection Time: 4.85162
Timestep Consumption Time: 0.67994
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 5.53156

Cumulative Model Updates: 46,225
Cumulative Timesteps: 771,045,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,731.52100
Policy Entropy: 1.14302
Value Function Loss: 4.46858

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.06957

Collected Steps per Second: 10,882.11884
Overall Steps per Second: 9,256.99692

Timestep Collection Time: 4.59672
Timestep Consumption Time: 0.80698
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.40370

Cumulative Model Updates: 46,228
Cumulative Timesteps: 771,095,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 771095646...
Checkpoint 771095646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,738.50142
Policy Entropy: 1.15994
Value Function Loss: 4.58560

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.06824

Collected Steps per Second: 10,805.86862
Overall Steps per Second: 9,371.57805

Timestep Collection Time: 4.62952
Timestep Consumption Time: 0.70853
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.33806

Cumulative Model Updates: 46,231
Cumulative Timesteps: 771,145,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,655.11132
Policy Entropy: 1.14816
Value Function Loss: 4.47531

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12122
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.06729

Collected Steps per Second: 10,608.98690
Overall Steps per Second: 8,995.31855

Timestep Collection Time: 4.71525
Timestep Consumption Time: 0.84587
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.56111

Cumulative Model Updates: 46,234
Cumulative Timesteps: 771,195,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 771195696...
Checkpoint 771195696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,905.60147
Policy Entropy: 1.14641
Value Function Loss: 4.26291

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.06995
Value Function Update Magnitude: 0.06478

Collected Steps per Second: 10,548.43976
Overall Steps per Second: 9,078.28946

Timestep Collection Time: 4.74042
Timestep Consumption Time: 0.76767
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.50809

Cumulative Model Updates: 46,237
Cumulative Timesteps: 771,245,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,301.10645
Policy Entropy: 1.15469
Value Function Loss: 4.23176

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.06627

Collected Steps per Second: 10,177.22000
Overall Steps per Second: 8,937.84860

Timestep Collection Time: 4.91293
Timestep Consumption Time: 0.68125
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.59419

Cumulative Model Updates: 46,240
Cumulative Timesteps: 771,295,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 771295700...
Checkpoint 771295700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,831.75419
Policy Entropy: 1.15808
Value Function Loss: 4.34728

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.06751

Collected Steps per Second: 10,707.56410
Overall Steps per Second: 9,122.55565

Timestep Collection Time: 4.67240
Timestep Consumption Time: 0.81181
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.48421

Cumulative Model Updates: 46,243
Cumulative Timesteps: 771,345,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,555.48269
Policy Entropy: 1.14615
Value Function Loss: 4.47769

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.06558
Value Function Update Magnitude: 0.07675

Collected Steps per Second: 10,595.53056
Overall Steps per Second: 9,136.37388

Timestep Collection Time: 4.71973
Timestep Consumption Time: 0.75378
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 5.47351

Cumulative Model Updates: 46,246
Cumulative Timesteps: 771,395,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 771395738...
Checkpoint 771395738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,521.25807
Policy Entropy: 1.13782
Value Function Loss: 4.44034

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.15059
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.08599

Collected Steps per Second: 10,843.50994
Overall Steps per Second: 9,280.35358

Timestep Collection Time: 4.61198
Timestep Consumption Time: 0.77683
PPO Batch Consumption Time: 0.03889
Total Iteration Time: 5.38880

Cumulative Model Updates: 46,249
Cumulative Timesteps: 771,445,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,869.35356
Policy Entropy: 1.14213
Value Function Loss: 4.34256

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.08364

Collected Steps per Second: 10,241.03304
Overall Steps per Second: 8,823.69768

Timestep Collection Time: 4.88388
Timestep Consumption Time: 0.78449
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.66837

Cumulative Model Updates: 46,252
Cumulative Timesteps: 771,495,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 771495764...
Checkpoint 771495764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,268.01003
Policy Entropy: 1.13440
Value Function Loss: 4.38042

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.08057

Collected Steps per Second: 10,597.35688
Overall Steps per Second: 9,223.64961

Timestep Collection Time: 4.72023
Timestep Consumption Time: 0.70300
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 5.42323

Cumulative Model Updates: 46,255
Cumulative Timesteps: 771,545,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,536.60113
Policy Entropy: 1.13337
Value Function Loss: 4.36934

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.09384

Collected Steps per Second: 10,743.27452
Overall Steps per Second: 9,203.49850

Timestep Collection Time: 4.65407
Timestep Consumption Time: 0.77864
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.43272

Cumulative Model Updates: 46,258
Cumulative Timesteps: 771,595,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 771595786...
Checkpoint 771595786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,160.86832
Policy Entropy: 1.11993
Value Function Loss: 4.47114

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.07134
Value Function Update Magnitude: 0.09239

Collected Steps per Second: 10,666.68828
Overall Steps per Second: 9,157.60575

Timestep Collection Time: 4.68805
Timestep Consumption Time: 0.77254
PPO Batch Consumption Time: 0.03829
Total Iteration Time: 5.46060

Cumulative Model Updates: 46,261
Cumulative Timesteps: 771,645,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,631.94418
Policy Entropy: 1.13695
Value Function Loss: 4.32856

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.10594

Collected Steps per Second: 10,790.94591
Overall Steps per Second: 9,213.32670

Timestep Collection Time: 4.63444
Timestep Consumption Time: 0.79357
PPO Batch Consumption Time: 0.03342
Total Iteration Time: 5.42801

Cumulative Model Updates: 46,264
Cumulative Timesteps: 771,695,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 771695802...
Checkpoint 771695802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,180.86936
Policy Entropy: 1.13371
Value Function Loss: 4.27976

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.11156

Collected Steps per Second: 10,368.13705
Overall Steps per Second: 8,922.57555

Timestep Collection Time: 4.82497
Timestep Consumption Time: 0.78170
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.60668

Cumulative Model Updates: 46,267
Cumulative Timesteps: 771,745,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,085.16519
Policy Entropy: 1.12329
Value Function Loss: 4.00731

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.09528

Collected Steps per Second: 11,074.29273
Overall Steps per Second: 9,625.62795

Timestep Collection Time: 4.51749
Timestep Consumption Time: 0.67989
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 5.19738

Cumulative Model Updates: 46,270
Cumulative Timesteps: 771,795,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 771795856...
Checkpoint 771795856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,497.33105
Policy Entropy: 1.10878
Value Function Loss: 4.13924

Mean KL Divergence: 0.02803
SB3 Clip Fraction: 0.17002
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.08970

Collected Steps per Second: 11,298.75559
Overall Steps per Second: 9,558.13773

Timestep Collection Time: 4.42704
Timestep Consumption Time: 0.80620
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.23324

Cumulative Model Updates: 46,273
Cumulative Timesteps: 771,845,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,551.23839
Policy Entropy: 1.12047
Value Function Loss: 4.12008

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.06328
Value Function Update Magnitude: 0.09760

Collected Steps per Second: 11,176.45213
Overall Steps per Second: 9,545.00033

Timestep Collection Time: 4.47369
Timestep Consumption Time: 0.76465
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.23834

Cumulative Model Updates: 46,276
Cumulative Timesteps: 771,895,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 771895876...
Checkpoint 771895876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515,922.68883
Policy Entropy: 1.11585
Value Function Loss: 4.19153

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.06545
Value Function Update Magnitude: 0.10383

Collected Steps per Second: 11,413.02297
Overall Steps per Second: 9,707.52439

Timestep Collection Time: 4.38254
Timestep Consumption Time: 0.76996
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.15250

Cumulative Model Updates: 46,279
Cumulative Timesteps: 771,945,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,334.83803
Policy Entropy: 1.10897
Value Function Loss: 4.00029

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.07136
Value Function Update Magnitude: 0.09420

Collected Steps per Second: 10,865.73162
Overall Steps per Second: 9,325.46238

Timestep Collection Time: 4.60346
Timestep Consumption Time: 0.76035
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.36381

Cumulative Model Updates: 46,282
Cumulative Timesteps: 771,995,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 771995914...
Checkpoint 771995914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,434.82458
Policy Entropy: 1.10654
Value Function Loss: 4.05376

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.07493
Value Function Update Magnitude: 0.08149

Collected Steps per Second: 10,424.31876
Overall Steps per Second: 9,066.38399

Timestep Collection Time: 4.79744
Timestep Consumption Time: 0.71855
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 5.51598

Cumulative Model Updates: 46,285
Cumulative Timesteps: 772,045,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,223.58383
Policy Entropy: 1.11237
Value Function Loss: 4.05867

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.06291
Value Function Update Magnitude: 0.07628

Collected Steps per Second: 10,678.26355
Overall Steps per Second: 9,187.17605

Timestep Collection Time: 4.68484
Timestep Consumption Time: 0.76035
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.44520

Cumulative Model Updates: 46,288
Cumulative Timesteps: 772,095,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 772095950...
Checkpoint 772095950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,287.98867
Policy Entropy: 1.11153
Value Function Loss: 4.42230

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 10,458.59955
Overall Steps per Second: 9,024.87767

Timestep Collection Time: 4.78075
Timestep Consumption Time: 0.75949
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.54024

Cumulative Model Updates: 46,291
Cumulative Timesteps: 772,145,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,822.75985
Policy Entropy: 1.11193
Value Function Loss: 4.27016

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.06527
Value Function Update Magnitude: 0.06842

Collected Steps per Second: 11,027.22357
Overall Steps per Second: 9,462.12385

Timestep Collection Time: 4.53605
Timestep Consumption Time: 0.75029
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.28634

Cumulative Model Updates: 46,294
Cumulative Timesteps: 772,195,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 772195970...
Checkpoint 772195970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,400.06080
Policy Entropy: 1.10970
Value Function Loss: 4.33269

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.06698
Value Function Update Magnitude: 0.08713

Collected Steps per Second: 10,862.19746
Overall Steps per Second: 9,356.80391

Timestep Collection Time: 4.60496
Timestep Consumption Time: 0.74088
PPO Batch Consumption Time: 0.03338
Total Iteration Time: 5.34584

Cumulative Model Updates: 46,297
Cumulative Timesteps: 772,245,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,890.04277
Policy Entropy: 1.10453
Value Function Loss: 4.18402

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.06091
Value Function Update Magnitude: 0.09259

Collected Steps per Second: 10,661.37348
Overall Steps per Second: 9,163.02294

Timestep Collection Time: 4.69152
Timestep Consumption Time: 0.76716
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.45868

Cumulative Model Updates: 46,300
Cumulative Timesteps: 772,296,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 772296008...
Checkpoint 772296008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,333.03446
Policy Entropy: 1.11719
Value Function Loss: 4.32583

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.08982

Collected Steps per Second: 10,502.98574
Overall Steps per Second: 9,073.93797

Timestep Collection Time: 4.76169
Timestep Consumption Time: 0.74992
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.51161

Cumulative Model Updates: 46,303
Cumulative Timesteps: 772,346,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,803.61372
Policy Entropy: 1.11617
Value Function Loss: 4.36874

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.08438

Collected Steps per Second: 10,451.16735
Overall Steps per Second: 9,054.69076

Timestep Collection Time: 4.78454
Timestep Consumption Time: 0.73790
PPO Batch Consumption Time: 0.03326
Total Iteration Time: 5.52244

Cumulative Model Updates: 46,306
Cumulative Timesteps: 772,396,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 772396024...
Checkpoint 772396024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,927.62655
Policy Entropy: 1.10411
Value Function Loss: 4.36943

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.08213

Collected Steps per Second: 10,831.69911
Overall Steps per Second: 9,234.01874

Timestep Collection Time: 4.61627
Timestep Consumption Time: 0.79871
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 5.41498

Cumulative Model Updates: 46,309
Cumulative Timesteps: 772,446,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,935.07141
Policy Entropy: 1.09848
Value Function Loss: 4.47524

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.08300

Collected Steps per Second: 10,608.62833
Overall Steps per Second: 9,129.96287

Timestep Collection Time: 4.71560
Timestep Consumption Time: 0.76373
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 5.47932

Cumulative Model Updates: 46,312
Cumulative Timesteps: 772,496,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 772496052...
Checkpoint 772496052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,644.13175
Policy Entropy: 1.11011
Value Function Loss: 4.63104

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.08079

Collected Steps per Second: 10,778.36655
Overall Steps per Second: 9,380.58058

Timestep Collection Time: 4.63911
Timestep Consumption Time: 0.69127
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.33037

Cumulative Model Updates: 46,315
Cumulative Timesteps: 772,546,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,865.74362
Policy Entropy: 1.11452
Value Function Loss: 4.51287

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.06859
Value Function Update Magnitude: 0.06660

Collected Steps per Second: 10,198.77768
Overall Steps per Second: 8,720.66617

Timestep Collection Time: 4.90431
Timestep Consumption Time: 0.83126
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.73557

Cumulative Model Updates: 46,318
Cumulative Timesteps: 772,596,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 772596072...
Checkpoint 772596072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,604.62241
Policy Entropy: 1.10148
Value Function Loss: 4.41946

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.06897
Value Function Update Magnitude: 0.06005

Collected Steps per Second: 10,583.34298
Overall Steps per Second: 9,129.28870

Timestep Collection Time: 4.72554
Timestep Consumption Time: 0.75265
PPO Batch Consumption Time: 0.03379
Total Iteration Time: 5.47819

Cumulative Model Updates: 46,321
Cumulative Timesteps: 772,646,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,692.34089
Policy Entropy: 1.08313
Value Function Loss: 4.07714

Mean KL Divergence: 0.03249
SB3 Clip Fraction: 0.18727
Policy Update Magnitude: 0.06076
Value Function Update Magnitude: 0.05216

Collected Steps per Second: 10,940.56947
Overall Steps per Second: 9,277.12989

Timestep Collection Time: 4.57271
Timestep Consumption Time: 0.81991
PPO Batch Consumption Time: 0.04001
Total Iteration Time: 5.39262

Cumulative Model Updates: 46,324
Cumulative Timesteps: 772,696,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 772696112...
Checkpoint 772696112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,232.54653
Policy Entropy: 1.09437
Value Function Loss: 4.24413

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.04946

Collected Steps per Second: 10,691.62751
Overall Steps per Second: 9,119.63085

Timestep Collection Time: 4.67749
Timestep Consumption Time: 0.80628
PPO Batch Consumption Time: 0.03809
Total Iteration Time: 5.48377

Cumulative Model Updates: 46,327
Cumulative Timesteps: 772,746,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,692.99500
Policy Entropy: 1.08936
Value Function Loss: 4.25434

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.07199
Value Function Update Magnitude: 0.04852

Collected Steps per Second: 10,382.06131
Overall Steps per Second: 8,995.91358

Timestep Collection Time: 4.81696
Timestep Consumption Time: 0.74223
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.55919

Cumulative Model Updates: 46,330
Cumulative Timesteps: 772,796,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 772796132...
Checkpoint 772796132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,147.01420
Policy Entropy: 1.09120
Value Function Loss: 4.38999

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.07246
Value Function Update Magnitude: 0.04658

Collected Steps per Second: 10,529.73291
Overall Steps per Second: 8,972.19282

Timestep Collection Time: 4.74884
Timestep Consumption Time: 0.82438
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.57322

Cumulative Model Updates: 46,333
Cumulative Timesteps: 772,846,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,399.90064
Policy Entropy: 1.07654
Value Function Loss: 4.25060

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.16871
Policy Update Magnitude: 0.07485
Value Function Update Magnitude: 0.04478

Collected Steps per Second: 11,707.01372
Overall Steps per Second: 10,040.13888

Timestep Collection Time: 4.27231
Timestep Consumption Time: 0.70929
PPO Batch Consumption Time: 0.03343
Total Iteration Time: 4.98160

Cumulative Model Updates: 46,336
Cumulative Timesteps: 772,896,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 772896152...
Checkpoint 772896152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,835.50401
Policy Entropy: 1.09650
Value Function Loss: 4.12111

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.06117

Collected Steps per Second: 11,661.86984
Overall Steps per Second: 9,757.29280

Timestep Collection Time: 4.28954
Timestep Consumption Time: 0.83730
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.12683

Cumulative Model Updates: 46,339
Cumulative Timesteps: 772,946,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,059.02610
Policy Entropy: 1.09389
Value Function Loss: 3.93074

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.06801

Collected Steps per Second: 11,257.20907
Overall Steps per Second: 9,546.33554

Timestep Collection Time: 4.44426
Timestep Consumption Time: 0.79649
PPO Batch Consumption Time: 0.04459
Total Iteration Time: 5.24075

Cumulative Model Updates: 46,342
Cumulative Timesteps: 772,996,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 772996206...
Checkpoint 772996206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,678.42036
Policy Entropy: 1.09536
Value Function Loss: 3.88102

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.06992
Value Function Update Magnitude: 0.07032

Collected Steps per Second: 11,568.12012
Overall Steps per Second: 9,859.19964

Timestep Collection Time: 4.32292
Timestep Consumption Time: 0.74930
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.07222

Cumulative Model Updates: 46,345
Cumulative Timesteps: 773,046,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,255.37585
Policy Entropy: 1.08003
Value Function Loss: 3.90027

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.07415
Value Function Update Magnitude: 0.07008

Collected Steps per Second: 11,387.10447
Overall Steps per Second: 9,609.01758

Timestep Collection Time: 4.39199
Timestep Consumption Time: 0.81271
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.20469

Cumulative Model Updates: 46,348
Cumulative Timesteps: 773,096,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 773096226...
Checkpoint 773096226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,036.06575
Policy Entropy: 1.10122
Value Function Loss: 4.12803

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.07675

Collected Steps per Second: 10,872.12289
Overall Steps per Second: 9,250.53045

Timestep Collection Time: 4.60168
Timestep Consumption Time: 0.80666
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.40834

Cumulative Model Updates: 46,351
Cumulative Timesteps: 773,146,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,083.52247
Policy Entropy: 1.08644
Value Function Loss: 4.20287

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.06590
Value Function Update Magnitude: 0.07314

Collected Steps per Second: 11,027.41126
Overall Steps per Second: 9,328.12855

Timestep Collection Time: 4.53543
Timestep Consumption Time: 0.82621
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.36163

Cumulative Model Updates: 46,354
Cumulative Timesteps: 773,196,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 773196270...
Checkpoint 773196270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,525.83714
Policy Entropy: 1.08452
Value Function Loss: 4.29778

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.11755
Policy Update Magnitude: 0.07556
Value Function Update Magnitude: 0.06671

Collected Steps per Second: 10,511.07149
Overall Steps per Second: 8,956.86395

Timestep Collection Time: 4.75898
Timestep Consumption Time: 0.82579
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.58477

Cumulative Model Updates: 46,357
Cumulative Timesteps: 773,246,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,436.19142
Policy Entropy: 1.08532
Value Function Loss: 4.29534

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.06853
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 10,647.56768
Overall Steps per Second: 9,272.84759

Timestep Collection Time: 4.69816
Timestep Consumption Time: 0.69651
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.39468

Cumulative Model Updates: 46,360
Cumulative Timesteps: 773,296,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 773296316...
Checkpoint 773296316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,826.13712
Policy Entropy: 1.09461
Value Function Loss: 4.33048

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.06005
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 10,802.89933
Overall Steps per Second: 9,204.00415

Timestep Collection Time: 4.63042
Timestep Consumption Time: 0.80438
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 5.43481

Cumulative Model Updates: 46,363
Cumulative Timesteps: 773,346,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,028.87607
Policy Entropy: 1.10026
Value Function Loss: 4.29578

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.06937

Collected Steps per Second: 10,598.21125
Overall Steps per Second: 9,065.92115

Timestep Collection Time: 4.71853
Timestep Consumption Time: 0.79751
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 5.51604

Cumulative Model Updates: 46,366
Cumulative Timesteps: 773,396,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 773396346...
Checkpoint 773396346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,547.13400
Policy Entropy: 1.10291
Value Function Loss: 4.06815

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.06328
Value Function Update Magnitude: 0.07823

Collected Steps per Second: 10,151.96597
Overall Steps per Second: 8,765.15631

Timestep Collection Time: 4.92791
Timestep Consumption Time: 0.77969
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.70760

Cumulative Model Updates: 46,369
Cumulative Timesteps: 773,446,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,148.25089
Policy Entropy: 1.09794
Value Function Loss: 3.96460

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.08338

Collected Steps per Second: 10,469.41120
Overall Steps per Second: 9,004.29046

Timestep Collection Time: 4.77601
Timestep Consumption Time: 0.77712
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.55313

Cumulative Model Updates: 46,372
Cumulative Timesteps: 773,496,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 773496376...
Checkpoint 773496376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,260.39066
Policy Entropy: 1.10689
Value Function Loss: 4.10807

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.07872

Collected Steps per Second: 10,787.70687
Overall Steps per Second: 9,381.12962

Timestep Collection Time: 4.63602
Timestep Consumption Time: 0.69511
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.33113

Cumulative Model Updates: 46,375
Cumulative Timesteps: 773,546,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,623.14076
Policy Entropy: 1.10923
Value Function Loss: 4.21499

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.11162
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.07284

Collected Steps per Second: 10,588.80913
Overall Steps per Second: 9,014.79306

Timestep Collection Time: 4.72386
Timestep Consumption Time: 0.82480
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.54866

Cumulative Model Updates: 46,378
Cumulative Timesteps: 773,596,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 773596408...
Checkpoint 773596408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,129.75384
Policy Entropy: 1.11672
Value Function Loss: 4.29519

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.07807

Collected Steps per Second: 10,454.72297
Overall Steps per Second: 8,999.50728

Timestep Collection Time: 4.78463
Timestep Consumption Time: 0.77367
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 5.55830

Cumulative Model Updates: 46,381
Cumulative Timesteps: 773,646,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,420.26951
Policy Entropy: 1.11532
Value Function Loss: 4.23912

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.06547
Value Function Update Magnitude: 0.09234

Collected Steps per Second: 10,420.00212
Overall Steps per Second: 8,829.99168

Timestep Collection Time: 4.80038
Timestep Consumption Time: 0.86440
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 5.66478

Cumulative Model Updates: 46,384
Cumulative Timesteps: 773,696,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 773696450...
Checkpoint 773696450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,166.18115
Policy Entropy: 1.11099
Value Function Loss: 4.15767

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.06731
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 10,650.96915
Overall Steps per Second: 9,160.12600

Timestep Collection Time: 4.69591
Timestep Consumption Time: 0.76428
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.46019

Cumulative Model Updates: 46,387
Cumulative Timesteps: 773,746,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,826.39405
Policy Entropy: 1.11477
Value Function Loss: 4.30138

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.10079

Collected Steps per Second: 10,596.12591
Overall Steps per Second: 9,230.04305

Timestep Collection Time: 4.72135
Timestep Consumption Time: 0.69878
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.42013

Cumulative Model Updates: 46,390
Cumulative Timesteps: 773,796,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 773796494...
Checkpoint 773796494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,904.27166
Policy Entropy: 1.12254
Value Function Loss: 4.37766

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 10,615.23331
Overall Steps per Second: 9,117.20304

Timestep Collection Time: 4.71097
Timestep Consumption Time: 0.77405
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.48502

Cumulative Model Updates: 46,393
Cumulative Timesteps: 773,846,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,413.39409
Policy Entropy: 1.11139
Value Function Loss: 4.43497

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 10,383.41376
Overall Steps per Second: 8,973.16939

Timestep Collection Time: 4.81653
Timestep Consumption Time: 0.75698
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 5.57350

Cumulative Model Updates: 46,396
Cumulative Timesteps: 773,896,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 773896514...
Checkpoint 773896514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,585.01178
Policy Entropy: 1.10965
Value Function Loss: 4.22546

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.12552

Collected Steps per Second: 10,506.93692
Overall Steps per Second: 9,036.88581

Timestep Collection Time: 4.76162
Timestep Consumption Time: 0.77458
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 5.53620

Cumulative Model Updates: 46,399
Cumulative Timesteps: 773,946,544

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,016.62180
Policy Entropy: 1.11677
Value Function Loss: 4.13693

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 10,784.47328
Overall Steps per Second: 9,245.27926

Timestep Collection Time: 4.63722
Timestep Consumption Time: 0.77202
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.40925

Cumulative Model Updates: 46,402
Cumulative Timesteps: 773,996,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 773996554...
Checkpoint 773996554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,878.67086
Policy Entropy: 1.11643
Value Function Loss: 4.27849

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.11650

Collected Steps per Second: 10,738.32848
Overall Steps per Second: 9,260.64493

Timestep Collection Time: 4.65678
Timestep Consumption Time: 0.74306
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.39984

Cumulative Model Updates: 46,405
Cumulative Timesteps: 774,046,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,124.47428
Policy Entropy: 1.09184
Value Function Loss: 4.43512

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.12554

Collected Steps per Second: 11,118.12450
Overall Steps per Second: 9,517.80943

Timestep Collection Time: 4.49806
Timestep Consumption Time: 0.75630
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.25436

Cumulative Model Updates: 46,408
Cumulative Timesteps: 774,096,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 774096570...
Checkpoint 774096570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,418.48750
Policy Entropy: 1.10844
Value Function Loss: 4.40226

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.05773
Value Function Update Magnitude: 0.11605

Collected Steps per Second: 10,651.38014
Overall Steps per Second: 9,179.68408

Timestep Collection Time: 4.69517
Timestep Consumption Time: 0.75273
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 5.44790

Cumulative Model Updates: 46,411
Cumulative Timesteps: 774,146,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,485.72421
Policy Entropy: 1.10877
Value Function Loss: 4.36829

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.10908

Collected Steps per Second: 10,875.66783
Overall Steps per Second: 9,485.13204

Timestep Collection Time: 4.59871
Timestep Consumption Time: 0.67418
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.27288

Cumulative Model Updates: 46,414
Cumulative Timesteps: 774,196,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 774196594...
Checkpoint 774196594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,139.68559
Policy Entropy: 1.10873
Value Function Loss: 4.12187

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.06359
Value Function Update Magnitude: 0.09413

Collected Steps per Second: 10,103.69108
Overall Steps per Second: 8,730.58502

Timestep Collection Time: 4.95146
Timestep Consumption Time: 0.77874
PPO Batch Consumption Time: 0.03945
Total Iteration Time: 5.73020

Cumulative Model Updates: 46,417
Cumulative Timesteps: 774,246,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,506.53341
Policy Entropy: 1.09281
Value Function Loss: 4.02073

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.17351
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.09588

Collected Steps per Second: 10,941.96786
Overall Steps per Second: 9,401.04941

Timestep Collection Time: 4.57011
Timestep Consumption Time: 0.74908
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.31919

Cumulative Model Updates: 46,420
Cumulative Timesteps: 774,296,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 774296628...
Checkpoint 774296628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,176.14567
Policy Entropy: 1.10219
Value Function Loss: 3.94942

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.08582

Collected Steps per Second: 11,021.40196
Overall Steps per Second: 9,385.55422

Timestep Collection Time: 4.53681
Timestep Consumption Time: 0.79074
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.32755

Cumulative Model Updates: 46,423
Cumulative Timesteps: 774,346,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,533.01131
Policy Entropy: 1.11189
Value Function Loss: 4.23180

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.07862

Collected Steps per Second: 10,912.99406
Overall Steps per Second: 9,260.55517

Timestep Collection Time: 4.58371
Timestep Consumption Time: 0.81791
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.40162

Cumulative Model Updates: 46,426
Cumulative Timesteps: 774,396,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 774396652...
Checkpoint 774396652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,718.69940
Policy Entropy: 1.09536
Value Function Loss: 4.41342

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.08542

Collected Steps per Second: 10,797.46541
Overall Steps per Second: 9,284.53543

Timestep Collection Time: 4.63275
Timestep Consumption Time: 0.75491
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.38767

Cumulative Model Updates: 46,429
Cumulative Timesteps: 774,446,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,205.60161
Policy Entropy: 1.09828
Value Function Loss: 4.46001

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.08192

Collected Steps per Second: 10,702.72709
Overall Steps per Second: 9,030.12685

Timestep Collection Time: 4.67245
Timestep Consumption Time: 0.86545
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 5.53791

Cumulative Model Updates: 46,432
Cumulative Timesteps: 774,496,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 774496682...
Checkpoint 774496682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,527.50331
Policy Entropy: 1.10130
Value Function Loss: 4.26427

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.07954

Collected Steps per Second: 10,493.80172
Overall Steps per Second: 9,012.28828

Timestep Collection Time: 4.76529
Timestep Consumption Time: 0.78336
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.54865

Cumulative Model Updates: 46,435
Cumulative Timesteps: 774,546,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,180.45209
Policy Entropy: 1.10781
Value Function Loss: 4.00130

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.08194

Collected Steps per Second: 10,488.97669
Overall Steps per Second: 9,200.97980

Timestep Collection Time: 4.76729
Timestep Consumption Time: 0.66735
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.43464

Cumulative Model Updates: 46,438
Cumulative Timesteps: 774,596,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 774596692...
Checkpoint 774596692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,124.46903
Policy Entropy: 1.09258
Value Function Loss: 4.05988

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.08341

Collected Steps per Second: 10,746.12199
Overall Steps per Second: 9,220.01751

Timestep Collection Time: 4.65582
Timestep Consumption Time: 0.77063
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.42645

Cumulative Model Updates: 46,441
Cumulative Timesteps: 774,646,724

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,749.10073
Policy Entropy: 1.08547
Value Function Loss: 4.18592

Mean KL Divergence: 0.02673
SB3 Clip Fraction: 0.15715
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 10,894.07103
Overall Steps per Second: 9,405.42959

Timestep Collection Time: 4.59057
Timestep Consumption Time: 0.72657
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.31714

Cumulative Model Updates: 46,444
Cumulative Timesteps: 774,696,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 774696734...
Checkpoint 774696734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,593.26145
Policy Entropy: 1.09972
Value Function Loss: 4.42099

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.07982

Collected Steps per Second: 11,028.16756
Overall Steps per Second: 9,441.96100

Timestep Collection Time: 4.53457
Timestep Consumption Time: 0.76179
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.29636

Cumulative Model Updates: 46,447
Cumulative Timesteps: 774,746,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,256.42892
Policy Entropy: 1.10372
Value Function Loss: 4.36486

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.06760
Value Function Update Magnitude: 0.08799

Collected Steps per Second: 10,381.00328
Overall Steps per Second: 8,950.81288

Timestep Collection Time: 4.81861
Timestep Consumption Time: 0.76993
PPO Batch Consumption Time: 0.03846
Total Iteration Time: 5.58854

Cumulative Model Updates: 46,450
Cumulative Timesteps: 774,796,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 774796764...
Checkpoint 774796764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,958.83796
Policy Entropy: 1.09190
Value Function Loss: 4.27489

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.06419
Value Function Update Magnitude: 0.10009

Collected Steps per Second: 10,715.59809
Overall Steps per Second: 9,340.16693

Timestep Collection Time: 4.66684
Timestep Consumption Time: 0.68724
PPO Batch Consumption Time: 0.03967
Total Iteration Time: 5.35408

Cumulative Model Updates: 46,453
Cumulative Timesteps: 774,846,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,313.79112
Policy Entropy: 1.08110
Value Function Loss: 4.13601

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.17718
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.10780

Collected Steps per Second: 10,923.16111
Overall Steps per Second: 9,344.76030

Timestep Collection Time: 4.57798
Timestep Consumption Time: 0.77326
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.35123

Cumulative Model Updates: 46,456
Cumulative Timesteps: 774,896,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 774896778...
Checkpoint 774896778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,653.26064
Policy Entropy: 1.09134
Value Function Loss: 4.10271

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.09691

Collected Steps per Second: 10,923.03941
Overall Steps per Second: 9,316.23346

Timestep Collection Time: 4.57968
Timestep Consumption Time: 0.78987
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.36955

Cumulative Model Updates: 46,459
Cumulative Timesteps: 774,946,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,391.23205
Policy Entropy: 1.09323
Value Function Loss: 3.99364

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.08653

Collected Steps per Second: 10,880.20398
Overall Steps per Second: 9,331.30459

Timestep Collection Time: 4.59569
Timestep Consumption Time: 0.76284
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.35852

Cumulative Model Updates: 46,462
Cumulative Timesteps: 774,996,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 774996804...
Checkpoint 774996804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,849.77444
Policy Entropy: 1.08564
Value Function Loss: 4.04853

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.07676

Collected Steps per Second: 10,798.69719
Overall Steps per Second: 9,150.49138

Timestep Collection Time: 4.63093
Timestep Consumption Time: 0.83413
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.46506

Cumulative Model Updates: 46,465
Cumulative Timesteps: 775,046,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,922.07370
Policy Entropy: 1.07588
Value Function Loss: 3.99529

Mean KL Divergence: 0.03095
SB3 Clip Fraction: 0.16675
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.07146

Collected Steps per Second: 11,164.21647
Overall Steps per Second: 9,577.50987

Timestep Collection Time: 4.47967
Timestep Consumption Time: 0.74215
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.22182

Cumulative Model Updates: 46,468
Cumulative Timesteps: 775,096,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 775096824...
Checkpoint 775096824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,770.15592
Policy Entropy: 1.09383
Value Function Loss: 3.95587

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.07837

Collected Steps per Second: 11,472.21375
Overall Steps per Second: 9,709.32540

Timestep Collection Time: 4.35923
Timestep Consumption Time: 0.79149
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.15072

Cumulative Model Updates: 46,471
Cumulative Timesteps: 775,146,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,330.84114
Policy Entropy: 1.09256
Value Function Loss: 3.98531

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.06785
Value Function Update Magnitude: 0.08340

Collected Steps per Second: 11,729.95218
Overall Steps per Second: 10,092.53963

Timestep Collection Time: 4.26379
Timestep Consumption Time: 0.69176
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 4.95554

Cumulative Model Updates: 46,474
Cumulative Timesteps: 775,196,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 775196848...
Checkpoint 775196848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,065.75122
Policy Entropy: 1.08535
Value Function Loss: 4.07820

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.07101
Value Function Update Magnitude: 0.08116

Collected Steps per Second: 11,564.06727
Overall Steps per Second: 9,757.25506

Timestep Collection Time: 4.32460
Timestep Consumption Time: 0.80081
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 5.12542

Cumulative Model Updates: 46,477
Cumulative Timesteps: 775,246,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,918.46519
Policy Entropy: 1.08125
Value Function Loss: 4.07311

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.10137

Collected Steps per Second: 11,546.99701
Overall Steps per Second: 9,990.58389

Timestep Collection Time: 4.33152
Timestep Consumption Time: 0.67480
PPO Batch Consumption Time: 0.03386
Total Iteration Time: 5.00631

Cumulative Model Updates: 46,480
Cumulative Timesteps: 775,296,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 775296874...
Checkpoint 775296874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,206.57262
Policy Entropy: 1.09308
Value Function Loss: 4.12987

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.10079

Collected Steps per Second: 11,362.40958
Overall Steps per Second: 9,354.80138

Timestep Collection Time: 4.40083
Timestep Consumption Time: 0.94445
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 5.34528

Cumulative Model Updates: 46,483
Cumulative Timesteps: 775,346,878

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,114.02912
Policy Entropy: 1.09935
Value Function Loss: 3.99603

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.10341

Collected Steps per Second: 10,893.66122
Overall Steps per Second: 9,456.66963

Timestep Collection Time: 4.59056
Timestep Consumption Time: 0.69756
PPO Batch Consumption Time: 0.03881
Total Iteration Time: 5.28812

Cumulative Model Updates: 46,486
Cumulative Timesteps: 775,396,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 775396886...
Checkpoint 775396886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,515.70019
Policy Entropy: 1.09760
Value Function Loss: 4.17669

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.09589

Collected Steps per Second: 10,728.75070
Overall Steps per Second: 9,197.38802

Timestep Collection Time: 4.66093
Timestep Consumption Time: 0.77604
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.43698

Cumulative Model Updates: 46,489
Cumulative Timesteps: 775,446,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,358.57356
Policy Entropy: 1.09588
Value Function Loss: 3.84913

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.07193
Value Function Update Magnitude: 0.09972

Collected Steps per Second: 11,114.59204
Overall Steps per Second: 9,486.41062

Timestep Collection Time: 4.50039
Timestep Consumption Time: 0.77242
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 5.27281

Cumulative Model Updates: 46,492
Cumulative Timesteps: 775,496,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 775496912...
Checkpoint 775496912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,832.19866
Policy Entropy: 1.09481
Value Function Loss: 4.07380

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.07150
Value Function Update Magnitude: 0.10334

Collected Steps per Second: 10,959.56013
Overall Steps per Second: 9,484.70560

Timestep Collection Time: 4.56387
Timestep Consumption Time: 0.70967
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.27354

Cumulative Model Updates: 46,495
Cumulative Timesteps: 775,546,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,957.06065
Policy Entropy: 1.09768
Value Function Loss: 3.85904

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.06784
Value Function Update Magnitude: 0.09221

Collected Steps per Second: 10,825.36783
Overall Steps per Second: 9,207.68636

Timestep Collection Time: 4.61915
Timestep Consumption Time: 0.81153
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.43068

Cumulative Model Updates: 46,498
Cumulative Timesteps: 775,596,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 775596934...
Checkpoint 775596934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,641.50785
Policy Entropy: 1.10055
Value Function Loss: 4.05823

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.09345

Collected Steps per Second: 10,615.68421
Overall Steps per Second: 9,170.70696

Timestep Collection Time: 4.71095
Timestep Consumption Time: 0.74228
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.45323

Cumulative Model Updates: 46,501
Cumulative Timesteps: 775,646,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,338.28097
Policy Entropy: 1.09997
Value Function Loss: 3.93393

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.07404
Value Function Update Magnitude: 0.08899

Collected Steps per Second: 10,961.80646
Overall Steps per Second: 9,404.88278

Timestep Collection Time: 4.56239
Timestep Consumption Time: 0.75528
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.31766

Cumulative Model Updates: 46,504
Cumulative Timesteps: 775,696,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 775696956...
Checkpoint 775696956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,752.91802
Policy Entropy: 1.09807
Value Function Loss: 4.22203

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.07955
Value Function Update Magnitude: 0.08719

Collected Steps per Second: 10,795.96996
Overall Steps per Second: 9,238.71749

Timestep Collection Time: 4.63228
Timestep Consumption Time: 0.78080
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.41309

Cumulative Model Updates: 46,507
Cumulative Timesteps: 775,746,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,940.24299
Policy Entropy: 1.09046
Value Function Loss: 4.24650

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.15207
Policy Update Magnitude: 0.06949
Value Function Update Magnitude: 0.09323

Collected Steps per Second: 10,661.71783
Overall Steps per Second: 9,326.39204

Timestep Collection Time: 4.69099
Timestep Consumption Time: 0.67164
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.36263

Cumulative Model Updates: 46,510
Cumulative Timesteps: 775,796,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 775796980...
Checkpoint 775796980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,058.97818
Policy Entropy: 1.10890
Value Function Loss: 4.35357

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.09618

Collected Steps per Second: 10,949.97920
Overall Steps per Second: 9,369.53859

Timestep Collection Time: 4.56914
Timestep Consumption Time: 0.77072
PPO Batch Consumption Time: 0.04001
Total Iteration Time: 5.33986

Cumulative Model Updates: 46,513
Cumulative Timesteps: 775,847,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,959.20372
Policy Entropy: 1.11776
Value Function Loss: 4.18853

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.09718

Collected Steps per Second: 10,769.28434
Overall Steps per Second: 9,380.42524

Timestep Collection Time: 4.64358
Timestep Consumption Time: 0.68752
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.33110

Cumulative Model Updates: 46,516
Cumulative Timesteps: 775,897,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 775897020...
Checkpoint 775897020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,581.04930
Policy Entropy: 1.09611
Value Function Loss: 4.14877

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.15831
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.08918

Collected Steps per Second: 10,646.61061
Overall Steps per Second: 9,184.68050

Timestep Collection Time: 4.69633
Timestep Consumption Time: 0.74752
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 5.44385

Cumulative Model Updates: 46,519
Cumulative Timesteps: 775,947,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,478.22819
Policy Entropy: 1.10706
Value Function Loss: 4.18914

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.08888

Collected Steps per Second: 10,833.51713
Overall Steps per Second: 9,295.47185

Timestep Collection Time: 4.61660
Timestep Consumption Time: 0.76387
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 5.38047

Cumulative Model Updates: 46,522
Cumulative Timesteps: 775,997,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 775997034...
Checkpoint 775997034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,016.15391
Policy Entropy: 1.10450
Value Function Loss: 4.21552

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.08656

Collected Steps per Second: 10,816.69717
Overall Steps per Second: 9,444.65518

Timestep Collection Time: 4.62581
Timestep Consumption Time: 0.67200
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.29781

Cumulative Model Updates: 46,525
Cumulative Timesteps: 776,047,070

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,346.64176
Policy Entropy: 1.09037
Value Function Loss: 4.14430

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.08967

Collected Steps per Second: 10,627.15468
Overall Steps per Second: 9,125.53949

Timestep Collection Time: 4.70662
Timestep Consumption Time: 0.77448
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.48110

Cumulative Model Updates: 46,528
Cumulative Timesteps: 776,097,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 776097088...
Checkpoint 776097088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,221.06406
Policy Entropy: 1.08151
Value Function Loss: 4.04561

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.16607
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.09535

Collected Steps per Second: 10,836.78301
Overall Steps per Second: 9,479.37850

Timestep Collection Time: 4.61392
Timestep Consumption Time: 0.66069
PPO Batch Consumption Time: 0.03333
Total Iteration Time: 5.27461

Cumulative Model Updates: 46,531
Cumulative Timesteps: 776,147,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,469.02001
Policy Entropy: 1.09228
Value Function Loss: 3.91272

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 10,421.58376
Overall Steps per Second: 8,980.67135

Timestep Collection Time: 4.79831
Timestep Consumption Time: 0.76987
PPO Batch Consumption Time: 0.03844
Total Iteration Time: 5.56818

Cumulative Model Updates: 46,534
Cumulative Timesteps: 776,197,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 776197094...
Checkpoint 776197094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,226.51903
Policy Entropy: 1.09957
Value Function Loss: 3.88961

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.08594

Collected Steps per Second: 11,314.05019
Overall Steps per Second: 9,648.49276

Timestep Collection Time: 4.41999
Timestep Consumption Time: 0.76299
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.18299

Cumulative Model Updates: 46,537
Cumulative Timesteps: 776,247,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,739.11750
Policy Entropy: 1.07317
Value Function Loss: 4.04360

Mean KL Divergence: 0.02982
SB3 Clip Fraction: 0.17932
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.08154

Collected Steps per Second: 11,445.71502
Overall Steps per Second: 9,945.24942

Timestep Collection Time: 4.36915
Timestep Consumption Time: 0.65918
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.02833

Cumulative Model Updates: 46,540
Cumulative Timesteps: 776,297,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 776297110...
Checkpoint 776297110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,951.02880
Policy Entropy: 1.09086
Value Function Loss: 4.21250

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.08422

Collected Steps per Second: 11,319.29141
Overall Steps per Second: 9,682.09575

Timestep Collection Time: 4.41777
Timestep Consumption Time: 0.74702
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.16479

Cumulative Model Updates: 46,543
Cumulative Timesteps: 776,347,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,527.67951
Policy Entropy: 1.09096
Value Function Loss: 4.36759

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14992
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.09963

Collected Steps per Second: 11,281.69803
Overall Steps per Second: 9,676.99419

Timestep Collection Time: 4.43320
Timestep Consumption Time: 0.73514
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.16834

Cumulative Model Updates: 46,546
Cumulative Timesteps: 776,397,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 776397130...
Checkpoint 776397130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,586.94018
Policy Entropy: 1.07740
Value Function Loss: 4.12309

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.09685

Collected Steps per Second: 11,482.66826
Overall Steps per Second: 9,711.69255

Timestep Collection Time: 4.35596
Timestep Consumption Time: 0.79433
PPO Batch Consumption Time: 0.03908
Total Iteration Time: 5.15029

Cumulative Model Updates: 46,549
Cumulative Timesteps: 776,447,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,783.38290
Policy Entropy: 1.06223
Value Function Loss: 4.28272

Mean KL Divergence: 0.02502
SB3 Clip Fraction: 0.17682
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.09081

Collected Steps per Second: 10,931.36793
Overall Steps per Second: 9,394.53757

Timestep Collection Time: 4.57655
Timestep Consumption Time: 0.74867
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.32522

Cumulative Model Updates: 46,552
Cumulative Timesteps: 776,497,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 776497176...
Checkpoint 776497176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,148.99888
Policy Entropy: 1.07519
Value Function Loss: 4.42809

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.09231

Collected Steps per Second: 11,030.72627
Overall Steps per Second: 9,560.61047

Timestep Collection Time: 4.53424
Timestep Consumption Time: 0.69722
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.23147

Cumulative Model Updates: 46,555
Cumulative Timesteps: 776,547,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,692.19602
Policy Entropy: 1.08371
Value Function Loss: 4.17867

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.09258

Collected Steps per Second: 10,896.05605
Overall Steps per Second: 9,271.38501

Timestep Collection Time: 4.58973
Timestep Consumption Time: 0.80428
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 5.39402

Cumulative Model Updates: 46,558
Cumulative Timesteps: 776,597,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 776597202...
Checkpoint 776597202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,156.21242
Policy Entropy: 1.06658
Value Function Loss: 3.96708

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.08548

Collected Steps per Second: 10,834.49247
Overall Steps per Second: 9,195.98693

Timestep Collection Time: 4.61637
Timestep Consumption Time: 0.82253
PPO Batch Consumption Time: 0.04325
Total Iteration Time: 5.43889

Cumulative Model Updates: 46,561
Cumulative Timesteps: 776,647,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,334.39435
Policy Entropy: 1.07114
Value Function Loss: 3.88828

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.07539

Collected Steps per Second: 11,309.33858
Overall Steps per Second: 9,631.84091

Timestep Collection Time: 4.42254
Timestep Consumption Time: 0.77024
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.19278

Cumulative Model Updates: 46,564
Cumulative Timesteps: 776,697,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 776697234...
Checkpoint 776697234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,764.46272
Policy Entropy: 1.08479
Value Function Loss: 4.27323

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.10367

Collected Steps per Second: 11,059.94648
Overall Steps per Second: 9,491.07674

Timestep Collection Time: 4.52172
Timestep Consumption Time: 0.74744
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 5.26916

Cumulative Model Updates: 46,567
Cumulative Timesteps: 776,747,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,387.13139
Policy Entropy: 1.07360
Value Function Loss: 4.20728

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.08789

Collected Steps per Second: 10,710.01717
Overall Steps per Second: 9,373.78522

Timestep Collection Time: 4.66946
Timestep Consumption Time: 0.66563
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 5.33509

Cumulative Model Updates: 46,570
Cumulative Timesteps: 776,797,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 776797254...
Checkpoint 776797254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,366.74787
Policy Entropy: 1.06306
Value Function Loss: 4.05689

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.18180
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.08808

Collected Steps per Second: 11,009.54063
Overall Steps per Second: 9,412.06720

Timestep Collection Time: 4.54315
Timestep Consumption Time: 0.77109
PPO Batch Consumption Time: 0.04079
Total Iteration Time: 5.31424

Cumulative Model Updates: 46,573
Cumulative Timesteps: 776,847,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,237.60863
Policy Entropy: 1.07256
Value Function Loss: 3.71813

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.08026

Collected Steps per Second: 10,888.11749
Overall Steps per Second: 9,407.94051

Timestep Collection Time: 4.59290
Timestep Consumption Time: 0.72261
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.31551

Cumulative Model Updates: 46,576
Cumulative Timesteps: 776,897,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 776897280...
Checkpoint 776897280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,659.96003
Policy Entropy: 1.07382
Value Function Loss: 3.76209

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.07077

Collected Steps per Second: 11,192.53239
Overall Steps per Second: 9,546.56161

Timestep Collection Time: 4.46852
Timestep Consumption Time: 0.77044
PPO Batch Consumption Time: 0.03847
Total Iteration Time: 5.23895

Cumulative Model Updates: 46,579
Cumulative Timesteps: 776,947,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,721.57528
Policy Entropy: 1.06234
Value Function Loss: 3.86534

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.06662

Collected Steps per Second: 10,861.45944
Overall Steps per Second: 9,348.59438

Timestep Collection Time: 4.60380
Timestep Consumption Time: 0.74502
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 5.34883

Cumulative Model Updates: 46,582
Cumulative Timesteps: 776,997,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 776997298...
Checkpoint 776997298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,162.60955
Policy Entropy: 1.05168
Value Function Loss: 3.94575

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.16941
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.07390

Collected Steps per Second: 10,463.00633
Overall Steps per Second: 9,153.56865

Timestep Collection Time: 4.78084
Timestep Consumption Time: 0.68391
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.46475

Cumulative Model Updates: 46,585
Cumulative Timesteps: 777,047,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,273.96187
Policy Entropy: 1.06808
Value Function Loss: 3.85484

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.08027

Collected Steps per Second: 10,979.38594
Overall Steps per Second: 9,391.76408

Timestep Collection Time: 4.55690
Timestep Consumption Time: 0.77032
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.32722

Cumulative Model Updates: 46,588
Cumulative Timesteps: 777,097,352

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 777097352...
Checkpoint 777097352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,782.03394
Policy Entropy: 1.08220
Value Function Loss: 3.82621

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.07292

Collected Steps per Second: 10,741.22855
Overall Steps per Second: 9,256.54292

Timestep Collection Time: 4.65515
Timestep Consumption Time: 0.74665
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.40180

Cumulative Model Updates: 46,591
Cumulative Timesteps: 777,147,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,188.23342
Policy Entropy: 1.06020
Value Function Loss: 4.06794

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.15940
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.07392

Collected Steps per Second: 11,203.83190
Overall Steps per Second: 9,616.29285

Timestep Collection Time: 4.46526
Timestep Consumption Time: 0.73716
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.20242

Cumulative Model Updates: 46,594
Cumulative Timesteps: 777,197,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 777197382...
Checkpoint 777197382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,123.65511
Policy Entropy: 1.07924
Value Function Loss: 4.18808

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.16187
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.08230

Collected Steps per Second: 10,689.74943
Overall Steps per Second: 9,154.06693

Timestep Collection Time: 4.67775
Timestep Consumption Time: 0.78474
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.46249

Cumulative Model Updates: 46,597
Cumulative Timesteps: 777,247,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,664.81437
Policy Entropy: 1.07150
Value Function Loss: 4.30893

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.16931
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.09339

Collected Steps per Second: 10,740.03765
Overall Steps per Second: 9,219.66975

Timestep Collection Time: 4.65585
Timestep Consumption Time: 0.76777
PPO Batch Consumption Time: 0.04447
Total Iteration Time: 5.42362

Cumulative Model Updates: 46,600
Cumulative Timesteps: 777,297,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 777297390...
Checkpoint 777297390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,549.57233
Policy Entropy: 1.06583
Value Function Loss: 4.01417

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.15877
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.09201

Collected Steps per Second: 10,853.77424
Overall Steps per Second: 9,290.28202

Timestep Collection Time: 4.60706
Timestep Consumption Time: 0.77534
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 5.38240

Cumulative Model Updates: 46,603
Cumulative Timesteps: 777,347,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,777.48785
Policy Entropy: 1.05655
Value Function Loss: 4.11523

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.17459
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.08604

Collected Steps per Second: 11,771.00439
Overall Steps per Second: 10,044.33494

Timestep Collection Time: 4.24993
Timestep Consumption Time: 0.73058
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.98052

Cumulative Model Updates: 46,606
Cumulative Timesteps: 777,397,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 777397420...
Checkpoint 777397420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,582.80255
Policy Entropy: 1.06721
Value Function Loss: 4.00478

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.08223

Collected Steps per Second: 12,129.80903
Overall Steps per Second: 10,237.14183

Timestep Collection Time: 4.12438
Timestep Consumption Time: 0.76253
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 4.88691

Cumulative Model Updates: 46,609
Cumulative Timesteps: 777,447,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,157.34292
Policy Entropy: 1.07646
Value Function Loss: 4.25926

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.07714

Collected Steps per Second: 11,892.09069
Overall Steps per Second: 10,078.29093

Timestep Collection Time: 4.20582
Timestep Consumption Time: 0.75693
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.96275

Cumulative Model Updates: 46,612
Cumulative Timesteps: 777,497,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 777497464...
Checkpoint 777497464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,944.36714
Policy Entropy: 1.05176
Value Function Loss: 4.12713

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.08337

Collected Steps per Second: 11,847.43493
Overall Steps per Second: 10,131.39874

Timestep Collection Time: 4.22269
Timestep Consumption Time: 0.71523
PPO Batch Consumption Time: 0.04112
Total Iteration Time: 4.93792

Cumulative Model Updates: 46,615
Cumulative Timesteps: 777,547,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,972.24698
Policy Entropy: 1.06884
Value Function Loss: 4.08352

Mean KL Divergence: 0.02511
SB3 Clip Fraction: 0.16626
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 11,610.53399
Overall Steps per Second: 9,832.06714

Timestep Collection Time: 4.30661
Timestep Consumption Time: 0.77900
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.08560

Cumulative Model Updates: 46,618
Cumulative Timesteps: 777,597,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 777597494...
Checkpoint 777597494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,373.06949
Policy Entropy: 1.06039
Value Function Loss: 4.11208

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.16920
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.08171

Collected Steps per Second: 10,678.16262
Overall Steps per Second: 9,314.19785

Timestep Collection Time: 4.68320
Timestep Consumption Time: 0.68581
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.36901

Cumulative Model Updates: 46,621
Cumulative Timesteps: 777,647,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,287.14057
Policy Entropy: 1.05781
Value Function Loss: 3.99393

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.08041

Collected Steps per Second: 10,885.41461
Overall Steps per Second: 9,278.88105

Timestep Collection Time: 4.59385
Timestep Consumption Time: 0.79537
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.38923

Cumulative Model Updates: 46,624
Cumulative Timesteps: 777,697,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 777697508...
Checkpoint 777697508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,061.95390
Policy Entropy: 1.05034
Value Function Loss: 3.98492

Mean KL Divergence: 0.02985
SB3 Clip Fraction: 0.18767
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.09726

Collected Steps per Second: 11,099.81253
Overall Steps per Second: 9,655.94242

Timestep Collection Time: 4.50548
Timestep Consumption Time: 0.67371
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.17919

Cumulative Model Updates: 46,627
Cumulative Timesteps: 777,747,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,958.01991
Policy Entropy: 1.06204
Value Function Loss: 3.72308

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.09809

Collected Steps per Second: 11,078.32262
Overall Steps per Second: 9,394.56315

Timestep Collection Time: 4.51585
Timestep Consumption Time: 0.80936
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.32521

Cumulative Model Updates: 46,630
Cumulative Timesteps: 777,797,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 777797546...
Checkpoint 777797546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,856.02758
Policy Entropy: 1.06818
Value Function Loss: 3.94838

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.09111

Collected Steps per Second: 11,070.12050
Overall Steps per Second: 9,466.14339

Timestep Collection Time: 4.51757
Timestep Consumption Time: 0.76547
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.28304

Cumulative Model Updates: 46,633
Cumulative Timesteps: 777,847,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633,540.95291
Policy Entropy: 1.04997
Value Function Loss: 4.11275

Mean KL Divergence: 0.02603
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.09623

Collected Steps per Second: 10,638.66479
Overall Steps per Second: 9,209.68133

Timestep Collection Time: 4.69984
Timestep Consumption Time: 0.72923
PPO Batch Consumption Time: 0.03777
Total Iteration Time: 5.42907

Cumulative Model Updates: 46,636
Cumulative Timesteps: 777,897,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 777897556...
Checkpoint 777897556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,295.71172
Policy Entropy: 1.05149
Value Function Loss: 4.24704

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.10371

Collected Steps per Second: 10,718.39828
Overall Steps per Second: 9,209.51554

Timestep Collection Time: 4.66506
Timestep Consumption Time: 0.76432
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.42938

Cumulative Model Updates: 46,639
Cumulative Timesteps: 777,947,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,956.40185
Policy Entropy: 1.05196
Value Function Loss: 4.07736

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.15769
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.10038

Collected Steps per Second: 10,888.03983
Overall Steps per Second: 9,308.12756

Timestep Collection Time: 4.59238
Timestep Consumption Time: 0.77949
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.37186

Cumulative Model Updates: 46,642
Cumulative Timesteps: 777,997,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 777997560...
Checkpoint 777997560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779,915.53780
Policy Entropy: 1.05984
Value Function Loss: 3.85146

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.09600

Collected Steps per Second: 11,148.39376
Overall Steps per Second: 9,570.58747

Timestep Collection Time: 4.48692
Timestep Consumption Time: 0.73971
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.22664

Cumulative Model Updates: 46,645
Cumulative Timesteps: 778,047,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,667.90802
Policy Entropy: 1.04488
Value Function Loss: 3.89454

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.08656

Collected Steps per Second: 11,015.09965
Overall Steps per Second: 9,508.38437

Timestep Collection Time: 4.54140
Timestep Consumption Time: 0.71964
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.26104

Cumulative Model Updates: 46,648
Cumulative Timesteps: 778,097,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 778097606...
Checkpoint 778097606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,160.24182
Policy Entropy: 1.02633
Value Function Loss: 3.93639

Mean KL Divergence: 0.03037
SB3 Clip Fraction: 0.18964
Policy Update Magnitude: 0.06316
Value Function Update Magnitude: 0.08473

Collected Steps per Second: 10,715.39463
Overall Steps per Second: 9,350.01033

Timestep Collection Time: 4.66768
Timestep Consumption Time: 0.68162
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.34930

Cumulative Model Updates: 46,651
Cumulative Timesteps: 778,147,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,177.04897
Policy Entropy: 1.04682
Value Function Loss: 4.03082

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.09553

Collected Steps per Second: 10,488.83720
Overall Steps per Second: 9,012.27866

Timestep Collection Time: 4.76735
Timestep Consumption Time: 0.78108
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.54843

Cumulative Model Updates: 46,654
Cumulative Timesteps: 778,197,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 778197626...
Checkpoint 778197626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,336.90944
Policy Entropy: 1.05887
Value Function Loss: 4.06452

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14489
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.08869

Collected Steps per Second: 10,607.33044
Overall Steps per Second: 9,177.76033

Timestep Collection Time: 4.71429
Timestep Consumption Time: 0.73432
PPO Batch Consumption Time: 0.03814
Total Iteration Time: 5.44861

Cumulative Model Updates: 46,657
Cumulative Timesteps: 778,247,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,283.89158
Policy Entropy: 1.04582
Value Function Loss: 4.11046

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.07821

Collected Steps per Second: 11,098.07639
Overall Steps per Second: 9,527.71438

Timestep Collection Time: 4.50745
Timestep Consumption Time: 0.74292
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.25037

Cumulative Model Updates: 46,660
Cumulative Timesteps: 778,297,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 778297656...
Checkpoint 778297656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,160.55241
Policy Entropy: 1.03139
Value Function Loss: 4.31958

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.17854
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.08588

Collected Steps per Second: 10,684.15102
Overall Steps per Second: 9,095.18331

Timestep Collection Time: 4.68039
Timestep Consumption Time: 0.81768
PPO Batch Consumption Time: 0.04014
Total Iteration Time: 5.49807

Cumulative Model Updates: 46,663
Cumulative Timesteps: 778,347,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,941.53770
Policy Entropy: 1.04193
Value Function Loss: 4.28397

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.09672

Collected Steps per Second: 10,901.24933
Overall Steps per Second: 9,480.64136

Timestep Collection Time: 4.58957
Timestep Consumption Time: 0.68771
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.27728

Cumulative Model Updates: 46,666
Cumulative Timesteps: 778,397,694

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 778397694...
Checkpoint 778397694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,291.47639
Policy Entropy: 1.05623
Value Function Loss: 4.11521

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.17190
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.09699

Collected Steps per Second: 10,835.93454
Overall Steps per Second: 9,163.97677

Timestep Collection Time: 4.61538
Timestep Consumption Time: 0.84207
PPO Batch Consumption Time: 0.04310
Total Iteration Time: 5.45746

Cumulative Model Updates: 46,669
Cumulative Timesteps: 778,447,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,092.83939
Policy Entropy: 1.01238
Value Function Loss: 4.10486

Mean KL Divergence: 0.07314
SB3 Clip Fraction: 0.22426
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.07936

Collected Steps per Second: 10,863.05145
Overall Steps per Second: 9,495.08873

Timestep Collection Time: 4.60313
Timestep Consumption Time: 0.66317
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.26630

Cumulative Model Updates: 46,672
Cumulative Timesteps: 778,497,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 778497710...
Checkpoint 778497710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,667.29405
Policy Entropy: 1.04038
Value Function Loss: 4.17462

Mean KL Divergence: 0.03817
SB3 Clip Fraction: 0.18797
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.07691

Collected Steps per Second: 11,487.01148
Overall Steps per Second: 9,655.53147

Timestep Collection Time: 4.35396
Timestep Consumption Time: 0.82587
PPO Batch Consumption Time: 0.04850
Total Iteration Time: 5.17983

Cumulative Model Updates: 46,675
Cumulative Timesteps: 778,547,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,523.51738
Policy Entropy: 1.01821
Value Function Loss: 4.40047

Mean KL Divergence: 0.02892
SB3 Clip Fraction: 0.16876
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.09374

Collected Steps per Second: 10,315.81516
Overall Steps per Second: 8,687.20672

Timestep Collection Time: 4.84867
Timestep Consumption Time: 0.90899
PPO Batch Consumption Time: 0.04718
Total Iteration Time: 5.75766

Cumulative Model Updates: 46,678
Cumulative Timesteps: 778,597,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 778597742...
Checkpoint 778597742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,099.06950
Policy Entropy: 1.04170
Value Function Loss: 4.35773

Mean KL Divergence: 0.02792
SB3 Clip Fraction: 0.16628
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.08695

Collected Steps per Second: 11,199.49357
Overall Steps per Second: 9,745.24612

Timestep Collection Time: 4.46609
Timestep Consumption Time: 0.66646
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.13255

Cumulative Model Updates: 46,681
Cumulative Timesteps: 778,647,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,599.03928
Policy Entropy: 1.05351
Value Function Loss: 4.20546

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.16541
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.07866

Collected Steps per Second: 11,406.48631
Overall Steps per Second: 9,634.96182

Timestep Collection Time: 4.38470
Timestep Consumption Time: 0.80619
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 5.19089

Cumulative Model Updates: 46,684
Cumulative Timesteps: 778,697,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 778697774...
Checkpoint 778697774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,406.72504
Policy Entropy: 1.03667
Value Function Loss: 4.23832

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.07812

Collected Steps per Second: 10,712.50682
Overall Steps per Second: 9,246.90469

Timestep Collection Time: 4.66763
Timestep Consumption Time: 0.73980
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 5.40743

Cumulative Model Updates: 46,687
Cumulative Timesteps: 778,747,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,382.94803
Policy Entropy: 1.04509
Value Function Loss: 4.20488

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.08023

Collected Steps per Second: 11,233.82072
Overall Steps per Second: 9,609.24566

Timestep Collection Time: 4.45209
Timestep Consumption Time: 0.75269
PPO Batch Consumption Time: 0.03812
Total Iteration Time: 5.20478

Cumulative Model Updates: 46,690
Cumulative Timesteps: 778,797,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 778797790...
Checkpoint 778797790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,055.95524
Policy Entropy: 1.04800
Value Function Loss: 4.35330

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.07017
Value Function Update Magnitude: 0.07753

Collected Steps per Second: 11,031.23106
Overall Steps per Second: 9,393.33709

Timestep Collection Time: 4.53331
Timestep Consumption Time: 0.79046
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.32377

Cumulative Model Updates: 46,693
Cumulative Timesteps: 778,847,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,789.30565
Policy Entropy: 1.05383
Value Function Loss: 4.20489

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.07915
Value Function Update Magnitude: 0.07515

Collected Steps per Second: 11,074.64000
Overall Steps per Second: 9,623.61472

Timestep Collection Time: 4.51590
Timestep Consumption Time: 0.68090
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.19680

Cumulative Model Updates: 46,696
Cumulative Timesteps: 778,897,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 778897810...
Checkpoint 778897810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,125.35445
Policy Entropy: 1.05583
Value Function Loss: 4.01833

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.07247
Value Function Update Magnitude: 0.08525

Collected Steps per Second: 11,013.78752
Overall Steps per Second: 9,405.93151

Timestep Collection Time: 4.54085
Timestep Consumption Time: 0.77622
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 5.31707

Cumulative Model Updates: 46,699
Cumulative Timesteps: 778,947,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,776.69897
Policy Entropy: 1.05630
Value Function Loss: 3.62086

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.06817
Value Function Update Magnitude: 0.08951

Collected Steps per Second: 11,194.84946
Overall Steps per Second: 9,627.11517

Timestep Collection Time: 4.46884
Timestep Consumption Time: 0.72773
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 5.19657

Cumulative Model Updates: 46,702
Cumulative Timesteps: 778,997,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 778997850...
Checkpoint 778997850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,995.25379
Policy Entropy: 1.06084
Value Function Loss: 3.46273

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.06740
Value Function Update Magnitude: 0.09806

Collected Steps per Second: 10,161.33291
Overall Steps per Second: 8,930.52642

Timestep Collection Time: 4.92061
Timestep Consumption Time: 0.67816
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 5.59877

Cumulative Model Updates: 46,705
Cumulative Timesteps: 779,047,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,036.89846
Policy Entropy: 1.05516
Value Function Loss: 3.52658

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.06944
Value Function Update Magnitude: 0.08861

Collected Steps per Second: 10,815.69739
Overall Steps per Second: 9,332.89850

Timestep Collection Time: 4.62513
Timestep Consumption Time: 0.73483
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.35996

Cumulative Model Updates: 46,708
Cumulative Timesteps: 779,097,874

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 779097874...
Checkpoint 779097874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,127.88823
Policy Entropy: 1.07524
Value Function Loss: 3.80598

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.14699
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.08523

Collected Steps per Second: 11,016.51947
Overall Steps per Second: 9,506.76105

Timestep Collection Time: 4.53882
Timestep Consumption Time: 0.72081
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.25963

Cumulative Model Updates: 46,711
Cumulative Timesteps: 779,147,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,032.68173
Policy Entropy: 1.06781
Value Function Loss: 3.99249

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 11,155.18707
Overall Steps per Second: 9,574.62986

Timestep Collection Time: 4.48330
Timestep Consumption Time: 0.74009
PPO Batch Consumption Time: 0.03784
Total Iteration Time: 5.22339

Cumulative Model Updates: 46,714
Cumulative Timesteps: 779,197,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 779197888...
Checkpoint 779197888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,242.22319
Policy Entropy: 1.07219
Value Function Loss: 4.04387

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.06337
Value Function Update Magnitude: 0.07186

Collected Steps per Second: 11,042.97122
Overall Steps per Second: 9,475.78492

Timestep Collection Time: 4.53048
Timestep Consumption Time: 0.74929
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.27977

Cumulative Model Updates: 46,717
Cumulative Timesteps: 779,247,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,209.68390
Policy Entropy: 1.06714
Value Function Loss: 4.03653

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.06620
Value Function Update Magnitude: 0.06711

Collected Steps per Second: 10,501.50987
Overall Steps per Second: 9,089.89523

Timestep Collection Time: 4.76312
Timestep Consumption Time: 0.73969
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.50281

Cumulative Model Updates: 46,720
Cumulative Timesteps: 779,297,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 779297938...
Checkpoint 779297938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,379.62998
Policy Entropy: 1.06458
Value Function Loss: 4.21532

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.06555
Value Function Update Magnitude: 0.06919

Collected Steps per Second: 10,863.97458
Overall Steps per Second: 9,315.93049

Timestep Collection Time: 4.60494
Timestep Consumption Time: 0.76521
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 5.37016

Cumulative Model Updates: 46,723
Cumulative Timesteps: 779,347,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,862.27302
Policy Entropy: 1.06614
Value Function Loss: 4.19518

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.07602

Collected Steps per Second: 10,758.49544
Overall Steps per Second: 9,258.00887

Timestep Collection Time: 4.64861
Timestep Consumption Time: 0.75342
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 5.40203

Cumulative Model Updates: 46,726
Cumulative Timesteps: 779,397,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 779397978...
Checkpoint 779397978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618,984.91449
Policy Entropy: 1.07914
Value Function Loss: 4.46025

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.09331

Collected Steps per Second: 11,306.46652
Overall Steps per Second: 9,627.32672

Timestep Collection Time: 4.42384
Timestep Consumption Time: 0.77158
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 5.19542

Cumulative Model Updates: 46,729
Cumulative Timesteps: 779,447,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,270.92199
Policy Entropy: 1.07765
Value Function Loss: 4.03421

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.06301
Value Function Update Magnitude: 0.08428

Collected Steps per Second: 10,738.57960
Overall Steps per Second: 9,217.71624

Timestep Collection Time: 4.65667
Timestep Consumption Time: 0.76832
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.42499

Cumulative Model Updates: 46,732
Cumulative Timesteps: 779,498,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 779498002...
Checkpoint 779498002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,293.19677
Policy Entropy: 1.07829
Value Function Loss: 3.96692

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.09289

Collected Steps per Second: 11,008.33545
Overall Steps per Second: 9,466.22352

Timestep Collection Time: 4.54437
Timestep Consumption Time: 0.74031
PPO Batch Consumption Time: 0.04145
Total Iteration Time: 5.28468

Cumulative Model Updates: 46,735
Cumulative Timesteps: 779,548,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,114.19472
Policy Entropy: 1.06252
Value Function Loss: 3.78862

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.09783

Collected Steps per Second: 10,567.17620
Overall Steps per Second: 9,048.00926

Timestep Collection Time: 4.73182
Timestep Consumption Time: 0.79448
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.52630

Cumulative Model Updates: 46,738
Cumulative Timesteps: 779,598,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 779598030...
Checkpoint 779598030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,237.23624
Policy Entropy: 1.07601
Value Function Loss: 3.90181

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.10127

Collected Steps per Second: 11,826.31586
Overall Steps per Second: 10,027.08086

Timestep Collection Time: 4.22972
Timestep Consumption Time: 0.75897
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.98869

Cumulative Model Updates: 46,741
Cumulative Timesteps: 779,648,052

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,205.97106
Policy Entropy: 1.07693
Value Function Loss: 3.86486

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.09199

Collected Steps per Second: 12,144.32744
Overall Steps per Second: 10,208.01750

Timestep Collection Time: 4.11764
Timestep Consumption Time: 0.78106
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.89870

Cumulative Model Updates: 46,744
Cumulative Timesteps: 779,698,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 779698058...
Checkpoint 779698058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,832.74456
Policy Entropy: 1.08754
Value Function Loss: 3.93368

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.07155
Value Function Update Magnitude: 0.08642

Collected Steps per Second: 11,601.03516
Overall Steps per Second: 9,887.14447

Timestep Collection Time: 4.31151
Timestep Consumption Time: 0.74738
PPO Batch Consumption Time: 0.03323
Total Iteration Time: 5.05889

Cumulative Model Updates: 46,747
Cumulative Timesteps: 779,748,076

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,378.29102
Policy Entropy: 1.07710
Value Function Loss: 4.19895

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.07640
Value Function Update Magnitude: 0.09748

Collected Steps per Second: 11,829.92143
Overall Steps per Second: 10,164.86867

Timestep Collection Time: 4.22775
Timestep Consumption Time: 0.69253
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.92028

Cumulative Model Updates: 46,750
Cumulative Timesteps: 779,798,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 779798090...
Checkpoint 779798090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,959.30503
Policy Entropy: 1.08310
Value Function Loss: 4.31894

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.06689
Value Function Update Magnitude: 0.09738

Collected Steps per Second: 11,765.35727
Overall Steps per Second: 9,827.26189

Timestep Collection Time: 4.24976
Timestep Consumption Time: 0.83812
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.08789

Cumulative Model Updates: 46,753
Cumulative Timesteps: 779,848,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,482.77636
Policy Entropy: 1.08376
Value Function Loss: 4.23459

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.09326

Collected Steps per Second: 10,904.59783
Overall Steps per Second: 9,280.37377

Timestep Collection Time: 4.58669
Timestep Consumption Time: 0.80275
PPO Batch Consumption Time: 0.03777
Total Iteration Time: 5.38944

Cumulative Model Updates: 46,756
Cumulative Timesteps: 779,898,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 779898106...
Checkpoint 779898106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,927.50782
Policy Entropy: 1.09462
Value Function Loss: 4.23940

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.06653
Value Function Update Magnitude: 0.08406

Collected Steps per Second: 11,120.74087
Overall Steps per Second: 9,504.92400

Timestep Collection Time: 4.49682
Timestep Consumption Time: 0.76445
PPO Batch Consumption Time: 0.03784
Total Iteration Time: 5.26127

Cumulative Model Updates: 46,759
Cumulative Timesteps: 779,948,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,912.66628
Policy Entropy: 1.09491
Value Function Loss: 3.99968

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.07699
Value Function Update Magnitude: 0.07357

Collected Steps per Second: 11,101.36627
Overall Steps per Second: 9,268.87559

Timestep Collection Time: 4.50449
Timestep Consumption Time: 0.89055
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 5.39504

Cumulative Model Updates: 46,762
Cumulative Timesteps: 779,998,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 779998120...
Checkpoint 779998120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,665.39365
Policy Entropy: 1.09069
Value Function Loss: 4.20551

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.11774
Policy Update Magnitude: 0.07673
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 10,877.68677
Overall Steps per Second: 9,451.50620

Timestep Collection Time: 4.59914
Timestep Consumption Time: 0.69398
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 5.29312

Cumulative Model Updates: 46,765
Cumulative Timesteps: 780,048,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,816.22132
Policy Entropy: 1.08874
Value Function Loss: 4.23476

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.07082
Value Function Update Magnitude: 0.08148

Collected Steps per Second: 11,013.55115
Overall Steps per Second: 9,448.90907

Timestep Collection Time: 4.54277
Timestep Consumption Time: 0.75224
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.29500

Cumulative Model Updates: 46,768
Cumulative Timesteps: 780,098,180

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 780098180...
Checkpoint 780098180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,874.93498
Policy Entropy: 1.09709
Value Function Loss: 4.32250

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.07788

Collected Steps per Second: 11,153.49476
Overall Steps per Second: 9,350.66017

Timestep Collection Time: 4.48344
Timestep Consumption Time: 0.86442
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 5.34786

Cumulative Model Updates: 46,771
Cumulative Timesteps: 780,148,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,666.50348
Policy Entropy: 1.09570
Value Function Loss: 4.00793

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.08165

Collected Steps per Second: 10,966.15471
Overall Steps per Second: 9,326.41459

Timestep Collection Time: 4.56185
Timestep Consumption Time: 0.80205
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 5.36390

Cumulative Model Updates: 46,774
Cumulative Timesteps: 780,198,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 780198212...
Checkpoint 780198212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,947.98333
Policy Entropy: 1.09733
Value Function Loss: 3.99913

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.07024
Value Function Update Magnitude: 0.08365

Collected Steps per Second: 10,985.12314
Overall Steps per Second: 9,398.35244

Timestep Collection Time: 4.55179
Timestep Consumption Time: 0.76850
PPO Batch Consumption Time: 0.03771
Total Iteration Time: 5.32029

Cumulative Model Updates: 46,777
Cumulative Timesteps: 780,248,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,890.72169
Policy Entropy: 1.09351
Value Function Loss: 4.10338

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.07683

Collected Steps per Second: 10,843.05830
Overall Steps per Second: 9,499.44844

Timestep Collection Time: 4.61180
Timestep Consumption Time: 0.65230
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.26410

Cumulative Model Updates: 46,780
Cumulative Timesteps: 780,298,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 780298220...
Checkpoint 780298220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,814.24925
Policy Entropy: 1.09630
Value Function Loss: 4.27415

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.06863
Value Function Update Magnitude: 0.07255

Collected Steps per Second: 11,014.45136
Overall Steps per Second: 9,452.36753

Timestep Collection Time: 4.54167
Timestep Consumption Time: 0.75055
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 5.29222

Cumulative Model Updates: 46,783
Cumulative Timesteps: 780,348,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,472.65219
Policy Entropy: 1.10070
Value Function Loss: 4.18257

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.06285

Collected Steps per Second: 11,080.90480
Overall Steps per Second: 9,659.44219

Timestep Collection Time: 4.51425
Timestep Consumption Time: 0.66431
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.17856

Cumulative Model Updates: 46,786
Cumulative Timesteps: 780,398,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 780398266...
Checkpoint 780398266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,016.11916
Policy Entropy: 1.10515
Value Function Loss: 4.11147

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.05497

Collected Steps per Second: 10,489.74792
Overall Steps per Second: 9,011.47130

Timestep Collection Time: 4.76694
Timestep Consumption Time: 0.78199
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.54893

Cumulative Model Updates: 46,789
Cumulative Timesteps: 780,448,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,168.31030
Policy Entropy: 1.11061
Value Function Loss: 4.05069

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.06171

Collected Steps per Second: 10,968.81341
Overall Steps per Second: 9,452.27140

Timestep Collection Time: 4.56093
Timestep Consumption Time: 0.73177
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.29270

Cumulative Model Updates: 46,792
Cumulative Timesteps: 780,498,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 780498298...
Checkpoint 780498298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,407.61390
Policy Entropy: 1.10442
Value Function Loss: 3.79935

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.07302
Value Function Update Magnitude: 0.06243

Collected Steps per Second: 10,971.11983
Overall Steps per Second: 9,418.83058

Timestep Collection Time: 4.55815
Timestep Consumption Time: 0.75121
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.30936

Cumulative Model Updates: 46,795
Cumulative Timesteps: 780,548,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,445.89269
Policy Entropy: 1.10591
Value Function Loss: 3.87507

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.06729
Value Function Update Magnitude: 0.06785

Collected Steps per Second: 10,721.00874
Overall Steps per Second: 9,221.87782

Timestep Collection Time: 4.66393
Timestep Consumption Time: 0.75818
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.42211

Cumulative Model Updates: 46,798
Cumulative Timesteps: 780,598,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 780598308...
Checkpoint 780598308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,763.96597
Policy Entropy: 1.11489
Value Function Loss: 4.04505

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.08008

Collected Steps per Second: 10,770.62335
Overall Steps per Second: 9,418.53117

Timestep Collection Time: 4.64504
Timestep Consumption Time: 0.66683
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.31187

Cumulative Model Updates: 46,801
Cumulative Timesteps: 780,648,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,362.73429
Policy Entropy: 1.12154
Value Function Loss: 4.22067

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.10043

Collected Steps per Second: 11,016.32928
Overall Steps per Second: 9,422.68958

Timestep Collection Time: 4.54017
Timestep Consumption Time: 0.76787
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.30804

Cumulative Model Updates: 46,804
Cumulative Timesteps: 780,698,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 780698354...
Checkpoint 780698354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,673.35930
Policy Entropy: 1.11378
Value Function Loss: 4.11854

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.09959

Collected Steps per Second: 10,915.34467
Overall Steps per Second: 9,431.10074

Timestep Collection Time: 4.58272
Timestep Consumption Time: 0.72122
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.30394

Cumulative Model Updates: 46,807
Cumulative Timesteps: 780,748,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,192.17546
Policy Entropy: 1.11246
Value Function Loss: 3.81984

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.08724

Collected Steps per Second: 11,537.05709
Overall Steps per Second: 9,898.18128

Timestep Collection Time: 4.33403
Timestep Consumption Time: 0.71760
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 5.05164

Cumulative Model Updates: 46,810
Cumulative Timesteps: 780,798,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 780798378...
Checkpoint 780798378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,791.86067
Policy Entropy: 1.12396
Value Function Loss: 3.83098

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.08816

Collected Steps per Second: 11,287.10276
Overall Steps per Second: 9,620.84218

Timestep Collection Time: 4.43108
Timestep Consumption Time: 0.76743
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 5.19851

Cumulative Model Updates: 46,813
Cumulative Timesteps: 780,848,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,551.73233
Policy Entropy: 1.12310
Value Function Loss: 4.02456

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.08264

Collected Steps per Second: 11,321.40524
Overall Steps per Second: 9,709.80887

Timestep Collection Time: 4.41677
Timestep Consumption Time: 0.73308
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.14984

Cumulative Model Updates: 46,816
Cumulative Timesteps: 780,898,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 780898396...
Checkpoint 780898396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,224.93682
Policy Entropy: 1.10450
Value Function Loss: 3.93114

Mean KL Divergence: 0.02548
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.06814
Value Function Update Magnitude: 0.07592

Collected Steps per Second: 11,561.77204
Overall Steps per Second: 9,823.77219

Timestep Collection Time: 4.32563
Timestep Consumption Time: 0.76528
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.09092

Cumulative Model Updates: 46,819
Cumulative Timesteps: 780,948,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469,357.31171
Policy Entropy: 1.12150
Value Function Loss: 3.73556

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.08480

Collected Steps per Second: 11,257.76819
Overall Steps per Second: 9,537.62483

Timestep Collection Time: 4.44315
Timestep Consumption Time: 0.80134
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.24449

Cumulative Model Updates: 46,822
Cumulative Timesteps: 780,998,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 780998428...
Checkpoint 780998428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,838.10565
Policy Entropy: 1.11450
Value Function Loss: 3.51179

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.08446

Collected Steps per Second: 11,046.31361
Overall Steps per Second: 9,632.27355

Timestep Collection Time: 4.52857
Timestep Consumption Time: 0.66480
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.19337

Cumulative Model Updates: 46,825
Cumulative Timesteps: 781,048,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,215.92083
Policy Entropy: 1.11291
Value Function Loss: 3.75612

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.08471

Collected Steps per Second: 11,294.92857
Overall Steps per Second: 9,610.42124

Timestep Collection Time: 4.42730
Timestep Consumption Time: 0.77601
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.20331

Cumulative Model Updates: 46,828
Cumulative Timesteps: 781,098,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 781098458...
Checkpoint 781098458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,616.12494
Policy Entropy: 1.09830
Value Function Loss: 3.92025

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.16526
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.08387

Collected Steps per Second: 10,959.03453
Overall Steps per Second: 9,413.22434

Timestep Collection Time: 4.56263
Timestep Consumption Time: 0.74926
PPO Batch Consumption Time: 0.03814
Total Iteration Time: 5.31189

Cumulative Model Updates: 46,831
Cumulative Timesteps: 781,148,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,527.79987
Policy Entropy: 1.10702
Value Function Loss: 3.95326

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.07601

Collected Steps per Second: 11,402.44250
Overall Steps per Second: 9,721.18457

Timestep Collection Time: 4.38503
Timestep Consumption Time: 0.75838
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.14341

Cumulative Model Updates: 46,834
Cumulative Timesteps: 781,198,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 781198460...
Checkpoint 781198460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407,385.73499
Policy Entropy: 1.10651
Value Function Loss: 3.91715

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.07796

Collected Steps per Second: 11,150.20631
Overall Steps per Second: 9,614.08904

Timestep Collection Time: 4.48458
Timestep Consumption Time: 0.71654
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.20112

Cumulative Model Updates: 46,837
Cumulative Timesteps: 781,248,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,593.33927
Policy Entropy: 1.10165
Value Function Loss: 3.94926

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.06796
Value Function Update Magnitude: 0.08129

Collected Steps per Second: 10,471.01435
Overall Steps per Second: 9,207.17728

Timestep Collection Time: 4.77661
Timestep Consumption Time: 0.65567
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 5.43228

Cumulative Model Updates: 46,840
Cumulative Timesteps: 781,298,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 781298480...
Checkpoint 781298480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,886.16744
Policy Entropy: 1.09197
Value Function Loss: 4.01493

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.08132

Collected Steps per Second: 11,011.73613
Overall Steps per Second: 9,450.78595

Timestep Collection Time: 4.54079
Timestep Consumption Time: 0.74999
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.29078

Cumulative Model Updates: 46,843
Cumulative Timesteps: 781,348,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,641.15981
Policy Entropy: 1.09888
Value Function Loss: 4.06644

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.07933

Collected Steps per Second: 10,946.07926
Overall Steps per Second: 9,423.32919

Timestep Collection Time: 4.56785
Timestep Consumption Time: 0.73813
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.30598

Cumulative Model Updates: 46,846
Cumulative Timesteps: 781,398,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 781398482...
Checkpoint 781398482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,664.50994
Policy Entropy: 1.11166
Value Function Loss: 4.10872

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.07573

Collected Steps per Second: 10,703.00322
Overall Steps per Second: 9,254.19687

Timestep Collection Time: 4.67159
Timestep Consumption Time: 0.73137
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.40295

Cumulative Model Updates: 46,849
Cumulative Timesteps: 781,448,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,210.50778
Policy Entropy: 1.08038
Value Function Loss: 4.10142

Mean KL Divergence: 0.03904
SB3 Clip Fraction: 0.17725
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.08732

Collected Steps per Second: 10,762.12550
Overall Steps per Second: 9,288.24910

Timestep Collection Time: 4.64741
Timestep Consumption Time: 0.73746
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 5.38487

Cumulative Model Updates: 46,852
Cumulative Timesteps: 781,498,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 781498498...
Checkpoint 781498498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,227.16052
Policy Entropy: 1.09384
Value Function Loss: 4.24709

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.10177

Collected Steps per Second: 10,735.93939
Overall Steps per Second: 9,373.10759

Timestep Collection Time: 4.65744
Timestep Consumption Time: 0.67718
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 5.33462

Cumulative Model Updates: 46,855
Cumulative Timesteps: 781,548,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,098.53287
Policy Entropy: 1.08995
Value Function Loss: 4.01214

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.09064

Collected Steps per Second: 10,248.62980
Overall Steps per Second: 8,828.69664

Timestep Collection Time: 4.87929
Timestep Consumption Time: 0.78474
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 5.66403

Cumulative Model Updates: 46,858
Cumulative Timesteps: 781,598,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 781598506...
Checkpoint 781598506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,423.11560
Policy Entropy: 1.07655
Value Function Loss: 3.89971

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.11872
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.08552

Collected Steps per Second: 10,629.87719
Overall Steps per Second: 9,289.46048

Timestep Collection Time: 4.70485
Timestep Consumption Time: 0.67888
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.38374

Cumulative Model Updates: 46,861
Cumulative Timesteps: 781,648,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,974.00461
Policy Entropy: 1.07175
Value Function Loss: 3.60824

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.08334

Collected Steps per Second: 11,003.66881
Overall Steps per Second: 9,415.95652

Timestep Collection Time: 4.54485
Timestep Consumption Time: 0.76635
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.31120

Cumulative Model Updates: 46,864
Cumulative Timesteps: 781,698,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 781698528...
Checkpoint 781698528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,476.41345
Policy Entropy: 1.08834
Value Function Loss: 3.94402

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.07607

Collected Steps per Second: 10,616.37719
Overall Steps per Second: 9,161.61096

Timestep Collection Time: 4.71215
Timestep Consumption Time: 0.74824
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.46039

Cumulative Model Updates: 46,867
Cumulative Timesteps: 781,748,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,159.50054
Policy Entropy: 1.09461
Value Function Loss: 4.21476

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.08495

Collected Steps per Second: 11,100.26382
Overall Steps per Second: 9,505.10742

Timestep Collection Time: 4.50548
Timestep Consumption Time: 0.75611
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 5.26159

Cumulative Model Updates: 46,870
Cumulative Timesteps: 781,798,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 781798566...
Checkpoint 781798566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,202.24859
Policy Entropy: 1.08237
Value Function Loss: 4.24330

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.07128

Collected Steps per Second: 10,517.70424
Overall Steps per Second: 9,027.58443

Timestep Collection Time: 4.75408
Timestep Consumption Time: 0.78472
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.53880

Cumulative Model Updates: 46,873
Cumulative Timesteps: 781,848,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,912.19968
Policy Entropy: 1.06040
Value Function Loss: 4.10998

Mean KL Divergence: 0.02941
SB3 Clip Fraction: 0.17462
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.06587

Collected Steps per Second: 12,044.52863
Overall Steps per Second: 10,387.44803

Timestep Collection Time: 4.15159
Timestep Consumption Time: 0.66229
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 4.81389

Cumulative Model Updates: 46,876
Cumulative Timesteps: 781,898,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 781898572...
Checkpoint 781898572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,948.38674
Policy Entropy: 1.07812
Value Function Loss: 3.98239

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.06349

Collected Steps per Second: 11,737.29666
Overall Steps per Second: 9,859.04826

Timestep Collection Time: 4.26010
Timestep Consumption Time: 0.81159
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 5.07169

Cumulative Model Updates: 46,879
Cumulative Timesteps: 781,948,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,172.24770
Policy Entropy: 1.07665
Value Function Loss: 4.12349

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.07471
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 11,953.05039
Overall Steps per Second: 10,101.62917

Timestep Collection Time: 4.18504
Timestep Consumption Time: 0.76703
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.95207

Cumulative Model Updates: 46,882
Cumulative Timesteps: 781,998,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 781998598...
Checkpoint 781998598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,884.54453
Policy Entropy: 1.07238
Value Function Loss: 3.90382

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.07366
Value Function Update Magnitude: 0.07581

Collected Steps per Second: 12,130.36702
Overall Steps per Second: 10,284.10366

Timestep Collection Time: 4.12205
Timestep Consumption Time: 0.74002
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.86207

Cumulative Model Updates: 46,885
Cumulative Timesteps: 782,048,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,646.04529
Policy Entropy: 1.07413
Value Function Loss: 3.96419

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.06981
Value Function Update Magnitude: 0.07781

Collected Steps per Second: 12,067.92543
Overall Steps per Second: 10,138.94967

Timestep Collection Time: 4.14437
Timestep Consumption Time: 0.78848
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 4.93286

Cumulative Model Updates: 46,888
Cumulative Timesteps: 782,098,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 782098614...
Checkpoint 782098614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,919.13715
Policy Entropy: 1.07004
Value Function Loss: 4.09853

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.06754
Value Function Update Magnitude: 0.07332

Collected Steps per Second: 11,429.69079
Overall Steps per Second: 9,809.19223

Timestep Collection Time: 4.37597
Timestep Consumption Time: 0.72292
PPO Batch Consumption Time: 0.04375
Total Iteration Time: 5.09889

Cumulative Model Updates: 46,891
Cumulative Timesteps: 782,148,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,098.03941
Policy Entropy: 1.07836
Value Function Loss: 4.24560

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.06734
Value Function Update Magnitude: 0.07482

Collected Steps per Second: 11,020.58491
Overall Steps per Second: 9,414.07473

Timestep Collection Time: 4.53842
Timestep Consumption Time: 0.77448
PPO Batch Consumption Time: 0.03737
Total Iteration Time: 5.31290

Cumulative Model Updates: 46,894
Cumulative Timesteps: 782,198,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 782198646...
Checkpoint 782198646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,266.02518
Policy Entropy: 1.08546
Value Function Loss: 4.11538

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.06210
Value Function Update Magnitude: 0.07942

Collected Steps per Second: 11,113.17898
Overall Steps per Second: 9,665.25236

Timestep Collection Time: 4.50006
Timestep Consumption Time: 0.67414
PPO Batch Consumption Time: 0.03816
Total Iteration Time: 5.17421

Cumulative Model Updates: 46,897
Cumulative Timesteps: 782,248,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,547.96100
Policy Entropy: 1.09501
Value Function Loss: 3.86121

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.06174
Value Function Update Magnitude: 0.08913

Collected Steps per Second: 11,003.76903
Overall Steps per Second: 9,381.66740

Timestep Collection Time: 4.54608
Timestep Consumption Time: 0.78602
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.33210

Cumulative Model Updates: 46,900
Cumulative Timesteps: 782,298,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 782298680...
Checkpoint 782298680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,000.58912
Policy Entropy: 1.10153
Value Function Loss: 3.74094

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.08997

Collected Steps per Second: 10,937.82904
Overall Steps per Second: 9,401.11891

Timestep Collection Time: 4.57147
Timestep Consumption Time: 0.74725
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.31873

Cumulative Model Updates: 46,903
Cumulative Timesteps: 782,348,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,647.17198
Policy Entropy: 1.09234
Value Function Loss: 3.72412

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.07739

Collected Steps per Second: 11,379.00957
Overall Steps per Second: 9,675.45993

Timestep Collection Time: 4.39423
Timestep Consumption Time: 0.77369
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.16792

Cumulative Model Updates: 46,906
Cumulative Timesteps: 782,398,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 782398684...
Checkpoint 782398684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,011.63551
Policy Entropy: 1.07941
Value Function Loss: 4.01215

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.15511
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.08228

Collected Steps per Second: 10,423.23871
Overall Steps per Second: 8,959.48497

Timestep Collection Time: 4.79889
Timestep Consumption Time: 0.78402
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 5.58291

Cumulative Model Updates: 46,909
Cumulative Timesteps: 782,448,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566,673.74912
Policy Entropy: 1.09313
Value Function Loss: 4.16434

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.08646

Collected Steps per Second: 10,953.88514
Overall Steps per Second: 9,568.32003

Timestep Collection Time: 4.56678
Timestep Consumption Time: 0.66130
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.22809

Cumulative Model Updates: 46,912
Cumulative Timesteps: 782,498,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 782498728...
Checkpoint 782498728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,170.33090
Policy Entropy: 1.08903
Value Function Loss: 4.08738

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.09175

Collected Steps per Second: 10,539.06305
Overall Steps per Second: 9,080.49793

Timestep Collection Time: 4.74653
Timestep Consumption Time: 0.76242
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.50895

Cumulative Model Updates: 46,915
Cumulative Timesteps: 782,548,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,592.29596
Policy Entropy: 1.08870
Value Function Loss: 3.92426

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.09893

Collected Steps per Second: 10,951.81473
Overall Steps per Second: 9,550.35453

Timestep Collection Time: 4.56728
Timestep Consumption Time: 0.67022
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.23750

Cumulative Model Updates: 46,918
Cumulative Timesteps: 782,598,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 782598772...
Checkpoint 782598772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538,698.74015
Policy Entropy: 1.09833
Value Function Loss: 4.01939

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.10358

Collected Steps per Second: 10,998.97273
Overall Steps per Second: 9,407.95023

Timestep Collection Time: 4.54806
Timestep Consumption Time: 0.76914
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 5.31720

Cumulative Model Updates: 46,921
Cumulative Timesteps: 782,648,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,198.41291
Policy Entropy: 1.10416
Value Function Loss: 4.31987

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.06338
Value Function Update Magnitude: 0.10567

Collected Steps per Second: 11,021.04588
Overall Steps per Second: 9,471.78874

Timestep Collection Time: 4.53932
Timestep Consumption Time: 0.74248
PPO Batch Consumption Time: 0.04082
Total Iteration Time: 5.28179

Cumulative Model Updates: 46,924
Cumulative Timesteps: 782,698,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 782698824...
Checkpoint 782698824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,231.55031
Policy Entropy: 1.11070
Value Function Loss: 4.40173

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.10163

Collected Steps per Second: 10,526.90456
Overall Steps per Second: 8,967.39849

Timestep Collection Time: 4.75030
Timestep Consumption Time: 0.82612
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.57642

Cumulative Model Updates: 46,927
Cumulative Timesteps: 782,748,830

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,629.82116
Policy Entropy: 1.09558
Value Function Loss: 4.16733

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.08893

Collected Steps per Second: 10,904.10933
Overall Steps per Second: 9,435.53599

Timestep Collection Time: 4.58818
Timestep Consumption Time: 0.71412
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.30230

Cumulative Model Updates: 46,930
Cumulative Timesteps: 782,798,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 782798860...
Checkpoint 782798860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,799.43263
Policy Entropy: 1.08309
Value Function Loss: 4.11993

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14363
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.07781

Collected Steps per Second: 10,712.71755
Overall Steps per Second: 9,297.88826

Timestep Collection Time: 4.67015
Timestep Consumption Time: 0.71064
PPO Batch Consumption Time: 0.04468
Total Iteration Time: 5.38079

Cumulative Model Updates: 46,933
Cumulative Timesteps: 782,848,890

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,538.62862
Policy Entropy: 1.10693
Value Function Loss: 3.90464

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.06110

Collected Steps per Second: 10,800.57333
Overall Steps per Second: 9,289.17907

Timestep Collection Time: 4.63068
Timestep Consumption Time: 0.75343
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.38411

Cumulative Model Updates: 46,936
Cumulative Timesteps: 782,898,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 782898904...
Checkpoint 782898904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624,859.99202
Policy Entropy: 1.09972
Value Function Loss: 4.00716

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12123
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.06064

Collected Steps per Second: 10,795.95854
Overall Steps per Second: 9,404.64321

Timestep Collection Time: 4.63229
Timestep Consumption Time: 0.68530
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.31759

Cumulative Model Updates: 46,939
Cumulative Timesteps: 782,948,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,106.55300
Policy Entropy: 1.08923
Value Function Loss: 3.93303

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.05348

Collected Steps per Second: 10,560.42425
Overall Steps per Second: 9,114.31494

Timestep Collection Time: 4.73561
Timestep Consumption Time: 0.75137
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.48697

Cumulative Model Updates: 46,942
Cumulative Timesteps: 782,998,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 782998924...
Checkpoint 782998924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,183.52302
Policy Entropy: 1.07773
Value Function Loss: 3.78999

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.18514
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.04547

Collected Steps per Second: 11,328.20702
Overall Steps per Second: 9,655.47070

Timestep Collection Time: 4.41500
Timestep Consumption Time: 0.76486
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.17986

Cumulative Model Updates: 46,945
Cumulative Timesteps: 783,048,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,943.18200
Policy Entropy: 1.08729
Value Function Loss: 3.77540

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.05127

Collected Steps per Second: 11,072.28456
Overall Steps per Second: 9,666.35482

Timestep Collection Time: 4.51813
Timestep Consumption Time: 0.65714
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.17527

Cumulative Model Updates: 46,948
Cumulative Timesteps: 783,098,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 783098964...
Checkpoint 783098964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,659.63325
Policy Entropy: 1.09444
Value Function Loss: 3.99504

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.06023

Collected Steps per Second: 11,421.16267
Overall Steps per Second: 9,714.96011

Timestep Collection Time: 4.37906
Timestep Consumption Time: 0.76908
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.14814

Cumulative Model Updates: 46,951
Cumulative Timesteps: 783,148,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,286.37371
Policy Entropy: 1.08741
Value Function Loss: 4.22705

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.07147

Collected Steps per Second: 11,330.57777
Overall Steps per Second: 9,719.99401

Timestep Collection Time: 4.41372
Timestep Consumption Time: 0.73134
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.14506

Cumulative Model Updates: 46,954
Cumulative Timesteps: 783,198,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 783198988...
Checkpoint 783198988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,440.39070
Policy Entropy: 1.07955
Value Function Loss: 4.17951

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.06263
Value Function Update Magnitude: 0.08758

Collected Steps per Second: 11,567.49826
Overall Steps per Second: 9,883.22090

Timestep Collection Time: 4.32280
Timestep Consumption Time: 0.73668
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 5.05948

Cumulative Model Updates: 46,957
Cumulative Timesteps: 783,248,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,501.61029
Policy Entropy: 1.09314
Value Function Loss: 3.98610

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.08608

Collected Steps per Second: 10,673.42296
Overall Steps per Second: 8,974.88486

Timestep Collection Time: 4.68659
Timestep Consumption Time: 0.88696
PPO Batch Consumption Time: 0.03838
Total Iteration Time: 5.57355

Cumulative Model Updates: 46,960
Cumulative Timesteps: 783,299,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 783299014...
Checkpoint 783299014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,610.49577
Policy Entropy: 1.09618
Value Function Loss: 4.04539

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.11162
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.08033

Collected Steps per Second: 10,150.31730
Overall Steps per Second: 8,912.30826

Timestep Collection Time: 4.92655
Timestep Consumption Time: 0.68435
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.61089

Cumulative Model Updates: 46,963
Cumulative Timesteps: 783,349,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,083.09281
Policy Entropy: 1.08405
Value Function Loss: 4.01901

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.07737

Collected Steps per Second: 11,109.73880
Overall Steps per Second: 9,507.94331

Timestep Collection Time: 4.50254
Timestep Consumption Time: 0.75854
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.26107

Cumulative Model Updates: 46,966
Cumulative Timesteps: 783,399,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 783399042...
Checkpoint 783399042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,916.65362
Policy Entropy: 1.07540
Value Function Loss: 4.08834

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.14994
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.08636

Collected Steps per Second: 10,774.60820
Overall Steps per Second: 9,271.81337

Timestep Collection Time: 4.64165
Timestep Consumption Time: 0.75233
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.39398

Cumulative Model Updates: 46,969
Cumulative Timesteps: 783,449,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,927.12898
Policy Entropy: 1.08252
Value Function Loss: 4.21204

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.08968

Collected Steps per Second: 11,493.73563
Overall Steps per Second: 9,716.18539

Timestep Collection Time: 4.35107
Timestep Consumption Time: 0.79602
PPO Batch Consumption Time: 0.04015
Total Iteration Time: 5.14708

Cumulative Model Updates: 46,972
Cumulative Timesteps: 783,499,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 783499064...
Checkpoint 783499064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,212.32152
Policy Entropy: 1.08499
Value Function Loss: 4.19632

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.11129

Collected Steps per Second: 10,916.38046
Overall Steps per Second: 9,273.18260

Timestep Collection Time: 4.58101
Timestep Consumption Time: 0.81175
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 5.39275

Cumulative Model Updates: 46,975
Cumulative Timesteps: 783,549,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,870.15413
Policy Entropy: 1.07327
Value Function Loss: 4.01558

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.10863

Collected Steps per Second: 10,779.55035
Overall Steps per Second: 9,432.82993

Timestep Collection Time: 4.64045
Timestep Consumption Time: 0.66252
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.30297

Cumulative Model Updates: 46,978
Cumulative Timesteps: 783,599,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 783599094...
Checkpoint 783599094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,805.35384
Policy Entropy: 1.08596
Value Function Loss: 3.78016

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.10638

Collected Steps per Second: 10,992.24562
Overall Steps per Second: 9,414.05496

Timestep Collection Time: 4.55103
Timestep Consumption Time: 0.76294
PPO Batch Consumption Time: 0.03732
Total Iteration Time: 5.31397

Cumulative Model Updates: 46,981
Cumulative Timesteps: 783,649,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,491.74208
Policy Entropy: 1.09044
Value Function Loss: 4.01638

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 10,925.95180
Overall Steps per Second: 9,491.95815

Timestep Collection Time: 4.57681
Timestep Consumption Time: 0.69144
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 5.26825

Cumulative Model Updates: 46,984
Cumulative Timesteps: 783,699,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 783699126...
Checkpoint 783699126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,686.20446
Policy Entropy: 1.09112
Value Function Loss: 4.17052

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.10281

Collected Steps per Second: 10,898.24337
Overall Steps per Second: 9,374.43278

Timestep Collection Time: 4.58973
Timestep Consumption Time: 0.74606
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.33579

Cumulative Model Updates: 46,987
Cumulative Timesteps: 783,749,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585,720.80688
Policy Entropy: 1.07832
Value Function Loss: 4.26814

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.15330
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.09404

Collected Steps per Second: 10,993.31112
Overall Steps per Second: 9,504.40998

Timestep Collection Time: 4.54931
Timestep Consumption Time: 0.71267
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.26198

Cumulative Model Updates: 46,990
Cumulative Timesteps: 783,799,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 783799158...
Checkpoint 783799158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,581.95889
Policy Entropy: 1.09526
Value Function Loss: 4.33627

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 10,470.02126
Overall Steps per Second: 9,037.04070

Timestep Collection Time: 4.77649
Timestep Consumption Time: 0.75740
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.53389

Cumulative Model Updates: 46,993
Cumulative Timesteps: 783,849,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,360.12654
Policy Entropy: 1.09215
Value Function Loss: 4.28018

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 10,795.46102
Overall Steps per Second: 9,237.40426

Timestep Collection Time: 4.63343
Timestep Consumption Time: 0.78151
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.41494

Cumulative Model Updates: 46,996
Cumulative Timesteps: 783,899,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 783899188...
Checkpoint 783899188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631,898.43932
Policy Entropy: 1.07820
Value Function Loss: 4.19879

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.07672

Collected Steps per Second: 10,702.63295
Overall Steps per Second: 9,213.31622

Timestep Collection Time: 4.67250
Timestep Consumption Time: 0.75530
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.42780

Cumulative Model Updates: 46,999
Cumulative Timesteps: 783,949,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,675.09885
Policy Entropy: 1.06823
Value Function Loss: 4.18559

Mean KL Divergence: 0.02576
SB3 Clip Fraction: 0.17305
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.07912

Collected Steps per Second: 10,897.77056
Overall Steps per Second: 9,318.39254

Timestep Collection Time: 4.59048
Timestep Consumption Time: 0.77804
PPO Batch Consumption Time: 0.03359
Total Iteration Time: 5.36852

Cumulative Model Updates: 47,002
Cumulative Timesteps: 783,999,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 783999222...
Checkpoint 783999222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,913.27385
Policy Entropy: 1.07399
Value Function Loss: 4.26806

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.07790

Collected Steps per Second: 10,813.49438
Overall Steps per Second: 9,234.99256

Timestep Collection Time: 4.62515
Timestep Consumption Time: 0.79056
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.41571

Cumulative Model Updates: 47,005
Cumulative Timesteps: 784,049,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,458.44777
Policy Entropy: 1.09245
Value Function Loss: 4.51701

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.08106

Collected Steps per Second: 10,655.38478
Overall Steps per Second: 9,197.43464

Timestep Collection Time: 4.69396
Timestep Consumption Time: 0.74407
PPO Batch Consumption Time: 0.04607
Total Iteration Time: 5.43804

Cumulative Model Updates: 47,008
Cumulative Timesteps: 784,099,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 784099252...
Checkpoint 784099252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,810.60150
Policy Entropy: 1.04781
Value Function Loss: 4.43912

Mean KL Divergence: 0.08565
SB3 Clip Fraction: 0.25060
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.08495

Collected Steps per Second: 11,296.72607
Overall Steps per Second: 9,606.12653

Timestep Collection Time: 4.42642
Timestep Consumption Time: 0.77901
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 5.20543

Cumulative Model Updates: 47,011
Cumulative Timesteps: 784,149,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,527.58640
Policy Entropy: 1.07438
Value Function Loss: 4.09139

Mean KL Divergence: 0.03921
SB3 Clip Fraction: 0.18971
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.08204

Collected Steps per Second: 11,984.89630
Overall Steps per Second: 10,185.21698

Timestep Collection Time: 4.17275
Timestep Consumption Time: 0.73731
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 4.91006

Cumulative Model Updates: 47,014
Cumulative Timesteps: 784,199,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 784199266...
Checkpoint 784199266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,094.94863
Policy Entropy: 1.05544
Value Function Loss: 3.73132

Mean KL Divergence: 0.04823
SB3 Clip Fraction: 0.21275
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.07674

Collected Steps per Second: 11,624.95052
Overall Steps per Second: 9,982.25428

Timestep Collection Time: 4.30316
Timestep Consumption Time: 0.70813
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.01129

Cumulative Model Updates: 47,017
Cumulative Timesteps: 784,249,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,073.95789
Policy Entropy: 1.07126
Value Function Loss: 3.57726

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.16763
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.08448

Collected Steps per Second: 11,552.15825
Overall Steps per Second: 9,669.77352

Timestep Collection Time: 4.33097
Timestep Consumption Time: 0.84310
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.17406

Cumulative Model Updates: 47,020
Cumulative Timesteps: 784,299,322

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 784299322...
Checkpoint 784299322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,358.60532
Policy Entropy: 1.05097
Value Function Loss: 3.91771

Mean KL Divergence: 0.03276
SB3 Clip Fraction: 0.15746
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.08761

Collected Steps per Second: 11,756.87106
Overall Steps per Second: 9,942.59319

Timestep Collection Time: 4.25521
Timestep Consumption Time: 0.77647
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.03169

Cumulative Model Updates: 47,023
Cumulative Timesteps: 784,349,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,088.54698
Policy Entropy: 1.05327
Value Function Loss: 4.12060

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.16260
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.08092

Collected Steps per Second: 12,183.61363
Overall Steps per Second: 10,156.08081

Timestep Collection Time: 4.10551
Timestep Consumption Time: 0.81961
PPO Batch Consumption Time: 0.03804
Total Iteration Time: 4.92513

Cumulative Model Updates: 47,026
Cumulative Timesteps: 784,399,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 784399370...
Checkpoint 784399370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,605.09241
Policy Entropy: 1.06924
Value Function Loss: 4.20516

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.16026
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.09033

Collected Steps per Second: 10,599.74776
Overall Steps per Second: 9,105.48920

Timestep Collection Time: 4.71804
Timestep Consumption Time: 0.77425
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.49229

Cumulative Model Updates: 47,029
Cumulative Timesteps: 784,449,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,813.51851
Policy Entropy: 1.06992
Value Function Loss: 3.86817

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.16125
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.09769

Collected Steps per Second: 11,180.29022
Overall Steps per Second: 9,684.60067

Timestep Collection Time: 4.47502
Timestep Consumption Time: 0.69112
PPO Batch Consumption Time: 0.03942
Total Iteration Time: 5.16614

Cumulative Model Updates: 47,032
Cumulative Timesteps: 784,499,412

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 784499412...
Checkpoint 784499412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,916.32111
Policy Entropy: 1.05100
Value Function Loss: 3.97770

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.08719

Collected Steps per Second: 11,068.98913
Overall Steps per Second: 9,478.73819

Timestep Collection Time: 4.51857
Timestep Consumption Time: 0.75808
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.27665

Cumulative Model Updates: 47,035
Cumulative Timesteps: 784,549,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,246.21372
Policy Entropy: 1.03857
Value Function Loss: 4.04123

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.16037
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.08407

Collected Steps per Second: 11,039.67645
Overall Steps per Second: 9,463.94514

Timestep Collection Time: 4.52984
Timestep Consumption Time: 0.75421
PPO Batch Consumption Time: 0.03860
Total Iteration Time: 5.28405

Cumulative Model Updates: 47,038
Cumulative Timesteps: 784,599,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 784599436...
Checkpoint 784599436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,901.31615
Policy Entropy: 1.05218
Value Function Loss: 4.02170

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.08713

Collected Steps per Second: 11,071.11548
Overall Steps per Second: 9,406.87970

Timestep Collection Time: 4.51644
Timestep Consumption Time: 0.79903
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.31547

Cumulative Model Updates: 47,041
Cumulative Timesteps: 784,649,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,425.31047
Policy Entropy: 1.06106
Value Function Loss: 4.01645

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.09229

Collected Steps per Second: 10,353.54879
Overall Steps per Second: 8,939.80302

Timestep Collection Time: 4.83139
Timestep Consumption Time: 0.76404
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.59543

Cumulative Model Updates: 47,044
Cumulative Timesteps: 784,699,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 784699460...
Checkpoint 784699460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,678.98784
Policy Entropy: 1.04777
Value Function Loss: 3.72455

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.08118

Collected Steps per Second: 10,780.46297
Overall Steps per Second: 9,393.16009

Timestep Collection Time: 4.63950
Timestep Consumption Time: 0.68522
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.32473

Cumulative Model Updates: 47,047
Cumulative Timesteps: 784,749,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,058.20115
Policy Entropy: 1.03862
Value Function Loss: 3.85751

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.16629
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.08595

Collected Steps per Second: 10,724.88153
Overall Steps per Second: 9,221.58727

Timestep Collection Time: 4.66373
Timestep Consumption Time: 0.76028
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.42401

Cumulative Model Updates: 47,050
Cumulative Timesteps: 784,799,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 784799494...
Checkpoint 784799494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,546.80129
Policy Entropy: 1.04855
Value Function Loss: 3.83699

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.07974

Collected Steps per Second: 10,709.57465
Overall Steps per Second: 9,228.30172

Timestep Collection Time: 4.66872
Timestep Consumption Time: 0.74940
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 5.41812

Cumulative Model Updates: 47,053
Cumulative Timesteps: 784,849,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,954.73619
Policy Entropy: 1.05310
Value Function Loss: 3.83175

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.08209

Collected Steps per Second: 10,709.97447
Overall Steps per Second: 9,190.68869

Timestep Collection Time: 4.66985
Timestep Consumption Time: 0.77196
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.44181

Cumulative Model Updates: 47,056
Cumulative Timesteps: 784,899,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 784899508...
Checkpoint 784899508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,514.32485
Policy Entropy: 1.02020
Value Function Loss: 3.84389

Mean KL Divergence: 0.03558
SB3 Clip Fraction: 0.20704
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.07795

Collected Steps per Second: 10,708.24129
Overall Steps per Second: 9,069.42750

Timestep Collection Time: 4.67154
Timestep Consumption Time: 0.84413
PPO Batch Consumption Time: 0.03931
Total Iteration Time: 5.51567

Cumulative Model Updates: 47,059
Cumulative Timesteps: 784,949,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,660.87310
Policy Entropy: 1.04873
Value Function Loss: 3.74604

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.18358
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.08092

Collected Steps per Second: 8,781.03263
Overall Steps per Second: 6,296.22192

Timestep Collection Time: 5.69865
Timestep Consumption Time: 2.24898
PPO Batch Consumption Time: 0.05912
Total Iteration Time: 7.94762

Cumulative Model Updates: 47,062
Cumulative Timesteps: 784,999,572

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 784999572...
Checkpoint 784999572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,902.66557
Policy Entropy: 1.04397
Value Function Loss: 3.64147

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.08023

Collected Steps per Second: 3,918.87665
Overall Steps per Second: 3,209.66841

Timestep Collection Time: 12.76488
Timestep Consumption Time: 2.82053
PPO Batch Consumption Time: 0.06617
Total Iteration Time: 15.58541

Cumulative Model Updates: 47,065
Cumulative Timesteps: 785,049,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,257.69188
Policy Entropy: 1.04952
Value Function Loss: 3.52252

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.08636

Collected Steps per Second: 3,982.58779
Overall Steps per Second: 3,327.44635

Timestep Collection Time: 12.55967
Timestep Consumption Time: 2.47288
PPO Batch Consumption Time: 0.05784
Total Iteration Time: 15.03255

Cumulative Model Updates: 47,068
Cumulative Timesteps: 785,099,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 785099616...
Checkpoint 785099616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,449.44874
Policy Entropy: 1.03819
Value Function Loss: 3.37431

Mean KL Divergence: 0.02837
SB3 Clip Fraction: 0.17473
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.09420

Collected Steps per Second: 4,108.87641
Overall Steps per Second: 3,423.67699

Timestep Collection Time: 12.17997
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.05170
Total Iteration Time: 14.61762

Cumulative Model Updates: 47,071
Cumulative Timesteps: 785,149,662

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,192.29414
Policy Entropy: 1.05360
Value Function Loss: 3.52399

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 4,122.07717
Overall Steps per Second: 3,367.42561

Timestep Collection Time: 12.13466
Timestep Consumption Time: 2.71942
PPO Batch Consumption Time: 0.05387
Total Iteration Time: 14.85408

Cumulative Model Updates: 47,074
Cumulative Timesteps: 785,199,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 785199682...
Checkpoint 785199682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,206.34792
Policy Entropy: 1.06366
Value Function Loss: 3.74192

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.06242
Value Function Update Magnitude: 0.09657

Collected Steps per Second: 3,928.69633
Overall Steps per Second: 3,282.64232

Timestep Collection Time: 12.73501
Timestep Consumption Time: 2.50637
PPO Batch Consumption Time: 0.05154
Total Iteration Time: 15.24138

Cumulative Model Updates: 47,077
Cumulative Timesteps: 785,249,714

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,850.27872
Policy Entropy: 1.04301
Value Function Loss: 3.87053

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.09188

Collected Steps per Second: 3,980.96311
Overall Steps per Second: 3,299.59113

Timestep Collection Time: 12.56882
Timestep Consumption Time: 2.59549
PPO Batch Consumption Time: 0.05280
Total Iteration Time: 15.16430

Cumulative Model Updates: 47,080
Cumulative Timesteps: 785,299,750

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 785299750...
Checkpoint 785299750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,252.58438
Policy Entropy: 1.03311
Value Function Loss: 4.21531

Mean KL Divergence: 0.02689
SB3 Clip Fraction: 0.17690
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.08982

Collected Steps per Second: 4,042.95462
Overall Steps per Second: 3,372.10808

Timestep Collection Time: 12.37412
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.05303
Total Iteration Time: 14.83582

Cumulative Model Updates: 47,083
Cumulative Timesteps: 785,349,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,522.22999
Policy Entropy: 1.04210
Value Function Loss: 4.49812

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.08749

Collected Steps per Second: 4,192.53394
Overall Steps per Second: 3,432.54176

Timestep Collection Time: 11.93836
Timestep Consumption Time: 2.64325
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 14.58161

Cumulative Model Updates: 47,086
Cumulative Timesteps: 785,399,830

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 785399830...
Checkpoint 785399830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,971.48090
Policy Entropy: 1.04980
Value Function Loss: 4.59129

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.09233

Collected Steps per Second: 4,265.43829
Overall Steps per Second: 3,502.70107

Timestep Collection Time: 11.72259
Timestep Consumption Time: 2.55268
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 14.27527

Cumulative Model Updates: 47,089
Cumulative Timesteps: 785,449,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566,791.62954
Policy Entropy: 1.03445
Value Function Loss: 4.45503

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.15499
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.09028

Collected Steps per Second: 4,164.05280
Overall Steps per Second: 3,382.68211

Timestep Collection Time: 12.01666
Timestep Consumption Time: 2.77575
PPO Batch Consumption Time: 0.06034
Total Iteration Time: 14.79240

Cumulative Model Updates: 47,092
Cumulative Timesteps: 785,499,870

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 785499870...
Checkpoint 785499870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,737.67258
Policy Entropy: 1.04052
Value Function Loss: 4.27704

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.08587

Collected Steps per Second: 4,030.01275
Overall Steps per Second: 3,317.37519

Timestep Collection Time: 12.41832
Timestep Consumption Time: 2.66770
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 15.08602

Cumulative Model Updates: 47,095
Cumulative Timesteps: 785,549,916

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,700.79836
Policy Entropy: 1.03353
Value Function Loss: 4.37300

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.07698

Collected Steps per Second: 3,993.23211
Overall Steps per Second: 3,357.32433

Timestep Collection Time: 12.52219
Timestep Consumption Time: 2.37182
PPO Batch Consumption Time: 0.05922
Total Iteration Time: 14.89400

Cumulative Model Updates: 47,098
Cumulative Timesteps: 785,599,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 785599920...
Checkpoint 785599920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,840.46282
Policy Entropy: 1.03769
Value Function Loss: 4.46741

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.16719
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.07904

Collected Steps per Second: 3,815.25971
Overall Steps per Second: 3,185.00631

Timestep Collection Time: 13.11261
Timestep Consumption Time: 2.59474
PPO Batch Consumption Time: 0.05814
Total Iteration Time: 15.70735

Cumulative Model Updates: 47,101
Cumulative Timesteps: 785,649,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,691.82225
Policy Entropy: 1.02732
Value Function Loss: 4.45597

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.09316

Collected Steps per Second: 4,005.09102
Overall Steps per Second: 3,337.30815

Timestep Collection Time: 12.48511
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.06128
Total Iteration Time: 14.98333

Cumulative Model Updates: 47,104
Cumulative Timesteps: 785,699,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 785699952...
Checkpoint 785699952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,516.76468
Policy Entropy: 1.01900
Value Function Loss: 4.36315

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.16043
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.11000

Collected Steps per Second: 4,338.30988
Overall Steps per Second: 3,490.46479

Timestep Collection Time: 11.53122
Timestep Consumption Time: 2.80097
PPO Batch Consumption Time: 0.06224
Total Iteration Time: 14.33219

Cumulative Model Updates: 47,107
Cumulative Timesteps: 785,749,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,621.35252
Policy Entropy: 1.03981
Value Function Loss: 4.31150

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 4,135.90528
Overall Steps per Second: 3,413.03028

Timestep Collection Time: 12.09747
Timestep Consumption Time: 2.56223
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 14.65970

Cumulative Model Updates: 47,110
Cumulative Timesteps: 785,800,012

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 785800012...
Checkpoint 785800012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,922.09417
Policy Entropy: 1.05073
Value Function Loss: 4.37255

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.16153
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.09581

Collected Steps per Second: 3,969.20951
Overall Steps per Second: 3,285.94713

Timestep Collection Time: 12.59697
Timestep Consumption Time: 2.61935
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 15.21631

Cumulative Model Updates: 47,113
Cumulative Timesteps: 785,850,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,615.49812
Policy Entropy: 1.03470
Value Function Loss: 4.53675

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.09801

Collected Steps per Second: 3,858.97108
Overall Steps per Second: 3,108.88351

Timestep Collection Time: 12.96511
Timestep Consumption Time: 3.12812
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 16.09324

Cumulative Model Updates: 47,116
Cumulative Timesteps: 785,900,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 785900044...
Checkpoint 785900044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,804.98047
Policy Entropy: 1.03967
Value Function Loss: 4.49268

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.09066

Collected Steps per Second: 3,977.56986
Overall Steps per Second: 3,351.43906

Timestep Collection Time: 12.57652
Timestep Consumption Time: 2.34960
PPO Batch Consumption Time: 0.05376
Total Iteration Time: 14.92613

Cumulative Model Updates: 47,119
Cumulative Timesteps: 785,950,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,912.94665
Policy Entropy: 1.03900
Value Function Loss: 4.41071

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.10247

Collected Steps per Second: 3,883.85186
Overall Steps per Second: 3,214.26228

Timestep Collection Time: 12.87794
Timestep Consumption Time: 2.68271
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 15.56065

Cumulative Model Updates: 47,122
Cumulative Timesteps: 786,000,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 786000084...
Checkpoint 786000084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,580.36399
Policy Entropy: 1.04407
Value Function Loss: 4.37910

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.12007

Collected Steps per Second: 4,042.33161
Overall Steps per Second: 3,349.47740

Timestep Collection Time: 12.37108
Timestep Consumption Time: 2.55901
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 14.93009

Cumulative Model Updates: 47,125
Cumulative Timesteps: 786,050,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,207.58009
Policy Entropy: 1.03424
Value Function Loss: 4.51091

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.12617

Collected Steps per Second: 4,201.27148
Overall Steps per Second: 3,399.67571

Timestep Collection Time: 11.91306
Timestep Consumption Time: 2.80893
PPO Batch Consumption Time: 0.06593
Total Iteration Time: 14.72199

Cumulative Model Updates: 47,128
Cumulative Timesteps: 786,100,142

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 786100142...
Checkpoint 786100142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,380.28649
Policy Entropy: 1.03360
Value Function Loss: 4.47976

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 3,970.94653
Overall Steps per Second: 3,301.05035

Timestep Collection Time: 12.59246
Timestep Consumption Time: 2.55544
PPO Batch Consumption Time: 0.05776
Total Iteration Time: 15.14791

Cumulative Model Updates: 47,131
Cumulative Timesteps: 786,150,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,297.08637
Policy Entropy: 1.05108
Value Function Loss: 4.41714

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.16022
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.10985

Collected Steps per Second: 3,976.05458
Overall Steps per Second: 3,293.79773

Timestep Collection Time: 12.57528
Timestep Consumption Time: 2.60477
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 15.18005

Cumulative Model Updates: 47,134
Cumulative Timesteps: 786,200,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 786200146...
Checkpoint 786200146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,625.16967
Policy Entropy: 1.05361
Value Function Loss: 4.34557

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.15675
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.09840

Collected Steps per Second: 4,004.99271
Overall Steps per Second: 3,280.01646

Timestep Collection Time: 12.48492
Timestep Consumption Time: 2.75952
PPO Batch Consumption Time: 0.05908
Total Iteration Time: 15.24444

Cumulative Model Updates: 47,137
Cumulative Timesteps: 786,250,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,859.58135
Policy Entropy: 1.04723
Value Function Loss: 4.49171

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.09296

Collected Steps per Second: 4,091.98491
Overall Steps per Second: 3,340.24184

Timestep Collection Time: 12.21901
Timestep Consumption Time: 2.74997
PPO Batch Consumption Time: 0.06138
Total Iteration Time: 14.96898

Cumulative Model Updates: 47,140
Cumulative Timesteps: 786,300,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 786300148...
Checkpoint 786300148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575,005.77336
Policy Entropy: 1.03384
Value Function Loss: 4.45988

Mean KL Divergence: 0.02414
SB3 Clip Fraction: 0.17005
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.08381

Collected Steps per Second: 3,891.87964
Overall Steps per Second: 3,239.91415

Timestep Collection Time: 12.85651
Timestep Consumption Time: 2.58711
PPO Batch Consumption Time: 0.06460
Total Iteration Time: 15.44362

Cumulative Model Updates: 47,143
Cumulative Timesteps: 786,350,184

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,057.67683
Policy Entropy: 1.04681
Value Function Loss: 4.50265

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.09006

Collected Steps per Second: 4,207.07250
Overall Steps per Second: 3,447.15802

Timestep Collection Time: 11.88713
Timestep Consumption Time: 2.62048
PPO Batch Consumption Time: 0.05293
Total Iteration Time: 14.50760

Cumulative Model Updates: 47,146
Cumulative Timesteps: 786,400,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 786400194...
Checkpoint 786400194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,671.81941
Policy Entropy: 1.05540
Value Function Loss: 4.40421

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.06325
Value Function Update Magnitude: 0.08551

Collected Steps per Second: 3,955.33188
Overall Steps per Second: 3,291.79894

Timestep Collection Time: 12.65229
Timestep Consumption Time: 2.55034
PPO Batch Consumption Time: 0.06254
Total Iteration Time: 15.20263

Cumulative Model Updates: 47,149
Cumulative Timesteps: 786,450,238

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,622.41406
Policy Entropy: 1.03912
Value Function Loss: 4.38580

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.08382

Collected Steps per Second: 4,032.77818
Overall Steps per Second: 3,303.77491

Timestep Collection Time: 12.40733
Timestep Consumption Time: 2.73777
PPO Batch Consumption Time: 0.06446
Total Iteration Time: 15.14510

Cumulative Model Updates: 47,152
Cumulative Timesteps: 786,500,274

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 786500274...
Checkpoint 786500274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,989.45740
Policy Entropy: 1.03742
Value Function Loss: 4.43127

Mean KL Divergence: 0.02530
SB3 Clip Fraction: 0.16822
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.08155

Collected Steps per Second: 4,116.51214
Overall Steps per Second: 3,441.45795

Timestep Collection Time: 12.15204
Timestep Consumption Time: 2.38366
PPO Batch Consumption Time: 0.05871
Total Iteration Time: 14.53570

Cumulative Model Updates: 47,155
Cumulative Timesteps: 786,550,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,960.15297
Policy Entropy: 1.04018
Value Function Loss: 4.42079

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.08331

Collected Steps per Second: 4,318.14789
Overall Steps per Second: 3,513.09115

Timestep Collection Time: 11.58923
Timestep Consumption Time: 2.65578
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 14.24500

Cumulative Model Updates: 47,158
Cumulative Timesteps: 786,600,342

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 786600342...
Checkpoint 786600342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,176.60351
Policy Entropy: 1.04452
Value Function Loss: 4.51686

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.07994

Collected Steps per Second: 4,100.93958
Overall Steps per Second: 3,326.13642

Timestep Collection Time: 12.19233
Timestep Consumption Time: 2.84013
PPO Batch Consumption Time: 0.05145
Total Iteration Time: 15.03246

Cumulative Model Updates: 47,161
Cumulative Timesteps: 786,650,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,036.58084
Policy Entropy: 1.03824
Value Function Loss: 4.46861

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.06101
Value Function Update Magnitude: 0.08125

Collected Steps per Second: 4,162.53437
Overall Steps per Second: 3,470.08124

Timestep Collection Time: 12.01480
Timestep Consumption Time: 2.39755
PPO Batch Consumption Time: 0.06494
Total Iteration Time: 14.41234

Cumulative Model Updates: 47,164
Cumulative Timesteps: 786,700,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 786700354...
Checkpoint 786700354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,247.85325
Policy Entropy: 1.04298
Value Function Loss: 4.58050

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.07098
Value Function Update Magnitude: 0.09002

Collected Steps per Second: 4,279.54429
Overall Steps per Second: 3,480.22486

Timestep Collection Time: 11.69096
Timestep Consumption Time: 2.68512
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 14.37608

Cumulative Model Updates: 47,167
Cumulative Timesteps: 786,750,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,302.43364
Policy Entropy: 1.04043
Value Function Loss: 4.61178

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.10351

Collected Steps per Second: 3,973.81294
Overall Steps per Second: 3,377.00252

Timestep Collection Time: 12.58690
Timestep Consumption Time: 2.22446
PPO Batch Consumption Time: 0.06482
Total Iteration Time: 14.81136

Cumulative Model Updates: 47,170
Cumulative Timesteps: 786,800,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 786800404...
Checkpoint 786800404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,869.52634
Policy Entropy: 1.03377
Value Function Loss: 4.55306

Mean KL Divergence: 0.02832
SB3 Clip Fraction: 0.18192
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.10129

Collected Steps per Second: 4,107.09144
Overall Steps per Second: 3,342.50017

Timestep Collection Time: 12.18527
Timestep Consumption Time: 2.78736
PPO Batch Consumption Time: 0.06093
Total Iteration Time: 14.97262

Cumulative Model Updates: 47,173
Cumulative Timesteps: 786,850,450

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,572.81704
Policy Entropy: 1.05047
Value Function Loss: 4.51340

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.15212
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.12165

Collected Steps per Second: 3,968.91610
Overall Steps per Second: 3,239.57701

Timestep Collection Time: 12.59941
Timestep Consumption Time: 2.83656
PPO Batch Consumption Time: 0.05997
Total Iteration Time: 15.43597

Cumulative Model Updates: 47,176
Cumulative Timesteps: 786,900,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 786900456...
Checkpoint 786900456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,996.24606
Policy Entropy: 1.05384
Value Function Loss: 4.45700

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 4,172.66900
Overall Steps per Second: 3,427.39707

Timestep Collection Time: 11.98513
Timestep Consumption Time: 2.60611
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 14.59125

Cumulative Model Updates: 47,179
Cumulative Timesteps: 786,950,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694,062.53921
Policy Entropy: 1.03458
Value Function Loss: 4.66786

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.11671

Collected Steps per Second: 3,907.70683
Overall Steps per Second: 3,233.72517

Timestep Collection Time: 12.80495
Timestep Consumption Time: 2.66884
PPO Batch Consumption Time: 0.06779
Total Iteration Time: 15.47379

Cumulative Model Updates: 47,182
Cumulative Timesteps: 787,000,504

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 787000504...
Checkpoint 787000504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,358.04513
Policy Entropy: 1.02215
Value Function Loss: 4.73536

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.15108
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.10691

Collected Steps per Second: 4,095.53211
Overall Steps per Second: 3,392.51875

Timestep Collection Time: 12.21184
Timestep Consumption Time: 2.53059
PPO Batch Consumption Time: 0.07311
Total Iteration Time: 14.74244

Cumulative Model Updates: 47,185
Cumulative Timesteps: 787,050,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,916.95690
Policy Entropy: 1.03393
Value Function Loss: 4.71696

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.10657

Collected Steps per Second: 4,241.45960
Overall Steps per Second: 3,531.28252

Timestep Collection Time: 11.79452
Timestep Consumption Time: 2.37200
PPO Batch Consumption Time: 0.06069
Total Iteration Time: 14.16652

Cumulative Model Updates: 47,188
Cumulative Timesteps: 787,100,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 787100544...
Checkpoint 787100544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,558.61347
Policy Entropy: 1.04915
Value Function Loss: 4.68286

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.11497

Collected Steps per Second: 4,062.58093
Overall Steps per Second: 3,421.61868

Timestep Collection Time: 12.31385
Timestep Consumption Time: 2.30672
PPO Batch Consumption Time: 0.05297
Total Iteration Time: 14.62057

Cumulative Model Updates: 47,191
Cumulative Timesteps: 787,150,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,238.07743
Policy Entropy: 1.02745
Value Function Loss: 4.51325

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.11391

Collected Steps per Second: 4,227.96934
Overall Steps per Second: 3,445.89781

Timestep Collection Time: 11.83547
Timestep Consumption Time: 2.68615
PPO Batch Consumption Time: 0.05148
Total Iteration Time: 14.52161

Cumulative Model Updates: 47,194
Cumulative Timesteps: 787,200,610

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 787200610...
Checkpoint 787200610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,795.25009
Policy Entropy: 1.03973
Value Function Loss: 4.39518

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.11190

Collected Steps per Second: 4,037.28268
Overall Steps per Second: 3,313.49436

Timestep Collection Time: 12.39150
Timestep Consumption Time: 2.70676
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 15.09826

Cumulative Model Updates: 47,197
Cumulative Timesteps: 787,250,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,820.28506
Policy Entropy: 1.04684
Value Function Loss: 4.36922

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.12295

Collected Steps per Second: 4,251.56910
Overall Steps per Second: 3,447.28695

Timestep Collection Time: 11.76836
Timestep Consumption Time: 2.74566
PPO Batch Consumption Time: 0.05966
Total Iteration Time: 14.51402

Cumulative Model Updates: 47,200
Cumulative Timesteps: 787,300,672

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 787300672...
Checkpoint 787300672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,495.15486
Policy Entropy: 1.05561
Value Function Loss: 4.39521

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.11684

Collected Steps per Second: 4,157.00499
Overall Steps per Second: 3,405.33023

Timestep Collection Time: 12.03078
Timestep Consumption Time: 2.65561
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 14.68639

Cumulative Model Updates: 47,203
Cumulative Timesteps: 787,350,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453,927.82158
Policy Entropy: 1.06307
Value Function Loss: 4.60732

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.11341

Collected Steps per Second: 4,016.48772
Overall Steps per Second: 3,343.82250

Timestep Collection Time: 12.45416
Timestep Consumption Time: 2.50536
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 14.95953

Cumulative Model Updates: 47,206
Cumulative Timesteps: 787,400,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 787400706...
Checkpoint 787400706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,608.69731
Policy Entropy: 1.05799
Value Function Loss: 4.63724

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.11522

Collected Steps per Second: 3,976.74380
Overall Steps per Second: 3,271.83027

Timestep Collection Time: 12.58064
Timestep Consumption Time: 2.71049
PPO Batch Consumption Time: 0.05902
Total Iteration Time: 15.29114

Cumulative Model Updates: 47,209
Cumulative Timesteps: 787,450,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,386.50174
Policy Entropy: 1.05367
Value Function Loss: 4.90563

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.06408
Value Function Update Magnitude: 0.12258

Collected Steps per Second: 3,874.47893
Overall Steps per Second: 3,252.69849

Timestep Collection Time: 12.91219
Timestep Consumption Time: 2.46827
PPO Batch Consumption Time: 0.05037
Total Iteration Time: 15.38046

Cumulative Model Updates: 47,212
Cumulative Timesteps: 787,500,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 787500764...
Checkpoint 787500764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,034.31122
Policy Entropy: 1.05361
Value Function Loss: 4.84359

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.06622
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 4,158.59840
Overall Steps per Second: 3,382.65846

Timestep Collection Time: 12.03434
Timestep Consumption Time: 2.76053
PPO Batch Consumption Time: 0.06511
Total Iteration Time: 14.79487

Cumulative Model Updates: 47,215
Cumulative Timesteps: 787,550,810

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,681.49318
Policy Entropy: 1.04631
Value Function Loss: 4.91093

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.07549
Value Function Update Magnitude: 0.11436

Collected Steps per Second: 4,443.90485
Overall Steps per Second: 3,605.94446

Timestep Collection Time: 11.26037
Timestep Consumption Time: 2.61672
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 13.87709

Cumulative Model Updates: 47,218
Cumulative Timesteps: 787,600,850

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 787600850...
Checkpoint 787600850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,185.79657
Policy Entropy: 1.04826
Value Function Loss: 4.79264

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.06808
Value Function Update Magnitude: 0.10866

Collected Steps per Second: 3,958.37689
Overall Steps per Second: 3,322.41298

Timestep Collection Time: 12.63548
Timestep Consumption Time: 2.41864
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 15.05412

Cumulative Model Updates: 47,221
Cumulative Timesteps: 787,650,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,355.55328
Policy Entropy: 1.04281
Value Function Loss: 4.75011

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.07190
Value Function Update Magnitude: 0.10688

Collected Steps per Second: 3,976.10989
Overall Steps per Second: 3,279.83413

Timestep Collection Time: 12.58114
Timestep Consumption Time: 2.67085
PPO Batch Consumption Time: 0.06239
Total Iteration Time: 15.25199

Cumulative Model Updates: 47,224
Cumulative Timesteps: 787,700,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 787700890...
Checkpoint 787700890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,627.88566
Policy Entropy: 1.04845
Value Function Loss: 4.62241

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.07074
Value Function Update Magnitude: 0.09174

Collected Steps per Second: 4,065.05800
Overall Steps per Second: 3,423.44510

Timestep Collection Time: 12.30290
Timestep Consumption Time: 2.30578
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 14.60868

Cumulative Model Updates: 47,227
Cumulative Timesteps: 787,750,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,501.37208
Policy Entropy: 1.04901
Value Function Loss: 4.60440

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.07124
Value Function Update Magnitude: 0.08656

Collected Steps per Second: 4,273.60523
Overall Steps per Second: 3,456.59899

Timestep Collection Time: 11.70815
Timestep Consumption Time: 2.76735
PPO Batch Consumption Time: 0.05295
Total Iteration Time: 14.47550

Cumulative Model Updates: 47,230
Cumulative Timesteps: 787,800,938

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 787800938...
Checkpoint 787800938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,298.99985
Policy Entropy: 1.04733
Value Function Loss: 4.34837

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.07100
Value Function Update Magnitude: 0.09873

Collected Steps per Second: 3,968.15831
Overall Steps per Second: 3,278.95711

Timestep Collection Time: 12.60282
Timestep Consumption Time: 2.64898
PPO Batch Consumption Time: 0.05894
Total Iteration Time: 15.25180

Cumulative Model Updates: 47,233
Cumulative Timesteps: 787,850,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,488.03881
Policy Entropy: 1.03392
Value Function Loss: 4.33337

Mean KL Divergence: 0.02891
SB3 Clip Fraction: 0.17145
Policy Update Magnitude: 0.06592
Value Function Update Magnitude: 0.11502

Collected Steps per Second: 4,221.51155
Overall Steps per Second: 3,504.09227

Timestep Collection Time: 11.84978
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.06753
Total Iteration Time: 14.27588

Cumulative Model Updates: 47,236
Cumulative Timesteps: 787,900,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 787900972...
Checkpoint 787900972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,995.05401
Policy Entropy: 1.05392
Value Function Loss: 4.19162

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.09898

Collected Steps per Second: 4,191.14822
Overall Steps per Second: 3,430.19352

Timestep Collection Time: 11.94088
Timestep Consumption Time: 2.64897
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 14.58985

Cumulative Model Updates: 47,239
Cumulative Timesteps: 787,951,018

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,987.19614
Policy Entropy: 1.04959
Value Function Loss: 4.41763

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.09881

Collected Steps per Second: 4,143.08358
Overall Steps per Second: 3,470.23434

Timestep Collection Time: 12.08037
Timestep Consumption Time: 2.34228
PPO Batch Consumption Time: 0.05875
Total Iteration Time: 14.42266

Cumulative Model Updates: 47,242
Cumulative Timesteps: 788,001,068

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 788001068...
Checkpoint 788001068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,883.52866
Policy Entropy: 1.04923
Value Function Loss: 4.46428

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.11595

Collected Steps per Second: 4,025.97735
Overall Steps per Second: 3,275.65600

Timestep Collection Time: 12.43027
Timestep Consumption Time: 2.84728
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 15.27755

Cumulative Model Updates: 47,245
Cumulative Timesteps: 788,051,112

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,037.76160
Policy Entropy: 1.04604
Value Function Loss: 4.51389

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.06890
Value Function Update Magnitude: 0.11366

Collected Steps per Second: 4,339.38213
Overall Steps per Second: 3,519.92742

Timestep Collection Time: 11.52560
Timestep Consumption Time: 2.68321
PPO Batch Consumption Time: 0.06799
Total Iteration Time: 14.20882

Cumulative Model Updates: 47,248
Cumulative Timesteps: 788,101,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 788101126...
Checkpoint 788101126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,474.61373
Policy Entropy: 1.03848
Value Function Loss: 4.48790

Mean KL Divergence: 0.02652
SB3 Clip Fraction: 0.17005
Policy Update Magnitude: 0.06944
Value Function Update Magnitude: 0.10624

Collected Steps per Second: 4,373.53899
Overall Steps per Second: 3,559.64010

Timestep Collection Time: 11.43376
Timestep Consumption Time: 2.61429
PPO Batch Consumption Time: 0.05314
Total Iteration Time: 14.04805

Cumulative Model Updates: 47,251
Cumulative Timesteps: 788,151,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,426.24996
Policy Entropy: 1.06672
Value Function Loss: 4.40640

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.05900
Value Function Update Magnitude: 0.10247

Collected Steps per Second: 4,230.97441
Overall Steps per Second: 3,494.54927

Timestep Collection Time: 11.82801
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.06241
Total Iteration Time: 14.32059

Cumulative Model Updates: 47,254
Cumulative Timesteps: 788,201,176

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 788201176...
Checkpoint 788201176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,778.05295
Policy Entropy: 1.06123
Value Function Loss: 4.35430

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.11321

Collected Steps per Second: 4,257.31144
Overall Steps per Second: 3,508.22101

Timestep Collection Time: 11.75296
Timestep Consumption Time: 2.50954
PPO Batch Consumption Time: 0.07041
Total Iteration Time: 14.26250

Cumulative Model Updates: 47,257
Cumulative Timesteps: 788,251,212

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,157.39967
Policy Entropy: 1.05950
Value Function Loss: 4.42591

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.07045
Value Function Update Magnitude: 0.11188

Collected Steps per Second: 4,079.70887
Overall Steps per Second: 3,333.22331

Timestep Collection Time: 12.26264
Timestep Consumption Time: 2.74626
PPO Batch Consumption Time: 0.06554
Total Iteration Time: 15.00890

Cumulative Model Updates: 47,260
Cumulative Timesteps: 788,301,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 788301240...
Checkpoint 788301240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,486.56297
Policy Entropy: 1.03917
Value Function Loss: 4.49319

Mean KL Divergence: 0.02715
SB3 Clip Fraction: 0.15986
Policy Update Magnitude: 0.07242
Value Function Update Magnitude: 0.12773

Collected Steps per Second: 4,369.31754
Overall Steps per Second: 3,557.24282

Timestep Collection Time: 11.45305
Timestep Consumption Time: 2.61459
PPO Batch Consumption Time: 0.05413
Total Iteration Time: 14.06764

Cumulative Model Updates: 47,263
Cumulative Timesteps: 788,351,282

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,757.18471
Policy Entropy: 1.05905
Value Function Loss: 4.57157

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.06160
Value Function Update Magnitude: 0.13874

Collected Steps per Second: 4,426.86289
Overall Steps per Second: 3,578.10539

Timestep Collection Time: 11.30372
Timestep Consumption Time: 2.68134
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 13.98505

Cumulative Model Updates: 47,266
Cumulative Timesteps: 788,401,322

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 788401322...
Checkpoint 788401322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,009.43061
Policy Entropy: 1.06690
Value Function Loss: 4.53341

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.13165

Collected Steps per Second: 4,016.89975
Overall Steps per Second: 3,323.73397

Timestep Collection Time: 12.45538
Timestep Consumption Time: 2.59757
PPO Batch Consumption Time: 0.05275
Total Iteration Time: 15.05295

Cumulative Model Updates: 47,269
Cumulative Timesteps: 788,451,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,814.72515
Policy Entropy: 1.05317
Value Function Loss: 4.31117

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.14659
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.13176

Collected Steps per Second: 4,106.01156
Overall Steps per Second: 3,470.68268

Timestep Collection Time: 12.18311
Timestep Consumption Time: 2.23019
PPO Batch Consumption Time: 0.05142
Total Iteration Time: 14.41330

Cumulative Model Updates: 47,272
Cumulative Timesteps: 788,501,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 788501378...
Checkpoint 788501378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,578.98156
Policy Entropy: 1.04286
Value Function Loss: 4.24034

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.15723
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.12465

Collected Steps per Second: 3,849.34094
Overall Steps per Second: 3,157.56894

Timestep Collection Time: 13.00015
Timestep Consumption Time: 2.84812
PPO Batch Consumption Time: 0.06579
Total Iteration Time: 15.84827

Cumulative Model Updates: 47,275
Cumulative Timesteps: 788,551,420

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,502.30613
Policy Entropy: 1.05056
Value Function Loss: 4.23720

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.13470

Collected Steps per Second: 4,226.63984
Overall Steps per Second: 3,479.78015

Timestep Collection Time: 11.84203
Timestep Consumption Time: 2.54164
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 14.38367

Cumulative Model Updates: 47,278
Cumulative Timesteps: 788,601,472

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 788601472...
Checkpoint 788601472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,985.79165
Policy Entropy: 1.06703
Value Function Loss: 4.34343

Mean KL Divergence: 0.02216
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.13464

Collected Steps per Second: 4,039.49678
Overall Steps per Second: 3,341.22159

Timestep Collection Time: 12.37877
Timestep Consumption Time: 2.58701
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 14.96578

Cumulative Model Updates: 47,281
Cumulative Timesteps: 788,651,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,571.46524
Policy Entropy: 1.05034
Value Function Loss: 4.38936

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.12253

Collected Steps per Second: 3,773.91336
Overall Steps per Second: 3,125.91639

Timestep Collection Time: 13.25468
Timestep Consumption Time: 2.74767
PPO Batch Consumption Time: 0.06149
Total Iteration Time: 16.00235

Cumulative Model Updates: 47,284
Cumulative Timesteps: 788,701,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 788701498...
Checkpoint 788701498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,147.04858
Policy Entropy: 1.06384
Value Function Loss: 4.43252

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.14345
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.10695

Collected Steps per Second: 3,990.34609
Overall Steps per Second: 3,318.54431

Timestep Collection Time: 12.53776
Timestep Consumption Time: 2.53813
PPO Batch Consumption Time: 0.07056
Total Iteration Time: 15.07589

Cumulative Model Updates: 47,287
Cumulative Timesteps: 788,751,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,005.34891
Policy Entropy: 1.06613
Value Function Loss: 4.27627

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.14595
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.09645

Collected Steps per Second: 3,692.76320
Overall Steps per Second: 3,040.54562

Timestep Collection Time: 13.54216
Timestep Consumption Time: 2.90489
PPO Batch Consumption Time: 0.06481
Total Iteration Time: 16.44705

Cumulative Model Updates: 47,290
Cumulative Timesteps: 788,801,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 788801536...
Checkpoint 788801536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,078.08383
Policy Entropy: 1.04938
Value Function Loss: 3.97962

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.10711

Collected Steps per Second: 3,860.93031
Overall Steps per Second: 3,225.23446

Timestep Collection Time: 12.95076
Timestep Consumption Time: 2.55260
PPO Batch Consumption Time: 0.06182
Total Iteration Time: 15.50337

Cumulative Model Updates: 47,293
Cumulative Timesteps: 788,851,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,471.34570
Policy Entropy: 1.03721
Value Function Loss: 4.07791

Mean KL Divergence: 0.02544
SB3 Clip Fraction: 0.16031
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 3,735.96789
Overall Steps per Second: 3,126.55814

Timestep Collection Time: 13.39680
Timestep Consumption Time: 2.61122
PPO Batch Consumption Time: 0.06142
Total Iteration Time: 16.00802

Cumulative Model Updates: 47,296
Cumulative Timesteps: 788,901,588

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 788901588...
Checkpoint 788901588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,426.32471
Policy Entropy: 1.04928
Value Function Loss: 4.22365

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.12122

Collected Steps per Second: 3,760.69736
Overall Steps per Second: 3,138.10701

Timestep Collection Time: 13.29966
Timestep Consumption Time: 2.63861
PPO Batch Consumption Time: 0.06221
Total Iteration Time: 15.93827

Cumulative Model Updates: 47,299
Cumulative Timesteps: 788,951,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,922.68373
Policy Entropy: 1.06008
Value Function Loss: 4.53726

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.16138
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.10414

Collected Steps per Second: 3,780.06854
Overall Steps per Second: 3,185.91851

Timestep Collection Time: 13.23838
Timestep Consumption Time: 2.46886
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 15.70724

Cumulative Model Updates: 47,302
Cumulative Timesteps: 789,001,646

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 789001646...
Checkpoint 789001646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618,604.38045
Policy Entropy: 1.04477
Value Function Loss: 4.43964

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.08601

Collected Steps per Second: 3,761.15643
Overall Steps per Second: 3,112.86599

Timestep Collection Time: 13.29485
Timestep Consumption Time: 2.76881
PPO Batch Consumption Time: 0.06032
Total Iteration Time: 16.06365

Cumulative Model Updates: 47,305
Cumulative Timesteps: 789,051,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,934.28606
Policy Entropy: 1.03739
Value Function Loss: 4.42862

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.16216
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.07246

Collected Steps per Second: 3,756.90792
Overall Steps per Second: 3,169.57410

Timestep Collection Time: 13.31680
Timestep Consumption Time: 2.46765
PPO Batch Consumption Time: 0.06030
Total Iteration Time: 15.78446

Cumulative Model Updates: 47,308
Cumulative Timesteps: 789,101,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 789101680...
Checkpoint 789101680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,423.96228
Policy Entropy: 1.05353
Value Function Loss: 4.38881

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.06705

Collected Steps per Second: 3,770.30538
Overall Steps per Second: 3,100.20445

Timestep Collection Time: 13.26789
Timestep Consumption Time: 2.86782
PPO Batch Consumption Time: 0.06965
Total Iteration Time: 16.13571

Cumulative Model Updates: 47,311
Cumulative Timesteps: 789,151,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,104.72986
Policy Entropy: 1.06360
Value Function Loss: 4.47406

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.16453
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.07524

Collected Steps per Second: 3,888.89265
Overall Steps per Second: 3,213.21937

Timestep Collection Time: 12.85764
Timestep Consumption Time: 2.70370
PPO Batch Consumption Time: 0.06228
Total Iteration Time: 15.56134

Cumulative Model Updates: 47,314
Cumulative Timesteps: 789,201,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 789201706...
Checkpoint 789201706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,308.69392
Policy Entropy: 1.04746
Value Function Loss: 4.37204

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.09048

Collected Steps per Second: 3,867.89675
Overall Steps per Second: 3,181.59697

Timestep Collection Time: 12.92692
Timestep Consumption Time: 2.78846
PPO Batch Consumption Time: 0.05795
Total Iteration Time: 15.71538

Cumulative Model Updates: 47,317
Cumulative Timesteps: 789,251,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,145.97130
Policy Entropy: 1.03977
Value Function Loss: 4.15568

Mean KL Divergence: 0.02790
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.10090

Collected Steps per Second: 3,836.15751
Overall Steps per Second: 3,154.95341

Timestep Collection Time: 13.04378
Timestep Consumption Time: 2.81636
PPO Batch Consumption Time: 0.06164
Total Iteration Time: 15.86014

Cumulative Model Updates: 47,320
Cumulative Timesteps: 789,301,744

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 789301744...
Checkpoint 789301744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,278.13429
Policy Entropy: 1.05682
Value Function Loss: 4.02314

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.09731

Collected Steps per Second: 3,778.40465
Overall Steps per Second: 3,174.89080

Timestep Collection Time: 13.23839
Timestep Consumption Time: 2.51648
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 15.75487

Cumulative Model Updates: 47,323
Cumulative Timesteps: 789,351,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,715.06255
Policy Entropy: 1.06157
Value Function Loss: 4.19130

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.09450

Collected Steps per Second: 3,833.30315
Overall Steps per Second: 3,189.37189

Timestep Collection Time: 13.05245
Timestep Consumption Time: 2.63528
PPO Batch Consumption Time: 0.05988
Total Iteration Time: 15.68773

Cumulative Model Updates: 47,326
Cumulative Timesteps: 789,401,798

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 789401798...
Checkpoint 789401798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,523.08908
Policy Entropy: 1.05986
Value Function Loss: 4.33006

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.06143
Value Function Update Magnitude: 0.10075

Collected Steps per Second: 3,753.59862
Overall Steps per Second: 3,144.36166

Timestep Collection Time: 13.32321
Timestep Consumption Time: 2.58144
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 15.90466

Cumulative Model Updates: 47,329
Cumulative Timesteps: 789,451,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,592.06319
Policy Entropy: 1.05166
Value Function Loss: 4.39733

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.06454
Value Function Update Magnitude: 0.10318

Collected Steps per Second: 3,781.43791
Overall Steps per Second: 3,133.12739

Timestep Collection Time: 13.22619
Timestep Consumption Time: 2.73678
PPO Batch Consumption Time: 0.06782
Total Iteration Time: 15.96296

Cumulative Model Updates: 47,332
Cumulative Timesteps: 789,501,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 789501822...
Checkpoint 789501822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,187.57275
Policy Entropy: 1.04964
Value Function Loss: 4.31494

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.09751

Collected Steps per Second: 3,959.94576
Overall Steps per Second: 3,265.57459

Timestep Collection Time: 12.63805
Timestep Consumption Time: 2.68728
PPO Batch Consumption Time: 0.06159
Total Iteration Time: 15.32533

Cumulative Model Updates: 47,335
Cumulative Timesteps: 789,551,868

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,066.28250
Policy Entropy: 1.03743
Value Function Loss: 4.36134

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.16005
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.09204

Collected Steps per Second: 3,984.10773
Overall Steps per Second: 3,262.54500

Timestep Collection Time: 12.55438
Timestep Consumption Time: 2.77660
PPO Batch Consumption Time: 0.04890
Total Iteration Time: 15.33098

Cumulative Model Updates: 47,338
Cumulative Timesteps: 789,601,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 789601886...
Checkpoint 789601886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,200.53751
Policy Entropy: 1.04833
Value Function Loss: 4.43260

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.08789

Collected Steps per Second: 3,918.09808
Overall Steps per Second: 3,187.19572

Timestep Collection Time: 12.77201
Timestep Consumption Time: 2.92894
PPO Batch Consumption Time: 0.05926
Total Iteration Time: 15.70095

Cumulative Model Updates: 47,341
Cumulative Timesteps: 789,651,928

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,709.07639
Policy Entropy: 1.05605
Value Function Loss: 4.47245

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.09644

Collected Steps per Second: 3,854.81303
Overall Steps per Second: 3,242.01899

Timestep Collection Time: 12.98221
Timestep Consumption Time: 2.45385
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 15.43606

Cumulative Model Updates: 47,344
Cumulative Timesteps: 789,701,972

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 789701972...
Checkpoint 789701972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,800.14526
Policy Entropy: 1.04277
Value Function Loss: 4.37564

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.09926

Collected Steps per Second: 3,896.94779
Overall Steps per Second: 3,182.53743

Timestep Collection Time: 12.83877
Timestep Consumption Time: 2.88202
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 15.72079

Cumulative Model Updates: 47,347
Cumulative Timesteps: 789,752,004

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,105.83358
Policy Entropy: 1.04608
Value Function Loss: 4.32000

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.16133
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.08657

Collected Steps per Second: 3,778.66309
Overall Steps per Second: 3,173.38384

Timestep Collection Time: 13.23537
Timestep Consumption Time: 2.52446
PPO Batch Consumption Time: 0.05886
Total Iteration Time: 15.75983

Cumulative Model Updates: 47,350
Cumulative Timesteps: 789,802,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 789802016...
Checkpoint 789802016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,499.26005
Policy Entropy: 1.05883
Value Function Loss: 4.16516

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12121
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.08655

Collected Steps per Second: 3,843.68618
Overall Steps per Second: 3,206.65059

Timestep Collection Time: 13.01511
Timestep Consumption Time: 2.58559
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 15.60070

Cumulative Model Updates: 47,353
Cumulative Timesteps: 789,852,042

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,017.03861
Policy Entropy: 1.07331
Value Function Loss: 4.07775

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.08637

Collected Steps per Second: 3,723.40364
Overall Steps per Second: 3,099.28099

Timestep Collection Time: 13.43932
Timestep Consumption Time: 2.70636
PPO Batch Consumption Time: 0.06779
Total Iteration Time: 16.14568

Cumulative Model Updates: 47,356
Cumulative Timesteps: 789,902,082

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 789902082...
Checkpoint 789902082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,128.23087
Policy Entropy: 1.04639
Value Function Loss: 4.04127

Mean KL Divergence: 0.02659
SB3 Clip Fraction: 0.16306
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.08720

Collected Steps per Second: 3,929.11469
Overall Steps per Second: 3,201.41348

Timestep Collection Time: 12.72806
Timestep Consumption Time: 2.89317
PPO Batch Consumption Time: 0.06625
Total Iteration Time: 15.62122

Cumulative Model Updates: 47,359
Cumulative Timesteps: 789,952,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,762.28554
Policy Entropy: 1.06182
Value Function Loss: 4.26027

Mean KL Divergence: 0.02408
SB3 Clip Fraction: 0.16262
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.08846

Collected Steps per Second: 3,727.68173
Overall Steps per Second: 3,081.98071

Timestep Collection Time: 13.42121
Timestep Consumption Time: 2.81186
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 16.23307

Cumulative Model Updates: 47,362
Cumulative Timesteps: 790,002,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 790002122...
Checkpoint 790002122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,177.65971
Policy Entropy: 1.06225
Value Function Loss: 4.44622

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.15585
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.08988

Collected Steps per Second: 3,833.71874
Overall Steps per Second: 3,216.54601

Timestep Collection Time: 13.05312
Timestep Consumption Time: 2.50456
PPO Batch Consumption Time: 0.06329
Total Iteration Time: 15.55768

Cumulative Model Updates: 47,365
Cumulative Timesteps: 790,052,164

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,388.10585
Policy Entropy: 1.05627
Value Function Loss: 4.62663

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.08749

Collected Steps per Second: 3,799.58097
Overall Steps per Second: 3,146.44249

Timestep Collection Time: 13.16198
Timestep Consumption Time: 2.73216
PPO Batch Consumption Time: 0.06136
Total Iteration Time: 15.89414

Cumulative Model Updates: 47,368
Cumulative Timesteps: 790,102,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 790102174...
Checkpoint 790102174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,115.47562
Policy Entropy: 1.04176
Value Function Loss: 4.55460

Mean KL Divergence: 0.03305
SB3 Clip Fraction: 0.17693
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.08922

Collected Steps per Second: 3,809.73445
Overall Steps per Second: 3,199.55174

Timestep Collection Time: 13.12847
Timestep Consumption Time: 2.50372
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 15.63219

Cumulative Model Updates: 47,371
Cumulative Timesteps: 790,152,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,056.02796
Policy Entropy: 1.07589
Value Function Loss: 4.47292

Mean KL Divergence: 0.03282
SB3 Clip Fraction: 0.17967
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.09365

Collected Steps per Second: 3,868.61282
Overall Steps per Second: 3,192.20746

Timestep Collection Time: 12.92660
Timestep Consumption Time: 2.73905
PPO Batch Consumption Time: 0.06060
Total Iteration Time: 15.66565

Cumulative Model Updates: 47,374
Cumulative Timesteps: 790,202,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 790202198...
Checkpoint 790202198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,841.57047
Policy Entropy: 1.03851
Value Function Loss: 4.24384

Mean KL Divergence: 0.04974
SB3 Clip Fraction: 0.21748
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.10022

Collected Steps per Second: 3,796.94140
Overall Steps per Second: 3,140.32914

Timestep Collection Time: 13.17534
Timestep Consumption Time: 2.75484
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 15.93018

Cumulative Model Updates: 47,377
Cumulative Timesteps: 790,252,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,071.73849
Policy Entropy: 1.07814
Value Function Loss: 4.18543

Mean KL Divergence: 0.04488
SB3 Clip Fraction: 0.20750
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.08864

Collected Steps per Second: 3,749.40687
Overall Steps per Second: 3,102.30714

Timestep Collection Time: 13.34504
Timestep Consumption Time: 2.78360
PPO Batch Consumption Time: 0.06184
Total Iteration Time: 16.12864

Cumulative Model Updates: 47,380
Cumulative Timesteps: 790,302,260

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 790302260...
Checkpoint 790302260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,721.96674
Policy Entropy: 1.04234
Value Function Loss: 4.27003

Mean KL Divergence: 0.07988
SB3 Clip Fraction: 0.27327
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.08598

Collected Steps per Second: 3,817.29451
Overall Steps per Second: 3,201.27254

Timestep Collection Time: 13.10143
Timestep Consumption Time: 2.52111
PPO Batch Consumption Time: 0.06390
Total Iteration Time: 15.62254

Cumulative Model Updates: 47,383
Cumulative Timesteps: 790,352,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,685.75374
Policy Entropy: 1.06891
Value Function Loss: 4.26716

Mean KL Divergence: 0.05180
SB3 Clip Fraction: 0.22408
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.08050

Collected Steps per Second: 3,736.08782
Overall Steps per Second: 3,129.94097

Timestep Collection Time: 13.38727
Timestep Consumption Time: 2.59259
PPO Batch Consumption Time: 0.05980
Total Iteration Time: 15.97985

Cumulative Model Updates: 47,386
Cumulative Timesteps: 790,402,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 790402288...
Checkpoint 790402288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,891.57152
Policy Entropy: 1.05179
Value Function Loss: 4.31307

Mean KL Divergence: 0.04332
SB3 Clip Fraction: 0.20683
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.08253

Collected Steps per Second: 3,903.21622
Overall Steps per Second: 3,224.57202

Timestep Collection Time: 12.81354
Timestep Consumption Time: 2.69674
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 15.51028

Cumulative Model Updates: 47,389
Cumulative Timesteps: 790,452,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,897.72464
Policy Entropy: 1.06205
Value Function Loss: 4.24019

Mean KL Divergence: 0.02879
SB3 Clip Fraction: 0.17463
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.07410

Collected Steps per Second: 3,843.14480
Overall Steps per Second: 3,176.77031

Timestep Collection Time: 13.01434
Timestep Consumption Time: 2.72995
PPO Batch Consumption Time: 0.05908
Total Iteration Time: 15.74429

Cumulative Model Updates: 47,392
Cumulative Timesteps: 790,502,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 790502318...
Checkpoint 790502318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,252.97342
Policy Entropy: 1.05922
Value Function Loss: 4.19404

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.16475
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 3,981.84830
Overall Steps per Second: 3,224.74107

Timestep Collection Time: 12.56050
Timestep Consumption Time: 2.94896
PPO Batch Consumption Time: 0.05981
Total Iteration Time: 15.50946

Cumulative Model Updates: 47,395
Cumulative Timesteps: 790,552,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,710.06787
Policy Entropy: 1.04724
Value Function Loss: 4.28043

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.10597

Collected Steps per Second: 3,706.09181
Overall Steps per Second: 3,092.30084

Timestep Collection Time: 13.49184
Timestep Consumption Time: 2.67800
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 16.16984

Cumulative Model Updates: 47,398
Cumulative Timesteps: 790,602,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 790602334...
Checkpoint 790602334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,055.47133
Policy Entropy: 1.06192
Value Function Loss: 4.14794

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.15239
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.10681

Collected Steps per Second: 3,787.48990
Overall Steps per Second: 3,169.22563

Timestep Collection Time: 13.20188
Timestep Consumption Time: 2.57547
PPO Batch Consumption Time: 0.06165
Total Iteration Time: 15.77736

Cumulative Model Updates: 47,401
Cumulative Timesteps: 790,652,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,918.94125
Policy Entropy: 1.06741
Value Function Loss: 4.35215

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.10205

Collected Steps per Second: 3,708.35805
Overall Steps per Second: 3,100.16137

Timestep Collection Time: 13.48521
Timestep Consumption Time: 2.64556
PPO Batch Consumption Time: 0.07113
Total Iteration Time: 16.13077

Cumulative Model Updates: 47,404
Cumulative Timesteps: 790,702,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 790702344...
Checkpoint 790702344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,859.57479
Policy Entropy: 1.07062
Value Function Loss: 4.20734

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.06743
Value Function Update Magnitude: 0.09664

Collected Steps per Second: 3,691.26938
Overall Steps per Second: 3,104.72083

Timestep Collection Time: 13.55198
Timestep Consumption Time: 2.56026
PPO Batch Consumption Time: 0.06399
Total Iteration Time: 16.11224

Cumulative Model Updates: 47,407
Cumulative Timesteps: 790,752,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,192.31109
Policy Entropy: 1.06560
Value Function Loss: 4.45868

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.10042

Collected Steps per Second: 3,794.28244
Overall Steps per Second: 3,128.05565

Timestep Collection Time: 13.18299
Timestep Consumption Time: 2.80777
PPO Batch Consumption Time: 0.06297
Total Iteration Time: 15.99076

Cumulative Model Updates: 47,410
Cumulative Timesteps: 790,802,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 790802388...
Checkpoint 790802388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,352.85777
Policy Entropy: 1.07379
Value Function Loss: 4.33738

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.11270

Collected Steps per Second: 3,729.94005
Overall Steps per Second: 3,120.41337

Timestep Collection Time: 13.41201
Timestep Consumption Time: 2.61984
PPO Batch Consumption Time: 0.05932
Total Iteration Time: 16.03185

Cumulative Model Updates: 47,413
Cumulative Timesteps: 790,852,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,577.73476
Policy Entropy: 1.07563
Value Function Loss: 4.29970

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.11036

Collected Steps per Second: 3,989.13684
Overall Steps per Second: 3,261.24133

Timestep Collection Time: 12.54357
Timestep Consumption Time: 2.79967
PPO Batch Consumption Time: 0.06340
Total Iteration Time: 15.34324

Cumulative Model Updates: 47,416
Cumulative Timesteps: 790,902,452

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 790902452...
Checkpoint 790902452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,356.91215
Policy Entropy: 1.06172
Value Function Loss: 4.40500

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.09233

Collected Steps per Second: 3,742.89028
Overall Steps per Second: 3,084.11462

Timestep Collection Time: 13.36935
Timestep Consumption Time: 2.85573
PPO Batch Consumption Time: 0.07516
Total Iteration Time: 16.22508

Cumulative Model Updates: 47,419
Cumulative Timesteps: 790,952,492

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,878.88673
Policy Entropy: 1.06138
Value Function Loss: 4.46484

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.08349

Collected Steps per Second: 3,835.95010
Overall Steps per Second: 3,196.03361

Timestep Collection Time: 13.03823
Timestep Consumption Time: 2.61054
PPO Batch Consumption Time: 0.07118
Total Iteration Time: 15.64877

Cumulative Model Updates: 47,422
Cumulative Timesteps: 791,002,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 791002506...
Checkpoint 791002506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,464.48029
Policy Entropy: 1.06783
Value Function Loss: 4.61062

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.08291

Collected Steps per Second: 3,771.29538
Overall Steps per Second: 3,117.11835

Timestep Collection Time: 13.26388
Timestep Consumption Time: 2.78364
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 16.04751

Cumulative Model Updates: 47,425
Cumulative Timesteps: 791,052,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,947.98378
Policy Entropy: 1.07760
Value Function Loss: 4.33209

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.04386
Value Function Update Magnitude: 0.07772

Collected Steps per Second: 3,819.61846
Overall Steps per Second: 3,146.79092

Timestep Collection Time: 13.09031
Timestep Consumption Time: 2.79889
PPO Batch Consumption Time: 0.06163
Total Iteration Time: 15.88920

Cumulative Model Updates: 47,428
Cumulative Timesteps: 791,102,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 791102528...
Checkpoint 791102528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,776.28308
Policy Entropy: 1.05823
Value Function Loss: 4.44532

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.07777

Collected Steps per Second: 4,055.66382
Overall Steps per Second: 3,330.60565

Timestep Collection Time: 12.33090
Timestep Consumption Time: 2.68438
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 15.01529

Cumulative Model Updates: 47,431
Cumulative Timesteps: 791,152,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,466.64870
Policy Entropy: 1.08259
Value Function Loss: 4.34265

Mean KL Divergence: 0.02536
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.07449

Collected Steps per Second: 3,856.17350
Overall Steps per Second: 3,155.74941

Timestep Collection Time: 12.97711
Timestep Consumption Time: 2.88029
PPO Batch Consumption Time: 0.06033
Total Iteration Time: 15.85741

Cumulative Model Updates: 47,434
Cumulative Timesteps: 791,202,580

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 791202580...
Checkpoint 791202580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,867.80100
Policy Entropy: 1.07528
Value Function Loss: 4.60759

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.07353

Collected Steps per Second: 3,837.39381
Overall Steps per Second: 3,208.34396

Timestep Collection Time: 13.04166
Timestep Consumption Time: 2.55704
PPO Batch Consumption Time: 0.06472
Total Iteration Time: 15.59870

Cumulative Model Updates: 47,437
Cumulative Timesteps: 791,252,626

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,018.88695
Policy Entropy: 1.06854
Value Function Loss: 4.48929

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.07196

Collected Steps per Second: 3,833.68721
Overall Steps per Second: 3,167.54295

Timestep Collection Time: 13.05062
Timestep Consumption Time: 2.74459
PPO Batch Consumption Time: 0.06392
Total Iteration Time: 15.79521

Cumulative Model Updates: 47,440
Cumulative Timesteps: 791,302,658

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 791302658...
Checkpoint 791302658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,181.72105
Policy Entropy: 1.05816
Value Function Loss: 4.56016

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.15814
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.07687

Collected Steps per Second: 3,798.64115
Overall Steps per Second: 3,152.92245

Timestep Collection Time: 13.16365
Timestep Consumption Time: 2.69592
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 15.85957

Cumulative Model Updates: 47,443
Cumulative Timesteps: 791,352,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,954.45934
Policy Entropy: 1.07599
Value Function Loss: 4.45984

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.08952

Collected Steps per Second: 3,880.23764
Overall Steps per Second: 3,194.94487

Timestep Collection Time: 12.88581
Timestep Consumption Time: 2.76391
PPO Batch Consumption Time: 0.06712
Total Iteration Time: 15.64972

Cumulative Model Updates: 47,446
Cumulative Timesteps: 791,402,662

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 791402662...
Checkpoint 791402662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,321.60926
Policy Entropy: 1.07526
Value Function Loss: 4.62966

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.07009
Value Function Update Magnitude: 0.11064

Collected Steps per Second: 3,744.07509
Overall Steps per Second: 3,123.35808

Timestep Collection Time: 13.35497
Timestep Consumption Time: 2.65408
PPO Batch Consumption Time: 0.05178
Total Iteration Time: 16.00905

Cumulative Model Updates: 47,449
Cumulative Timesteps: 791,452,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,759.78248
Policy Entropy: 1.07977
Value Function Loss: 4.68731

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.07209
Value Function Update Magnitude: 0.11877

Collected Steps per Second: 3,893.03603
Overall Steps per Second: 3,247.75661

Timestep Collection Time: 12.84858
Timestep Consumption Time: 2.55282
PPO Batch Consumption Time: 0.05943
Total Iteration Time: 15.40140

Cumulative Model Updates: 47,452
Cumulative Timesteps: 791,502,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 791502684...
Checkpoint 791502684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,776.81405
Policy Entropy: 1.08300
Value Function Loss: 4.63766

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.07092
Value Function Update Magnitude: 0.12695

Collected Steps per Second: 3,762.75854
Overall Steps per Second: 3,127.07437

Timestep Collection Time: 13.29344
Timestep Consumption Time: 2.70234
PPO Batch Consumption Time: 0.05432
Total Iteration Time: 15.99578

Cumulative Model Updates: 47,455
Cumulative Timesteps: 791,552,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,116.11215
Policy Entropy: 1.07306
Value Function Loss: 4.46171

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.07720
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 3,836.58858
Overall Steps per Second: 3,174.40601

Timestep Collection Time: 13.03293
Timestep Consumption Time: 2.71868
PPO Batch Consumption Time: 0.06505
Total Iteration Time: 15.75161

Cumulative Model Updates: 47,458
Cumulative Timesteps: 791,602,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 791602706...
Checkpoint 791602706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,489.88756
Policy Entropy: 1.06154
Value Function Loss: 4.36962

Mean KL Divergence: 0.02566
SB3 Clip Fraction: 0.15675
Policy Update Magnitude: 0.07046
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 3,878.98772
Overall Steps per Second: 3,156.66358

Timestep Collection Time: 12.89099
Timestep Consumption Time: 2.94978
PPO Batch Consumption Time: 0.06129
Total Iteration Time: 15.84078

Cumulative Model Updates: 47,461
Cumulative Timesteps: 791,652,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,746.89342
Policy Entropy: 1.07565
Value Function Loss: 4.52385

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.09363

Collected Steps per Second: 3,724.62686
Overall Steps per Second: 3,085.79769

Timestep Collection Time: 13.42900
Timestep Consumption Time: 2.78010
PPO Batch Consumption Time: 0.06081
Total Iteration Time: 16.20910

Cumulative Model Updates: 47,464
Cumulative Timesteps: 791,702,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 791702728...
Checkpoint 791702728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,267.98897
Policy Entropy: 1.08422
Value Function Loss: 4.47641

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.08991

Collected Steps per Second: 3,776.21988
Overall Steps per Second: 3,152.37633

Timestep Collection Time: 13.24393
Timestep Consumption Time: 2.62092
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 15.86486

Cumulative Model Updates: 47,467
Cumulative Timesteps: 791,752,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,680.65787
Policy Entropy: 1.06955
Value Function Loss: 4.49436

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.08538

Collected Steps per Second: 3,675.12870
Overall Steps per Second: 3,047.04549

Timestep Collection Time: 13.61095
Timestep Consumption Time: 2.80561
PPO Batch Consumption Time: 0.06172
Total Iteration Time: 16.41656

Cumulative Model Updates: 47,470
Cumulative Timesteps: 791,802,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 791802762...
Checkpoint 791802762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,107.44931
Policy Entropy: 1.05992
Value Function Loss: 4.37053

Mean KL Divergence: 0.02340
SB3 Clip Fraction: 0.15641
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.08346

Collected Steps per Second: 3,844.72870
Overall Steps per Second: 3,179.76485

Timestep Collection Time: 13.00950
Timestep Consumption Time: 2.72059
PPO Batch Consumption Time: 0.06479
Total Iteration Time: 15.73009

Cumulative Model Updates: 47,473
Cumulative Timesteps: 791,852,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,191.31972
Policy Entropy: 1.06934
Value Function Loss: 4.45803

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 3,836.66349
Overall Steps per Second: 3,176.90868

Timestep Collection Time: 13.04154
Timestep Consumption Time: 2.70836
PPO Batch Consumption Time: 0.06310
Total Iteration Time: 15.74990

Cumulative Model Updates: 47,476
Cumulative Timesteps: 791,902,816

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 791902816...
Checkpoint 791902816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,271.15753
Policy Entropy: 1.07719
Value Function Loss: 4.43310

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.08859

Collected Steps per Second: 3,831.28214
Overall Steps per Second: 3,168.43158

Timestep Collection Time: 13.05673
Timestep Consumption Time: 2.73153
PPO Batch Consumption Time: 0.05324
Total Iteration Time: 15.78825

Cumulative Model Updates: 47,479
Cumulative Timesteps: 791,952,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,089.52299
Policy Entropy: 1.05768
Value Function Loss: 4.47093

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.09465

Collected Steps per Second: 3,894.01148
Overall Steps per Second: 3,219.18038

Timestep Collection Time: 12.85102
Timestep Consumption Time: 2.69394
PPO Batch Consumption Time: 0.06264
Total Iteration Time: 15.54495

Cumulative Model Updates: 47,482
Cumulative Timesteps: 792,002,882

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 792002882...
Checkpoint 792002882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731,536.57815
Policy Entropy: 1.07088
Value Function Loss: 4.51622

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.14901
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.10197

Collected Steps per Second: 3,826.31986
Overall Steps per Second: 3,148.78600

Timestep Collection Time: 13.07523
Timestep Consumption Time: 2.81344
PPO Batch Consumption Time: 0.06460
Total Iteration Time: 15.88866

Cumulative Model Updates: 47,485
Cumulative Timesteps: 792,052,912

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,073.36223
Policy Entropy: 1.06990
Value Function Loss: 4.53431

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.11691

Collected Steps per Second: 3,694.10754
Overall Steps per Second: 3,112.76849

Timestep Collection Time: 13.53723
Timestep Consumption Time: 2.52821
PPO Batch Consumption Time: 0.06468
Total Iteration Time: 16.06544

Cumulative Model Updates: 47,488
Cumulative Timesteps: 792,102,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 792102920...
Checkpoint 792102920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,234.85869
Policy Entropy: 1.07735
Value Function Loss: 4.51278

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.12729

Collected Steps per Second: 3,174.26914
Overall Steps per Second: 2,684.58174

Timestep Collection Time: 15.76867
Timestep Consumption Time: 2.87632
PPO Batch Consumption Time: 0.05921
Total Iteration Time: 18.64499

Cumulative Model Updates: 47,491
Cumulative Timesteps: 792,152,974

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,568.03318
Policy Entropy: 1.07185
Value Function Loss: 4.37918

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.12856

Collected Steps per Second: 3,787.96809
Overall Steps per Second: 3,126.23795

Timestep Collection Time: 13.20391
Timestep Consumption Time: 2.79487
PPO Batch Consumption Time: 0.06584
Total Iteration Time: 15.99878

Cumulative Model Updates: 47,494
Cumulative Timesteps: 792,202,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 792202990...
Checkpoint 792202990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,239.54303
Policy Entropy: 1.06155
Value Function Loss: 4.37778

Mean KL Divergence: 0.02958
SB3 Clip Fraction: 0.15889
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.12688

Collected Steps per Second: 3,862.22943
Overall Steps per Second: 3,244.56601

Timestep Collection Time: 12.95314
Timestep Consumption Time: 2.46587
PPO Batch Consumption Time: 0.05415
Total Iteration Time: 15.41901

Cumulative Model Updates: 47,497
Cumulative Timesteps: 792,253,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,894.92561
Policy Entropy: 1.07553
Value Function Loss: 4.45033

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.11963
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.12648

Collected Steps per Second: 3,944.70957
Overall Steps per Second: 3,233.87991

Timestep Collection Time: 12.67622
Timestep Consumption Time: 2.78632
PPO Batch Consumption Time: 0.06531
Total Iteration Time: 15.46254

Cumulative Model Updates: 47,500
Cumulative Timesteps: 792,303,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 792303022...
Checkpoint 792303022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,011.54313
Policy Entropy: 1.08295
Value Function Loss: 4.62605

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.11581

Collected Steps per Second: 3,703.94306
Overall Steps per Second: 3,112.41652

Timestep Collection Time: 13.50237
Timestep Consumption Time: 2.56618
PPO Batch Consumption Time: 0.05938
Total Iteration Time: 16.06854

Cumulative Model Updates: 47,503
Cumulative Timesteps: 792,353,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716,454.83302
Policy Entropy: 1.06364
Value Function Loss: 4.54338

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 3,943.53163
Overall Steps per Second: 3,258.80277

Timestep Collection Time: 12.68508
Timestep Consumption Time: 2.66535
PPO Batch Consumption Time: 0.06271
Total Iteration Time: 15.35042

Cumulative Model Updates: 47,506
Cumulative Timesteps: 792,403,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 792403058...
Checkpoint 792403058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,476.84101
Policy Entropy: 1.04905
Value Function Loss: 4.47759

Mean KL Divergence: 0.03245
SB3 Clip Fraction: 0.17729
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.10229

Collected Steps per Second: 3,832.69348
Overall Steps per Second: 3,200.82984

Timestep Collection Time: 13.05140
Timestep Consumption Time: 2.57643
PPO Batch Consumption Time: 0.05836
Total Iteration Time: 15.62782

Cumulative Model Updates: 47,509
Cumulative Timesteps: 792,453,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,386.11252
Policy Entropy: 1.06727
Value Function Loss: 4.41483

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.08882

Collected Steps per Second: 3,772.26404
Overall Steps per Second: 3,110.95960

Timestep Collection Time: 13.25517
Timestep Consumption Time: 2.81768
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 16.07285

Cumulative Model Updates: 47,512
Cumulative Timesteps: 792,503,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 792503082...
Checkpoint 792503082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,353.38004
Policy Entropy: 1.07413
Value Function Loss: 4.69501

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.05783
Value Function Update Magnitude: 0.08348

Collected Steps per Second: 3,825.03362
Overall Steps per Second: 3,170.00485

Timestep Collection Time: 13.07753
Timestep Consumption Time: 2.70225
PPO Batch Consumption Time: 0.05032
Total Iteration Time: 15.77979

Cumulative Model Updates: 47,515
Cumulative Timesteps: 792,553,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,558.01295
Policy Entropy: 1.06840
Value Function Loss: 4.70239

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.12525
Policy Update Magnitude: 0.06368
Value Function Update Magnitude: 0.09215

Collected Steps per Second: 3,693.52830
Overall Steps per Second: 3,118.22797

Timestep Collection Time: 13.53773
Timestep Consumption Time: 2.49766
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 16.03539

Cumulative Model Updates: 47,518
Cumulative Timesteps: 792,603,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 792603106...
Checkpoint 792603106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,192.76890
Policy Entropy: 1.06143
Value Function Loss: 4.76987

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.11670

Collected Steps per Second: 3,790.16835
Overall Steps per Second: 3,140.07923

Timestep Collection Time: 13.19361
Timestep Consumption Time: 2.73147
PPO Batch Consumption Time: 0.06477
Total Iteration Time: 15.92508

Cumulative Model Updates: 47,521
Cumulative Timesteps: 792,653,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,766.49743
Policy Entropy: 1.07044
Value Function Loss: 4.62444

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.13053

Collected Steps per Second: 3,674.87095
Overall Steps per Second: 3,119.84388

Timestep Collection Time: 13.61680
Timestep Consumption Time: 2.42246
PPO Batch Consumption Time: 0.05876
Total Iteration Time: 16.03926

Cumulative Model Updates: 47,524
Cumulative Timesteps: 792,703,152

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 792703152...
Checkpoint 792703152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,625.01250
Policy Entropy: 1.07357
Value Function Loss: 4.68538

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.06448
Value Function Update Magnitude: 0.12698

Collected Steps per Second: 3,776.42561
Overall Steps per Second: 3,108.58297

Timestep Collection Time: 13.24851
Timestep Consumption Time: 2.84629
PPO Batch Consumption Time: 0.06783
Total Iteration Time: 16.09479

Cumulative Model Updates: 47,527
Cumulative Timesteps: 792,753,184

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,751.53181
Policy Entropy: 1.05561
Value Function Loss: 4.51746

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.12229

Collected Steps per Second: 3,824.19637
Overall Steps per Second: 3,156.02986

Timestep Collection Time: 13.07830
Timestep Consumption Time: 2.76882
PPO Batch Consumption Time: 0.06428
Total Iteration Time: 15.84713

Cumulative Model Updates: 47,530
Cumulative Timesteps: 792,803,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 792803198...
Checkpoint 792803198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575,803.58172
Policy Entropy: 1.05551
Value Function Loss: 4.41306

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.11519

Collected Steps per Second: 3,747.18496
Overall Steps per Second: 3,115.11529

Timestep Collection Time: 13.34815
Timestep Consumption Time: 2.70840
PPO Batch Consumption Time: 0.05440
Total Iteration Time: 16.05655

Cumulative Model Updates: 47,533
Cumulative Timesteps: 792,853,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,439.46498
Policy Entropy: 1.06943
Value Function Loss: 4.26493

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.11165

Collected Steps per Second: 4,213.72312
Overall Steps per Second: 3,468.38800

Timestep Collection Time: 11.86884
Timestep Consumption Time: 2.55054
PPO Batch Consumption Time: 0.06028
Total Iteration Time: 14.41938

Cumulative Model Updates: 47,536
Cumulative Timesteps: 792,903,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 792903228...
Checkpoint 792903228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,962.42314
Policy Entropy: 1.07760
Value Function Loss: 4.33441

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12606
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.10679

Collected Steps per Second: 4,144.44304
Overall Steps per Second: 3,427.04210

Timestep Collection Time: 12.07110
Timestep Consumption Time: 2.52691
PPO Batch Consumption Time: 0.05819
Total Iteration Time: 14.59801

Cumulative Model Updates: 47,539
Cumulative Timesteps: 792,953,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,141.42756
Policy Entropy: 1.06078
Value Function Loss: 4.42328

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.09831

Collected Steps per Second: 3,956.38294
Overall Steps per Second: 3,256.90487

Timestep Collection Time: 12.65095
Timestep Consumption Time: 2.71702
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 15.36796

Cumulative Model Updates: 47,542
Cumulative Timesteps: 793,003,308

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 793003308...
Checkpoint 793003308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,222.08969
Policy Entropy: 1.04921
Value Function Loss: 4.35547

Mean KL Divergence: 0.02227
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.11003

Collected Steps per Second: 3,799.35887
Overall Steps per Second: 3,152.71765

Timestep Collection Time: 13.16169
Timestep Consumption Time: 2.69954
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 15.86124

Cumulative Model Updates: 47,545
Cumulative Timesteps: 793,053,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,364.56962
Policy Entropy: 1.06042
Value Function Loss: 4.26337

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.10978

Collected Steps per Second: 3,932.50090
Overall Steps per Second: 3,214.35419

Timestep Collection Time: 12.72727
Timestep Consumption Time: 2.84351
PPO Batch Consumption Time: 0.06015
Total Iteration Time: 15.57078

Cumulative Model Updates: 47,548
Cumulative Timesteps: 793,103,364

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 793103364...
Checkpoint 793103364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,936.85936
Policy Entropy: 1.06029
Value Function Loss: 4.18388

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.11796

Collected Steps per Second: 3,716.70322
Overall Steps per Second: 3,066.50435

Timestep Collection Time: 13.46731
Timestep Consumption Time: 2.85551
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 16.32282

Cumulative Model Updates: 47,551
Cumulative Timesteps: 793,153,418

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,102.51211
Policy Entropy: 1.05521
Value Function Loss: 4.08466

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.06896
Value Function Update Magnitude: 0.10029

Collected Steps per Second: 3,711.64720
Overall Steps per Second: 3,128.00417

Timestep Collection Time: 13.47219
Timestep Consumption Time: 2.51373
PPO Batch Consumption Time: 0.06179
Total Iteration Time: 15.98591

Cumulative Model Updates: 47,554
Cumulative Timesteps: 793,203,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 793203422...
Checkpoint 793203422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,475.08744
Policy Entropy: 1.05666
Value Function Loss: 4.22633

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.06840
Value Function Update Magnitude: 0.09109

Collected Steps per Second: 3,803.81267
Overall Steps per Second: 3,147.39898

Timestep Collection Time: 13.14471
Timestep Consumption Time: 2.74143
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 15.88613

Cumulative Model Updates: 47,557
Cumulative Timesteps: 793,253,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,610.85677
Policy Entropy: 1.06286
Value Function Loss: 4.47233

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.09174

Collected Steps per Second: 3,790.99040
Overall Steps per Second: 3,151.26475

Timestep Collection Time: 13.19972
Timestep Consumption Time: 2.67962
PPO Batch Consumption Time: 0.06005
Total Iteration Time: 15.87934

Cumulative Model Updates: 47,560
Cumulative Timesteps: 793,303,462

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 793303462...
Checkpoint 793303462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,415.46559
Policy Entropy: 1.07707
Value Function Loss: 4.58973

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.10087

Collected Steps per Second: 3,843.76998
Overall Steps per Second: 3,153.80853

Timestep Collection Time: 13.00858
Timestep Consumption Time: 2.84590
PPO Batch Consumption Time: 0.05796
Total Iteration Time: 15.85448

Cumulative Model Updates: 47,563
Cumulative Timesteps: 793,353,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,634.72094
Policy Entropy: 1.07286
Value Function Loss: 4.66933

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.06681
Value Function Update Magnitude: 0.10846

Collected Steps per Second: 3,755.73051
Overall Steps per Second: 3,099.86082

Timestep Collection Time: 13.31405
Timestep Consumption Time: 2.81699
PPO Batch Consumption Time: 0.06629
Total Iteration Time: 16.13105

Cumulative Model Updates: 47,566
Cumulative Timesteps: 793,403,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 793403468...
Checkpoint 793403468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701,842.72189
Policy Entropy: 1.06810
Value Function Loss: 4.36990

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.07341
Value Function Update Magnitude: 0.09968

Collected Steps per Second: 3,826.80606
Overall Steps per Second: 3,221.75689

Timestep Collection Time: 13.07566
Timestep Consumption Time: 2.45562
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 15.53128

Cumulative Model Updates: 47,569
Cumulative Timesteps: 793,453,506

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,803.87599
Policy Entropy: 1.07174
Value Function Loss: 4.43264

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.08056
Value Function Update Magnitude: 0.08642

Collected Steps per Second: 3,806.42420
Overall Steps per Second: 3,143.92321

Timestep Collection Time: 13.13884
Timestep Consumption Time: 2.76867
PPO Batch Consumption Time: 0.05871
Total Iteration Time: 15.90751

Cumulative Model Updates: 47,572
Cumulative Timesteps: 793,503,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 793503518...
Checkpoint 793503518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,018.93739
Policy Entropy: 1.05932
Value Function Loss: 4.29535

Mean KL Divergence: 0.02626
SB3 Clip Fraction: 0.17967
Policy Update Magnitude: 0.07308
Value Function Update Magnitude: 0.08649

Collected Steps per Second: 3,915.03374
Overall Steps per Second: 3,227.79071

Timestep Collection Time: 12.77894
Timestep Consumption Time: 2.72082
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 15.49977

Cumulative Model Updates: 47,575
Cumulative Timesteps: 793,553,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,894.10611
Policy Entropy: 1.08018
Value Function Loss: 4.34226

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14288
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.08581

Collected Steps per Second: 3,852.57365
Overall Steps per Second: 3,195.62199

Timestep Collection Time: 12.98872
Timestep Consumption Time: 2.67020
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 15.65892

Cumulative Model Updates: 47,578
Cumulative Timesteps: 793,603,588

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 793603588...
Checkpoint 793603588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,946.99811
Policy Entropy: 1.08181
Value Function Loss: 4.41318

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.08709

Collected Steps per Second: 3,836.38353
Overall Steps per Second: 3,086.05849

Timestep Collection Time: 13.03571
Timestep Consumption Time: 3.16942
PPO Batch Consumption Time: 0.06253
Total Iteration Time: 16.20514

Cumulative Model Updates: 47,581
Cumulative Timesteps: 793,653,598

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,106.31756
Policy Entropy: 1.06960
Value Function Loss: 4.26091

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.08380

Collected Steps per Second: 3,684.66693
Overall Steps per Second: 3,089.46894

Timestep Collection Time: 13.58223
Timestep Consumption Time: 2.61667
PPO Batch Consumption Time: 0.06719
Total Iteration Time: 16.19890

Cumulative Model Updates: 47,584
Cumulative Timesteps: 793,703,644

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 793703644...
Checkpoint 793703644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,838.09718
Policy Entropy: 1.06579
Value Function Loss: 4.15133

Mean KL Divergence: 0.02338
SB3 Clip Fraction: 0.16219
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.08578

Collected Steps per Second: 3,971.94360
Overall Steps per Second: 3,260.09083

Timestep Collection Time: 12.59837
Timestep Consumption Time: 2.75090
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 15.34927

Cumulative Model Updates: 47,587
Cumulative Timesteps: 793,753,684

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,646.52108
Policy Entropy: 1.07718
Value Function Loss: 3.92929

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.09179

Collected Steps per Second: 3,748.78056
Overall Steps per Second: 3,126.85068

Timestep Collection Time: 13.34194
Timestep Consumption Time: 2.65371
PPO Batch Consumption Time: 0.06614
Total Iteration Time: 15.99565

Cumulative Model Updates: 47,590
Cumulative Timesteps: 793,803,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 793803700...
Checkpoint 793803700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,500.48790
Policy Entropy: 1.08302
Value Function Loss: 4.11334

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.09655

Collected Steps per Second: 3,979.08471
Overall Steps per Second: 3,251.66973

Timestep Collection Time: 12.57375
Timestep Consumption Time: 2.81281
PPO Batch Consumption Time: 0.05839
Total Iteration Time: 15.38656

Cumulative Model Updates: 47,593
Cumulative Timesteps: 793,853,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,978.16756
Policy Entropy: 1.07040
Value Function Loss: 4.14506

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.10632

Collected Steps per Second: 3,803.41662
Overall Steps per Second: 3,119.67650

Timestep Collection Time: 13.15396
Timestep Consumption Time: 2.88296
PPO Batch Consumption Time: 0.06289
Total Iteration Time: 16.03692

Cumulative Model Updates: 47,596
Cumulative Timesteps: 793,903,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 793903762...
Checkpoint 793903762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,684.40425
Policy Entropy: 1.05283
Value Function Loss: 4.18036

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.15543
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.13200

Collected Steps per Second: 3,809.09670
Overall Steps per Second: 3,199.18639

Timestep Collection Time: 13.12647
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.05842
Total Iteration Time: 15.62897

Cumulative Model Updates: 47,599
Cumulative Timesteps: 793,953,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,635.58904
Policy Entropy: 1.07381
Value Function Loss: 4.16457

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.12720

Collected Steps per Second: 3,755.49200
Overall Steps per Second: 3,105.04893

Timestep Collection Time: 13.31597
Timestep Consumption Time: 2.78942
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 16.10538

Cumulative Model Updates: 47,602
Cumulative Timesteps: 794,003,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 794003770...
Checkpoint 794003770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,651.60103
Policy Entropy: 1.06190
Value Function Loss: 4.31790

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.06887
Value Function Update Magnitude: 0.12573

Collected Steps per Second: 3,846.95091
Overall Steps per Second: 3,198.28572

Timestep Collection Time: 13.00199
Timestep Consumption Time: 2.63702
PPO Batch Consumption Time: 0.06712
Total Iteration Time: 15.63900

Cumulative Model Updates: 47,605
Cumulative Timesteps: 794,053,788

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,925.63609
Policy Entropy: 1.06226
Value Function Loss: 4.26447

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.07068
Value Function Update Magnitude: 0.12215

Collected Steps per Second: 3,808.11211
Overall Steps per Second: 3,109.13813

Timestep Collection Time: 13.13564
Timestep Consumption Time: 2.95306
PPO Batch Consumption Time: 0.05903
Total Iteration Time: 16.08870

Cumulative Model Updates: 47,608
Cumulative Timesteps: 794,103,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 794103810...
Checkpoint 794103810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,022.18123
Policy Entropy: 1.05286
Value Function Loss: 4.29149

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.07845
Value Function Update Magnitude: 0.13475

Collected Steps per Second: 3,770.13554
Overall Steps per Second: 3,139.15688

Timestep Collection Time: 13.27538
Timestep Consumption Time: 2.66839
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 15.94377

Cumulative Model Updates: 47,611
Cumulative Timesteps: 794,153,860

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,406.16030
Policy Entropy: 1.05014
Value Function Loss: 4.17568

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.07042
Value Function Update Magnitude: 0.13789

Collected Steps per Second: 3,829.86156
Overall Steps per Second: 3,195.98074

Timestep Collection Time: 13.06836
Timestep Consumption Time: 2.59194
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 15.66029

Cumulative Model Updates: 47,614
Cumulative Timesteps: 794,203,910

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 794203910...
Checkpoint 794203910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,418.32897
Policy Entropy: 1.06029
Value Function Loss: 4.34038

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.13294

Collected Steps per Second: 3,794.83057
Overall Steps per Second: 3,144.03083

Timestep Collection Time: 13.18689
Timestep Consumption Time: 2.72962
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 15.91651

Cumulative Model Updates: 47,617
Cumulative Timesteps: 794,253,952

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,786.32002
Policy Entropy: 1.06607
Value Function Loss: 4.23361

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 3,789.41823
Overall Steps per Second: 3,179.78482

Timestep Collection Time: 13.19939
Timestep Consumption Time: 2.53061
PPO Batch Consumption Time: 0.06230
Total Iteration Time: 15.73000

Cumulative Model Updates: 47,620
Cumulative Timesteps: 794,303,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 794303970...
Checkpoint 794303970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,204.14145
Policy Entropy: 1.06632
Value Function Loss: 4.35393

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.10052

Collected Steps per Second: 3,777.18325
Overall Steps per Second: 3,124.25881

Timestep Collection Time: 13.24161
Timestep Consumption Time: 2.76730
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 16.00892

Cumulative Model Updates: 47,623
Cumulative Timesteps: 794,353,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498,549.30475
Policy Entropy: 1.06297
Value Function Loss: 4.34135

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.06526
Value Function Update Magnitude: 0.10887

Collected Steps per Second: 3,807.81685
Overall Steps per Second: 3,142.07478

Timestep Collection Time: 13.13614
Timestep Consumption Time: 2.78328
PPO Batch Consumption Time: 0.06042
Total Iteration Time: 15.91942

Cumulative Model Updates: 47,626
Cumulative Timesteps: 794,404,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 794404006...
Checkpoint 794404006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,395.80580
Policy Entropy: 1.07308
Value Function Loss: 4.51319

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.10163

Collected Steps per Second: 3,985.71733
Overall Steps per Second: 3,257.77024

Timestep Collection Time: 12.55583
Timestep Consumption Time: 2.80559
PPO Batch Consumption Time: 0.06634
Total Iteration Time: 15.36143

Cumulative Model Updates: 47,629
Cumulative Timesteps: 794,454,050

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,910.97312
Policy Entropy: 1.07341
Value Function Loss: 4.41345

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.15135
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.09432

Collected Steps per Second: 3,841.01119
Overall Steps per Second: 3,198.00108

Timestep Collection Time: 13.02574
Timestep Consumption Time: 2.61904
PPO Batch Consumption Time: 0.05944
Total Iteration Time: 15.64477

Cumulative Model Updates: 47,632
Cumulative Timesteps: 794,504,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 794504082...
Checkpoint 794504082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,182.83881
Policy Entropy: 1.05536
Value Function Loss: 4.35030

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.09004

Collected Steps per Second: 3,839.29020
Overall Steps per Second: 3,230.52108

Timestep Collection Time: 13.03053
Timestep Consumption Time: 2.45551
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 15.48605

Cumulative Model Updates: 47,635
Cumulative Timesteps: 794,554,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,518.68579
Policy Entropy: 1.05172
Value Function Loss: 4.38195

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.15850
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.08486

Collected Steps per Second: 3,777.31638
Overall Steps per Second: 3,130.10544

Timestep Collection Time: 13.23903
Timestep Consumption Time: 2.73743
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 15.97646

Cumulative Model Updates: 47,638
Cumulative Timesteps: 794,604,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 794604118...
Checkpoint 794604118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,791.89592
Policy Entropy: 1.06550
Value Function Loss: 4.48374

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.08724

Collected Steps per Second: 3,770.31028
Overall Steps per Second: 3,159.76696

Timestep Collection Time: 13.27530
Timestep Consumption Time: 2.56511
PPO Batch Consumption Time: 0.06261
Total Iteration Time: 15.84041

Cumulative Model Updates: 47,641
Cumulative Timesteps: 794,654,170

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,854.50567
Policy Entropy: 1.08123
Value Function Loss: 4.71858

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.15850
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.08525

Collected Steps per Second: 3,877.94023
Overall Steps per Second: 3,174.77819

Timestep Collection Time: 12.89396
Timestep Consumption Time: 2.85580
PPO Batch Consumption Time: 0.06554
Total Iteration Time: 15.74976

Cumulative Model Updates: 47,644
Cumulative Timesteps: 794,704,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 794704172...
Checkpoint 794704172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,941.91036
Policy Entropy: 1.06152
Value Function Loss: 4.65575

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14851
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.08747

Collected Steps per Second: 3,815.00067
Overall Steps per Second: 3,159.93347

Timestep Collection Time: 13.11192
Timestep Consumption Time: 2.71816
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 15.83008

Cumulative Model Updates: 47,647
Cumulative Timesteps: 794,754,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,013.25523
Policy Entropy: 1.07059
Value Function Loss: 4.77933

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.09191

Collected Steps per Second: 3,811.73221
Overall Steps per Second: 3,210.15334

Timestep Collection Time: 13.12527
Timestep Consumption Time: 2.45966
PPO Batch Consumption Time: 0.06926
Total Iteration Time: 15.58493

Cumulative Model Updates: 47,650
Cumulative Timesteps: 794,804,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 794804224...
Checkpoint 794804224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,593.52253
Policy Entropy: 1.07136
Value Function Loss: 4.58526

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.08512

Collected Steps per Second: 3,850.22404
Overall Steps per Second: 3,166.30777

Timestep Collection Time: 12.99457
Timestep Consumption Time: 2.80680
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 15.80137

Cumulative Model Updates: 47,653
Cumulative Timesteps: 794,854,256

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551,394.47654
Policy Entropy: 1.08102
Value Function Loss: 4.62427

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.08684

Collected Steps per Second: 3,873.39189
Overall Steps per Second: 3,192.96880

Timestep Collection Time: 12.91323
Timestep Consumption Time: 2.75182
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 15.66505

Cumulative Model Updates: 47,656
Cumulative Timesteps: 794,904,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 794904274...
Checkpoint 794904274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,142.83717
Policy Entropy: 1.05431
Value Function Loss: 4.39625

Mean KL Divergence: 0.03895
SB3 Clip Fraction: 0.18809
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 3,870.14912
Overall Steps per Second: 3,195.73354

Timestep Collection Time: 12.92198
Timestep Consumption Time: 2.72701
PPO Batch Consumption Time: 0.05888
Total Iteration Time: 15.64899

Cumulative Model Updates: 47,659
Cumulative Timesteps: 794,954,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,662.46081
Policy Entropy: 1.07168
Value Function Loss: 4.40834

Mean KL Divergence: 0.03062
SB3 Clip Fraction: 0.18039
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.10818

Collected Steps per Second: 3,877.63916
Overall Steps per Second: 3,230.83993

Timestep Collection Time: 12.89548
Timestep Consumption Time: 2.58161
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 15.47709

Cumulative Model Updates: 47,662
Cumulative Timesteps: 795,004,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 795004288...
Checkpoint 795004288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,627.33047
Policy Entropy: 1.05768
Value Function Loss: 4.17093

Mean KL Divergence: 0.03150
SB3 Clip Fraction: 0.18117
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.10849

Collected Steps per Second: 3,805.43141
Overall Steps per Second: 3,168.23746

Timestep Collection Time: 13.14279
Timestep Consumption Time: 2.64327
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 15.78606

Cumulative Model Updates: 47,665
Cumulative Timesteps: 795,054,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,725.93362
Policy Entropy: 1.07155
Value Function Loss: 4.25223

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.15970
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 3,832.31993
Overall Steps per Second: 3,143.95746

Timestep Collection Time: 13.04745
Timestep Consumption Time: 2.85671
PPO Batch Consumption Time: 0.06089
Total Iteration Time: 15.90416

Cumulative Model Updates: 47,668
Cumulative Timesteps: 795,104,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 795104304...
Checkpoint 795104304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,479.40241
Policy Entropy: 1.08406
Value Function Loss: 4.35856

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.11674

Collected Steps per Second: 3,790.55741
Overall Steps per Second: 3,114.09817

Timestep Collection Time: 13.19753
Timestep Consumption Time: 2.86683
PPO Batch Consumption Time: 0.06509
Total Iteration Time: 16.06436

Cumulative Model Updates: 47,671
Cumulative Timesteps: 795,154,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,182.80490
Policy Entropy: 1.06258
Value Function Loss: 4.39993

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.09639

Collected Steps per Second: 3,901.31956
Overall Steps per Second: 3,187.13995

Timestep Collection Time: 12.82387
Timestep Consumption Time: 2.87359
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 15.69746

Cumulative Model Updates: 47,674
Cumulative Timesteps: 795,204,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 795204360...
Checkpoint 795204360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,973.96224
Policy Entropy: 1.06210
Value Function Loss: 4.43949

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.08577

Collected Steps per Second: 3,801.93980
Overall Steps per Second: 3,130.71518

Timestep Collection Time: 13.16328
Timestep Consumption Time: 2.82220
PPO Batch Consumption Time: 0.04963
Total Iteration Time: 15.98548

Cumulative Model Updates: 47,677
Cumulative Timesteps: 795,254,406

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,937.97236
Policy Entropy: 1.07478
Value Function Loss: 4.25030

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.08656

Collected Steps per Second: 3,780.12474
Overall Steps per Second: 3,174.31831

Timestep Collection Time: 13.23078
Timestep Consumption Time: 2.52504
PPO Batch Consumption Time: 0.06619
Total Iteration Time: 15.75582

Cumulative Model Updates: 47,680
Cumulative Timesteps: 795,304,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 795304420...
Checkpoint 795304420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,256.91405
Policy Entropy: 1.08213
Value Function Loss: 4.39445

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.14698
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.08919

Collected Steps per Second: 3,839.83854
Overall Steps per Second: 3,149.16119

Timestep Collection Time: 13.02763
Timestep Consumption Time: 2.85723
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 15.88486

Cumulative Model Updates: 47,683
Cumulative Timesteps: 795,354,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,421.24630
Policy Entropy: 1.06455
Value Function Loss: 4.35726

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.08338

Collected Steps per Second: 3,764.77353
Overall Steps per Second: 3,146.04488

Timestep Collection Time: 13.28951
Timestep Consumption Time: 2.61363
PPO Batch Consumption Time: 0.07107
Total Iteration Time: 15.90314

Cumulative Model Updates: 47,686
Cumulative Timesteps: 795,404,476

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 795404476...
Checkpoint 795404476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,167.69557
Policy Entropy: 1.05084
Value Function Loss: 4.47204

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.08380

Collected Steps per Second: 3,918.55656
Overall Steps per Second: 3,201.60466

Timestep Collection Time: 12.76593
Timestep Consumption Time: 2.85874
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 15.62466

Cumulative Model Updates: 47,689
Cumulative Timesteps: 795,454,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,836.38339
Policy Entropy: 1.06340
Value Function Loss: 4.42632

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.08185

Collected Steps per Second: 3,789.39832
Overall Steps per Second: 3,135.82290

Timestep Collection Time: 13.20632
Timestep Consumption Time: 2.75249
PPO Batch Consumption Time: 0.06511
Total Iteration Time: 15.95881

Cumulative Model Updates: 47,692
Cumulative Timesteps: 795,504,544

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 795504544...
Checkpoint 795504544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,909.35537
Policy Entropy: 1.08156
Value Function Loss: 4.42669

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.09746

Collected Steps per Second: 3,875.79002
Overall Steps per Second: 3,306.23690

Timestep Collection Time: 12.90730
Timestep Consumption Time: 2.22349
PPO Batch Consumption Time: 0.05369
Total Iteration Time: 15.13080

Cumulative Model Updates: 47,695
Cumulative Timesteps: 795,554,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,044.57325
Policy Entropy: 1.04996
Value Function Loss: 4.51233

Mean KL Divergence: 0.03030
SB3 Clip Fraction: 0.16113
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.08860

Collected Steps per Second: 3,796.58492
Overall Steps per Second: 3,119.34524

Timestep Collection Time: 13.17711
Timestep Consumption Time: 2.86088
PPO Batch Consumption Time: 0.07313
Total Iteration Time: 16.03798

Cumulative Model Updates: 47,698
Cumulative Timesteps: 795,604,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 795604598...
Checkpoint 795604598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,325.72492
Policy Entropy: 1.06470
Value Function Loss: 4.54079

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.07978

Collected Steps per Second: 3,795.73398
Overall Steps per Second: 3,201.71724

Timestep Collection Time: 13.18059
Timestep Consumption Time: 2.44540
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 15.62599

Cumulative Model Updates: 47,701
Cumulative Timesteps: 795,654,628

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,370.53746
Policy Entropy: 1.06705
Value Function Loss: 4.48672

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.08021

Collected Steps per Second: 3,810.07420
Overall Steps per Second: 3,134.83043

Timestep Collection Time: 13.13150
Timestep Consumption Time: 2.82853
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 15.96003

Cumulative Model Updates: 47,704
Cumulative Timesteps: 795,704,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 795704660...
Checkpoint 795704660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,890.45094
Policy Entropy: 1.04824
Value Function Loss: 4.26636

Mean KL Divergence: 0.02601
SB3 Clip Fraction: 0.15595
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 3,822.09121
Overall Steps per Second: 3,238.72165

Timestep Collection Time: 13.08708
Timestep Consumption Time: 2.35729
PPO Batch Consumption Time: 0.05313
Total Iteration Time: 15.44437

Cumulative Model Updates: 47,707
Cumulative Timesteps: 795,754,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,277.22749
Policy Entropy: 1.05592
Value Function Loss: 4.35023

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.08555

Collected Steps per Second: 3,811.66623
Overall Steps per Second: 3,138.35996

Timestep Collection Time: 13.12444
Timestep Consumption Time: 2.81573
PPO Batch Consumption Time: 0.05797
Total Iteration Time: 15.94017

Cumulative Model Updates: 47,710
Cumulative Timesteps: 795,804,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 795804706...
Checkpoint 795804706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,257.40626
Policy Entropy: 1.06481
Value Function Loss: 4.47204

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.09478

Collected Steps per Second: 3,919.26659
Overall Steps per Second: 3,213.95809

Timestep Collection Time: 12.76004
Timestep Consumption Time: 2.80021
PPO Batch Consumption Time: 0.05318
Total Iteration Time: 15.56025

Cumulative Model Updates: 47,713
Cumulative Timesteps: 795,854,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,622.53771
Policy Entropy: 1.07148
Value Function Loss: 4.61594

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.08782

Collected Steps per Second: 3,875.77406
Overall Steps per Second: 3,235.88343

Timestep Collection Time: 12.90271
Timestep Consumption Time: 2.55149
PPO Batch Consumption Time: 0.05153
Total Iteration Time: 15.45420

Cumulative Model Updates: 47,716
Cumulative Timesteps: 795,904,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 795904724...
Checkpoint 795904724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,982.14173
Policy Entropy: 1.06437
Value Function Loss: 4.62309

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.06495
Value Function Update Magnitude: 0.08602

Collected Steps per Second: 3,918.74229
Overall Steps per Second: 3,206.89963

Timestep Collection Time: 12.76940
Timestep Consumption Time: 2.83445
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 15.60386

Cumulative Model Updates: 47,719
Cumulative Timesteps: 795,954,764

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,599.77031
Policy Entropy: 1.05514
Value Function Loss: 4.51066

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 3,727.26758
Overall Steps per Second: 3,100.73974

Timestep Collection Time: 13.41734
Timestep Consumption Time: 2.71107
PPO Batch Consumption Time: 0.05936
Total Iteration Time: 16.12841

Cumulative Model Updates: 47,722
Cumulative Timesteps: 796,004,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 796004774...
Checkpoint 796004774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,897.48167
Policy Entropy: 1.06200
Value Function Loss: 4.45312

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.08702

Collected Steps per Second: 3,910.32359
Overall Steps per Second: 3,202.48340

Timestep Collection Time: 12.78922
Timestep Consumption Time: 2.82678
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 15.61601

Cumulative Model Updates: 47,725
Cumulative Timesteps: 796,054,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,119.76105
Policy Entropy: 1.07313
Value Function Loss: 4.51998

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.15925
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.08421

Collected Steps per Second: 3,896.42449
Overall Steps per Second: 3,183.31204

Timestep Collection Time: 12.83946
Timestep Consumption Time: 2.87624
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 15.71571

Cumulative Model Updates: 47,728
Cumulative Timesteps: 796,104,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 796104812...
Checkpoint 796104812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,906.52735
Policy Entropy: 1.05157
Value Function Loss: 4.46182

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.08237

Collected Steps per Second: 3,752.65442
Overall Steps per Second: 3,166.14099

Timestep Collection Time: 13.33190
Timestep Consumption Time: 2.46967
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 15.80157

Cumulative Model Updates: 47,731
Cumulative Timesteps: 796,154,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,887.11251
Policy Entropy: 1.06350
Value Function Loss: 4.46369

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.08570

Collected Steps per Second: 3,894.30932
Overall Steps per Second: 3,195.56997

Timestep Collection Time: 12.85106
Timestep Consumption Time: 2.81000
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 15.66106

Cumulative Model Updates: 47,734
Cumulative Timesteps: 796,204,888

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 796204888...
Checkpoint 796204888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596,330.08488
Policy Entropy: 1.06953
Value Function Loss: 4.32440

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.07635

Collected Steps per Second: 3,749.43056
Overall Steps per Second: 3,148.97245

Timestep Collection Time: 13.33856
Timestep Consumption Time: 2.54345
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 15.88201

Cumulative Model Updates: 47,737
Cumulative Timesteps: 796,254,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,180.83825
Policy Entropy: 1.07570
Value Function Loss: 4.30207

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.10815
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.07982

Collected Steps per Second: 3,792.19465
Overall Steps per Second: 3,129.00656

Timestep Collection Time: 13.19289
Timestep Consumption Time: 2.79621
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 15.98910

Cumulative Model Updates: 47,740
Cumulative Timesteps: 796,304,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 796304930...
Checkpoint 796304930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,466.30732
Policy Entropy: 1.07580
Value Function Loss: 4.19998

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.07935

Collected Steps per Second: 3,787.02273
Overall Steps per Second: 3,127.71529

Timestep Collection Time: 13.21513
Timestep Consumption Time: 2.78569
PPO Batch Consumption Time: 0.05396
Total Iteration Time: 16.00082

Cumulative Model Updates: 47,743
Cumulative Timesteps: 796,354,976

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,614.12439
Policy Entropy: 1.07030
Value Function Loss: 4.08012

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.07561

Collected Steps per Second: 3,941.95957
Overall Steps per Second: 3,225.29774

Timestep Collection Time: 12.69064
Timestep Consumption Time: 2.81986
PPO Batch Consumption Time: 0.06618
Total Iteration Time: 15.51051

Cumulative Model Updates: 47,746
Cumulative Timesteps: 796,405,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 796405002...
Checkpoint 796405002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,294.55880
Policy Entropy: 1.06253
Value Function Loss: 4.12086

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.14279
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.07782

Collected Steps per Second: 3,713.44681
Overall Steps per Second: 3,055.53212

Timestep Collection Time: 13.47320
Timestep Consumption Time: 2.90104
PPO Batch Consumption Time: 0.05968
Total Iteration Time: 16.37423

Cumulative Model Updates: 47,749
Cumulative Timesteps: 796,455,034

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,470.68943
Policy Entropy: 1.07870
Value Function Loss: 4.25375

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.08984

Collected Steps per Second: 3,826.89365
Overall Steps per Second: 3,193.91657

Timestep Collection Time: 13.06595
Timestep Consumption Time: 2.58944
PPO Batch Consumption Time: 0.06615
Total Iteration Time: 15.65539

Cumulative Model Updates: 47,752
Cumulative Timesteps: 796,505,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 796505036...
Checkpoint 796505036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,553.80668
Policy Entropy: 1.07610
Value Function Loss: 4.43297

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.08877

Collected Steps per Second: 3,771.32515
Overall Steps per Second: 3,113.58075

Timestep Collection Time: 13.26377
Timestep Consumption Time: 2.80197
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 16.06575

Cumulative Model Updates: 47,755
Cumulative Timesteps: 796,555,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,727.62317
Policy Entropy: 1.05937
Value Function Loss: 4.33243

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.08048

Collected Steps per Second: 3,822.44661
Overall Steps per Second: 3,164.26358

Timestep Collection Time: 13.09214
Timestep Consumption Time: 2.72323
PPO Batch Consumption Time: 0.06252
Total Iteration Time: 15.81537

Cumulative Model Updates: 47,758
Cumulative Timesteps: 796,605,102

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 796605102...
Checkpoint 796605102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,838.27747
Policy Entropy: 1.04282
Value Function Loss: 4.47098

Mean KL Divergence: 0.02451
SB3 Clip Fraction: 0.16076
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.08285

Collected Steps per Second: 3,810.07937
Overall Steps per Second: 3,154.49149

Timestep Collection Time: 13.12519
Timestep Consumption Time: 2.72777
PPO Batch Consumption Time: 0.05926
Total Iteration Time: 15.85295

Cumulative Model Updates: 47,761
Cumulative Timesteps: 796,655,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,516.92936
Policy Entropy: 1.05632
Value Function Loss: 4.28247

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.09422

Collected Steps per Second: 3,801.47447
Overall Steps per Second: 3,173.23064

Timestep Collection Time: 13.16121
Timestep Consumption Time: 2.60569
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 15.76690

Cumulative Model Updates: 47,764
Cumulative Timesteps: 796,705,142

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 796705142...
Checkpoint 796705142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,395.49466
Policy Entropy: 1.06405
Value Function Loss: 4.29475

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.10860

Collected Steps per Second: 3,803.20281
Overall Steps per Second: 3,214.64252

Timestep Collection Time: 13.14681
Timestep Consumption Time: 2.40702
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 15.55383

Cumulative Model Updates: 47,767
Cumulative Timesteps: 796,755,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,156.86601
Policy Entropy: 1.06003
Value Function Loss: 4.21088

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.10940

Collected Steps per Second: 3,852.92142
Overall Steps per Second: 3,205.08220

Timestep Collection Time: 12.98807
Timestep Consumption Time: 2.62526
PPO Batch Consumption Time: 0.04892
Total Iteration Time: 15.61333

Cumulative Model Updates: 47,770
Cumulative Timesteps: 796,805,184

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 796805184...
Checkpoint 796805184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,236.28663
Policy Entropy: 1.06102
Value Function Loss: 4.25487

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.10729

Collected Steps per Second: 3,766.99214
Overall Steps per Second: 3,118.36692

Timestep Collection Time: 13.28328
Timestep Consumption Time: 2.76294
PPO Batch Consumption Time: 0.05824
Total Iteration Time: 16.04622

Cumulative Model Updates: 47,773
Cumulative Timesteps: 796,855,222

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,072.02129
Policy Entropy: 1.05074
Value Function Loss: 4.37465

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.09110

Collected Steps per Second: 3,828.31920
Overall Steps per Second: 3,144.53793

Timestep Collection Time: 13.06213
Timestep Consumption Time: 2.84037
PPO Batch Consumption Time: 0.06289
Total Iteration Time: 15.90250

Cumulative Model Updates: 47,776
Cumulative Timesteps: 796,905,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 796905228...
Checkpoint 796905228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,966.58595
Policy Entropy: 1.07182
Value Function Loss: 4.33521

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.08178

Collected Steps per Second: 3,751.29691
Overall Steps per Second: 3,095.98173

Timestep Collection Time: 13.33086
Timestep Consumption Time: 2.82169
PPO Batch Consumption Time: 0.06204
Total Iteration Time: 16.15255

Cumulative Model Updates: 47,779
Cumulative Timesteps: 796,955,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,978.22828
Policy Entropy: 1.06772
Value Function Loss: 4.26297

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.08168

Collected Steps per Second: 3,730.49684
Overall Steps per Second: 3,133.23697

Timestep Collection Time: 13.40947
Timestep Consumption Time: 2.55612
PPO Batch Consumption Time: 0.05884
Total Iteration Time: 15.96560

Cumulative Model Updates: 47,782
Cumulative Timesteps: 797,005,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 797005260...
Checkpoint 797005260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,925.15213
Policy Entropy: 1.05710
Value Function Loss: 4.25641

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.07633

Collected Steps per Second: 3,813.92413
Overall Steps per Second: 3,148.03316

Timestep Collection Time: 13.11930
Timestep Consumption Time: 2.77507
PPO Batch Consumption Time: 0.05012
Total Iteration Time: 15.89437

Cumulative Model Updates: 47,785
Cumulative Timesteps: 797,055,296

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,191.34166
Policy Entropy: 1.05442
Value Function Loss: 4.24943

Mean KL Divergence: 0.02485
SB3 Clip Fraction: 0.16522
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.07634

Collected Steps per Second: 3,747.37482
Overall Steps per Second: 3,188.81223

Timestep Collection Time: 13.34748
Timestep Consumption Time: 2.33799
PPO Batch Consumption Time: 0.05376
Total Iteration Time: 15.68546

Cumulative Model Updates: 47,788
Cumulative Timesteps: 797,105,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 797105314...
Checkpoint 797105314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,634.38345
Policy Entropy: 1.06376
Value Function Loss: 4.32141

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.07946

Collected Steps per Second: 3,893.85934
Overall Steps per Second: 3,203.17617

Timestep Collection Time: 12.84227
Timestep Consumption Time: 2.76911
PPO Batch Consumption Time: 0.06228
Total Iteration Time: 15.61138

Cumulative Model Updates: 47,791
Cumulative Timesteps: 797,155,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,908.74867
Policy Entropy: 1.07274
Value Function Loss: 4.31716

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14279
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 3,732.98142
Overall Steps per Second: 3,082.90581

Timestep Collection Time: 13.39573
Timestep Consumption Time: 2.82468
PPO Batch Consumption Time: 0.06168
Total Iteration Time: 16.22041

Cumulative Model Updates: 47,794
Cumulative Timesteps: 797,205,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 797205326...
Checkpoint 797205326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,157.63378
Policy Entropy: 1.04967
Value Function Loss: 4.32670

Mean KL Divergence: 0.02802
SB3 Clip Fraction: 0.17375
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.07677

Collected Steps per Second: 3,774.81766
Overall Steps per Second: 3,160.63243

Timestep Collection Time: 13.25362
Timestep Consumption Time: 2.57549
PPO Batch Consumption Time: 0.06417
Total Iteration Time: 15.82911

Cumulative Model Updates: 47,797
Cumulative Timesteps: 797,255,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,396.30037
Policy Entropy: 1.06713
Value Function Loss: 4.34174

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 3,879.44003
Overall Steps per Second: 3,185.09302

Timestep Collection Time: 12.89361
Timestep Consumption Time: 2.81079
PPO Batch Consumption Time: 0.06192
Total Iteration Time: 15.70441

Cumulative Model Updates: 47,800
Cumulative Timesteps: 797,305,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 797305376...
Checkpoint 797305376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,343.34037
Policy Entropy: 1.06761
Value Function Loss: 4.31297

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.08419

Collected Steps per Second: 3,830.70843
Overall Steps per Second: 3,195.34163

Timestep Collection Time: 13.05242
Timestep Consumption Time: 2.59536
PPO Batch Consumption Time: 0.06581
Total Iteration Time: 15.64778

Cumulative Model Updates: 47,803
Cumulative Timesteps: 797,355,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,832.64610
Policy Entropy: 1.04843
Value Function Loss: 4.46682

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.08944

Collected Steps per Second: 3,766.55195
Overall Steps per Second: 3,126.49096

Timestep Collection Time: 13.27899
Timestep Consumption Time: 2.71850
PPO Batch Consumption Time: 0.05966
Total Iteration Time: 15.99749

Cumulative Model Updates: 47,806
Cumulative Timesteps: 797,405,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 797405392...
Checkpoint 797405392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650,365.05401
Policy Entropy: 1.04655
Value Function Loss: 4.39425

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.16307
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.09166

Collected Steps per Second: 3,963.78854
Overall Steps per Second: 3,275.71007

Timestep Collection Time: 12.62025
Timestep Consumption Time: 2.65094
PPO Batch Consumption Time: 0.05413
Total Iteration Time: 15.27119

Cumulative Model Updates: 47,809
Cumulative Timesteps: 797,455,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,499.70089
Policy Entropy: 1.05665
Value Function Loss: 4.42450

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.09805

Collected Steps per Second: 3,824.31146
Overall Steps per Second: 3,169.82856

Timestep Collection Time: 13.08157
Timestep Consumption Time: 2.70099
PPO Batch Consumption Time: 0.05295
Total Iteration Time: 15.78256

Cumulative Model Updates: 47,812
Cumulative Timesteps: 797,505,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 797505444...
Checkpoint 797505444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,649.27291
Policy Entropy: 1.06006
Value Function Loss: 4.21612

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.09456

Collected Steps per Second: 3,880.04057
Overall Steps per Second: 3,233.48569

Timestep Collection Time: 12.89007
Timestep Consumption Time: 2.57745
PPO Batch Consumption Time: 0.06230
Total Iteration Time: 15.46752

Cumulative Model Updates: 47,815
Cumulative Timesteps: 797,555,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,009.12257
Policy Entropy: 1.03139
Value Function Loss: 4.16927

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.08887

Collected Steps per Second: 3,842.06739
Overall Steps per Second: 3,227.14458

Timestep Collection Time: 13.02164
Timestep Consumption Time: 2.48123
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 15.50287

Cumulative Model Updates: 47,818
Cumulative Timesteps: 797,605,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 797605488...
Checkpoint 797605488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,126.17546
Policy Entropy: 1.05312
Value Function Loss: 3.91369

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.17037
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.09529

Collected Steps per Second: 3,867.63711
Overall Steps per Second: 3,193.16965

Timestep Collection Time: 12.93658
Timestep Consumption Time: 2.73249
PPO Batch Consumption Time: 0.05397
Total Iteration Time: 15.66907

Cumulative Model Updates: 47,821
Cumulative Timesteps: 797,655,522

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,347.32564
Policy Entropy: 1.05452
Value Function Loss: 3.93534

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.16533
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.08554

Collected Steps per Second: 3,749.35826
Overall Steps per Second: 3,121.23936

Timestep Collection Time: 13.34042
Timestep Consumption Time: 2.68463
PPO Batch Consumption Time: 0.04975
Total Iteration Time: 16.02504

Cumulative Model Updates: 47,824
Cumulative Timesteps: 797,705,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 797705540...
Checkpoint 797705540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,473.97048
Policy Entropy: 1.05735
Value Function Loss: 4.06610

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.07476

Collected Steps per Second: 3,773.28530
Overall Steps per Second: 3,101.89584

Timestep Collection Time: 13.26536
Timestep Consumption Time: 2.87122
PPO Batch Consumption Time: 0.06357
Total Iteration Time: 16.13658

Cumulative Model Updates: 47,827
Cumulative Timesteps: 797,755,594

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,709.76889
Policy Entropy: 1.04376
Value Function Loss: 4.28989

Mean KL Divergence: 0.02538
SB3 Clip Fraction: 0.16508
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.08238

Collected Steps per Second: 3,778.22080
Overall Steps per Second: 3,123.03489

Timestep Collection Time: 13.23904
Timestep Consumption Time: 2.77744
PPO Batch Consumption Time: 0.06043
Total Iteration Time: 16.01647

Cumulative Model Updates: 47,830
Cumulative Timesteps: 797,805,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 797805614...
Checkpoint 797805614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,103.38772
Policy Entropy: 1.06152
Value Function Loss: 4.26829

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.10852

Collected Steps per Second: 3,740.70698
Overall Steps per Second: 3,172.20093

Timestep Collection Time: 13.36753
Timestep Consumption Time: 2.39566
PPO Batch Consumption Time: 0.05397
Total Iteration Time: 15.76319

Cumulative Model Updates: 47,833
Cumulative Timesteps: 797,855,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,246.63185
Policy Entropy: 1.06332
Value Function Loss: 4.36056

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.11673

Collected Steps per Second: 3,931.13621
Overall Steps per Second: 3,197.94787

Timestep Collection Time: 12.71897
Timestep Consumption Time: 2.91606
PPO Batch Consumption Time: 0.06415
Total Iteration Time: 15.63503

Cumulative Model Updates: 47,836
Cumulative Timesteps: 797,905,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 797905618...
Checkpoint 797905618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,510.90266
Policy Entropy: 1.05282
Value Function Loss: 4.37250

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.06335
Value Function Update Magnitude: 0.12286

Collected Steps per Second: 3,799.61702
Overall Steps per Second: 3,216.79126

Timestep Collection Time: 13.17080
Timestep Consumption Time: 2.38632
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 15.55712

Cumulative Model Updates: 47,839
Cumulative Timesteps: 797,955,662

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,490.89008
Policy Entropy: 1.03679
Value Function Loss: 4.32935

Mean KL Divergence: 0.03149
SB3 Clip Fraction: 0.18235
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.12470

Collected Steps per Second: 3,836.68052
Overall Steps per Second: 3,154.95719

Timestep Collection Time: 13.03523
Timestep Consumption Time: 2.81665
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 15.85188

Cumulative Model Updates: 47,842
Cumulative Timesteps: 798,005,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 798005674...
Checkpoint 798005674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,369.33541
Policy Entropy: 1.05045
Value Function Loss: 4.20680

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.13989

Collected Steps per Second: 3,776.36010
Overall Steps per Second: 3,124.03475

Timestep Collection Time: 13.24768
Timestep Consumption Time: 2.76623
PPO Batch Consumption Time: 0.06366
Total Iteration Time: 16.01391

Cumulative Model Updates: 47,845
Cumulative Timesteps: 798,055,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,168.77520
Policy Entropy: 1.05172
Value Function Loss: 4.19385

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.13372

Collected Steps per Second: 3,837.48379
Overall Steps per Second: 3,130.34081

Timestep Collection Time: 13.02937
Timestep Consumption Time: 2.94333
PPO Batch Consumption Time: 0.05936
Total Iteration Time: 15.97270

Cumulative Model Updates: 47,848
Cumulative Timesteps: 798,105,702

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 798105702...
Checkpoint 798105702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,908.80678
Policy Entropy: 1.04216
Value Function Loss: 4.25154

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.12439

Collected Steps per Second: 3,755.01544
Overall Steps per Second: 3,119.13599

Timestep Collection Time: 13.31606
Timestep Consumption Time: 2.71466
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 16.03072

Cumulative Model Updates: 47,851
Cumulative Timesteps: 798,155,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,120.05696
Policy Entropy: 1.02880
Value Function Loss: 4.14164

Mean KL Divergence: 0.02753
SB3 Clip Fraction: 0.17015
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.11463

Collected Steps per Second: 3,881.38993
Overall Steps per Second: 3,243.28733

Timestep Collection Time: 12.88817
Timestep Consumption Time: 2.53569
PPO Batch Consumption Time: 0.06028
Total Iteration Time: 15.42386

Cumulative Model Updates: 47,854
Cumulative Timesteps: 798,205,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 798205728...
Checkpoint 798205728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,646.03139
Policy Entropy: 1.04180
Value Function Loss: 4.08580

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.09850

Collected Steps per Second: 3,887.21118
Overall Steps per Second: 3,183.41355

Timestep Collection Time: 12.86526
Timestep Consumption Time: 2.84429
PPO Batch Consumption Time: 0.05955
Total Iteration Time: 15.70955

Cumulative Model Updates: 47,857
Cumulative Timesteps: 798,255,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,431.77268
Policy Entropy: 1.04863
Value Function Loss: 4.08500

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.10449

Collected Steps per Second: 3,843.91014
Overall Steps per Second: 3,244.45908

Timestep Collection Time: 13.01383
Timestep Consumption Time: 2.40445
PPO Batch Consumption Time: 0.06032
Total Iteration Time: 15.41829

Cumulative Model Updates: 47,860
Cumulative Timesteps: 798,305,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 798305762...
Checkpoint 798305762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,484.73515
Policy Entropy: 1.02682
Value Function Loss: 4.09113

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.09451

Collected Steps per Second: 3,776.48406
Overall Steps per Second: 3,128.40025

Timestep Collection Time: 13.24565
Timestep Consumption Time: 2.74399
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 15.98964

Cumulative Model Updates: 47,863
Cumulative Timesteps: 798,355,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,228.54591
Policy Entropy: 1.03334
Value Function Loss: 4.26251

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.09934

Collected Steps per Second: 3,822.31336
Overall Steps per Second: 3,153.23746

Timestep Collection Time: 13.08893
Timestep Consumption Time: 2.77730
PPO Batch Consumption Time: 0.06175
Total Iteration Time: 15.86623

Cumulative Model Updates: 47,866
Cumulative Timesteps: 798,405,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 798405814...
Checkpoint 798405814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,582.39760
Policy Entropy: 1.03626
Value Function Loss: 4.26976

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.09674

Collected Steps per Second: 3,910.17329
Overall Steps per Second: 3,210.43927

Timestep Collection Time: 12.78920
Timestep Consumption Time: 2.78748
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 15.57668

Cumulative Model Updates: 47,869
Cumulative Timesteps: 798,455,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,765.68624
Policy Entropy: 1.04584
Value Function Loss: 4.32332

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 3,799.49024
Overall Steps per Second: 3,144.61568

Timestep Collection Time: 13.16650
Timestep Consumption Time: 2.74196
PPO Batch Consumption Time: 0.05962
Total Iteration Time: 15.90846

Cumulative Model Updates: 47,872
Cumulative Timesteps: 798,505,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 798505848...
Checkpoint 798505848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,218.77638
Policy Entropy: 1.02891
Value Function Loss: 4.23897

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.05910
Value Function Update Magnitude: 0.08731

Collected Steps per Second: 3,709.86339
Overall Steps per Second: 3,128.36752

Timestep Collection Time: 13.48837
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.06695
Total Iteration Time: 15.99556

Cumulative Model Updates: 47,875
Cumulative Timesteps: 798,555,888

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,323.45208
Policy Entropy: 1.01466
Value Function Loss: 4.19632

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.15611
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.07752

Collected Steps per Second: 3,863.03932
Overall Steps per Second: 3,169.18965

Timestep Collection Time: 12.94784
Timestep Consumption Time: 2.83475
PPO Batch Consumption Time: 0.05969
Total Iteration Time: 15.78258

Cumulative Model Updates: 47,878
Cumulative Timesteps: 798,605,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 798605906...
Checkpoint 798605906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,020.59082
Policy Entropy: 1.03446
Value Function Loss: 4.05407

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.06928

Collected Steps per Second: 3,783.57280
Overall Steps per Second: 3,149.50631

Timestep Collection Time: 13.22559
Timestep Consumption Time: 2.66261
PPO Batch Consumption Time: 0.06060
Total Iteration Time: 15.88820

Cumulative Model Updates: 47,881
Cumulative Timesteps: 798,655,946

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,706.70829
Policy Entropy: 1.03711
Value Function Loss: 4.10279

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.14173
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.06560

Collected Steps per Second: 4,094.31304
Overall Steps per Second: 3,328.69502

Timestep Collection Time: 12.21646
Timestep Consumption Time: 2.80985
PPO Batch Consumption Time: 0.06075
Total Iteration Time: 15.02631

Cumulative Model Updates: 47,884
Cumulative Timesteps: 798,705,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 798705964...
Checkpoint 798705964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,820.25909
Policy Entropy: 1.02879
Value Function Loss: 4.20010

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.07358

Collected Steps per Second: 3,853.81879
Overall Steps per Second: 3,187.77625

Timestep Collection Time: 12.98037
Timestep Consumption Time: 2.71207
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 15.69244

Cumulative Model Updates: 47,887
Cumulative Timesteps: 798,755,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,373.21096
Policy Entropy: 1.01152
Value Function Loss: 4.30069

Mean KL Divergence: 0.03335
SB3 Clip Fraction: 0.19005
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.07238

Collected Steps per Second: 3,836.73476
Overall Steps per Second: 3,219.72313

Timestep Collection Time: 13.04443
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 15.54419

Cumulative Model Updates: 47,890
Cumulative Timesteps: 798,806,036

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 798806036...
Checkpoint 798806036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,659.54423
Policy Entropy: 1.03338
Value Function Loss: 4.10491

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.09143

Collected Steps per Second: 3,844.22279
Overall Steps per Second: 3,162.83356

Timestep Collection Time: 13.01121
Timestep Consumption Time: 2.80309
PPO Batch Consumption Time: 0.06509
Total Iteration Time: 15.81430

Cumulative Model Updates: 47,893
Cumulative Timesteps: 798,856,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,773.86648
Policy Entropy: 1.03166
Value Function Loss: 4.04822

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.08919

Collected Steps per Second: 3,811.77043
Overall Steps per Second: 3,169.48284

Timestep Collection Time: 13.12041
Timestep Consumption Time: 2.65882
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 15.77923

Cumulative Model Updates: 47,896
Cumulative Timesteps: 798,906,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 798906066...
Checkpoint 798906066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695,694.19814
Policy Entropy: 1.02083
Value Function Loss: 4.06547

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.05972
Value Function Update Magnitude: 0.10448

Collected Steps per Second: 3,853.04455
Overall Steps per Second: 3,163.13070

Timestep Collection Time: 12.98142
Timestep Consumption Time: 2.83139
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 15.81281

Cumulative Model Updates: 47,899
Cumulative Timesteps: 798,956,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,928.30019
Policy Entropy: 1.02827
Value Function Loss: 4.17706

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.10864

Collected Steps per Second: 3,787.21566
Overall Steps per Second: 3,114.15179

Timestep Collection Time: 13.21446
Timestep Consumption Time: 2.85605
PPO Batch Consumption Time: 0.06035
Total Iteration Time: 16.07051

Cumulative Model Updates: 47,902
Cumulative Timesteps: 799,006,130

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 799006130...
Checkpoint 799006130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,343.38496
Policy Entropy: 1.03813
Value Function Loss: 4.37842

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.10176

Collected Steps per Second: 3,779.78665
Overall Steps per Second: 3,175.45806

Timestep Collection Time: 13.23091
Timestep Consumption Time: 2.51800
PPO Batch Consumption Time: 0.06175
Total Iteration Time: 15.74891

Cumulative Model Updates: 47,905
Cumulative Timesteps: 799,056,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585,395.01191
Policy Entropy: 1.04411
Value Function Loss: 4.37364

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.06840
Value Function Update Magnitude: 0.09565

Collected Steps per Second: 3,780.91276
Overall Steps per Second: 3,101.84187

Timestep Collection Time: 13.23067
Timestep Consumption Time: 2.89652
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 16.12719

Cumulative Model Updates: 47,908
Cumulative Timesteps: 799,106,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 799106164...
Checkpoint 799106164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,947.50893
Policy Entropy: 1.04898
Value Function Loss: 4.29855

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.07185
Value Function Update Magnitude: 0.11380

Collected Steps per Second: 3,827.91715
Overall Steps per Second: 3,231.02808

Timestep Collection Time: 13.06402
Timestep Consumption Time: 2.41340
PPO Batch Consumption Time: 0.06364
Total Iteration Time: 15.47743

Cumulative Model Updates: 47,911
Cumulative Timesteps: 799,156,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,779.74253
Policy Entropy: 1.04243
Value Function Loss: 4.11415

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.07708
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 3,832.48773
Overall Steps per Second: 3,156.24494

Timestep Collection Time: 13.05418
Timestep Consumption Time: 2.79693
PPO Batch Consumption Time: 0.06202
Total Iteration Time: 15.85111

Cumulative Model Updates: 47,914
Cumulative Timesteps: 799,206,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 799206202...
Checkpoint 799206202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,882.12976
Policy Entropy: 1.04095
Value Function Loss: 4.13979

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.07203
Value Function Update Magnitude: 0.10936

Collected Steps per Second: 3,820.61895
Overall Steps per Second: 3,177.17805

Timestep Collection Time: 13.08898
Timestep Consumption Time: 2.65078
PPO Batch Consumption Time: 0.05838
Total Iteration Time: 15.73975

Cumulative Model Updates: 47,917
Cumulative Timesteps: 799,256,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,510.65106
Policy Entropy: 1.04690
Value Function Loss: 4.36156

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.06548
Value Function Update Magnitude: 0.10993

Collected Steps per Second: 3,723.07442
Overall Steps per Second: 3,142.85453

Timestep Collection Time: 13.44050
Timestep Consumption Time: 2.48133
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 15.92183

Cumulative Model Updates: 47,920
Cumulative Timesteps: 799,306,250

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 799306250...
Checkpoint 799306250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,738.39744
Policy Entropy: 1.05104
Value Function Loss: 4.26242

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.10560

Collected Steps per Second: 3,762.47588
Overall Steps per Second: 3,096.69418

Timestep Collection Time: 13.29550
Timestep Consumption Time: 2.85850
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 16.15400

Cumulative Model Updates: 47,923
Cumulative Timesteps: 799,356,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,015.32680
Policy Entropy: 1.05909
Value Function Loss: 4.43846

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.15301
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 3,762.97306
Overall Steps per Second: 3,173.05280

Timestep Collection Time: 13.29109
Timestep Consumption Time: 2.47102
PPO Batch Consumption Time: 0.06705
Total Iteration Time: 15.76211

Cumulative Model Updates: 47,926
Cumulative Timesteps: 799,406,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 799406288...
Checkpoint 799406288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,826.35772
Policy Entropy: 1.05338
Value Function Loss: 4.33819

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.07519
Value Function Update Magnitude: 0.08827

Collected Steps per Second: 3,868.56847
Overall Steps per Second: 3,201.15685

Timestep Collection Time: 12.93347
Timestep Consumption Time: 2.69651
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 15.62997

Cumulative Model Updates: 47,929
Cumulative Timesteps: 799,456,322

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,086.33659
Policy Entropy: 1.04965
Value Function Loss: 4.34791

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.07712
Value Function Update Magnitude: 0.08928

Collected Steps per Second: 3,796.31217
Overall Steps per Second: 3,143.72543

Timestep Collection Time: 13.17753
Timestep Consumption Time: 2.73544
PPO Batch Consumption Time: 0.05044
Total Iteration Time: 15.91297

Cumulative Model Updates: 47,932
Cumulative Timesteps: 799,506,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 799506348...
Checkpoint 799506348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,579.81487
Policy Entropy: 1.04697
Value Function Loss: 4.31664

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.16534
Policy Update Magnitude: 0.06746
Value Function Update Magnitude: 0.08968

Collected Steps per Second: 3,891.89092
Overall Steps per Second: 3,188.47706

Timestep Collection Time: 12.85339
Timestep Consumption Time: 2.83560
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 15.68899

Cumulative Model Updates: 47,935
Cumulative Timesteps: 799,556,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,604.81436
Policy Entropy: 1.05482
Value Function Loss: 4.37037

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.06271
Value Function Update Magnitude: 0.09449

Collected Steps per Second: 3,696.32391
Overall Steps per Second: 3,072.22178

Timestep Collection Time: 13.53777
Timestep Consumption Time: 2.75011
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 16.28789

Cumulative Model Updates: 47,938
Cumulative Timesteps: 799,606,412

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 799606412...
Checkpoint 799606412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,247.43240
Policy Entropy: 1.06083
Value Function Loss: 4.39326

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.09605

Collected Steps per Second: 3,843.50930
Overall Steps per Second: 3,205.04072

Timestep Collection Time: 13.01779
Timestep Consumption Time: 2.59324
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 15.61103

Cumulative Model Updates: 47,941
Cumulative Timesteps: 799,656,446

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,948.95632
Policy Entropy: 1.05108
Value Function Loss: 4.25479

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.07045
Value Function Update Magnitude: 0.09126

Collected Steps per Second: 3,925.21011
Overall Steps per Second: 3,176.59931

Timestep Collection Time: 12.73817
Timestep Consumption Time: 3.00193
PPO Batch Consumption Time: 0.06384
Total Iteration Time: 15.74010

Cumulative Model Updates: 47,944
Cumulative Timesteps: 799,706,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 799706446...
Checkpoint 799706446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,935.25173
Policy Entropy: 1.05790
Value Function Loss: 4.20796

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.07297
Value Function Update Magnitude: 0.08480

Collected Steps per Second: 3,698.68772
Overall Steps per Second: 3,051.17818

Timestep Collection Time: 13.52101
Timestep Consumption Time: 2.86938
PPO Batch Consumption Time: 0.05907
Total Iteration Time: 16.39039

Cumulative Model Updates: 47,947
Cumulative Timesteps: 799,756,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,907.51404
Policy Entropy: 1.06444
Value Function Loss: 4.41909

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.07228
Value Function Update Magnitude: 0.08498

Collected Steps per Second: 3,811.06778
Overall Steps per Second: 3,156.42841

Timestep Collection Time: 13.12808
Timestep Consumption Time: 2.72275
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 15.85083

Cumulative Model Updates: 47,950
Cumulative Timesteps: 799,806,488

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 799806488...
Checkpoint 799806488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,473.82274
Policy Entropy: 1.07324
Value Function Loss: 4.50745

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.07394
Value Function Update Magnitude: 0.08337

Collected Steps per Second: 3,830.06921
Overall Steps per Second: 3,143.95914

Timestep Collection Time: 13.05773
Timestep Consumption Time: 2.84960
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 15.90733

Cumulative Model Updates: 47,953
Cumulative Timesteps: 799,856,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,444.37509
Policy Entropy: 1.07106
Value Function Loss: 4.48087

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.07014
Value Function Update Magnitude: 0.09474

Collected Steps per Second: 3,772.26654
Overall Steps per Second: 3,142.17513

Timestep Collection Time: 13.25940
Timestep Consumption Time: 2.65887
PPO Batch Consumption Time: 0.06249
Total Iteration Time: 15.91827

Cumulative Model Updates: 47,956
Cumulative Timesteps: 799,906,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 799906518...
Checkpoint 799906518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,700.57242
Policy Entropy: 1.06621
Value Function Loss: 4.42104

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.09011

Collected Steps per Second: 3,745.16873
Overall Steps per Second: 3,085.62296

Timestep Collection Time: 13.35214
Timestep Consumption Time: 2.85399
PPO Batch Consumption Time: 0.07117
Total Iteration Time: 16.20613

Cumulative Model Updates: 47,959
Cumulative Timesteps: 799,956,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,734.62572
Policy Entropy: 1.08356
Value Function Loss: 4.41195

Mean KL Divergence: 0.02447
SB3 Clip Fraction: 0.17749
Policy Update Magnitude: 0.06363
Value Function Update Magnitude: 0.08938

Collected Steps per Second: 3,863.91896
Overall Steps per Second: 3,207.90578

Timestep Collection Time: 12.94644
Timestep Consumption Time: 2.64753
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 15.59397

Cumulative Model Updates: 47,962
Cumulative Timesteps: 800,006,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 800006548...
Checkpoint 800006548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,432.42740
Policy Entropy: 1.07957
Value Function Loss: 4.42789

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.09793

Collected Steps per Second: 3,737.00400
Overall Steps per Second: 3,101.74199

Timestep Collection Time: 13.38024
Timestep Consumption Time: 2.74038
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 16.12062

Cumulative Model Updates: 47,965
Cumulative Timesteps: 800,056,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,039.88965
Policy Entropy: 1.08268
Value Function Loss: 4.25021

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.06447
Value Function Update Magnitude: 0.10019

Collected Steps per Second: 3,772.11949
Overall Steps per Second: 3,083.59746

Timestep Collection Time: 13.26204
Timestep Consumption Time: 2.96122
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 16.22326

Cumulative Model Updates: 47,968
Cumulative Timesteps: 800,106,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 800106576...
Checkpoint 800106576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,340.60347
Policy Entropy: 1.08102
Value Function Loss: 4.46749

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.06669
Value Function Update Magnitude: 0.09334

Collected Steps per Second: 3,781.87815
Overall Steps per Second: 3,102.20464

Timestep Collection Time: 13.22676
Timestep Consumption Time: 2.89790
PPO Batch Consumption Time: 0.06535
Total Iteration Time: 16.12466

Cumulative Model Updates: 47,971
Cumulative Timesteps: 800,156,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,737.79640
Policy Entropy: 1.09076
Value Function Loss: 4.64390

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.06882
Value Function Update Magnitude: 0.09806

Collected Steps per Second: 3,748.29265
Overall Steps per Second: 3,101.15988

Timestep Collection Time: 13.34581
Timestep Consumption Time: 2.78493
PPO Batch Consumption Time: 0.06925
Total Iteration Time: 16.13074

Cumulative Model Updates: 47,974
Cumulative Timesteps: 800,206,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 800206622...
Checkpoint 800206622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,789.08860
Policy Entropy: 1.07959
Value Function Loss: 4.80328

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.06682
Value Function Update Magnitude: 0.09742

Collected Steps per Second: 3,810.87271
Overall Steps per Second: 3,136.69065

Timestep Collection Time: 13.12928
Timestep Consumption Time: 2.82193
PPO Batch Consumption Time: 0.06374
Total Iteration Time: 15.95121

Cumulative Model Updates: 47,977
Cumulative Timesteps: 800,256,656

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,754.27813
Policy Entropy: 1.09798
Value Function Loss: 4.68115

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.09418

Collected Steps per Second: 3,673.67226
Overall Steps per Second: 3,036.25670

Timestep Collection Time: 13.62343
Timestep Consumption Time: 2.86003
PPO Batch Consumption Time: 0.06216
Total Iteration Time: 16.48345

Cumulative Model Updates: 47,980
Cumulative Timesteps: 800,306,704

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 800306704...
Checkpoint 800306704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,014.22064
Policy Entropy: 1.09300
Value Function Loss: 4.48815

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.10695

Collected Steps per Second: 3,742.58152
Overall Steps per Second: 3,084.50597

Timestep Collection Time: 13.36243
Timestep Consumption Time: 2.85086
PPO Batch Consumption Time: 0.06589
Total Iteration Time: 16.21329

Cumulative Model Updates: 47,983
Cumulative Timesteps: 800,356,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,985.28383
Policy Entropy: 1.08367
Value Function Loss: 4.46443

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.10596

Collected Steps per Second: 3,664.45044
Overall Steps per Second: 3,062.49757

Timestep Collection Time: 13.64734
Timestep Consumption Time: 2.68247
PPO Batch Consumption Time: 0.06621
Total Iteration Time: 16.32981

Cumulative Model Updates: 47,986
Cumulative Timesteps: 800,406,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 800406724...
Checkpoint 800406724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,912.74870
Policy Entropy: 1.07045
Value Function Loss: 4.52827

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.15545
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.09347

Collected Steps per Second: 3,960.82991
Overall Steps per Second: 3,230.27007

Timestep Collection Time: 12.62867
Timestep Consumption Time: 2.85611
PPO Batch Consumption Time: 0.06553
Total Iteration Time: 15.48477

Cumulative Model Updates: 47,989
Cumulative Timesteps: 800,456,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,194.54447
Policy Entropy: 1.08546
Value Function Loss: 4.61473

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.08727

Collected Steps per Second: 3,789.42570
Overall Steps per Second: 3,110.33242

Timestep Collection Time: 13.19831
Timestep Consumption Time: 2.88165
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 16.07995

Cumulative Model Updates: 47,992
Cumulative Timesteps: 800,506,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 800506758...
Checkpoint 800506758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,116.12143
Policy Entropy: 1.09646
Value Function Loss: 4.55743

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.15204
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.08066

Collected Steps per Second: 3,841.19907
Overall Steps per Second: 3,150.12684

Timestep Collection Time: 13.02093
Timestep Consumption Time: 2.85652
PPO Batch Consumption Time: 0.06541
Total Iteration Time: 15.87746

Cumulative Model Updates: 47,995
Cumulative Timesteps: 800,556,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,933.37979
Policy Entropy: 1.08015
Value Function Loss: 4.51275

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.07678

Collected Steps per Second: 3,666.45095
Overall Steps per Second: 3,022.03176

Timestep Collection Time: 13.64262
Timestep Consumption Time: 2.90916
PPO Batch Consumption Time: 0.05995
Total Iteration Time: 16.55178

Cumulative Model Updates: 47,998
Cumulative Timesteps: 800,606,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 800606794...
Checkpoint 800606794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,226.63879
Policy Entropy: 1.08380
Value Function Loss: 4.38815

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.08682

Collected Steps per Second: 3,968.49604
Overall Steps per Second: 3,234.75398

Timestep Collection Time: 12.60427
Timestep Consumption Time: 2.85904
PPO Batch Consumption Time: 0.06387
Total Iteration Time: 15.46331

Cumulative Model Updates: 48,001
Cumulative Timesteps: 800,656,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,578.30088
Policy Entropy: 1.08716
Value Function Loss: 4.34984

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.08757

Collected Steps per Second: 3,736.22366
Overall Steps per Second: 3,081.06773

Timestep Collection Time: 13.38250
Timestep Consumption Time: 2.84564
PPO Batch Consumption Time: 0.06361
Total Iteration Time: 16.22814

Cumulative Model Updates: 48,004
Cumulative Timesteps: 800,706,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 800706814...
Checkpoint 800706814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,285.41599
Policy Entropy: 1.09512
Value Function Loss: 4.45827

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.09282

Collected Steps per Second: 3,881.69378
Overall Steps per Second: 3,179.49541

Timestep Collection Time: 12.88561
Timestep Consumption Time: 2.84582
PPO Batch Consumption Time: 0.06386
Total Iteration Time: 15.73143

Cumulative Model Updates: 48,007
Cumulative Timesteps: 800,756,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,628.46716
Policy Entropy: 1.07141
Value Function Loss: 4.55985

Mean KL Divergence: 0.04433
SB3 Clip Fraction: 0.16451
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.08474

Collected Steps per Second: 3,645.64114
Overall Steps per Second: 3,024.36633

Timestep Collection Time: 13.72324
Timestep Consumption Time: 2.81907
PPO Batch Consumption Time: 0.06343
Total Iteration Time: 16.54231

Cumulative Model Updates: 48,010
Cumulative Timesteps: 800,806,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 800806862...
Checkpoint 800806862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,636.27051
Policy Entropy: 1.08737
Value Function Loss: 4.60335

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.15670
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.07437

Collected Steps per Second: 3,738.11110
Overall Steps per Second: 3,070.32450

Timestep Collection Time: 13.38055
Timestep Consumption Time: 2.91023
PPO Batch Consumption Time: 0.06396
Total Iteration Time: 16.29079

Cumulative Model Updates: 48,013
Cumulative Timesteps: 800,856,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,954.01005
Policy Entropy: 1.08218
Value Function Loss: 4.47041

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.07165

Collected Steps per Second: 3,722.33157
Overall Steps per Second: 3,057.87409

Timestep Collection Time: 13.43298
Timestep Consumption Time: 2.91890
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 16.35188

Cumulative Model Updates: 48,016
Cumulative Timesteps: 800,906,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 800906882...
Checkpoint 800906882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596,292.80134
Policy Entropy: 1.06645
Value Function Loss: 4.41483

Mean KL Divergence: 0.03161
SB3 Clip Fraction: 0.16836
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.06936

Collected Steps per Second: 3,777.49185
Overall Steps per Second: 3,106.32264

Timestep Collection Time: 13.24000
Timestep Consumption Time: 2.86071
PPO Batch Consumption Time: 0.05955
Total Iteration Time: 16.10071

Cumulative Model Updates: 48,019
Cumulative Timesteps: 800,956,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,048.43694
Policy Entropy: 1.08096
Value Function Loss: 4.36536

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 3,694.97568
Overall Steps per Second: 3,070.69499

Timestep Collection Time: 13.54055
Timestep Consumption Time: 2.75283
PPO Batch Consumption Time: 0.06282
Total Iteration Time: 16.29338

Cumulative Model Updates: 48,022
Cumulative Timesteps: 801,006,928

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 801006928...
Checkpoint 801006928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,373.29473
Policy Entropy: 1.08702
Value Function Loss: 4.22638

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 3,731.23206
Overall Steps per Second: 3,133.27295

Timestep Collection Time: 13.40308
Timestep Consumption Time: 2.55787
PPO Batch Consumption Time: 0.06076
Total Iteration Time: 15.96095

Cumulative Model Updates: 48,025
Cumulative Timesteps: 801,056,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,440.09950
Policy Entropy: 1.07502
Value Function Loss: 4.30667

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.09464

Collected Steps per Second: 3,726.03905
Overall Steps per Second: 3,070.61027

Timestep Collection Time: 13.42605
Timestep Consumption Time: 2.86582
PPO Batch Consumption Time: 0.05826
Total Iteration Time: 16.29188

Cumulative Model Updates: 48,028
Cumulative Timesteps: 801,106,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 801106964...
Checkpoint 801106964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,998.45187
Policy Entropy: 1.06054
Value Function Loss: 4.16779

Mean KL Divergence: 0.02805
SB3 Clip Fraction: 0.18575
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.10226

Collected Steps per Second: 3,600.02376
Overall Steps per Second: 3,016.47241

Timestep Collection Time: 13.89491
Timestep Consumption Time: 2.68804
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 16.58295

Cumulative Model Updates: 48,031
Cumulative Timesteps: 801,156,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,268.20070
Policy Entropy: 1.07070
Value Function Loss: 4.42333

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.09182

Collected Steps per Second: 3,859.81140
Overall Steps per Second: 3,099.21405

Timestep Collection Time: 12.96592
Timestep Consumption Time: 3.18205
PPO Batch Consumption Time: 0.06404
Total Iteration Time: 16.14796

Cumulative Model Updates: 48,034
Cumulative Timesteps: 801,207,032

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 801207032...
Checkpoint 801207032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,835.67179
Policy Entropy: 1.07889
Value Function Loss: 4.29734

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.09580

Collected Steps per Second: 3,693.12012
Overall Steps per Second: 3,037.02428

Timestep Collection Time: 13.53869
Timestep Consumption Time: 2.92480
PPO Batch Consumption Time: 0.06207
Total Iteration Time: 16.46348

Cumulative Model Updates: 48,037
Cumulative Timesteps: 801,257,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,877.77293
Policy Entropy: 1.06133
Value Function Loss: 4.34655

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.10428

Collected Steps per Second: 3,752.36084
Overall Steps per Second: 3,148.54014

Timestep Collection Time: 13.32548
Timestep Consumption Time: 2.55553
PPO Batch Consumption Time: 0.05932
Total Iteration Time: 15.88101

Cumulative Model Updates: 48,040
Cumulative Timesteps: 801,307,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 801307034...
Checkpoint 801307034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,153.09227
Policy Entropy: 1.05889
Value Function Loss: 4.14233

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.16552
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.09833

Collected Steps per Second: 3,716.60483
Overall Steps per Second: 3,084.05343

Timestep Collection Time: 13.46713
Timestep Consumption Time: 2.76216
PPO Batch Consumption Time: 0.05311
Total Iteration Time: 16.22929

Cumulative Model Updates: 48,043
Cumulative Timesteps: 801,357,086

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740,820.19335
Policy Entropy: 1.07622
Value Function Loss: 4.08518

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.09634

Collected Steps per Second: 3,729.52396
Overall Steps per Second: 3,129.57137

Timestep Collection Time: 13.41833
Timestep Consumption Time: 2.57235
PPO Batch Consumption Time: 0.06876
Total Iteration Time: 15.99069

Cumulative Model Updates: 48,046
Cumulative Timesteps: 801,407,130

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 801407130...
Checkpoint 801407130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,749.75086
Policy Entropy: 1.08270
Value Function Loss: 4.02148

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.10064

Collected Steps per Second: 3,733.57816
Overall Steps per Second: 3,106.17686

Timestep Collection Time: 13.39251
Timestep Consumption Time: 2.70509
PPO Batch Consumption Time: 0.05975
Total Iteration Time: 16.09760

Cumulative Model Updates: 48,049
Cumulative Timesteps: 801,457,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,878.55021
Policy Entropy: 1.07218
Value Function Loss: 4.13745

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.09787

Collected Steps per Second: 3,741.89904
Overall Steps per Second: 3,074.07433

Timestep Collection Time: 13.36754
Timestep Consumption Time: 2.90402
PPO Batch Consumption Time: 0.06672
Total Iteration Time: 16.27156

Cumulative Model Updates: 48,052
Cumulative Timesteps: 801,507,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 801507152...
Checkpoint 801507152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,095.24379
Policy Entropy: 1.06274
Value Function Loss: 4.19172

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.09378

Collected Steps per Second: 3,945.73077
Overall Steps per Second: 3,245.23311

Timestep Collection Time: 12.67598
Timestep Consumption Time: 2.73617
PPO Batch Consumption Time: 0.05220
Total Iteration Time: 15.41214

Cumulative Model Updates: 48,055
Cumulative Timesteps: 801,557,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,692.95536
Policy Entropy: 1.07834
Value Function Loss: 4.45355

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 3,737.48967
Overall Steps per Second: 3,060.15797

Timestep Collection Time: 13.37796
Timestep Consumption Time: 2.96106
PPO Batch Consumption Time: 0.06569
Total Iteration Time: 16.33903

Cumulative Model Updates: 48,058
Cumulative Timesteps: 801,607,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 801607168...
Checkpoint 801607168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,669.70679
Policy Entropy: 1.07728
Value Function Loss: 4.37805

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.08453

Collected Steps per Second: 3,686.78164
Overall Steps per Second: 3,079.39451

Timestep Collection Time: 13.57010
Timestep Consumption Time: 2.67660
PPO Batch Consumption Time: 0.05769
Total Iteration Time: 16.24670

Cumulative Model Updates: 48,061
Cumulative Timesteps: 801,657,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,717.97478
Policy Entropy: 1.06684
Value Function Loss: 4.28097

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.09130

Collected Steps per Second: 3,648.36023
Overall Steps per Second: 3,032.00821

Timestep Collection Time: 13.71356
Timestep Consumption Time: 2.78772
PPO Batch Consumption Time: 0.06269
Total Iteration Time: 16.50127

Cumulative Model Updates: 48,064
Cumulative Timesteps: 801,707,230

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 801707230...
Checkpoint 801707230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624,081.91850
Policy Entropy: 1.05497
Value Function Loss: 4.04097

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.17237
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.08904

Collected Steps per Second: 3,783.21649
Overall Steps per Second: 3,197.08291

Timestep Collection Time: 13.22367
Timestep Consumption Time: 2.42435
PPO Batch Consumption Time: 0.06214
Total Iteration Time: 15.64801

Cumulative Model Updates: 48,067
Cumulative Timesteps: 801,757,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,500.18096
Policy Entropy: 1.06144
Value Function Loss: 4.10592

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.08971

Collected Steps per Second: 3,685.65468
Overall Steps per Second: 3,041.46459

Timestep Collection Time: 13.57154
Timestep Consumption Time: 2.87449
PPO Batch Consumption Time: 0.06300
Total Iteration Time: 16.44602

Cumulative Model Updates: 48,070
Cumulative Timesteps: 801,807,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 801807278...
Checkpoint 801807278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,135.74510
Policy Entropy: 1.06878
Value Function Loss: 4.35277

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.08400

Collected Steps per Second: 3,833.74555
Overall Steps per Second: 3,150.11745

Timestep Collection Time: 13.05094
Timestep Consumption Time: 2.83227
PPO Batch Consumption Time: 0.06464
Total Iteration Time: 15.88322

Cumulative Model Updates: 48,073
Cumulative Timesteps: 801,857,312

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,777.71081
Policy Entropy: 1.04944
Value Function Loss: 4.37561

Mean KL Divergence: 0.04075
SB3 Clip Fraction: 0.16233
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.07595

Collected Steps per Second: 3,777.37055
Overall Steps per Second: 3,097.91518

Timestep Collection Time: 13.24678
Timestep Consumption Time: 2.90537
PPO Batch Consumption Time: 0.06566
Total Iteration Time: 16.15215

Cumulative Model Updates: 48,076
Cumulative Timesteps: 801,907,350

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 801907350...
Checkpoint 801907350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,245.13455
Policy Entropy: 1.06343
Value Function Loss: 4.33040

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.09308

Collected Steps per Second: 3,806.39252
Overall Steps per Second: 3,124.08026

Timestep Collection Time: 13.13842
Timestep Consumption Time: 2.86949
PPO Batch Consumption Time: 0.06741
Total Iteration Time: 16.00791

Cumulative Model Updates: 48,079
Cumulative Timesteps: 801,957,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,647.60377
Policy Entropy: 1.06186
Value Function Loss: 4.22277

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.15503
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.08818

Collected Steps per Second: 3,870.74383
Overall Steps per Second: 3,156.88588

Timestep Collection Time: 12.92516
Timestep Consumption Time: 2.92273
PPO Batch Consumption Time: 0.06327
Total Iteration Time: 15.84790

Cumulative Model Updates: 48,082
Cumulative Timesteps: 802,007,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 802007390...
Checkpoint 802007390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,384.92401
Policy Entropy: 1.03863
Value Function Loss: 4.25776

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.16864
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.08333

Collected Steps per Second: 3,778.27689
Overall Steps per Second: 3,111.75673

Timestep Collection Time: 13.23566
Timestep Consumption Time: 2.83500
PPO Batch Consumption Time: 0.06737
Total Iteration Time: 16.07066

Cumulative Model Updates: 48,085
Cumulative Timesteps: 802,057,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516,332.75877
Policy Entropy: 1.05373
Value Function Loss: 4.32393

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.08815

Collected Steps per Second: 3,742.02926
Overall Steps per Second: 3,139.16223

Timestep Collection Time: 13.36868
Timestep Consumption Time: 2.56742
PPO Batch Consumption Time: 0.06239
Total Iteration Time: 15.93610

Cumulative Model Updates: 48,088
Cumulative Timesteps: 802,107,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 802107424...
Checkpoint 802107424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,303.65366
Policy Entropy: 1.06149
Value Function Loss: 4.30412

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.08756

Collected Steps per Second: 3,876.51613
Overall Steps per Second: 3,172.54017

Timestep Collection Time: 12.90643
Timestep Consumption Time: 2.86389
PPO Batch Consumption Time: 0.06562
Total Iteration Time: 15.77033

Cumulative Model Updates: 48,091
Cumulative Timesteps: 802,157,456

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535,790.02985
Policy Entropy: 1.05115
Value Function Loss: 4.28118

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.09637

Collected Steps per Second: 3,667.98978
Overall Steps per Second: 3,067.84315

Timestep Collection Time: 13.64344
Timestep Consumption Time: 2.66900
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 16.31244

Cumulative Model Updates: 48,094
Cumulative Timesteps: 802,207,500

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 802207500...
Checkpoint 802207500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,779.74086
Policy Entropy: 1.03185
Value Function Loss: 4.03429

Mean KL Divergence: 0.03186
SB3 Clip Fraction: 0.19762
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.09835

Collected Steps per Second: 3,758.77279
Overall Steps per Second: 3,089.19854

Timestep Collection Time: 13.31126
Timestep Consumption Time: 2.88517
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 16.19643

Cumulative Model Updates: 48,097
Cumulative Timesteps: 802,257,534

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,034.95154
Policy Entropy: 1.05520
Value Function Loss: 3.91181

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.09138

Collected Steps per Second: 3,698.37892
Overall Steps per Second: 3,065.58900

Timestep Collection Time: 13.52106
Timestep Consumption Time: 2.79098
PPO Batch Consumption Time: 0.06343
Total Iteration Time: 16.31204

Cumulative Model Updates: 48,100
Cumulative Timesteps: 802,307,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 802307540...
Checkpoint 802307540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,946.38186
Policy Entropy: 1.04201
Value Function Loss: 3.96515

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.08733

Collected Steps per Second: 3,657.21739
Overall Steps per Second: 3,099.04340

Timestep Collection Time: 13.67706
Timestep Consumption Time: 2.46340
PPO Batch Consumption Time: 0.06505
Total Iteration Time: 16.14046

Cumulative Model Updates: 48,103
Cumulative Timesteps: 802,357,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,796.11962
Policy Entropy: 1.03558
Value Function Loss: 4.16159

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.08669

Collected Steps per Second: 3,858.08719
Overall Steps per Second: 3,194.62813

Timestep Collection Time: 12.96860
Timestep Consumption Time: 2.69331
PPO Batch Consumption Time: 0.05391
Total Iteration Time: 15.66192

Cumulative Model Updates: 48,106
Cumulative Timesteps: 802,407,594

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 802407594...
Checkpoint 802407594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618,484.97515
Policy Entropy: 1.04935
Value Function Loss: 4.27483

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.14669
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.09476

Collected Steps per Second: 4,344.71270
Overall Steps per Second: 3,582.69681

Timestep Collection Time: 11.51284
Timestep Consumption Time: 2.44871
PPO Batch Consumption Time: 0.06029
Total Iteration Time: 13.96155

Cumulative Model Updates: 48,109
Cumulative Timesteps: 802,457,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,224.34538
Policy Entropy: 1.05476
Value Function Loss: 4.16900

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.11185
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.09266

Collected Steps per Second: 4,682.15431
Overall Steps per Second: 3,800.86739

Timestep Collection Time: 10.68867
Timestep Consumption Time: 2.47833
PPO Batch Consumption Time: 0.06406
Total Iteration Time: 13.16699

Cumulative Model Updates: 48,112
Cumulative Timesteps: 802,507,660

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 802507660...
Checkpoint 802507660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,659.47815
Policy Entropy: 1.06476
Value Function Loss: 4.02757

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.08416

Collected Steps per Second: 4,035.92872
Overall Steps per Second: 3,310.25590

Timestep Collection Time: 12.39516
Timestep Consumption Time: 2.71726
PPO Batch Consumption Time: 0.06703
Total Iteration Time: 15.11243

Cumulative Model Updates: 48,115
Cumulative Timesteps: 802,557,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,829.54107
Policy Entropy: 1.05081
Value Function Loss: 4.07612

Mean KL Divergence: 0.02790
SB3 Clip Fraction: 0.15617
Policy Update Magnitude: 0.06949
Value Function Update Magnitude: 0.08202

Collected Steps per Second: 4,029.04090
Overall Steps per Second: 3,357.80191

Timestep Collection Time: 12.41189
Timestep Consumption Time: 2.48119
PPO Batch Consumption Time: 0.06130
Total Iteration Time: 14.89308

Cumulative Model Updates: 48,118
Cumulative Timesteps: 802,607,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 802607694...
Checkpoint 802607694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722,919.77559
Policy Entropy: 1.05768
Value Function Loss: 4.34700

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.08163

Collected Steps per Second: 4,030.57157
Overall Steps per Second: 3,359.17440

Timestep Collection Time: 12.40668
Timestep Consumption Time: 2.47972
PPO Batch Consumption Time: 0.06249
Total Iteration Time: 14.88640

Cumulative Model Updates: 48,121
Cumulative Timesteps: 802,657,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,504.88589
Policy Entropy: 1.05867
Value Function Loss: 4.50229

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 3,952.28524
Overall Steps per Second: 3,337.29584

Timestep Collection Time: 12.65394
Timestep Consumption Time: 2.33184
PPO Batch Consumption Time: 0.06119
Total Iteration Time: 14.98579

Cumulative Model Updates: 48,124
Cumulative Timesteps: 802,707,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 802707712...
Checkpoint 802707712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,536.43722
Policy Entropy: 1.06755
Value Function Loss: 4.51030

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.09984

Collected Steps per Second: 4,118.13705
Overall Steps per Second: 3,393.12147

Timestep Collection Time: 12.14530
Timestep Consumption Time: 2.59511
PPO Batch Consumption Time: 0.05421
Total Iteration Time: 14.74041

Cumulative Model Updates: 48,127
Cumulative Timesteps: 802,757,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,276.70120
Policy Entropy: 1.06410
Value Function Loss: 4.34240

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.06589
Value Function Update Magnitude: 0.10575

Collected Steps per Second: 4,006.98385
Overall Steps per Second: 3,324.30609

Timestep Collection Time: 12.48520
Timestep Consumption Time: 2.56395
PPO Batch Consumption Time: 0.05923
Total Iteration Time: 15.04916

Cumulative Model Updates: 48,130
Cumulative Timesteps: 802,807,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 802807756...
Checkpoint 802807756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,340.61221
Policy Entropy: 1.05419
Value Function Loss: 4.29367

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.15902
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.11604

Collected Steps per Second: 4,146.51382
Overall Steps per Second: 3,385.61159

Timestep Collection Time: 12.06459
Timestep Consumption Time: 2.71147
PPO Batch Consumption Time: 0.06165
Total Iteration Time: 14.77606

Cumulative Model Updates: 48,133
Cumulative Timesteps: 802,857,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,076.52132
Policy Entropy: 1.07101
Value Function Loss: 4.12457

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 4,090.21135
Overall Steps per Second: 3,394.62180

Timestep Collection Time: 12.22577
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.06298
Total Iteration Time: 14.73095

Cumulative Model Updates: 48,136
Cumulative Timesteps: 802,907,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 802907788...
Checkpoint 802907788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,337.40296
Policy Entropy: 1.08196
Value Function Loss: 4.18272

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.11406

Collected Steps per Second: 4,110.23887
Overall Steps per Second: 3,449.79568

Timestep Collection Time: 12.17496
Timestep Consumption Time: 2.33083
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 14.50579

Cumulative Model Updates: 48,139
Cumulative Timesteps: 802,957,830

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,981.03814
Policy Entropy: 1.07416
Value Function Loss: 4.15827

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.09513

Collected Steps per Second: 3,988.53188
Overall Steps per Second: 3,330.45549

Timestep Collection Time: 12.54497
Timestep Consumption Time: 2.47880
PPO Batch Consumption Time: 0.05414
Total Iteration Time: 15.02377

Cumulative Model Updates: 48,142
Cumulative Timesteps: 803,007,866

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 803007866...
Checkpoint 803007866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,197.09107
Policy Entropy: 1.05873
Value Function Loss: 4.16515

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.16255
Policy Update Magnitude: 0.05217
Value Function Update Magnitude: 0.09225

Collected Steps per Second: 3,858.80389
Overall Steps per Second: 3,166.59548

Timestep Collection Time: 12.95894
Timestep Consumption Time: 2.83279
PPO Batch Consumption Time: 0.05970
Total Iteration Time: 15.79172

Cumulative Model Updates: 48,145
Cumulative Timesteps: 803,057,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566,635.23230
Policy Entropy: 1.06903
Value Function Loss: 3.96521

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.09555

Collected Steps per Second: 3,891.61636
Overall Steps per Second: 3,235.74223

Timestep Collection Time: 12.85790
Timestep Consumption Time: 2.60625
PPO Batch Consumption Time: 0.06585
Total Iteration Time: 15.46415

Cumulative Model Updates: 48,148
Cumulative Timesteps: 803,107,910

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 803107910...
Checkpoint 803107910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,185.84739
Policy Entropy: 1.06952
Value Function Loss: 4.03769

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.09133

Collected Steps per Second: 3,798.88343
Overall Steps per Second: 3,181.15095

Timestep Collection Time: 13.17598
Timestep Consumption Time: 2.55858
PPO Batch Consumption Time: 0.06155
Total Iteration Time: 15.73456

Cumulative Model Updates: 48,151
Cumulative Timesteps: 803,157,964

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515,209.07565
Policy Entropy: 1.05509
Value Function Loss: 4.23396

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.08661

Collected Steps per Second: 3,898.21676
Overall Steps per Second: 3,315.85608

Timestep Collection Time: 12.83972
Timestep Consumption Time: 2.25503
PPO Batch Consumption Time: 0.05097
Total Iteration Time: 15.09474

Cumulative Model Updates: 48,154
Cumulative Timesteps: 803,208,016

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 803208016...
Checkpoint 803208016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,424.64410
Policy Entropy: 1.05392
Value Function Loss: 4.48232

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.15232
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.08381

Collected Steps per Second: 3,848.08155
Overall Steps per Second: 3,154.71313

Timestep Collection Time: 12.99972
Timestep Consumption Time: 2.85718
PPO Batch Consumption Time: 0.06226
Total Iteration Time: 15.85691

Cumulative Model Updates: 48,157
Cumulative Timesteps: 803,258,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,015.72887
Policy Entropy: 1.06714
Value Function Loss: 4.46282

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.09121

Collected Steps per Second: 3,829.47523
Overall Steps per Second: 3,240.29480

Timestep Collection Time: 13.05714
Timestep Consumption Time: 2.37417
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 15.43131

Cumulative Model Updates: 48,160
Cumulative Timesteps: 803,308,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 803308042...
Checkpoint 803308042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,671.37275
Policy Entropy: 1.07728
Value Function Loss: 4.25785

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.15425
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.10172

Collected Steps per Second: 3,962.91680
Overall Steps per Second: 3,238.28085

Timestep Collection Time: 12.62858
Timestep Consumption Time: 2.82592
PPO Batch Consumption Time: 0.06217
Total Iteration Time: 15.45450

Cumulative Model Updates: 48,163
Cumulative Timesteps: 803,358,088

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,493.67312
Policy Entropy: 1.05709
Value Function Loss: 4.08385

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.09373

Collected Steps per Second: 3,875.12225
Overall Steps per Second: 3,228.83037

Timestep Collection Time: 12.91366
Timestep Consumption Time: 2.58483
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 15.49849

Cumulative Model Updates: 48,166
Cumulative Timesteps: 803,408,130

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 803408130...
Checkpoint 803408130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,137.19465
Policy Entropy: 1.06987
Value Function Loss: 4.10740

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.08414

Collected Steps per Second: 4,224.49851
Overall Steps per Second: 3,453.10110

Timestep Collection Time: 11.84567
Timestep Consumption Time: 2.64623
PPO Batch Consumption Time: 0.06337
Total Iteration Time: 14.49190

Cumulative Model Updates: 48,169
Cumulative Timesteps: 803,458,172

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,558.97424
Policy Entropy: 1.06844
Value Function Loss: 4.14660

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.11168
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.09013

Collected Steps per Second: 4,367.09291
Overall Steps per Second: 3,520.76015

Timestep Collection Time: 11.45384
Timestep Consumption Time: 2.75332
PPO Batch Consumption Time: 0.06012
Total Iteration Time: 14.20716

Cumulative Model Updates: 48,172
Cumulative Timesteps: 803,508,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 803508192...
Checkpoint 803508192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,892.35700
Policy Entropy: 1.07227
Value Function Loss: 4.22084

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.07047
Value Function Update Magnitude: 0.08202

Collected Steps per Second: 4,123.46143
Overall Steps per Second: 3,416.63800

Timestep Collection Time: 12.12962
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.06953
Total Iteration Time: 14.63895

Cumulative Model Updates: 48,175
Cumulative Timesteps: 803,558,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692,134.44593
Policy Entropy: 1.06701
Value Function Loss: 4.12788

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.07012
Value Function Update Magnitude: 0.08095

Collected Steps per Second: 3,882.74793
Overall Steps per Second: 3,187.94955

Timestep Collection Time: 12.88572
Timestep Consumption Time: 2.80838
PPO Batch Consumption Time: 0.05903
Total Iteration Time: 15.69410

Cumulative Model Updates: 48,178
Cumulative Timesteps: 803,608,240

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 803608240...
Checkpoint 803608240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,222.61434
Policy Entropy: 1.06479
Value Function Loss: 4.14314

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.08344

Collected Steps per Second: 3,864.47585
Overall Steps per Second: 3,205.48726

Timestep Collection Time: 12.94820
Timestep Consumption Time: 2.66191
PPO Batch Consumption Time: 0.06207
Total Iteration Time: 15.61011

Cumulative Model Updates: 48,181
Cumulative Timesteps: 803,658,278

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528,909.29992
Policy Entropy: 1.07564
Value Function Loss: 4.18579

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.08795

Collected Steps per Second: 3,902.06174
Overall Steps per Second: 3,256.71132

Timestep Collection Time: 12.82296
Timestep Consumption Time: 2.54100
PPO Batch Consumption Time: 0.05822
Total Iteration Time: 15.36397

Cumulative Model Updates: 48,184
Cumulative Timesteps: 803,708,314

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 803708314...
Checkpoint 803708314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,134.63619
Policy Entropy: 1.08322
Value Function Loss: 4.19570

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.06747
Value Function Update Magnitude: 0.08613

Collected Steps per Second: 3,842.84910
Overall Steps per Second: 3,216.26665

Timestep Collection Time: 13.02159
Timestep Consumption Time: 2.53682
PPO Batch Consumption Time: 0.05003
Total Iteration Time: 15.55841

Cumulative Model Updates: 48,187
Cumulative Timesteps: 803,758,354

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699,094.75852
Policy Entropy: 1.08378
Value Function Loss: 4.37213

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.06402
Value Function Update Magnitude: 0.08521

Collected Steps per Second: 3,815.43763
Overall Steps per Second: 3,199.36784

Timestep Collection Time: 13.11252
Timestep Consumption Time: 2.52494
PPO Batch Consumption Time: 0.05065
Total Iteration Time: 15.63746

Cumulative Model Updates: 48,190
Cumulative Timesteps: 803,808,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 803808384...
Checkpoint 803808384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,845.79034
Policy Entropy: 1.07769
Value Function Loss: 4.22758

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.06355
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 3,823.47888
Overall Steps per Second: 3,172.82549

Timestep Collection Time: 13.07710
Timestep Consumption Time: 2.68173
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 15.75882

Cumulative Model Updates: 48,193
Cumulative Timesteps: 803,858,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551,202.04885
Policy Entropy: 1.07499
Value Function Loss: 4.24213

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.08558

Collected Steps per Second: 3,837.02189
Overall Steps per Second: 3,198.45266

Timestep Collection Time: 13.04241
Timestep Consumption Time: 2.60391
PPO Batch Consumption Time: 0.05837
Total Iteration Time: 15.64632

Cumulative Model Updates: 48,196
Cumulative Timesteps: 803,908,428

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 803908428...
Checkpoint 803908428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,898.22434
Policy Entropy: 1.08403
Value Function Loss: 4.23844

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.08710

Collected Steps per Second: 3,826.57480
Overall Steps per Second: 3,177.79076

Timestep Collection Time: 13.07697
Timestep Consumption Time: 2.66982
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 15.74679

Cumulative Model Updates: 48,199
Cumulative Timesteps: 803,958,468

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,091.27147
Policy Entropy: 1.08838
Value Function Loss: 4.60049

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.10404

Collected Steps per Second: 3,877.85388
Overall Steps per Second: 3,187.95097

Timestep Collection Time: 12.90353
Timestep Consumption Time: 2.79245
PPO Batch Consumption Time: 0.05984
Total Iteration Time: 15.69598

Cumulative Model Updates: 48,202
Cumulative Timesteps: 804,008,506

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 804008506...
Checkpoint 804008506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,598.64441
Policy Entropy: 1.09782
Value Function Loss: 4.58018

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.11228

Collected Steps per Second: 3,836.04277
Overall Steps per Second: 3,246.91631

Timestep Collection Time: 13.03792
Timestep Consumption Time: 2.36562
PPO Batch Consumption Time: 0.06357
Total Iteration Time: 15.40354

Cumulative Model Updates: 48,205
Cumulative Timesteps: 804,058,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,089.14920
Policy Entropy: 1.10362
Value Function Loss: 4.55123

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.10965

Collected Steps per Second: 3,850.00237
Overall Steps per Second: 3,150.93906

Timestep Collection Time: 12.98701
Timestep Consumption Time: 2.88128
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 15.86829

Cumulative Model Updates: 48,208
Cumulative Timesteps: 804,108,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 804108520...
Checkpoint 804108520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,412.51812
Policy Entropy: 1.10323
Value Function Loss: 4.36346

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.07888
Value Function Update Magnitude: 0.09934

Collected Steps per Second: 3,853.98110
Overall Steps per Second: 3,253.23387

Timestep Collection Time: 12.98190
Timestep Consumption Time: 2.39726
PPO Batch Consumption Time: 0.05088
Total Iteration Time: 15.37916

Cumulative Model Updates: 48,211
Cumulative Timesteps: 804,158,552

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,990.65096
Policy Entropy: 1.08745
Value Function Loss: 4.35548

Mean KL Divergence: 0.02343
SB3 Clip Fraction: 0.15829
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.09817

Collected Steps per Second: 3,824.78133
Overall Steps per Second: 3,178.83141

Timestep Collection Time: 13.07630
Timestep Consumption Time: 2.65715
PPO Batch Consumption Time: 0.05755
Total Iteration Time: 15.73345

Cumulative Model Updates: 48,214
Cumulative Timesteps: 804,208,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 804208566...
Checkpoint 804208566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,201.17231
Policy Entropy: 1.09643
Value Function Loss: 4.25905

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.09996

Collected Steps per Second: 3,840.39343
Overall Steps per Second: 3,190.71328

Timestep Collection Time: 13.02210
Timestep Consumption Time: 2.65151
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 15.67361

Cumulative Model Updates: 48,217
Cumulative Timesteps: 804,258,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727,034.28929
Policy Entropy: 1.09427
Value Function Loss: 4.31064

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.10687

Collected Steps per Second: 3,956.05572
Overall Steps per Second: 3,289.33214

Timestep Collection Time: 12.65098
Timestep Consumption Time: 2.56426
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 15.21525

Cumulative Model Updates: 48,220
Cumulative Timesteps: 804,308,624

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 804308624...
Checkpoint 804308624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575,033.21884
Policy Entropy: 1.10432
Value Function Loss: 4.32422

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.11265
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.10937

Collected Steps per Second: 4,086.60641
Overall Steps per Second: 3,336.22351

Timestep Collection Time: 12.23705
Timestep Consumption Time: 2.75236
PPO Batch Consumption Time: 0.05832
Total Iteration Time: 14.98940

Cumulative Model Updates: 48,223
Cumulative Timesteps: 804,358,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,338.78838
Policy Entropy: 1.10503
Value Function Loss: 4.33983

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.10984

Collected Steps per Second: 3,917.48255
Overall Steps per Second: 3,267.89462

Timestep Collection Time: 12.76789
Timestep Consumption Time: 2.53799
PPO Batch Consumption Time: 0.06546
Total Iteration Time: 15.30588

Cumulative Model Updates: 48,226
Cumulative Timesteps: 804,408,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 804408650...
Checkpoint 804408650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,070.33228
Policy Entropy: 1.09547
Value Function Loss: 4.32179

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.11051

Collected Steps per Second: 3,859.26403
Overall Steps per Second: 3,182.48424

Timestep Collection Time: 12.95584
Timestep Consumption Time: 2.75516
PPO Batch Consumption Time: 0.06694
Total Iteration Time: 15.71100

Cumulative Model Updates: 48,229
Cumulative Timesteps: 804,458,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,483.55479
Policy Entropy: 1.10767
Value Function Loss: 4.46638

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.10374

Collected Steps per Second: 3,956.05064
Overall Steps per Second: 3,283.78795

Timestep Collection Time: 12.63937
Timestep Consumption Time: 2.58755
PPO Batch Consumption Time: 0.06507
Total Iteration Time: 15.22693

Cumulative Model Updates: 48,232
Cumulative Timesteps: 804,508,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 804508652...
Checkpoint 804508652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,696.03386
Policy Entropy: 1.10945
Value Function Loss: 4.38397

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.10099

Collected Steps per Second: 3,850.11152
Overall Steps per Second: 3,146.92289

Timestep Collection Time: 12.98975
Timestep Consumption Time: 2.90260
PPO Batch Consumption Time: 0.06147
Total Iteration Time: 15.89235

Cumulative Model Updates: 48,235
Cumulative Timesteps: 804,558,664

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,668.46280
Policy Entropy: 1.11098
Value Function Loss: 4.15237

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.07402
Value Function Update Magnitude: 0.09917

Collected Steps per Second: 3,863.43867
Overall Steps per Second: 3,195.51235

Timestep Collection Time: 12.94909
Timestep Consumption Time: 2.70662
PPO Batch Consumption Time: 0.06257
Total Iteration Time: 15.65571

Cumulative Model Updates: 48,238
Cumulative Timesteps: 804,608,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 804608692...
Checkpoint 804608692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,402.75413
Policy Entropy: 1.10260
Value Function Loss: 4.03443

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.07068
Value Function Update Magnitude: 0.09112

Collected Steps per Second: 3,805.79779
Overall Steps per Second: 3,182.40655

Timestep Collection Time: 13.14994
Timestep Consumption Time: 2.57590
PPO Batch Consumption Time: 0.06923
Total Iteration Time: 15.72583

Cumulative Model Updates: 48,241
Cumulative Timesteps: 804,658,738

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,279.56395
Policy Entropy: 1.11672
Value Function Loss: 4.11053

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.09554

Collected Steps per Second: 3,943.30596
Overall Steps per Second: 3,230.56079

Timestep Collection Time: 12.68834
Timestep Consumption Time: 2.79938
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 15.48771

Cumulative Model Updates: 48,244
Cumulative Timesteps: 804,708,772

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 804708772...
Checkpoint 804708772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,067.53298
Policy Entropy: 1.11486
Value Function Loss: 4.24562

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.10176

Collected Steps per Second: 3,832.54757
Overall Steps per Second: 3,210.07058

Timestep Collection Time: 13.05555
Timestep Consumption Time: 2.53165
PPO Batch Consumption Time: 0.06519
Total Iteration Time: 15.58720

Cumulative Model Updates: 48,247
Cumulative Timesteps: 804,758,808

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592,904.66675
Policy Entropy: 1.09718
Value Function Loss: 4.21779

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.10172

Collected Steps per Second: 3,832.98507
Overall Steps per Second: 3,165.40126

Timestep Collection Time: 13.05249
Timestep Consumption Time: 2.75277
PPO Batch Consumption Time: 0.06561
Total Iteration Time: 15.80526

Cumulative Model Updates: 48,250
Cumulative Timesteps: 804,808,838

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 804808838...
Checkpoint 804808838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,402.91773
Policy Entropy: 1.09274
Value Function Loss: 4.39106

Mean KL Divergence: 0.03062
SB3 Clip Fraction: 0.16097
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.09969

Collected Steps per Second: 3,891.46178
Overall Steps per Second: 3,202.45674

Timestep Collection Time: 12.85892
Timestep Consumption Time: 2.76658
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 15.62550

Cumulative Model Updates: 48,253
Cumulative Timesteps: 804,858,878

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,812.87536
Policy Entropy: 1.11098
Value Function Loss: 4.32922

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.09321

Collected Steps per Second: 3,965.78979
Overall Steps per Second: 3,253.00527

Timestep Collection Time: 12.61085
Timestep Consumption Time: 2.76324
PPO Batch Consumption Time: 0.05924
Total Iteration Time: 15.37409

Cumulative Model Updates: 48,256
Cumulative Timesteps: 804,908,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 804908890...
Checkpoint 804908890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,759.88451
Policy Entropy: 1.10682
Value Function Loss: 4.34352

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.10073

Collected Steps per Second: 3,832.45752
Overall Steps per Second: 3,156.76541

Timestep Collection Time: 13.05168
Timestep Consumption Time: 2.79366
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 15.84533

Cumulative Model Updates: 48,259
Cumulative Timesteps: 804,958,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,920.56592
Policy Entropy: 1.08833
Value Function Loss: 4.18767

Mean KL Divergence: 0.03585
SB3 Clip Fraction: 0.20043
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.10141

Collected Steps per Second: 3,771.08720
Overall Steps per Second: 3,175.76611

Timestep Collection Time: 13.27044
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.05257
Total Iteration Time: 15.75809

Cumulative Model Updates: 48,262
Cumulative Timesteps: 805,008,954

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 805008954...
Checkpoint 805008954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,534.14036
Policy Entropy: 1.10527
Value Function Loss: 4.09598

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.09069

Collected Steps per Second: 3,902.35367
Overall Steps per Second: 3,135.42410

Timestep Collection Time: 12.81944
Timestep Consumption Time: 3.13566
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 15.95510

Cumulative Model Updates: 48,265
Cumulative Timesteps: 805,058,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,270.01663
Policy Entropy: 1.10604
Value Function Loss: 4.08404

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.09020

Collected Steps per Second: 3,852.24326
Overall Steps per Second: 3,252.16181

Timestep Collection Time: 12.98257
Timestep Consumption Time: 2.39551
PPO Batch Consumption Time: 0.05796
Total Iteration Time: 15.37808

Cumulative Model Updates: 48,268
Cumulative Timesteps: 805,108,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 805108992...
Checkpoint 805108992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,992.47778
Policy Entropy: 1.09253
Value Function Loss: 4.12313

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.09231

Collected Steps per Second: 3,889.64072
Overall Steps per Second: 3,193.35847

Timestep Collection Time: 12.85826
Timestep Consumption Time: 2.80362
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 15.66188

Cumulative Model Updates: 48,271
Cumulative Timesteps: 805,159,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,480.55463
Policy Entropy: 1.09910
Value Function Loss: 4.25707

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.08825

Collected Steps per Second: 3,873.85925
Overall Steps per Second: 3,191.51874

Timestep Collection Time: 12.90909
Timestep Consumption Time: 2.75994
PPO Batch Consumption Time: 0.06521
Total Iteration Time: 15.66903

Cumulative Model Updates: 48,274
Cumulative Timesteps: 805,209,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 805209014...
Checkpoint 805209014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,378.24452
Policy Entropy: 1.10539
Value Function Loss: 4.48728

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.08680

Collected Steps per Second: 3,862.66818
Overall Steps per Second: 3,214.24837

Timestep Collection Time: 12.94856
Timestep Consumption Time: 2.61215
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 15.56071

Cumulative Model Updates: 48,277
Cumulative Timesteps: 805,259,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,263.83718
Policy Entropy: 1.10946
Value Function Loss: 4.36743

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.06585
Value Function Update Magnitude: 0.09431

Collected Steps per Second: 3,780.43643
Overall Steps per Second: 3,112.69958

Timestep Collection Time: 13.23445
Timestep Consumption Time: 2.83906
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 16.07351

Cumulative Model Updates: 48,280
Cumulative Timesteps: 805,309,062

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 805309062...
Checkpoint 805309062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,336.48853
Policy Entropy: 1.10130
Value Function Loss: 4.36063

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.06873
Value Function Update Magnitude: 0.10401

Collected Steps per Second: 3,938.71126
Overall Steps per Second: 3,300.76218

Timestep Collection Time: 12.69451
Timestep Consumption Time: 2.45351
PPO Batch Consumption Time: 0.05795
Total Iteration Time: 15.14802

Cumulative Model Updates: 48,283
Cumulative Timesteps: 805,359,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,252.49019
Policy Entropy: 1.11079
Value Function Loss: 4.13363

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.10024

Collected Steps per Second: 3,824.77219
Overall Steps per Second: 3,153.84776

Timestep Collection Time: 13.07999
Timestep Consumption Time: 2.78253
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 15.86253

Cumulative Model Updates: 48,286
Cumulative Timesteps: 805,409,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 805409090...
Checkpoint 805409090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,980.47789
Policy Entropy: 1.11270
Value Function Loss: 4.20481

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14533
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.09111

Collected Steps per Second: 4,003.44229
Overall Steps per Second: 3,299.55108

Timestep Collection Time: 12.50074
Timestep Consumption Time: 2.66678
PPO Batch Consumption Time: 0.06092
Total Iteration Time: 15.16752

Cumulative Model Updates: 48,289
Cumulative Timesteps: 805,459,136

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,505.60969
Policy Entropy: 1.10113
Value Function Loss: 4.28836

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.09864

Collected Steps per Second: 3,898.27920
Overall Steps per Second: 3,232.78681

Timestep Collection Time: 12.83130
Timestep Consumption Time: 2.64142
PPO Batch Consumption Time: 0.05978
Total Iteration Time: 15.47272

Cumulative Model Updates: 48,292
Cumulative Timesteps: 805,509,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 805509156...
Checkpoint 805509156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558,806.11274
Policy Entropy: 1.09421
Value Function Loss: 4.44622

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.09865

Collected Steps per Second: 3,968.73493
Overall Steps per Second: 3,277.90432

Timestep Collection Time: 12.60956
Timestep Consumption Time: 2.65751
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 15.26707

Cumulative Model Updates: 48,295
Cumulative Timesteps: 805,559,200

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,486.90873
Policy Entropy: 1.10242
Value Function Loss: 4.53560

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.09751

Collected Steps per Second: 3,845.38818
Overall Steps per Second: 3,238.68469

Timestep Collection Time: 13.00675
Timestep Consumption Time: 2.43656
PPO Batch Consumption Time: 0.06857
Total Iteration Time: 15.44331

Cumulative Model Updates: 48,298
Cumulative Timesteps: 805,609,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 805609216...
Checkpoint 805609216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,307.95831
Policy Entropy: 1.10725
Value Function Loss: 4.37658

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.09680

Collected Steps per Second: 3,917.14078
Overall Steps per Second: 3,223.37605

Timestep Collection Time: 12.76441
Timestep Consumption Time: 2.74727
PPO Batch Consumption Time: 0.05950
Total Iteration Time: 15.51169

Cumulative Model Updates: 48,301
Cumulative Timesteps: 805,659,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,116.15686
Policy Entropy: 1.08641
Value Function Loss: 4.25265

Mean KL Divergence: 0.03443
SB3 Clip Fraction: 0.16961
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.08929

Collected Steps per Second: 3,855.10076
Overall Steps per Second: 3,156.83795

Timestep Collection Time: 12.97190
Timestep Consumption Time: 2.86926
PPO Batch Consumption Time: 0.06634
Total Iteration Time: 15.84117

Cumulative Model Updates: 48,304
Cumulative Timesteps: 805,709,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 805709224...
Checkpoint 805709224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,779.73863
Policy Entropy: 1.10104
Value Function Loss: 4.11329

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.09846

Collected Steps per Second: 3,954.33544
Overall Steps per Second: 3,226.24424

Timestep Collection Time: 12.65699
Timestep Consumption Time: 2.85640
PPO Batch Consumption Time: 0.06684
Total Iteration Time: 15.51339

Cumulative Model Updates: 48,307
Cumulative Timesteps: 805,759,274

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,102.77533
Policy Entropy: 1.11133
Value Function Loss: 4.12759

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.15103
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.10246

Collected Steps per Second: 3,767.26590
Overall Steps per Second: 3,141.33996

Timestep Collection Time: 13.28231
Timestep Consumption Time: 2.64656
PPO Batch Consumption Time: 0.06223
Total Iteration Time: 15.92887

Cumulative Model Updates: 48,310
Cumulative Timesteps: 805,809,312

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 805809312...
Checkpoint 805809312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,141.18633
Policy Entropy: 1.09979
Value Function Loss: 4.03102

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.11346

Collected Steps per Second: 3,847.29662
Overall Steps per Second: 3,218.10904

Timestep Collection Time: 12.99978
Timestep Consumption Time: 2.54165
PPO Batch Consumption Time: 0.06070
Total Iteration Time: 15.54142

Cumulative Model Updates: 48,313
Cumulative Timesteps: 805,859,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,678.85806
Policy Entropy: 1.08871
Value Function Loss: 4.07928

Mean KL Divergence: 0.02620
SB3 Clip Fraction: 0.17037
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.12657

Collected Steps per Second: 3,825.91779
Overall Steps per Second: 3,166.21529

Timestep Collection Time: 13.07974
Timestep Consumption Time: 2.72525
PPO Batch Consumption Time: 0.05943
Total Iteration Time: 15.80499

Cumulative Model Updates: 48,316
Cumulative Timesteps: 805,909,368

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 805909368...
Checkpoint 805909368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,437.09267
Policy Entropy: 1.10313
Value Function Loss: 4.23202

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.12107

Collected Steps per Second: 3,905.28733
Overall Steps per Second: 3,217.58617

Timestep Collection Time: 12.80572
Timestep Consumption Time: 2.73699
PPO Batch Consumption Time: 0.06946
Total Iteration Time: 15.54271

Cumulative Model Updates: 48,319
Cumulative Timesteps: 805,959,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,503.76971
Policy Entropy: 1.10493
Value Function Loss: 4.45300

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.11212

Collected Steps per Second: 3,975.97789
Overall Steps per Second: 3,259.40874

Timestep Collection Time: 12.57904
Timestep Consumption Time: 2.76546
PPO Batch Consumption Time: 0.05817
Total Iteration Time: 15.34450

Cumulative Model Updates: 48,322
Cumulative Timesteps: 806,009,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 806009392...
Checkpoint 806009392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,976.38413
Policy Entropy: 1.09184
Value Function Loss: 4.50792

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.10289

Collected Steps per Second: 3,823.79765
Overall Steps per Second: 3,169.70866

Timestep Collection Time: 13.07967
Timestep Consumption Time: 2.69907
PPO Batch Consumption Time: 0.05075
Total Iteration Time: 15.77874

Cumulative Model Updates: 48,325
Cumulative Timesteps: 806,059,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,074.11248
Policy Entropy: 1.07746
Value Function Loss: 4.45098

Mean KL Divergence: 0.02632
SB3 Clip Fraction: 0.16195
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.09387

Collected Steps per Second: 3,952.90999
Overall Steps per Second: 3,287.37838

Timestep Collection Time: 12.65953
Timestep Consumption Time: 2.56293
PPO Batch Consumption Time: 0.06053
Total Iteration Time: 15.22246

Cumulative Model Updates: 48,328
Cumulative Timesteps: 806,109,448

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 806109448...
Checkpoint 806109448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618,557.57328
Policy Entropy: 1.08712
Value Function Loss: 4.49382

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.09594

Collected Steps per Second: 3,839.53801
Overall Steps per Second: 3,152.35815

Timestep Collection Time: 13.02917
Timestep Consumption Time: 2.84022
PPO Batch Consumption Time: 0.06412
Total Iteration Time: 15.86939

Cumulative Model Updates: 48,331
Cumulative Timesteps: 806,159,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,128.06068
Policy Entropy: 1.09118
Value Function Loss: 4.39204

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.09030

Collected Steps per Second: 3,973.72994
Overall Steps per Second: 3,311.29837

Timestep Collection Time: 12.58666
Timestep Consumption Time: 2.51799
PPO Batch Consumption Time: 0.06902
Total Iteration Time: 15.10465

Cumulative Model Updates: 48,334
Cumulative Timesteps: 806,209,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 806209490...
Checkpoint 806209490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,484.81877
Policy Entropy: 1.07185
Value Function Loss: 4.28300

Mean KL Divergence: 0.03185
SB3 Clip Fraction: 0.16968
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.08994

Collected Steps per Second: 3,876.18940
Overall Steps per Second: 3,149.27781

Timestep Collection Time: 12.90752
Timestep Consumption Time: 2.97929
PPO Batch Consumption Time: 0.05197
Total Iteration Time: 15.88682

Cumulative Model Updates: 48,337
Cumulative Timesteps: 806,259,522

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,986.78274
Policy Entropy: 1.09636
Value Function Loss: 4.14767

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.09764

Collected Steps per Second: 3,983.31243
Overall Steps per Second: 3,287.09884

Timestep Collection Time: 12.55337
Timestep Consumption Time: 2.65883
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 15.21220

Cumulative Model Updates: 48,340
Cumulative Timesteps: 806,309,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 806309526...
Checkpoint 806309526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,972.11948
Policy Entropy: 1.09839
Value Function Loss: 4.06978

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.09377

Collected Steps per Second: 3,880.48211
Overall Steps per Second: 3,214.20557

Timestep Collection Time: 12.88603
Timestep Consumption Time: 2.67116
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 15.55719

Cumulative Model Updates: 48,343
Cumulative Timesteps: 806,359,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585,401.74305
Policy Entropy: 1.08902
Value Function Loss: 4.13176

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.05933
Value Function Update Magnitude: 0.08816

Collected Steps per Second: 3,846.69345
Overall Steps per Second: 3,187.24334

Timestep Collection Time: 13.00805
Timestep Consumption Time: 2.69141
PPO Batch Consumption Time: 0.06195
Total Iteration Time: 15.69946

Cumulative Model Updates: 48,346
Cumulative Timesteps: 806,409,568

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 806409568...
Checkpoint 806409568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,898.31830
Policy Entropy: 1.07057
Value Function Loss: 3.97327

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.16562
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.08483

Collected Steps per Second: 3,930.06711
Overall Steps per Second: 3,238.40228

Timestep Collection Time: 12.73312
Timestep Consumption Time: 2.71957
PPO Batch Consumption Time: 0.04775
Total Iteration Time: 15.45268

Cumulative Model Updates: 48,349
Cumulative Timesteps: 806,459,610

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,985.48418
Policy Entropy: 1.08798
Value Function Loss: 4.01789

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.07871

Collected Steps per Second: 3,887.08848
Overall Steps per Second: 3,200.70565

Timestep Collection Time: 12.87390
Timestep Consumption Time: 2.76077
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 15.63468

Cumulative Model Updates: 48,352
Cumulative Timesteps: 806,509,652

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 806509652...
Checkpoint 806509652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,162.70619
Policy Entropy: 1.08559
Value Function Loss: 4.07566

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.07477

Collected Steps per Second: 3,945.53799
Overall Steps per Second: 3,234.86778

Timestep Collection Time: 12.68572
Timestep Consumption Time: 2.78693
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 15.47266

Cumulative Model Updates: 48,355
Cumulative Timesteps: 806,559,704

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,818.87428
Policy Entropy: 1.08342
Value Function Loss: 4.20106

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.08018

Collected Steps per Second: 3,945.76731
Overall Steps per Second: 3,223.66947

Timestep Collection Time: 12.68144
Timestep Consumption Time: 2.84063
PPO Batch Consumption Time: 0.07598
Total Iteration Time: 15.52206

Cumulative Model Updates: 48,358
Cumulative Timesteps: 806,609,742

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 806609742...
Checkpoint 806609742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,821.74834
Policy Entropy: 1.07210
Value Function Loss: 4.25290

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.15887
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.08708

Collected Steps per Second: 3,767.06077
Overall Steps per Second: 3,158.48565

Timestep Collection Time: 13.28622
Timestep Consumption Time: 2.55998
PPO Batch Consumption Time: 0.05380
Total Iteration Time: 15.84620

Cumulative Model Updates: 48,361
Cumulative Timesteps: 806,659,792

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470,820.84544
Policy Entropy: 1.08748
Value Function Loss: 4.31733

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.08622

Collected Steps per Second: 3,853.87908
Overall Steps per Second: 3,195.17980

Timestep Collection Time: 12.98069
Timestep Consumption Time: 2.67602
PPO Batch Consumption Time: 0.05403
Total Iteration Time: 15.65671

Cumulative Model Updates: 48,364
Cumulative Timesteps: 806,709,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 806709818...
Checkpoint 806709818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,738.07023
Policy Entropy: 1.08831
Value Function Loss: 4.28493

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.08970

Collected Steps per Second: 3,868.78255
Overall Steps per Second: 3,205.59328

Timestep Collection Time: 12.93430
Timestep Consumption Time: 2.67591
PPO Batch Consumption Time: 0.06016
Total Iteration Time: 15.61021

Cumulative Model Updates: 48,367
Cumulative Timesteps: 806,759,858

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,489.27990
Policy Entropy: 1.07786
Value Function Loss: 4.32277

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.08822

Collected Steps per Second: 4,040.41520
Overall Steps per Second: 3,308.13222

Timestep Collection Time: 12.38586
Timestep Consumption Time: 2.74171
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 15.12757

Cumulative Model Updates: 48,370
Cumulative Timesteps: 806,809,902

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 806809902...
Checkpoint 806809902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,663.40340
Policy Entropy: 1.07067
Value Function Loss: 4.25321

Mean KL Divergence: 0.02622
SB3 Clip Fraction: 0.18788
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.09774

Collected Steps per Second: 3,844.84364
Overall Steps per Second: 3,144.76878

Timestep Collection Time: 13.00495
Timestep Consumption Time: 2.89511
PPO Batch Consumption Time: 0.06116
Total Iteration Time: 15.90006

Cumulative Model Updates: 48,373
Cumulative Timesteps: 806,859,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,860.53594
Policy Entropy: 1.08075
Value Function Loss: 4.30378

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.11354

Collected Steps per Second: 3,800.91068
Overall Steps per Second: 3,187.79818

Timestep Collection Time: 13.15790
Timestep Consumption Time: 2.53067
PPO Batch Consumption Time: 0.05998
Total Iteration Time: 15.68857

Cumulative Model Updates: 48,376
Cumulative Timesteps: 806,909,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 806909916...
Checkpoint 806909916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575,941.71852
Policy Entropy: 1.07745
Value Function Loss: 4.52360

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.10887

Collected Steps per Second: 3,828.33905
Overall Steps per Second: 3,137.00512

Timestep Collection Time: 13.07042
Timestep Consumption Time: 2.88046
PPO Batch Consumption Time: 0.05206
Total Iteration Time: 15.95088

Cumulative Model Updates: 48,379
Cumulative Timesteps: 806,959,954

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,230.15589
Policy Entropy: 1.07445
Value Function Loss: 4.40448

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.06463
Value Function Update Magnitude: 0.09930

Collected Steps per Second: 3,899.94521
Overall Steps per Second: 3,209.67010

Timestep Collection Time: 12.82531
Timestep Consumption Time: 2.75822
PPO Batch Consumption Time: 0.05885
Total Iteration Time: 15.58353

Cumulative Model Updates: 48,382
Cumulative Timesteps: 807,009,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 807009972...
Checkpoint 807009972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,699.30574
Policy Entropy: 1.05996
Value Function Loss: 4.35451

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.15663
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.09261

Collected Steps per Second: 3,956.16602
Overall Steps per Second: 3,259.32007

Timestep Collection Time: 12.64558
Timestep Consumption Time: 2.70364
PPO Batch Consumption Time: 0.06057
Total Iteration Time: 15.34921

Cumulative Model Updates: 48,385
Cumulative Timesteps: 807,060,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,179.98713
Policy Entropy: 1.08101
Value Function Loss: 4.11665

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.08861

Collected Steps per Second: 3,850.92131
Overall Steps per Second: 3,180.96387

Timestep Collection Time: 12.98910
Timestep Consumption Time: 2.73569
PPO Batch Consumption Time: 0.06116
Total Iteration Time: 15.72479

Cumulative Model Updates: 48,388
Cumulative Timesteps: 807,110,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 807110020...
Checkpoint 807110020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,459.90888
Policy Entropy: 1.07813
Value Function Loss: 4.00290

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.08393

Collected Steps per Second: 3,862.34173
Overall Steps per Second: 3,235.19943

Timestep Collection Time: 12.95121
Timestep Consumption Time: 2.51059
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 15.46180

Cumulative Model Updates: 48,391
Cumulative Timesteps: 807,160,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,791.86975
Policy Entropy: 1.06906
Value Function Loss: 3.92996

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.09632

Collected Steps per Second: 3,854.54156
Overall Steps per Second: 3,165.29406

Timestep Collection Time: 12.97379
Timestep Consumption Time: 2.82506
PPO Batch Consumption Time: 0.05317
Total Iteration Time: 15.79885

Cumulative Model Updates: 48,394
Cumulative Timesteps: 807,210,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 807210050...
Checkpoint 807210050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,118.79001
Policy Entropy: 1.05942
Value Function Loss: 4.01377

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.16970
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.10648

Collected Steps per Second: 3,857.58586
Overall Steps per Second: 3,229.08499

Timestep Collection Time: 12.97029
Timestep Consumption Time: 2.52450
PPO Batch Consumption Time: 0.05960
Total Iteration Time: 15.49479

Cumulative Model Updates: 48,397
Cumulative Timesteps: 807,260,084

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,926.54735
Policy Entropy: 1.06890
Value Function Loss: 4.20895

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.10003

Collected Steps per Second: 3,820.72249
Overall Steps per Second: 3,171.90412

Timestep Collection Time: 13.09124
Timestep Consumption Time: 2.67784
PPO Batch Consumption Time: 0.05997
Total Iteration Time: 15.76908

Cumulative Model Updates: 48,400
Cumulative Timesteps: 807,310,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 807310102...
Checkpoint 807310102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,242.70314
Policy Entropy: 1.07908
Value Function Loss: 4.37844

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.15585
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.09256

Collected Steps per Second: 3,820.56129
Overall Steps per Second: 3,171.73239

Timestep Collection Time: 13.08970
Timestep Consumption Time: 2.67771
PPO Batch Consumption Time: 0.05897
Total Iteration Time: 15.76741

Cumulative Model Updates: 48,403
Cumulative Timesteps: 807,360,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,905.22100
Policy Entropy: 1.06084
Value Function Loss: 4.37965

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.08608

Collected Steps per Second: 3,877.41332
Overall Steps per Second: 3,252.89550

Timestep Collection Time: 12.89571
Timestep Consumption Time: 2.47583
PPO Batch Consumption Time: 0.05871
Total Iteration Time: 15.37154

Cumulative Model Updates: 48,406
Cumulative Timesteps: 807,410,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 807410114...
Checkpoint 807410114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,496.35381
Policy Entropy: 1.07043
Value Function Loss: 4.51191

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 3,932.96915
Overall Steps per Second: 3,232.21706

Timestep Collection Time: 12.72219
Timestep Consumption Time: 2.75820
PPO Batch Consumption Time: 0.06167
Total Iteration Time: 15.48040

Cumulative Model Updates: 48,409
Cumulative Timesteps: 807,460,150

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,113.70580
Policy Entropy: 1.08175
Value Function Loss: 4.48547

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.08213

Collected Steps per Second: 3,784.88431
Overall Steps per Second: 3,184.70559

Timestep Collection Time: 13.21890
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 15.71009

Cumulative Model Updates: 48,412
Cumulative Timesteps: 807,510,182

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 807510182...
Checkpoint 807510182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,930.45047
Policy Entropy: 1.09090
Value Function Loss: 4.50914

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.12101
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.08222

Collected Steps per Second: 3,907.75855
Overall Steps per Second: 3,210.42166

Timestep Collection Time: 12.79813
Timestep Consumption Time: 2.77989
PPO Batch Consumption Time: 0.06784
Total Iteration Time: 15.57802

Cumulative Model Updates: 48,415
Cumulative Timesteps: 807,560,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699,592.83163
Policy Entropy: 1.07194
Value Function Loss: 4.43049

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.07953

Collected Steps per Second: 3,805.71450
Overall Steps per Second: 3,153.95502

Timestep Collection Time: 13.14024
Timestep Consumption Time: 2.71541
PPO Batch Consumption Time: 0.06016
Total Iteration Time: 15.85565

Cumulative Model Updates: 48,418
Cumulative Timesteps: 807,610,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 807610202...
Checkpoint 807610202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,754.13680
Policy Entropy: 1.06040
Value Function Loss: 4.45001

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.08806

Collected Steps per Second: 3,978.47673
Overall Steps per Second: 3,234.49850

Timestep Collection Time: 12.57868
Timestep Consumption Time: 2.89327
PPO Batch Consumption Time: 0.06122
Total Iteration Time: 15.47195

Cumulative Model Updates: 48,421
Cumulative Timesteps: 807,660,246

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,034.71831
Policy Entropy: 1.07196
Value Function Loss: 4.48517

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.09026

Collected Steps per Second: 3,839.68445
Overall Steps per Second: 3,146.61130

Timestep Collection Time: 13.03076
Timestep Consumption Time: 2.87016
PPO Batch Consumption Time: 0.06680
Total Iteration Time: 15.90092

Cumulative Model Updates: 48,424
Cumulative Timesteps: 807,710,280

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 807710280...
Checkpoint 807710280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519,839.29120
Policy Entropy: 1.08217
Value Function Loss: 4.57300

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.09037

Collected Steps per Second: 3,793.60499
Overall Steps per Second: 3,173.96842

Timestep Collection Time: 13.18640
Timestep Consumption Time: 2.57431
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 15.76071

Cumulative Model Updates: 48,427
Cumulative Timesteps: 807,760,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,967.68305
Policy Entropy: 1.06434
Value Function Loss: 4.59897

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.08672

Collected Steps per Second: 3,881.32470
Overall Steps per Second: 3,196.28942

Timestep Collection Time: 12.88375
Timestep Consumption Time: 2.76127
PPO Batch Consumption Time: 0.05917
Total Iteration Time: 15.64502

Cumulative Model Updates: 48,430
Cumulative Timesteps: 807,810,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 807810310...
Checkpoint 807810310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,091.33160
Policy Entropy: 1.05606
Value Function Loss: 4.46065

Mean KL Divergence: 0.02692
SB3 Clip Fraction: 0.15550
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.09066

Collected Steps per Second: 3,890.45098
Overall Steps per Second: 3,263.80663

Timestep Collection Time: 12.86072
Timestep Consumption Time: 2.46923
PPO Batch Consumption Time: 0.06472
Total Iteration Time: 15.32995

Cumulative Model Updates: 48,433
Cumulative Timesteps: 807,860,344

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,804.69122
Policy Entropy: 1.06982
Value Function Loss: 4.37767

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.10150

Collected Steps per Second: 3,854.32783
Overall Steps per Second: 3,183.74985

Timestep Collection Time: 12.97502
Timestep Consumption Time: 2.73287
PPO Batch Consumption Time: 0.06298
Total Iteration Time: 15.70789

Cumulative Model Updates: 48,436
Cumulative Timesteps: 807,910,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 807910354...
Checkpoint 807910354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,582.42972
Policy Entropy: 1.08185
Value Function Loss: 4.25046

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15388
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.11021

Collected Steps per Second: 3,913.20424
Overall Steps per Second: 3,226.09722

Timestep Collection Time: 12.77981
Timestep Consumption Time: 2.72189
PPO Batch Consumption Time: 0.06036
Total Iteration Time: 15.50170

Cumulative Model Updates: 48,439
Cumulative Timesteps: 807,960,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,630.86855
Policy Entropy: 1.06405
Value Function Loss: 4.12980

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.10650

Collected Steps per Second: 3,828.53905
Overall Steps per Second: 3,222.24280

Timestep Collection Time: 13.07026
Timestep Consumption Time: 2.45930
PPO Batch Consumption Time: 0.04814
Total Iteration Time: 15.52956

Cumulative Model Updates: 48,442
Cumulative Timesteps: 808,010,404

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 808010404...
Checkpoint 808010404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,821.42694
Policy Entropy: 1.07514
Value Function Loss: 4.10156

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.09636

Collected Steps per Second: 3,839.88639
Overall Steps per Second: 3,181.05428

Timestep Collection Time: 13.02695
Timestep Consumption Time: 2.69803
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 15.72498

Cumulative Model Updates: 48,445
Cumulative Timesteps: 808,060,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,472.81659
Policy Entropy: 1.07615
Value Function Loss: 4.07045

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.15837
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.09342

Collected Steps per Second: 3,991.68484
Overall Steps per Second: 3,350.11810

Timestep Collection Time: 12.53205
Timestep Consumption Time: 2.39996
PPO Batch Consumption Time: 0.05214
Total Iteration Time: 14.93201

Cumulative Model Updates: 48,448
Cumulative Timesteps: 808,110,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 808110450...
Checkpoint 808110450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,207.47733
Policy Entropy: 1.05956
Value Function Loss: 4.13357

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.09075

Collected Steps per Second: 3,902.47928
Overall Steps per Second: 3,210.53747

Timestep Collection Time: 12.81698
Timestep Consumption Time: 2.76234
PPO Batch Consumption Time: 0.07342
Total Iteration Time: 15.57932

Cumulative Model Updates: 48,451
Cumulative Timesteps: 808,160,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,283.66359
Policy Entropy: 1.05186
Value Function Loss: 4.09835

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.18528
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.08629

Collected Steps per Second: 3,869.33448
Overall Steps per Second: 3,203.13422

Timestep Collection Time: 12.92419
Timestep Consumption Time: 2.68802
PPO Batch Consumption Time: 0.06205
Total Iteration Time: 15.61221

Cumulative Model Updates: 48,454
Cumulative Timesteps: 808,210,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 808210476...
Checkpoint 808210476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,128.33758
Policy Entropy: 1.06558
Value Function Loss: 4.10391

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.09275

Collected Steps per Second: 4,044.09515
Overall Steps per Second: 3,320.75164

Timestep Collection Time: 12.37557
Timestep Consumption Time: 2.69571
PPO Batch Consumption Time: 0.05037
Total Iteration Time: 15.07129

Cumulative Model Updates: 48,457
Cumulative Timesteps: 808,260,524

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,152.76249
Policy Entropy: 1.06710
Value Function Loss: 4.07634

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 3,870.56627
Overall Steps per Second: 3,232.35089

Timestep Collection Time: 12.92679
Timestep Consumption Time: 2.55235
PPO Batch Consumption Time: 0.05276
Total Iteration Time: 15.47914

Cumulative Model Updates: 48,460
Cumulative Timesteps: 808,310,558

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 808310558...
Checkpoint 808310558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,690.38153
Policy Entropy: 1.05586
Value Function Loss: 4.06091

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.11332

Collected Steps per Second: 3,880.16582
Overall Steps per Second: 3,265.75923

Timestep Collection Time: 12.89069
Timestep Consumption Time: 2.42520
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 15.31589

Cumulative Model Updates: 48,463
Cumulative Timesteps: 808,360,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,780.03648
Policy Entropy: 1.06151
Value Function Loss: 4.13717

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.07113
Value Function Update Magnitude: 0.12151

Collected Steps per Second: 3,885.87222
Overall Steps per Second: 3,197.78868

Timestep Collection Time: 12.87330
Timestep Consumption Time: 2.77001
PPO Batch Consumption Time: 0.06099
Total Iteration Time: 15.64331

Cumulative Model Updates: 48,466
Cumulative Timesteps: 808,410,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 808410600...
Checkpoint 808410600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,420.50190
Policy Entropy: 1.06613
Value Function Loss: 4.29433

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.07209
Value Function Update Magnitude: 0.11802

Collected Steps per Second: 3,900.71729
Overall Steps per Second: 3,257.77919

Timestep Collection Time: 12.82021
Timestep Consumption Time: 2.53013
PPO Batch Consumption Time: 0.06372
Total Iteration Time: 15.35033

Cumulative Model Updates: 48,469
Cumulative Timesteps: 808,460,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,734.26970
Policy Entropy: 1.05637
Value Function Loss: 4.27399

Mean KL Divergence: 0.03010
SB3 Clip Fraction: 0.18124
Policy Update Magnitude: 0.07165
Value Function Update Magnitude: 0.11489

Collected Steps per Second: 4,030.53269
Overall Steps per Second: 3,322.86241

Timestep Collection Time: 12.41176
Timestep Consumption Time: 2.64333
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 15.05509

Cumulative Model Updates: 48,472
Cumulative Timesteps: 808,510,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 808510634...
Checkpoint 808510634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653,439.28446
Policy Entropy: 1.07134
Value Function Loss: 4.40222

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.06259
Value Function Update Magnitude: 0.10016

Collected Steps per Second: 3,830.68759
Overall Steps per Second: 3,159.50516

Timestep Collection Time: 13.05353
Timestep Consumption Time: 2.77300
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 15.82653

Cumulative Model Updates: 48,475
Cumulative Timesteps: 808,560,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,439.39970
Policy Entropy: 1.07885
Value Function Loss: 4.32982

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.11026

Collected Steps per Second: 3,880.20836
Overall Steps per Second: 3,252.23009

Timestep Collection Time: 12.88951
Timestep Consumption Time: 2.48886
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 15.37837

Cumulative Model Updates: 48,478
Cumulative Timesteps: 808,610,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 808610652...
Checkpoint 808610652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,053.46982
Policy Entropy: 1.06870
Value Function Loss: 4.39361

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.10805

Collected Steps per Second: 3,844.78796
Overall Steps per Second: 3,175.71301

Timestep Collection Time: 13.01606
Timestep Consumption Time: 2.74229
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 15.75835

Cumulative Model Updates: 48,481
Cumulative Timesteps: 808,660,696

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,291.76486
Policy Entropy: 1.05934
Value Function Loss: 4.31332

Mean KL Divergence: 0.02338
SB3 Clip Fraction: 0.16808
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.09685

Collected Steps per Second: 3,845.39768
Overall Steps per Second: 3,188.02343

Timestep Collection Time: 13.01400
Timestep Consumption Time: 2.68350
PPO Batch Consumption Time: 0.06521
Total Iteration Time: 15.69750

Cumulative Model Updates: 48,484
Cumulative Timesteps: 808,710,740

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 808710740...
Checkpoint 808710740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,490.90185
Policy Entropy: 1.06767
Value Function Loss: 4.35596

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.08957

Collected Steps per Second: 4,023.76363
Overall Steps per Second: 3,311.23790

Timestep Collection Time: 12.43860
Timestep Consumption Time: 2.67659
PPO Batch Consumption Time: 0.06787
Total Iteration Time: 15.11519

Cumulative Model Updates: 48,487
Cumulative Timesteps: 808,760,790

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,904.39904
Policy Entropy: 1.07463
Value Function Loss: 4.30173

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.07999

Collected Steps per Second: 3,823.05769
Overall Steps per Second: 3,163.30842

Timestep Collection Time: 13.08848
Timestep Consumption Time: 2.72977
PPO Batch Consumption Time: 0.06186
Total Iteration Time: 15.81825

Cumulative Model Updates: 48,490
Cumulative Timesteps: 808,810,828

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 808810828...
Checkpoint 808810828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,514.14216
Policy Entropy: 1.04486
Value Function Loss: 4.33009

Mean KL Divergence: 0.04056
SB3 Clip Fraction: 0.18295
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.08284

Collected Steps per Second: 3,732.36161
Overall Steps per Second: 3,138.85737

Timestep Collection Time: 13.40438
Timestep Consumption Time: 2.53454
PPO Batch Consumption Time: 0.05027
Total Iteration Time: 15.93892

Cumulative Model Updates: 48,493
Cumulative Timesteps: 808,860,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,753.70752
Policy Entropy: 1.06743
Value Function Loss: 4.20746

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.08678

Collected Steps per Second: 3,849.93026
Overall Steps per Second: 3,166.72174

Timestep Collection Time: 12.99972
Timestep Consumption Time: 2.80464
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 15.80436

Cumulative Model Updates: 48,496
Cumulative Timesteps: 808,910,906

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 808910906...
Checkpoint 808910906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,709.17958
Policy Entropy: 1.06595
Value Function Loss: 4.24237

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.08455

Collected Steps per Second: 3,796.14132
Overall Steps per Second: 3,183.30797

Timestep Collection Time: 13.18075
Timestep Consumption Time: 2.53749
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 15.71824

Cumulative Model Updates: 48,499
Cumulative Timesteps: 808,960,942

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,073.43770
Policy Entropy: 1.05823
Value Function Loss: 4.26016

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.08413

Collected Steps per Second: 4,046.74194
Overall Steps per Second: 3,311.03741

Timestep Collection Time: 12.36353
Timestep Consumption Time: 2.74715
PPO Batch Consumption Time: 0.06721
Total Iteration Time: 15.11067

Cumulative Model Updates: 48,502
Cumulative Timesteps: 809,010,974

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 809010974...
Checkpoint 809010974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,725.47203
Policy Entropy: 1.04078
Value Function Loss: 4.34104

Mean KL Divergence: 0.02695
SB3 Clip Fraction: 0.16733
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.08811

Collected Steps per Second: 3,699.60183
Overall Steps per Second: 3,053.30071

Timestep Collection Time: 13.51875
Timestep Consumption Time: 2.86155
PPO Batch Consumption Time: 0.06441
Total Iteration Time: 16.38031

Cumulative Model Updates: 48,505
Cumulative Timesteps: 809,060,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,911.78031
Policy Entropy: 1.05593
Value Function Loss: 4.35430

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.07894

Collected Steps per Second: 3,805.99462
Overall Steps per Second: 3,184.20117

Timestep Collection Time: 13.14190
Timestep Consumption Time: 2.56628
PPO Batch Consumption Time: 0.07160
Total Iteration Time: 15.70818

Cumulative Model Updates: 48,508
Cumulative Timesteps: 809,111,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 809111006...
Checkpoint 809111006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,557.05159
Policy Entropy: 1.06175
Value Function Loss: 4.29461

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 3,900.85717
Overall Steps per Second: 3,193.34452

Timestep Collection Time: 12.82026
Timestep Consumption Time: 2.84044
PPO Batch Consumption Time: 0.04669
Total Iteration Time: 15.66070

Cumulative Model Updates: 48,511
Cumulative Timesteps: 809,161,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,395.62286
Policy Entropy: 1.04985
Value Function Loss: 4.31866

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.08407

Collected Steps per Second: 3,835.31894
Overall Steps per Second: 3,236.89555

Timestep Collection Time: 13.03725
Timestep Consumption Time: 2.41027
PPO Batch Consumption Time: 0.05406
Total Iteration Time: 15.44752

Cumulative Model Updates: 48,514
Cumulative Timesteps: 809,211,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 809211018...
Checkpoint 809211018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,922.23644
Policy Entropy: 1.04052
Value Function Loss: 4.38650

Mean KL Divergence: 0.02767
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.09642

Collected Steps per Second: 3,813.38987
Overall Steps per Second: 3,143.89976

Timestep Collection Time: 13.11536
Timestep Consumption Time: 2.79290
PPO Batch Consumption Time: 0.04955
Total Iteration Time: 15.90827

Cumulative Model Updates: 48,517
Cumulative Timesteps: 809,261,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,290.12480
Policy Entropy: 1.06149
Value Function Loss: 4.45976

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.09201

Collected Steps per Second: 3,891.70871
Overall Steps per Second: 3,224.24685

Timestep Collection Time: 12.85759
Timestep Consumption Time: 2.66169
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 15.51928

Cumulative Model Updates: 48,520
Cumulative Timesteps: 809,311,070

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 809311070...
Checkpoint 809311070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,704.83178
Policy Entropy: 1.05476
Value Function Loss: 4.41192

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.08881

Collected Steps per Second: 3,987.79543
Overall Steps per Second: 3,264.13057

Timestep Collection Time: 12.54829
Timestep Consumption Time: 2.78198
PPO Batch Consumption Time: 0.05176
Total Iteration Time: 15.33027

Cumulative Model Updates: 48,523
Cumulative Timesteps: 809,361,110

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,073.52183
Policy Entropy: 1.05060
Value Function Loss: 4.31640

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.06637
Value Function Update Magnitude: 0.08644

Collected Steps per Second: 3,860.34487
Overall Steps per Second: 3,190.93640

Timestep Collection Time: 12.95532
Timestep Consumption Time: 2.71782
PPO Batch Consumption Time: 0.05757
Total Iteration Time: 15.67314

Cumulative Model Updates: 48,526
Cumulative Timesteps: 809,411,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 809411122...
Checkpoint 809411122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,823.13538
Policy Entropy: 1.05380
Value Function Loss: 4.23864

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.06696
Value Function Update Magnitude: 0.08994

Collected Steps per Second: 3,866.85856
Overall Steps per Second: 3,233.18842

Timestep Collection Time: 12.93143
Timestep Consumption Time: 2.53442
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 15.46585

Cumulative Model Updates: 48,529
Cumulative Timesteps: 809,461,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,422.63156
Policy Entropy: 1.05613
Value Function Loss: 4.16296

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.08890

Collected Steps per Second: 3,807.66268
Overall Steps per Second: 3,134.63074

Timestep Collection Time: 13.13877
Timestep Consumption Time: 2.82101
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 15.95977

Cumulative Model Updates: 48,532
Cumulative Timesteps: 809,511,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 809511154...
Checkpoint 809511154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,082.60129
Policy Entropy: 1.06764
Value Function Loss: 4.14244

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.08302

Collected Steps per Second: 3,859.29163
Overall Steps per Second: 3,245.80595

Timestep Collection Time: 12.95678
Timestep Consumption Time: 2.44894
PPO Batch Consumption Time: 0.06212
Total Iteration Time: 15.40573

Cumulative Model Updates: 48,535
Cumulative Timesteps: 809,561,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,458.41502
Policy Entropy: 1.06581
Value Function Loss: 4.11152

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.08079

Collected Steps per Second: 3,861.89579
Overall Steps per Second: 3,164.24430

Timestep Collection Time: 12.95840
Timestep Consumption Time: 2.85706
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 15.81547

Cumulative Model Updates: 48,538
Cumulative Timesteps: 809,611,202

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 809611202...
Checkpoint 809611202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,363.59110
Policy Entropy: 1.06496
Value Function Loss: 4.17702

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.07235
Value Function Update Magnitude: 0.09564

Collected Steps per Second: 3,877.07795
Overall Steps per Second: 3,209.83623

Timestep Collection Time: 12.90302
Timestep Consumption Time: 2.68220
PPO Batch Consumption Time: 0.05885
Total Iteration Time: 15.58522

Cumulative Model Updates: 48,541
Cumulative Timesteps: 809,661,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,643.54371
Policy Entropy: 1.06600
Value Function Loss: 4.21610

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.06873
Value Function Update Magnitude: 0.09019

Collected Steps per Second: 3,869.49307
Overall Steps per Second: 3,221.57422

Timestep Collection Time: 12.93348
Timestep Consumption Time: 2.60116
PPO Batch Consumption Time: 0.05119
Total Iteration Time: 15.53464

Cumulative Model Updates: 48,544
Cumulative Timesteps: 809,711,274

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 809711274...
Checkpoint 809711274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,932.08250
Policy Entropy: 1.07836
Value Function Loss: 4.25476

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.09738

Collected Steps per Second: 3,911.75140
Overall Steps per Second: 3,209.61859

Timestep Collection Time: 12.78660
Timestep Consumption Time: 2.79718
PPO Batch Consumption Time: 0.05854
Total Iteration Time: 15.58378

Cumulative Model Updates: 48,547
Cumulative Timesteps: 809,761,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,626.62407
Policy Entropy: 1.08505
Value Function Loss: 4.30064

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.09491

Collected Steps per Second: 3,818.76456
Overall Steps per Second: 3,218.61485

Timestep Collection Time: 13.09900
Timestep Consumption Time: 2.44247
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 15.54147

Cumulative Model Updates: 48,550
Cumulative Timesteps: 809,811,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 809811314...
Checkpoint 809811314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,885.17285
Policy Entropy: 1.08398
Value Function Loss: 4.19956

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.07866
Value Function Update Magnitude: 0.08914

Collected Steps per Second: 3,942.58904
Overall Steps per Second: 3,159.27409

Timestep Collection Time: 12.69166
Timestep Consumption Time: 3.14679
PPO Batch Consumption Time: 0.05269
Total Iteration Time: 15.83845

Cumulative Model Updates: 48,553
Cumulative Timesteps: 809,861,352

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,754.48256
Policy Entropy: 1.09041
Value Function Loss: 4.22479

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.08043
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 3,820.64889
Overall Steps per Second: 3,191.81448

Timestep Collection Time: 13.09620
Timestep Consumption Time: 2.58014
PPO Batch Consumption Time: 0.06533
Total Iteration Time: 15.67635

Cumulative Model Updates: 48,556
Cumulative Timesteps: 809,911,388

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 809911388...
Checkpoint 809911388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,302.72933
Policy Entropy: 1.08624
Value Function Loss: 4.29847

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.07565
Value Function Update Magnitude: 0.09787

Collected Steps per Second: 3,882.15157
Overall Steps per Second: 3,256.30041

Timestep Collection Time: 12.88461
Timestep Consumption Time: 2.47638
PPO Batch Consumption Time: 0.06384
Total Iteration Time: 15.36099

Cumulative Model Updates: 48,559
Cumulative Timesteps: 809,961,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,009.44828
Policy Entropy: 1.08811
Value Function Loss: 4.34669

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.15412
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.10017

Collected Steps per Second: 3,881.70288
Overall Steps per Second: 3,175.62378

Timestep Collection Time: 12.89228
Timestep Consumption Time: 2.86651
PPO Batch Consumption Time: 0.06282
Total Iteration Time: 15.75879

Cumulative Model Updates: 48,562
Cumulative Timesteps: 810,011,452

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 810011452...
Checkpoint 810011452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,453.29907
Policy Entropy: 1.09211
Value Function Loss: 4.39445

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.10349

Collected Steps per Second: 3,830.63730
Overall Steps per Second: 3,189.53700

Timestep Collection Time: 13.05422
Timestep Consumption Time: 2.62391
PPO Batch Consumption Time: 0.05415
Total Iteration Time: 15.67814

Cumulative Model Updates: 48,565
Cumulative Timesteps: 810,061,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,830.42222
Policy Entropy: 1.09925
Value Function Loss: 4.44022

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.09710

Collected Steps per Second: 3,967.87337
Overall Steps per Second: 3,268.56865

Timestep Collection Time: 12.60222
Timestep Consumption Time: 2.69622
PPO Batch Consumption Time: 0.06055
Total Iteration Time: 15.29844

Cumulative Model Updates: 48,568
Cumulative Timesteps: 810,111,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 810111462...
Checkpoint 810111462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,918.58438
Policy Entropy: 1.09824
Value Function Loss: 4.58764

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.09374

Collected Steps per Second: 3,884.31441
Overall Steps per Second: 3,187.44759

Timestep Collection Time: 12.87640
Timestep Consumption Time: 2.81515
PPO Batch Consumption Time: 0.05950
Total Iteration Time: 15.69155

Cumulative Model Updates: 48,571
Cumulative Timesteps: 810,161,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,254.59511
Policy Entropy: 1.10929
Value Function Loss: 4.54464

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.09636

Collected Steps per Second: 3,809.63293
Overall Steps per Second: 3,198.04673

Timestep Collection Time: 13.12987
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.07190
Total Iteration Time: 15.64080

Cumulative Model Updates: 48,574
Cumulative Timesteps: 810,211,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 810211498...
Checkpoint 810211498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,710.69019
Policy Entropy: 1.10095
Value Function Loss: 4.61484

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.07186
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 4,015.31172
Overall Steps per Second: 3,268.07515

Timestep Collection Time: 12.46230
Timestep Consumption Time: 2.84947
PPO Batch Consumption Time: 0.06396
Total Iteration Time: 15.31177

Cumulative Model Updates: 48,577
Cumulative Timesteps: 810,261,538

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,904.67020
Policy Entropy: 1.09798
Value Function Loss: 4.49558

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.07853
Value Function Update Magnitude: 0.10994

Collected Steps per Second: 3,840.33774
Overall Steps per Second: 3,172.69873

Timestep Collection Time: 13.01969
Timestep Consumption Time: 2.73977
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 15.75945

Cumulative Model Updates: 48,580
Cumulative Timesteps: 810,311,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 810311538...
Checkpoint 810311538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,780.37595
Policy Entropy: 1.08633
Value Function Loss: 4.39734

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.07328
Value Function Update Magnitude: 0.10838

Collected Steps per Second: 4,005.25433
Overall Steps per Second: 3,263.91196

Timestep Collection Time: 12.48410
Timestep Consumption Time: 2.83555
PPO Batch Consumption Time: 0.05902
Total Iteration Time: 15.31965

Cumulative Model Updates: 48,583
Cumulative Timesteps: 810,361,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,357.07353
Policy Entropy: 1.10176
Value Function Loss: 4.28854

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.06670
Value Function Update Magnitude: 0.11730

Collected Steps per Second: 3,881.42747
Overall Steps per Second: 3,186.29653

Timestep Collection Time: 12.88907
Timestep Consumption Time: 2.81191
PPO Batch Consumption Time: 0.06799
Total Iteration Time: 15.70099

Cumulative Model Updates: 48,586
Cumulative Timesteps: 810,411,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 810411568...
Checkpoint 810411568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,968.32041
Policy Entropy: 1.10005
Value Function Loss: 4.23491

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11543
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.11718

Collected Steps per Second: 3,973.42159
Overall Steps per Second: 3,316.77196

Timestep Collection Time: 12.58563
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.06086
Total Iteration Time: 15.07731

Cumulative Model Updates: 48,589
Cumulative Timesteps: 810,461,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513,738.87028
Policy Entropy: 1.10843
Value Function Loss: 4.20311

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.07023
Value Function Update Magnitude: 0.12064

Collected Steps per Second: 3,885.92169
Overall Steps per Second: 3,201.08681

Timestep Collection Time: 12.88034
Timestep Consumption Time: 2.75560
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 15.63594

Cumulative Model Updates: 48,592
Cumulative Timesteps: 810,511,628

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 810511628...
Checkpoint 810511628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596,958.31506
Policy Entropy: 1.10384
Value Function Loss: 4.14974

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.06864
Value Function Update Magnitude: 0.12264

Collected Steps per Second: 3,852.00472
Overall Steps per Second: 3,196.82104

Timestep Collection Time: 12.98025
Timestep Consumption Time: 2.66028
PPO Batch Consumption Time: 0.06605
Total Iteration Time: 15.64054

Cumulative Model Updates: 48,595
Cumulative Timesteps: 810,561,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,624.56708
Policy Entropy: 1.10390
Value Function Loss: 4.27553

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.11767

Collected Steps per Second: 3,963.32749
Overall Steps per Second: 3,301.79550

Timestep Collection Time: 12.62172
Timestep Consumption Time: 2.52883
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 15.15054

Cumulative Model Updates: 48,598
Cumulative Timesteps: 810,611,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 810611652...
Checkpoint 810611652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,874.69050
Policy Entropy: 1.09851
Value Function Loss: 4.36900

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.06359
Value Function Update Magnitude: 0.11250

Collected Steps per Second: 3,872.99992
Overall Steps per Second: 3,208.13903

Timestep Collection Time: 12.91454
Timestep Consumption Time: 2.67643
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 15.59097

Cumulative Model Updates: 48,601
Cumulative Timesteps: 810,661,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,039.11059
Policy Entropy: 1.11044
Value Function Loss: 4.40395

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.10878

Collected Steps per Second: 3,830.76981
Overall Steps per Second: 3,259.69070

Timestep Collection Time: 13.05952
Timestep Consumption Time: 2.28795
PPO Batch Consumption Time: 0.05275
Total Iteration Time: 15.34747

Cumulative Model Updates: 48,604
Cumulative Timesteps: 810,711,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 810711698...
Checkpoint 810711698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,204.05017
Policy Entropy: 1.10621
Value Function Loss: 4.38903

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.10491

Collected Steps per Second: 3,838.49556
Overall Steps per Second: 3,145.18817

Timestep Collection Time: 13.03375
Timestep Consumption Time: 2.87309
PPO Batch Consumption Time: 0.06113
Total Iteration Time: 15.90684

Cumulative Model Updates: 48,607
Cumulative Timesteps: 810,761,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,616.96908
Policy Entropy: 1.11342
Value Function Loss: 4.47452

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.09878

Collected Steps per Second: 3,837.86938
Overall Steps per Second: 3,184.96212

Timestep Collection Time: 13.04109
Timestep Consumption Time: 2.67338
PPO Batch Consumption Time: 0.06002
Total Iteration Time: 15.71447

Cumulative Model Updates: 48,610
Cumulative Timesteps: 810,811,778

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 810811778...
Checkpoint 810811778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,225.94175
Policy Entropy: 1.10875
Value Function Loss: 4.52735

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.10646

Collected Steps per Second: 3,867.10723
Overall Steps per Second: 3,182.98716

Timestep Collection Time: 12.93577
Timestep Consumption Time: 2.78029
PPO Batch Consumption Time: 0.06131
Total Iteration Time: 15.71605

Cumulative Model Updates: 48,613
Cumulative Timesteps: 810,861,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,072.05617
Policy Entropy: 1.11152
Value Function Loss: 4.50902

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.06537
Value Function Update Magnitude: 0.11953

Collected Steps per Second: 3,939.47144
Overall Steps per Second: 3,229.42563

Timestep Collection Time: 12.69815
Timestep Consumption Time: 2.79191
PPO Batch Consumption Time: 0.06398
Total Iteration Time: 15.49006

Cumulative Model Updates: 48,616
Cumulative Timesteps: 810,911,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 810911826...
Checkpoint 810911826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,632.15434
Policy Entropy: 1.11351
Value Function Loss: 4.54523

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.07305
Value Function Update Magnitude: 0.11292

Collected Steps per Second: 3,846.51880
Overall Steps per Second: 3,264.58974

Timestep Collection Time: 13.00813
Timestep Consumption Time: 2.31876
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 15.32689

Cumulative Model Updates: 48,619
Cumulative Timesteps: 810,961,862

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,625.23996
Policy Entropy: 1.10647
Value Function Loss: 4.40583

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.07989
Value Function Update Magnitude: 0.10002

Collected Steps per Second: 3,942.05671
Overall Steps per Second: 3,202.34895

Timestep Collection Time: 12.69084
Timestep Consumption Time: 2.93145
PPO Batch Consumption Time: 0.06122
Total Iteration Time: 15.62228

Cumulative Model Updates: 48,622
Cumulative Timesteps: 811,011,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 811011890...
Checkpoint 811011890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,613.85430
Policy Entropy: 1.11764
Value Function Loss: 4.35123

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.15920
Policy Update Magnitude: 0.06523
Value Function Update Magnitude: 0.10348

Collected Steps per Second: 3,862.12973
Overall Steps per Second: 3,239.48753

Timestep Collection Time: 12.95606
Timestep Consumption Time: 2.49021
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 15.44627

Cumulative Model Updates: 48,625
Cumulative Timesteps: 811,061,928

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,287.40407
Policy Entropy: 1.11871
Value Function Loss: 4.17024

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.10562

Collected Steps per Second: 3,890.09544
Overall Steps per Second: 3,199.57590

Timestep Collection Time: 12.85521
Timestep Consumption Time: 2.77436
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 15.62957

Cumulative Model Updates: 48,628
Cumulative Timesteps: 811,111,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 811111936...
Checkpoint 811111936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,738.88814
Policy Entropy: 1.10919
Value Function Loss: 4.34682

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.09486

Collected Steps per Second: 3,816.43625
Overall Steps per Second: 3,170.10131

Timestep Collection Time: 13.10228
Timestep Consumption Time: 2.67135
PPO Batch Consumption Time: 0.06966
Total Iteration Time: 15.77363

Cumulative Model Updates: 48,631
Cumulative Timesteps: 811,161,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,400.69256
Policy Entropy: 1.09909
Value Function Loss: 4.25084

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.16554
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.09337

Collected Steps per Second: 3,962.77315
Overall Steps per Second: 3,240.93941

Timestep Collection Time: 12.62954
Timestep Consumption Time: 2.81290
PPO Batch Consumption Time: 0.06613
Total Iteration Time: 15.44244

Cumulative Model Updates: 48,634
Cumulative Timesteps: 811,211,988

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 811211988...
Checkpoint 811211988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,531.36207
Policy Entropy: 1.11153
Value Function Loss: 4.34630

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.09666

Collected Steps per Second: 3,802.08607
Overall Steps per Second: 3,135.93286

Timestep Collection Time: 13.15909
Timestep Consumption Time: 2.79533
PPO Batch Consumption Time: 0.06173
Total Iteration Time: 15.95442

Cumulative Model Updates: 48,637
Cumulative Timesteps: 811,262,020

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,536.50423
Policy Entropy: 1.10961
Value Function Loss: 4.25929

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.06292
Value Function Update Magnitude: 0.08643

Collected Steps per Second: 3,932.48743
Overall Steps per Second: 3,283.03734

Timestep Collection Time: 12.72477
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.06015
Total Iteration Time: 15.24198

Cumulative Model Updates: 48,640
Cumulative Timesteps: 811,312,060

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 811312060...
Checkpoint 811312060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,569.63515
Policy Entropy: 1.10474
Value Function Loss: 4.40093

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.10120

Collected Steps per Second: 3,864.93779
Overall Steps per Second: 3,187.25691

Timestep Collection Time: 12.94148
Timestep Consumption Time: 2.75164
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 15.69312

Cumulative Model Updates: 48,643
Cumulative Timesteps: 811,362,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,226.94399
Policy Entropy: 1.11034
Value Function Loss: 4.42076

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11935
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.10161

Collected Steps per Second: 3,898.47357
Overall Steps per Second: 3,277.43916

Timestep Collection Time: 12.82964
Timestep Consumption Time: 2.43106
PPO Batch Consumption Time: 0.06184
Total Iteration Time: 15.26070

Cumulative Model Updates: 48,646
Cumulative Timesteps: 811,412,094

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 811412094...
Checkpoint 811412094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,989.86695
Policy Entropy: 1.11519
Value Function Loss: 4.39703

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 3,838.33070
Overall Steps per Second: 3,173.74719

Timestep Collection Time: 13.04004
Timestep Consumption Time: 2.73059
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 15.77063

Cumulative Model Updates: 48,649
Cumulative Timesteps: 811,462,146

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,621.43216
Policy Entropy: 1.11134
Value Function Loss: 4.56708

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.07353

Collected Steps per Second: 3,830.83190
Overall Steps per Second: 3,162.73867

Timestep Collection Time: 13.05774
Timestep Consumption Time: 2.75830
PPO Batch Consumption Time: 0.05797
Total Iteration Time: 15.81604

Cumulative Model Updates: 48,652
Cumulative Timesteps: 811,512,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 811512168...
Checkpoint 811512168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495,540.00071
Policy Entropy: 1.10603
Value Function Loss: 4.29654

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.08439

Collected Steps per Second: 3,872.72230
Overall Steps per Second: 3,177.33668

Timestep Collection Time: 12.91546
Timestep Consumption Time: 2.82665
PPO Batch Consumption Time: 0.05764
Total Iteration Time: 15.74212

Cumulative Model Updates: 48,655
Cumulative Timesteps: 811,562,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,453.88071
Policy Entropy: 1.09921
Value Function Loss: 4.31452

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.08869

Collected Steps per Second: 3,915.68568
Overall Steps per Second: 3,201.30621

Timestep Collection Time: 12.77937
Timestep Consumption Time: 2.85175
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 15.63112

Cumulative Model Updates: 48,658
Cumulative Timesteps: 811,612,226

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 811612226...
Checkpoint 811612226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,626.30552
Policy Entropy: 1.11086
Value Function Loss: 4.15027

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.06344
Value Function Update Magnitude: 0.07867

Collected Steps per Second: 3,849.14539
Overall Steps per Second: 3,244.60983

Timestep Collection Time: 12.99301
Timestep Consumption Time: 2.42086
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 15.41387

Cumulative Model Updates: 48,661
Cumulative Timesteps: 811,662,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,247.05064
Policy Entropy: 1.11775
Value Function Loss: 4.43108

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.06626
Value Function Update Magnitude: 0.08099

Collected Steps per Second: 3,761.59174
Overall Steps per Second: 3,128.89625

Timestep Collection Time: 13.30182
Timestep Consumption Time: 2.68977
PPO Batch Consumption Time: 0.05891
Total Iteration Time: 15.99158

Cumulative Model Updates: 48,664
Cumulative Timesteps: 811,712,274

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 811712274...
Checkpoint 811712274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,007.10996
Policy Entropy: 1.11969
Value Function Loss: 4.39429

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.07856

Collected Steps per Second: 3,804.00040
Overall Steps per Second: 3,143.84762

Timestep Collection Time: 13.14826
Timestep Consumption Time: 2.76090
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 15.90917

Cumulative Model Updates: 48,667
Cumulative Timesteps: 811,762,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,731.41465
Policy Entropy: 1.10775
Value Function Loss: 4.32752

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.06519
Value Function Update Magnitude: 0.09044

Collected Steps per Second: 3,950.66916
Overall Steps per Second: 3,267.01485

Timestep Collection Time: 12.66064
Timestep Consumption Time: 2.64936
PPO Batch Consumption Time: 0.06387
Total Iteration Time: 15.31000

Cumulative Model Updates: 48,670
Cumulative Timesteps: 811,812,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 811812308...
Checkpoint 811812308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,140.17461
Policy Entropy: 1.10428
Value Function Loss: 4.31005

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.06151
Value Function Update Magnitude: 0.11448

Collected Steps per Second: 3,757.03398
Overall Steps per Second: 3,130.87681

Timestep Collection Time: 13.31529
Timestep Consumption Time: 2.66298
PPO Batch Consumption Time: 0.06656
Total Iteration Time: 15.97827

Cumulative Model Updates: 48,673
Cumulative Timesteps: 811,862,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,761.53634
Policy Entropy: 1.11283
Value Function Loss: 4.40929

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.12073

Collected Steps per Second: 3,745.69648
Overall Steps per Second: 3,158.27180

Timestep Collection Time: 13.36360
Timestep Consumption Time: 2.48557
PPO Batch Consumption Time: 0.06206
Total Iteration Time: 15.84917

Cumulative Model Updates: 48,676
Cumulative Timesteps: 811,912,390

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 811912390...
Checkpoint 811912390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,692.66661
Policy Entropy: 1.12010
Value Function Loss: 4.61403

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.07260
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 3,891.39643
Overall Steps per Second: 3,219.93976

Timestep Collection Time: 12.85862
Timestep Consumption Time: 2.68142
PPO Batch Consumption Time: 0.05967
Total Iteration Time: 15.54004

Cumulative Model Updates: 48,679
Cumulative Timesteps: 811,962,428

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,096.74637
Policy Entropy: 1.12406
Value Function Loss: 4.62694

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.08908
Value Function Update Magnitude: 0.12328

Collected Steps per Second: 3,818.48423
Overall Steps per Second: 3,151.47578

Timestep Collection Time: 13.09420
Timestep Consumption Time: 2.77138
PPO Batch Consumption Time: 0.06296
Total Iteration Time: 15.86558

Cumulative Model Updates: 48,682
Cumulative Timesteps: 812,012,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 812012428...
Checkpoint 812012428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,626.91518
Policy Entropy: 1.13265
Value Function Loss: 4.59260

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.08235
Value Function Update Magnitude: 0.12242

Collected Steps per Second: 3,911.05801
Overall Steps per Second: 3,225.33165

Timestep Collection Time: 12.78887
Timestep Consumption Time: 2.71900
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 15.50786

Cumulative Model Updates: 48,685
Cumulative Timesteps: 812,062,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,183.97712
Policy Entropy: 1.12980
Value Function Loss: 4.52232

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.07506
Value Function Update Magnitude: 0.11989

Collected Steps per Second: 3,829.28927
Overall Steps per Second: 3,168.42260

Timestep Collection Time: 13.05725
Timestep Consumption Time: 2.72347
PPO Batch Consumption Time: 0.06402
Total Iteration Time: 15.78072

Cumulative Model Updates: 48,688
Cumulative Timesteps: 812,112,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 812112446...
Checkpoint 812112446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,954.79953
Policy Entropy: 1.14303
Value Function Loss: 4.62575

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 0.07050
Value Function Update Magnitude: 0.11551

Collected Steps per Second: 3,887.91497
Overall Steps per Second: 3,232.46422

Timestep Collection Time: 12.86911
Timestep Consumption Time: 2.60949
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 15.47859

Cumulative Model Updates: 48,691
Cumulative Timesteps: 812,162,480

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,668.46892
Policy Entropy: 1.14783
Value Function Loss: 4.57625

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.07010
Value Function Update Magnitude: 0.11136

Collected Steps per Second: 3,809.16026
Overall Steps per Second: 3,125.06114

Timestep Collection Time: 13.12993
Timestep Consumption Time: 2.87424
PPO Batch Consumption Time: 0.06826
Total Iteration Time: 16.00417

Cumulative Model Updates: 48,694
Cumulative Timesteps: 812,212,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 812212494...
Checkpoint 812212494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,134.25081
Policy Entropy: 1.14388
Value Function Loss: 4.56329

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.08068
Value Function Update Magnitude: 0.10967

Collected Steps per Second: 4,471.38774
Overall Steps per Second: 3,661.54854

Timestep Collection Time: 11.18758
Timestep Consumption Time: 2.47440
PPO Batch Consumption Time: 0.06585
Total Iteration Time: 13.66198

Cumulative Model Updates: 48,697
Cumulative Timesteps: 812,262,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,805.32134
Policy Entropy: 1.13828
Value Function Loss: 4.52242

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.07675
Value Function Update Magnitude: 0.10191

Collected Steps per Second: 4,220.69170
Overall Steps per Second: 3,472.66708

Timestep Collection Time: 11.85161
Timestep Consumption Time: 2.55288
PPO Batch Consumption Time: 0.07148
Total Iteration Time: 14.40449

Cumulative Model Updates: 48,700
Cumulative Timesteps: 812,312,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 812312540...
Checkpoint 812312540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474,267.63663
Policy Entropy: 1.13050
Value Function Loss: 4.59165

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.07360
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 4,604.60144
Overall Steps per Second: 3,774.05817

Timestep Collection Time: 10.86044
Timestep Consumption Time: 2.39002
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 13.25046

Cumulative Model Updates: 48,703
Cumulative Timesteps: 812,362,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551,892.56745
Policy Entropy: 1.14824
Value Function Loss: 4.57194

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.10854

Collected Steps per Second: 4,513.77955
Overall Steps per Second: 3,771.84998

Timestep Collection Time: 11.08783
Timestep Consumption Time: 2.18099
PPO Batch Consumption Time: 0.06281
Total Iteration Time: 13.26882

Cumulative Model Updates: 48,706
Cumulative Timesteps: 812,412,596

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 812412596...
Checkpoint 812412596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,682.68636
Policy Entropy: 1.15032
Value Function Loss: 4.59569

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.06515
Value Function Update Magnitude: 0.09986

Collected Steps per Second: 4,559.99687
Overall Steps per Second: 3,718.22887

Timestep Collection Time: 10.96536
Timestep Consumption Time: 2.48244
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 13.44780

Cumulative Model Updates: 48,709
Cumulative Timesteps: 812,462,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,557.51710
Policy Entropy: 1.14264
Value Function Loss: 4.46077

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.06884
Value Function Update Magnitude: 0.08922

Collected Steps per Second: 4,456.87388
Overall Steps per Second: 3,668.26318

Timestep Collection Time: 11.22222
Timestep Consumption Time: 2.41257
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 13.63479

Cumulative Model Updates: 48,712
Cumulative Timesteps: 812,512,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 812512614...
Checkpoint 812512614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,297.43298
Policy Entropy: 1.12771
Value Function Loss: 4.36310

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.08946

Collected Steps per Second: 4,430.09297
Overall Steps per Second: 3,594.94057

Timestep Collection Time: 11.28915
Timestep Consumption Time: 2.62262
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 13.91177

Cumulative Model Updates: 48,715
Cumulative Timesteps: 812,562,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,857.46541
Policy Entropy: 1.14305
Value Function Loss: 4.27451

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.08443

Collected Steps per Second: 4,166.10696
Overall Steps per Second: 3,436.05489

Timestep Collection Time: 12.00257
Timestep Consumption Time: 2.55016
PPO Batch Consumption Time: 0.05280
Total Iteration Time: 14.55274

Cumulative Model Updates: 48,718
Cumulative Timesteps: 812,612,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 812612630...
Checkpoint 812612630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,884.07007
Policy Entropy: 1.14159
Value Function Loss: 4.42959

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.09007

Collected Steps per Second: 3,838.08239
Overall Steps per Second: 3,218.19872

Timestep Collection Time: 13.03411
Timestep Consumption Time: 2.51061
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 15.54472

Cumulative Model Updates: 48,721
Cumulative Timesteps: 812,662,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495,568.40633
Policy Entropy: 1.13473
Value Function Loss: 4.50550

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.08381

Collected Steps per Second: 3,911.79459
Overall Steps per Second: 3,232.16271

Timestep Collection Time: 12.78237
Timestep Consumption Time: 2.68777
PPO Batch Consumption Time: 0.05809
Total Iteration Time: 15.47014

Cumulative Model Updates: 48,724
Cumulative Timesteps: 812,712,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 812712658...
Checkpoint 812712658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,372.68654
Policy Entropy: 1.12565
Value Function Loss: 4.50338

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.08235

Collected Steps per Second: 3,796.83119
Overall Steps per Second: 3,232.09504

Timestep Collection Time: 13.17151
Timestep Consumption Time: 2.30143
PPO Batch Consumption Time: 0.06531
Total Iteration Time: 15.47294

Cumulative Model Updates: 48,727
Cumulative Timesteps: 812,762,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,172.28821
Policy Entropy: 1.13636
Value Function Loss: 4.41890

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.08921

Collected Steps per Second: 3,972.39945
Overall Steps per Second: 3,267.07412

Timestep Collection Time: 12.59088
Timestep Consumption Time: 2.71823
PPO Batch Consumption Time: 0.06136
Total Iteration Time: 15.30911

Cumulative Model Updates: 48,730
Cumulative Timesteps: 812,812,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 812812684...
Checkpoint 812812684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765,432.59269
Policy Entropy: 1.14087
Value Function Loss: 4.22798

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.08713

Collected Steps per Second: 3,757.96632
Overall Steps per Second: 3,110.86940

Timestep Collection Time: 13.31146
Timestep Consumption Time: 2.76894
PPO Batch Consumption Time: 0.05906
Total Iteration Time: 16.08039

Cumulative Model Updates: 48,733
Cumulative Timesteps: 812,862,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,655.83358
Policy Entropy: 1.12626
Value Function Loss: 4.16857

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.09061

Collected Steps per Second: 3,915.18617
Overall Steps per Second: 3,227.90404

Timestep Collection Time: 12.77589
Timestep Consumption Time: 2.72023
PPO Batch Consumption Time: 0.06926
Total Iteration Time: 15.49612

Cumulative Model Updates: 48,736
Cumulative Timesteps: 812,912,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 812912728...
Checkpoint 812912728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,432.04491
Policy Entropy: 1.13509
Value Function Loss: 4.05569

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.08915

Collected Steps per Second: 3,871.97086
Overall Steps per Second: 3,235.23807

Timestep Collection Time: 12.92107
Timestep Consumption Time: 2.54302
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 15.46409

Cumulative Model Updates: 48,739
Cumulative Timesteps: 812,962,758

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,090.16083
Policy Entropy: 1.13852
Value Function Loss: 4.29250

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.10726

Collected Steps per Second: 3,792.46652
Overall Steps per Second: 3,191.51185

Timestep Collection Time: 13.19089
Timestep Consumption Time: 2.48382
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 15.67470

Cumulative Model Updates: 48,742
Cumulative Timesteps: 813,012,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 813012784...
Checkpoint 813012784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,782.13169
Policy Entropy: 1.12431
Value Function Loss: 4.46842

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.10807

Collected Steps per Second: 3,851.20181
Overall Steps per Second: 3,185.10396

Timestep Collection Time: 12.98400
Timestep Consumption Time: 2.71533
PPO Batch Consumption Time: 0.05395
Total Iteration Time: 15.69933

Cumulative Model Updates: 48,745
Cumulative Timesteps: 813,062,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504,722.52128
Policy Entropy: 1.12726
Value Function Loss: 4.62813

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.10646

Collected Steps per Second: 3,822.64369
Overall Steps per Second: 3,148.85418

Timestep Collection Time: 13.08989
Timestep Consumption Time: 2.80097
PPO Batch Consumption Time: 0.07429
Total Iteration Time: 15.89086

Cumulative Model Updates: 48,748
Cumulative Timesteps: 813,112,826

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 813112826...
Checkpoint 813112826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,756.12211
Policy Entropy: 1.13409
Value Function Loss: 4.63303

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.10261
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.11385

Collected Steps per Second: 3,962.41098
Overall Steps per Second: 3,263.29780

Timestep Collection Time: 12.61959
Timestep Consumption Time: 2.70356
PPO Batch Consumption Time: 0.06396
Total Iteration Time: 15.32315

Cumulative Model Updates: 48,751
Cumulative Timesteps: 813,162,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,216.62420
Policy Entropy: 1.14533
Value Function Loss: 4.61023

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.11420

Collected Steps per Second: 3,771.84166
Overall Steps per Second: 3,110.27527

Timestep Collection Time: 13.26779
Timestep Consumption Time: 2.82210
PPO Batch Consumption Time: 0.06030
Total Iteration Time: 16.08989

Cumulative Model Updates: 48,754
Cumulative Timesteps: 813,212,874

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 813212874...
Checkpoint 813212874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,867.61730
Policy Entropy: 1.12404
Value Function Loss: 4.52911

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.10742

Collected Steps per Second: 3,918.77373
Overall Steps per Second: 3,268.72998

Timestep Collection Time: 12.76165
Timestep Consumption Time: 2.53787
PPO Batch Consumption Time: 0.06209
Total Iteration Time: 15.29952

Cumulative Model Updates: 48,757
Cumulative Timesteps: 813,262,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,239.53210
Policy Entropy: 1.13530
Value Function Loss: 4.41115

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.10849

Collected Steps per Second: 3,768.61454
Overall Steps per Second: 3,152.14880

Timestep Collection Time: 13.27278
Timestep Consumption Time: 2.59576
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 15.86854

Cumulative Model Updates: 48,760
Cumulative Timesteps: 813,312,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 813312904...
Checkpoint 813312904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,492.38385
Policy Entropy: 1.12891
Value Function Loss: 4.34380

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.11372
Policy Update Magnitude: 0.06038
Value Function Update Magnitude: 0.10972

Collected Steps per Second: 3,944.05736
Overall Steps per Second: 3,219.94046

Timestep Collection Time: 12.67831
Timestep Consumption Time: 2.85117
PPO Batch Consumption Time: 0.06628
Total Iteration Time: 15.52948

Cumulative Model Updates: 48,763
Cumulative Timesteps: 813,362,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,069.50665
Policy Entropy: 1.13099
Value Function Loss: 4.24997

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.07724
Value Function Update Magnitude: 0.11606

Collected Steps per Second: 3,927.23104
Overall Steps per Second: 3,248.20373

Timestep Collection Time: 12.73926
Timestep Consumption Time: 2.66310
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 15.40236

Cumulative Model Updates: 48,766
Cumulative Timesteps: 813,412,938

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 813412938...
Checkpoint 813412938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,224.60603
Policy Entropy: 1.12492
Value Function Loss: 4.26067

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.07415
Value Function Update Magnitude: 0.10655

Collected Steps per Second: 4,024.95653
Overall Steps per Second: 3,271.59672

Timestep Collection Time: 12.43442
Timestep Consumption Time: 2.86331
PPO Batch Consumption Time: 0.06276
Total Iteration Time: 15.29773

Cumulative Model Updates: 48,769
Cumulative Timesteps: 813,462,986

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437,094.11727
Policy Entropy: 1.13306
Value Function Loss: 4.10808

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.10077

Collected Steps per Second: 3,755.43982
Overall Steps per Second: 3,152.60911

Timestep Collection Time: 13.31508
Timestep Consumption Time: 2.54606
PPO Batch Consumption Time: 0.06264
Total Iteration Time: 15.86115

Cumulative Model Updates: 48,772
Cumulative Timesteps: 813,512,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 813512990...
Checkpoint 813512990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,227.83534
Policy Entropy: 1.13775
Value Function Loss: 4.17321

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.09913

Collected Steps per Second: 3,886.10678
Overall Steps per Second: 3,218.22315

Timestep Collection Time: 12.86686
Timestep Consumption Time: 2.67028
PPO Batch Consumption Time: 0.06283
Total Iteration Time: 15.53715

Cumulative Model Updates: 48,775
Cumulative Timesteps: 813,562,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,911.89711
Policy Entropy: 1.12350
Value Function Loss: 4.21895

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.09933

Collected Steps per Second: 3,869.27319
Overall Steps per Second: 3,236.09449

Timestep Collection Time: 12.93266
Timestep Consumption Time: 2.53042
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 15.46308

Cumulative Model Updates: 48,778
Cumulative Timesteps: 813,613,032

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 813613032...
Checkpoint 813613032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,899.57365
Policy Entropy: 1.11843
Value Function Loss: 4.35722

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.09192

Collected Steps per Second: 3,882.64431
Overall Steps per Second: 3,188.52257

Timestep Collection Time: 12.88967
Timestep Consumption Time: 2.80600
PPO Batch Consumption Time: 0.06109
Total Iteration Time: 15.69567

Cumulative Model Updates: 48,781
Cumulative Timesteps: 813,663,078

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,974.79466
Policy Entropy: 1.12834
Value Function Loss: 4.33801

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.09682

Collected Steps per Second: 3,839.09903
Overall Steps per Second: 3,179.54429

Timestep Collection Time: 13.02962
Timestep Consumption Time: 2.70282
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 15.73244

Cumulative Model Updates: 48,784
Cumulative Timesteps: 813,713,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 813713100...
Checkpoint 813713100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531,888.67458
Policy Entropy: 1.12990
Value Function Loss: 4.21700

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.09880

Collected Steps per Second: 3,948.21341
Overall Steps per Second: 3,297.46340

Timestep Collection Time: 12.67206
Timestep Consumption Time: 2.50081
PPO Batch Consumption Time: 0.05425
Total Iteration Time: 15.17287

Cumulative Model Updates: 48,787
Cumulative Timesteps: 813,763,132

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,097.43964
Policy Entropy: 1.10517
Value Function Loss: 4.28681

Mean KL Divergence: 0.05488
SB3 Clip Fraction: 0.19862
Policy Update Magnitude: 0.06144
Value Function Update Magnitude: 0.09835

Collected Steps per Second: 3,834.53826
Overall Steps per Second: 3,160.85665

Timestep Collection Time: 13.04772
Timestep Consumption Time: 2.78090
PPO Batch Consumption Time: 0.06097
Total Iteration Time: 15.82862

Cumulative Model Updates: 48,790
Cumulative Timesteps: 813,813,164

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 813813164...
Checkpoint 813813164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,254.05994
Policy Entropy: 1.13169
Value Function Loss: 4.34338

Mean KL Divergence: 0.02413
SB3 Clip Fraction: 0.15070
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 3,869.73417
Overall Steps per Second: 3,196.79103

Timestep Collection Time: 12.92440
Timestep Consumption Time: 2.72066
PPO Batch Consumption Time: 0.06182
Total Iteration Time: 15.64506

Cumulative Model Updates: 48,793
Cumulative Timesteps: 813,863,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,805.83556
Policy Entropy: 1.10416
Value Function Loss: 4.31586

Mean KL Divergence: 0.03559
SB3 Clip Fraction: 0.19215
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.12842

Collected Steps per Second: 3,894.95820
Overall Steps per Second: 3,212.30847

Timestep Collection Time: 12.84173
Timestep Consumption Time: 2.72900
PPO Batch Consumption Time: 0.06558
Total Iteration Time: 15.57073

Cumulative Model Updates: 48,796
Cumulative Timesteps: 813,913,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 813913196...
Checkpoint 813913196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,412.84633
Policy Entropy: 1.12364
Value Function Loss: 4.19656

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.11862

Collected Steps per Second: 3,923.53263
Overall Steps per Second: 3,265.94048

Timestep Collection Time: 12.75687
Timestep Consumption Time: 2.56858
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 15.32545

Cumulative Model Updates: 48,799
Cumulative Timesteps: 813,963,248

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,128.46162
Policy Entropy: 1.11729
Value Function Loss: 4.17778

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.12876

Collected Steps per Second: 3,774.21564
Overall Steps per Second: 3,173.49139

Timestep Collection Time: 13.24832
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.05173
Total Iteration Time: 15.75615

Cumulative Model Updates: 48,802
Cumulative Timesteps: 814,013,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 814013250...
Checkpoint 814013250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,053.40025
Policy Entropy: 1.11384
Value Function Loss: 4.20557

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.11429

Collected Steps per Second: 3,888.58254
Overall Steps per Second: 3,217.33409

Timestep Collection Time: 12.87050
Timestep Consumption Time: 2.68524
PPO Batch Consumption Time: 0.05821
Total Iteration Time: 15.55574

Cumulative Model Updates: 48,805
Cumulative Timesteps: 814,063,298

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,394.16737
Policy Entropy: 1.09828
Value Function Loss: 4.35866

Mean KL Divergence: 0.03308
SB3 Clip Fraction: 0.19209
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.10004

Collected Steps per Second: 3,822.73564
Overall Steps per Second: 3,196.47321

Timestep Collection Time: 13.08801
Timestep Consumption Time: 2.56424
PPO Batch Consumption Time: 0.06892
Total Iteration Time: 15.65225

Cumulative Model Updates: 48,808
Cumulative Timesteps: 814,113,330

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 814113330...
Checkpoint 814113330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,624.39209
Policy Entropy: 1.13108
Value Function Loss: 4.24850

Mean KL Divergence: 0.02917
SB3 Clip Fraction: 0.19385
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.10706

Collected Steps per Second: 3,805.90137
Overall Steps per Second: 3,119.38614

Timestep Collection Time: 13.13749
Timestep Consumption Time: 2.89130
PPO Batch Consumption Time: 0.06696
Total Iteration Time: 16.02879

Cumulative Model Updates: 48,811
Cumulative Timesteps: 814,163,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,023.67812
Policy Entropy: 1.10112
Value Function Loss: 4.22950

Mean KL Divergence: 0.05411
SB3 Clip Fraction: 0.23116
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.11437

Collected Steps per Second: 3,772.86909
Overall Steps per Second: 3,160.97100

Timestep Collection Time: 13.25516
Timestep Consumption Time: 2.56592
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 15.82109

Cumulative Model Updates: 48,814
Cumulative Timesteps: 814,213,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 814213340...
Checkpoint 814213340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,738.12835
Policy Entropy: 1.12685
Value Function Loss: 4.13088

Mean KL Divergence: 0.03564
SB3 Clip Fraction: 0.19145
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.09742

Collected Steps per Second: 3,820.45831
Overall Steps per Second: 3,167.77915

Timestep Collection Time: 13.10105
Timestep Consumption Time: 2.69930
PPO Batch Consumption Time: 0.06446
Total Iteration Time: 15.80034

Cumulative Model Updates: 48,817
Cumulative Timesteps: 814,263,392

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537,759.67551
Policy Entropy: 1.10279
Value Function Loss: 4.13384

Mean KL Divergence: 0.05690
SB3 Clip Fraction: 0.22629
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.08419

Collected Steps per Second: 3,790.40404
Overall Steps per Second: 3,112.17933

Timestep Collection Time: 13.19384
Timestep Consumption Time: 2.87528
PPO Batch Consumption Time: 0.06280
Total Iteration Time: 16.06913

Cumulative Model Updates: 48,820
Cumulative Timesteps: 814,313,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 814313402...
Checkpoint 814313402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,691.24794
Policy Entropy: 1.11822
Value Function Loss: 4.08477

Mean KL Divergence: 0.03104
SB3 Clip Fraction: 0.15878
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.08065

Collected Steps per Second: 3,776.64058
Overall Steps per Second: 3,181.82328

Timestep Collection Time: 13.24352
Timestep Consumption Time: 2.47577
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 15.71929

Cumulative Model Updates: 48,823
Cumulative Timesteps: 814,363,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,186.36740
Policy Entropy: 1.10181
Value Function Loss: 3.99955

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.16608
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.09025

Collected Steps per Second: 3,893.24120
Overall Steps per Second: 3,179.16477

Timestep Collection Time: 12.84945
Timestep Consumption Time: 2.88613
PPO Batch Consumption Time: 0.06390
Total Iteration Time: 15.73558

Cumulative Model Updates: 48,826
Cumulative Timesteps: 814,413,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 814413444...
Checkpoint 814413444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,717.95263
Policy Entropy: 1.11229
Value Function Loss: 4.09989

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.15347
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.08973

Collected Steps per Second: 3,752.20777
Overall Steps per Second: 3,171.37104

Timestep Collection Time: 13.32815
Timestep Consumption Time: 2.44105
PPO Batch Consumption Time: 0.06029
Total Iteration Time: 15.76920

Cumulative Model Updates: 48,829
Cumulative Timesteps: 814,463,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,985.40760
Policy Entropy: 1.11748
Value Function Loss: 4.14127

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.08245

Collected Steps per Second: 4,004.32156
Overall Steps per Second: 3,288.29294

Timestep Collection Time: 12.49400
Timestep Consumption Time: 2.72058
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 15.21458

Cumulative Model Updates: 48,832
Cumulative Timesteps: 814,513,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 814513484...
Checkpoint 814513484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,327.01975
Policy Entropy: 1.10258
Value Function Loss: 4.29788

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.07892

Collected Steps per Second: 3,793.29845
Overall Steps per Second: 3,148.70278

Timestep Collection Time: 13.18536
Timestep Consumption Time: 2.69928
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 15.88464

Cumulative Model Updates: 48,835
Cumulative Timesteps: 814,563,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,208.61730
Policy Entropy: 1.09738
Value Function Loss: 4.30046

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.08801

Collected Steps per Second: 3,989.50875
Overall Steps per Second: 3,263.08372

Timestep Collection Time: 12.54039
Timestep Consumption Time: 2.79173
PPO Batch Consumption Time: 0.05293
Total Iteration Time: 15.33212

Cumulative Model Updates: 48,838
Cumulative Timesteps: 814,613,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 814613530...
Checkpoint 814613530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,062.08062
Policy Entropy: 1.10454
Value Function Loss: 4.34806

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.10032

Collected Steps per Second: 3,761.81418
Overall Steps per Second: 3,097.74646

Timestep Collection Time: 13.29890
Timestep Consumption Time: 2.85090
PPO Batch Consumption Time: 0.06196
Total Iteration Time: 16.14980

Cumulative Model Updates: 48,841
Cumulative Timesteps: 814,663,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,810.75893
Policy Entropy: 1.10847
Value Function Loss: 4.35914

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.10889

Collected Steps per Second: 3,837.06392
Overall Steps per Second: 3,219.16701

Timestep Collection Time: 13.03340
Timestep Consumption Time: 2.50167
PPO Batch Consumption Time: 0.05094
Total Iteration Time: 15.53507

Cumulative Model Updates: 48,844
Cumulative Timesteps: 814,713,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 814713568...
Checkpoint 814713568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,557.33375
Policy Entropy: 1.09377
Value Function Loss: 4.33408

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.10613

Collected Steps per Second: 3,749.71954
Overall Steps per Second: 3,107.34907

Timestep Collection Time: 13.34606
Timestep Consumption Time: 2.75898
PPO Batch Consumption Time: 0.05433
Total Iteration Time: 16.10505

Cumulative Model Updates: 48,847
Cumulative Timesteps: 814,763,612

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,520.68184
Policy Entropy: 1.10046
Value Function Loss: 4.32582

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.16399
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.09708

Collected Steps per Second: 3,883.33213
Overall Steps per Second: 3,232.47033

Timestep Collection Time: 12.88121
Timestep Consumption Time: 2.59365
PPO Batch Consumption Time: 0.06159
Total Iteration Time: 15.47485

Cumulative Model Updates: 48,850
Cumulative Timesteps: 814,813,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 814813634...
Checkpoint 814813634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,313.61800
Policy Entropy: 1.10443
Value Function Loss: 4.34220

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.16025
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.08694

Collected Steps per Second: 3,790.81525
Overall Steps per Second: 3,189.62870

Timestep Collection Time: 13.19822
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.06398
Total Iteration Time: 15.68584

Cumulative Model Updates: 48,853
Cumulative Timesteps: 814,863,666

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,333.67281
Policy Entropy: 1.09491
Value Function Loss: 4.20520

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.08647

Collected Steps per Second: 3,899.69745
Overall Steps per Second: 3,240.80147

Timestep Collection Time: 12.83279
Timestep Consumption Time: 2.60907
PPO Batch Consumption Time: 0.05318
Total Iteration Time: 15.44186

Cumulative Model Updates: 48,856
Cumulative Timesteps: 814,913,710

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 814913710...
Checkpoint 814913710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,841.42815
Policy Entropy: 1.09317
Value Function Loss: 4.06235

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.16103
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.09954

Collected Steps per Second: 3,826.42608
Overall Steps per Second: 3,226.68847

Timestep Collection Time: 13.06807
Timestep Consumption Time: 2.42893
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 15.49700

Cumulative Model Updates: 48,859
Cumulative Timesteps: 814,963,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,491.21290
Policy Entropy: 1.09755
Value Function Loss: 4.15460

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.09799

Collected Steps per Second: 3,989.92945
Overall Steps per Second: 3,341.78361

Timestep Collection Time: 12.53155
Timestep Consumption Time: 2.43052
PPO Batch Consumption Time: 0.05861
Total Iteration Time: 14.96207

Cumulative Model Updates: 48,862
Cumulative Timesteps: 815,013,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 815013714...
Checkpoint 815013714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,875.08203
Policy Entropy: 1.10169
Value Function Loss: 4.26670

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.09686

Collected Steps per Second: 4,015.07441
Overall Steps per Second: 3,318.06056

Timestep Collection Time: 12.46104
Timestep Consumption Time: 2.61765
PPO Batch Consumption Time: 0.06525
Total Iteration Time: 15.07869

Cumulative Model Updates: 48,865
Cumulative Timesteps: 815,063,746

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,048.79957
Policy Entropy: 1.07857
Value Function Loss: 4.43529

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.06288
Value Function Update Magnitude: 0.09312

Collected Steps per Second: 3,961.30630
Overall Steps per Second: 3,321.84152

Timestep Collection Time: 12.62311
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.06483
Total Iteration Time: 15.05310

Cumulative Model Updates: 48,868
Cumulative Timesteps: 815,113,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 815113750...
Checkpoint 815113750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,795.98104
Policy Entropy: 1.09833
Value Function Loss: 4.45266

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.09417

Collected Steps per Second: 3,797.50937
Overall Steps per Second: 3,176.96854

Timestep Collection Time: 13.17390
Timestep Consumption Time: 2.57319
PPO Batch Consumption Time: 0.05119
Total Iteration Time: 15.74709

Cumulative Model Updates: 48,871
Cumulative Timesteps: 815,163,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,710.28208
Policy Entropy: 1.10161
Value Function Loss: 4.45871

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.15169
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.11066

Collected Steps per Second: 3,895.70704
Overall Steps per Second: 3,262.96341

Timestep Collection Time: 12.84748
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.05118
Total Iteration Time: 15.33882

Cumulative Model Updates: 48,874
Cumulative Timesteps: 815,213,828

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 815213828...
Checkpoint 815213828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,307.24366
Policy Entropy: 1.10031
Value Function Loss: 4.28637

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.12836

Collected Steps per Second: 3,903.23734
Overall Steps per Second: 3,227.83048

Timestep Collection Time: 12.81193
Timestep Consumption Time: 2.68083
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 15.49276

Cumulative Model Updates: 48,877
Cumulative Timesteps: 815,263,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,816.81964
Policy Entropy: 1.08373
Value Function Loss: 4.09693

Mean KL Divergence: 0.03273
SB3 Clip Fraction: 0.19781
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 3,920.98385
Overall Steps per Second: 3,244.93501

Timestep Collection Time: 12.76108
Timestep Consumption Time: 2.65864
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 15.41972

Cumulative Model Updates: 48,880
Cumulative Timesteps: 815,313,872

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 815313872...
Checkpoint 815313872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,594.42670
Policy Entropy: 1.11761
Value Function Loss: 4.12199

Mean KL Divergence: 0.03003
SB3 Clip Fraction: 0.19333
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.11914

Collected Steps per Second: 3,893.82270
Overall Steps per Second: 3,239.98458

Timestep Collection Time: 12.84907
Timestep Consumption Time: 2.59298
PPO Batch Consumption Time: 0.05820
Total Iteration Time: 15.44205

Cumulative Model Updates: 48,883
Cumulative Timesteps: 815,363,904

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,032.39315
Policy Entropy: 1.07905
Value Function Loss: 4.11373

Mean KL Divergence: 0.05796
SB3 Clip Fraction: 0.23872
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.13022

Collected Steps per Second: 3,858.99892
Overall Steps per Second: 3,211.39457

Timestep Collection Time: 12.96139
Timestep Consumption Time: 2.61377
PPO Batch Consumption Time: 0.06321
Total Iteration Time: 15.57516

Cumulative Model Updates: 48,886
Cumulative Timesteps: 815,413,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 815413922...
Checkpoint 815413922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650,735.47871
Policy Entropy: 1.10202
Value Function Loss: 4.05922

Mean KL Divergence: 0.03807
SB3 Clip Fraction: 0.20421
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.13748

Collected Steps per Second: 3,830.16290
Overall Steps per Second: 3,219.13291

Timestep Collection Time: 13.05897
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 15.53772

Cumulative Model Updates: 48,889
Cumulative Timesteps: 815,463,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,385.47184
Policy Entropy: 1.07232
Value Function Loss: 3.98925

Mean KL Divergence: 0.05037
SB3 Clip Fraction: 0.23465
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.13071

Collected Steps per Second: 3,947.36949
Overall Steps per Second: 3,223.15880

Timestep Collection Time: 12.67021
Timestep Consumption Time: 2.84687
PPO Batch Consumption Time: 0.06671
Total Iteration Time: 15.51708

Cumulative Model Updates: 48,892
Cumulative Timesteps: 815,513,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 815513954...
Checkpoint 815513954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,081.24924
Policy Entropy: 1.09562
Value Function Loss: 4.09768

Mean KL Divergence: 0.03664
SB3 Clip Fraction: 0.19491
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.11843

Collected Steps per Second: 3,915.87199
Overall Steps per Second: 3,234.36990

Timestep Collection Time: 12.77059
Timestep Consumption Time: 2.69084
PPO Batch Consumption Time: 0.06794
Total Iteration Time: 15.46144

Cumulative Model Updates: 48,895
Cumulative Timesteps: 815,563,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,540.39211
Policy Entropy: 1.08146
Value Function Loss: 4.17828

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.16418
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.12333

Collected Steps per Second: 3,815.41582
Overall Steps per Second: 3,134.80182

Timestep Collection Time: 13.11522
Timestep Consumption Time: 2.84752
PPO Batch Consumption Time: 0.06368
Total Iteration Time: 15.96273

Cumulative Model Updates: 48,898
Cumulative Timesteps: 815,614,002

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 815614002...
Checkpoint 815614002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,165.62890
Policy Entropy: 1.10388
Value Function Loss: 4.23489

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.15946
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.11929

Collected Steps per Second: 3,921.49217
Overall Steps per Second: 3,156.35644

Timestep Collection Time: 12.75586
Timestep Consumption Time: 3.09216
PPO Batch Consumption Time: 0.06335
Total Iteration Time: 15.84802

Cumulative Model Updates: 48,901
Cumulative Timesteps: 815,664,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,131.94590
Policy Entropy: 1.10826
Value Function Loss: 4.40797

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.11982

Collected Steps per Second: 3,759.25321
Overall Steps per Second: 3,184.44850

Timestep Collection Time: 13.30264
Timestep Consumption Time: 2.40118
PPO Batch Consumption Time: 0.05847
Total Iteration Time: 15.70382

Cumulative Model Updates: 48,904
Cumulative Timesteps: 815,714,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 815714032...
Checkpoint 815714032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,209.64192
Policy Entropy: 1.09204
Value Function Loss: 4.51048

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12512
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.12347

Collected Steps per Second: 3,926.12364
Overall Steps per Second: 3,211.04693

Timestep Collection Time: 12.74743
Timestep Consumption Time: 2.83876
PPO Batch Consumption Time: 0.06271
Total Iteration Time: 15.58619

Cumulative Model Updates: 48,907
Cumulative Timesteps: 815,764,080

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,008.07397
Policy Entropy: 1.08835
Value Function Loss: 4.60830

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.11825

Collected Steps per Second: 3,806.00206
Overall Steps per Second: 3,160.11978

Timestep Collection Time: 13.13977
Timestep Consumption Time: 2.68558
PPO Batch Consumption Time: 0.06485
Total Iteration Time: 15.82535

Cumulative Model Updates: 48,910
Cumulative Timesteps: 815,814,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 815814090...
Checkpoint 815814090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,004.28062
Policy Entropy: 1.09390
Value Function Loss: 4.50453

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.11701

Collected Steps per Second: 4,029.53560
Overall Steps per Second: 3,276.15912

Timestep Collection Time: 12.41284
Timestep Consumption Time: 2.85442
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 15.26727

Cumulative Model Updates: 48,913
Cumulative Timesteps: 815,864,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,943.02239
Policy Entropy: 1.09986
Value Function Loss: 4.35223

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 3,833.18126
Overall Steps per Second: 3,157.54434

Timestep Collection Time: 13.04713
Timestep Consumption Time: 2.79176
PPO Batch Consumption Time: 0.05937
Total Iteration Time: 15.83889

Cumulative Model Updates: 48,916
Cumulative Timesteps: 815,914,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 815914120...
Checkpoint 815914120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,588.00688
Policy Entropy: 1.07841
Value Function Loss: 4.20752

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 3,812.16800
Overall Steps per Second: 3,201.08591

Timestep Collection Time: 13.12377
Timestep Consumption Time: 2.50531
PPO Batch Consumption Time: 0.05903
Total Iteration Time: 15.62907

Cumulative Model Updates: 48,919
Cumulative Timesteps: 815,964,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,155.38843
Policy Entropy: 1.09369
Value Function Loss: 4.22838

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.12811

Collected Steps per Second: 3,832.30791
Overall Steps per Second: 3,164.90028

Timestep Collection Time: 13.06054
Timestep Consumption Time: 2.75418
PPO Batch Consumption Time: 0.05818
Total Iteration Time: 15.81472

Cumulative Model Updates: 48,922
Cumulative Timesteps: 816,014,202

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 816014202...
Checkpoint 816014202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,378.87757
Policy Entropy: 1.09905
Value Function Loss: 4.26335

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.12572

Collected Steps per Second: 3,922.53023
Overall Steps per Second: 3,247.39465

Timestep Collection Time: 12.75197
Timestep Consumption Time: 2.65114
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 15.40312

Cumulative Model Updates: 48,925
Cumulative Timesteps: 816,064,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,738.81990
Policy Entropy: 1.08865
Value Function Loss: 4.37211

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 3,962.13281
Overall Steps per Second: 3,245.41852

Timestep Collection Time: 12.62048
Timestep Consumption Time: 2.78709
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 15.40757

Cumulative Model Updates: 48,928
Cumulative Timesteps: 816,114,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 816114226...
Checkpoint 816114226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,947.83737
Policy Entropy: 1.07577
Value Function Loss: 4.30479

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.09980

Collected Steps per Second: 4,363.44113
Overall Steps per Second: 3,530.94490

Timestep Collection Time: 11.46297
Timestep Consumption Time: 2.70264
PPO Batch Consumption Time: 0.06592
Total Iteration Time: 14.16561

Cumulative Model Updates: 48,931
Cumulative Timesteps: 816,164,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,746.39993
Policy Entropy: 1.08255
Value Function Loss: 4.21683

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.08857

Collected Steps per Second: 4,252.57005
Overall Steps per Second: 3,553.36243

Timestep Collection Time: 11.76136
Timestep Consumption Time: 2.31432
PPO Batch Consumption Time: 0.05883
Total Iteration Time: 14.07568

Cumulative Model Updates: 48,934
Cumulative Timesteps: 816,214,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 816214260...
Checkpoint 816214260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,269.38820
Policy Entropy: 1.09457
Value Function Loss: 4.28505

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.17150
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.09341

Collected Steps per Second: 4,469.33068
Overall Steps per Second: 3,619.06228

Timestep Collection Time: 11.19362
Timestep Consumption Time: 2.62985
PPO Batch Consumption Time: 0.06119
Total Iteration Time: 13.82347

Cumulative Model Updates: 48,937
Cumulative Timesteps: 816,264,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,678.13645
Policy Entropy: 1.07233
Value Function Loss: 4.17760

Mean KL Divergence: 0.03336
SB3 Clip Fraction: 0.16837
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.08856

Collected Steps per Second: 4,610.48336
Overall Steps per Second: 3,803.27383

Timestep Collection Time: 10.85222
Timestep Consumption Time: 2.30328
PPO Batch Consumption Time: 0.06577
Total Iteration Time: 13.15551

Cumulative Model Updates: 48,940
Cumulative Timesteps: 816,314,322

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 816314322...
Checkpoint 816314322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,466.21870
Policy Entropy: 1.08869
Value Function Loss: 4.29209

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.08196

Collected Steps per Second: 4,592.75730
Overall Steps per Second: 3,660.88474

Timestep Collection Time: 10.89411
Timestep Consumption Time: 2.77308
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 13.66719

Cumulative Model Updates: 48,943
Cumulative Timesteps: 816,364,356

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,093.13426
Policy Entropy: 1.08889
Value Function Loss: 4.18739

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.14793
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.08105

Collected Steps per Second: 4,275.06411
Overall Steps per Second: 3,480.18477

Timestep Collection Time: 11.70789
Timestep Consumption Time: 2.67410
PPO Batch Consumption Time: 0.05063
Total Iteration Time: 14.38200

Cumulative Model Updates: 48,946
Cumulative Timesteps: 816,414,408

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 816414408...
Checkpoint 816414408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,710.53361
Policy Entropy: 1.08451
Value Function Loss: 4.28178

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.09077

Collected Steps per Second: 4,050.19570
Overall Steps per Second: 3,353.12796

Timestep Collection Time: 12.34656
Timestep Consumption Time: 2.56668
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 14.91324

Cumulative Model Updates: 48,949
Cumulative Timesteps: 816,464,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,211.75195
Policy Entropy: 1.08581
Value Function Loss: 4.12471

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.10731

Collected Steps per Second: 4,300.14966
Overall Steps per Second: 3,524.56233

Timestep Collection Time: 11.63401
Timestep Consumption Time: 2.56009
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 14.19410

Cumulative Model Updates: 48,952
Cumulative Timesteps: 816,514,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 816514442...
Checkpoint 816514442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,422.74007
Policy Entropy: 1.09043
Value Function Loss: 4.14039

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.11593

Collected Steps per Second: 4,341.97733
Overall Steps per Second: 3,507.37583

Timestep Collection Time: 11.51779
Timestep Consumption Time: 2.74073
PPO Batch Consumption Time: 0.05861
Total Iteration Time: 14.25852

Cumulative Model Updates: 48,955
Cumulative Timesteps: 816,564,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,482.66729
Policy Entropy: 1.08751
Value Function Loss: 4.11954

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.06500
Value Function Update Magnitude: 0.12076

Collected Steps per Second: 4,163.96259
Overall Steps per Second: 3,436.13953

Timestep Collection Time: 12.01644
Timestep Consumption Time: 2.54525
PPO Batch Consumption Time: 0.06107
Total Iteration Time: 14.56169

Cumulative Model Updates: 48,958
Cumulative Timesteps: 816,614,488

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 816614488...
Checkpoint 816614488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,368.71335
Policy Entropy: 1.08918
Value Function Loss: 4.12671

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.06482
Value Function Update Magnitude: 0.10366

Collected Steps per Second: 4,103.36474
Overall Steps per Second: 3,352.97005

Timestep Collection Time: 12.18512
Timestep Consumption Time: 2.72703
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 14.91215

Cumulative Model Updates: 48,961
Cumulative Timesteps: 816,664,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,424.25952
Policy Entropy: 1.09104
Value Function Loss: 4.04323

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.06932
Value Function Update Magnitude: 0.09491

Collected Steps per Second: 3,956.98897
Overall Steps per Second: 3,300.19017

Timestep Collection Time: 12.63638
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.05997
Total Iteration Time: 15.15125

Cumulative Model Updates: 48,964
Cumulative Timesteps: 816,714,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 816714490...
Checkpoint 816714490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,851.25351
Policy Entropy: 1.09701
Value Function Loss: 4.06578

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.08678

Collected Steps per Second: 4,256.14663
Overall Steps per Second: 3,488.48831

Timestep Collection Time: 11.75007
Timestep Consumption Time: 2.58566
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 14.33572

Cumulative Model Updates: 48,967
Cumulative Timesteps: 816,764,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,408.55470
Policy Entropy: 1.09815
Value Function Loss: 4.18576

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.11068
Policy Update Magnitude: 0.06900
Value Function Update Magnitude: 0.09074

Collected Steps per Second: 4,345.08140
Overall Steps per Second: 3,612.76522

Timestep Collection Time: 11.51095
Timestep Consumption Time: 2.33330
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 13.84424

Cumulative Model Updates: 48,970
Cumulative Timesteps: 816,814,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 816814516...
Checkpoint 816814516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,470.16077
Policy Entropy: 1.10859
Value Function Loss: 4.20351

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.06437
Value Function Update Magnitude: 0.08840

Collected Steps per Second: 4,242.05204
Overall Steps per Second: 3,546.05034

Timestep Collection Time: 11.78958
Timestep Consumption Time: 2.31400
PPO Batch Consumption Time: 0.06070
Total Iteration Time: 14.10358

Cumulative Model Updates: 48,973
Cumulative Timesteps: 816,864,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,126.62219
Policy Entropy: 1.11830
Value Function Loss: 4.14082

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.07006
Value Function Update Magnitude: 0.07853

Collected Steps per Second: 4,146.85218
Overall Steps per Second: 3,382.27272

Timestep Collection Time: 12.06457
Timestep Consumption Time: 2.72726
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 14.79183

Cumulative Model Updates: 48,976
Cumulative Timesteps: 816,914,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 816914558...
Checkpoint 816914558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,176.20839
Policy Entropy: 1.10838
Value Function Loss: 4.08471

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.07140
Value Function Update Magnitude: 0.08164

Collected Steps per Second: 3,892.76726
Overall Steps per Second: 3,228.50977

Timestep Collection Time: 12.85101
Timestep Consumption Time: 2.64406
PPO Batch Consumption Time: 0.05886
Total Iteration Time: 15.49507

Cumulative Model Updates: 48,979
Cumulative Timesteps: 816,964,584

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,555.55285
Policy Entropy: 1.09990
Value Function Loss: 4.11562

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.06875
Value Function Update Magnitude: 0.10175

Collected Steps per Second: 3,791.43971
Overall Steps per Second: 3,101.34608

Timestep Collection Time: 13.19552
Timestep Consumption Time: 2.93619
PPO Batch Consumption Time: 0.06041
Total Iteration Time: 16.13170

Cumulative Model Updates: 48,982
Cumulative Timesteps: 817,014,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 817014614...
Checkpoint 817014614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,248.43996
Policy Entropy: 1.10810
Value Function Loss: 4.05481

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.11240

Collected Steps per Second: 3,931.16400
Overall Steps per Second: 3,208.57950

Timestep Collection Time: 12.73109
Timestep Consumption Time: 2.86709
PPO Batch Consumption Time: 0.06382
Total Iteration Time: 15.59818

Cumulative Model Updates: 48,985
Cumulative Timesteps: 817,064,662

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,675.25534
Policy Entropy: 1.10563
Value Function Loss: 4.08555

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 3,877.84847
Overall Steps per Second: 3,182.73928

Timestep Collection Time: 12.89529
Timestep Consumption Time: 2.81633
PPO Batch Consumption Time: 0.06991
Total Iteration Time: 15.71162

Cumulative Model Updates: 48,988
Cumulative Timesteps: 817,114,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 817114668...
Checkpoint 817114668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,072.08343
Policy Entropy: 1.09516
Value Function Loss: 4.17449

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.12120

Collected Steps per Second: 4,115.95673
Overall Steps per Second: 3,461.30818

Timestep Collection Time: 12.15319
Timestep Consumption Time: 2.29857
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 14.45176

Cumulative Model Updates: 48,991
Cumulative Timesteps: 817,164,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,071.32633
Policy Entropy: 1.08502
Value Function Loss: 4.30336

Mean KL Divergence: 0.02763
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.13279

Collected Steps per Second: 3,955.93201
Overall Steps per Second: 3,264.50500

Timestep Collection Time: 12.64683
Timestep Consumption Time: 2.67862
PPO Batch Consumption Time: 0.05816
Total Iteration Time: 15.32545

Cumulative Model Updates: 48,994
Cumulative Timesteps: 817,214,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 817214720...
Checkpoint 817214720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,430.22487
Policy Entropy: 1.11510
Value Function Loss: 4.26477

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.12645

Collected Steps per Second: 3,815.77473
Overall Steps per Second: 3,167.06191

Timestep Collection Time: 13.10979
Timestep Consumption Time: 2.68529
PPO Batch Consumption Time: 0.06253
Total Iteration Time: 15.79508

Cumulative Model Updates: 48,997
Cumulative Timesteps: 817,264,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,362.74834
Policy Entropy: 1.10135
Value Function Loss: 4.13542

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.16131
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 3,971.74311
Overall Steps per Second: 3,256.61702

Timestep Collection Time: 12.59850
Timestep Consumption Time: 2.76653
PPO Batch Consumption Time: 0.06933
Total Iteration Time: 15.36502

Cumulative Model Updates: 49,000
Cumulative Timesteps: 817,314,782

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 817314782...
Checkpoint 817314782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,309.52044
Policy Entropy: 1.10736
Value Function Loss: 4.08674

Mean KL Divergence: 0.02383
SB3 Clip Fraction: 0.16227
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.13811

Collected Steps per Second: 3,908.30655
Overall Steps per Second: 3,209.20382

Timestep Collection Time: 12.80248
Timestep Consumption Time: 2.78893
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 15.59141

Cumulative Model Updates: 49,003
Cumulative Timesteps: 817,364,818

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,071.27142
Policy Entropy: 1.11060
Value Function Loss: 4.00218

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.15621
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.14079

Collected Steps per Second: 3,772.97262
Overall Steps per Second: 3,166.04385

Timestep Collection Time: 13.25798
Timestep Consumption Time: 2.54155
PPO Batch Consumption Time: 0.06411
Total Iteration Time: 15.79953

Cumulative Model Updates: 49,006
Cumulative Timesteps: 817,414,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 817414840...
Checkpoint 817414840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,218.91564
Policy Entropy: 1.09713
Value Function Loss: 3.95785

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.14538

Collected Steps per Second: 3,839.67380
Overall Steps per Second: 3,165.17903

Timestep Collection Time: 13.03132
Timestep Consumption Time: 2.77695
PPO Batch Consumption Time: 0.06006
Total Iteration Time: 15.80827

Cumulative Model Updates: 49,009
Cumulative Timesteps: 817,464,876

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592,391.91536
Policy Entropy: 1.09076
Value Function Loss: 3.97778

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.16580
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.13364

Collected Steps per Second: 3,837.31789
Overall Steps per Second: 3,209.88788

Timestep Collection Time: 13.03098
Timestep Consumption Time: 2.54714
PPO Batch Consumption Time: 0.05912
Total Iteration Time: 15.57811

Cumulative Model Updates: 49,012
Cumulative Timesteps: 817,514,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 817514880...
Checkpoint 817514880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,343.46768
Policy Entropy: 1.10022
Value Function Loss: 4.07899

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.11754

Collected Steps per Second: 3,900.84685
Overall Steps per Second: 3,222.91348

Timestep Collection Time: 12.82491
Timestep Consumption Time: 2.69769
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 15.52260

Cumulative Model Updates: 49,015
Cumulative Timesteps: 817,564,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,483.73035
Policy Entropy: 1.10592
Value Function Loss: 4.20148

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.12345

Collected Steps per Second: 3,804.08422
Overall Steps per Second: 3,166.27113

Timestep Collection Time: 13.14692
Timestep Consumption Time: 2.64831
PPO Batch Consumption Time: 0.06478
Total Iteration Time: 15.79524

Cumulative Model Updates: 49,018
Cumulative Timesteps: 817,614,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 817614920...
Checkpoint 817614920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,001.58935
Policy Entropy: 1.09039
Value Function Loss: 4.03190

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.12131

Collected Steps per Second: 3,922.55254
Overall Steps per Second: 3,224.59367

Timestep Collection Time: 12.75904
Timestep Consumption Time: 2.76168
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 15.52072

Cumulative Model Updates: 49,021
Cumulative Timesteps: 817,664,968

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,745.93480
Policy Entropy: 1.10952
Value Function Loss: 3.99245

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.10173

Collected Steps per Second: 3,823.64184
Overall Steps per Second: 3,177.01390

Timestep Collection Time: 13.08438
Timestep Consumption Time: 2.66311
PPO Batch Consumption Time: 0.06650
Total Iteration Time: 15.74749

Cumulative Model Updates: 49,024
Cumulative Timesteps: 817,714,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 817714998...
Checkpoint 817714998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,328.82410
Policy Entropy: 1.11369
Value Function Loss: 3.98232

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.09004

Collected Steps per Second: 3,863.68529
Overall Steps per Second: 3,207.93622

Timestep Collection Time: 12.94981
Timestep Consumption Time: 2.64713
PPO Batch Consumption Time: 0.06696
Total Iteration Time: 15.59694

Cumulative Model Updates: 49,027
Cumulative Timesteps: 817,765,032

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,010.60919
Policy Entropy: 1.10712
Value Function Loss: 4.15352

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.09429

Collected Steps per Second: 3,843.63873
Overall Steps per Second: 3,148.89729

Timestep Collection Time: 13.01423
Timestep Consumption Time: 2.87133
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 15.88556

Cumulative Model Updates: 49,030
Cumulative Timesteps: 817,815,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 817815054...
Checkpoint 817815054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631,374.14545
Policy Entropy: 1.09767
Value Function Loss: 4.28377

Mean KL Divergence: 0.03415
SB3 Clip Fraction: 0.18107
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.09217

Collected Steps per Second: 3,916.76941
Overall Steps per Second: 3,283.14872

Timestep Collection Time: 12.77635
Timestep Consumption Time: 2.46573
PPO Batch Consumption Time: 0.05390
Total Iteration Time: 15.24208

Cumulative Model Updates: 49,033
Cumulative Timesteps: 817,865,096

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,293.01077
Policy Entropy: 1.11338
Value Function Loss: 4.24126

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.09688

Collected Steps per Second: 3,970.90891
Overall Steps per Second: 3,238.67465

Timestep Collection Time: 12.60316
Timestep Consumption Time: 2.84946
PPO Batch Consumption Time: 0.05869
Total Iteration Time: 15.45262

Cumulative Model Updates: 49,036
Cumulative Timesteps: 817,915,142

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 817915142...
Checkpoint 817915142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,398.99308
Policy Entropy: 1.11072
Value Function Loss: 4.25930

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.08955

Collected Steps per Second: 3,877.31632
Overall Steps per Second: 3,227.93079

Timestep Collection Time: 12.89861
Timestep Consumption Time: 2.59490
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 15.49352

Cumulative Model Updates: 49,039
Cumulative Timesteps: 817,965,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,502.23557
Policy Entropy: 1.10469
Value Function Loss: 4.14627

Mean KL Divergence: 0.02798
SB3 Clip Fraction: 0.16974
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.09978

Collected Steps per Second: 3,891.58165
Overall Steps per Second: 3,181.33757

Timestep Collection Time: 12.85133
Timestep Consumption Time: 2.86910
PPO Batch Consumption Time: 0.06772
Total Iteration Time: 15.72043

Cumulative Model Updates: 49,042
Cumulative Timesteps: 818,015,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 818015166...
Checkpoint 818015166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,317.83928
Policy Entropy: 1.11534
Value Function Loss: 3.98843

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 3,898.19161
Overall Steps per Second: 3,195.93573

Timestep Collection Time: 12.82800
Timestep Consumption Time: 2.81875
PPO Batch Consumption Time: 0.06010
Total Iteration Time: 15.64675

Cumulative Model Updates: 49,045
Cumulative Timesteps: 818,065,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,510.58841
Policy Entropy: 1.11380
Value Function Loss: 3.95376

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.10716

Collected Steps per Second: 3,887.69013
Overall Steps per Second: 3,226.32158

Timestep Collection Time: 12.86882
Timestep Consumption Time: 2.63800
PPO Batch Consumption Time: 0.05812
Total Iteration Time: 15.50682

Cumulative Model Updates: 49,048
Cumulative Timesteps: 818,115,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 818115202...
Checkpoint 818115202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,381.63292
Policy Entropy: 1.10006
Value Function Loss: 3.94155

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.05781
Value Function Update Magnitude: 0.09814

Collected Steps per Second: 3,804.77006
Overall Steps per Second: 3,138.70973

Timestep Collection Time: 13.14298
Timestep Consumption Time: 2.78905
PPO Batch Consumption Time: 0.05955
Total Iteration Time: 15.93202

Cumulative Model Updates: 49,051
Cumulative Timesteps: 818,165,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,073.20755
Policy Entropy: 1.09243
Value Function Loss: 4.12783

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.15227
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.09175

Collected Steps per Second: 3,675.85277
Overall Steps per Second: 3,034.69783

Timestep Collection Time: 13.60990
Timestep Consumption Time: 2.87543
PPO Batch Consumption Time: 0.05855
Total Iteration Time: 16.48533

Cumulative Model Updates: 49,054
Cumulative Timesteps: 818,215,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 818215236...
Checkpoint 818215236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,928.53819
Policy Entropy: 1.10131
Value Function Loss: 4.28966

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.07913

Collected Steps per Second: 3,862.49425
Overall Steps per Second: 3,155.17029

Timestep Collection Time: 12.95018
Timestep Consumption Time: 2.90316
PPO Batch Consumption Time: 0.06915
Total Iteration Time: 15.85334

Cumulative Model Updates: 49,057
Cumulative Timesteps: 818,265,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,793.57062
Policy Entropy: 1.11273
Value Function Loss: 4.32039

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.05683
Value Function Update Magnitude: 0.07787

Collected Steps per Second: 3,860.57154
Overall Steps per Second: 3,196.81721

Timestep Collection Time: 12.95249
Timestep Consumption Time: 2.68932
PPO Batch Consumption Time: 0.06776
Total Iteration Time: 15.64181

Cumulative Model Updates: 49,060
Cumulative Timesteps: 818,315,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 818315260...
Checkpoint 818315260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,386.71803
Policy Entropy: 1.08644
Value Function Loss: 4.30414

Mean KL Divergence: 0.02620
SB3 Clip Fraction: 0.17791
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.08056

Collected Steps per Second: 3,821.19835
Overall Steps per Second: 3,180.24408

Timestep Collection Time: 13.09327
Timestep Consumption Time: 2.63885
PPO Batch Consumption Time: 0.06977
Total Iteration Time: 15.73213

Cumulative Model Updates: 49,063
Cumulative Timesteps: 818,365,292

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,859.17794
Policy Entropy: 1.10707
Value Function Loss: 4.04393

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.08123

Collected Steps per Second: 3,849.76417
Overall Steps per Second: 3,165.74405

Timestep Collection Time: 12.98989
Timestep Consumption Time: 2.80672
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 15.79660

Cumulative Model Updates: 49,066
Cumulative Timesteps: 818,415,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 818415300...
Checkpoint 818415300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,483.64191
Policy Entropy: 1.10368
Value Function Loss: 3.98575

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.07674

Collected Steps per Second: 3,860.75054
Overall Steps per Second: 3,235.34687

Timestep Collection Time: 12.95396
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.06215
Total Iteration Time: 15.45800

Cumulative Model Updates: 49,069
Cumulative Timesteps: 818,465,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,235.24827
Policy Entropy: 1.09827
Value Function Loss: 3.82002

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.09527

Collected Steps per Second: 3,980.24637
Overall Steps per Second: 3,255.43665

Timestep Collection Time: 12.57410
Timestep Consumption Time: 2.79957
PPO Batch Consumption Time: 0.06146
Total Iteration Time: 15.37367

Cumulative Model Updates: 49,072
Cumulative Timesteps: 818,515,360

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 818515360...
Checkpoint 818515360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,149.21749
Policy Entropy: 1.08474
Value Function Loss: 3.85726

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.15537
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.11525

Collected Steps per Second: 3,843.27000
Overall Steps per Second: 3,181.81793

Timestep Collection Time: 13.02172
Timestep Consumption Time: 2.70702
PPO Batch Consumption Time: 0.06012
Total Iteration Time: 15.72874

Cumulative Model Updates: 49,075
Cumulative Timesteps: 818,565,406

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612,051.27166
Policy Entropy: 1.09427
Value Function Loss: 3.94501

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.10431

Collected Steps per Second: 3,838.35886
Overall Steps per Second: 3,209.81184

Timestep Collection Time: 13.02953
Timestep Consumption Time: 2.55145
PPO Batch Consumption Time: 0.06272
Total Iteration Time: 15.58098

Cumulative Model Updates: 49,078
Cumulative Timesteps: 818,615,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 818615418...
Checkpoint 818615418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,279.89959
Policy Entropy: 1.09361
Value Function Loss: 4.16632

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.09124

Collected Steps per Second: 3,855.17665
Overall Steps per Second: 3,183.61365

Timestep Collection Time: 12.97269
Timestep Consumption Time: 2.73651
PPO Batch Consumption Time: 0.06045
Total Iteration Time: 15.70919

Cumulative Model Updates: 49,081
Cumulative Timesteps: 818,665,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,583.74523
Policy Entropy: 1.08487
Value Function Loss: 4.21399

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.09418

Collected Steps per Second: 3,886.47381
Overall Steps per Second: 3,202.57053

Timestep Collection Time: 12.87800
Timestep Consumption Time: 2.75007
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 15.62807

Cumulative Model Updates: 49,084
Cumulative Timesteps: 818,715,480

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 818715480...
Checkpoint 818715480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,968.58528
Policy Entropy: 1.07383
Value Function Loss: 4.27607

Mean KL Divergence: 0.02491
SB3 Clip Fraction: 0.16729
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.09293

Collected Steps per Second: 3,888.03038
Overall Steps per Second: 3,183.84781

Timestep Collection Time: 12.86410
Timestep Consumption Time: 2.84520
PPO Batch Consumption Time: 0.06242
Total Iteration Time: 15.70929

Cumulative Model Updates: 49,087
Cumulative Timesteps: 818,765,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,648.14965
Policy Entropy: 1.09683
Value Function Loss: 4.35854

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.08085

Collected Steps per Second: 3,903.04991
Overall Steps per Second: 3,186.98140

Timestep Collection Time: 12.82177
Timestep Consumption Time: 2.88087
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 15.70263

Cumulative Model Updates: 49,090
Cumulative Timesteps: 818,815,540

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 818815540...
Checkpoint 818815540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742,532.98353
Policy Entropy: 1.08602
Value Function Loss: 4.24444

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.07036
Value Function Update Magnitude: 0.06538

Collected Steps per Second: 3,801.44756
Overall Steps per Second: 3,198.92351

Timestep Collection Time: 13.15920
Timestep Consumption Time: 2.47856
PPO Batch Consumption Time: 0.04915
Total Iteration Time: 15.63776

Cumulative Model Updates: 49,093
Cumulative Timesteps: 818,865,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,086.36514
Policy Entropy: 1.08118
Value Function Loss: 3.99928

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.14829
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.06757

Collected Steps per Second: 3,871.23094
Overall Steps per Second: 3,169.41499

Timestep Collection Time: 12.92250
Timestep Consumption Time: 2.86148
PPO Batch Consumption Time: 0.05827
Total Iteration Time: 15.78399

Cumulative Model Updates: 49,096
Cumulative Timesteps: 818,915,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 818915590...
Checkpoint 818915590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,858.74581
Policy Entropy: 1.09142
Value Function Loss: 3.85690

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.07067

Collected Steps per Second: 3,771.03506
Overall Steps per Second: 3,114.01925

Timestep Collection Time: 13.26002
Timestep Consumption Time: 2.79768
PPO Batch Consumption Time: 0.06602
Total Iteration Time: 16.05770

Cumulative Model Updates: 49,099
Cumulative Timesteps: 818,965,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,728.13823
Policy Entropy: 1.09840
Value Function Loss: 3.86319

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.15676
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.07145

Collected Steps per Second: 3,861.60524
Overall Steps per Second: 3,190.69704

Timestep Collection Time: 12.95161
Timestep Consumption Time: 2.72334
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 15.67494

Cumulative Model Updates: 49,102
Cumulative Timesteps: 819,015,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 819015608...
Checkpoint 819015608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,225.88075
Policy Entropy: 1.08964
Value Function Loss: 4.13511

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.07054

Collected Steps per Second: 3,933.24430
Overall Steps per Second: 3,231.16270

Timestep Collection Time: 12.71368
Timestep Consumption Time: 2.76249
PPO Batch Consumption Time: 0.06462
Total Iteration Time: 15.47616

Cumulative Model Updates: 49,105
Cumulative Timesteps: 819,065,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,198.86368
Policy Entropy: 1.09353
Value Function Loss: 4.25576

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.07279

Collected Steps per Second: 3,880.69482
Overall Steps per Second: 3,244.92429

Timestep Collection Time: 12.89408
Timestep Consumption Time: 2.52631
PPO Batch Consumption Time: 0.05979
Total Iteration Time: 15.42039

Cumulative Model Updates: 49,108
Cumulative Timesteps: 819,115,652

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 819115652...
Checkpoint 819115652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,408.65346
Policy Entropy: 1.10071
Value Function Loss: 4.24887

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.08074

Collected Steps per Second: 3,817.99583
Overall Steps per Second: 3,179.09719

Timestep Collection Time: 13.09745
Timestep Consumption Time: 2.63218
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 15.72962

Cumulative Model Updates: 49,111
Cumulative Timesteps: 819,165,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688,690.75884
Policy Entropy: 1.10470
Value Function Loss: 4.30523

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.08716

Collected Steps per Second: 3,786.18944
Overall Steps per Second: 3,131.23446

Timestep Collection Time: 13.20800
Timestep Consumption Time: 2.76270
PPO Batch Consumption Time: 0.06571
Total Iteration Time: 15.97070

Cumulative Model Updates: 49,114
Cumulative Timesteps: 819,215,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 819215666...
Checkpoint 819215666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,578.37000
Policy Entropy: 1.09970
Value Function Loss: 4.13820

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.06535
Value Function Update Magnitude: 0.09442

Collected Steps per Second: 3,877.90158
Overall Steps per Second: 3,173.00522

Timestep Collection Time: 12.89512
Timestep Consumption Time: 2.86470
PPO Batch Consumption Time: 0.06215
Total Iteration Time: 15.75982

Cumulative Model Updates: 49,117
Cumulative Timesteps: 819,265,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,991.42264
Policy Entropy: 1.09249
Value Function Loss: 4.29154

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.06811
Value Function Update Magnitude: 0.09249

Collected Steps per Second: 3,771.60778
Overall Steps per Second: 3,111.96551

Timestep Collection Time: 13.26225
Timestep Consumption Time: 2.81119
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 16.07344

Cumulative Model Updates: 49,120
Cumulative Timesteps: 819,315,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 819315692...
Checkpoint 819315692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,349.58211
Policy Entropy: 1.08535
Value Function Loss: 4.23150

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.10572

Collected Steps per Second: 3,842.03063
Overall Steps per Second: 3,190.22872

Timestep Collection Time: 13.01551
Timestep Consumption Time: 2.65923
PPO Batch Consumption Time: 0.06439
Total Iteration Time: 15.67474

Cumulative Model Updates: 49,123
Cumulative Timesteps: 819,365,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,849.10613
Policy Entropy: 1.09043
Value Function Loss: 4.26513

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.10797

Collected Steps per Second: 3,812.17153
Overall Steps per Second: 3,123.94099

Timestep Collection Time: 13.12008
Timestep Consumption Time: 2.89046
PPO Batch Consumption Time: 0.05240
Total Iteration Time: 16.01055

Cumulative Model Updates: 49,126
Cumulative Timesteps: 819,415,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 819415714...
Checkpoint 819415714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,911.23768
Policy Entropy: 1.09688
Value Function Loss: 4.28811

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.10505

Collected Steps per Second: 3,944.88629
Overall Steps per Second: 3,246.46966

Timestep Collection Time: 12.68376
Timestep Consumption Time: 2.72867
PPO Batch Consumption Time: 0.06156
Total Iteration Time: 15.41243

Cumulative Model Updates: 49,129
Cumulative Timesteps: 819,465,750

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,261.40528
Policy Entropy: 1.10127
Value Function Loss: 4.28585

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.09589

Collected Steps per Second: 3,848.69142
Overall Steps per Second: 3,069.82090

Timestep Collection Time: 12.99559
Timestep Consumption Time: 3.29722
PPO Batch Consumption Time: 0.06134
Total Iteration Time: 16.29281

Cumulative Model Updates: 49,132
Cumulative Timesteps: 819,515,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 819515766...
Checkpoint 819515766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,543.81190
Policy Entropy: 1.10567
Value Function Loss: 4.30194

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.07468
Value Function Update Magnitude: 0.10544

Collected Steps per Second: 3,806.40033
Overall Steps per Second: 3,046.83855

Timestep Collection Time: 13.14418
Timestep Consumption Time: 3.27678
PPO Batch Consumption Time: 0.06758
Total Iteration Time: 16.42096

Cumulative Model Updates: 49,135
Cumulative Timesteps: 819,565,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,590.71750
Policy Entropy: 1.10191
Value Function Loss: 4.08885

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.10495

Collected Steps per Second: 3,816.96658
Overall Steps per Second: 3,201.41222

Timestep Collection Time: 13.10674
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.06466
Total Iteration Time: 15.62685

Cumulative Model Updates: 49,138
Cumulative Timesteps: 819,615,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 819615826...
Checkpoint 819615826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,638.43259
Policy Entropy: 1.10134
Value Function Loss: 4.03003

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.11705

Collected Steps per Second: 3,858.73465
Overall Steps per Second: 3,171.84606

Timestep Collection Time: 12.96591
Timestep Consumption Time: 2.80787
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 15.77378

Cumulative Model Updates: 49,141
Cumulative Timesteps: 819,665,858

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,909.66855
Policy Entropy: 1.10252
Value Function Loss: 3.94489

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.06934
Value Function Update Magnitude: 0.10434

Collected Steps per Second: 3,742.57140
Overall Steps per Second: 3,107.64291

Timestep Collection Time: 13.37102
Timestep Consumption Time: 2.73186
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 16.10288

Cumulative Model Updates: 49,144
Cumulative Timesteps: 819,715,900

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 819715900...
Checkpoint 819715900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,512.04951
Policy Entropy: 1.09731
Value Function Loss: 3.91297

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.06680
Value Function Update Magnitude: 0.09289

Collected Steps per Second: 3,986.21415
Overall Steps per Second: 3,252.38653

Timestep Collection Time: 12.55226
Timestep Consumption Time: 2.83213
PPO Batch Consumption Time: 0.06270
Total Iteration Time: 15.38440

Cumulative Model Updates: 49,147
Cumulative Timesteps: 819,765,936

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,893.69850
Policy Entropy: 1.10040
Value Function Loss: 3.87507

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.08517

Collected Steps per Second: 3,916.23472
Overall Steps per Second: 3,222.22292

Timestep Collection Time: 12.77400
Timestep Consumption Time: 2.75130
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 15.52531

Cumulative Model Updates: 49,150
Cumulative Timesteps: 819,815,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 819815962...
Checkpoint 819815962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,219.51723
Policy Entropy: 1.10528
Value Function Loss: 4.11000

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.06717
Value Function Update Magnitude: 0.07946

Collected Steps per Second: 3,856.97856
Overall Steps per Second: 3,246.75970

Timestep Collection Time: 12.96663
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 15.40367

Cumulative Model Updates: 49,153
Cumulative Timesteps: 819,865,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,033.10484
Policy Entropy: 1.10635
Value Function Loss: 4.17452

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.06686
Value Function Update Magnitude: 0.09134

Collected Steps per Second: 3,832.05981
Overall Steps per Second: 3,158.01494

Timestep Collection Time: 13.05042
Timestep Consumption Time: 2.78547
PPO Batch Consumption Time: 0.05140
Total Iteration Time: 15.83590

Cumulative Model Updates: 49,156
Cumulative Timesteps: 819,915,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 819915984...
Checkpoint 819915984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,442.25363
Policy Entropy: 1.10425
Value Function Loss: 4.03500

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.09769

Collected Steps per Second: 3,862.87237
Overall Steps per Second: 3,241.72104

Timestep Collection Time: 12.94736
Timestep Consumption Time: 2.48086
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 15.42822

Cumulative Model Updates: 49,159
Cumulative Timesteps: 819,965,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,292.76336
Policy Entropy: 1.12397
Value Function Loss: 3.82974

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.08845

Collected Steps per Second: 3,964.98802
Overall Steps per Second: 3,264.34134

Timestep Collection Time: 12.61088
Timestep Consumption Time: 2.70676
PPO Batch Consumption Time: 0.05232
Total Iteration Time: 15.31764

Cumulative Model Updates: 49,162
Cumulative Timesteps: 820,016,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 820016000...
Checkpoint 820016000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,730.18290
Policy Entropy: 1.11524
Value Function Loss: 3.95083

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.07890

Collected Steps per Second: 3,842.89058
Overall Steps per Second: 3,216.90070

Timestep Collection Time: 13.01728
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.06182
Total Iteration Time: 15.55037

Cumulative Model Updates: 49,165
Cumulative Timesteps: 820,066,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,688.74417
Policy Entropy: 1.10659
Value Function Loss: 4.08810

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.07758

Collected Steps per Second: 3,738.35482
Overall Steps per Second: 3,156.02547

Timestep Collection Time: 13.38396
Timestep Consumption Time: 2.46952
PPO Batch Consumption Time: 0.05273
Total Iteration Time: 15.85348

Cumulative Model Updates: 49,168
Cumulative Timesteps: 820,116,058

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 820116058...
Checkpoint 820116058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493,130.74522
Policy Entropy: 1.09554
Value Function Loss: 4.11240

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.08146

Collected Steps per Second: 3,806.40757
Overall Steps per Second: 3,139.61555

Timestep Collection Time: 13.14468
Timestep Consumption Time: 2.79167
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 15.93635

Cumulative Model Updates: 49,171
Cumulative Timesteps: 820,166,092

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,372.03041
Policy Entropy: 1.10974
Value Function Loss: 4.12212

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.07505

Collected Steps per Second: 3,959.70497
Overall Steps per Second: 3,259.68402

Timestep Collection Time: 12.63933
Timestep Consumption Time: 2.71431
PPO Batch Consumption Time: 0.06204
Total Iteration Time: 15.35364

Cumulative Model Updates: 49,174
Cumulative Timesteps: 820,216,140

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 820216140...
Checkpoint 820216140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650,559.00089
Policy Entropy: 1.11206
Value Function Loss: 4.12665

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.07613

Collected Steps per Second: 3,729.13857
Overall Steps per Second: 3,070.90790

Timestep Collection Time: 13.40899
Timestep Consumption Time: 2.87414
PPO Batch Consumption Time: 0.06334
Total Iteration Time: 16.28313

Cumulative Model Updates: 49,177
Cumulative Timesteps: 820,266,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,284.44547
Policy Entropy: 1.09860
Value Function Loss: 4.15783

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.07209

Collected Steps per Second: 3,910.73746
Overall Steps per Second: 3,244.04523

Timestep Collection Time: 12.78634
Timestep Consumption Time: 2.62775
PPO Batch Consumption Time: 0.05921
Total Iteration Time: 15.41409

Cumulative Model Updates: 49,180
Cumulative Timesteps: 820,316,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 820316148...
Checkpoint 820316148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,562.15361
Policy Entropy: 1.10679
Value Function Loss: 4.00091

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.08009

Collected Steps per Second: 3,857.52958
Overall Steps per Second: 3,149.49102

Timestep Collection Time: 12.97411
Timestep Consumption Time: 2.91671
PPO Batch Consumption Time: 0.06736
Total Iteration Time: 15.89082

Cumulative Model Updates: 49,183
Cumulative Timesteps: 820,366,196

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,841.36901
Policy Entropy: 1.11812
Value Function Loss: 4.06553

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.09026

Collected Steps per Second: 3,956.15276
Overall Steps per Second: 3,252.08156

Timestep Collection Time: 12.64612
Timestep Consumption Time: 2.73787
PPO Batch Consumption Time: 0.06309
Total Iteration Time: 15.38399

Cumulative Model Updates: 49,186
Cumulative Timesteps: 820,416,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 820416226...
Checkpoint 820416226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,150.63293
Policy Entropy: 1.11932
Value Function Loss: 4.11134

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.09488

Collected Steps per Second: 3,838.28930
Overall Steps per Second: 3,155.21372

Timestep Collection Time: 13.03758
Timestep Consumption Time: 2.82252
PPO Batch Consumption Time: 0.05964
Total Iteration Time: 15.86010

Cumulative Model Updates: 49,189
Cumulative Timesteps: 820,466,268

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,143.02282
Policy Entropy: 1.10489
Value Function Loss: 4.16499

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.11265
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.09667

Collected Steps per Second: 3,817.38395
Overall Steps per Second: 3,158.36712

Timestep Collection Time: 13.10321
Timestep Consumption Time: 2.73408
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 15.83730

Cumulative Model Updates: 49,192
Cumulative Timesteps: 820,516,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 820516288...
Checkpoint 820516288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,126.84654
Policy Entropy: 1.10312
Value Function Loss: 4.07686

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.06236
Value Function Update Magnitude: 0.09395

Collected Steps per Second: 3,772.02345
Overall Steps per Second: 3,167.74622

Timestep Collection Time: 13.25973
Timestep Consumption Time: 2.52942
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 15.78914

Cumulative Model Updates: 49,195
Cumulative Timesteps: 820,566,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,885.77226
Policy Entropy: 1.10321
Value Function Loss: 4.03088

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.08676

Collected Steps per Second: 3,963.80954
Overall Steps per Second: 3,277.05404

Timestep Collection Time: 12.62523
Timestep Consumption Time: 2.64580
PPO Batch Consumption Time: 0.06542
Total Iteration Time: 15.27103

Cumulative Model Updates: 49,198
Cumulative Timesteps: 820,616,348

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 820616348...
Checkpoint 820616348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,730.80408
Policy Entropy: 1.10293
Value Function Loss: 3.88972

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.07540
Value Function Update Magnitude: 0.08453

Collected Steps per Second: 3,818.85129
Overall Steps per Second: 3,201.07201

Timestep Collection Time: 13.10708
Timestep Consumption Time: 2.52955
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 15.63664

Cumulative Model Updates: 49,201
Cumulative Timesteps: 820,666,402

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,087.42015
Policy Entropy: 1.11233
Value Function Loss: 3.76354

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.07491
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 3,896.85184
Overall Steps per Second: 3,193.64863

Timestep Collection Time: 12.83754
Timestep Consumption Time: 2.82667
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 15.66422

Cumulative Model Updates: 49,204
Cumulative Timesteps: 820,716,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 820716428...
Checkpoint 820716428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,840.94181
Policy Entropy: 1.10810
Value Function Loss: 3.90753

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.07288
Value Function Update Magnitude: 0.07941

Collected Steps per Second: 3,852.22338
Overall Steps per Second: 3,186.77270

Timestep Collection Time: 12.97952
Timestep Consumption Time: 2.71034
PPO Batch Consumption Time: 0.05284
Total Iteration Time: 15.68985

Cumulative Model Updates: 49,207
Cumulative Timesteps: 820,766,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,802.86305
Policy Entropy: 1.11953
Value Function Loss: 4.20979

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.06535
Value Function Update Magnitude: 0.07405

Collected Steps per Second: 3,929.82842
Overall Steps per Second: 3,224.06272

Timestep Collection Time: 12.72676
Timestep Consumption Time: 2.78596
PPO Batch Consumption Time: 0.06011
Total Iteration Time: 15.51273

Cumulative Model Updates: 49,210
Cumulative Timesteps: 820,816,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 820816442...
Checkpoint 820816442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,013.38115
Policy Entropy: 1.12208
Value Function Loss: 4.37427

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.06467

Collected Steps per Second: 3,797.87469
Overall Steps per Second: 3,124.89151

Timestep Collection Time: 13.17210
Timestep Consumption Time: 2.83677
PPO Batch Consumption Time: 0.06093
Total Iteration Time: 16.00888

Cumulative Model Updates: 49,213
Cumulative Timesteps: 820,866,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,132.48285
Policy Entropy: 1.12066
Value Function Loss: 4.33400

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.06717
Value Function Update Magnitude: 0.06135

Collected Steps per Second: 3,972.08385
Overall Steps per Second: 3,256.31609

Timestep Collection Time: 12.59540
Timestep Consumption Time: 2.76858
PPO Batch Consumption Time: 0.06119
Total Iteration Time: 15.36399

Cumulative Model Updates: 49,216
Cumulative Timesteps: 820,916,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 820916498...
Checkpoint 820916498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,147.46480
Policy Entropy: 1.11866
Value Function Loss: 4.24270

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.07062
Value Function Update Magnitude: 0.05754

Collected Steps per Second: 3,829.79460
Overall Steps per Second: 3,139.75985

Timestep Collection Time: 13.05710
Timestep Consumption Time: 2.86960
PPO Batch Consumption Time: 0.06314
Total Iteration Time: 15.92670

Cumulative Model Updates: 49,219
Cumulative Timesteps: 820,966,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,927.27582
Policy Entropy: 1.11880
Value Function Loss: 4.18726

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.07363
Value Function Update Magnitude: 0.07294

Collected Steps per Second: 3,830.37711
Overall Steps per Second: 3,220.16925

Timestep Collection Time: 13.05616
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 15.53024

Cumulative Model Updates: 49,222
Cumulative Timesteps: 821,016,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 821016514...
Checkpoint 821016514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,149.24291
Policy Entropy: 1.12365
Value Function Loss: 4.01628

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.07485
Value Function Update Magnitude: 0.08284

Collected Steps per Second: 3,847.64264
Overall Steps per Second: 3,155.00469

Timestep Collection Time: 13.00745
Timestep Consumption Time: 2.85561
PPO Batch Consumption Time: 0.05426
Total Iteration Time: 15.86305

Cumulative Model Updates: 49,225
Cumulative Timesteps: 821,066,562

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,896.98987
Policy Entropy: 1.12347
Value Function Loss: 4.15372

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.06982
Value Function Update Magnitude: 0.07999

Collected Steps per Second: 3,835.29987
Overall Steps per Second: 3,154.49059

Timestep Collection Time: 13.03783
Timestep Consumption Time: 2.81385
PPO Batch Consumption Time: 0.06957
Total Iteration Time: 15.85169

Cumulative Model Updates: 49,228
Cumulative Timesteps: 821,116,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 821116566...
Checkpoint 821116566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,368.90902
Policy Entropy: 1.12299
Value Function Loss: 4.11251

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.06846
Value Function Update Magnitude: 0.08684

Collected Steps per Second: 3,864.06714
Overall Steps per Second: 3,209.51359

Timestep Collection Time: 12.95164
Timestep Consumption Time: 2.64138
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 15.59302

Cumulative Model Updates: 49,231
Cumulative Timesteps: 821,166,612

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,570.96288
Policy Entropy: 1.12122
Value Function Loss: 4.12021

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.09007

Collected Steps per Second: 3,815.61287
Overall Steps per Second: 3,125.86621

Timestep Collection Time: 13.10772
Timestep Consumption Time: 2.89232
PPO Batch Consumption Time: 0.07075
Total Iteration Time: 16.00005

Cumulative Model Updates: 49,234
Cumulative Timesteps: 821,216,626

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 821216626...
Checkpoint 821216626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,893.62913
Policy Entropy: 1.12254
Value Function Loss: 3.95517

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.09239

Collected Steps per Second: 3,816.70607
Overall Steps per Second: 3,179.83222

Timestep Collection Time: 13.10711
Timestep Consumption Time: 2.62516
PPO Batch Consumption Time: 0.06563
Total Iteration Time: 15.73228

Cumulative Model Updates: 49,237
Cumulative Timesteps: 821,266,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,648.43072
Policy Entropy: 1.12684
Value Function Loss: 3.98474

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.09782

Collected Steps per Second: 3,766.13988
Overall Steps per Second: 3,093.61042

Timestep Collection Time: 13.28044
Timestep Consumption Time: 2.88708
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 16.16752

Cumulative Model Updates: 49,240
Cumulative Timesteps: 821,316,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 821316668...
Checkpoint 821316668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,767.02156
Policy Entropy: 1.12366
Value Function Loss: 4.13474

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.06758
Value Function Update Magnitude: 0.09064

Collected Steps per Second: 3,856.60019
Overall Steps per Second: 3,229.45336

Timestep Collection Time: 12.97049
Timestep Consumption Time: 2.51882
PPO Batch Consumption Time: 0.05006
Total Iteration Time: 15.48931

Cumulative Model Updates: 49,243
Cumulative Timesteps: 821,366,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,814.00996
Policy Entropy: 1.12458
Value Function Loss: 4.23735

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.08330

Collected Steps per Second: 3,721.48160
Overall Steps per Second: 3,075.49690

Timestep Collection Time: 13.44035
Timestep Consumption Time: 2.82304
PPO Batch Consumption Time: 0.06673
Total Iteration Time: 16.26339

Cumulative Model Updates: 49,246
Cumulative Timesteps: 821,416,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 821416708...
Checkpoint 821416708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,974.56289
Policy Entropy: 1.12887
Value Function Loss: 4.20541

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.07538

Collected Steps per Second: 3,756.26861
Overall Steps per Second: 3,140.97677

Timestep Collection Time: 13.32173
Timestep Consumption Time: 2.60962
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 15.93135

Cumulative Model Updates: 49,249
Cumulative Timesteps: 821,466,748

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,042.94026
Policy Entropy: 1.13317
Value Function Loss: 3.95697

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14392
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.07367

Collected Steps per Second: 3,846.56334
Overall Steps per Second: 3,170.57918

Timestep Collection Time: 13.00278
Timestep Consumption Time: 2.77226
PPO Batch Consumption Time: 0.06750
Total Iteration Time: 15.77504

Cumulative Model Updates: 49,252
Cumulative Timesteps: 821,516,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 821516764...
Checkpoint 821516764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,303.06147
Policy Entropy: 1.12132
Value Function Loss: 4.03614

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.07397

Collected Steps per Second: 3,910.38738
Overall Steps per Second: 3,218.10730

Timestep Collection Time: 12.78748
Timestep Consumption Time: 2.75085
PPO Batch Consumption Time: 0.06203
Total Iteration Time: 15.53833

Cumulative Model Updates: 49,255
Cumulative Timesteps: 821,566,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,045.42434
Policy Entropy: 1.12850
Value Function Loss: 4.06437

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.07363

Collected Steps per Second: 3,828.56844
Overall Steps per Second: 3,198.78788

Timestep Collection Time: 13.06807
Timestep Consumption Time: 2.57285
PPO Batch Consumption Time: 0.07265
Total Iteration Time: 15.64092

Cumulative Model Updates: 49,258
Cumulative Timesteps: 821,616,800

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 821616800...
Checkpoint 821616800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,464.77077
Policy Entropy: 1.12670
Value Function Loss: 4.17018

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.07911

Collected Steps per Second: 3,821.76117
Overall Steps per Second: 3,172.56449

Timestep Collection Time: 13.09239
Timestep Consumption Time: 2.67908
PPO Batch Consumption Time: 0.06327
Total Iteration Time: 15.77147

Cumulative Model Updates: 49,261
Cumulative Timesteps: 821,666,836

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,901.23505
Policy Entropy: 1.12357
Value Function Loss: 4.05664

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.07326
Value Function Update Magnitude: 0.07379

Collected Steps per Second: 3,794.15727
Overall Steps per Second: 3,139.87979

Timestep Collection Time: 13.18132
Timestep Consumption Time: 2.74668
PPO Batch Consumption Time: 0.06913
Total Iteration Time: 15.92800

Cumulative Model Updates: 49,264
Cumulative Timesteps: 821,716,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 821716848...
Checkpoint 821716848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,648.74891
Policy Entropy: 1.11743
Value Function Loss: 4.11405

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.07952
Value Function Update Magnitude: 0.06815

Collected Steps per Second: 3,904.04091
Overall Steps per Second: 3,213.64222

Timestep Collection Time: 12.80980
Timestep Consumption Time: 2.75198
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 15.56178

Cumulative Model Updates: 49,267
Cumulative Timesteps: 821,766,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,116.20262
Policy Entropy: 1.11316
Value Function Loss: 4.27557

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.08460
Value Function Update Magnitude: 0.07955

Collected Steps per Second: 3,676.85767
Overall Steps per Second: 3,074.39113

Timestep Collection Time: 13.61162
Timestep Consumption Time: 2.66737
PPO Batch Consumption Time: 0.06514
Total Iteration Time: 16.27900

Cumulative Model Updates: 49,270
Cumulative Timesteps: 821,816,906

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 821816906...
Checkpoint 821816906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,098.65425
Policy Entropy: 1.11942
Value Function Loss: 4.28929

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.07185
Value Function Update Magnitude: 0.10737

Collected Steps per Second: 3,909.89867
Overall Steps per Second: 3,267.68922

Timestep Collection Time: 12.79726
Timestep Consumption Time: 2.51509
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 15.31235

Cumulative Model Updates: 49,273
Cumulative Timesteps: 821,866,942

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,458.45326
Policy Entropy: 1.11956
Value Function Loss: 4.11969

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.07180
Value Function Update Magnitude: 0.10529

Collected Steps per Second: 3,951.02489
Overall Steps per Second: 3,220.42596

Timestep Collection Time: 12.66254
Timestep Consumption Time: 2.87267
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 15.53521

Cumulative Model Updates: 49,276
Cumulative Timesteps: 821,916,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 821916972...
Checkpoint 821916972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,921.59125
Policy Entropy: 1.11832
Value Function Loss: 4.17242

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.07510
Value Function Update Magnitude: 0.08984

Collected Steps per Second: 3,817.87077
Overall Steps per Second: 3,153.88505

Timestep Collection Time: 13.09630
Timestep Consumption Time: 2.75716
PPO Batch Consumption Time: 0.06192
Total Iteration Time: 15.85346

Cumulative Model Updates: 49,279
Cumulative Timesteps: 821,966,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,006.80873
Policy Entropy: 1.12171
Value Function Loss: 4.22150

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.07212
Value Function Update Magnitude: 0.08139

Collected Steps per Second: 3,818.66092
Overall Steps per Second: 3,168.29336

Timestep Collection Time: 13.10512
Timestep Consumption Time: 2.69014
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 15.79525

Cumulative Model Updates: 49,282
Cumulative Timesteps: 822,017,016

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 822017016...
Checkpoint 822017016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,183.65142
Policy Entropy: 1.12669
Value Function Loss: 4.41293

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.08726

Collected Steps per Second: 3,766.71426
Overall Steps per Second: 3,125.80872

Timestep Collection Time: 13.27842
Timestep Consumption Time: 2.72256
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 16.00098

Cumulative Model Updates: 49,285
Cumulative Timesteps: 822,067,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,306.07791
Policy Entropy: 1.12732
Value Function Loss: 4.33816

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.07553
Value Function Update Magnitude: 0.09532

Collected Steps per Second: 3,777.52445
Overall Steps per Second: 3,209.17371

Timestep Collection Time: 13.24306
Timestep Consumption Time: 2.34537
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 15.58844

Cumulative Model Updates: 49,288
Cumulative Timesteps: 822,117,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 822117058...
Checkpoint 822117058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,628.00333
Policy Entropy: 1.11674
Value Function Loss: 4.33006

Mean KL Divergence: 0.03124
SB3 Clip Fraction: 0.16445
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.08324

Collected Steps per Second: 3,744.98540
Overall Steps per Second: 3,079.92094

Timestep Collection Time: 13.36027
Timestep Consumption Time: 2.88496
PPO Batch Consumption Time: 0.06509
Total Iteration Time: 16.24522

Cumulative Model Updates: 49,291
Cumulative Timesteps: 822,167,092

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,932.30193
Policy Entropy: 1.13251
Value Function Loss: 4.26927

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.08214

Collected Steps per Second: 3,909.89911
Overall Steps per Second: 3,270.10917

Timestep Collection Time: 12.79163
Timestep Consumption Time: 2.50266
PPO Batch Consumption Time: 0.06173
Total Iteration Time: 15.29429

Cumulative Model Updates: 49,294
Cumulative Timesteps: 822,217,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 822217106...
Checkpoint 822217106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,692.87922
Policy Entropy: 1.12629
Value Function Loss: 4.19821

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.09215

Collected Steps per Second: 3,775.49316
Overall Steps per Second: 3,104.56492

Timestep Collection Time: 13.25602
Timestep Consumption Time: 2.86476
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 16.12078

Cumulative Model Updates: 49,297
Cumulative Timesteps: 822,267,154

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,759.29056
Policy Entropy: 1.11250
Value Function Loss: 4.02035

Mean KL Divergence: 0.02566
SB3 Clip Fraction: 0.15809
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.09330

Collected Steps per Second: 3,837.77791
Overall Steps per Second: 3,206.69316

Timestep Collection Time: 13.03827
Timestep Consumption Time: 2.56596
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 15.60424

Cumulative Model Updates: 49,300
Cumulative Timesteps: 822,317,192

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 822317192...
Checkpoint 822317192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,047.25240
Policy Entropy: 1.12606
Value Function Loss: 3.99895

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.09255

Collected Steps per Second: 3,849.61635
Overall Steps per Second: 3,245.62205

Timestep Collection Time: 12.99039
Timestep Consumption Time: 2.41745
PPO Batch Consumption Time: 0.05949
Total Iteration Time: 15.40783

Cumulative Model Updates: 49,303
Cumulative Timesteps: 822,367,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,744.39173
Policy Entropy: 1.12920
Value Function Loss: 4.02924

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 3,772.55352
Overall Steps per Second: 3,115.84926

Timestep Collection Time: 13.25892
Timestep Consumption Time: 2.79448
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 16.05341

Cumulative Model Updates: 49,306
Cumulative Timesteps: 822,417,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 822417220...
Checkpoint 822417220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,200.14965
Policy Entropy: 1.11919
Value Function Loss: 4.18086

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.08320

Collected Steps per Second: 3,739.46831
Overall Steps per Second: 3,129.23714

Timestep Collection Time: 13.37516
Timestep Consumption Time: 2.60828
PPO Batch Consumption Time: 0.06346
Total Iteration Time: 15.98345

Cumulative Model Updates: 49,309
Cumulative Timesteps: 822,467,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,172.41086
Policy Entropy: 1.11372
Value Function Loss: 4.12044

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.14676
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.08981

Collected Steps per Second: 3,918.40293
Overall Steps per Second: 3,188.62560

Timestep Collection Time: 12.76949
Timestep Consumption Time: 2.92254
PPO Batch Consumption Time: 0.06374
Total Iteration Time: 15.69203

Cumulative Model Updates: 49,312
Cumulative Timesteps: 822,517,272

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 822517272...
Checkpoint 822517272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,162.68249
Policy Entropy: 1.12144
Value Function Loss: 4.13037

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.09043

Collected Steps per Second: 3,800.35642
Overall Steps per Second: 3,178.56375

Timestep Collection Time: 13.16140
Timestep Consumption Time: 2.57464
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 15.73604

Cumulative Model Updates: 49,315
Cumulative Timesteps: 822,567,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,700.71040
Policy Entropy: 1.12828
Value Function Loss: 3.99858

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.11237

Collected Steps per Second: 3,924.01106
Overall Steps per Second: 3,184.70249

Timestep Collection Time: 12.74461
Timestep Consumption Time: 2.95858
PPO Batch Consumption Time: 0.07134
Total Iteration Time: 15.70319

Cumulative Model Updates: 49,318
Cumulative Timesteps: 822,617,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 822617300...
Checkpoint 822617300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,684.73731
Policy Entropy: 1.11246
Value Function Loss: 4.02694

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.11357

Collected Steps per Second: 3,759.86223
Overall Steps per Second: 3,105.67576

Timestep Collection Time: 13.29996
Timestep Consumption Time: 2.80153
PPO Batch Consumption Time: 0.06716
Total Iteration Time: 16.10149

Cumulative Model Updates: 49,321
Cumulative Timesteps: 822,667,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,678.89400
Policy Entropy: 1.12106
Value Function Loss: 3.87624

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.11505

Collected Steps per Second: 3,918.18730
Overall Steps per Second: 3,222.20920

Timestep Collection Time: 12.76560
Timestep Consumption Time: 2.75729
PPO Batch Consumption Time: 0.06364
Total Iteration Time: 15.52289

Cumulative Model Updates: 49,324
Cumulative Timesteps: 822,717,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 822717324...
Checkpoint 822717324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,852.21852
Policy Entropy: 1.11383
Value Function Loss: 4.01852

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.12029

Collected Steps per Second: 3,875.89246
Overall Steps per Second: 3,188.12022

Timestep Collection Time: 12.90903
Timestep Consumption Time: 2.78486
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 15.69389

Cumulative Model Updates: 49,327
Cumulative Timesteps: 822,767,358

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,753.68410
Policy Entropy: 1.10224
Value Function Loss: 3.97358

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.15507
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.12061

Collected Steps per Second: 3,972.25328
Overall Steps per Second: 3,246.08680

Timestep Collection Time: 12.59235
Timestep Consumption Time: 2.81697
PPO Batch Consumption Time: 0.05900
Total Iteration Time: 15.40932

Cumulative Model Updates: 49,330
Cumulative Timesteps: 822,817,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 822817378...
Checkpoint 822817378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,558.48654
Policy Entropy: 1.09161
Value Function Loss: 3.96852

Mean KL Divergence: 0.02588
SB3 Clip Fraction: 0.17059
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.10412

Collected Steps per Second: 3,790.99815
Overall Steps per Second: 3,134.39903

Timestep Collection Time: 13.19969
Timestep Consumption Time: 2.76509
PPO Batch Consumption Time: 0.05305
Total Iteration Time: 15.96478

Cumulative Model Updates: 49,333
Cumulative Timesteps: 822,867,418

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,088.78320
Policy Entropy: 1.10056
Value Function Loss: 3.85736

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.10751

Collected Steps per Second: 3,752.32563
Overall Steps per Second: 3,150.03314

Timestep Collection Time: 13.33360
Timestep Consumption Time: 2.54941
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 15.88301

Cumulative Model Updates: 49,336
Cumulative Timesteps: 822,917,450

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 822917450...
Checkpoint 822917450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,283.02707
Policy Entropy: 1.10871
Value Function Loss: 3.81414

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.10932

Collected Steps per Second: 3,759.83451
Overall Steps per Second: 3,113.61731

Timestep Collection Time: 13.30910
Timestep Consumption Time: 2.76224
PPO Batch Consumption Time: 0.06078
Total Iteration Time: 16.07134

Cumulative Model Updates: 49,339
Cumulative Timesteps: 822,967,490

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,809.86600
Policy Entropy: 1.09533
Value Function Loss: 3.93940

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.10795

Collected Steps per Second: 3,771.43991
Overall Steps per Second: 3,128.41306

Timestep Collection Time: 13.25860
Timestep Consumption Time: 2.72523
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 15.98382

Cumulative Model Updates: 49,342
Cumulative Timesteps: 823,017,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 823017494...
Checkpoint 823017494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,489.76729
Policy Entropy: 1.10167
Value Function Loss: 4.04137

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 3,960.94268
Overall Steps per Second: 3,231.46257

Timestep Collection Time: 12.63235
Timestep Consumption Time: 2.85166
PPO Batch Consumption Time: 0.06993
Total Iteration Time: 15.48401

Cumulative Model Updates: 49,345
Cumulative Timesteps: 823,067,530

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,218.86935
Policy Entropy: 1.10780
Value Function Loss: 4.20630

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.11882

Collected Steps per Second: 3,810.02841
Overall Steps per Second: 3,120.35607

Timestep Collection Time: 13.12641
Timestep Consumption Time: 2.90125
PPO Batch Consumption Time: 0.06170
Total Iteration Time: 16.02766

Cumulative Model Updates: 49,348
Cumulative Timesteps: 823,117,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 823117542...
Checkpoint 823117542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,542.51651
Policy Entropy: 1.10856
Value Function Loss: 4.22221

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.16676

Collected Steps per Second: 3,800.10266
Overall Steps per Second: 3,156.57418

Timestep Collection Time: 13.16017
Timestep Consumption Time: 2.68295
PPO Batch Consumption Time: 0.06632
Total Iteration Time: 15.84313

Cumulative Model Updates: 49,351
Cumulative Timesteps: 823,167,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,902.94035
Policy Entropy: 1.10404
Value Function Loss: 4.19963

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.07558
Value Function Update Magnitude: 0.18225

Collected Steps per Second: 3,829.91592
Overall Steps per Second: 3,107.58558

Timestep Collection Time: 13.06608
Timestep Consumption Time: 3.03709
PPO Batch Consumption Time: 0.06074
Total Iteration Time: 16.10318

Cumulative Model Updates: 49,354
Cumulative Timesteps: 823,217,594

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 823217594...
Checkpoint 823217594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,694.73070
Policy Entropy: 1.10664
Value Function Loss: 4.18298

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.07602
Value Function Update Magnitude: 0.15876

Collected Steps per Second: 3,907.51309
Overall Steps per Second: 3,253.80160

Timestep Collection Time: 12.80252
Timestep Consumption Time: 2.57212
PPO Batch Consumption Time: 0.05080
Total Iteration Time: 15.37463

Cumulative Model Updates: 49,357
Cumulative Timesteps: 823,267,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,521.10718
Policy Entropy: 1.10353
Value Function Loss: 3.98979

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.07239
Value Function Update Magnitude: 0.13937

Collected Steps per Second: 3,730.32981
Overall Steps per Second: 3,099.32051

Timestep Collection Time: 13.41329
Timestep Consumption Time: 2.73089
PPO Batch Consumption Time: 0.07067
Total Iteration Time: 16.14418

Cumulative Model Updates: 49,360
Cumulative Timesteps: 823,317,656

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 823317656...
Checkpoint 823317656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,359.42965
Policy Entropy: 1.11043
Value Function Loss: 4.01300

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.11616

Collected Steps per Second: 3,909.43376
Overall Steps per Second: 3,184.71660

Timestep Collection Time: 12.79981
Timestep Consumption Time: 2.91274
PPO Batch Consumption Time: 0.06704
Total Iteration Time: 15.71254

Cumulative Model Updates: 49,363
Cumulative Timesteps: 823,367,696

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,591.77652
Policy Entropy: 1.11074
Value Function Loss: 3.87311

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.06610
Value Function Update Magnitude: 0.10868

Collected Steps per Second: 3,788.86455
Overall Steps per Second: 3,222.07860

Timestep Collection Time: 13.20079
Timestep Consumption Time: 2.32211
PPO Batch Consumption Time: 0.06391
Total Iteration Time: 15.52290

Cumulative Model Updates: 49,366
Cumulative Timesteps: 823,417,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 823417712...
Checkpoint 823417712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,083.98687
Policy Entropy: 1.10840
Value Function Loss: 4.08348

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.07461
Value Function Update Magnitude: 0.09914

Collected Steps per Second: 3,976.43888
Overall Steps per Second: 3,261.49177

Timestep Collection Time: 12.58563
Timestep Consumption Time: 2.75888
PPO Batch Consumption Time: 0.05388
Total Iteration Time: 15.34451

Cumulative Model Updates: 49,369
Cumulative Timesteps: 823,467,758

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,372.67269
Policy Entropy: 1.10932
Value Function Loss: 3.99586

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.07006
Value Function Update Magnitude: 0.09222

Collected Steps per Second: 3,758.44187
Overall Steps per Second: 3,165.67717

Timestep Collection Time: 13.30605
Timestep Consumption Time: 2.49152
PPO Batch Consumption Time: 0.05837
Total Iteration Time: 15.79757

Cumulative Model Updates: 49,372
Cumulative Timesteps: 823,517,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 823517768...
Checkpoint 823517768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,854.75236
Policy Entropy: 1.10604
Value Function Loss: 4.19085

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.07023
Value Function Update Magnitude: 0.08444

Collected Steps per Second: 3,892.16507
Overall Steps per Second: 3,202.22383

Timestep Collection Time: 12.85095
Timestep Consumption Time: 2.76882
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 15.61977

Cumulative Model Updates: 49,375
Cumulative Timesteps: 823,567,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,093.10978
Policy Entropy: 1.12131
Value Function Loss: 4.09585

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.09480

Collected Steps per Second: 3,762.18902
Overall Steps per Second: 3,128.37699

Timestep Collection Time: 13.29014
Timestep Consumption Time: 2.69259
PPO Batch Consumption Time: 0.06285
Total Iteration Time: 15.98273

Cumulative Model Updates: 49,378
Cumulative Timesteps: 823,617,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 823617786...
Checkpoint 823617786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,683.59267
Policy Entropy: 1.12243
Value Function Loss: 4.23141

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.06880
Value Function Update Magnitude: 0.09166

Collected Steps per Second: 3,921.98852
Overall Steps per Second: 3,212.44984

Timestep Collection Time: 12.75475
Timestep Consumption Time: 2.81716
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 15.57192

Cumulative Model Updates: 49,381
Cumulative Timesteps: 823,667,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585,566.84146
Policy Entropy: 1.12111
Value Function Loss: 4.15171

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.16184
Policy Update Magnitude: 0.06920
Value Function Update Magnitude: 0.08394

Collected Steps per Second: 3,756.66535
Overall Steps per Second: 3,106.97638

Timestep Collection Time: 13.31979
Timestep Consumption Time: 2.78526
PPO Batch Consumption Time: 0.06132
Total Iteration Time: 16.10505

Cumulative Model Updates: 49,384
Cumulative Timesteps: 823,717,848

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 823717848...
Checkpoint 823717848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,153.45234
Policy Entropy: 1.11572
Value Function Loss: 4.19758

Mean KL Divergence: 0.02685
SB3 Clip Fraction: 0.17262
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.08277

Collected Steps per Second: 3,866.58075
Overall Steps per Second: 3,205.48377

Timestep Collection Time: 12.93494
Timestep Consumption Time: 2.66769
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 15.60264

Cumulative Model Updates: 49,387
Cumulative Timesteps: 823,767,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,926.50023
Policy Entropy: 1.12650
Value Function Loss: 4.00584

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.07715

Collected Steps per Second: 3,813.22662
Overall Steps per Second: 3,110.36907

Timestep Collection Time: 13.12065
Timestep Consumption Time: 2.96490
PPO Batch Consumption Time: 0.05989
Total Iteration Time: 16.08555

Cumulative Model Updates: 49,390
Cumulative Timesteps: 823,817,894

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 823817894...
Checkpoint 823817894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,088.67891
Policy Entropy: 1.12685
Value Function Loss: 3.89602

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.08575

Collected Steps per Second: 3,779.25582
Overall Steps per Second: 3,183.54218

Timestep Collection Time: 13.24441
Timestep Consumption Time: 2.47833
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 15.72274

Cumulative Model Updates: 49,393
Cumulative Timesteps: 823,867,948

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,688.03353
Policy Entropy: 1.11919
Value Function Loss: 3.83845

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.09545

Collected Steps per Second: 3,781.14601
Overall Steps per Second: 3,104.98826

Timestep Collection Time: 13.23038
Timestep Consumption Time: 2.88111
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 16.11149

Cumulative Model Updates: 49,396
Cumulative Timesteps: 823,917,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 823917974...
Checkpoint 823917974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,779.72157
Policy Entropy: 1.10592
Value Function Loss: 3.90491

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.09033

Collected Steps per Second: 3,777.90191
Overall Steps per Second: 3,128.77899

Timestep Collection Time: 13.24756
Timestep Consumption Time: 2.74845
PPO Batch Consumption Time: 0.06904
Total Iteration Time: 15.99602

Cumulative Model Updates: 49,399
Cumulative Timesteps: 823,968,022

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,499.42502
Policy Entropy: 1.11660
Value Function Loss: 4.09341

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.08664

Collected Steps per Second: 3,886.14729
Overall Steps per Second: 3,259.62519

Timestep Collection Time: 12.87239
Timestep Consumption Time: 2.47416
PPO Batch Consumption Time: 0.05985
Total Iteration Time: 15.34655

Cumulative Model Updates: 49,402
Cumulative Timesteps: 824,018,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 824018046...
Checkpoint 824018046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,855.30269
Policy Entropy: 1.11902
Value Function Loss: 4.06565

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.09372

Collected Steps per Second: 3,842.44786
Overall Steps per Second: 3,207.03382

Timestep Collection Time: 13.01254
Timestep Consumption Time: 2.57819
PPO Batch Consumption Time: 0.06107
Total Iteration Time: 15.59073

Cumulative Model Updates: 49,405
Cumulative Timesteps: 824,068,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,560.43034
Policy Entropy: 1.10491
Value Function Loss: 4.08237

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.08649

Collected Steps per Second: 3,835.05600
Overall Steps per Second: 3,201.51948

Timestep Collection Time: 13.04075
Timestep Consumption Time: 2.58058
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 15.62133

Cumulative Model Updates: 49,408
Cumulative Timesteps: 824,118,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 824118058...
Checkpoint 824118058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,954.11490
Policy Entropy: 1.09047
Value Function Loss: 3.97321

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.17763
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.08485

Collected Steps per Second: 3,857.47673
Overall Steps per Second: 3,182.19881

Timestep Collection Time: 12.97377
Timestep Consumption Time: 2.75310
PPO Batch Consumption Time: 0.05434
Total Iteration Time: 15.72686

Cumulative Model Updates: 49,411
Cumulative Timesteps: 824,168,104

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,333.83034
Policy Entropy: 1.11220
Value Function Loss: 4.21757

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.09580

Collected Steps per Second: 3,874.10152
Overall Steps per Second: 3,201.47340

Timestep Collection Time: 12.91241
Timestep Consumption Time: 2.71289
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 15.62531

Cumulative Model Updates: 49,414
Cumulative Timesteps: 824,218,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 824218128...
Checkpoint 824218128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,701.38849
Policy Entropy: 1.11490
Value Function Loss: 4.27494

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.09628

Collected Steps per Second: 3,952.20819
Overall Steps per Second: 3,246.34602

Timestep Collection Time: 12.65773
Timestep Consumption Time: 2.75221
PPO Batch Consumption Time: 0.05949
Total Iteration Time: 15.40994

Cumulative Model Updates: 49,417
Cumulative Timesteps: 824,268,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,825.86048
Policy Entropy: 1.10367
Value Function Loss: 4.31931

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.09781

Collected Steps per Second: 3,913.14495
Overall Steps per Second: 3,189.66194

Timestep Collection Time: 12.78307
Timestep Consumption Time: 2.89947
PPO Batch Consumption Time: 0.06325
Total Iteration Time: 15.68254

Cumulative Model Updates: 49,420
Cumulative Timesteps: 824,318,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 824318176...
Checkpoint 824318176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758,457.25602
Policy Entropy: 1.08961
Value Function Loss: 4.22568

Mean KL Divergence: 0.02844
SB3 Clip Fraction: 0.18847
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.08971

Collected Steps per Second: 3,720.63258
Overall Steps per Second: 3,137.94137

Timestep Collection Time: 13.44234
Timestep Consumption Time: 2.49614
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 15.93848

Cumulative Model Updates: 49,423
Cumulative Timesteps: 824,368,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,611.55845
Policy Entropy: 1.09648
Value Function Loss: 4.29134

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.12144
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.09480

Collected Steps per Second: 3,949.47618
Overall Steps per Second: 3,212.66682

Timestep Collection Time: 12.66041
Timestep Consumption Time: 2.90360
PPO Batch Consumption Time: 0.06151
Total Iteration Time: 15.56402

Cumulative Model Updates: 49,426
Cumulative Timesteps: 824,418,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 824418192...
Checkpoint 824418192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,734.25315
Policy Entropy: 1.10658
Value Function Loss: 4.29583

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.09833

Collected Steps per Second: 3,865.22898
Overall Steps per Second: 3,224.82291

Timestep Collection Time: 12.93843
Timestep Consumption Time: 2.56940
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 15.50783

Cumulative Model Updates: 49,429
Cumulative Timesteps: 824,468,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,521.41586
Policy Entropy: 1.09067
Value Function Loss: 4.23053

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.10869

Collected Steps per Second: 3,913.03621
Overall Steps per Second: 3,180.59855

Timestep Collection Time: 12.79007
Timestep Consumption Time: 2.94533
PPO Batch Consumption Time: 0.05375
Total Iteration Time: 15.73540

Cumulative Model Updates: 49,432
Cumulative Timesteps: 824,518,250

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 824518250...
Checkpoint 824518250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,354.03447
Policy Entropy: 1.10045
Value Function Loss: 4.14848

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.10388

Collected Steps per Second: 4,009.81203
Overall Steps per Second: 3,261.02057

Timestep Collection Time: 12.47839
Timestep Consumption Time: 2.86527
PPO Batch Consumption Time: 0.07176
Total Iteration Time: 15.34366

Cumulative Model Updates: 49,435
Cumulative Timesteps: 824,568,286

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,359.21292
Policy Entropy: 1.11160
Value Function Loss: 4.06766

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.10472

Collected Steps per Second: 4,183.65075
Overall Steps per Second: 3,295.06582

Timestep Collection Time: 11.95128
Timestep Consumption Time: 3.22292
PPO Batch Consumption Time: 0.06413
Total Iteration Time: 15.17420

Cumulative Model Updates: 49,438
Cumulative Timesteps: 824,618,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 824618286...
Checkpoint 824618286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,219.31605
Policy Entropy: 1.11216
Value Function Loss: 4.03312

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.11015

Collected Steps per Second: 4,008.59634
Overall Steps per Second: 3,243.32901

Timestep Collection Time: 12.48317
Timestep Consumption Time: 2.94542
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 15.42859

Cumulative Model Updates: 49,441
Cumulative Timesteps: 824,668,326

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,234.64136
Policy Entropy: 1.11097
Value Function Loss: 4.02842

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.07065
Value Function Update Magnitude: 0.09709

Collected Steps per Second: 4,051.14798
Overall Steps per Second: 3,369.09837

Timestep Collection Time: 12.34959
Timestep Consumption Time: 2.50008
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 14.84967

Cumulative Model Updates: 49,444
Cumulative Timesteps: 824,718,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 824718356...
Checkpoint 824718356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,000.44030
Policy Entropy: 1.11002
Value Function Loss: 4.17079

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.07421
Value Function Update Magnitude: 0.09069

Collected Steps per Second: 3,839.17152
Overall Steps per Second: 3,115.85483

Timestep Collection Time: 13.02625
Timestep Consumption Time: 3.02392
PPO Batch Consumption Time: 0.06237
Total Iteration Time: 16.05017

Cumulative Model Updates: 49,447
Cumulative Timesteps: 824,768,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,565.40372
Policy Entropy: 1.10724
Value Function Loss: 4.19100

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.11898
Policy Update Magnitude: 0.07749
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 3,906.05668
Overall Steps per Second: 3,205.09114

Timestep Collection Time: 12.80883
Timestep Consumption Time: 2.80134
PPO Batch Consumption Time: 0.07099
Total Iteration Time: 15.61016

Cumulative Model Updates: 49,450
Cumulative Timesteps: 824,818,398

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 824818398...
Checkpoint 824818398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,785.14498
Policy Entropy: 1.10173
Value Function Loss: 4.30616

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.07264
Value Function Update Magnitude: 0.08240

Collected Steps per Second: 3,941.08685
Overall Steps per Second: 3,215.34941

Timestep Collection Time: 12.69599
Timestep Consumption Time: 2.86562
PPO Batch Consumption Time: 0.06005
Total Iteration Time: 15.56161

Cumulative Model Updates: 49,453
Cumulative Timesteps: 824,868,434

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,896.93249
Policy Entropy: 1.11072
Value Function Loss: 4.29725

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.08054

Collected Steps per Second: 3,950.40069
Overall Steps per Second: 3,238.11958

Timestep Collection Time: 12.66201
Timestep Consumption Time: 2.78523
PPO Batch Consumption Time: 0.06217
Total Iteration Time: 15.44724

Cumulative Model Updates: 49,456
Cumulative Timesteps: 824,918,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 824918454...
Checkpoint 824918454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,440.88528
Policy Entropy: 1.11503
Value Function Loss: 4.39862

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.17159
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.08055

Collected Steps per Second: 3,805.46123
Overall Steps per Second: 3,206.96271

Timestep Collection Time: 13.14847
Timestep Consumption Time: 2.45383
PPO Batch Consumption Time: 0.05271
Total Iteration Time: 15.60230

Cumulative Model Updates: 49,459
Cumulative Timesteps: 824,968,490

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,397.22556
Policy Entropy: 1.09080
Value Function Loss: 4.39945

Mean KL Divergence: 0.04263
SB3 Clip Fraction: 0.20759
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.07067

Collected Steps per Second: 3,755.46499
Overall Steps per Second: 3,108.16959

Timestep Collection Time: 13.32671
Timestep Consumption Time: 2.77537
PPO Batch Consumption Time: 0.05176
Total Iteration Time: 16.10208

Cumulative Model Updates: 49,462
Cumulative Timesteps: 825,018,538

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 825018538...
Checkpoint 825018538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,216.58907
Policy Entropy: 1.11133
Value Function Loss: 4.29908

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.07063

Collected Steps per Second: 3,814.04041
Overall Steps per Second: 3,209.21500

Timestep Collection Time: 13.11051
Timestep Consumption Time: 2.47087
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 15.58138

Cumulative Model Updates: 49,465
Cumulative Timesteps: 825,068,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551,163.98496
Policy Entropy: 1.10722
Value Function Loss: 4.09911

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.06342

Collected Steps per Second: 3,860.92552
Overall Steps per Second: 3,171.17513

Timestep Collection Time: 12.95700
Timestep Consumption Time: 2.81823
PPO Batch Consumption Time: 0.06306
Total Iteration Time: 15.77522

Cumulative Model Updates: 49,468
Cumulative Timesteps: 825,118,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 825118568...
Checkpoint 825118568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699,925.21982
Policy Entropy: 1.09475
Value Function Loss: 3.85583

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.06402

Collected Steps per Second: 3,876.89700
Overall Steps per Second: 3,180.01989

Timestep Collection Time: 12.90259
Timestep Consumption Time: 2.82750
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 15.73009

Cumulative Model Updates: 49,471
Cumulative Timesteps: 825,168,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,332.12941
Policy Entropy: 1.09687
Value Function Loss: 3.94655

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.07057

Collected Steps per Second: 3,928.86657
Overall Steps per Second: 3,220.74571

Timestep Collection Time: 12.73752
Timestep Consumption Time: 2.80050
PPO Batch Consumption Time: 0.05126
Total Iteration Time: 15.53802

Cumulative Model Updates: 49,474
Cumulative Timesteps: 825,218,634

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 825218634...
Checkpoint 825218634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,232.29297
Policy Entropy: 1.10510
Value Function Loss: 4.00297

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.07829

Collected Steps per Second: 3,930.24906
Overall Steps per Second: 3,158.62386

Timestep Collection Time: 12.73100
Timestep Consumption Time: 3.11008
PPO Batch Consumption Time: 0.06240
Total Iteration Time: 15.84108

Cumulative Model Updates: 49,477
Cumulative Timesteps: 825,268,670

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714,608.27128
Policy Entropy: 1.10511
Value Function Loss: 4.11728

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.08138

Collected Steps per Second: 3,806.81648
Overall Steps per Second: 3,178.48318

Timestep Collection Time: 13.14274
Timestep Consumption Time: 2.59810
PPO Batch Consumption Time: 0.06126
Total Iteration Time: 15.74084

Cumulative Model Updates: 49,480
Cumulative Timesteps: 825,318,702

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 825318702...
Checkpoint 825318702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,813.11677
Policy Entropy: 1.09961
Value Function Loss: 3.95033

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.09153

Collected Steps per Second: 3,922.61833
Overall Steps per Second: 3,198.38373

Timestep Collection Time: 12.75577
Timestep Consumption Time: 2.88839
PPO Batch Consumption Time: 0.06144
Total Iteration Time: 15.64415

Cumulative Model Updates: 49,483
Cumulative Timesteps: 825,368,738

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,925.07831
Policy Entropy: 1.08302
Value Function Loss: 3.99277

Mean KL Divergence: 0.03841
SB3 Clip Fraction: 0.20435
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.10421

Collected Steps per Second: 3,774.12625
Overall Steps per Second: 3,122.17304

Timestep Collection Time: 13.25976
Timestep Consumption Time: 2.76882
PPO Batch Consumption Time: 0.05986
Total Iteration Time: 16.02858

Cumulative Model Updates: 49,486
Cumulative Timesteps: 825,418,782

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 825418782...
Checkpoint 825418782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,928.00400
Policy Entropy: 1.11612
Value Function Loss: 4.00471

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.19093
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.11489

Collected Steps per Second: 3,861.46579
Overall Steps per Second: 3,219.08919

Timestep Collection Time: 12.95570
Timestep Consumption Time: 2.58534
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 15.54104

Cumulative Model Updates: 49,489
Cumulative Timesteps: 825,468,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,534.35177
Policy Entropy: 1.09211
Value Function Loss: 3.97879

Mean KL Divergence: 0.02972
SB3 Clip Fraction: 0.19086
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.10581

Collected Steps per Second: 3,837.19796
Overall Steps per Second: 3,152.44401

Timestep Collection Time: 13.03555
Timestep Consumption Time: 2.83150
PPO Batch Consumption Time: 0.06795
Total Iteration Time: 15.86705

Cumulative Model Updates: 49,492
Cumulative Timesteps: 825,518,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 825518830...
Checkpoint 825518830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618,508.72822
Policy Entropy: 1.10176
Value Function Loss: 4.01818

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.09740

Collected Steps per Second: 3,844.22626
Overall Steps per Second: 3,213.91978

Timestep Collection Time: 13.01328
Timestep Consumption Time: 2.55213
PPO Batch Consumption Time: 0.06107
Total Iteration Time: 15.56542

Cumulative Model Updates: 49,495
Cumulative Timesteps: 825,568,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,637.31173
Policy Entropy: 1.10383
Value Function Loss: 4.00072

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.08921

Collected Steps per Second: 3,744.72260
Overall Steps per Second: 3,091.70137

Timestep Collection Time: 13.35853
Timestep Consumption Time: 2.82155
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 16.18009

Cumulative Model Updates: 49,498
Cumulative Timesteps: 825,618,880

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 825618880...
Checkpoint 825618880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,939.14153
Policy Entropy: 1.08945
Value Function Loss: 4.02733

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.08711

Collected Steps per Second: 3,875.68820
Overall Steps per Second: 3,198.25539

Timestep Collection Time: 12.90661
Timestep Consumption Time: 2.73379
PPO Batch Consumption Time: 0.06039
Total Iteration Time: 15.64040

Cumulative Model Updates: 49,501
Cumulative Timesteps: 825,668,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,388.06404
Policy Entropy: 1.08490
Value Function Loss: 3.83146

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.09371

Collected Steps per Second: 3,910.71990
Overall Steps per Second: 3,147.55822

Timestep Collection Time: 12.78588
Timestep Consumption Time: 3.10008
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 15.88597

Cumulative Model Updates: 49,504
Cumulative Timesteps: 825,718,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 825718904...
Checkpoint 825718904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,080.43879
Policy Entropy: 1.10483
Value Function Loss: 3.88698

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.08996

Collected Steps per Second: 3,870.46458
Overall Steps per Second: 3,169.54680

Timestep Collection Time: 12.92093
Timestep Consumption Time: 2.85735
PPO Batch Consumption Time: 0.06857
Total Iteration Time: 15.77828

Cumulative Model Updates: 49,507
Cumulative Timesteps: 825,768,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,145.21464
Policy Entropy: 1.10767
Value Function Loss: 3.99082

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.10059

Collected Steps per Second: 3,763.13523
Overall Steps per Second: 3,154.25160

Timestep Collection Time: 13.29636
Timestep Consumption Time: 2.56667
PPO Batch Consumption Time: 0.06147
Total Iteration Time: 15.86303

Cumulative Model Updates: 49,510
Cumulative Timesteps: 825,818,950

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 825818950...
Checkpoint 825818950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,101.88676
Policy Entropy: 1.10129
Value Function Loss: 4.02269

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.10197

Collected Steps per Second: 3,851.52674
Overall Steps per Second: 3,160.32689

Timestep Collection Time: 12.98913
Timestep Consumption Time: 2.84087
PPO Batch Consumption Time: 0.05856
Total Iteration Time: 15.83001

Cumulative Model Updates: 49,513
Cumulative Timesteps: 825,868,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730,821.65212
Policy Entropy: 1.08322
Value Function Loss: 4.00586

Mean KL Divergence: 0.02700
SB3 Clip Fraction: 0.17777
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.09486

Collected Steps per Second: 3,814.45832
Overall Steps per Second: 3,213.17877

Timestep Collection Time: 13.12165
Timestep Consumption Time: 2.45544
PPO Batch Consumption Time: 0.05239
Total Iteration Time: 15.57710

Cumulative Model Updates: 49,516
Cumulative Timesteps: 825,919,030

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 825919030...
Checkpoint 825919030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,763.74841
Policy Entropy: 1.10062
Value Function Loss: 4.04347

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.08700

Collected Steps per Second: 3,854.89203
Overall Steps per Second: 3,189.71180

Timestep Collection Time: 12.98091
Timestep Consumption Time: 2.70703
PPO Batch Consumption Time: 0.05892
Total Iteration Time: 15.68794

Cumulative Model Updates: 49,519
Cumulative Timesteps: 825,969,070

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,765.64906
Policy Entropy: 1.08775
Value Function Loss: 4.12031

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.08225

Collected Steps per Second: 3,859.60048
Overall Steps per Second: 3,208.90113

Timestep Collection Time: 12.95626
Timestep Consumption Time: 2.62726
PPO Batch Consumption Time: 0.05874
Total Iteration Time: 15.58353

Cumulative Model Updates: 49,522
Cumulative Timesteps: 826,019,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 826019076...
Checkpoint 826019076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,048.98795
Policy Entropy: 1.08339
Value Function Loss: 4.04840

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 3,900.47463
Overall Steps per Second: 3,210.87532

Timestep Collection Time: 12.81947
Timestep Consumption Time: 2.75324
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 15.57270

Cumulative Model Updates: 49,525
Cumulative Timesteps: 826,069,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,602.91321
Policy Entropy: 1.09245
Value Function Loss: 4.03250

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.07640

Collected Steps per Second: 3,810.53012
Overall Steps per Second: 3,165.03618

Timestep Collection Time: 13.13046
Timestep Consumption Time: 2.67789
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 15.80835

Cumulative Model Updates: 49,528
Cumulative Timesteps: 826,119,112

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 826119112...
Checkpoint 826119112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,435.14808
Policy Entropy: 1.10183
Value Function Loss: 4.04048

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.15858
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.10635

Collected Steps per Second: 3,830.50989
Overall Steps per Second: 3,211.23151

Timestep Collection Time: 13.06145
Timestep Consumption Time: 2.51887
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 15.58032

Cumulative Model Updates: 49,531
Cumulative Timesteps: 826,169,144

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612,570.62247
Policy Entropy: 1.07594
Value Function Loss: 4.18484

Mean KL Divergence: 0.03254
SB3 Clip Fraction: 0.18131
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.11767

Collected Steps per Second: 3,830.74484
Overall Steps per Second: 3,090.59689

Timestep Collection Time: 13.05542
Timestep Consumption Time: 3.12656
PPO Batch Consumption Time: 0.06245
Total Iteration Time: 16.18199

Cumulative Model Updates: 49,534
Cumulative Timesteps: 826,219,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 826219156...
Checkpoint 826219156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,456.30103
Policy Entropy: 1.09692
Value Function Loss: 4.19343

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.15855
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.11336

Collected Steps per Second: 3,819.49677
Overall Steps per Second: 3,147.66967

Timestep Collection Time: 13.09701
Timestep Consumption Time: 2.79538
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 15.89239

Cumulative Model Updates: 49,537
Cumulative Timesteps: 826,269,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,799.16875
Policy Entropy: 1.09052
Value Function Loss: 4.15592

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.10814

Collected Steps per Second: 4,045.25213
Overall Steps per Second: 3,290.06343

Timestep Collection Time: 12.36610
Timestep Consumption Time: 2.83847
PPO Batch Consumption Time: 0.06225
Total Iteration Time: 15.20457

Cumulative Model Updates: 49,540
Cumulative Timesteps: 826,319,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 826319204...
Checkpoint 826319204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,993.60883
Policy Entropy: 1.08003
Value Function Loss: 4.13515

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 3,829.03842
Overall Steps per Second: 3,165.98710

Timestep Collection Time: 13.05968
Timestep Consumption Time: 2.73508
PPO Batch Consumption Time: 0.07215
Total Iteration Time: 15.79476

Cumulative Model Updates: 49,543
Cumulative Timesteps: 826,369,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,876.69644
Policy Entropy: 1.08743
Value Function Loss: 4.11777

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.10032

Collected Steps per Second: 3,832.34173
Overall Steps per Second: 3,203.38873

Timestep Collection Time: 13.04738
Timestep Consumption Time: 2.56172
PPO Batch Consumption Time: 0.06295
Total Iteration Time: 15.60910

Cumulative Model Updates: 49,546
Cumulative Timesteps: 826,419,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 826419212...
Checkpoint 826419212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,755.44196
Policy Entropy: 1.09762
Value Function Loss: 4.09120

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.11566
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.10001

Collected Steps per Second: 3,854.89722
Overall Steps per Second: 3,185.17153

Timestep Collection Time: 12.97467
Timestep Consumption Time: 2.72810
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 15.70277

Cumulative Model Updates: 49,549
Cumulative Timesteps: 826,469,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,658.48397
Policy Entropy: 1.10644
Value Function Loss: 4.11278

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11563
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.09570

Collected Steps per Second: 3,826.38371
Overall Steps per Second: 3,173.38834

Timestep Collection Time: 13.07971
Timestep Consumption Time: 2.69144
PPO Batch Consumption Time: 0.06924
Total Iteration Time: 15.77116

Cumulative Model Updates: 49,552
Cumulative Timesteps: 826,519,276

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 826519276...
Checkpoint 826519276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,080.77348
Policy Entropy: 1.09572
Value Function Loss: 4.06713

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.06451
Value Function Update Magnitude: 0.09607

Collected Steps per Second: 3,869.88377
Overall Steps per Second: 3,182.73534

Timestep Collection Time: 12.93527
Timestep Consumption Time: 2.79271
PPO Batch Consumption Time: 0.06115
Total Iteration Time: 15.72798

Cumulative Model Updates: 49,555
Cumulative Timesteps: 826,569,334

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,215.23398
Policy Entropy: 1.08446
Value Function Loss: 4.13733

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 0.06452
Value Function Update Magnitude: 0.10087

Collected Steps per Second: 3,849.05546
Overall Steps per Second: 3,201.03795

Timestep Collection Time: 13.00007
Timestep Consumption Time: 2.63173
PPO Batch Consumption Time: 0.06193
Total Iteration Time: 15.63180

Cumulative Model Updates: 49,558
Cumulative Timesteps: 826,619,372

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 826619372...
Checkpoint 826619372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,286.44776
Policy Entropy: 1.09623
Value Function Loss: 4.01626

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.09158

Collected Steps per Second: 3,687.15634
Overall Steps per Second: 3,115.21156

Timestep Collection Time: 13.56655
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 16.05734

Cumulative Model Updates: 49,561
Cumulative Timesteps: 826,669,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,948.24386
Policy Entropy: 1.09705
Value Function Loss: 4.19271

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.15351
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.08789

Collected Steps per Second: 3,893.01108
Overall Steps per Second: 3,193.29581

Timestep Collection Time: 12.85072
Timestep Consumption Time: 2.81585
PPO Batch Consumption Time: 0.05298
Total Iteration Time: 15.66657

Cumulative Model Updates: 49,564
Cumulative Timesteps: 826,719,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 826719422...
Checkpoint 826719422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,655.56218
Policy Entropy: 1.08506
Value Function Loss: 4.14866

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.09049

Collected Steps per Second: 3,819.29353
Overall Steps per Second: 3,147.52451

Timestep Collection Time: 13.09352
Timestep Consumption Time: 2.79452
PPO Batch Consumption Time: 0.06340
Total Iteration Time: 15.88804

Cumulative Model Updates: 49,567
Cumulative Timesteps: 826,769,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,605.28564
Policy Entropy: 1.06685
Value Function Loss: 4.14275

Mean KL Divergence: 0.02656
SB3 Clip Fraction: 0.17022
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.09832

Collected Steps per Second: 3,950.69290
Overall Steps per Second: 3,236.71831

Timestep Collection Time: 12.65651
Timestep Consumption Time: 2.79185
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 15.44836

Cumulative Model Updates: 49,570
Cumulative Timesteps: 826,819,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 826819432...
Checkpoint 826819432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,028.21930
Policy Entropy: 1.08740
Value Function Loss: 3.88620

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.09652

Collected Steps per Second: 3,786.12589
Overall Steps per Second: 3,093.07977

Timestep Collection Time: 13.20822
Timestep Consumption Time: 2.95948
PPO Batch Consumption Time: 0.05278
Total Iteration Time: 16.16770

Cumulative Model Updates: 49,573
Cumulative Timesteps: 826,869,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,418.56237
Policy Entropy: 1.08099
Value Function Loss: 4.08265

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.08978

Collected Steps per Second: 3,806.67976
Overall Steps per Second: 3,186.74465

Timestep Collection Time: 13.13953
Timestep Consumption Time: 2.55611
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 15.69564

Cumulative Model Updates: 49,576
Cumulative Timesteps: 826,919,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 826919458...
Checkpoint 826919458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,922.15838
Policy Entropy: 1.07084
Value Function Loss: 4.20125

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.08572

Collected Steps per Second: 3,788.59165
Overall Steps per Second: 3,169.16746

Timestep Collection Time: 13.20491
Timestep Consumption Time: 2.58094
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 15.78585

Cumulative Model Updates: 49,579
Cumulative Timesteps: 826,969,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,492.49894
Policy Entropy: 1.09032
Value Function Loss: 4.37064

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.08560

Collected Steps per Second: 3,752.59542
Overall Steps per Second: 3,108.67871

Timestep Collection Time: 13.33530
Timestep Consumption Time: 2.76221
PPO Batch Consumption Time: 0.06212
Total Iteration Time: 16.09751

Cumulative Model Updates: 49,582
Cumulative Timesteps: 827,019,528

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 827019528...
Checkpoint 827019528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,552.66639
Policy Entropy: 1.09293
Value Function Loss: 4.28541

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.08039

Collected Steps per Second: 3,897.45488
Overall Steps per Second: 3,247.44995

Timestep Collection Time: 12.83350
Timestep Consumption Time: 2.56874
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 15.40224

Cumulative Model Updates: 49,585
Cumulative Timesteps: 827,069,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,743.74452
Policy Entropy: 1.07423
Value Function Loss: 4.22806

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.08315

Collected Steps per Second: 3,768.49492
Overall Steps per Second: 3,092.00266

Timestep Collection Time: 13.27586
Timestep Consumption Time: 2.90459
PPO Batch Consumption Time: 0.05915
Total Iteration Time: 16.18045

Cumulative Model Updates: 49,588
Cumulative Timesteps: 827,119,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 827119576...
Checkpoint 827119576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,113.18580
Policy Entropy: 1.06825
Value Function Loss: 4.35228

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.15121
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.07877

Collected Steps per Second: 3,872.08974
Overall Steps per Second: 3,149.94603

Timestep Collection Time: 12.92016
Timestep Consumption Time: 2.96202
PPO Batch Consumption Time: 0.06303
Total Iteration Time: 15.88218

Cumulative Model Updates: 49,591
Cumulative Timesteps: 827,169,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,301.88244
Policy Entropy: 1.07638
Value Function Loss: 4.36056

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 3,707.00511
Overall Steps per Second: 3,078.05006

Timestep Collection Time: 13.50200
Timestep Consumption Time: 2.75894
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 16.26094

Cumulative Model Updates: 49,594
Cumulative Timesteps: 827,219,656

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 827219656...
Checkpoint 827219656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,449.29042
Policy Entropy: 1.07911
Value Function Loss: 4.34603

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.04425
Value Function Update Magnitude: 0.06513

Collected Steps per Second: 3,884.01577
Overall Steps per Second: 3,197.47308

Timestep Collection Time: 12.88306
Timestep Consumption Time: 2.76617
PPO Batch Consumption Time: 0.06606
Total Iteration Time: 15.64923

Cumulative Model Updates: 49,597
Cumulative Timesteps: 827,269,694

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,146.12047
Policy Entropy: 1.05974
Value Function Loss: 4.31353

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.06352
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 3,749.17038
Overall Steps per Second: 3,145.35883

Timestep Collection Time: 13.34215
Timestep Consumption Time: 2.56128
PPO Batch Consumption Time: 0.06120
Total Iteration Time: 15.90343

Cumulative Model Updates: 49,600
Cumulative Timesteps: 827,319,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 827319716...
Checkpoint 827319716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,334.52207
Policy Entropy: 1.07806
Value Function Loss: 4.26684

Mean KL Divergence: 0.02431
SB3 Clip Fraction: 0.16018
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.07703

Collected Steps per Second: 3,807.60828
Overall Steps per Second: 3,137.18386

Timestep Collection Time: 13.13896
Timestep Consumption Time: 2.80783
PPO Batch Consumption Time: 0.06172
Total Iteration Time: 15.94679

Cumulative Model Updates: 49,603
Cumulative Timesteps: 827,369,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,093.12339
Policy Entropy: 1.08036
Value Function Loss: 4.19200

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.16460
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.08218

Collected Steps per Second: 3,769.75460
Overall Steps per Second: 3,192.45244

Timestep Collection Time: 13.27407
Timestep Consumption Time: 2.40040
PPO Batch Consumption Time: 0.05256
Total Iteration Time: 15.67447

Cumulative Model Updates: 49,606
Cumulative Timesteps: 827,419,784

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 827419784...
Checkpoint 827419784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,652.05146
Policy Entropy: 1.06636
Value Function Loss: 4.03012

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.08249

Collected Steps per Second: 3,922.97714
Overall Steps per Second: 3,230.68175

Timestep Collection Time: 12.75052
Timestep Consumption Time: 2.73228
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 15.48280

Cumulative Model Updates: 49,609
Cumulative Timesteps: 827,469,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,552.24087
Policy Entropy: 1.05875
Value Function Loss: 4.05914

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.17654
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.07941

Collected Steps per Second: 3,818.07071
Overall Steps per Second: 3,135.02312

Timestep Collection Time: 13.10243
Timestep Consumption Time: 2.85471
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 15.95714

Cumulative Model Updates: 49,612
Cumulative Timesteps: 827,519,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 827519830...
Checkpoint 827519830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,595.03596
Policy Entropy: 1.06733
Value Function Loss: 4.06052

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.09071

Collected Steps per Second: 3,926.27017
Overall Steps per Second: 3,215.82181

Timestep Collection Time: 12.73983
Timestep Consumption Time: 2.81452
PPO Batch Consumption Time: 0.06065
Total Iteration Time: 15.55434

Cumulative Model Updates: 49,615
Cumulative Timesteps: 827,569,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,798.74103
Policy Entropy: 1.08469
Value Function Loss: 4.11939

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.16339
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.08766

Collected Steps per Second: 3,789.71493
Overall Steps per Second: 3,106.72268

Timestep Collection Time: 13.19572
Timestep Consumption Time: 2.90099
PPO Batch Consumption Time: 0.05956
Total Iteration Time: 16.09671

Cumulative Model Updates: 49,618
Cumulative Timesteps: 827,619,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 827619858...
Checkpoint 827619858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,088.85073
Policy Entropy: 1.05125
Value Function Loss: 4.04324

Mean KL Divergence: 0.03380
SB3 Clip Fraction: 0.19244
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.08824

Collected Steps per Second: 3,940.94550
Overall Steps per Second: 3,274.33552

Timestep Collection Time: 12.70000
Timestep Consumption Time: 2.58555
PPO Batch Consumption Time: 0.06402
Total Iteration Time: 15.28554

Cumulative Model Updates: 49,621
Cumulative Timesteps: 827,669,908

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,291.60822
Policy Entropy: 1.07182
Value Function Loss: 3.91982

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.15928
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.08815

Collected Steps per Second: 3,729.72875
Overall Steps per Second: 3,086.41478

Timestep Collection Time: 13.41063
Timestep Consumption Time: 2.79523
PPO Batch Consumption Time: 0.04987
Total Iteration Time: 16.20586

Cumulative Model Updates: 49,624
Cumulative Timesteps: 827,719,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 827719926...
Checkpoint 827719926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,611.64324
Policy Entropy: 1.06347
Value Function Loss: 3.89023

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.09401

Collected Steps per Second: 3,871.66417
Overall Steps per Second: 3,258.12126

Timestep Collection Time: 12.91538
Timestep Consumption Time: 2.43212
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 15.34750

Cumulative Model Updates: 49,627
Cumulative Timesteps: 827,769,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,483.29670
Policy Entropy: 1.05774
Value Function Loss: 4.03249

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.09713

Collected Steps per Second: 3,718.75651
Overall Steps per Second: 3,131.07243

Timestep Collection Time: 13.45288
Timestep Consumption Time: 2.52503
PPO Batch Consumption Time: 0.05766
Total Iteration Time: 15.97791

Cumulative Model Updates: 49,630
Cumulative Timesteps: 827,819,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 827819958...
Checkpoint 827819958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,861.96316
Policy Entropy: 1.07885
Value Function Loss: 4.03706

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.16251
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.10476

Collected Steps per Second: 3,864.44227
Overall Steps per Second: 3,185.08465

Timestep Collection Time: 12.94572
Timestep Consumption Time: 2.76124
PPO Batch Consumption Time: 0.06440
Total Iteration Time: 15.70696

Cumulative Model Updates: 49,633
Cumulative Timesteps: 827,869,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,889.88603
Policy Entropy: 1.07518
Value Function Loss: 4.10682

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 3,885.60161
Overall Steps per Second: 3,190.98459

Timestep Collection Time: 12.87265
Timestep Consumption Time: 2.80213
PPO Batch Consumption Time: 0.05997
Total Iteration Time: 15.67479

Cumulative Model Updates: 49,636
Cumulative Timesteps: 827,920,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 827920004...
Checkpoint 827920004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,782.69175
Policy Entropy: 1.06060
Value Function Loss: 3.97138

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.09179

Collected Steps per Second: 3,891.93964
Overall Steps per Second: 3,201.46245

Timestep Collection Time: 12.84758
Timestep Consumption Time: 2.77091
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 15.61849

Cumulative Model Updates: 49,639
Cumulative Timesteps: 827,970,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,167.31433
Policy Entropy: 1.05733
Value Function Loss: 3.99901

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15334
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.08046

Collected Steps per Second: 3,937.30586
Overall Steps per Second: 3,174.84692

Timestep Collection Time: 12.70463
Timestep Consumption Time: 3.05109
PPO Batch Consumption Time: 0.06228
Total Iteration Time: 15.75572

Cumulative Model Updates: 49,642
Cumulative Timesteps: 828,020,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 828020028...
Checkpoint 828020028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,658.18406
Policy Entropy: 1.06006
Value Function Loss: 3.97476

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.08290

Collected Steps per Second: 3,703.46106
Overall Steps per Second: 3,077.54928

Timestep Collection Time: 13.51169
Timestep Consumption Time: 2.74801
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 16.25969

Cumulative Model Updates: 49,645
Cumulative Timesteps: 828,070,068

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,231.88077
Policy Entropy: 1.07178
Value Function Loss: 3.94567

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.15243
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.07548

Collected Steps per Second: 3,748.81661
Overall Steps per Second: 3,163.12347

Timestep Collection Time: 13.34928
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.06223
Total Iteration Time: 15.82107

Cumulative Model Updates: 49,648
Cumulative Timesteps: 828,120,112

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 828120112...
Checkpoint 828120112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,863.26240
Policy Entropy: 1.04836
Value Function Loss: 3.93690

Mean KL Divergence: 0.02327
SB3 Clip Fraction: 0.15858
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.06681

Collected Steps per Second: 3,754.63547
Overall Steps per Second: 3,110.82783

Timestep Collection Time: 13.32380
Timestep Consumption Time: 2.75745
PPO Batch Consumption Time: 0.05943
Total Iteration Time: 16.08125

Cumulative Model Updates: 49,651
Cumulative Timesteps: 828,170,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,926.60411
Policy Entropy: 1.06957
Value Function Loss: 3.96280

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.15292
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.06339

Collected Steps per Second: 3,904.91675
Overall Steps per Second: 3,241.28112

Timestep Collection Time: 12.80796
Timestep Consumption Time: 2.62236
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 15.43032

Cumulative Model Updates: 49,654
Cumulative Timesteps: 828,220,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 828220152...
Checkpoint 828220152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,709.41748
Policy Entropy: 1.07045
Value Function Loss: 4.06913

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.05722

Collected Steps per Second: 3,899.14899
Overall Steps per Second: 3,198.73094

Timestep Collection Time: 12.82844
Timestep Consumption Time: 2.80901
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 15.63745

Cumulative Model Updates: 49,657
Cumulative Timesteps: 828,270,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,882.75258
Policy Entropy: 1.05516
Value Function Loss: 4.15685

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.05381

Collected Steps per Second: 3,872.72725
Overall Steps per Second: 3,213.71447

Timestep Collection Time: 12.91545
Timestep Consumption Time: 2.64848
PPO Batch Consumption Time: 0.05258
Total Iteration Time: 15.56392

Cumulative Model Updates: 49,660
Cumulative Timesteps: 828,320,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 828320190...
Checkpoint 828320190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,494.23398
Policy Entropy: 1.05416
Value Function Loss: 4.03401

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.15918
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.06958

Collected Steps per Second: 3,744.27073
Overall Steps per Second: 3,163.25353

Timestep Collection Time: 13.35854
Timestep Consumption Time: 2.45366
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 15.81220

Cumulative Model Updates: 49,663
Cumulative Timesteps: 828,370,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,180.42359
Policy Entropy: 1.06858
Value Function Loss: 3.99215

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.07426

Collected Steps per Second: 3,830.11153
Overall Steps per Second: 3,152.51242

Timestep Collection Time: 13.06280
Timestep Consumption Time: 2.80771
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 15.87052

Cumulative Model Updates: 49,666
Cumulative Timesteps: 828,420,240

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 828420240...
Checkpoint 828420240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,653.25255
Policy Entropy: 1.08367
Value Function Loss: 3.92051

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.15926
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.08264

Collected Steps per Second: 3,811.03252
Overall Steps per Second: 3,167.10529

Timestep Collection Time: 13.12400
Timestep Consumption Time: 2.66834
PPO Batch Consumption Time: 0.05883
Total Iteration Time: 15.79234

Cumulative Model Updates: 49,669
Cumulative Timesteps: 828,470,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,247.58835
Policy Entropy: 1.05417
Value Function Loss: 4.02822

Mean KL Divergence: 0.04339
SB3 Clip Fraction: 0.17035
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.08886

Collected Steps per Second: 3,876.37529
Overall Steps per Second: 3,186.25284

Timestep Collection Time: 12.89865
Timestep Consumption Time: 2.79377
PPO Batch Consumption Time: 0.06066
Total Iteration Time: 15.69241

Cumulative Model Updates: 49,672
Cumulative Timesteps: 828,520,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 828520256...
Checkpoint 828520256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,039.45528
Policy Entropy: 1.08170
Value Function Loss: 4.09729

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.16959
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.09429

Collected Steps per Second: 3,971.06740
Overall Steps per Second: 3,257.75387

Timestep Collection Time: 12.59309
Timestep Consumption Time: 2.75737
PPO Batch Consumption Time: 0.06613
Total Iteration Time: 15.35045

Cumulative Model Updates: 49,675
Cumulative Timesteps: 828,570,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,380.47768
Policy Entropy: 1.07084
Value Function Loss: 4.07064

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.16353
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.09079

Collected Steps per Second: 3,846.79858
Overall Steps per Second: 3,225.86658

Timestep Collection Time: 13.01082
Timestep Consumption Time: 2.50439
PPO Batch Consumption Time: 0.06073
Total Iteration Time: 15.51521

Cumulative Model Updates: 49,678
Cumulative Timesteps: 828,620,314

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 828620314...
Checkpoint 828620314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,393.47863
Policy Entropy: 1.07479
Value Function Loss: 4.09494

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.08589

Collected Steps per Second: 3,772.17934
Overall Steps per Second: 3,123.36607

Timestep Collection Time: 13.26077
Timestep Consumption Time: 2.75464
PPO Batch Consumption Time: 0.05021
Total Iteration Time: 16.01541

Cumulative Model Updates: 49,681
Cumulative Timesteps: 828,670,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,559.00758
Policy Entropy: 1.08653
Value Function Loss: 4.09206

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.09317

Collected Steps per Second: 3,811.63459
Overall Steps per Second: 3,153.79614

Timestep Collection Time: 13.12665
Timestep Consumption Time: 2.73804
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 15.86469

Cumulative Model Updates: 49,684
Cumulative Timesteps: 828,720,370

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 828720370...
Checkpoint 828720370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,593.45889
Policy Entropy: 1.08478
Value Function Loss: 4.15474

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.08514

Collected Steps per Second: 3,898.87020
Overall Steps per Second: 3,199.11853

Timestep Collection Time: 12.83397
Timestep Consumption Time: 2.80721
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 15.64118

Cumulative Model Updates: 49,687
Cumulative Timesteps: 828,770,408

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,277.42191
Policy Entropy: 1.07394
Value Function Loss: 4.07098

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.08377

Collected Steps per Second: 3,815.56919
Overall Steps per Second: 3,132.22705

Timestep Collection Time: 13.10735
Timestep Consumption Time: 2.85956
PPO Batch Consumption Time: 0.06176
Total Iteration Time: 15.96691

Cumulative Model Updates: 49,690
Cumulative Timesteps: 828,820,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 828820420...
Checkpoint 828820420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,895.48949
Policy Entropy: 1.05924
Value Function Loss: 3.94406

Mean KL Divergence: 0.03220
SB3 Clip Fraction: 0.17763
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.09173

Collected Steps per Second: 3,846.86627
Overall Steps per Second: 3,231.73137

Timestep Collection Time: 13.00435
Timestep Consumption Time: 2.47528
PPO Batch Consumption Time: 0.06129
Total Iteration Time: 15.47963

Cumulative Model Updates: 49,693
Cumulative Timesteps: 828,870,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,947.69429
Policy Entropy: 1.08701
Value Function Loss: 3.80925

Mean KL Divergence: 0.03022
SB3 Clip Fraction: 0.16567
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.09286

Collected Steps per Second: 3,892.11313
Overall Steps per Second: 3,221.36931

Timestep Collection Time: 12.85471
Timestep Consumption Time: 2.67657
PPO Batch Consumption Time: 0.05156
Total Iteration Time: 15.53128

Cumulative Model Updates: 49,696
Cumulative Timesteps: 828,920,478

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 828920478...
Checkpoint 828920478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,592.98081
Policy Entropy: 1.06722
Value Function Loss: 3.84542

Mean KL Divergence: 0.03413
SB3 Clip Fraction: 0.19181
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.09388

Collected Steps per Second: 3,826.79147
Overall Steps per Second: 3,218.36327

Timestep Collection Time: 13.07989
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.05318
Total Iteration Time: 15.55263

Cumulative Model Updates: 49,699
Cumulative Timesteps: 828,970,532

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,436.07647
Policy Entropy: 1.08010
Value Function Loss: 3.85779

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.17597
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.11268

Collected Steps per Second: 3,818.18386
Overall Steps per Second: 3,150.92339

Timestep Collection Time: 13.09628
Timestep Consumption Time: 2.77336
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 15.86963

Cumulative Model Updates: 49,702
Cumulative Timesteps: 829,020,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 829020536...
Checkpoint 829020536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,282.65683
Policy Entropy: 1.08353
Value Function Loss: 4.00739

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.15787
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.10109

Collected Steps per Second: 3,772.07033
Overall Steps per Second: 3,093.26051

Timestep Collection Time: 13.26858
Timestep Consumption Time: 2.91176
PPO Batch Consumption Time: 0.06099
Total Iteration Time: 16.18034

Cumulative Model Updates: 49,705
Cumulative Timesteps: 829,070,586

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,436.74995
Policy Entropy: 1.06792
Value Function Loss: 3.83262

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.14729
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.09525

Collected Steps per Second: 3,838.97556
Overall Steps per Second: 3,170.78010

Timestep Collection Time: 13.02952
Timestep Consumption Time: 2.74578
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 15.77530

Cumulative Model Updates: 49,708
Cumulative Timesteps: 829,120,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 829120606...
Checkpoint 829120606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,881.90856
Policy Entropy: 1.05718
Value Function Loss: 3.96650

Mean KL Divergence: 0.03865
SB3 Clip Fraction: 0.20660
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.09404

Collected Steps per Second: 3,987.51264
Overall Steps per Second: 3,260.06940

Timestep Collection Time: 12.54215
Timestep Consumption Time: 2.79862
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 15.34078

Cumulative Model Updates: 49,711
Cumulative Timesteps: 829,170,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,863.39010
Policy Entropy: 1.07691
Value Function Loss: 3.92796

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.09225

Collected Steps per Second: 3,776.67288
Overall Steps per Second: 3,156.00040

Timestep Collection Time: 13.24552
Timestep Consumption Time: 2.60492
PPO Batch Consumption Time: 0.06291
Total Iteration Time: 15.85044

Cumulative Model Updates: 49,714
Cumulative Timesteps: 829,220,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 829220642...
Checkpoint 829220642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740,482.67963
Policy Entropy: 1.06074
Value Function Loss: 4.01663

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.15477
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.11004

Collected Steps per Second: 3,863.33444
Overall Steps per Second: 3,150.97527

Timestep Collection Time: 12.95151
Timestep Consumption Time: 2.92802
PPO Batch Consumption Time: 0.06547
Total Iteration Time: 15.87953

Cumulative Model Updates: 49,717
Cumulative Timesteps: 829,270,678

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,505.99198
Policy Entropy: 1.06220
Value Function Loss: 3.98346

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.10266

Collected Steps per Second: 3,674.72141
Overall Steps per Second: 3,072.33338

Timestep Collection Time: 13.61083
Timestep Consumption Time: 2.66866
PPO Batch Consumption Time: 0.05020
Total Iteration Time: 16.27948

Cumulative Model Updates: 49,720
Cumulative Timesteps: 829,320,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 829320694...
Checkpoint 829320694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,939.61552
Policy Entropy: 1.06228
Value Function Loss: 3.99928

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.10032

Collected Steps per Second: 3,820.07280
Overall Steps per Second: 3,202.60941

Timestep Collection Time: 13.09085
Timestep Consumption Time: 2.52392
PPO Batch Consumption Time: 0.05220
Total Iteration Time: 15.61477

Cumulative Model Updates: 49,723
Cumulative Timesteps: 829,370,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,272.87478
Policy Entropy: 1.06786
Value Function Loss: 4.12860

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.09534

Collected Steps per Second: 3,877.68248
Overall Steps per Second: 3,201.02244

Timestep Collection Time: 12.89791
Timestep Consumption Time: 2.72647
PPO Batch Consumption Time: 0.06089
Total Iteration Time: 15.62438

Cumulative Model Updates: 49,726
Cumulative Timesteps: 829,420,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 829420716...
Checkpoint 829420716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,587.48657
Policy Entropy: 1.07170
Value Function Loss: 4.07372

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.09408

Collected Steps per Second: 3,928.27338
Overall Steps per Second: 3,293.49784

Timestep Collection Time: 12.73537
Timestep Consumption Time: 2.45456
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 15.18993

Cumulative Model Updates: 49,729
Cumulative Timesteps: 829,470,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,745.88074
Policy Entropy: 1.07275
Value Function Loss: 4.19720

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.07385
Value Function Update Magnitude: 0.08286

Collected Steps per Second: 3,967.63130
Overall Steps per Second: 3,251.83885

Timestep Collection Time: 12.60903
Timestep Consumption Time: 2.77549
PPO Batch Consumption Time: 0.06282
Total Iteration Time: 15.38453

Cumulative Model Updates: 49,732
Cumulative Timesteps: 829,520,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 829520772...
Checkpoint 829520772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,031.01143
Policy Entropy: 1.07285
Value Function Loss: 4.16310

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.07258
Value Function Update Magnitude: 0.08796

Collected Steps per Second: 3,872.40327
Overall Steps per Second: 3,202.43754

Timestep Collection Time: 12.91549
Timestep Consumption Time: 2.70198
PPO Batch Consumption Time: 0.06615
Total Iteration Time: 15.61748

Cumulative Model Updates: 49,735
Cumulative Timesteps: 829,570,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,679.43762
Policy Entropy: 1.07110
Value Function Loss: 4.26557

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.08063
Value Function Update Magnitude: 0.10268

Collected Steps per Second: 3,844.23259
Overall Steps per Second: 3,147.59926

Timestep Collection Time: 13.01170
Timestep Consumption Time: 2.87978
PPO Batch Consumption Time: 0.06264
Total Iteration Time: 15.89148

Cumulative Model Updates: 49,738
Cumulative Timesteps: 829,620,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 829620806...
Checkpoint 829620806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,338.82146
Policy Entropy: 1.06686
Value Function Loss: 4.27626

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.07397
Value Function Update Magnitude: 0.10593

Collected Steps per Second: 3,914.11267
Overall Steps per Second: 3,236.49438

Timestep Collection Time: 12.78093
Timestep Consumption Time: 2.67592
PPO Batch Consumption Time: 0.05317
Total Iteration Time: 15.45685

Cumulative Model Updates: 49,741
Cumulative Timesteps: 829,670,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,794.13130
Policy Entropy: 1.06197
Value Function Loss: 4.36666

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.06706
Value Function Update Magnitude: 0.09656

Collected Steps per Second: 3,757.55272
Overall Steps per Second: 3,161.31332

Timestep Collection Time: 13.31771
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.07435
Total Iteration Time: 15.82950

Cumulative Model Updates: 49,744
Cumulative Timesteps: 829,720,874

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 829720874...
Checkpoint 829720874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,773.22367
Policy Entropy: 1.07890
Value Function Loss: 4.38472

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 3,790.75856
Overall Steps per Second: 3,120.96156

Timestep Collection Time: 13.19261
Timestep Consumption Time: 2.83130
PPO Batch Consumption Time: 0.06749
Total Iteration Time: 16.02391

Cumulative Model Updates: 49,747
Cumulative Timesteps: 829,770,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,506.99673
Policy Entropy: 1.08336
Value Function Loss: 4.34625

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.06441
Value Function Update Magnitude: 0.09386

Collected Steps per Second: 3,846.16488
Overall Steps per Second: 3,227.75491

Timestep Collection Time: 13.00568
Timestep Consumption Time: 2.49178
PPO Batch Consumption Time: 0.06486
Total Iteration Time: 15.49746

Cumulative Model Updates: 49,750
Cumulative Timesteps: 829,820,906

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 829820906...
Checkpoint 829820906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,727.32434
Policy Entropy: 1.08274
Value Function Loss: 4.12322

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.10181

Collected Steps per Second: 3,953.06488
Overall Steps per Second: 3,239.34825

Timestep Collection Time: 12.65651
Timestep Consumption Time: 2.78857
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 15.44508

Cumulative Model Updates: 49,753
Cumulative Timesteps: 829,870,938

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,807.80459
Policy Entropy: 1.07613
Value Function Loss: 4.14752

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.09205

Collected Steps per Second: 3,756.88875
Overall Steps per Second: 3,132.65637

Timestep Collection Time: 13.30888
Timestep Consumption Time: 2.65201
PPO Batch Consumption Time: 0.06802
Total Iteration Time: 15.96090

Cumulative Model Updates: 49,756
Cumulative Timesteps: 829,920,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 829920938...
Checkpoint 829920938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,146.44987
Policy Entropy: 1.09555
Value Function Loss: 4.18049

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.08581

Collected Steps per Second: 3,832.50222
Overall Steps per Second: 3,191.57948

Timestep Collection Time: 13.05674
Timestep Consumption Time: 2.62201
PPO Batch Consumption Time: 0.06185
Total Iteration Time: 15.67876

Cumulative Model Updates: 49,759
Cumulative Timesteps: 829,970,978

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,405.35638
Policy Entropy: 1.09206
Value Function Loss: 4.22441

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.07870

Collected Steps per Second: 3,745.91243
Overall Steps per Second: 3,021.99186

Timestep Collection Time: 13.35536
Timestep Consumption Time: 3.19929
PPO Batch Consumption Time: 0.06459
Total Iteration Time: 16.55464

Cumulative Model Updates: 49,762
Cumulative Timesteps: 830,021,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 830021006...
Checkpoint 830021006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,906.95037
Policy Entropy: 1.09005
Value Function Loss: 4.18961

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.07131
Value Function Update Magnitude: 0.08798

Collected Steps per Second: 3,719.88745
Overall Steps per Second: 3,082.99342

Timestep Collection Time: 13.44127
Timestep Consumption Time: 2.77674
PPO Batch Consumption Time: 0.05858
Total Iteration Time: 16.21800

Cumulative Model Updates: 49,765
Cumulative Timesteps: 830,071,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,530.30553
Policy Entropy: 1.08267
Value Function Loss: 4.22724

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.07683
Value Function Update Magnitude: 0.09230

Collected Steps per Second: 3,953.22997
Overall Steps per Second: 3,292.00728

Timestep Collection Time: 12.65143
Timestep Consumption Time: 2.54113
PPO Batch Consumption Time: 0.06217
Total Iteration Time: 15.19255

Cumulative Model Updates: 49,768
Cumulative Timesteps: 830,121,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 830121020...
Checkpoint 830121020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,272.31989
Policy Entropy: 1.08527
Value Function Loss: 4.41687

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.07554
Value Function Update Magnitude: 0.08813

Collected Steps per Second: 3,809.66120
Overall Steps per Second: 3,141.76062

Timestep Collection Time: 13.12925
Timestep Consumption Time: 2.79112
PPO Batch Consumption Time: 0.05843
Total Iteration Time: 15.92037

Cumulative Model Updates: 49,771
Cumulative Timesteps: 830,171,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,213.91004
Policy Entropy: 1.08865
Value Function Loss: 4.39630

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.09022

Collected Steps per Second: 3,890.84785
Overall Steps per Second: 3,283.54058

Timestep Collection Time: 12.85375
Timestep Consumption Time: 2.37737
PPO Batch Consumption Time: 0.05302
Total Iteration Time: 15.23112

Cumulative Model Updates: 49,774
Cumulative Timesteps: 830,221,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 830221050...
Checkpoint 830221050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,081.09102
Policy Entropy: 1.10156
Value Function Loss: 4.34160

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.09771

Collected Steps per Second: 3,812.05714
Overall Steps per Second: 3,138.75968

Timestep Collection Time: 13.12152
Timestep Consumption Time: 2.81471
PPO Batch Consumption Time: 0.05940
Total Iteration Time: 15.93623

Cumulative Model Updates: 49,777
Cumulative Timesteps: 830,271,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688,030.00488
Policy Entropy: 1.09941
Value Function Loss: 4.19689

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.06623
Value Function Update Magnitude: 0.09295

Collected Steps per Second: 3,744.00306
Overall Steps per Second: 3,139.39707

Timestep Collection Time: 13.36110
Timestep Consumption Time: 2.57317
PPO Batch Consumption Time: 0.06057
Total Iteration Time: 15.93427

Cumulative Model Updates: 49,780
Cumulative Timesteps: 830,321,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 830321094...
Checkpoint 830321094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,861.98058
Policy Entropy: 1.09988
Value Function Loss: 4.36171

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.07426
Value Function Update Magnitude: 0.09256

Collected Steps per Second: 3,666.11865
Overall Steps per Second: 3,037.89252

Timestep Collection Time: 13.64113
Timestep Consumption Time: 2.82094
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 16.46207

Cumulative Model Updates: 49,783
Cumulative Timesteps: 830,371,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,169.30784
Policy Entropy: 1.09555
Value Function Loss: 4.34453

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.07139
Value Function Update Magnitude: 0.09272

Collected Steps per Second: 3,832.51759
Overall Steps per Second: 3,180.88074

Timestep Collection Time: 13.05199
Timestep Consumption Time: 2.67384
PPO Batch Consumption Time: 0.05960
Total Iteration Time: 15.72583

Cumulative Model Updates: 49,786
Cumulative Timesteps: 830,421,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 830421126...
Checkpoint 830421126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596,915.19708
Policy Entropy: 1.10958
Value Function Loss: 4.28601

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.10633

Collected Steps per Second: 3,865.79891
Overall Steps per Second: 3,162.76037

Timestep Collection Time: 12.93911
Timestep Consumption Time: 2.87619
PPO Batch Consumption Time: 0.07210
Total Iteration Time: 15.81530

Cumulative Model Updates: 49,789
Cumulative Timesteps: 830,471,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,782.59248
Policy Entropy: 1.11235
Value Function Loss: 4.02025

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.11245

Collected Steps per Second: 3,922.36202
Overall Steps per Second: 3,228.36909

Timestep Collection Time: 12.74793
Timestep Consumption Time: 2.74038
PPO Batch Consumption Time: 0.06949
Total Iteration Time: 15.48832

Cumulative Model Updates: 49,792
Cumulative Timesteps: 830,521,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 830521148...
Checkpoint 830521148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,797.50244
Policy Entropy: 1.09880
Value Function Loss: 3.94635

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.11266

Collected Steps per Second: 3,700.18058
Overall Steps per Second: 3,106.22129

Timestep Collection Time: 13.52420
Timestep Consumption Time: 2.58604
PPO Batch Consumption Time: 0.05789
Total Iteration Time: 16.11025

Cumulative Model Updates: 49,795
Cumulative Timesteps: 830,571,190

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,797.96366
Policy Entropy: 1.09321
Value Function Loss: 4.01535

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.10350

Collected Steps per Second: 3,825.74193
Overall Steps per Second: 3,122.78215

Timestep Collection Time: 13.07929
Timestep Consumption Time: 2.94424
PPO Batch Consumption Time: 0.06650
Total Iteration Time: 16.02353

Cumulative Model Updates: 49,798
Cumulative Timesteps: 830,621,228

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 830621228...
Checkpoint 830621228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,508.19137
Policy Entropy: 1.10228
Value Function Loss: 4.23311

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.09475

Collected Steps per Second: 3,740.11382
Overall Steps per Second: 3,088.02764

Timestep Collection Time: 13.37446
Timestep Consumption Time: 2.82423
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 16.19869

Cumulative Model Updates: 49,801
Cumulative Timesteps: 830,671,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,424.07241
Policy Entropy: 1.10967
Value Function Loss: 4.20584

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.09720

Collected Steps per Second: 3,831.90823
Overall Steps per Second: 3,145.96869

Timestep Collection Time: 13.05459
Timestep Consumption Time: 2.84639
PPO Batch Consumption Time: 0.06405
Total Iteration Time: 15.90098

Cumulative Model Updates: 49,804
Cumulative Timesteps: 830,721,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 830721274...
Checkpoint 830721274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,018.90004
Policy Entropy: 1.09074
Value Function Loss: 4.18641

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.09179

Collected Steps per Second: 3,847.50966
Overall Steps per Second: 3,148.75848

Timestep Collection Time: 13.00634
Timestep Consumption Time: 2.88628
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 15.89261

Cumulative Model Updates: 49,807
Cumulative Timesteps: 830,771,316

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,380.43459
Policy Entropy: 1.08433
Value Function Loss: 4.03832

Mean KL Divergence: 0.03009
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.09262

Collected Steps per Second: 3,785.31161
Overall Steps per Second: 3,159.38416

Timestep Collection Time: 13.21741
Timestep Consumption Time: 2.61859
PPO Batch Consumption Time: 0.05903
Total Iteration Time: 15.83600

Cumulative Model Updates: 49,810
Cumulative Timesteps: 830,821,348

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 830821348...
Checkpoint 830821348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,428.95546
Policy Entropy: 1.09333
Value Function Loss: 4.26132

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.12077

Collected Steps per Second: 3,801.63386
Overall Steps per Second: 3,150.62273

Timestep Collection Time: 13.15434
Timestep Consumption Time: 2.71807
PPO Batch Consumption Time: 0.05304
Total Iteration Time: 15.87242

Cumulative Model Updates: 49,813
Cumulative Timesteps: 830,871,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,606.37199
Policy Entropy: 1.10684
Value Function Loss: 4.21329

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.13135

Collected Steps per Second: 3,755.04535
Overall Steps per Second: 3,157.38213

Timestep Collection Time: 13.32128
Timestep Consumption Time: 2.52159
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 15.84287

Cumulative Model Updates: 49,816
Cumulative Timesteps: 830,921,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 830921378...
Checkpoint 830921378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,074.03691
Policy Entropy: 1.08748
Value Function Loss: 4.13945

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.12539

Collected Steps per Second: 3,774.12803
Overall Steps per Second: 3,102.70739

Timestep Collection Time: 13.25657
Timestep Consumption Time: 2.86870
PPO Batch Consumption Time: 0.06681
Total Iteration Time: 16.12527

Cumulative Model Updates: 49,819
Cumulative Timesteps: 830,971,410

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533,330.63266
Policy Entropy: 1.10016
Value Function Loss: 3.91782

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.12301

Collected Steps per Second: 3,715.33951
Overall Steps per Second: 3,080.34956

Timestep Collection Time: 13.46795
Timestep Consumption Time: 2.77631
PPO Batch Consumption Time: 0.06913
Total Iteration Time: 16.24426

Cumulative Model Updates: 49,822
Cumulative Timesteps: 831,021,448

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 831021448...
Checkpoint 831021448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,788.08921
Policy Entropy: 1.10308
Value Function Loss: 3.89459

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.11350

Collected Steps per Second: 3,892.04550
Overall Steps per Second: 3,205.64534

Timestep Collection Time: 12.84774
Timestep Consumption Time: 2.75099
PPO Batch Consumption Time: 0.05861
Total Iteration Time: 15.59873

Cumulative Model Updates: 49,825
Cumulative Timesteps: 831,071,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,803.90797
Policy Entropy: 1.10978
Value Function Loss: 4.04308

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.09993

Collected Steps per Second: 3,720.73795
Overall Steps per Second: 3,092.76175

Timestep Collection Time: 13.44357
Timestep Consumption Time: 2.72968
PPO Batch Consumption Time: 0.06147
Total Iteration Time: 16.17325

Cumulative Model Updates: 49,828
Cumulative Timesteps: 831,121,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 831121472...
Checkpoint 831121472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,345.51242
Policy Entropy: 1.10842
Value Function Loss: 3.97445

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.08585

Collected Steps per Second: 3,845.15014
Overall Steps per Second: 3,211.39336

Timestep Collection Time: 13.00755
Timestep Consumption Time: 2.56699
PPO Batch Consumption Time: 0.05979
Total Iteration Time: 15.57455

Cumulative Model Updates: 49,831
Cumulative Timesteps: 831,171,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,467.77427
Policy Entropy: 1.09822
Value Function Loss: 3.98524

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.08130

Collected Steps per Second: 3,806.37587
Overall Steps per Second: 3,119.96038

Timestep Collection Time: 13.14321
Timestep Consumption Time: 2.89161
PPO Batch Consumption Time: 0.05908
Total Iteration Time: 16.03482

Cumulative Model Updates: 49,834
Cumulative Timesteps: 831,221,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 831221516...
Checkpoint 831221516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,203.09954
Policy Entropy: 1.10442
Value Function Loss: 4.06584

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.07510

Collected Steps per Second: 3,845.54416
Overall Steps per Second: 3,158.00828

Timestep Collection Time: 13.00414
Timestep Consumption Time: 2.83116
PPO Batch Consumption Time: 0.05930
Total Iteration Time: 15.83530

Cumulative Model Updates: 49,837
Cumulative Timesteps: 831,271,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,519.16064
Policy Entropy: 1.10441
Value Function Loss: 4.28970

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.07623

Collected Steps per Second: 3,911.24992
Overall Steps per Second: 3,212.32823

Timestep Collection Time: 12.79028
Timestep Consumption Time: 2.78284
PPO Batch Consumption Time: 0.05750
Total Iteration Time: 15.57313

Cumulative Model Updates: 49,840
Cumulative Timesteps: 831,321,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 831321550...
Checkpoint 831321550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,376.19925
Policy Entropy: 1.11039
Value Function Loss: 4.21211

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.06558
Value Function Update Magnitude: 0.08145

Collected Steps per Second: 3,873.04399
Overall Steps per Second: 3,175.98382

Timestep Collection Time: 12.92214
Timestep Consumption Time: 2.83613
PPO Batch Consumption Time: 0.07290
Total Iteration Time: 15.75827

Cumulative Model Updates: 49,843
Cumulative Timesteps: 831,371,598

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,230.67815
Policy Entropy: 1.10374
Value Function Loss: 4.15386

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.06871
Value Function Update Magnitude: 0.09152

Collected Steps per Second: 3,755.85124
Overall Steps per Second: 3,176.46122

Timestep Collection Time: 13.32481
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 15.75527

Cumulative Model Updates: 49,846
Cumulative Timesteps: 831,421,644

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 831421644...
Checkpoint 831421644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558,345.46638
Policy Entropy: 1.11451
Value Function Loss: 4.07103

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.08669

Collected Steps per Second: 3,858.67297
Overall Steps per Second: 3,155.85367

Timestep Collection Time: 12.96352
Timestep Consumption Time: 2.88702
PPO Batch Consumption Time: 0.06295
Total Iteration Time: 15.85054

Cumulative Model Updates: 49,849
Cumulative Timesteps: 831,471,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,953.01685
Policy Entropy: 1.10289
Value Function Loss: 4.19827

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.09558

Collected Steps per Second: 3,910.84857
Overall Steps per Second: 3,223.91873

Timestep Collection Time: 12.78955
Timestep Consumption Time: 2.72511
PPO Batch Consumption Time: 0.06228
Total Iteration Time: 15.51466

Cumulative Model Updates: 49,852
Cumulative Timesteps: 831,521,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 831521684...
Checkpoint 831521684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,914.49550
Policy Entropy: 1.12263
Value Function Loss: 4.07601

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.10095

Collected Steps per Second: 3,864.36884
Overall Steps per Second: 3,177.37183

Timestep Collection Time: 12.94286
Timestep Consumption Time: 2.79845
PPO Batch Consumption Time: 0.05934
Total Iteration Time: 15.74131

Cumulative Model Updates: 49,855
Cumulative Timesteps: 831,571,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,156.36849
Policy Entropy: 1.11115
Value Function Loss: 4.16252

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.15564
Policy Update Magnitude: 0.06270
Value Function Update Magnitude: 0.09936

Collected Steps per Second: 3,892.31379
Overall Steps per Second: 3,200.54485

Timestep Collection Time: 12.85097
Timestep Consumption Time: 2.77762
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 15.62859

Cumulative Model Updates: 49,858
Cumulative Timesteps: 831,621,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 831621720...
Checkpoint 831621720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,408.72559
Policy Entropy: 1.11244
Value Function Loss: 4.23841

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.10519

Collected Steps per Second: 3,861.45946
Overall Steps per Second: 3,239.79735

Timestep Collection Time: 12.95003
Timestep Consumption Time: 2.48489
PPO Batch Consumption Time: 0.06752
Total Iteration Time: 15.43492

Cumulative Model Updates: 49,861
Cumulative Timesteps: 831,671,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,211.96194
Policy Entropy: 1.08807
Value Function Loss: 4.31967

Mean KL Divergence: 0.03702
SB3 Clip Fraction: 0.22836
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.09844

Collected Steps per Second: 3,809.51066
Overall Steps per Second: 3,083.96850

Timestep Collection Time: 13.12662
Timestep Consumption Time: 3.08820
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 16.21482

Cumulative Model Updates: 49,864
Cumulative Timesteps: 831,721,732

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 831721732...
Checkpoint 831721732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,113.59370
Policy Entropy: 1.11212
Value Function Loss: 4.39831

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.08929

Collected Steps per Second: 3,807.26764
Overall Steps per Second: 3,149.88694

Timestep Collection Time: 13.14118
Timestep Consumption Time: 2.74256
PPO Batch Consumption Time: 0.05919
Total Iteration Time: 15.88374

Cumulative Model Updates: 49,867
Cumulative Timesteps: 831,771,764

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,770.38940
Policy Entropy: 1.09555
Value Function Loss: 4.35802

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.10836

Collected Steps per Second: 3,866.05631
Overall Steps per Second: 3,204.49577

Timestep Collection Time: 12.93359
Timestep Consumption Time: 2.67011
PPO Batch Consumption Time: 0.05910
Total Iteration Time: 15.60370

Cumulative Model Updates: 49,870
Cumulative Timesteps: 831,821,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 831821766...
Checkpoint 831821766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,308.04388
Policy Entropy: 1.09387
Value Function Loss: 4.21010

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.11796

Collected Steps per Second: 3,754.62746
Overall Steps per Second: 3,101.41831

Timestep Collection Time: 13.32169
Timestep Consumption Time: 2.80577
PPO Batch Consumption Time: 0.05757
Total Iteration Time: 16.12746

Cumulative Model Updates: 49,873
Cumulative Timesteps: 831,871,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,101.92694
Policy Entropy: 1.10224
Value Function Loss: 4.24481

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.11313

Collected Steps per Second: 3,726.03904
Overall Steps per Second: 3,146.14200

Timestep Collection Time: 13.41908
Timestep Consumption Time: 2.47340
PPO Batch Consumption Time: 0.06345
Total Iteration Time: 15.89248

Cumulative Model Updates: 49,876
Cumulative Timesteps: 831,921,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 831921784...
Checkpoint 831921784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,529.48724
Policy Entropy: 1.10349
Value Function Loss: 4.23994

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.09776

Collected Steps per Second: 3,891.78025
Overall Steps per Second: 3,182.08492

Timestep Collection Time: 12.85376
Timestep Consumption Time: 2.86675
PPO Batch Consumption Time: 0.06929
Total Iteration Time: 15.72051

Cumulative Model Updates: 49,879
Cumulative Timesteps: 831,971,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,073.12580
Policy Entropy: 1.10089
Value Function Loss: 4.47295

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.06654
Value Function Update Magnitude: 0.09737

Collected Steps per Second: 3,930.23940
Overall Steps per Second: 3,285.40614

Timestep Collection Time: 12.72696
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.06475
Total Iteration Time: 15.22491

Cumulative Model Updates: 49,882
Cumulative Timesteps: 832,021,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 832021828...
Checkpoint 832021828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,368.83130
Policy Entropy: 1.09796
Value Function Loss: 4.41809

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.06721
Value Function Update Magnitude: 0.10109

Collected Steps per Second: 3,857.21960
Overall Steps per Second: 3,204.35580

Timestep Collection Time: 12.96633
Timestep Consumption Time: 2.64179
PPO Batch Consumption Time: 0.04873
Total Iteration Time: 15.60813

Cumulative Model Updates: 49,885
Cumulative Timesteps: 832,071,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,516.60158
Policy Entropy: 1.11326
Value Function Loss: 4.42638

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.08986

Collected Steps per Second: 4,065.09666
Overall Steps per Second: 3,330.12140

Timestep Collection Time: 12.30278
Timestep Consumption Time: 2.71529
PPO Batch Consumption Time: 0.05841
Total Iteration Time: 15.01807

Cumulative Model Updates: 49,888
Cumulative Timesteps: 832,121,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 832121854...
Checkpoint 832121854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,658.76565
Policy Entropy: 1.10846
Value Function Loss: 4.49341

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.10207

Collected Steps per Second: 3,903.64289
Overall Steps per Second: 3,205.65612

Timestep Collection Time: 12.81726
Timestep Consumption Time: 2.79078
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 15.60804

Cumulative Model Updates: 49,891
Cumulative Timesteps: 832,171,888

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,682.48762
Policy Entropy: 1.09952
Value Function Loss: 4.33623

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.09996

Collected Steps per Second: 3,862.20676
Overall Steps per Second: 3,173.67088

Timestep Collection Time: 12.95322
Timestep Consumption Time: 2.81023
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 15.76345

Cumulative Model Updates: 49,894
Cumulative Timesteps: 832,221,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 832221916...
Checkpoint 832221916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,250.39886
Policy Entropy: 1.08883
Value Function Loss: 4.31702

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.17229
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.09009

Collected Steps per Second: 3,811.24652
Overall Steps per Second: 3,187.76614

Timestep Collection Time: 13.12327
Timestep Consumption Time: 2.56672
PPO Batch Consumption Time: 0.05884
Total Iteration Time: 15.68998

Cumulative Model Updates: 49,897
Cumulative Timesteps: 832,271,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,625.48972
Policy Entropy: 1.10117
Value Function Loss: 4.13940

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.10765

Collected Steps per Second: 3,956.22092
Overall Steps per Second: 3,238.11569

Timestep Collection Time: 12.64692
Timestep Consumption Time: 2.80466
PPO Batch Consumption Time: 0.05259
Total Iteration Time: 15.45158

Cumulative Model Updates: 49,900
Cumulative Timesteps: 832,321,966

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 832321966...
Checkpoint 832321966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,802.10393
Policy Entropy: 1.10843
Value Function Loss: 4.12619

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.11445

Collected Steps per Second: 3,787.91807
Overall Steps per Second: 3,111.89442

Timestep Collection Time: 13.20937
Timestep Consumption Time: 2.86958
PPO Batch Consumption Time: 0.05434
Total Iteration Time: 16.07895

Cumulative Model Updates: 49,903
Cumulative Timesteps: 832,372,002

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,013.39523
Policy Entropy: 1.08045
Value Function Loss: 4.18659

Mean KL Divergence: 0.03798
SB3 Clip Fraction: 0.18746
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.09656

Collected Steps per Second: 3,905.64792
Overall Steps per Second: 3,208.03549

Timestep Collection Time: 12.80965
Timestep Consumption Time: 2.78556
PPO Batch Consumption Time: 0.06770
Total Iteration Time: 15.59521

Cumulative Model Updates: 49,906
Cumulative Timesteps: 832,422,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 832422032...
Checkpoint 832422032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,970.26408
Policy Entropy: 1.09952
Value Function Loss: 4.12798

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.09189

Collected Steps per Second: 3,782.00090
Overall Steps per Second: 3,144.39253

Timestep Collection Time: 13.23056
Timestep Consumption Time: 2.68284
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 15.91341

Cumulative Model Updates: 49,909
Cumulative Timesteps: 832,472,070

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,054.57985
Policy Entropy: 1.10823
Value Function Loss: 4.16716

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.08271

Collected Steps per Second: 3,869.49307
Overall Steps per Second: 3,224.05921

Timestep Collection Time: 12.92779
Timestep Consumption Time: 2.58805
PPO Batch Consumption Time: 0.06009
Total Iteration Time: 15.51584

Cumulative Model Updates: 49,912
Cumulative Timesteps: 832,522,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 832522094...
Checkpoint 832522094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,221.98749
Policy Entropy: 1.09390
Value Function Loss: 3.98004

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.07308

Collected Steps per Second: 3,861.01390
Overall Steps per Second: 3,154.13781

Timestep Collection Time: 12.95825
Timestep Consumption Time: 2.90408
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 15.86234

Cumulative Model Updates: 49,915
Cumulative Timesteps: 832,572,126

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,424.71044
Policy Entropy: 1.09272
Value Function Loss: 3.97063

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.15525
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.07225

Collected Steps per Second: 3,759.75222
Overall Steps per Second: 3,153.84480

Timestep Collection Time: 13.30832
Timestep Consumption Time: 2.55676
PPO Batch Consumption Time: 0.06391
Total Iteration Time: 15.86508

Cumulative Model Updates: 49,918
Cumulative Timesteps: 832,622,162

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 832622162...
Checkpoint 832622162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,126.70640
Policy Entropy: 1.09929
Value Function Loss: 4.00422

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.07449

Collected Steps per Second: 3,829.91804
Overall Steps per Second: 3,153.96577

Timestep Collection Time: 13.06033
Timestep Consumption Time: 2.79907
PPO Batch Consumption Time: 0.06405
Total Iteration Time: 15.85940

Cumulative Model Updates: 49,921
Cumulative Timesteps: 832,672,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,778.90301
Policy Entropy: 1.11177
Value Function Loss: 4.13073

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.08073

Collected Steps per Second: 3,903.26693
Overall Steps per Second: 3,222.57054

Timestep Collection Time: 12.82208
Timestep Consumption Time: 2.70838
PPO Batch Consumption Time: 0.06223
Total Iteration Time: 15.53046

Cumulative Model Updates: 49,924
Cumulative Timesteps: 832,722,230

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 832722230...
Checkpoint 832722230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,314.98814
Policy Entropy: 1.09156
Value Function Loss: 4.16007

Mean KL Divergence: 0.02770
SB3 Clip Fraction: 0.15532
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.07892

Collected Steps per Second: 3,917.94989
Overall Steps per Second: 3,226.65062

Timestep Collection Time: 12.77199
Timestep Consumption Time: 2.73636
PPO Batch Consumption Time: 0.05821
Total Iteration Time: 15.50834

Cumulative Model Updates: 49,927
Cumulative Timesteps: 832,772,270

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,442.92866
Policy Entropy: 1.10582
Value Function Loss: 4.04724

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.08036

Collected Steps per Second: 3,762.91924
Overall Steps per Second: 3,115.44353

Timestep Collection Time: 13.29181
Timestep Consumption Time: 2.76241
PPO Batch Consumption Time: 0.05814
Total Iteration Time: 16.05421

Cumulative Model Updates: 49,930
Cumulative Timesteps: 832,822,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 832822286...
Checkpoint 832822286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730,856.78808
Policy Entropy: 1.10508
Value Function Loss: 4.02522

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.08295

Collected Steps per Second: 4,019.84241
Overall Steps per Second: 3,280.39159

Timestep Collection Time: 12.44228
Timestep Consumption Time: 2.80468
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 15.24696

Cumulative Model Updates: 49,933
Cumulative Timesteps: 832,872,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,423.60247
Policy Entropy: 1.09445
Value Function Loss: 3.92272

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.08220

Collected Steps per Second: 3,812.47470
Overall Steps per Second: 3,154.25218

Timestep Collection Time: 13.11641
Timestep Consumption Time: 2.73711
PPO Batch Consumption Time: 0.06863
Total Iteration Time: 15.85352

Cumulative Model Updates: 49,936
Cumulative Timesteps: 832,922,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 832922308...
Checkpoint 832922308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,503.61218
Policy Entropy: 1.08481
Value Function Loss: 4.19210

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.15659
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.08161

Collected Steps per Second: 4,128.95279
Overall Steps per Second: 3,313.25134

Timestep Collection Time: 12.12123
Timestep Consumption Time: 2.98417
PPO Batch Consumption Time: 0.05789
Total Iteration Time: 15.10540

Cumulative Model Updates: 49,939
Cumulative Timesteps: 832,972,356

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,731.82040
Policy Entropy: 1.08882
Value Function Loss: 4.27204

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.08112

Collected Steps per Second: 3,879.92214
Overall Steps per Second: 3,172.93230

Timestep Collection Time: 12.89356
Timestep Consumption Time: 2.87293
PPO Batch Consumption Time: 0.06134
Total Iteration Time: 15.76649

Cumulative Model Updates: 49,942
Cumulative Timesteps: 833,022,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 833022382...
Checkpoint 833022382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,921.98977
Policy Entropy: 1.09600
Value Function Loss: 4.22355

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.08459

Collected Steps per Second: 3,804.28376
Overall Steps per Second: 3,214.74339

Timestep Collection Time: 13.14571
Timestep Consumption Time: 2.41074
PPO Batch Consumption Time: 0.06284
Total Iteration Time: 15.55645

Cumulative Model Updates: 49,945
Cumulative Timesteps: 833,072,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,753.94500
Policy Entropy: 1.08304
Value Function Loss: 3.98407

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.08101

Collected Steps per Second: 3,860.64051
Overall Steps per Second: 3,157.62442

Timestep Collection Time: 12.95951
Timestep Consumption Time: 2.88532
PPO Batch Consumption Time: 0.05909
Total Iteration Time: 15.84482

Cumulative Model Updates: 49,948
Cumulative Timesteps: 833,122,424

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 833122424...
Checkpoint 833122424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565,189.86803
Policy Entropy: 1.09835
Value Function Loss: 4.03477

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.08423

Collected Steps per Second: 3,807.88163
Overall Steps per Second: 3,140.74817

Timestep Collection Time: 13.13906
Timestep Consumption Time: 2.79090
PPO Batch Consumption Time: 0.06566
Total Iteration Time: 15.92996

Cumulative Model Updates: 49,951
Cumulative Timesteps: 833,172,456

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,143.70167
Policy Entropy: 1.09644
Value Function Loss: 4.17851

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.08193

Collected Steps per Second: 3,896.55676
Overall Steps per Second: 3,199.62908

Timestep Collection Time: 12.84211
Timestep Consumption Time: 2.79721
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 15.63931

Cumulative Model Updates: 49,954
Cumulative Timesteps: 833,222,496

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 833222496...
Checkpoint 833222496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,584.07620
Policy Entropy: 1.09285
Value Function Loss: 4.27131

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.08138

Collected Steps per Second: 3,909.43953
Overall Steps per Second: 3,202.81367

Timestep Collection Time: 12.79723
Timestep Consumption Time: 2.82341
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 15.62064

Cumulative Model Updates: 49,957
Cumulative Timesteps: 833,272,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,403.75559
Policy Entropy: 1.09084
Value Function Loss: 4.26338

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.09095

Collected Steps per Second: 3,812.03772
Overall Steps per Second: 3,190.86248

Timestep Collection Time: 13.12421
Timestep Consumption Time: 2.55493
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 15.67915

Cumulative Model Updates: 49,960
Cumulative Timesteps: 833,322,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 833322556...
Checkpoint 833322556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,608.80764
Policy Entropy: 1.11028
Value Function Loss: 4.24707

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.10503

Collected Steps per Second: 3,798.94221
Overall Steps per Second: 3,158.21980

Timestep Collection Time: 13.16261
Timestep Consumption Time: 2.67036
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 15.83297

Cumulative Model Updates: 49,963
Cumulative Timesteps: 833,372,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,341.96070
Policy Entropy: 1.10645
Value Function Loss: 4.39934

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.10615

Collected Steps per Second: 3,758.77270
Overall Steps per Second: 3,150.50049

Timestep Collection Time: 13.31126
Timestep Consumption Time: 2.57003
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 15.88129

Cumulative Model Updates: 49,966
Cumulative Timesteps: 833,422,594

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 833422594...
Checkpoint 833422594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,228.80444
Policy Entropy: 1.09894
Value Function Loss: 4.40140

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.06441
Value Function Update Magnitude: 0.09698

Collected Steps per Second: 3,809.70379
Overall Steps per Second: 3,077.15982

Timestep Collection Time: 13.12753
Timestep Consumption Time: 3.12512
PPO Batch Consumption Time: 0.06523
Total Iteration Time: 16.25265

Cumulative Model Updates: 49,969
Cumulative Timesteps: 833,472,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,871.15199
Policy Entropy: 1.08572
Value Function Loss: 4.33475

Mean KL Divergence: 0.02846
SB3 Clip Fraction: 0.16181
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.09724

Collected Steps per Second: 3,767.72928
Overall Steps per Second: 2,877.76916

Timestep Collection Time: 13.27696
Timestep Consumption Time: 4.10595
PPO Batch Consumption Time: 0.06375
Total Iteration Time: 17.38291

Cumulative Model Updates: 49,972
Cumulative Timesteps: 833,522,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 833522630...
Checkpoint 833522630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,014.43914
Policy Entropy: 1.10123
Value Function Loss: 4.15411

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.09804

Collected Steps per Second: 3,868.82763
Overall Steps per Second: 3,128.43184

Timestep Collection Time: 12.93312
Timestep Consumption Time: 3.06084
PPO Batch Consumption Time: 0.05225
Total Iteration Time: 15.99396

Cumulative Model Updates: 49,975
Cumulative Timesteps: 833,572,666

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,883.94666
Policy Entropy: 1.09696
Value Function Loss: 4.11965

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.08898

Collected Steps per Second: 3,881.80418
Overall Steps per Second: 3,193.32543

Timestep Collection Time: 12.88885
Timestep Consumption Time: 2.77883
PPO Batch Consumption Time: 0.06184
Total Iteration Time: 15.66768

Cumulative Model Updates: 49,978
Cumulative Timesteps: 833,622,698

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 833622698...
Checkpoint 833622698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,894.09791
Policy Entropy: 1.09265
Value Function Loss: 4.22908

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 3,830.16502
Overall Steps per Second: 3,194.17795

Timestep Collection Time: 13.06523
Timestep Consumption Time: 2.60140
PPO Batch Consumption Time: 0.06467
Total Iteration Time: 15.66663

Cumulative Model Updates: 49,981
Cumulative Timesteps: 833,672,740

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,635.26712
Policy Entropy: 1.09260
Value Function Loss: 4.33699

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.11087

Collected Steps per Second: 3,871.83492
Overall Steps per Second: 3,167.41173

Timestep Collection Time: 12.91584
Timestep Consumption Time: 2.87245
PPO Batch Consumption Time: 0.06367
Total Iteration Time: 15.78829

Cumulative Model Updates: 49,984
Cumulative Timesteps: 833,722,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 833722748...
Checkpoint 833722748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,513.63893
Policy Entropy: 1.09329
Value Function Loss: 4.26818

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.06452
Value Function Update Magnitude: 0.10716

Collected Steps per Second: 3,794.28464
Overall Steps per Second: 3,123.79133

Timestep Collection Time: 13.18562
Timestep Consumption Time: 2.83017
PPO Batch Consumption Time: 0.05839
Total Iteration Time: 16.01579

Cumulative Model Updates: 49,987
Cumulative Timesteps: 833,772,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,612.67561
Policy Entropy: 1.09468
Value Function Loss: 4.30776

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.06582
Value Function Update Magnitude: 0.09711

Collected Steps per Second: 4,084.97306
Overall Steps per Second: 3,370.69609

Timestep Collection Time: 12.24635
Timestep Consumption Time: 2.59510
PPO Batch Consumption Time: 0.05383
Total Iteration Time: 14.84144

Cumulative Model Updates: 49,990
Cumulative Timesteps: 833,822,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 833822804...
Checkpoint 833822804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,899.98711
Policy Entropy: 1.09826
Value Function Loss: 4.16099

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.09845

Collected Steps per Second: 4,135.13009
Overall Steps per Second: 3,359.33455

Timestep Collection Time: 12.09297
Timestep Consumption Time: 2.79272
PPO Batch Consumption Time: 0.05093
Total Iteration Time: 14.88569

Cumulative Model Updates: 49,993
Cumulative Timesteps: 833,872,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,430.09929
Policy Entropy: 1.10467
Value Function Loss: 4.15375

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.10129

Collected Steps per Second: 3,895.80410
Overall Steps per Second: 3,268.56007

Timestep Collection Time: 12.83791
Timestep Consumption Time: 2.46362
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 15.30154

Cumulative Model Updates: 49,996
Cumulative Timesteps: 833,922,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 833922824...
Checkpoint 833922824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,002.31302
Policy Entropy: 1.10059
Value Function Loss: 4.02326

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.10651

Collected Steps per Second: 3,799.00984
Overall Steps per Second: 3,137.26332

Timestep Collection Time: 13.16554
Timestep Consumption Time: 2.77702
PPO Batch Consumption Time: 0.05887
Total Iteration Time: 15.94256

Cumulative Model Updates: 49,999
Cumulative Timesteps: 833,972,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,984.84279
Policy Entropy: 1.10900
Value Function Loss: 4.11636

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.11530

Collected Steps per Second: 3,862.75377
Overall Steps per Second: 3,176.16325

Timestep Collection Time: 12.95294
Timestep Consumption Time: 2.80003
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 15.75297

Cumulative Model Updates: 50,002
Cumulative Timesteps: 834,022,874

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 834022874...
Checkpoint 834022874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,768.46776
Policy Entropy: 1.09852
Value Function Loss: 4.24553

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.11630

Collected Steps per Second: 4,102.41778
Overall Steps per Second: 3,305.43954

Timestep Collection Time: 12.18842
Timestep Consumption Time: 2.93876
PPO Batch Consumption Time: 0.06081
Total Iteration Time: 15.12719

Cumulative Model Updates: 50,005
Cumulative Timesteps: 834,072,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,564.91520
Policy Entropy: 1.09174
Value Function Loss: 4.38404

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.11425

Collected Steps per Second: 3,721.21048
Overall Steps per Second: 3,088.54212

Timestep Collection Time: 13.44455
Timestep Consumption Time: 2.75403
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 16.19858

Cumulative Model Updates: 50,008
Cumulative Timesteps: 834,122,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 834122906...
Checkpoint 834122906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,301.67563
Policy Entropy: 1.10489
Value Function Loss: 4.26717

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.11393

Collected Steps per Second: 3,825.22667
Overall Steps per Second: 3,208.65485

Timestep Collection Time: 13.07530
Timestep Consumption Time: 2.51254
PPO Batch Consumption Time: 0.06209
Total Iteration Time: 15.58784

Cumulative Model Updates: 50,011
Cumulative Timesteps: 834,172,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,475.10693
Policy Entropy: 1.10528
Value Function Loss: 4.18267

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.15131
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.11351

Collected Steps per Second: 3,904.51602
Overall Steps per Second: 3,212.15430

Timestep Collection Time: 12.80722
Timestep Consumption Time: 2.76052
PPO Batch Consumption Time: 0.06616
Total Iteration Time: 15.56775

Cumulative Model Updates: 50,014
Cumulative Timesteps: 834,222,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 834222928...
Checkpoint 834222928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,743.28477
Policy Entropy: 1.08594
Value Function Loss: 4.01407

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.15054
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.11899

Collected Steps per Second: 3,788.71044
Overall Steps per Second: 3,140.02311

Timestep Collection Time: 13.20713
Timestep Consumption Time: 2.72842
PPO Batch Consumption Time: 0.06386
Total Iteration Time: 15.93555

Cumulative Model Updates: 50,017
Cumulative Timesteps: 834,272,966

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,546.98474
Policy Entropy: 1.10147
Value Function Loss: 3.98081

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 4,145.94008
Overall Steps per Second: 3,375.10471

Timestep Collection Time: 12.06144
Timestep Consumption Time: 2.75469
PPO Batch Consumption Time: 0.05901
Total Iteration Time: 14.81613

Cumulative Model Updates: 50,020
Cumulative Timesteps: 834,322,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 834322972...
Checkpoint 834322972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,437.70409
Policy Entropy: 1.10251
Value Function Loss: 3.95465

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.10072

Collected Steps per Second: 4,073.34447
Overall Steps per Second: 3,308.66007

Timestep Collection Time: 12.27934
Timestep Consumption Time: 2.83795
PPO Batch Consumption Time: 0.06856
Total Iteration Time: 15.11730

Cumulative Model Updates: 50,023
Cumulative Timesteps: 834,372,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,379.73160
Policy Entropy: 1.10033
Value Function Loss: 3.97162

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.09071

Collected Steps per Second: 3,884.62424
Overall Steps per Second: 3,233.34694

Timestep Collection Time: 12.87538
Timestep Consumption Time: 2.59342
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 15.46880

Cumulative Model Updates: 50,026
Cumulative Timesteps: 834,423,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 834423006...
Checkpoint 834423006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,349.72336
Policy Entropy: 1.09549
Value Function Loss: 3.93720

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.16188
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.09615

Collected Steps per Second: 3,752.24999
Overall Steps per Second: 3,094.76942

Timestep Collection Time: 13.33440
Timestep Consumption Time: 2.83288
PPO Batch Consumption Time: 0.05851
Total Iteration Time: 16.16728

Cumulative Model Updates: 50,029
Cumulative Timesteps: 834,473,040

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,329.37132
Policy Entropy: 1.10830
Value Function Loss: 4.06780

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.10648

Collected Steps per Second: 3,792.74294
Overall Steps per Second: 3,176.86391

Timestep Collection Time: 13.18887
Timestep Consumption Time: 2.55685
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 15.74572

Cumulative Model Updates: 50,032
Cumulative Timesteps: 834,523,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 834523062...
Checkpoint 834523062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,804.74719
Policy Entropy: 1.11352
Value Function Loss: 4.15155

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.09908

Collected Steps per Second: 3,772.37850
Overall Steps per Second: 3,093.64590

Timestep Collection Time: 13.25848
Timestep Consumption Time: 2.90885
PPO Batch Consumption Time: 0.05850
Total Iteration Time: 16.16733

Cumulative Model Updates: 50,035
Cumulative Timesteps: 834,573,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,432.49643
Policy Entropy: 1.10268
Value Function Loss: 4.33296

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.11296

Collected Steps per Second: 3,898.55276
Overall Steps per Second: 3,219.39042

Timestep Collection Time: 12.83451
Timestep Consumption Time: 2.70757
PPO Batch Consumption Time: 0.06394
Total Iteration Time: 15.54207

Cumulative Model Updates: 50,038
Cumulative Timesteps: 834,623,114

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 834623114...
Checkpoint 834623114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,275.98637
Policy Entropy: 1.08202
Value Function Loss: 4.27034

Mean KL Divergence: 0.03074
SB3 Clip Fraction: 0.17176
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.12221

Collected Steps per Second: 3,885.93702
Overall Steps per Second: 3,174.41856

Timestep Collection Time: 12.87566
Timestep Consumption Time: 2.88597
PPO Batch Consumption Time: 0.05270
Total Iteration Time: 15.76163

Cumulative Model Updates: 50,041
Cumulative Timesteps: 834,673,148

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,838.10349
Policy Entropy: 1.09611
Value Function Loss: 4.27216

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.11772

Collected Steps per Second: 3,794.85201
Overall Steps per Second: 3,134.00574

Timestep Collection Time: 13.18523
Timestep Consumption Time: 2.78028
PPO Batch Consumption Time: 0.06069
Total Iteration Time: 15.96551

Cumulative Model Updates: 50,044
Cumulative Timesteps: 834,723,184

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 834723184...
Checkpoint 834723184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650,766.32725
Policy Entropy: 1.09809
Value Function Loss: 4.24702

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.06291
Value Function Update Magnitude: 0.12478

Collected Steps per Second: 3,780.32295
Overall Steps per Second: 3,145.43234

Timestep Collection Time: 13.22903
Timestep Consumption Time: 2.67022
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 15.89925

Cumulative Model Updates: 50,047
Cumulative Timesteps: 834,773,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,992.55882
Policy Entropy: 1.09305
Value Function Loss: 4.13703

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.11851

Collected Steps per Second: 3,857.12391
Overall Steps per Second: 3,152.36064

Timestep Collection Time: 12.96977
Timestep Consumption Time: 2.89961
PPO Batch Consumption Time: 0.06245
Total Iteration Time: 15.86938

Cumulative Model Updates: 50,050
Cumulative Timesteps: 834,823,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 834823220...
Checkpoint 834823220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504,354.50525
Policy Entropy: 1.07976
Value Function Loss: 4.05253

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.15965
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.11361

Collected Steps per Second: 3,836.48461
Overall Steps per Second: 3,174.40480

Timestep Collection Time: 13.04267
Timestep Consumption Time: 2.72029
PPO Batch Consumption Time: 0.06145
Total Iteration Time: 15.76296

Cumulative Model Updates: 50,053
Cumulative Timesteps: 834,873,258

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,025.18297
Policy Entropy: 1.09423
Value Function Loss: 4.04854

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.12333

Collected Steps per Second: 3,941.82908
Overall Steps per Second: 3,213.27676

Timestep Collection Time: 12.68650
Timestep Consumption Time: 2.87643
PPO Batch Consumption Time: 0.06415
Total Iteration Time: 15.56293

Cumulative Model Updates: 50,056
Cumulative Timesteps: 834,923,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 834923266...
Checkpoint 834923266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,504.48041
Policy Entropy: 1.10141
Value Function Loss: 4.02286

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.12542

Collected Steps per Second: 3,959.82610
Overall Steps per Second: 3,290.20673

Timestep Collection Time: 12.62934
Timestep Consumption Time: 2.57031
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 15.19965

Cumulative Model Updates: 50,059
Cumulative Timesteps: 834,973,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,039.25829
Policy Entropy: 1.08782
Value Function Loss: 4.11422

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.10513

Collected Steps per Second: 3,823.03381
Overall Steps per Second: 3,195.68689

Timestep Collection Time: 13.09117
Timestep Consumption Time: 2.56993
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 15.66111

Cumulative Model Updates: 50,062
Cumulative Timesteps: 835,023,324

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 835023324...
Checkpoint 835023324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,444.67548
Policy Entropy: 1.07315
Value Function Loss: 4.07184

Mean KL Divergence: 0.03028
SB3 Clip Fraction: 0.16654
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.08669

Collected Steps per Second: 3,825.00597
Overall Steps per Second: 3,157.30795

Timestep Collection Time: 13.07449
Timestep Consumption Time: 2.76495
PPO Batch Consumption Time: 0.06050
Total Iteration Time: 15.83944

Cumulative Model Updates: 50,065
Cumulative Timesteps: 835,073,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592,651.23562
Policy Entropy: 1.07909
Value Function Loss: 4.12369

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.11103
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.08216

Collected Steps per Second: 3,799.77168
Overall Steps per Second: 3,143.62558

Timestep Collection Time: 13.16237
Timestep Consumption Time: 2.74729
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 15.90966

Cumulative Model Updates: 50,068
Cumulative Timesteps: 835,123,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 835123348...
Checkpoint 835123348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,947.61569
Policy Entropy: 1.07765
Value Function Loss: 4.12432

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.06426
Value Function Update Magnitude: 0.08364

Collected Steps per Second: 3,919.19827
Overall Steps per Second: 3,215.31037

Timestep Collection Time: 12.76383
Timestep Consumption Time: 2.79423
PPO Batch Consumption Time: 0.05937
Total Iteration Time: 15.55806

Cumulative Model Updates: 50,071
Cumulative Timesteps: 835,173,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735,615.00422
Policy Entropy: 1.07038
Value Function Loss: 4.26233

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.06936
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 3,753.18280
Overall Steps per Second: 3,102.74636

Timestep Collection Time: 13.33375
Timestep Consumption Time: 2.79519
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 16.12894

Cumulative Model Updates: 50,074
Cumulative Timesteps: 835,223,416

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 835223416...
Checkpoint 835223416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,428.07763
Policy Entropy: 1.08911
Value Function Loss: 4.21778

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.06254
Value Function Update Magnitude: 0.07017

Collected Steps per Second: 3,963.21802
Overall Steps per Second: 3,297.93872

Timestep Collection Time: 12.62661
Timestep Consumption Time: 2.54711
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 15.17372

Cumulative Model Updates: 50,077
Cumulative Timesteps: 835,273,458

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,030.98752
Policy Entropy: 1.08249
Value Function Loss: 4.16641

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.06100

Collected Steps per Second: 4,069.16550
Overall Steps per Second: 3,280.70726

Timestep Collection Time: 12.29245
Timestep Consumption Time: 2.95427
PPO Batch Consumption Time: 0.06362
Total Iteration Time: 15.24671

Cumulative Model Updates: 50,080
Cumulative Timesteps: 835,323,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 835323478...
Checkpoint 835323478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,751.12105
Policy Entropy: 1.09194
Value Function Loss: 4.05223

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.06516
Value Function Update Magnitude: 0.05653

Collected Steps per Second: 3,832.54029
Overall Steps per Second: 3,202.68261

Timestep Collection Time: 13.05661
Timestep Consumption Time: 2.56779
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 15.62440

Cumulative Model Updates: 50,083
Cumulative Timesteps: 835,373,518

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,228.90629
Policy Entropy: 1.07568
Value Function Loss: 4.19541

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.05603

Collected Steps per Second: 3,849.51191
Overall Steps per Second: 3,184.63934

Timestep Collection Time: 12.99697
Timestep Consumption Time: 2.71344
PPO Batch Consumption Time: 0.05421
Total Iteration Time: 15.71041

Cumulative Model Updates: 50,086
Cumulative Timesteps: 835,423,550

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 835423550...
Checkpoint 835423550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543,404.90872
Policy Entropy: 1.07594
Value Function Loss: 4.26464

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.05220

Collected Steps per Second: 3,872.08356
Overall Steps per Second: 3,207.92575

Timestep Collection Time: 12.91346
Timestep Consumption Time: 2.67356
PPO Batch Consumption Time: 0.05354
Total Iteration Time: 15.58702

Cumulative Model Updates: 50,089
Cumulative Timesteps: 835,473,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,690.89118
Policy Entropy: 1.08635
Value Function Loss: 4.31588

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.05905

Collected Steps per Second: 3,906.73151
Overall Steps per Second: 3,197.64230

Timestep Collection Time: 12.81122
Timestep Consumption Time: 2.84094
PPO Batch Consumption Time: 0.06879
Total Iteration Time: 15.65216

Cumulative Model Updates: 50,092
Cumulative Timesteps: 835,523,602

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 835523602...
Checkpoint 835523602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,415.39618
Policy Entropy: 1.09184
Value Function Loss: 4.35855

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.07125
Value Function Update Magnitude: 0.06317

Collected Steps per Second: 3,858.60991
Overall Steps per Second: 3,177.11091

Timestep Collection Time: 12.96944
Timestep Consumption Time: 2.78198
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 15.75142

Cumulative Model Updates: 50,095
Cumulative Timesteps: 835,573,646

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,342.98675
Policy Entropy: 1.09043
Value Function Loss: 4.24532

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.08189
Value Function Update Magnitude: 0.06911

Collected Steps per Second: 3,747.52138
Overall Steps per Second: 3,126.52429

Timestep Collection Time: 13.34749
Timestep Consumption Time: 2.65111
PPO Batch Consumption Time: 0.06724
Total Iteration Time: 15.99860

Cumulative Model Updates: 50,098
Cumulative Timesteps: 835,623,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 835623666...
Checkpoint 835623666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,799.98840
Policy Entropy: 1.08779
Value Function Loss: 4.09561

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.07822
Value Function Update Magnitude: 0.07754

Collected Steps per Second: 3,793.63315
Overall Steps per Second: 3,121.29258

Timestep Collection Time: 13.18736
Timestep Consumption Time: 2.84062
PPO Batch Consumption Time: 0.06107
Total Iteration Time: 16.02798

Cumulative Model Updates: 50,101
Cumulative Timesteps: 835,673,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,538.82814
Policy Entropy: 1.08882
Value Function Loss: 3.90020

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.07901
Value Function Update Magnitude: 0.07390

Collected Steps per Second: 3,794.86076
Overall Steps per Second: 3,060.77281

Timestep Collection Time: 13.18151
Timestep Consumption Time: 3.16142
PPO Batch Consumption Time: 0.06564
Total Iteration Time: 16.34293

Cumulative Model Updates: 50,104
Cumulative Timesteps: 835,723,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 835723716...
Checkpoint 835723716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,199.77001
Policy Entropy: 1.08676
Value Function Loss: 4.04056

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.08194
Value Function Update Magnitude: 0.07624

Collected Steps per Second: 3,861.43679
Overall Steps per Second: 3,172.13878

Timestep Collection Time: 12.94855
Timestep Consumption Time: 2.81369
PPO Batch Consumption Time: 0.06176
Total Iteration Time: 15.76224

Cumulative Model Updates: 50,107
Cumulative Timesteps: 835,773,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,700.22113
Policy Entropy: 1.09289
Value Function Loss: 4.17618

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.07215
Value Function Update Magnitude: 0.07689

Collected Steps per Second: 3,748.07343
Overall Steps per Second: 3,098.26504

Timestep Collection Time: 13.34872
Timestep Consumption Time: 2.79967
PPO Batch Consumption Time: 0.06198
Total Iteration Time: 16.14839

Cumulative Model Updates: 50,110
Cumulative Timesteps: 835,823,748

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 835823748...
Checkpoint 835823748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718,641.39286
Policy Entropy: 1.10352
Value Function Loss: 4.41164

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.06796
Value Function Update Magnitude: 0.07912

Collected Steps per Second: 3,752.38858
Overall Steps per Second: 3,144.45311

Timestep Collection Time: 13.33444
Timestep Consumption Time: 2.57803
PPO Batch Consumption Time: 0.06278
Total Iteration Time: 15.91247

Cumulative Model Updates: 50,113
Cumulative Timesteps: 835,873,784

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,153.49784
Policy Entropy: 1.11317
Value Function Loss: 4.19013

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.16662
Policy Update Magnitude: 0.06172
Value Function Update Magnitude: 0.09112

Collected Steps per Second: 3,881.95336
Overall Steps per Second: 3,174.84799

Timestep Collection Time: 12.88733
Timestep Consumption Time: 2.87028
PPO Batch Consumption Time: 0.06021
Total Iteration Time: 15.75760

Cumulative Model Updates: 50,116
Cumulative Timesteps: 835,923,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 835923812...
Checkpoint 835923812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,649.13621
Policy Entropy: 1.09497
Value Function Loss: 4.22207

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.09996

Collected Steps per Second: 3,907.31699
Overall Steps per Second: 3,266.70324

Timestep Collection Time: 12.79958
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.06045
Total Iteration Time: 15.30962

Cumulative Model Updates: 50,119
Cumulative Timesteps: 835,973,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,206.78633
Policy Entropy: 1.10580
Value Function Loss: 4.28169

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.09628

Collected Steps per Second: 3,954.89054
Overall Steps per Second: 3,226.62646

Timestep Collection Time: 12.65370
Timestep Consumption Time: 2.85600
PPO Batch Consumption Time: 0.06382
Total Iteration Time: 15.50970

Cumulative Model Updates: 50,122
Cumulative Timesteps: 836,023,868

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 836023868...
Checkpoint 836023868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,045.64802
Policy Entropy: 1.10674
Value Function Loss: 4.33895

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.09988

Collected Steps per Second: 3,819.64070
Overall Steps per Second: 3,151.11254

Timestep Collection Time: 13.10280
Timestep Consumption Time: 2.77984
PPO Batch Consumption Time: 0.05283
Total Iteration Time: 15.88264

Cumulative Model Updates: 50,125
Cumulative Timesteps: 836,073,916

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726,550.67236
Policy Entropy: 1.11514
Value Function Loss: 4.33097

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.09962

Collected Steps per Second: 3,898.60516
Overall Steps per Second: 3,263.66510

Timestep Collection Time: 12.83331
Timestep Consumption Time: 2.49670
PPO Batch Consumption Time: 0.06299
Total Iteration Time: 15.33000

Cumulative Model Updates: 50,128
Cumulative Timesteps: 836,123,948

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 836123948...
Checkpoint 836123948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,079.10165
Policy Entropy: 1.11862
Value Function Loss: 4.16427

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.06590
Value Function Update Magnitude: 0.10238

Collected Steps per Second: 3,815.67352
Overall Steps per Second: 3,148.74760

Timestep Collection Time: 13.10804
Timestep Consumption Time: 2.77637
PPO Batch Consumption Time: 0.06925
Total Iteration Time: 15.88441

Cumulative Model Updates: 50,131
Cumulative Timesteps: 836,173,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,573.41844
Policy Entropy: 1.11211
Value Function Loss: 4.28677

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.07425
Value Function Update Magnitude: 0.11178

Collected Steps per Second: 3,812.65265
Overall Steps per Second: 3,201.62927

Timestep Collection Time: 13.11790
Timestep Consumption Time: 2.50352
PPO Batch Consumption Time: 0.04924
Total Iteration Time: 15.62142

Cumulative Model Updates: 50,134
Cumulative Timesteps: 836,223,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 836223978...
Checkpoint 836223978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,381.18407
Policy Entropy: 1.11460
Value Function Loss: 4.32956

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.06744
Value Function Update Magnitude: 0.11549

Collected Steps per Second: 3,791.87797
Overall Steps per Second: 3,111.42060

Timestep Collection Time: 13.19874
Timestep Consumption Time: 2.88652
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 16.08526

Cumulative Model Updates: 50,137
Cumulative Timesteps: 836,274,026

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,647.34788
Policy Entropy: 1.11722
Value Function Loss: 4.53767

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.11870

Collected Steps per Second: 3,862.40628
Overall Steps per Second: 3,217.65071

Timestep Collection Time: 12.95358
Timestep Consumption Time: 2.59565
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 15.54923

Cumulative Model Updates: 50,140
Cumulative Timesteps: 836,324,058

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 836324058...
Checkpoint 836324058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,105.73012
Policy Entropy: 1.12746
Value Function Loss: 4.40608

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.11456

Collected Steps per Second: 3,945.19925
Overall Steps per Second: 3,358.45141

Timestep Collection Time: 12.68124
Timestep Consumption Time: 2.21551
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 14.89675

Cumulative Model Updates: 50,143
Cumulative Timesteps: 836,374,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,970.62609
Policy Entropy: 1.12657
Value Function Loss: 4.47901

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.09852

Collected Steps per Second: 4,414.01268
Overall Steps per Second: 3,535.62819

Timestep Collection Time: 11.33209
Timestep Consumption Time: 2.81532
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 14.14742

Cumulative Model Updates: 50,146
Cumulative Timesteps: 836,424,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 836424108...
Checkpoint 836424108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,911.98905
Policy Entropy: 1.12546
Value Function Loss: 4.32280

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.09058

Collected Steps per Second: 5,693.56489
Overall Steps per Second: 5,242.79734

Timestep Collection Time: 8.78501
Timestep Consumption Time: 0.75532
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 9.54033

Cumulative Model Updates: 50,149
Cumulative Timesteps: 836,474,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 836474126...
Checkpoint 836474126 saved!
