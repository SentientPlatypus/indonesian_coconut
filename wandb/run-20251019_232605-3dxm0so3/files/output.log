Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059,612.17794
Policy Entropy: 1.08381
Value Function Loss: 2.98790

Mean KL Divergence: -0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.02643
Value Function Update Magnitude: 0.03565

Collected Steps per Second: 3,390.45707
Overall Steps per Second: 2,834.32633

Timestep Collection Time: 14.76025
Timestep Consumption Time: 2.89615
PPO Batch Consumption Time: 0.60994
Total Iteration Time: 17.65640

Cumulative Model Updates: 59,956
Cumulative Timesteps: 1,000,073,882

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248,907.96398
Policy Entropy: 1.03341
Value Function Loss: 2.66736

Mean KL Divergence: 0.13141
SB3 Clip Fraction: 0.28596
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.07390

Collected Steps per Second: 3,730.63099
Overall Steps per Second: 3,131.17924

Timestep Collection Time: 13.40470
Timestep Consumption Time: 2.56628
PPO Batch Consumption Time: 0.05272
Total Iteration Time: 15.97098

Cumulative Model Updates: 59,958
Cumulative Timesteps: 1,000,123,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1000123890...
Checkpoint 1000123890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417,325.81876
Policy Entropy: 1.02388
Value Function Loss: 2.59091

Mean KL Divergence: 0.20386
SB3 Clip Fraction: 0.32434
Policy Update Magnitude: 0.07474
Value Function Update Magnitude: 0.10021

Collected Steps per Second: 4,132.15197
Overall Steps per Second: 3,403.71539

Timestep Collection Time: 12.11088
Timestep Consumption Time: 2.59188
PPO Batch Consumption Time: 0.06479
Total Iteration Time: 14.70276

Cumulative Model Updates: 59,961
Cumulative Timesteps: 1,000,173,934

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889,922.07522
Policy Entropy: 1.05673
Value Function Loss: 2.36175

Mean KL Divergence: 0.08296
SB3 Clip Fraction: 0.29539
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.07928

Collected Steps per Second: 4,170.05150
Overall Steps per Second: 3,415.72670

Timestep Collection Time: 11.99074
Timestep Consumption Time: 2.64802
PPO Batch Consumption Time: 0.06209
Total Iteration Time: 14.63876

Cumulative Model Updates: 59,964
Cumulative Timesteps: 1,000,223,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1000223936...
Checkpoint 1000223936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,816,120.23685
Policy Entropy: 1.01767
Value Function Loss: 2.27512

Mean KL Divergence: 0.10526
SB3 Clip Fraction: 0.32051
Policy Update Magnitude: 0.06355
Value Function Update Magnitude: 0.06982

Collected Steps per Second: 4,310.94094
Overall Steps per Second: 3,554.93228

Timestep Collection Time: 11.60396
Timestep Consumption Time: 2.46775
PPO Batch Consumption Time: 0.04990
Total Iteration Time: 14.07172

Cumulative Model Updates: 59,967
Cumulative Timesteps: 1,000,273,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652,105.29775
Policy Entropy: 1.04474
Value Function Loss: 2.28171

Mean KL Divergence: 0.05709
SB3 Clip Fraction: 0.24961
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.06856

Collected Steps per Second: 4,050.63214
Overall Steps per Second: 3,319.34640

Timestep Collection Time: 12.34523
Timestep Consumption Time: 2.71978
PPO Batch Consumption Time: 0.05950
Total Iteration Time: 15.06501

Cumulative Model Updates: 59,970
Cumulative Timesteps: 1,000,323,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1000323966...
Checkpoint 1000323966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,778,511.45535
Policy Entropy: 1.01097
Value Function Loss: 2.25654

Mean KL Divergence: 0.06332
SB3 Clip Fraction: 0.29051
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.07420

Collected Steps per Second: 4,110.01581
Overall Steps per Second: 3,444.14577

Timestep Collection Time: 12.17027
Timestep Consumption Time: 2.35293
PPO Batch Consumption Time: 0.05806
Total Iteration Time: 14.52319

Cumulative Model Updates: 59,973
Cumulative Timesteps: 1,000,373,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357,743.03128
Policy Entropy: 1.02288
Value Function Loss: 2.22038

Mean KL Divergence: 0.03021
SB3 Clip Fraction: 0.18391
Policy Update Magnitude: 0.06029
Value Function Update Magnitude: 0.07355

Collected Steps per Second: 4,255.14912
Overall Steps per Second: 3,474.86930

Timestep Collection Time: 11.75282
Timestep Consumption Time: 2.63909
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 14.39191

Cumulative Model Updates: 59,976
Cumulative Timesteps: 1,000,423,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1000423996...
Checkpoint 1000423996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506,436.20317
Policy Entropy: 1.01812
Value Function Loss: 2.15290

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.16391
Policy Update Magnitude: 0.06441
Value Function Update Magnitude: 0.07313

Collected Steps per Second: 4,189.02935
Overall Steps per Second: 3,460.22424

Timestep Collection Time: 11.94358
Timestep Consumption Time: 2.51560
PPO Batch Consumption Time: 0.06600
Total Iteration Time: 14.45918

Cumulative Model Updates: 59,979
Cumulative Timesteps: 1,000,474,028

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,855,964.35568
Policy Entropy: 0.99799
Value Function Loss: 2.11281

Mean KL Divergence: 0.03487
SB3 Clip Fraction: 0.24092
Policy Update Magnitude: 0.06711
Value Function Update Magnitude: 0.07541

Collected Steps per Second: 3,817.17199
Overall Steps per Second: 3,218.01881

Timestep Collection Time: 13.10499
Timestep Consumption Time: 2.43998
PPO Batch Consumption Time: 0.05265
Total Iteration Time: 15.54497

Cumulative Model Updates: 59,982
Cumulative Timesteps: 1,000,524,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1000524052...
Checkpoint 1000524052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688,732.61133
Policy Entropy: 1.02014
Value Function Loss: 2.06682

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.16551
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.06830

Collected Steps per Second: 3,754.76718
Overall Steps per Second: 3,139.24101

Timestep Collection Time: 13.31960
Timestep Consumption Time: 2.61164
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 15.93124

Cumulative Model Updates: 59,985
Cumulative Timesteps: 1,000,574,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514,840.37093
Policy Entropy: 1.01416
Value Function Loss: 2.02510

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.16825
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.07057

Collected Steps per Second: 3,726.77423
Overall Steps per Second: 3,155.40687

Timestep Collection Time: 13.41911
Timestep Consumption Time: 2.42987
PPO Batch Consumption Time: 0.06077
Total Iteration Time: 15.84899

Cumulative Model Updates: 59,988
Cumulative Timesteps: 1,000,624,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1000624074...
Checkpoint 1000624074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661,803.74885
Policy Entropy: 1.00533
Value Function Loss: 2.06102

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.18196
Policy Update Magnitude: 0.06947
Value Function Update Magnitude: 0.08163

Collected Steps per Second: 3,605.86890
Overall Steps per Second: 3,042.17057

Timestep Collection Time: 13.87405
Timestep Consumption Time: 2.57079
PPO Batch Consumption Time: 0.05295
Total Iteration Time: 16.44484

Cumulative Model Updates: 59,991
Cumulative Timesteps: 1,000,674,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,968,720.05483
Policy Entropy: 0.97791
Value Function Loss: 1.99486

Mean KL Divergence: 0.04448
SB3 Clip Fraction: 0.27275
Policy Update Magnitude: 0.06527
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 3,807.47423
Overall Steps per Second: 3,214.25721

Timestep Collection Time: 13.13942
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.05408
Total Iteration Time: 15.56440

Cumulative Model Updates: 59,994
Cumulative Timesteps: 1,000,724,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1000724130...
Checkpoint 1000724130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443,012.75851
Policy Entropy: 0.99639
Value Function Loss: 2.07233

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.16203
Policy Update Magnitude: 0.06565
Value Function Update Magnitude: 0.11566

Collected Steps per Second: 3,859.54669
Overall Steps per Second: 3,254.61210

Timestep Collection Time: 12.96318
Timestep Consumption Time: 2.40947
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 15.37265

Cumulative Model Updates: 59,997
Cumulative Timesteps: 1,000,774,162

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497,748.96117
Policy Entropy: 0.99556
Value Function Loss: 1.95337

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.16615
Policy Update Magnitude: 0.07589
Value Function Update Magnitude: 0.13153

Collected Steps per Second: 3,651.64468
Overall Steps per Second: 3,057.24999

Timestep Collection Time: 13.70670
Timestep Consumption Time: 2.66488
PPO Batch Consumption Time: 0.05270
Total Iteration Time: 16.37158

Cumulative Model Updates: 60,000
Cumulative Timesteps: 1,000,824,214

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1000824214...
Checkpoint 1000824214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710,122.65546
Policy Entropy: 0.98322
Value Function Loss: 1.93978

Mean KL Divergence: 0.03083
SB3 Clip Fraction: 0.22162
Policy Update Magnitude: 0.07426
Value Function Update Magnitude: 0.12299

Collected Steps per Second: 3,567.81097
Overall Steps per Second: 2,933.45848

Timestep Collection Time: 14.01700
Timestep Consumption Time: 3.03114
PPO Batch Consumption Time: 0.05809
Total Iteration Time: 17.04814

Cumulative Model Updates: 60,003
Cumulative Timesteps: 1,000,874,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,942,084.55880
Policy Entropy: 1.00305
Value Function Loss: 1.84682

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.17076
Policy Update Magnitude: 0.06502
Value Function Update Magnitude: 0.10533

Collected Steps per Second: 3,574.12571
Overall Steps per Second: 2,982.98445

Timestep Collection Time: 13.98944
Timestep Consumption Time: 2.77230
PPO Batch Consumption Time: 0.05885
Total Iteration Time: 16.76174

Cumulative Model Updates: 60,006
Cumulative Timesteps: 1,000,924,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1000924224...
Checkpoint 1000924224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820,411.42336
Policy Entropy: 0.99880
Value Function Loss: 1.87521

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.17629
Policy Update Magnitude: 0.06229
Value Function Update Magnitude: 0.09842

Collected Steps per Second: 3,640.91564
Overall Steps per Second: 3,037.21977

Timestep Collection Time: 13.73556
Timestep Consumption Time: 2.73016
PPO Batch Consumption Time: 0.06608
Total Iteration Time: 16.46572

Cumulative Model Updates: 60,009
Cumulative Timesteps: 1,000,974,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538,950.48029
Policy Entropy: 0.97982
Value Function Loss: 1.82918

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.16162
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.09170

Collected Steps per Second: 4,033.20497
Overall Steps per Second: 3,342.44393

Timestep Collection Time: 12.40205
Timestep Consumption Time: 2.56305
PPO Batch Consumption Time: 0.05926
Total Iteration Time: 14.96510

Cumulative Model Updates: 60,012
Cumulative Timesteps: 1,001,024,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1001024254...
Checkpoint 1001024254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531,795.29597
Policy Entropy: 0.96901
Value Function Loss: 1.90023

Mean KL Divergence: 0.02863
SB3 Clip Fraction: 0.23011
Policy Update Magnitude: 0.06745
Value Function Update Magnitude: 0.08628

Collected Steps per Second: 4,079.04839
Overall Steps per Second: 3,347.61459

Timestep Collection Time: 12.26512
Timestep Consumption Time: 2.67985
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 14.94497

Cumulative Model Updates: 60,015
Cumulative Timesteps: 1,001,074,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561,266.80332
Policy Entropy: 0.99416
Value Function Loss: 1.84015

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.06648
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 4,255.37331
Overall Steps per Second: 3,479.27581

Timestep Collection Time: 11.75455
Timestep Consumption Time: 2.62200
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 14.37655

Cumulative Model Updates: 60,018
Cumulative Timesteps: 1,001,124,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1001124304...
Checkpoint 1001124304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759,683.69393
Policy Entropy: 0.99428
Value Function Loss: 1.98222

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.07774
Value Function Update Magnitude: 0.10061

Collected Steps per Second: 3,948.21605
Overall Steps per Second: 3,285.41017

Timestep Collection Time: 12.66395
Timestep Consumption Time: 2.55485
PPO Batch Consumption Time: 0.06303
Total Iteration Time: 15.21880

Cumulative Model Updates: 60,021
Cumulative Timesteps: 1,001,174,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417,355.64092
Policy Entropy: 0.98466
Value Function Loss: 1.94537

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.08515
Value Function Update Magnitude: 0.10776

Collected Steps per Second: 3,938.37227
Overall Steps per Second: 3,265.49513

Timestep Collection Time: 12.69865
Timestep Consumption Time: 2.61664
PPO Batch Consumption Time: 0.06175
Total Iteration Time: 15.31529

Cumulative Model Updates: 60,024
Cumulative Timesteps: 1,001,224,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1001224316...
Checkpoint 1001224316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476,022.41919
Policy Entropy: 0.96374
Value Function Loss: 1.97086

Mean KL Divergence: 0.02445
SB3 Clip Fraction: 0.20320
Policy Update Magnitude: 0.08359
Value Function Update Magnitude: 0.12195

Collected Steps per Second: 4,199.89259
Overall Steps per Second: 3,484.25004

Timestep Collection Time: 11.91173
Timestep Consumption Time: 2.44659
PPO Batch Consumption Time: 0.06525
Total Iteration Time: 14.35833

Cumulative Model Updates: 60,027
Cumulative Timesteps: 1,001,274,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690,308.35544
Policy Entropy: 0.98243
Value Function Loss: 1.92286

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.17329
Policy Update Magnitude: 0.07111
Value Function Update Magnitude: 0.10904

Collected Steps per Second: 4,024.62903
Overall Steps per Second: 3,433.18868

Timestep Collection Time: 12.43493
Timestep Consumption Time: 2.14218
PPO Batch Consumption Time: 0.05958
Total Iteration Time: 14.57712

Cumulative Model Updates: 60,030
Cumulative Timesteps: 1,001,324,390

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1001324390...
Checkpoint 1001324390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212,642.78448
Policy Entropy: 0.98898
Value Function Loss: 2.00155

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.18718
Policy Update Magnitude: 0.06583
Value Function Update Magnitude: 0.09558

Collected Steps per Second: 4,117.73402
Overall Steps per Second: 3,395.26872

Timestep Collection Time: 12.15523
Timestep Consumption Time: 2.58646
PPO Batch Consumption Time: 0.06116
Total Iteration Time: 14.74169

Cumulative Model Updates: 60,033
Cumulative Timesteps: 1,001,374,442

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278,029.47834
Policy Entropy: 0.98327
Value Function Loss: 1.98466

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.18501
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.09904

Collected Steps per Second: 3,998.96631
Overall Steps per Second: 3,288.25365

Timestep Collection Time: 12.50473
Timestep Consumption Time: 2.70273
PPO Batch Consumption Time: 0.05919
Total Iteration Time: 15.20746

Cumulative Model Updates: 60,036
Cumulative Timesteps: 1,001,424,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1001424448...
Checkpoint 1001424448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930,376.30266
Policy Entropy: 0.98007
Value Function Loss: 1.92446

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.19347
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.09264

Collected Steps per Second: 4,193.12210
Overall Steps per Second: 3,489.52973

Timestep Collection Time: 11.93526
Timestep Consumption Time: 2.40650
PPO Batch Consumption Time: 0.05388
Total Iteration Time: 14.34176

Cumulative Model Updates: 60,039
Cumulative Timesteps: 1,001,474,494

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,367,282.75530
Policy Entropy: 0.99344
Value Function Loss: 2.03018

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.16248
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.09413

Collected Steps per Second: 3,948.02291
Overall Steps per Second: 3,274.72762

Timestep Collection Time: 12.66507
Timestep Consumption Time: 2.60398
PPO Batch Consumption Time: 0.05439
Total Iteration Time: 15.26906

Cumulative Model Updates: 60,042
Cumulative Timesteps: 1,001,524,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1001524496...
Checkpoint 1001524496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673,893.09846
Policy Entropy: 0.99688
Value Function Loss: 2.01237

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.18511
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.09863

Collected Steps per Second: 4,000.35555
Overall Steps per Second: 3,306.43179

Timestep Collection Time: 12.49889
Timestep Consumption Time: 2.62315
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 15.12204

Cumulative Model Updates: 60,045
Cumulative Timesteps: 1,001,574,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269,372.27411
Policy Entropy: 0.97688
Value Function Loss: 1.99076

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.09737

Collected Steps per Second: 3,854.00769
Overall Steps per Second: 3,240.86546

Timestep Collection Time: 12.97714
Timestep Consumption Time: 2.45516
PPO Batch Consumption Time: 0.05884
Total Iteration Time: 15.43230

Cumulative Model Updates: 60,048
Cumulative Timesteps: 1,001,624,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1001624510...
Checkpoint 1001624510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503,370.13382
Policy Entropy: 0.95985
Value Function Loss: 1.91662

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.18543
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.08870

Collected Steps per Second: 4,187.54998
Overall Steps per Second: 3,473.23839

Timestep Collection Time: 11.94016
Timestep Consumption Time: 2.45563
PPO Batch Consumption Time: 0.05299
Total Iteration Time: 14.39579

Cumulative Model Updates: 60,051
Cumulative Timesteps: 1,001,674,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678,292.33316
Policy Entropy: 0.97199
Value Function Loss: 1.97084

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.08393

Collected Steps per Second: 4,083.56993
Overall Steps per Second: 3,376.29397

Timestep Collection Time: 12.24566
Timestep Consumption Time: 2.56526
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 14.81091

Cumulative Model Updates: 60,054
Cumulative Timesteps: 1,001,724,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1001724516...
Checkpoint 1001724516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869,601.67398
Policy Entropy: 0.98313
Value Function Loss: 2.00695

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.06459
Value Function Update Magnitude: 0.08179

Collected Steps per Second: 4,348.70945
Overall Steps per Second: 3,543.30048

Timestep Collection Time: 11.50640
Timestep Consumption Time: 2.61546
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 14.12186

Cumulative Model Updates: 60,057
Cumulative Timesteps: 1,001,774,554

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831,285.67456
Policy Entropy: 0.96519
Value Function Loss: 1.93383

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.17219
Policy Update Magnitude: 0.06365
Value Function Update Magnitude: 0.09207

Collected Steps per Second: 4,009.87929
Overall Steps per Second: 3,289.66585

Timestep Collection Time: 12.47220
Timestep Consumption Time: 2.73056
PPO Batch Consumption Time: 0.06109
Total Iteration Time: 15.20276

Cumulative Model Updates: 60,060
Cumulative Timesteps: 1,001,824,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1001824566...
Checkpoint 1001824566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945,931.85385
Policy Entropy: 0.95756
Value Function Loss: 1.98679

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.20521
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.09478

Collected Steps per Second: 4,335.22768
Overall Steps per Second: 3,568.87372

Timestep Collection Time: 11.53434
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.06826
Total Iteration Time: 14.01114

Cumulative Model Updates: 60,063
Cumulative Timesteps: 1,001,874,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721,255.88125
Policy Entropy: 0.97179
Value Function Loss: 1.98447

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.09328

Collected Steps per Second: 4,057.19258
Overall Steps per Second: 3,422.60464

Timestep Collection Time: 12.33414
Timestep Consumption Time: 2.28688
PPO Batch Consumption Time: 0.05831
Total Iteration Time: 14.62103

Cumulative Model Updates: 60,066
Cumulative Timesteps: 1,001,924,612

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1001924612...
Checkpoint 1001924612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641,442.48570
Policy Entropy: 0.97806
Value Function Loss: 2.13409

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.17591
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 4,049.58844
Overall Steps per Second: 3,389.61710

Timestep Collection Time: 12.35582
Timestep Consumption Time: 2.40573
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 14.76155

Cumulative Model Updates: 60,069
Cumulative Timesteps: 1,001,974,648

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958,248.43886
Policy Entropy: 0.96179
Value Function Loss: 1.99576

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.06502
Value Function Update Magnitude: 0.07518

Collected Steps per Second: 4,236.48932
Overall Steps per Second: 3,526.59340

Timestep Collection Time: 11.80459
Timestep Consumption Time: 2.37624
PPO Batch Consumption Time: 0.05902
Total Iteration Time: 14.18082

Cumulative Model Updates: 60,072
Cumulative Timesteps: 1,002,024,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1002024658...
Checkpoint 1002024658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551,535.03478
Policy Entropy: 0.95938
Value Function Loss: 2.07958

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.16425
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.07234

Collected Steps per Second: 4,282.17894
Overall Steps per Second: 3,469.62559

Timestep Collection Time: 11.68517
Timestep Consumption Time: 2.73656
PPO Batch Consumption Time: 0.05902
Total Iteration Time: 14.42173

Cumulative Model Updates: 60,075
Cumulative Timesteps: 1,002,074,696

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,394,264.16296
Policy Entropy: 0.97581
Value Function Loss: 2.07359

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15503
Policy Update Magnitude: 0.06601
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 4,328.06565
Overall Steps per Second: 3,573.35935

Timestep Collection Time: 11.56082
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.05968
Total Iteration Time: 14.00251

Cumulative Model Updates: 60,078
Cumulative Timesteps: 1,002,124,732

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1002124732...
Checkpoint 1002124732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843,048.90018
Policy Entropy: 0.98974
Value Function Loss: 2.11226

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.20483
Policy Update Magnitude: 0.06993
Value Function Update Magnitude: 0.07836

Collected Steps per Second: 4,124.96212
Overall Steps per Second: 3,358.17100

Timestep Collection Time: 12.13102
Timestep Consumption Time: 2.76995
PPO Batch Consumption Time: 0.05926
Total Iteration Time: 14.90097

Cumulative Model Updates: 60,081
Cumulative Timesteps: 1,002,174,772

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399,128.49711
Policy Entropy: 0.97386
Value Function Loss: 2.02074

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.15128
Policy Update Magnitude: 0.06909
Value Function Update Magnitude: 0.08705

Collected Steps per Second: 4,130.75599
Overall Steps per Second: 3,377.77675

Timestep Collection Time: 12.11401
Timestep Consumption Time: 2.70047
PPO Batch Consumption Time: 0.06021
Total Iteration Time: 14.81448

Cumulative Model Updates: 60,084
Cumulative Timesteps: 1,002,224,812

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1002224812...
Checkpoint 1002224812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,167,752.87816
Policy Entropy: 0.97743
Value Function Loss: 1.91029

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.15860
Policy Update Magnitude: 0.06708
Value Function Update Magnitude: 0.08479

Collected Steps per Second: 4,110.66758
Overall Steps per Second: 3,402.81182

Timestep Collection Time: 12.17175
Timestep Consumption Time: 2.53198
PPO Batch Consumption Time: 0.06437
Total Iteration Time: 14.70372

Cumulative Model Updates: 60,087
Cumulative Timesteps: 1,002,274,846

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869,719.45951
Policy Entropy: 0.99304
Value Function Loss: 1.98532

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.15839
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.08229

Collected Steps per Second: 4,321.44415
Overall Steps per Second: 3,542.93976

Timestep Collection Time: 11.58039
Timestep Consumption Time: 2.54461
PPO Batch Consumption Time: 0.06500
Total Iteration Time: 14.12499

Cumulative Model Updates: 60,090
Cumulative Timesteps: 1,002,324,890

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1002324890...
Checkpoint 1002324890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464,381.93954
Policy Entropy: 1.00194
Value Function Loss: 2.03839

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.19429
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.08631

Collected Steps per Second: 4,122.16350
Overall Steps per Second: 3,429.22368

Timestep Collection Time: 12.13586
Timestep Consumption Time: 2.45228
PPO Batch Consumption Time: 0.05952
Total Iteration Time: 14.58814

Cumulative Model Updates: 60,093
Cumulative Timesteps: 1,002,374,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415,840.36543
Policy Entropy: 0.98495
Value Function Loss: 2.10949

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.08481

Collected Steps per Second: 4,259.00134
Overall Steps per Second: 3,538.77143

Timestep Collection Time: 11.74219
Timestep Consumption Time: 2.38983
PPO Batch Consumption Time: 0.05395
Total Iteration Time: 14.13202

Cumulative Model Updates: 60,096
Cumulative Timesteps: 1,002,424,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1002424926...
Checkpoint 1002424926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702,169.28706
Policy Entropy: 0.96440
Value Function Loss: 2.09480

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.15990
Policy Update Magnitude: 0.06765
Value Function Update Magnitude: 0.09910

Collected Steps per Second: 4,274.38053
Overall Steps per Second: 3,574.87565

Timestep Collection Time: 11.69994
Timestep Consumption Time: 2.28936
PPO Batch Consumption Time: 0.05981
Total Iteration Time: 13.98930

Cumulative Model Updates: 60,099
Cumulative Timesteps: 1,002,474,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337,025.11386
Policy Entropy: 0.99037
Value Function Loss: 2.09719

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.17336
Policy Update Magnitude: 0.06428
Value Function Update Magnitude: 0.09116

Collected Steps per Second: 4,286.89734
Overall Steps per Second: 3,577.78868

Timestep Collection Time: 11.67558
Timestep Consumption Time: 2.31407
PPO Batch Consumption Time: 0.06433
Total Iteration Time: 13.98965

Cumulative Model Updates: 60,102
Cumulative Timesteps: 1,002,524,988

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1002524988...
Checkpoint 1002524988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723,987.73692
Policy Entropy: 0.99509
Value Function Loss: 2.05249

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.18684
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.09162

Collected Steps per Second: 4,106.97786
Overall Steps per Second: 3,422.09321

Timestep Collection Time: 12.18317
Timestep Consumption Time: 2.43829
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 14.62146

Cumulative Model Updates: 60,105
Cumulative Timesteps: 1,002,575,024

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888,231.22425
Policy Entropy: 0.98442
Value Function Loss: 2.05540

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.06254
Value Function Update Magnitude: 0.08688

Collected Steps per Second: 3,889.48846
Overall Steps per Second: 3,275.92699

Timestep Collection Time: 12.86185
Timestep Consumption Time: 2.40895
PPO Batch Consumption Time: 0.05932
Total Iteration Time: 15.27079

Cumulative Model Updates: 60,108
Cumulative Timesteps: 1,002,625,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1002625050...
Checkpoint 1002625050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606,016.55319
Policy Entropy: 0.97901
Value Function Loss: 2.01590

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.19693
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.08503

Collected Steps per Second: 4,066.09406
Overall Steps per Second: 3,339.58970

Timestep Collection Time: 12.30075
Timestep Consumption Time: 2.67594
PPO Batch Consumption Time: 0.06019
Total Iteration Time: 14.97669

Cumulative Model Updates: 60,111
Cumulative Timesteps: 1,002,675,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616,539.81163
Policy Entropy: 0.99461
Value Function Loss: 1.99751

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.08228

Collected Steps per Second: 4,207.08455
Overall Steps per Second: 3,400.44793

Timestep Collection Time: 11.88899
Timestep Consumption Time: 2.82025
PPO Batch Consumption Time: 0.06139
Total Iteration Time: 14.70924

Cumulative Model Updates: 60,114
Cumulative Timesteps: 1,002,725,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1002725084...
Checkpoint 1002725084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421,604.97809
Policy Entropy: 1.00601
Value Function Loss: 2.08731

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.17056
Policy Update Magnitude: 0.06948
Value Function Update Magnitude: 0.09943

Collected Steps per Second: 4,063.87056
Overall Steps per Second: 3,337.25947

Timestep Collection Time: 12.31092
Timestep Consumption Time: 2.68042
PPO Batch Consumption Time: 0.05222
Total Iteration Time: 14.99134

Cumulative Model Updates: 60,117
Cumulative Timesteps: 1,002,775,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,113,421.58723
Policy Entropy: 0.97414
Value Function Loss: 2.22800

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.15649
Policy Update Magnitude: 0.06795
Value Function Update Magnitude: 0.10951

Collected Steps per Second: 4,170.61862
Overall Steps per Second: 3,405.99267

Timestep Collection Time: 11.99007
Timestep Consumption Time: 2.69170
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 14.68177

Cumulative Model Updates: 60,120
Cumulative Timesteps: 1,002,825,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1002825120...
Checkpoint 1002825120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,961.32095
Policy Entropy: 0.97238
Value Function Loss: 2.19904

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.17289
Policy Update Magnitude: 0.06690
Value Function Update Magnitude: 0.10858

Collected Steps per Second: 4,353.10341
Overall Steps per Second: 3,665.71226

Timestep Collection Time: 11.48927
Timestep Consumption Time: 2.15446
PPO Batch Consumption Time: 0.05155
Total Iteration Time: 13.64373

Cumulative Model Updates: 60,123
Cumulative Timesteps: 1,002,875,134

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578,426.31657
Policy Entropy: 0.98422
Value Function Loss: 2.17367

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.16331
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.10043

Collected Steps per Second: 4,388.50484
Overall Steps per Second: 3,671.68071

Timestep Collection Time: 11.39659
Timestep Consumption Time: 2.22496
PPO Batch Consumption Time: 0.05325
Total Iteration Time: 13.62155

Cumulative Model Updates: 60,126
Cumulative Timesteps: 1,002,925,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1002925148...
Checkpoint 1002925148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432,011.16532
Policy Entropy: 0.99327
Value Function Loss: 1.97794

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.18157
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.09939

Collected Steps per Second: 4,377.77232
Overall Steps per Second: 3,575.39845

Timestep Collection Time: 11.42864
Timestep Consumption Time: 2.56476
PPO Batch Consumption Time: 0.05978
Total Iteration Time: 13.99341

Cumulative Model Updates: 60,129
Cumulative Timesteps: 1,002,975,180

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441,900.15204
Policy Entropy: 0.97870
Value Function Loss: 2.05079

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.14932
Policy Update Magnitude: 0.06302
Value Function Update Magnitude: 0.08981

Collected Steps per Second: 4,165.50407
Overall Steps per Second: 3,412.21634

Timestep Collection Time: 12.00335
Timestep Consumption Time: 2.64988
PPO Batch Consumption Time: 0.07348
Total Iteration Time: 14.65323

Cumulative Model Updates: 60,132
Cumulative Timesteps: 1,003,025,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1003025180...
Checkpoint 1003025180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,680,640.84087
Policy Entropy: 0.97386
Value Function Loss: 2.03237

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.17731
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.08866

Collected Steps per Second: 4,364.81035
Overall Steps per Second: 3,582.22794

Timestep Collection Time: 11.45846
Timestep Consumption Time: 2.50324
PPO Batch Consumption Time: 0.05091
Total Iteration Time: 13.96170

Cumulative Model Updates: 60,135
Cumulative Timesteps: 1,003,075,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842,446.54959
Policy Entropy: 0.97903
Value Function Loss: 2.12742

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.09562

Collected Steps per Second: 4,380.87248
Overall Steps per Second: 3,589.54946

Timestep Collection Time: 11.42010
Timestep Consumption Time: 2.51758
PPO Batch Consumption Time: 0.06127
Total Iteration Time: 13.93768

Cumulative Model Updates: 60,138
Cumulative Timesteps: 1,003,125,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1003125224...
Checkpoint 1003125224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739,932.71313
Policy Entropy: 0.99116
Value Function Loss: 2.13568

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.18973
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.09531

Collected Steps per Second: 4,050.96664
Overall Steps per Second: 3,397.54965

Timestep Collection Time: 12.34866
Timestep Consumption Time: 2.37489
PPO Batch Consumption Time: 0.05339
Total Iteration Time: 14.72355

Cumulative Model Updates: 60,141
Cumulative Timesteps: 1,003,175,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642,754.97166
Policy Entropy: 0.97674
Value Function Loss: 2.10242

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.08604

Collected Steps per Second: 4,153.76565
Overall Steps per Second: 3,471.19345

Timestep Collection Time: 12.04353
Timestep Consumption Time: 2.36823
PPO Batch Consumption Time: 0.04977
Total Iteration Time: 14.41176

Cumulative Model Updates: 60,144
Cumulative Timesteps: 1,003,225,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1003225274...
Checkpoint 1003225274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450,128.67236
Policy Entropy: 0.97164
Value Function Loss: 2.02260

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.19758
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.10768

Collected Steps per Second: 4,058.02519
Overall Steps per Second: 3,369.74639

Timestep Collection Time: 12.32816
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 14.84622

Cumulative Model Updates: 60,147
Cumulative Timesteps: 1,003,275,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,390,411.39368
Policy Entropy: 1.00224
Value Function Loss: 1.99980

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.15593
Policy Update Magnitude: 0.06621
Value Function Update Magnitude: 0.13458

Collected Steps per Second: 4,330.03240
Overall Steps per Second: 3,556.06493

Timestep Collection Time: 11.55234
Timestep Consumption Time: 2.51433
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 14.06667

Cumulative Model Updates: 60,150
Cumulative Timesteps: 1,003,325,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1003325324...
Checkpoint 1003325324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,824,325.62924
Policy Entropy: 0.99124
Value Function Loss: 2.04128

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.06787
Value Function Update Magnitude: 0.12255

Collected Steps per Second: 4,290.37885
Overall Steps per Second: 3,521.63579

Timestep Collection Time: 11.65958
Timestep Consumption Time: 2.54519
PPO Batch Consumption Time: 0.06324
Total Iteration Time: 14.20476

Cumulative Model Updates: 60,153
Cumulative Timesteps: 1,003,375,348

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656,870.54535
Policy Entropy: 0.98827
Value Function Loss: 2.05512

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.07799
Value Function Update Magnitude: 0.10364

Collected Steps per Second: 4,190.39954
Overall Steps per Second: 3,394.05083

Timestep Collection Time: 11.94301
Timestep Consumption Time: 2.80220
PPO Batch Consumption Time: 0.06355
Total Iteration Time: 14.74521

Cumulative Model Updates: 60,156
Cumulative Timesteps: 1,003,425,394

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1003425394...
Checkpoint 1003425394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041,342.19453
Policy Entropy: 0.97111
Value Function Loss: 2.03004

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.07758
Value Function Update Magnitude: 0.09818

Collected Steps per Second: 3,597.58802
Overall Steps per Second: 3,010.72685

Timestep Collection Time: 13.90209
Timestep Consumption Time: 2.70984
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 16.61194

Cumulative Model Updates: 60,159
Cumulative Timesteps: 1,003,475,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769,885.54507
Policy Entropy: 0.97716
Value Function Loss: 2.04400

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.07764
Value Function Update Magnitude: 0.08758

Collected Steps per Second: 3,639.24736
Overall Steps per Second: 3,030.74226

Timestep Collection Time: 13.74460
Timestep Consumption Time: 2.75961
PPO Batch Consumption Time: 0.06081
Total Iteration Time: 16.50421

Cumulative Model Updates: 60,162
Cumulative Timesteps: 1,003,525,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1003525428...
Checkpoint 1003525428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,611,000.42834
Policy Entropy: 0.97078
Value Function Loss: 2.07321

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.07962
Value Function Update Magnitude: 0.09450

Collected Steps per Second: 3,480.06557
Overall Steps per Second: 2,939.87727

Timestep Collection Time: 14.37387
Timestep Consumption Time: 2.64113
PPO Batch Consumption Time: 0.06713
Total Iteration Time: 17.01500

Cumulative Model Updates: 60,165
Cumulative Timesteps: 1,003,575,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896,906.96959
Policy Entropy: 0.97683
Value Function Loss: 2.16607

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.07828
Value Function Update Magnitude: 0.09272

Collected Steps per Second: 3,664.15822
Overall Steps per Second: 3,073.08653

Timestep Collection Time: 13.64679
Timestep Consumption Time: 2.62480
PPO Batch Consumption Time: 0.06536
Total Iteration Time: 16.27159

Cumulative Model Updates: 60,168
Cumulative Timesteps: 1,003,625,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1003625454...
Checkpoint 1003625454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668,250.94484
Policy Entropy: 0.98688
Value Function Loss: 2.18009

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.07962
Value Function Update Magnitude: 0.09359

Collected Steps per Second: 3,688.58130
Overall Steps per Second: 3,073.27823

Timestep Collection Time: 13.56456
Timestep Consumption Time: 2.71577
PPO Batch Consumption Time: 0.06092
Total Iteration Time: 16.28034

Cumulative Model Updates: 60,171
Cumulative Timesteps: 1,003,675,488

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237,579.76587
Policy Entropy: 0.98981
Value Function Loss: 2.23284

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14595
Policy Update Magnitude: 0.08159
Value Function Update Magnitude: 0.09508

Collected Steps per Second: 3,648.46314
Overall Steps per Second: 3,054.54263

Timestep Collection Time: 13.71262
Timestep Consumption Time: 2.66626
PPO Batch Consumption Time: 0.06333
Total Iteration Time: 16.37888

Cumulative Model Updates: 60,174
Cumulative Timesteps: 1,003,725,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1003725518...
Checkpoint 1003725518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955,916.84108
Policy Entropy: 0.99093
Value Function Loss: 2.32425

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.07825
Value Function Update Magnitude: 0.09236

Collected Steps per Second: 3,598.84802
Overall Steps per Second: 3,023.17942

Timestep Collection Time: 13.90056
Timestep Consumption Time: 2.64692
PPO Batch Consumption Time: 0.05423
Total Iteration Time: 16.54748

Cumulative Model Updates: 60,177
Cumulative Timesteps: 1,003,775,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586,507.65975
Policy Entropy: 0.98798
Value Function Loss: 2.29481

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.16214
Policy Update Magnitude: 0.07717
Value Function Update Magnitude: 0.10219

Collected Steps per Second: 3,612.84936
Overall Steps per Second: 3,069.00002

Timestep Collection Time: 13.84392
Timestep Consumption Time: 2.45324
PPO Batch Consumption Time: 0.06274
Total Iteration Time: 16.29717

Cumulative Model Updates: 60,180
Cumulative Timesteps: 1,003,825,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1003825560...
Checkpoint 1003825560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216,384.26101
Policy Entropy: 0.99815
Value Function Loss: 2.22253

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.17563
Policy Update Magnitude: 0.07608
Value Function Update Magnitude: 0.10202

Collected Steps per Second: 3,514.33422
Overall Steps per Second: 2,954.62595

Timestep Collection Time: 14.23029
Timestep Consumption Time: 2.69571
PPO Batch Consumption Time: 0.05796
Total Iteration Time: 16.92600

Cumulative Model Updates: 60,183
Cumulative Timesteps: 1,003,875,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,681,020.13439
Policy Entropy: 0.98416
Value Function Loss: 2.08135

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.07450
Value Function Update Magnitude: 0.09567

Collected Steps per Second: 3,528.38055
Overall Steps per Second: 3,015.12096

Timestep Collection Time: 14.18044
Timestep Consumption Time: 2.41392
PPO Batch Consumption Time: 0.06732
Total Iteration Time: 16.59436

Cumulative Model Updates: 60,186
Cumulative Timesteps: 1,003,925,604

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1003925604...
Checkpoint 1003925604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838,559.40256
Policy Entropy: 0.98797
Value Function Loss: 2.12311

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.07723
Value Function Update Magnitude: 0.10359

Collected Steps per Second: 3,529.37293
Overall Steps per Second: 3,001.42579

Timestep Collection Time: 14.16796
Timestep Consumption Time: 2.49213
PPO Batch Consumption Time: 0.05938
Total Iteration Time: 16.66008

Cumulative Model Updates: 60,189
Cumulative Timesteps: 1,003,975,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066,004.00638
Policy Entropy: 0.99611
Value Function Loss: 2.10574

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.15668
Policy Update Magnitude: 0.07217
Value Function Update Magnitude: 0.10128

Collected Steps per Second: 3,600.01918
Overall Steps per Second: 3,000.86842

Timestep Collection Time: 13.89326
Timestep Consumption Time: 2.77392
PPO Batch Consumption Time: 0.05921
Total Iteration Time: 16.66718

Cumulative Model Updates: 60,192
Cumulative Timesteps: 1,004,025,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1004025624...
Checkpoint 1004025624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597,218.41624
Policy Entropy: 1.00990
Value Function Loss: 2.12047

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.07293
Value Function Update Magnitude: 0.09487

Collected Steps per Second: 3,655.42987
Overall Steps per Second: 3,058.23738

Timestep Collection Time: 13.68977
Timestep Consumption Time: 2.67325
PPO Batch Consumption Time: 0.05817
Total Iteration Time: 16.36302

Cumulative Model Updates: 60,195
Cumulative Timesteps: 1,004,075,666

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737,735.23674
Policy Entropy: 1.00824
Value Function Loss: 2.09899

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.07516
Value Function Update Magnitude: 0.09315

Collected Steps per Second: 3,589.66982
Overall Steps per Second: 3,004.92077

Timestep Collection Time: 13.93109
Timestep Consumption Time: 2.71095
PPO Batch Consumption Time: 0.06415
Total Iteration Time: 16.64204

Cumulative Model Updates: 60,198
Cumulative Timesteps: 1,004,125,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1004125674...
Checkpoint 1004125674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592,131.43135
Policy Entropy: 1.01394
Value Function Loss: 2.08728

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.07867
Value Function Update Magnitude: 0.09335

Collected Steps per Second: 3,459.02302
Overall Steps per Second: 2,903.32174

Timestep Collection Time: 14.46073
Timestep Consumption Time: 2.76781
PPO Batch Consumption Time: 0.05795
Total Iteration Time: 17.22854

Cumulative Model Updates: 60,201
Cumulative Timesteps: 1,004,175,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211,299.09200
Policy Entropy: 1.02040
Value Function Loss: 2.12835

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.08330
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 3,620.73990
Overall Steps per Second: 3,028.07177

Timestep Collection Time: 13.81927
Timestep Consumption Time: 2.70477
PPO Batch Consumption Time: 0.06727
Total Iteration Time: 16.52405

Cumulative Model Updates: 60,204
Cumulative Timesteps: 1,004,225,730

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1004225730...
Checkpoint 1004225730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564,631.09649
Policy Entropy: 1.02658
Value Function Loss: 2.18194

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.09053
Value Function Update Magnitude: 0.09383

Collected Steps per Second: 3,553.48066
Overall Steps per Second: 3,031.69832

Timestep Collection Time: 14.07747
Timestep Consumption Time: 2.42286
PPO Batch Consumption Time: 0.06055
Total Iteration Time: 16.50032

Cumulative Model Updates: 60,207
Cumulative Timesteps: 1,004,275,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633,065.60395
Policy Entropy: 1.02205
Value Function Loss: 2.11107

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.09446
Value Function Update Magnitude: 0.09971

Collected Steps per Second: 3,659.19410
Overall Steps per Second: 3,062.34348

Timestep Collection Time: 13.66476
Timestep Consumption Time: 2.66326
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 16.32802

Cumulative Model Updates: 60,210
Cumulative Timesteps: 1,004,325,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1004325756...
Checkpoint 1004325756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662,998.13441
Policy Entropy: 1.02069
Value Function Loss: 2.04157

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.09529
Value Function Update Magnitude: 0.09829

Collected Steps per Second: 3,777.92332
Overall Steps per Second: 3,179.54285

Timestep Collection Time: 13.23690
Timestep Consumption Time: 2.49115
PPO Batch Consumption Time: 0.06646
Total Iteration Time: 15.72805

Cumulative Model Updates: 60,213
Cumulative Timesteps: 1,004,375,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,093,675.70708
Policy Entropy: 1.01747
Value Function Loss: 1.96121

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.09380
Value Function Update Magnitude: 0.08753

Collected Steps per Second: 3,719.25893
Overall Steps per Second: 3,090.73019

Timestep Collection Time: 13.44676
Timestep Consumption Time: 2.73452
PPO Batch Consumption Time: 0.06819
Total Iteration Time: 16.18129

Cumulative Model Updates: 60,216
Cumulative Timesteps: 1,004,425,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1004425776...
Checkpoint 1004425776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514,721.12746
Policy Entropy: 1.01958
Value Function Loss: 2.08829

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.09388
Value Function Update Magnitude: 0.09759

Collected Steps per Second: 3,625.85232
Overall Steps per Second: 3,030.25138

Timestep Collection Time: 13.79317
Timestep Consumption Time: 2.71107
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 16.50424

Cumulative Model Updates: 60,219
Cumulative Timesteps: 1,004,475,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589,910.10512
Policy Entropy: 1.01049
Value Function Loss: 2.11512

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.09424
Value Function Update Magnitude: 0.12698

Collected Steps per Second: 3,681.32468
Overall Steps per Second: 3,060.07718

Timestep Collection Time: 13.59565
Timestep Consumption Time: 2.76015
PPO Batch Consumption Time: 0.06264
Total Iteration Time: 16.35580

Cumulative Model Updates: 60,222
Cumulative Timesteps: 1,004,525,838

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1004525838...
Checkpoint 1004525838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670,562.22046
Policy Entropy: 1.01935
Value Function Loss: 2.18580

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.08997
Value Function Update Magnitude: 0.12571

Collected Steps per Second: 3,504.31519
Overall Steps per Second: 2,934.38397

Timestep Collection Time: 14.26926
Timestep Consumption Time: 2.77145
PPO Batch Consumption Time: 0.05857
Total Iteration Time: 17.04071

Cumulative Model Updates: 60,225
Cumulative Timesteps: 1,004,575,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657,834.64871
Policy Entropy: 1.01238
Value Function Loss: 2.19753

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.08681
Value Function Update Magnitude: 0.11931

Collected Steps per Second: 3,580.39777
Overall Steps per Second: 2,967.55060

Timestep Collection Time: 13.96828
Timestep Consumption Time: 2.88468
PPO Batch Consumption Time: 0.06265
Total Iteration Time: 16.85296

Cumulative Model Updates: 60,228
Cumulative Timesteps: 1,004,625,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1004625854...
Checkpoint 1004625854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327,300.34327
Policy Entropy: 1.01620
Value Function Loss: 2.14216

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.09201
Value Function Update Magnitude: 0.11236

Collected Steps per Second: 3,610.13837
Overall Steps per Second: 3,004.23800

Timestep Collection Time: 13.85542
Timestep Consumption Time: 2.79439
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 16.64981

Cumulative Model Updates: 60,231
Cumulative Timesteps: 1,004,675,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607,913.34034
Policy Entropy: 1.02080
Value Function Loss: 2.08348

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.08947
Value Function Update Magnitude: 0.10482

Collected Steps per Second: 3,624.37585
Overall Steps per Second: 3,019.17539

Timestep Collection Time: 13.80045
Timestep Consumption Time: 2.76633
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 16.56678

Cumulative Model Updates: 60,234
Cumulative Timesteps: 1,004,725,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1004725892...
Checkpoint 1004725892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554,452.79991
Policy Entropy: 1.03360
Value Function Loss: 2.11466

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.08471
Value Function Update Magnitude: 0.09143

Collected Steps per Second: 3,665.80924
Overall Steps per Second: 3,047.14120

Timestep Collection Time: 13.65374
Timestep Consumption Time: 2.77215
PPO Batch Consumption Time: 0.06067
Total Iteration Time: 16.42589

Cumulative Model Updates: 60,237
Cumulative Timesteps: 1,004,775,944

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600,655.31430
Policy Entropy: 1.03390
Value Function Loss: 2.17391

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.08045
Value Function Update Magnitude: 0.08501

Collected Steps per Second: 3,578.40648
Overall Steps per Second: 3,002.09084

Timestep Collection Time: 13.97717
Timestep Consumption Time: 2.68322
PPO Batch Consumption Time: 0.06689
Total Iteration Time: 16.66039

Cumulative Model Updates: 60,240
Cumulative Timesteps: 1,004,825,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1004825960...
Checkpoint 1004825960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208,424.53462
Policy Entropy: 1.04293
Value Function Loss: 2.13816

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.08770
Value Function Update Magnitude: 0.10373

Collected Steps per Second: 3,628.46239
Overall Steps per Second: 3,086.45325

Timestep Collection Time: 13.78821
Timestep Consumption Time: 2.42133
PPO Batch Consumption Time: 0.06757
Total Iteration Time: 16.20954

Cumulative Model Updates: 60,243
Cumulative Timesteps: 1,004,875,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999,376.28858
Policy Entropy: 1.04648
Value Function Loss: 2.04559

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.09278
Value Function Update Magnitude: 0.09868

Collected Steps per Second: 3,603.91343
Overall Steps per Second: 3,062.94698

Timestep Collection Time: 13.87603
Timestep Consumption Time: 2.45073
PPO Batch Consumption Time: 0.06106
Total Iteration Time: 16.32676

Cumulative Model Updates: 60,246
Cumulative Timesteps: 1,004,925,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1004925998...
Checkpoint 1004925998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966,276.09540
Policy Entropy: 1.03627
Value Function Loss: 1.98872

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.15104
Policy Update Magnitude: 0.08999
Value Function Update Magnitude: 0.09305

Collected Steps per Second: 3,565.47791
Overall Steps per Second: 3,044.89444

Timestep Collection Time: 14.02954
Timestep Consumption Time: 2.39862
PPO Batch Consumption Time: 0.05384
Total Iteration Time: 16.42816

Cumulative Model Updates: 60,249
Cumulative Timesteps: 1,004,976,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493,320.22815
Policy Entropy: 1.05788
Value Function Loss: 2.01625

Mean KL Divergence: 0.02546
SB3 Clip Fraction: 0.18447
Policy Update Magnitude: 0.07375
Value Function Update Magnitude: 0.11408

Collected Steps per Second: 3,573.60958
Overall Steps per Second: 3,017.29638

Timestep Collection Time: 14.00153
Timestep Consumption Time: 2.58153
PPO Batch Consumption Time: 0.05914
Total Iteration Time: 16.58306

Cumulative Model Updates: 60,252
Cumulative Timesteps: 1,005,026,056

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1005026056...
Checkpoint 1005026056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353,909.17576
Policy Entropy: 1.06109
Value Function Loss: 2.08929

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.17287
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.12687

Collected Steps per Second: 3,720.21150
Overall Steps per Second: 3,062.67800

Timestep Collection Time: 13.44117
Timestep Consumption Time: 2.88572
PPO Batch Consumption Time: 0.06038
Total Iteration Time: 16.32689

Cumulative Model Updates: 60,255
Cumulative Timesteps: 1,005,076,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712,839.53856
Policy Entropy: 1.04934
Value Function Loss: 2.04623

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.06395
Value Function Update Magnitude: 0.12943

Collected Steps per Second: 3,758.07861
Overall Steps per Second: 3,106.42284

Timestep Collection Time: 13.30946
Timestep Consumption Time: 2.79202
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 16.10148

Cumulative Model Updates: 60,258
Cumulative Timesteps: 1,005,126,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1005126078...
Checkpoint 1005126078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278,911.02279
Policy Entropy: 1.04520
Value Function Loss: 2.10157

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.15700
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 3,600.03827
Overall Steps per Second: 3,003.08518

Timestep Collection Time: 13.90041
Timestep Consumption Time: 2.76312
PPO Batch Consumption Time: 0.05437
Total Iteration Time: 16.66353

Cumulative Model Updates: 60,261
Cumulative Timesteps: 1,005,176,120

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321,743.51559
Policy Entropy: 1.05987
Value Function Loss: 1.99802

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.10197

Collected Steps per Second: 3,646.77031
Overall Steps per Second: 3,053.46795

Timestep Collection Time: 13.72063
Timestep Consumption Time: 2.66598
PPO Batch Consumption Time: 0.06060
Total Iteration Time: 16.38661

Cumulative Model Updates: 60,264
Cumulative Timesteps: 1,005,226,156

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1005226156...
Checkpoint 1005226156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509,795.46347
Policy Entropy: 1.06472
Value Function Loss: 2.10232

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.16943
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.09547

Collected Steps per Second: 3,754.02654
Overall Steps per Second: 3,130.43636

Timestep Collection Time: 13.32596
Timestep Consumption Time: 2.65456
PPO Batch Consumption Time: 0.05867
Total Iteration Time: 15.98052

Cumulative Model Updates: 60,267
Cumulative Timesteps: 1,005,276,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101,081.54425
Policy Entropy: 1.03768
Value Function Loss: 1.95118

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.09953

Collected Steps per Second: 3,571.91989
Overall Steps per Second: 3,012.31352

Timestep Collection Time: 14.01319
Timestep Consumption Time: 2.60327
PPO Batch Consumption Time: 0.05902
Total Iteration Time: 16.61646

Cumulative Model Updates: 60,270
Cumulative Timesteps: 1,005,326,236

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1005326236...
Checkpoint 1005326236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808,733.63691
Policy Entropy: 1.05294
Value Function Loss: 1.93375

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.09203

Collected Steps per Second: 3,529.14098
Overall Steps per Second: 3,010.83943

Timestep Collection Time: 14.17115
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.05018
Total Iteration Time: 16.61065

Cumulative Model Updates: 60,273
Cumulative Timesteps: 1,005,376,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716,175.10748
Policy Entropy: 1.05845
Value Function Loss: 1.83021

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.07048
Value Function Update Magnitude: 0.09655

Collected Steps per Second: 3,730.73695
Overall Steps per Second: 3,095.48313

Timestep Collection Time: 13.41183
Timestep Consumption Time: 2.75237
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 16.16420

Cumulative Model Updates: 60,276
Cumulative Timesteps: 1,005,426,284

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1005426284...
Checkpoint 1005426284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467,795.38729
Policy Entropy: 1.05989
Value Function Loss: 1.93887

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.07585
Value Function Update Magnitude: 0.11228

Collected Steps per Second: 3,637.59173
Overall Steps per Second: 3,029.28860

Timestep Collection Time: 13.74756
Timestep Consumption Time: 2.76061
PPO Batch Consumption Time: 0.05982
Total Iteration Time: 16.50817

Cumulative Model Updates: 60,279
Cumulative Timesteps: 1,005,476,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232,976.24107
Policy Entropy: 1.05993
Value Function Loss: 2.01414

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.07970
Value Function Update Magnitude: 0.10086

Collected Steps per Second: 3,904.57608
Overall Steps per Second: 3,217.11159

Timestep Collection Time: 12.81215
Timestep Consumption Time: 2.73783
PPO Batch Consumption Time: 0.06485
Total Iteration Time: 15.54997

Cumulative Model Updates: 60,282
Cumulative Timesteps: 1,005,526,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1005526318...
Checkpoint 1005526318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654,068.12375
Policy Entropy: 1.05834
Value Function Loss: 2.10503

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.08330
Value Function Update Magnitude: 0.09594

Collected Steps per Second: 3,626.81555
Overall Steps per Second: 3,031.88288

Timestep Collection Time: 13.78896
Timestep Consumption Time: 2.70574
PPO Batch Consumption Time: 0.05202
Total Iteration Time: 16.49470

Cumulative Model Updates: 60,285
Cumulative Timesteps: 1,005,576,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147,827.34373
Policy Entropy: 1.06397
Value Function Loss: 2.12083

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.08037
Value Function Update Magnitude: 0.10963

Collected Steps per Second: 3,843.88532
Overall Steps per Second: 3,171.52614

Timestep Collection Time: 13.01964
Timestep Consumption Time: 2.76015
PPO Batch Consumption Time: 0.05084
Total Iteration Time: 15.77978

Cumulative Model Updates: 60,288
Cumulative Timesteps: 1,005,626,374

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1005626374...
Checkpoint 1005626374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430,826.63655
Policy Entropy: 1.05433
Value Function Loss: 2.09658

Mean KL Divergence: 0.02343
SB3 Clip Fraction: 0.16855
Policy Update Magnitude: 0.07621
Value Function Update Magnitude: 0.12731

Collected Steps per Second: 3,566.19351
Overall Steps per Second: 2,988.58819

Timestep Collection Time: 14.02952
Timestep Consumption Time: 2.71149
PPO Batch Consumption Time: 0.06542
Total Iteration Time: 16.74102

Cumulative Model Updates: 60,291
Cumulative Timesteps: 1,005,676,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403,474.57313
Policy Entropy: 1.06872
Value Function Loss: 2.09097

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.11996

Collected Steps per Second: 3,633.69577
Overall Steps per Second: 3,059.17560

Timestep Collection Time: 13.76285
Timestep Consumption Time: 2.58469
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 16.34754

Cumulative Model Updates: 60,294
Cumulative Timesteps: 1,005,726,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1005726416...
Checkpoint 1005726416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253,020.91222
Policy Entropy: 1.06374
Value Function Loss: 2.08170

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.06282
Value Function Update Magnitude: 0.09934

Collected Steps per Second: 3,887.03599
Overall Steps per Second: 3,203.14803

Timestep Collection Time: 12.87202
Timestep Consumption Time: 2.74824
PPO Batch Consumption Time: 0.06223
Total Iteration Time: 15.62026

Cumulative Model Updates: 60,297
Cumulative Timesteps: 1,005,776,450

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481,320.87686
Policy Entropy: 1.04781
Value Function Loss: 2.06723

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.05943
Value Function Update Magnitude: 0.08130

Collected Steps per Second: 3,664.96321
Overall Steps per Second: 3,083.66724

Timestep Collection Time: 13.65252
Timestep Consumption Time: 2.57361
PPO Batch Consumption Time: 0.05891
Total Iteration Time: 16.22613

Cumulative Model Updates: 60,300
Cumulative Timesteps: 1,005,826,486

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1005826486...
Checkpoint 1005826486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236,222.86510
Policy Entropy: 1.04045
Value Function Loss: 2.00377

Mean KL Divergence: 0.02763
SB3 Clip Fraction: 0.18804
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.06793

Collected Steps per Second: 3,932.35998
Overall Steps per Second: 3,714.57383

Timestep Collection Time: 12.71908
Timestep Consumption Time: 0.74572
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 13.46480

Cumulative Model Updates: 60,303
Cumulative Timesteps: 1,005,876,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,863.98059
Policy Entropy: 1.06291
Value Function Loss: 2.12263

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.06404

Collected Steps per Second: 10,321.69993
Overall Steps per Second: 8,927.97747

Timestep Collection Time: 4.84474
Timestep Consumption Time: 0.75630
PPO Batch Consumption Time: 0.03877
Total Iteration Time: 5.60104

Cumulative Model Updates: 60,306
Cumulative Timesteps: 1,005,926,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1005926508...
Checkpoint 1005926508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400,666.16083
Policy Entropy: 1.05058
Value Function Loss: 2.18188

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.06533

Collected Steps per Second: 11,189.25735
Overall Steps per Second: 9,761.73448

Timestep Collection Time: 4.47018
Timestep Consumption Time: 0.65370
PPO Batch Consumption Time: 0.03336
Total Iteration Time: 5.12388

Cumulative Model Updates: 60,309
Cumulative Timesteps: 1,005,976,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706,823.56866
Policy Entropy: 1.04973
Value Function Loss: 2.14009

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.06751
Value Function Update Magnitude: 0.07389

Collected Steps per Second: 11,561.69726
Overall Steps per Second: 9,769.65435

Timestep Collection Time: 4.32653
Timestep Consumption Time: 0.79361
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.12014

Cumulative Model Updates: 60,312
Cumulative Timesteps: 1,006,026,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1006026548...
Checkpoint 1006026548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557,428.66342
Policy Entropy: 1.04550
Value Function Loss: 1.93884

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.07042
Value Function Update Magnitude: 0.07656

Collected Steps per Second: 7,896.78670
Overall Steps per Second: 5,427.87781

Timestep Collection Time: 6.33574
Timestep Consumption Time: 2.88186
PPO Batch Consumption Time: 0.06410
Total Iteration Time: 9.21760

Cumulative Model Updates: 60,315
Cumulative Timesteps: 1,006,076,580

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589,860.03437
Policy Entropy: 1.03994
Value Function Loss: 1.91704

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.15668
Policy Update Magnitude: 0.06779
Value Function Update Magnitude: 0.09479

Collected Steps per Second: 3,618.23021
Overall Steps per Second: 3,007.30382

Timestep Collection Time: 13.82997
Timestep Consumption Time: 2.80952
PPO Batch Consumption Time: 0.06958
Total Iteration Time: 16.63949

Cumulative Model Updates: 60,318
Cumulative Timesteps: 1,006,126,620

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1006126620...
Checkpoint 1006126620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463,289.60775
Policy Entropy: 1.06306
Value Function Loss: 1.92726

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.06007
Value Function Update Magnitude: 0.11172

Collected Steps per Second: 3,564.41178
Overall Steps per Second: 3,005.21812

Timestep Collection Time: 14.03598
Timestep Consumption Time: 2.61173
PPO Batch Consumption Time: 0.06965
Total Iteration Time: 16.64771

Cumulative Model Updates: 60,321
Cumulative Timesteps: 1,006,176,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,665.75153
Policy Entropy: 1.05920
Value Function Loss: 2.12197

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.11064

Collected Steps per Second: 4,170.85212
Overall Steps per Second: 3,405.23495

Timestep Collection Time: 11.99323
Timestep Consumption Time: 2.69650
PPO Batch Consumption Time: 0.06495
Total Iteration Time: 14.68974

Cumulative Model Updates: 60,324
Cumulative Timesteps: 1,006,226,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1006226672...
Checkpoint 1006226672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584,809.49039
Policy Entropy: 1.04189
Value Function Loss: 2.09349

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.16085
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.10872

Collected Steps per Second: 3,729.07036
Overall Steps per Second: 3,129.57843

Timestep Collection Time: 13.42050
Timestep Consumption Time: 2.57079
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 15.99129

Cumulative Model Updates: 60,327
Cumulative Timesteps: 1,006,276,718

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170,661.58027
Policy Entropy: 1.03273
Value Function Loss: 2.18626

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.18999
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.11673

Collected Steps per Second: 3,960.13029
Overall Steps per Second: 3,336.96122

Timestep Collection Time: 12.62837
Timestep Consumption Time: 2.35832
PPO Batch Consumption Time: 0.05785
Total Iteration Time: 14.98669

Cumulative Model Updates: 60,330
Cumulative Timesteps: 1,006,326,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1006326728...
Checkpoint 1006326728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925,839.82461
Policy Entropy: 1.04903
Value Function Loss: 2.06727

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.10516

Collected Steps per Second: 3,964.05556
Overall Steps per Second: 3,277.45564

Timestep Collection Time: 12.61334
Timestep Consumption Time: 2.64239
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 15.25574

Cumulative Model Updates: 60,333
Cumulative Timesteps: 1,006,376,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589,466.43604
Policy Entropy: 1.06131
Value Function Loss: 2.03901

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.16113
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.09510

Collected Steps per Second: 3,577.03804
Overall Steps per Second: 3,055.32426

Timestep Collection Time: 13.97860
Timestep Consumption Time: 2.38693
PPO Batch Consumption Time: 0.05858
Total Iteration Time: 16.36553

Cumulative Model Updates: 60,336
Cumulative Timesteps: 1,006,426,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1006426730...
Checkpoint 1006426730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354,630.71753
Policy Entropy: 1.02214
Value Function Loss: 2.04126

Mean KL Divergence: 0.03311
SB3 Clip Fraction: 0.18917
Policy Update Magnitude: 0.06242
Value Function Update Magnitude: 0.09886

Collected Steps per Second: 3,602.65535
Overall Steps per Second: 3,086.59148

Timestep Collection Time: 13.89253
Timestep Consumption Time: 2.32277
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 16.21530

Cumulative Model Updates: 60,339
Cumulative Timesteps: 1,006,476,780

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463,672.41656
Policy Entropy: 1.04625
Value Function Loss: 2.09223

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.10273

Collected Steps per Second: 3,623.34327
Overall Steps per Second: 3,045.06469

Timestep Collection Time: 13.80383
Timestep Consumption Time: 2.62144
PPO Batch Consumption Time: 0.05377
Total Iteration Time: 16.42527

Cumulative Model Updates: 60,342
Cumulative Timesteps: 1,006,526,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1006526796...
Checkpoint 1006526796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481,203.49929
Policy Entropy: 1.05049
Value Function Loss: 2.15199

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.09688

Collected Steps per Second: 3,746.24093
Overall Steps per Second: 3,130.72884

Timestep Collection Time: 13.35419
Timestep Consumption Time: 2.62548
PPO Batch Consumption Time: 0.05917
Total Iteration Time: 15.97967

Cumulative Model Updates: 60,345
Cumulative Timesteps: 1,006,576,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114,474.64181
Policy Entropy: 1.03977
Value Function Loss: 2.05896

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.15597
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 3,709.77117
Overall Steps per Second: 3,084.03041

Timestep Collection Time: 13.47900
Timestep Consumption Time: 2.73485
PPO Batch Consumption Time: 0.05172
Total Iteration Time: 16.21385

Cumulative Model Updates: 60,348
Cumulative Timesteps: 1,006,626,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1006626828...
Checkpoint 1006626828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228,710.32324
Policy Entropy: 1.03798
Value Function Loss: 2.12770

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.16717
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.10306

Collected Steps per Second: 3,690.12559
Overall Steps per Second: 3,094.67848

Timestep Collection Time: 13.55509
Timestep Consumption Time: 2.60814
PPO Batch Consumption Time: 0.05238
Total Iteration Time: 16.16323

Cumulative Model Updates: 60,351
Cumulative Timesteps: 1,006,676,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391,842.95587
Policy Entropy: 1.04552
Value Function Loss: 2.10505

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.10929

Collected Steps per Second: 3,659.79127
Overall Steps per Second: 3,058.34881

Timestep Collection Time: 13.66526
Timestep Consumption Time: 2.68735
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 16.35261

Cumulative Model Updates: 60,354
Cumulative Timesteps: 1,006,726,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1006726860...
Checkpoint 1006726860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480,267.80216
Policy Entropy: 1.05744
Value Function Loss: 2.27505

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.17579
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.09641

Collected Steps per Second: 3,707.03918
Overall Steps per Second: 3,098.89185

Timestep Collection Time: 13.49001
Timestep Consumption Time: 2.64737
PPO Batch Consumption Time: 0.06039
Total Iteration Time: 16.13738

Cumulative Model Updates: 60,357
Cumulative Timesteps: 1,006,776,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409,908.45754
Policy Entropy: 1.01869
Value Function Loss: 2.18693

Mean KL Divergence: 0.03638
SB3 Clip Fraction: 0.19407
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 3,729.52958
Overall Steps per Second: 3,114.41417

Timestep Collection Time: 13.41242
Timestep Consumption Time: 2.64903
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 16.06145

Cumulative Model Updates: 60,360
Cumulative Timesteps: 1,006,826,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1006826890...
Checkpoint 1006826890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624,914.94778
Policy Entropy: 1.05036
Value Function Loss: 2.13159

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.15846
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.12693

Collected Steps per Second: 3,629.11369
Overall Steps per Second: 3,079.18353

Timestep Collection Time: 13.78408
Timestep Consumption Time: 2.46178
PPO Batch Consumption Time: 0.06084
Total Iteration Time: 16.24586

Cumulative Model Updates: 60,363
Cumulative Timesteps: 1,006,876,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393,797.14574
Policy Entropy: 1.04130
Value Function Loss: 2.08688

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.06385
Value Function Update Magnitude: 0.11916

Collected Steps per Second: 3,657.86203
Overall Steps per Second: 3,103.96470

Timestep Collection Time: 13.67903
Timestep Consumption Time: 2.44100
PPO Batch Consumption Time: 0.05415
Total Iteration Time: 16.12003

Cumulative Model Updates: 60,366
Cumulative Timesteps: 1,006,926,950

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1006926950...
Checkpoint 1006926950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538,496.77915
Policy Entropy: 1.03890
Value Function Loss: 2.09015

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.07079
Value Function Update Magnitude: 0.12504

Collected Steps per Second: 3,723.95011
Overall Steps per Second: 3,124.13567

Timestep Collection Time: 13.43358
Timestep Consumption Time: 2.57916
PPO Batch Consumption Time: 0.05966
Total Iteration Time: 16.01275

Cumulative Model Updates: 60,369
Cumulative Timesteps: 1,006,976,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475,833.72500
Policy Entropy: 1.02150
Value Function Loss: 2.11050

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.18501
Policy Update Magnitude: 0.06791
Value Function Update Magnitude: 0.12885

Collected Steps per Second: 3,659.74560
Overall Steps per Second: 3,099.65885

Timestep Collection Time: 13.66324
Timestep Consumption Time: 2.46885
PPO Batch Consumption Time: 0.05931
Total Iteration Time: 16.13210

Cumulative Model Updates: 60,372
Cumulative Timesteps: 1,007,026,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1007026980...
Checkpoint 1007026980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413,193.80981
Policy Entropy: 1.03649
Value Function Loss: 2.03421

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.06174
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 3,521.56779
Overall Steps per Second: 2,951.32808

Timestep Collection Time: 14.20731
Timestep Consumption Time: 2.74506
PPO Batch Consumption Time: 0.06177
Total Iteration Time: 16.95237

Cumulative Model Updates: 60,375
Cumulative Timesteps: 1,007,077,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264,193.92809
Policy Entropy: 1.04615
Value Function Loss: 2.04538

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.09974

Collected Steps per Second: 3,720.30598
Overall Steps per Second: 3,097.26444

Timestep Collection Time: 13.44782
Timestep Consumption Time: 2.70515
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 16.15296

Cumulative Model Updates: 60,378
Cumulative Timesteps: 1,007,127,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1007127042...
Checkpoint 1007127042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584,081.36194
Policy Entropy: 1.02732
Value Function Loss: 2.05151

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.09244

Collected Steps per Second: 3,603.04665
Overall Steps per Second: 3,026.53352

Timestep Collection Time: 13.88048
Timestep Consumption Time: 2.64404
PPO Batch Consumption Time: 0.06321
Total Iteration Time: 16.52452

Cumulative Model Updates: 60,381
Cumulative Timesteps: 1,007,177,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755,223.10963
Policy Entropy: 1.01619
Value Function Loss: 2.11886

Mean KL Divergence: 0.02910
SB3 Clip Fraction: 0.20037
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.08888

Collected Steps per Second: 3,702.36593
Overall Steps per Second: 3,120.97929

Timestep Collection Time: 13.50974
Timestep Consumption Time: 2.51664
PPO Batch Consumption Time: 0.05950
Total Iteration Time: 16.02638

Cumulative Model Updates: 60,384
Cumulative Timesteps: 1,007,227,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1007227072...
Checkpoint 1007227072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402,694.29680
Policy Entropy: 1.03512
Value Function Loss: 2.13362

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.06150
Value Function Update Magnitude: 0.09096

Collected Steps per Second: 3,884.63359
Overall Steps per Second: 3,226.75047

Timestep Collection Time: 12.87843
Timestep Consumption Time: 2.62571
PPO Batch Consumption Time: 0.07139
Total Iteration Time: 15.50414

Cumulative Model Updates: 60,387
Cumulative Timesteps: 1,007,277,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661,593.28604
Policy Entropy: 1.03976
Value Function Loss: 2.13399

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.06918
Value Function Update Magnitude: 0.08912

Collected Steps per Second: 3,900.88352
Overall Steps per Second: 3,263.20633

Timestep Collection Time: 12.81915
Timestep Consumption Time: 2.50504
PPO Batch Consumption Time: 0.05856
Total Iteration Time: 15.32419

Cumulative Model Updates: 60,390
Cumulative Timesteps: 1,007,327,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1007327106...
Checkpoint 1007327106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,088,313.04190
Policy Entropy: 1.03558
Value Function Loss: 2.09439

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.06840
Value Function Update Magnitude: 0.08784

Collected Steps per Second: 3,653.67391
Overall Steps per Second: 3,066.16085

Timestep Collection Time: 13.68869
Timestep Consumption Time: 2.62292
PPO Batch Consumption Time: 0.06310
Total Iteration Time: 16.31160

Cumulative Model Updates: 60,393
Cumulative Timesteps: 1,007,377,120

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181,519.86255
Policy Entropy: 1.01908
Value Function Loss: 2.19234

Mean KL Divergence: 0.02675
SB3 Clip Fraction: 0.18941
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.09923

Collected Steps per Second: 3,684.01574
Overall Steps per Second: 3,084.07680

Timestep Collection Time: 13.58138
Timestep Consumption Time: 2.64196
PPO Batch Consumption Time: 0.06579
Total Iteration Time: 16.22333

Cumulative Model Updates: 60,396
Cumulative Timesteps: 1,007,427,154

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1007427154...
Checkpoint 1007427154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198,802.21633
Policy Entropy: 1.03361
Value Function Loss: 2.14723

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.06136
Value Function Update Magnitude: 0.09841

Collected Steps per Second: 3,675.42744
Overall Steps per Second: 3,126.97882

Timestep Collection Time: 13.60767
Timestep Consumption Time: 2.38668
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 15.99435

Cumulative Model Updates: 60,399
Cumulative Timesteps: 1,007,477,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,317,671.22027
Policy Entropy: 1.04534
Value Function Loss: 2.17995

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.16505
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.09782

Collected Steps per Second: 3,668.11683
Overall Steps per Second: 3,132.17269

Timestep Collection Time: 13.63370
Timestep Consumption Time: 2.33285
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 15.96655

Cumulative Model Updates: 60,402
Cumulative Timesteps: 1,007,527,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1007527178...
Checkpoint 1007527178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363,712.72118
Policy Entropy: 1.02829
Value Function Loss: 1.93431

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.09233

Collected Steps per Second: 3,852.16563
Overall Steps per Second: 3,269.76906

Timestep Collection Time: 12.98854
Timestep Consumption Time: 2.31346
PPO Batch Consumption Time: 0.06402
Total Iteration Time: 15.30200

Cumulative Model Updates: 60,405
Cumulative Timesteps: 1,007,577,212

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,001,003.12392
Policy Entropy: 1.04038
Value Function Loss: 2.00501

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.09250

Collected Steps per Second: 3,517.50563
Overall Steps per Second: 2,945.11283

Timestep Collection Time: 14.22997
Timestep Consumption Time: 2.76564
PPO Batch Consumption Time: 0.06540
Total Iteration Time: 16.99561

Cumulative Model Updates: 60,408
Cumulative Timesteps: 1,007,627,266

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1007627266...
Checkpoint 1007627266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291,614.16009
Policy Entropy: 1.04479
Value Function Loss: 1.98026

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.06171
Value Function Update Magnitude: 0.08925

Collected Steps per Second: 3,690.25740
Overall Steps per Second: 3,076.12462

Timestep Collection Time: 13.56003
Timestep Consumption Time: 2.70719
PPO Batch Consumption Time: 0.05881
Total Iteration Time: 16.26722

Cumulative Model Updates: 60,411
Cumulative Timesteps: 1,007,677,306

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914,735.39247
Policy Entropy: 1.05204
Value Function Loss: 2.03276

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.07236
Value Function Update Magnitude: 0.10883

Collected Steps per Second: 3,606.86381
Overall Steps per Second: 3,013.82753

Timestep Collection Time: 13.86800
Timestep Consumption Time: 2.72883
PPO Batch Consumption Time: 0.06391
Total Iteration Time: 16.59684

Cumulative Model Updates: 60,414
Cumulative Timesteps: 1,007,727,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1007727326...
Checkpoint 1007727326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493,390.90095
Policy Entropy: 1.05045
Value Function Loss: 1.98792

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.07581
Value Function Update Magnitude: 0.11437

Collected Steps per Second: 3,599.14170
Overall Steps per Second: 3,020.40570

Timestep Collection Time: 13.90165
Timestep Consumption Time: 2.66368
PPO Batch Consumption Time: 0.04939
Total Iteration Time: 16.56532

Cumulative Model Updates: 60,417
Cumulative Timesteps: 1,007,777,360

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942,869.46298
Policy Entropy: 1.05989
Value Function Loss: 2.08615

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.07775
Value Function Update Magnitude: 0.11002

Collected Steps per Second: 3,647.69309
Overall Steps per Second: 3,070.35045

Timestep Collection Time: 13.71826
Timestep Consumption Time: 2.57955
PPO Batch Consumption Time: 0.06247
Total Iteration Time: 16.29781

Cumulative Model Updates: 60,420
Cumulative Timesteps: 1,007,827,400

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1007827400...
Checkpoint 1007827400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364,619.81478
Policy Entropy: 1.05757
Value Function Loss: 2.12515

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.07961
Value Function Update Magnitude: 0.10882

Collected Steps per Second: 3,812.04954
Overall Steps per Second: 3,171.96558

Timestep Collection Time: 13.12890
Timestep Consumption Time: 2.64933
PPO Batch Consumption Time: 0.05805
Total Iteration Time: 15.77823

Cumulative Model Updates: 60,423
Cumulative Timesteps: 1,007,877,448

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,675.38432
Policy Entropy: 1.05871
Value Function Loss: 2.11632

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.08043
Value Function Update Magnitude: 0.11450

Collected Steps per Second: 3,648.59303
Overall Steps per Second: 3,069.23121

Timestep Collection Time: 13.71378
Timestep Consumption Time: 2.58867
PPO Batch Consumption Time: 0.06196
Total Iteration Time: 16.30245

Cumulative Model Updates: 60,426
Cumulative Timesteps: 1,007,927,484

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1007927484...
Checkpoint 1007927484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368,692.02460
Policy Entropy: 1.04975
Value Function Loss: 2.10229

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.07977
Value Function Update Magnitude: 0.13042

Collected Steps per Second: 3,653.73472
Overall Steps per Second: 3,069.82394

Timestep Collection Time: 13.69503
Timestep Consumption Time: 2.60493
PPO Batch Consumption Time: 0.05161
Total Iteration Time: 16.29996

Cumulative Model Updates: 60,429
Cumulative Timesteps: 1,007,977,522

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256,650.75777
Policy Entropy: 1.05043
Value Function Loss: 2.12041

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.07330
Value Function Update Magnitude: 0.13723

Collected Steps per Second: 3,585.39502
Overall Steps per Second: 3,021.31456

Timestep Collection Time: 13.95160
Timestep Consumption Time: 2.60477
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 16.55637

Cumulative Model Updates: 60,432
Cumulative Timesteps: 1,008,027,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1008027544...
Checkpoint 1008027544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541,333.39009
Policy Entropy: 1.03373
Value Function Loss: 2.16857

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.07991
Value Function Update Magnitude: 0.12728

Collected Steps per Second: 3,641.23705
Overall Steps per Second: 3,092.22136

Timestep Collection Time: 13.74148
Timestep Consumption Time: 2.43976
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 16.18125

Cumulative Model Updates: 60,435
Cumulative Timesteps: 1,008,077,580

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357,206.88245
Policy Entropy: 1.05069
Value Function Loss: 2.12272

Mean KL Divergence: 0.02442
SB3 Clip Fraction: 0.16949
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 3,724.67639
Overall Steps per Second: 3,163.86795

Timestep Collection Time: 13.43580
Timestep Consumption Time: 2.38155
PPO Batch Consumption Time: 0.05310
Total Iteration Time: 15.81735

Cumulative Model Updates: 60,438
Cumulative Timesteps: 1,008,127,624

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1008127624...
Checkpoint 1008127624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706,389.58074
Policy Entropy: 1.05176
Value Function Loss: 2.08833

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.15265
Policy Update Magnitude: 0.06133
Value Function Update Magnitude: 0.09958

Collected Steps per Second: 4,149.11939
Overall Steps per Second: 3,392.41213

Timestep Collection Time: 12.06232
Timestep Consumption Time: 2.69061
PPO Batch Consumption Time: 0.06677
Total Iteration Time: 14.75292

Cumulative Model Updates: 60,441
Cumulative Timesteps: 1,008,177,672

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612,300.78536
Policy Entropy: 1.04167
Value Function Loss: 2.05020

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.08894

Collected Steps per Second: 3,802.13930
Overall Steps per Second: 3,159.97027

Timestep Collection Time: 13.15417
Timestep Consumption Time: 2.67319
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 15.82736

Cumulative Model Updates: 60,444
Cumulative Timesteps: 1,008,227,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1008227686...
Checkpoint 1008227686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664,332.52243
Policy Entropy: 1.03754
Value Function Loss: 2.11115

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.17834
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.08412

Collected Steps per Second: 3,761.12475
Overall Steps per Second: 3,132.31926

Timestep Collection Time: 13.29709
Timestep Consumption Time: 2.66936
PPO Batch Consumption Time: 0.06305
Total Iteration Time: 15.96644

Cumulative Model Updates: 60,447
Cumulative Timesteps: 1,008,277,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445,854.69189
Policy Entropy: 1.04698
Value Function Loss: 2.10799

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.08157

Collected Steps per Second: 3,704.67631
Overall Steps per Second: 3,092.87375

Timestep Collection Time: 13.51157
Timestep Consumption Time: 2.67273
PPO Batch Consumption Time: 0.05848
Total Iteration Time: 16.18430

Cumulative Model Updates: 60,450
Cumulative Timesteps: 1,008,327,754

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1008327754...
Checkpoint 1008327754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774,437.73048
Policy Entropy: 1.05903
Value Function Loss: 2.09172

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.15875
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.10553

Collected Steps per Second: 3,656.00432
Overall Steps per Second: 3,077.26219

Timestep Collection Time: 13.68434
Timestep Consumption Time: 2.57362
PPO Batch Consumption Time: 0.05127
Total Iteration Time: 16.25796

Cumulative Model Updates: 60,453
Cumulative Timesteps: 1,008,377,784

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292,753.82526
Policy Entropy: 1.04719
Value Function Loss: 2.07100

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.10852

Collected Steps per Second: 3,754.68169
Overall Steps per Second: 3,155.62977

Timestep Collection Time: 13.32843
Timestep Consumption Time: 2.53021
PPO Batch Consumption Time: 0.05789
Total Iteration Time: 15.85864

Cumulative Model Updates: 60,456
Cumulative Timesteps: 1,008,427,828

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1008427828...
Checkpoint 1008427828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640,715.98691
Policy Entropy: 1.06014
Value Function Loss: 2.07698

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14646
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.09972

Collected Steps per Second: 3,696.71704
Overall Steps per Second: 3,100.21848

Timestep Collection Time: 13.53255
Timestep Consumption Time: 2.60373
PPO Batch Consumption Time: 0.06711
Total Iteration Time: 16.13628

Cumulative Model Updates: 60,459
Cumulative Timesteps: 1,008,477,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169,075.28058
Policy Entropy: 1.05935
Value Function Loss: 2.05945

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.07198
Value Function Update Magnitude: 0.09985

Collected Steps per Second: 3,755.50809
Overall Steps per Second: 3,223.10789

Timestep Collection Time: 13.31857
Timestep Consumption Time: 2.19999
PPO Batch Consumption Time: 0.06074
Total Iteration Time: 15.51856

Cumulative Model Updates: 60,462
Cumulative Timesteps: 1,008,527,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1008527872...
Checkpoint 1008527872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075,891.30850
Policy Entropy: 1.05264
Value Function Loss: 2.10526

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.07854
Value Function Update Magnitude: 0.09425

Collected Steps per Second: 3,885.73123
Overall Steps per Second: 3,262.04521

Timestep Collection Time: 12.87274
Timestep Consumption Time: 2.46120
PPO Batch Consumption Time: 0.05789
Total Iteration Time: 15.33394

Cumulative Model Updates: 60,465
Cumulative Timesteps: 1,008,577,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698,274.77480
Policy Entropy: 1.04904
Value Function Loss: 2.09586

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.08412
Value Function Update Magnitude: 0.10546

Collected Steps per Second: 3,679.53376
Overall Steps per Second: 3,054.58299

Timestep Collection Time: 13.59520
Timestep Consumption Time: 2.78150
PPO Batch Consumption Time: 0.05378
Total Iteration Time: 16.37670

Cumulative Model Updates: 60,468
Cumulative Timesteps: 1,008,627,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1008627916...
Checkpoint 1008627916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817,226.98930
Policy Entropy: 1.04924
Value Function Loss: 2.08983

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.07571
Value Function Update Magnitude: 0.10747

Collected Steps per Second: 3,637.20887
Overall Steps per Second: 3,068.56845

Timestep Collection Time: 13.75065
Timestep Consumption Time: 2.54815
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 16.29881

Cumulative Model Updates: 60,471
Cumulative Timesteps: 1,008,677,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413,167.79775
Policy Entropy: 1.06528
Value Function Loss: 2.17364

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.14529
Policy Update Magnitude: 0.06515
Value Function Update Magnitude: 0.09710

Collected Steps per Second: 3,744.53645
Overall Steps per Second: 3,130.51640

Timestep Collection Time: 13.36454
Timestep Consumption Time: 2.62132
PPO Batch Consumption Time: 0.05398
Total Iteration Time: 15.98586

Cumulative Model Updates: 60,474
Cumulative Timesteps: 1,008,727,974

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1008727974...
Checkpoint 1008727974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552,347.76179
Policy Entropy: 1.07158
Value Function Loss: 2.22485

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.06199
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 3,634.85739
Overall Steps per Second: 3,058.57748

Timestep Collection Time: 13.75680
Timestep Consumption Time: 2.59198
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 16.34878

Cumulative Model Updates: 60,477
Cumulative Timesteps: 1,008,777,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623,775.49120
Policy Entropy: 1.05642
Value Function Loss: 2.26012

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 3,849.63482
Overall Steps per Second: 3,214.61953

Timestep Collection Time: 12.99967
Timestep Consumption Time: 2.56795
PPO Batch Consumption Time: 0.05919
Total Iteration Time: 15.56763

Cumulative Model Updates: 60,480
Cumulative Timesteps: 1,008,828,022

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1008828022...
Checkpoint 1008828022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682,358.68756
Policy Entropy: 1.04648
Value Function Loss: 2.19076

Mean KL Divergence: 0.03019
SB3 Clip Fraction: 0.18819
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.09817

Collected Steps per Second: 3,623.36140
Overall Steps per Second: 3,051.53197

Timestep Collection Time: 13.79989
Timestep Consumption Time: 2.58597
PPO Batch Consumption Time: 0.05188
Total Iteration Time: 16.38587

Cumulative Model Updates: 60,483
Cumulative Timesteps: 1,008,878,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306,939.07468
Policy Entropy: 1.07789
Value Function Loss: 2.13387

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.10816

Collected Steps per Second: 3,678.04655
Overall Steps per Second: 3,103.70213

Timestep Collection Time: 13.60559
Timestep Consumption Time: 2.51773
PPO Batch Consumption Time: 0.05088
Total Iteration Time: 16.12333

Cumulative Model Updates: 60,486
Cumulative Timesteps: 1,008,928,066

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1008928066...
Checkpoint 1008928066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734,754.25051
Policy Entropy: 1.07289
Value Function Loss: 2.09244

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.10058

Collected Steps per Second: 3,688.98125
Overall Steps per Second: 3,088.89327

Timestep Collection Time: 13.55388
Timestep Consumption Time: 2.63315
PPO Batch Consumption Time: 0.06013
Total Iteration Time: 16.18703

Cumulative Model Updates: 60,489
Cumulative Timesteps: 1,008,978,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459,982.58554
Policy Entropy: 1.06491
Value Function Loss: 2.03841

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.06297
Value Function Update Magnitude: 0.10031

Collected Steps per Second: 3,651.78895
Overall Steps per Second: 3,068.52613

Timestep Collection Time: 13.69247
Timestep Consumption Time: 2.60265
PPO Batch Consumption Time: 0.05809
Total Iteration Time: 16.29512

Cumulative Model Updates: 60,492
Cumulative Timesteps: 1,009,028,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1009028068...
Checkpoint 1009028068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410,086.19032
Policy Entropy: 1.05006
Value Function Loss: 2.12313

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.09210

Collected Steps per Second: 3,725.91712
Overall Steps per Second: 3,156.86838

Timestep Collection Time: 13.42005
Timestep Consumption Time: 2.41906
PPO Batch Consumption Time: 0.06629
Total Iteration Time: 15.83911

Cumulative Model Updates: 60,495
Cumulative Timesteps: 1,009,078,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327,439.77717
Policy Entropy: 1.05032
Value Function Loss: 2.16266

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.15355
Policy Update Magnitude: 0.06140
Value Function Update Magnitude: 0.09709

Collected Steps per Second: 3,504.72115
Overall Steps per Second: 3,015.74071

Timestep Collection Time: 14.27674
Timestep Consumption Time: 2.31487
PPO Batch Consumption Time: 0.05785
Total Iteration Time: 16.59161

Cumulative Model Updates: 60,498
Cumulative Timesteps: 1,009,128,106

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1009128106...
Checkpoint 1009128106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110,644.96750
Policy Entropy: 1.06254
Value Function Loss: 2.20455

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.09978

Collected Steps per Second: 3,676.19638
Overall Steps per Second: 3,116.16138

Timestep Collection Time: 13.60754
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.06072
Total Iteration Time: 16.05308

Cumulative Model Updates: 60,501
Cumulative Timesteps: 1,009,178,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541,120.75135
Policy Entropy: 1.06353
Value Function Loss: 2.17122

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.06325
Value Function Update Magnitude: 0.09694

Collected Steps per Second: 3,675.14598
Overall Steps per Second: 3,069.96648

Timestep Collection Time: 13.61252
Timestep Consumption Time: 2.68342
PPO Batch Consumption Time: 0.06111
Total Iteration Time: 16.29594

Cumulative Model Updates: 60,504
Cumulative Timesteps: 1,009,228,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1009228158...
Checkpoint 1009228158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185,880.66468
Policy Entropy: 1.08038
Value Function Loss: 2.13465

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.15294
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.09577

Collected Steps per Second: 3,723.01362
Overall Steps per Second: 3,100.74550

Timestep Collection Time: 13.44448
Timestep Consumption Time: 2.69808
PPO Batch Consumption Time: 0.06491
Total Iteration Time: 16.14257

Cumulative Model Updates: 60,507
Cumulative Timesteps: 1,009,278,212

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540,797.48531
Policy Entropy: 1.06295
Value Function Loss: 2.05706

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.09327

Collected Steps per Second: 3,626.51066
Overall Steps per Second: 3,057.84321

Timestep Collection Time: 13.79453
Timestep Consumption Time: 2.56537
PPO Batch Consumption Time: 0.06661
Total Iteration Time: 16.35990

Cumulative Model Updates: 60,510
Cumulative Timesteps: 1,009,328,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1009328238...
Checkpoint 1009328238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684,035.21601
Policy Entropy: 1.07928
Value Function Loss: 2.06778

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.09238

Collected Steps per Second: 3,641.17404
Overall Steps per Second: 3,046.73915

Timestep Collection Time: 13.73568
Timestep Consumption Time: 2.67990
PPO Batch Consumption Time: 0.05176
Total Iteration Time: 16.41558

Cumulative Model Updates: 60,513
Cumulative Timesteps: 1,009,378,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738,237.34015
Policy Entropy: 1.07803
Value Function Loss: 2.06788

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.07951
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 3,816.63918
Overall Steps per Second: 3,148.12096

Timestep Collection Time: 13.10263
Timestep Consumption Time: 2.78240
PPO Batch Consumption Time: 0.04932
Total Iteration Time: 15.88503

Cumulative Model Updates: 60,516
Cumulative Timesteps: 1,009,428,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1009428260...
Checkpoint 1009428260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550,803.80685
Policy Entropy: 1.07855
Value Function Loss: 2.14039

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.08233
Value Function Update Magnitude: 0.08689

Collected Steps per Second: 3,588.79954
Overall Steps per Second: 3,050.66184

Timestep Collection Time: 13.93781
Timestep Consumption Time: 2.45863
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 16.39644

Cumulative Model Updates: 60,519
Cumulative Timesteps: 1,009,478,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463,721.43684
Policy Entropy: 1.07019
Value Function Loss: 2.11233

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.08298
Value Function Update Magnitude: 0.09564

Collected Steps per Second: 3,745.05292
Overall Steps per Second: 3,135.96148

Timestep Collection Time: 13.35255
Timestep Consumption Time: 2.59344
PPO Batch Consumption Time: 0.05238
Total Iteration Time: 15.94599

Cumulative Model Updates: 60,522
Cumulative Timesteps: 1,009,528,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1009528286...
Checkpoint 1009528286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192,924.47972
Policy Entropy: 1.05715
Value Function Loss: 2.17764

Mean KL Divergence: 0.02880
SB3 Clip Fraction: 0.17231
Policy Update Magnitude: 0.07443
Value Function Update Magnitude: 0.10241

Collected Steps per Second: 3,686.43019
Overall Steps per Second: 3,090.66664

Timestep Collection Time: 13.56543
Timestep Consumption Time: 2.61490
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 16.18033

Cumulative Model Updates: 60,525
Cumulative Timesteps: 1,009,578,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487,650.74720
Policy Entropy: 1.07845
Value Function Loss: 2.16692

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.06208
Value Function Update Magnitude: 0.09517

Collected Steps per Second: 3,643.85644
Overall Steps per Second: 3,105.78531

Timestep Collection Time: 13.73215
Timestep Consumption Time: 2.37907
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 16.11122

Cumulative Model Updates: 60,528
Cumulative Timesteps: 1,009,628,332

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1009628332...
Checkpoint 1009628332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006,854.62033
Policy Entropy: 1.08247
Value Function Loss: 2.28511

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.08671

Collected Steps per Second: 3,658.42449
Overall Steps per Second: 3,100.19455

Timestep Collection Time: 13.67802
Timestep Consumption Time: 2.46290
PPO Batch Consumption Time: 0.05009
Total Iteration Time: 16.14092

Cumulative Model Updates: 60,531
Cumulative Timesteps: 1,009,678,372

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696,847.42346
Policy Entropy: 1.06811
Value Function Loss: 2.31791

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.09205

Collected Steps per Second: 3,684.92872
Overall Steps per Second: 3,131.33845

Timestep Collection Time: 13.57638
Timestep Consumption Time: 2.40017
PPO Batch Consumption Time: 0.05211
Total Iteration Time: 15.97655

Cumulative Model Updates: 60,534
Cumulative Timesteps: 1,009,728,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1009728400...
Checkpoint 1009728400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542,765.87865
Policy Entropy: 1.05688
Value Function Loss: 2.23601

Mean KL Divergence: 0.02985
SB3 Clip Fraction: 0.17877
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.10038

Collected Steps per Second: 3,723.42413
Overall Steps per Second: 3,105.12171

Timestep Collection Time: 13.42904
Timestep Consumption Time: 2.67404
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 16.10307

Cumulative Model Updates: 60,537
Cumulative Timesteps: 1,009,778,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212,693.95907
Policy Entropy: 1.07461
Value Function Loss: 2.22777

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.05946
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 3,664.41361
Overall Steps per Second: 3,064.00958

Timestep Collection Time: 13.65239
Timestep Consumption Time: 2.67524
PPO Batch Consumption Time: 0.05910
Total Iteration Time: 16.32763

Cumulative Model Updates: 60,540
Cumulative Timesteps: 1,009,828,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1009828430...
Checkpoint 1009828430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,726,462.57306
Policy Entropy: 1.06816
Value Function Loss: 2.22809

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.11798

Collected Steps per Second: 3,646.81842
Overall Steps per Second: 3,036.66884

Timestep Collection Time: 13.72319
Timestep Consumption Time: 2.75736
PPO Batch Consumption Time: 0.06299
Total Iteration Time: 16.48056

Cumulative Model Updates: 60,543
Cumulative Timesteps: 1,009,878,476

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,435.05389
Policy Entropy: 1.06276
Value Function Loss: 2.27070

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.06904
Value Function Update Magnitude: 0.11613

Collected Steps per Second: 3,626.15121
Overall Steps per Second: 3,029.71260

Timestep Collection Time: 13.79424
Timestep Consumption Time: 2.71558
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 16.50982

Cumulative Model Updates: 60,546
Cumulative Timesteps: 1,009,928,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1009928496...
Checkpoint 1009928496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444,274.52423
Policy Entropy: 1.05408
Value Function Loss: 2.22038

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.10831

Collected Steps per Second: 3,634.95064
Overall Steps per Second: 3,045.20005

Timestep Collection Time: 13.75645
Timestep Consumption Time: 2.66415
PPO Batch Consumption Time: 0.05106
Total Iteration Time: 16.42060

Cumulative Model Updates: 60,549
Cumulative Timesteps: 1,009,978,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272,754.42661
Policy Entropy: 1.07642
Value Function Loss: 2.19367

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.09243

Collected Steps per Second: 3,668.57714
Overall Steps per Second: 3,101.62454

Timestep Collection Time: 13.63035
Timestep Consumption Time: 2.49152
PPO Batch Consumption Time: 0.05325
Total Iteration Time: 16.12187

Cumulative Model Updates: 60,552
Cumulative Timesteps: 1,010,028,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1010028504...
Checkpoint 1010028504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605,569.03818
Policy Entropy: 1.08284
Value Function Loss: 2.16030

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.08251

Collected Steps per Second: 3,673.41387
Overall Steps per Second: 3,100.53333

Timestep Collection Time: 13.62057
Timestep Consumption Time: 2.51665
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 16.13722

Cumulative Model Updates: 60,555
Cumulative Timesteps: 1,010,078,538

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538,202.24051
Policy Entropy: 1.07352
Value Function Loss: 2.09157

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.08362

Collected Steps per Second: 3,630.92796
Overall Steps per Second: 3,049.89614

Timestep Collection Time: 13.77995
Timestep Consumption Time: 2.62520
PPO Batch Consumption Time: 0.05075
Total Iteration Time: 16.40515

Cumulative Model Updates: 60,558
Cumulative Timesteps: 1,010,128,572

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1010128572...
Checkpoint 1010128572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453,361.78590
Policy Entropy: 1.05961
Value Function Loss: 2.03804

Mean KL Divergence: 0.02415
SB3 Clip Fraction: 0.17119
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.09357

Collected Steps per Second: 3,724.04951
Overall Steps per Second: 3,176.79173

Timestep Collection Time: 13.43591
Timestep Consumption Time: 2.31457
PPO Batch Consumption Time: 0.05024
Total Iteration Time: 15.75048

Cumulative Model Updates: 60,561
Cumulative Timesteps: 1,010,178,608

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640,708.47805
Policy Entropy: 1.06311
Value Function Loss: 2.03941

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.09110

Collected Steps per Second: 3,573.99254
Overall Steps per Second: 3,051.40531

Timestep Collection Time: 14.00395
Timestep Consumption Time: 2.39833
PPO Batch Consumption Time: 0.05314
Total Iteration Time: 16.40228

Cumulative Model Updates: 60,564
Cumulative Timesteps: 1,010,228,658

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1010228658...
Checkpoint 1010228658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643,076.84505
Policy Entropy: 1.07072
Value Function Loss: 2.13014

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.15943
Policy Update Magnitude: 0.06143
Value Function Update Magnitude: 0.09034

Collected Steps per Second: 3,944.59530
Overall Steps per Second: 3,279.19509

Timestep Collection Time: 12.68318
Timestep Consumption Time: 2.57362
PPO Batch Consumption Time: 0.06316
Total Iteration Time: 15.25679

Cumulative Model Updates: 60,567
Cumulative Timesteps: 1,010,278,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581,059.20608
Policy Entropy: 1.04401
Value Function Loss: 2.15286

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.17104
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.08913

Collected Steps per Second: 3,685.90551
Overall Steps per Second: 3,080.54933

Timestep Collection Time: 13.56682
Timestep Consumption Time: 2.66600
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 16.23282

Cumulative Model Updates: 60,570
Cumulative Timesteps: 1,010,328,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1010328694...
Checkpoint 1010328694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830,382.44634
Policy Entropy: 1.06600
Value Function Loss: 2.24580

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.09178

Collected Steps per Second: 3,865.12918
Overall Steps per Second: 3,198.86879

Timestep Collection Time: 12.94239
Timestep Consumption Time: 2.69564
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 15.63803

Cumulative Model Updates: 60,573
Cumulative Timesteps: 1,010,378,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201,831.94607
Policy Entropy: 1.06997
Value Function Loss: 2.16064

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.09724

Collected Steps per Second: 3,632.47134
Overall Steps per Second: 3,037.81578

Timestep Collection Time: 13.77024
Timestep Consumption Time: 2.69554
PPO Batch Consumption Time: 0.06342
Total Iteration Time: 16.46578

Cumulative Model Updates: 60,576
Cumulative Timesteps: 1,010,428,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1010428738...
Checkpoint 1010428738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184,034.98346
Policy Entropy: 1.06504
Value Function Loss: 2.13385

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.09269

Collected Steps per Second: 3,649.53483
Overall Steps per Second: 3,070.79836

Timestep Collection Time: 13.71243
Timestep Consumption Time: 2.58431
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 16.29674

Cumulative Model Updates: 60,579
Cumulative Timesteps: 1,010,478,782

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209,354.81637
Policy Entropy: 1.06042
Value Function Loss: 2.07020

Mean KL Divergence: 0.02593
SB3 Clip Fraction: 0.17739
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.09845

Collected Steps per Second: 3,852.52416
Overall Steps per Second: 3,198.80449

Timestep Collection Time: 12.98577
Timestep Consumption Time: 2.65382
PPO Batch Consumption Time: 0.05821
Total Iteration Time: 15.63959

Cumulative Model Updates: 60,582
Cumulative Timesteps: 1,010,528,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1010528810...
Checkpoint 1010528810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457,432.59419
Policy Entropy: 1.06848
Value Function Loss: 2.12812

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.12313

Collected Steps per Second: 3,700.87260
Overall Steps per Second: 3,098.82394

Timestep Collection Time: 13.51627
Timestep Consumption Time: 2.62598
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 16.14225

Cumulative Model Updates: 60,585
Cumulative Timesteps: 1,010,578,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490,579.16102
Policy Entropy: 1.06657
Value Function Loss: 2.15210

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.15442
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 3,579.76713
Overall Steps per Second: 3,015.29690

Timestep Collection Time: 13.96739
Timestep Consumption Time: 2.61473
PPO Batch Consumption Time: 0.05149
Total Iteration Time: 16.58212

Cumulative Model Updates: 60,588
Cumulative Timesteps: 1,010,628,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1010628832...
Checkpoint 1010628832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480,647.09275
Policy Entropy: 1.04290
Value Function Loss: 2.17746

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.06700
Value Function Update Magnitude: 0.13933

Collected Steps per Second: 3,721.29894
Overall Steps per Second: 3,147.47308

Timestep Collection Time: 13.44853
Timestep Consumption Time: 2.45184
PPO Batch Consumption Time: 0.06667
Total Iteration Time: 15.90037

Cumulative Model Updates: 60,591
Cumulative Timesteps: 1,010,678,878

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653,826.10155
Policy Entropy: 1.06970
Value Function Loss: 2.16417

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.16771
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 3,547.24471
Overall Steps per Second: 3,005.83584

Timestep Collection Time: 14.10672
Timestep Consumption Time: 2.54089
PPO Batch Consumption Time: 0.06511
Total Iteration Time: 16.64762

Cumulative Model Updates: 60,594
Cumulative Timesteps: 1,010,728,918

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1010728918...
Checkpoint 1010728918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554,138.00377
Policy Entropy: 1.06942
Value Function Loss: 2.07250

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.16083
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.10656

Collected Steps per Second: 3,650.61555
Overall Steps per Second: 3,103.84806

Timestep Collection Time: 13.70016
Timestep Consumption Time: 2.41339
PPO Batch Consumption Time: 0.05985
Total Iteration Time: 16.11355

Cumulative Model Updates: 60,597
Cumulative Timesteps: 1,010,778,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398,418.15962
Policy Entropy: 1.06904
Value Function Loss: 1.95780

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.06680
Value Function Update Magnitude: 0.09977

Collected Steps per Second: 3,684.04169
Overall Steps per Second: 3,090.51387

Timestep Collection Time: 13.58182
Timestep Consumption Time: 2.60837
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 16.19019

Cumulative Model Updates: 60,600
Cumulative Timesteps: 1,010,828,968

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1010828968...
Checkpoint 1010828968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348,197.25395
Policy Entropy: 1.04482
Value Function Loss: 1.95828

Mean KL Divergence: 0.04038
SB3 Clip Fraction: 0.21635
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.10125

Collected Steps per Second: 3,696.05019
Overall Steps per Second: 3,092.67829

Timestep Collection Time: 13.53607
Timestep Consumption Time: 2.64085
PPO Batch Consumption Time: 0.05934
Total Iteration Time: 16.17692

Cumulative Model Updates: 60,603
Cumulative Timesteps: 1,010,878,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520,119.84116
Policy Entropy: 1.07544
Value Function Loss: 2.00840

Mean KL Divergence: 0.03220
SB3 Clip Fraction: 0.19667
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.09652

Collected Steps per Second: 3,652.50401
Overall Steps per Second: 3,063.95027

Timestep Collection Time: 13.69088
Timestep Consumption Time: 2.62988
PPO Batch Consumption Time: 0.05161
Total Iteration Time: 16.32076

Cumulative Model Updates: 60,606
Cumulative Timesteps: 1,010,929,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1010929004...
Checkpoint 1010929004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390,555.58230
Policy Entropy: 1.05068
Value Function Loss: 2.11813

Mean KL Divergence: 0.02732
SB3 Clip Fraction: 0.17789
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.10058

Collected Steps per Second: 3,839.39009
Overall Steps per Second: 3,197.66086

Timestep Collection Time: 13.02342
Timestep Consumption Time: 2.61363
PPO Batch Consumption Time: 0.05429
Total Iteration Time: 15.63706

Cumulative Model Updates: 60,609
Cumulative Timesteps: 1,010,979,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360,598.41580
Policy Entropy: 1.06155
Value Function Loss: 2.29236

Mean KL Divergence: 0.03055
SB3 Clip Fraction: 0.17291
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 3,733.16513
Overall Steps per Second: 3,126.97348

Timestep Collection Time: 13.40096
Timestep Consumption Time: 2.59790
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 15.99886

Cumulative Model Updates: 60,612
Cumulative Timesteps: 1,011,029,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1011029034...
Checkpoint 1011029034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517,972.13236
Policy Entropy: 1.06115
Value Function Loss: 2.20926

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.17031
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.09323

Collected Steps per Second: 3,616.86192
Overall Steps per Second: 3,030.20184

Timestep Collection Time: 13.82856
Timestep Consumption Time: 2.67727
PPO Batch Consumption Time: 0.05277
Total Iteration Time: 16.50583

Cumulative Model Updates: 60,615
Cumulative Timesteps: 1,011,079,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708,657.26696
Policy Entropy: 1.05367
Value Function Loss: 2.16441

Mean KL Divergence: 0.02199
SB3 Clip Fraction: 0.15166
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.10312

Collected Steps per Second: 3,736.17132
Overall Steps per Second: 3,117.83201

Timestep Collection Time: 13.39339
Timestep Consumption Time: 2.65622
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 16.04961

Cumulative Model Updates: 60,618
Cumulative Timesteps: 1,011,129,090

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1011129090...
Checkpoint 1011129090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576,396.61932
Policy Entropy: 1.05217
Value Function Loss: 2.04074

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.17965
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.09838

Collected Steps per Second: 3,686.11379
Overall Steps per Second: 3,124.52811

Timestep Collection Time: 13.56876
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.06279
Total Iteration Time: 16.00754

Cumulative Model Updates: 60,621
Cumulative Timesteps: 1,011,179,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558,538.69772
Policy Entropy: 1.07079
Value Function Loss: 2.14717

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.10010

Collected Steps per Second: 3,799.84213
Overall Steps per Second: 3,192.98730

Timestep Collection Time: 13.16423
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.06483
Total Iteration Time: 15.66621

Cumulative Model Updates: 60,624
Cumulative Timesteps: 1,011,229,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1011229128...
Checkpoint 1011229128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558,345.85545
Policy Entropy: 1.06980
Value Function Loss: 2.20041

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.06676
Value Function Update Magnitude: 0.10442

Collected Steps per Second: 3,664.00270
Overall Steps per Second: 3,095.35682

Timestep Collection Time: 13.65119
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.04955
Total Iteration Time: 16.15904

Cumulative Model Updates: 60,627
Cumulative Timesteps: 1,011,279,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457,161.13626
Policy Entropy: 1.05736
Value Function Loss: 2.13620

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.07175
Value Function Update Magnitude: 0.09419

Collected Steps per Second: 3,648.44227
Overall Steps per Second: 3,040.90920

Timestep Collection Time: 13.70667
Timestep Consumption Time: 2.73841
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 16.44508

Cumulative Model Updates: 60,630
Cumulative Timesteps: 1,011,329,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1011329154...
Checkpoint 1011329154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284,288.50224
Policy Entropy: 1.04783
Value Function Loss: 2.16421

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.07517
Value Function Update Magnitude: 0.10802

Collected Steps per Second: 3,650.02235
Overall Steps per Second: 3,044.54574

Timestep Collection Time: 13.70457
Timestep Consumption Time: 2.72546
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 16.43004

Cumulative Model Updates: 60,633
Cumulative Timesteps: 1,011,379,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439,950.73281
Policy Entropy: 1.06194
Value Function Loss: 2.19198

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.15655
Policy Update Magnitude: 0.06573
Value Function Update Magnitude: 0.10990

Collected Steps per Second: 3,651.03036
Overall Steps per Second: 3,057.89259

Timestep Collection Time: 13.70298
Timestep Consumption Time: 2.65796
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 16.36094

Cumulative Model Updates: 60,636
Cumulative Timesteps: 1,011,429,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1011429206...
Checkpoint 1011429206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342,696.81735
Policy Entropy: 1.06334
Value Function Loss: 2.26542

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.07781
Value Function Update Magnitude: 0.10308

Collected Steps per Second: 3,898.25520
Overall Steps per Second: 3,220.54538

Timestep Collection Time: 12.82830
Timestep Consumption Time: 2.69950
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 15.52780

Cumulative Model Updates: 60,639
Cumulative Timesteps: 1,011,479,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738,048.83375
Policy Entropy: 1.07449
Value Function Loss: 2.27857

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.07931
Value Function Update Magnitude: 0.10207

Collected Steps per Second: 3,725.77747
Overall Steps per Second: 3,122.94375

Timestep Collection Time: 13.42109
Timestep Consumption Time: 2.59072
PPO Batch Consumption Time: 0.05903
Total Iteration Time: 16.01182

Cumulative Model Updates: 60,642
Cumulative Timesteps: 1,011,529,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1011529218...
Checkpoint 1011529218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349,937.14214
Policy Entropy: 1.07724
Value Function Loss: 2.19873

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.07747
Value Function Update Magnitude: 0.09719

Collected Steps per Second: 3,637.79746
Overall Steps per Second: 3,064.99850

Timestep Collection Time: 13.75778
Timestep Consumption Time: 2.57111
PPO Batch Consumption Time: 0.05825
Total Iteration Time: 16.32888

Cumulative Model Updates: 60,645
Cumulative Timesteps: 1,011,579,266

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599,374.80064
Policy Entropy: 1.08298
Value Function Loss: 2.09916

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.07499
Value Function Update Magnitude: 0.10159

Collected Steps per Second: 3,638.64765
Overall Steps per Second: 3,097.03444

Timestep Collection Time: 13.74137
Timestep Consumption Time: 2.40311
PPO Batch Consumption Time: 0.06355
Total Iteration Time: 16.14448

Cumulative Model Updates: 60,648
Cumulative Timesteps: 1,011,629,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1011629266...
Checkpoint 1011629266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737,741.96985
Policy Entropy: 1.07798
Value Function Loss: 2.03922

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.07636
Value Function Update Magnitude: 0.10759

Collected Steps per Second: 3,610.74705
Overall Steps per Second: 3,076.21905

Timestep Collection Time: 13.84755
Timestep Consumption Time: 2.40617
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 16.25372

Cumulative Model Updates: 60,651
Cumulative Timesteps: 1,011,679,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453,862.26096
Policy Entropy: 1.08185
Value Function Loss: 2.06993

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.07248
Value Function Update Magnitude: 0.09808

Collected Steps per Second: 3,591.36323
Overall Steps per Second: 3,020.12001

Timestep Collection Time: 13.92285
Timestep Consumption Time: 2.63345
PPO Batch Consumption Time: 0.05238
Total Iteration Time: 16.55630

Cumulative Model Updates: 60,654
Cumulative Timesteps: 1,011,729,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1011729268...
Checkpoint 1011729268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719,148.93731
Policy Entropy: 1.08219
Value Function Loss: 2.12144

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.06942
Value Function Update Magnitude: 0.09835

Collected Steps per Second: 3,709.60104
Overall Steps per Second: 3,115.77188

Timestep Collection Time: 13.48016
Timestep Consumption Time: 2.56916
PPO Batch Consumption Time: 0.05895
Total Iteration Time: 16.04931

Cumulative Model Updates: 60,657
Cumulative Timesteps: 1,011,779,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324,395.97588
Policy Entropy: 1.08595
Value Function Loss: 2.20237

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.07183
Value Function Update Magnitude: 0.10634

Collected Steps per Second: 3,773.35855
Overall Steps per Second: 3,133.47956

Timestep Collection Time: 13.25345
Timestep Consumption Time: 2.70645
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 15.95989

Cumulative Model Updates: 60,660
Cumulative Timesteps: 1,011,829,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1011829284...
Checkpoint 1011829284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527,980.32013
Policy Entropy: 1.08330
Value Function Loss: 2.14894

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.07652
Value Function Update Magnitude: 0.12093

Collected Steps per Second: 3,753.10912
Overall Steps per Second: 3,128.33807

Timestep Collection Time: 13.32549
Timestep Consumption Time: 2.66128
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 15.98676

Cumulative Model Updates: 60,663
Cumulative Timesteps: 1,011,879,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203,186.54049
Policy Entropy: 1.10621
Value Function Loss: 2.18822

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.06782
Value Function Update Magnitude: 0.12477

Collected Steps per Second: 3,636.80825
Overall Steps per Second: 3,077.11964

Timestep Collection Time: 13.75987
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.05798
Total Iteration Time: 16.26261

Cumulative Model Updates: 60,666
Cumulative Timesteps: 1,011,929,338

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1011929338...
Checkpoint 1011929338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252,859.70413
Policy Entropy: 1.11838
Value Function Loss: 2.08183

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.15446
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.11513

Collected Steps per Second: 3,566.14054
Overall Steps per Second: 2,994.57849

Timestep Collection Time: 14.02244
Timestep Consumption Time: 2.67640
PPO Batch Consumption Time: 0.06140
Total Iteration Time: 16.69884

Cumulative Model Updates: 60,669
Cumulative Timesteps: 1,011,979,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434,741.53708
Policy Entropy: 1.10570
Value Function Loss: 2.09198

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.09783

Collected Steps per Second: 3,785.22599
Overall Steps per Second: 3,196.67352

Timestep Collection Time: 13.21031
Timestep Consumption Time: 2.43220
PPO Batch Consumption Time: 0.05265
Total Iteration Time: 15.64251

Cumulative Model Updates: 60,672
Cumulative Timesteps: 1,012,029,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1012029348...
Checkpoint 1012029348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621,590.99998
Policy Entropy: 1.08804
Value Function Loss: 2.18203

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.09182

Collected Steps per Second: 3,538.66381
Overall Steps per Second: 3,006.81690

Timestep Collection Time: 14.13641
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.06280
Total Iteration Time: 16.63686

Cumulative Model Updates: 60,675
Cumulative Timesteps: 1,012,079,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223,841.94300
Policy Entropy: 1.09982
Value Function Loss: 2.15817

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.09303

Collected Steps per Second: 3,654.36287
Overall Steps per Second: 3,041.16049

Timestep Collection Time: 13.68884
Timestep Consumption Time: 2.76014
PPO Batch Consumption Time: 0.06098
Total Iteration Time: 16.44898

Cumulative Model Updates: 60,678
Cumulative Timesteps: 1,012,129,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1012129396...
Checkpoint 1012129396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206,008.52236
Policy Entropy: 1.09941
Value Function Loss: 2.10826

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.14434
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.08907

Collected Steps per Second: 3,708.86330
Overall Steps per Second: 3,089.53815

Timestep Collection Time: 13.48176
Timestep Consumption Time: 2.70254
PPO Batch Consumption Time: 0.05412
Total Iteration Time: 16.18430

Cumulative Model Updates: 60,681
Cumulative Timesteps: 1,012,179,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211,941.04907
Policy Entropy: 1.08934
Value Function Loss: 1.93976

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.09127

Collected Steps per Second: 3,665.80391
Overall Steps per Second: 3,054.26438

Timestep Collection Time: 13.63957
Timestep Consumption Time: 2.73098
PPO Batch Consumption Time: 0.05787
Total Iteration Time: 16.37055

Cumulative Model Updates: 60,684
Cumulative Timesteps: 1,012,229,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1012229398...
Checkpoint 1012229398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357,943.52369
Policy Entropy: 1.08605
Value Function Loss: 1.98535

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.09533

Collected Steps per Second: 3,639.18293
Overall Steps per Second: 3,035.21870

Timestep Collection Time: 13.74374
Timestep Consumption Time: 2.73480
PPO Batch Consumption Time: 0.05288
Total Iteration Time: 16.47855

Cumulative Model Updates: 60,687
Cumulative Timesteps: 1,012,279,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407,041.29545
Policy Entropy: 1.09687
Value Function Loss: 2.00094

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.11305
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.09068

Collected Steps per Second: 3,625.86551
Overall Steps per Second: 3,044.19059

Timestep Collection Time: 13.79478
Timestep Consumption Time: 2.63586
PPO Batch Consumption Time: 0.05258
Total Iteration Time: 16.43064

Cumulative Model Updates: 60,690
Cumulative Timesteps: 1,012,329,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1012329432...
Checkpoint 1012329432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134,471.95175
Policy Entropy: 1.10221
Value Function Loss: 1.96116

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.06438
Value Function Update Magnitude: 0.08252

Collected Steps per Second: 3,740.06794
Overall Steps per Second: 3,129.28926

Timestep Collection Time: 13.37088
Timestep Consumption Time: 2.60975
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 15.98063

Cumulative Model Updates: 60,693
Cumulative Timesteps: 1,012,379,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361,225.38884
Policy Entropy: 1.09936
Value Function Loss: 2.10664

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.07052
Value Function Update Magnitude: 0.08549

Collected Steps per Second: 3,570.70807
Overall Steps per Second: 3,045.53135

Timestep Collection Time: 14.01403
Timestep Consumption Time: 2.41660
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 16.43063

Cumulative Model Updates: 60,696
Cumulative Timesteps: 1,012,429,480

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1012429480...
Checkpoint 1012429480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117,301.06590
Policy Entropy: 1.09362
Value Function Loss: 2.12122

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.07557
Value Function Update Magnitude: 0.08666

Collected Steps per Second: 3,624.02176
Overall Steps per Second: 3,109.22370

Timestep Collection Time: 13.80621
Timestep Consumption Time: 2.28591
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 16.09212

Cumulative Model Updates: 60,699
Cumulative Timesteps: 1,012,479,514

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132,728.25021
Policy Entropy: 1.10701
Value Function Loss: 2.25118

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.06773
Value Function Update Magnitude: 0.10287

Collected Steps per Second: 3,627.46307
Overall Steps per Second: 3,038.25954

Timestep Collection Time: 13.78870
Timestep Consumption Time: 2.67401
PPO Batch Consumption Time: 0.07020
Total Iteration Time: 16.46271

Cumulative Model Updates: 60,702
Cumulative Timesteps: 1,012,529,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1012529532...
Checkpoint 1012529532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290,588.93734
Policy Entropy: 1.11641
Value Function Loss: 2.11873

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.11190

Collected Steps per Second: 3,905.45576
Overall Steps per Second: 3,242.54741

Timestep Collection Time: 12.80312
Timestep Consumption Time: 2.61748
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 15.42059

Cumulative Model Updates: 60,705
Cumulative Timesteps: 1,012,579,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337,344.61870
Policy Entropy: 1.10695
Value Function Loss: 2.11484

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.10850

Collected Steps per Second: 3,640.51724
Overall Steps per Second: 3,067.46393

Timestep Collection Time: 13.73871
Timestep Consumption Time: 2.56662
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 16.30533

Cumulative Model Updates: 60,708
Cumulative Timesteps: 1,012,629,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1012629550...
Checkpoint 1012629550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165,906.30769
Policy Entropy: 1.09206
Value Function Loss: 2.10960

Mean KL Divergence: 0.02592
SB3 Clip Fraction: 0.16597
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.10083

Collected Steps per Second: 3,747.04370
Overall Steps per Second: 3,107.26281

Timestep Collection Time: 13.35666
Timestep Consumption Time: 2.75012
PPO Batch Consumption Time: 0.05281
Total Iteration Time: 16.10678

Cumulative Model Updates: 60,711
Cumulative Timesteps: 1,012,679,598

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449,338.06720
Policy Entropy: 1.10130
Value Function Loss: 2.14033

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.09954

Collected Steps per Second: 3,619.12980
Overall Steps per Second: 3,042.18719

Timestep Collection Time: 13.81934
Timestep Consumption Time: 2.62080
PPO Batch Consumption Time: 0.04824
Total Iteration Time: 16.44015

Cumulative Model Updates: 60,714
Cumulative Timesteps: 1,012,729,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1012729612...
Checkpoint 1012729612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267,302.14320
Policy Entropy: 1.10298
Value Function Loss: 2.09382

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.06946
Value Function Update Magnitude: 0.11124

Collected Steps per Second: 3,923.50661
Overall Steps per Second: 3,226.76600

Timestep Collection Time: 12.75288
Timestep Consumption Time: 2.75367
PPO Batch Consumption Time: 0.06143
Total Iteration Time: 15.50655

Cumulative Model Updates: 60,717
Cumulative Timesteps: 1,012,779,648

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256,598.61811
Policy Entropy: 1.09510
Value Function Loss: 2.02439

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.12367

Collected Steps per Second: 3,602.25523
Overall Steps per Second: 3,045.17723

Timestep Collection Time: 13.88019
Timestep Consumption Time: 2.53921
PPO Batch Consumption Time: 0.05046
Total Iteration Time: 16.41941

Cumulative Model Updates: 60,720
Cumulative Timesteps: 1,012,829,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1012829648...
Checkpoint 1012829648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290,364.04729
Policy Entropy: 1.09717
Value Function Loss: 1.89603

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.07556
Value Function Update Magnitude: 0.11468

Collected Steps per Second: 3,696.93945
Overall Steps per Second: 3,104.79822

Timestep Collection Time: 13.52524
Timestep Consumption Time: 2.57951
PPO Batch Consumption Time: 0.05291
Total Iteration Time: 16.10475

Cumulative Model Updates: 60,723
Cumulative Timesteps: 1,012,879,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216,818.93410
Policy Entropy: 1.08650
Value Function Loss: 1.94069

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.07268
Value Function Update Magnitude: 0.10384

Collected Steps per Second: 3,656.44304
Overall Steps per Second: 3,068.37043

Timestep Collection Time: 13.67668
Timestep Consumption Time: 2.62122
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 16.29790

Cumulative Model Updates: 60,726
Cumulative Timesteps: 1,012,929,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1012929658...
Checkpoint 1012929658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451,485.42230
Policy Entropy: 1.10039
Value Function Loss: 2.05238

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.09408

Collected Steps per Second: 3,587.47043
Overall Steps per Second: 3,016.30829

Timestep Collection Time: 13.94074
Timestep Consumption Time: 2.63979
PPO Batch Consumption Time: 0.06566
Total Iteration Time: 16.58053

Cumulative Model Updates: 60,729
Cumulative Timesteps: 1,012,979,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201,529.56021
Policy Entropy: 1.09759
Value Function Loss: 2.26417

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.15965
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 3,662.92551
Overall Steps per Second: 3,092.96465

Timestep Collection Time: 13.65302
Timestep Consumption Time: 2.51593
PPO Batch Consumption Time: 0.06050
Total Iteration Time: 16.16895

Cumulative Model Updates: 60,732
Cumulative Timesteps: 1,013,029,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1013029680...
Checkpoint 1013029680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541,472.77081
Policy Entropy: 1.08547
Value Function Loss: 2.21209

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.10036

Collected Steps per Second: 3,872.44777
Overall Steps per Second: 3,262.91037

Timestep Collection Time: 12.91173
Timestep Consumption Time: 2.41201
PPO Batch Consumption Time: 0.05783
Total Iteration Time: 15.32374

Cumulative Model Updates: 60,735
Cumulative Timesteps: 1,013,079,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508,050.01121
Policy Entropy: 1.07309
Value Function Loss: 2.13988

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.16885
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 3,526.03755
Overall Steps per Second: 3,020.44903

Timestep Collection Time: 14.19100
Timestep Consumption Time: 2.37541
PPO Batch Consumption Time: 0.04604
Total Iteration Time: 16.56641

Cumulative Model Updates: 60,738
Cumulative Timesteps: 1,013,129,718

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1013129718...
Checkpoint 1013129718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938,325.30643
Policy Entropy: 1.08710
Value Function Loss: 2.10786

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.09006

Collected Steps per Second: 4,357.18696
Overall Steps per Second: 3,568.01442

Timestep Collection Time: 11.47575
Timestep Consumption Time: 2.53820
PPO Batch Consumption Time: 0.04883
Total Iteration Time: 14.01396

Cumulative Model Updates: 60,741
Cumulative Timesteps: 1,013,179,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319,848.56840
Policy Entropy: 1.09567
Value Function Loss: 2.16661

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.06772
Value Function Update Magnitude: 0.09203

Collected Steps per Second: 4,369.76684
Overall Steps per Second: 3,594.37428

Timestep Collection Time: 11.45095
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.04545
Total Iteration Time: 13.92120

Cumulative Model Updates: 60,744
Cumulative Timesteps: 1,013,229,758

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1013229758...
Checkpoint 1013229758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217,465.07357
Policy Entropy: 1.09197
Value Function Loss: 2.24885

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.06873
Value Function Update Magnitude: 0.10519

Collected Steps per Second: 4,348.01051
Overall Steps per Second: 3,526.61275

Timestep Collection Time: 11.50503
Timestep Consumption Time: 2.67968
PPO Batch Consumption Time: 0.05943
Total Iteration Time: 14.18472

Cumulative Model Updates: 60,747
Cumulative Timesteps: 1,013,279,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302,408.73281
Policy Entropy: 1.07259
Value Function Loss: 2.22599

Mean KL Divergence: 0.03705
SB3 Clip Fraction: 0.19956
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.13657

Collected Steps per Second: 4,472.73026
Overall Steps per Second: 3,638.60419

Timestep Collection Time: 11.18601
Timestep Consumption Time: 2.56432
PPO Batch Consumption Time: 0.05040
Total Iteration Time: 13.75033

Cumulative Model Updates: 60,750
Cumulative Timesteps: 1,013,329,814

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1013329814...
Checkpoint 1013329814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250,354.78387
Policy Entropy: 1.09397
Value Function Loss: 2.18885

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.11767
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.14849

Collected Steps per Second: 4,437.69628
Overall Steps per Second: 3,591.57601

Timestep Collection Time: 11.27792
Timestep Consumption Time: 2.65691
PPO Batch Consumption Time: 0.04851
Total Iteration Time: 13.93483

Cumulative Model Updates: 60,753
Cumulative Timesteps: 1,013,379,862

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307,610.71723
Policy Entropy: 1.08738
Value Function Loss: 2.15233

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.07204
Value Function Update Magnitude: 0.13003

Collected Steps per Second: 4,619.47653
Overall Steps per Second: 3,664.01700

Timestep Collection Time: 10.82547
Timestep Consumption Time: 2.82294
PPO Batch Consumption Time: 0.05420
Total Iteration Time: 13.64841

Cumulative Model Updates: 60,756
Cumulative Timesteps: 1,013,429,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1013429870...
Checkpoint 1013429870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474,860.87001
Policy Entropy: 1.09679
Value Function Loss: 2.20185

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.07183
Value Function Update Magnitude: 0.11496

Collected Steps per Second: 4,607.95641
Overall Steps per Second: 3,686.65078

Timestep Collection Time: 10.85644
Timestep Consumption Time: 2.71306
PPO Batch Consumption Time: 0.05309
Total Iteration Time: 13.56950

Cumulative Model Updates: 60,759
Cumulative Timesteps: 1,013,479,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130,128.63690
Policy Entropy: 1.09114
Value Function Loss: 2.30819

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.11708
Policy Update Magnitude: 0.07452
Value Function Update Magnitude: 0.11123

Collected Steps per Second: 4,594.36586
Overall Steps per Second: 3,703.48661

Timestep Collection Time: 10.88768
Timestep Consumption Time: 2.61905
PPO Batch Consumption Time: 0.05355
Total Iteration Time: 13.50673

Cumulative Model Updates: 60,762
Cumulative Timesteps: 1,013,529,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1013529918...
Checkpoint 1013529918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452,404.62973
Policy Entropy: 1.08307
Value Function Loss: 2.36848

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.07360
Value Function Update Magnitude: 0.11003

Collected Steps per Second: 4,485.76836
Overall Steps per Second: 3,651.82011

Timestep Collection Time: 11.15082
Timestep Consumption Time: 2.54646
PPO Batch Consumption Time: 0.04940
Total Iteration Time: 13.69728

Cumulative Model Updates: 60,765
Cumulative Timesteps: 1,013,579,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453,818.63320
Policy Entropy: 1.09844
Value Function Loss: 2.36999

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.12045

Collected Steps per Second: 4,461.97765
Overall Steps per Second: 3,645.54474

Timestep Collection Time: 11.20624
Timestep Consumption Time: 2.50968
PPO Batch Consumption Time: 0.06195
Total Iteration Time: 13.71592

Cumulative Model Updates: 60,768
Cumulative Timesteps: 1,013,629,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1013629940...
Checkpoint 1013629940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175,228.42931
Policy Entropy: 1.09882
Value Function Loss: 2.32001

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.06790
Value Function Update Magnitude: 0.11335

Collected Steps per Second: 4,522.29249
Overall Steps per Second: 3,600.96152

Timestep Collection Time: 11.06076
Timestep Consumption Time: 2.82997
PPO Batch Consumption Time: 0.05047
Total Iteration Time: 13.89073

Cumulative Model Updates: 60,771
Cumulative Timesteps: 1,013,679,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437,784.94319
Policy Entropy: 1.08466
Value Function Loss: 2.11801

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.15825
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.10987

Collected Steps per Second: 4,563.02495
Overall Steps per Second: 3,645.31348

Timestep Collection Time: 10.96203
Timestep Consumption Time: 2.75970
PPO Batch Consumption Time: 0.05025
Total Iteration Time: 13.72173

Cumulative Model Updates: 60,774
Cumulative Timesteps: 1,013,729,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1013729980...
Checkpoint 1013729980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116,885.58831
Policy Entropy: 1.08379
Value Function Loss: 2.01913

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.16729
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.10176

Collected Steps per Second: 4,465.36743
Overall Steps per Second: 3,649.34702

Timestep Collection Time: 11.19997
Timestep Consumption Time: 2.50440
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 13.70437

Cumulative Model Updates: 60,777
Cumulative Timesteps: 1,013,779,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367,115.25394
Policy Entropy: 1.09409
Value Function Loss: 1.94354

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.09467

Collected Steps per Second: 4,556.25147
Overall Steps per Second: 3,703.00510

Timestep Collection Time: 10.97569
Timestep Consumption Time: 2.52902
PPO Batch Consumption Time: 0.05014
Total Iteration Time: 13.50471

Cumulative Model Updates: 60,780
Cumulative Timesteps: 1,013,830,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1013830000...
Checkpoint 1013830000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452,438.12921
Policy Entropy: 1.10252
Value Function Loss: 2.02487

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.11001

Collected Steps per Second: 4,452.33398
Overall Steps per Second: 3,659.80810

Timestep Collection Time: 11.23006
Timestep Consumption Time: 2.43185
PPO Batch Consumption Time: 0.05097
Total Iteration Time: 13.66192

Cumulative Model Updates: 60,783
Cumulative Timesteps: 1,013,880,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300,039.41338
Policy Entropy: 1.07315
Value Function Loss: 2.08847

Mean KL Divergence: 0.03638
SB3 Clip Fraction: 0.18403
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.11367

Collected Steps per Second: 4,465.56398
Overall Steps per Second: 3,711.18937

Timestep Collection Time: 11.20620
Timestep Consumption Time: 2.27789
PPO Batch Consumption Time: 0.04677
Total Iteration Time: 13.48409

Cumulative Model Updates: 60,786
Cumulative Timesteps: 1,013,930,042

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1013930042...
Checkpoint 1013930042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221,281.68214
Policy Entropy: 1.09152
Value Function Loss: 2.11917

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.10312

Collected Steps per Second: 4,516.86098
Overall Steps per Second: 3,701.30071

Timestep Collection Time: 11.07141
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.04713
Total Iteration Time: 13.51093

Cumulative Model Updates: 60,789
Cumulative Timesteps: 1,013,980,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228,403.13657
Policy Entropy: 1.09551
Value Function Loss: 2.15488

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.11065

Collected Steps per Second: 4,460.07695
Overall Steps per Second: 3,590.78169

Timestep Collection Time: 11.21236
Timestep Consumption Time: 2.71441
PPO Batch Consumption Time: 0.05095
Total Iteration Time: 13.92677

Cumulative Model Updates: 60,792
Cumulative Timesteps: 1,014,030,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1014030058...
Checkpoint 1014030058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249,071.98819
Policy Entropy: 1.08130
Value Function Loss: 2.13379

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.11978

Collected Steps per Second: 4,517.10828
Overall Steps per Second: 3,686.44837

Timestep Collection Time: 11.06947
Timestep Consumption Time: 2.49426
PPO Batch Consumption Time: 0.05110
Total Iteration Time: 13.56373

Cumulative Model Updates: 60,795
Cumulative Timesteps: 1,014,080,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469,214.62249
Policy Entropy: 1.06743
Value Function Loss: 1.98823

Mean KL Divergence: 0.02757
SB3 Clip Fraction: 0.18680
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.11841

Collected Steps per Second: 4,555.05694
Overall Steps per Second: 3,661.67451

Timestep Collection Time: 10.97988
Timestep Consumption Time: 2.67889
PPO Batch Consumption Time: 0.05053
Total Iteration Time: 13.65878

Cumulative Model Updates: 60,798
Cumulative Timesteps: 1,014,130,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1014130074...
Checkpoint 1014130074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296,415.95424
Policy Entropy: 1.07588
Value Function Loss: 1.99667

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.10218

Collected Steps per Second: 4,424.93112
Overall Steps per Second: 3,692.68512

Timestep Collection Time: 11.30006
Timestep Consumption Time: 2.24076
PPO Batch Consumption Time: 0.05365
Total Iteration Time: 13.54082

Cumulative Model Updates: 60,801
Cumulative Timesteps: 1,014,180,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,167,067.02911
Policy Entropy: 1.08346
Value Function Loss: 2.02682

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.10420

Collected Steps per Second: 4,530.35460
Overall Steps per Second: 3,639.05265

Timestep Collection Time: 11.04284
Timestep Consumption Time: 2.70469
PPO Batch Consumption Time: 0.04962
Total Iteration Time: 13.74753

Cumulative Model Updates: 60,804
Cumulative Timesteps: 1,014,230,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1014230104...
Checkpoint 1014230104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392,881.78853
Policy Entropy: 1.07840
Value Function Loss: 2.08253

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.11178

Collected Steps per Second: 4,279.08682
Overall Steps per Second: 3,522.32642

Timestep Collection Time: 11.69595
Timestep Consumption Time: 2.51284
PPO Batch Consumption Time: 0.04608
Total Iteration Time: 14.20879

Cumulative Model Updates: 60,807
Cumulative Timesteps: 1,014,280,152

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402,576.95328
Policy Entropy: 1.06851
Value Function Loss: 1.98919

Mean KL Divergence: 0.02994
SB3 Clip Fraction: 0.19383
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.10392

Collected Steps per Second: 4,411.67760
Overall Steps per Second: 3,711.02851

Timestep Collection Time: 11.33900
Timestep Consumption Time: 2.14082
PPO Batch Consumption Time: 0.05051
Total Iteration Time: 13.47982

Cumulative Model Updates: 60,810
Cumulative Timesteps: 1,014,330,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1014330176...
Checkpoint 1014330176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300,105.08159
Policy Entropy: 1.08967
Value Function Loss: 1.87297

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.10163

Collected Steps per Second: 4,350.47387
Overall Steps per Second: 3,536.50249

Timestep Collection Time: 11.50265
Timestep Consumption Time: 2.64748
PPO Batch Consumption Time: 0.04693
Total Iteration Time: 14.15014

Cumulative Model Updates: 60,813
Cumulative Timesteps: 1,014,380,218

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443,441.78702
Policy Entropy: 1.08678
Value Function Loss: 1.95684

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.09335

Collected Steps per Second: 4,335.03279
Overall Steps per Second: 3,508.47713

Timestep Collection Time: 11.53532
Timestep Consumption Time: 2.71759
PPO Batch Consumption Time: 0.04490
Total Iteration Time: 14.25291

Cumulative Model Updates: 60,816
Cumulative Timesteps: 1,014,430,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1014430224...
Checkpoint 1014430224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363,482.93570
Policy Entropy: 1.06230
Value Function Loss: 2.03857

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.15685
Policy Update Magnitude: 0.06785
Value Function Update Magnitude: 0.09032

Collected Steps per Second: 4,302.29488
Overall Steps per Second: 3,517.08160

Timestep Collection Time: 11.62542
Timestep Consumption Time: 2.59546
PPO Batch Consumption Time: 0.05432
Total Iteration Time: 14.22088

Cumulative Model Updates: 60,819
Cumulative Timesteps: 1,014,480,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588,506.62539
Policy Entropy: 1.07140
Value Function Loss: 2.12707

Mean KL Divergence: 0.02715
SB3 Clip Fraction: 0.17727
Policy Update Magnitude: 0.06140
Value Function Update Magnitude: 0.09471

Collected Steps per Second: 4,211.19191
Overall Steps per Second: 3,501.12045

Timestep Collection Time: 11.88452
Timestep Consumption Time: 2.41033
PPO Batch Consumption Time: 0.05021
Total Iteration Time: 14.29485

Cumulative Model Updates: 60,822
Cumulative Timesteps: 1,014,530,288

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1014530288...
Checkpoint 1014530288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389,450.08492
Policy Entropy: 1.07250
Value Function Loss: 2.17199

Mean KL Divergence: 0.02554
SB3 Clip Fraction: 0.17731
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.10479

Collected Steps per Second: 4,342.71587
Overall Steps per Second: 3,493.67431

Timestep Collection Time: 11.52320
Timestep Consumption Time: 2.80040
PPO Batch Consumption Time: 0.04988
Total Iteration Time: 14.32360

Cumulative Model Updates: 60,825
Cumulative Timesteps: 1,014,580,330

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275,218.97663
Policy Entropy: 1.07112
Value Function Loss: 2.14522

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.11430

Collected Steps per Second: 4,423.46041
Overall Steps per Second: 3,547.26391

Timestep Collection Time: 11.31105
Timestep Consumption Time: 2.79390
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 14.10496

Cumulative Model Updates: 60,828
Cumulative Timesteps: 1,014,630,364

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1014630364...
Checkpoint 1014630364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458,772.99504
Policy Entropy: 1.05741
Value Function Loss: 2.05695

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.19317
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 4,337.54832
Overall Steps per Second: 3,537.97527

Timestep Collection Time: 11.53693
Timestep Consumption Time: 2.60732
PPO Batch Consumption Time: 0.05866
Total Iteration Time: 14.14425

Cumulative Model Updates: 60,831
Cumulative Timesteps: 1,014,680,406

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263,426.25151
Policy Entropy: 1.07904
Value Function Loss: 1.93508

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.11136

Collected Steps per Second: 4,169.36368
Overall Steps per Second: 3,408.64752

Timestep Collection Time: 11.99368
Timestep Consumption Time: 2.67666
PPO Batch Consumption Time: 0.05418
Total Iteration Time: 14.67033

Cumulative Model Updates: 60,834
Cumulative Timesteps: 1,014,730,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1014730412...
Checkpoint 1014730412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345,646.30930
Policy Entropy: 1.06402
Value Function Loss: 1.96917

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.10288

Collected Steps per Second: 4,073.68733
Overall Steps per Second: 3,351.95317

Timestep Collection Time: 12.27635
Timestep Consumption Time: 2.64331
PPO Batch Consumption Time: 0.05188
Total Iteration Time: 14.91966

Cumulative Model Updates: 60,837
Cumulative Timesteps: 1,014,780,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326,802.11805
Policy Entropy: 1.06146
Value Function Loss: 2.05214

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.17163
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.10729

Collected Steps per Second: 4,259.00276
Overall Steps per Second: 3,499.77126

Timestep Collection Time: 11.74923
Timestep Consumption Time: 2.54885
PPO Batch Consumption Time: 0.05248
Total Iteration Time: 14.29808

Cumulative Model Updates: 60,840
Cumulative Timesteps: 1,014,830,462

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1014830462...
Checkpoint 1014830462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278,363.11787
Policy Entropy: 1.07582
Value Function Loss: 2.12916

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.12453

Collected Steps per Second: 4,278.40427
Overall Steps per Second: 3,511.87129

Timestep Collection Time: 11.69127
Timestep Consumption Time: 2.55184
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 14.24312

Cumulative Model Updates: 60,843
Cumulative Timesteps: 1,014,880,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294,197.97714
Policy Entropy: 1.08267
Value Function Loss: 2.11706

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.14729

Collected Steps per Second: 3,975.52895
Overall Steps per Second: 3,358.49091

Timestep Collection Time: 12.58449
Timestep Consumption Time: 2.31208
PPO Batch Consumption Time: 0.05016
Total Iteration Time: 14.89657

Cumulative Model Updates: 60,846
Cumulative Timesteps: 1,014,930,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1014930512...
Checkpoint 1014930512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405,115.85536
Policy Entropy: 1.06692
Value Function Loss: 2.14489

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.15074

Collected Steps per Second: 4,571.64562
Overall Steps per Second: 3,754.69808

Timestep Collection Time: 10.94136
Timestep Consumption Time: 2.38062
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 13.32198

Cumulative Model Updates: 60,849
Cumulative Timesteps: 1,014,980,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566,597.50168
Policy Entropy: 1.05719
Value Function Loss: 2.04570

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.16549
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.14330

Collected Steps per Second: 4,454.66337
Overall Steps per Second: 3,595.88024

Timestep Collection Time: 11.23227
Timestep Consumption Time: 2.68254
PPO Batch Consumption Time: 0.06345
Total Iteration Time: 13.91481

Cumulative Model Updates: 60,852
Cumulative Timesteps: 1,015,030,568

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1015030568...
Checkpoint 1015030568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309,613.41462
Policy Entropy: 1.07906
Value Function Loss: 1.94584

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 4,504.74706
Overall Steps per Second: 3,621.36628

Timestep Collection Time: 11.10562
Timestep Consumption Time: 2.70906
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 13.81468

Cumulative Model Updates: 60,855
Cumulative Timesteps: 1,015,080,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248,476.43077
Policy Entropy: 1.08056
Value Function Loss: 1.95975

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 4,540.91526
Overall Steps per Second: 3,647.91680

Timestep Collection Time: 11.01584
Timestep Consumption Time: 2.69664
PPO Batch Consumption Time: 0.06073
Total Iteration Time: 13.71248

Cumulative Model Updates: 60,858
Cumulative Timesteps: 1,015,130,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1015130618...
Checkpoint 1015130618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839,631.16236
Policy Entropy: 1.07425
Value Function Loss: 2.06423

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.07681
Value Function Update Magnitude: 0.11663

Collected Steps per Second: 4,481.85500
Overall Steps per Second: 3,604.20615

Timestep Collection Time: 11.15743
Timestep Consumption Time: 2.71691
PPO Batch Consumption Time: 0.04746
Total Iteration Time: 13.87435

Cumulative Model Updates: 60,861
Cumulative Timesteps: 1,015,180,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657,240.07669
Policy Entropy: 1.06370
Value Function Loss: 2.16758

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.15529
Policy Update Magnitude: 0.07269
Value Function Update Magnitude: 0.11986

Collected Steps per Second: 4,413.60923
Overall Steps per Second: 3,531.16045

Timestep Collection Time: 11.33539
Timestep Consumption Time: 2.83275
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 14.16815

Cumulative Model Updates: 60,864
Cumulative Timesteps: 1,015,230,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1015230654...
Checkpoint 1015230654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358,192.52802
Policy Entropy: 1.07993
Value Function Loss: 2.19021

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.15507
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.10548

Collected Steps per Second: 4,235.15169
Overall Steps per Second: 3,490.09900

Timestep Collection Time: 11.81493
Timestep Consumption Time: 2.52220
PPO Batch Consumption Time: 0.04758
Total Iteration Time: 14.33713

Cumulative Model Updates: 60,867
Cumulative Timesteps: 1,015,280,692

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372,643.69077
Policy Entropy: 1.07976
Value Function Loss: 2.23789

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.17093
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.09106

Collected Steps per Second: 4,336.56358
Overall Steps per Second: 3,504.68372

Timestep Collection Time: 11.52987
Timestep Consumption Time: 2.73676
PPO Batch Consumption Time: 0.05079
Total Iteration Time: 14.26662

Cumulative Model Updates: 60,870
Cumulative Timesteps: 1,015,330,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1015330692...
Checkpoint 1015330692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270,529.75700
Policy Entropy: 1.07438
Value Function Loss: 2.17811

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.05788
Value Function Update Magnitude: 0.08034

Collected Steps per Second: 4,255.76056
Overall Steps per Second: 3,502.20588

Timestep Collection Time: 11.76006
Timestep Consumption Time: 2.53036
PPO Batch Consumption Time: 0.04887
Total Iteration Time: 14.29042

Cumulative Model Updates: 60,873
Cumulative Timesteps: 1,015,380,740

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416,996.07517
Policy Entropy: 1.06610
Value Function Loss: 2.06320

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.16995
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.08214

Collected Steps per Second: 4,304.71204
Overall Steps per Second: 3,507.14395

Timestep Collection Time: 11.62168
Timestep Consumption Time: 2.64292
PPO Batch Consumption Time: 0.04965
Total Iteration Time: 14.26460

Cumulative Model Updates: 60,876
Cumulative Timesteps: 1,015,430,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1015430768...
Checkpoint 1015430768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539,148.22732
Policy Entropy: 1.07493
Value Function Loss: 2.00361

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.07930

Collected Steps per Second: 4,143.68315
Overall Steps per Second: 3,377.71698

Timestep Collection Time: 12.06897
Timestep Consumption Time: 2.73689
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 14.80586

Cumulative Model Updates: 60,879
Cumulative Timesteps: 1,015,480,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347,576.41760
Policy Entropy: 1.08172
Value Function Loss: 2.02227

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.06900

Collected Steps per Second: 4,227.10508
Overall Steps per Second: 3,492.00506

Timestep Collection Time: 11.83363
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 14.32472

Cumulative Model Updates: 60,882
Cumulative Timesteps: 1,015,530,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1015530800...
Checkpoint 1015530800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130,194.38250
Policy Entropy: 1.05735
Value Function Loss: 2.11315

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 4,267.55556
Overall Steps per Second: 3,469.40649

Timestep Collection Time: 11.71631
Timestep Consumption Time: 2.69538
PPO Batch Consumption Time: 0.06305
Total Iteration Time: 14.41169

Cumulative Model Updates: 60,885
Cumulative Timesteps: 1,015,580,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286,512.38149
Policy Entropy: 1.05796
Value Function Loss: 2.12905

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.06395

Collected Steps per Second: 4,292.05108
Overall Steps per Second: 3,461.35972

Timestep Collection Time: 11.65317
Timestep Consumption Time: 2.79664
PPO Batch Consumption Time: 0.05123
Total Iteration Time: 14.44981

Cumulative Model Updates: 60,888
Cumulative Timesteps: 1,015,630,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1015630816...
Checkpoint 1015630816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798,856.73666
Policy Entropy: 1.07409
Value Function Loss: 2.20825

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 4,253.85914
Overall Steps per Second: 3,461.48344

Timestep Collection Time: 11.76297
Timestep Consumption Time: 2.69269
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 14.45565

Cumulative Model Updates: 60,891
Cumulative Timesteps: 1,015,680,854

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518,204.11074
Policy Entropy: 1.08453
Value Function Loss: 2.23439

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.07240

Collected Steps per Second: 4,526.58628
Overall Steps per Second: 3,643.27988

Timestep Collection Time: 11.05071
Timestep Consumption Time: 2.67922
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 13.72994

Cumulative Model Updates: 60,894
Cumulative Timesteps: 1,015,730,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1015730876...
Checkpoint 1015730876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625,662.60440
Policy Entropy: 1.06095
Value Function Loss: 2.15237

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 4,332.15949
Overall Steps per Second: 3,512.35833

Timestep Collection Time: 11.55174
Timestep Consumption Time: 2.69623
PPO Batch Consumption Time: 0.04798
Total Iteration Time: 14.24798

Cumulative Model Updates: 60,897
Cumulative Timesteps: 1,015,780,920

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626,371.51239
Policy Entropy: 1.05457
Value Function Loss: 2.09172

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.17218
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 4,397.01337
Overall Steps per Second: 3,532.76168

Timestep Collection Time: 11.37545
Timestep Consumption Time: 2.78288
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 14.15833

Cumulative Model Updates: 60,900
Cumulative Timesteps: 1,015,830,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1015830938...
Checkpoint 1015830938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269,158.24903
Policy Entropy: 1.06740
Value Function Loss: 2.04389

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.06675

Collected Steps per Second: 4,340.07578
Overall Steps per Second: 3,507.42339

Timestep Collection Time: 11.52146
Timestep Consumption Time: 2.73516
PPO Batch Consumption Time: 0.04920
Total Iteration Time: 14.25662

Cumulative Model Updates: 60,903
Cumulative Timesteps: 1,015,880,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316,972.59067
Policy Entropy: 1.08419
Value Function Loss: 2.18438

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.06394

Collected Steps per Second: 4,446.45798
Overall Steps per Second: 3,607.69930

Timestep Collection Time: 11.25075
Timestep Consumption Time: 2.61570
PPO Batch Consumption Time: 0.05090
Total Iteration Time: 13.86645

Cumulative Model Updates: 60,906
Cumulative Timesteps: 1,015,930,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1015930968...
Checkpoint 1015930968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226,784.27210
Policy Entropy: 1.06271
Value Function Loss: 2.11970

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 4,325.14605
Overall Steps per Second: 3,573.13064

Timestep Collection Time: 11.56909
Timestep Consumption Time: 2.43488
PPO Batch Consumption Time: 0.05214
Total Iteration Time: 14.00397

Cumulative Model Updates: 60,909
Cumulative Timesteps: 1,015,981,006

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664,773.76178
Policy Entropy: 1.07284
Value Function Loss: 2.20695

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.07968

Collected Steps per Second: 4,290.62733
Overall Steps per Second: 3,535.54883

Timestep Collection Time: 11.65657
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.05382
Total Iteration Time: 14.14604

Cumulative Model Updates: 60,912
Cumulative Timesteps: 1,016,031,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1016031020...
Checkpoint 1016031020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253,651.71766
Policy Entropy: 1.07192
Value Function Loss: 2.08071

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.07522

Collected Steps per Second: 4,230.24858
Overall Steps per Second: 3,525.05664

Timestep Collection Time: 11.82578
Timestep Consumption Time: 2.36576
PPO Batch Consumption Time: 0.04857
Total Iteration Time: 14.19154

Cumulative Model Updates: 60,915
Cumulative Timesteps: 1,016,081,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259,788.38276
Policy Entropy: 1.06787
Value Function Loss: 2.10448

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.07668
Value Function Update Magnitude: 0.08581

Collected Steps per Second: 4,271.56579
Overall Steps per Second: 3,477.96405

Timestep Collection Time: 11.71280
Timestep Consumption Time: 2.67263
PPO Batch Consumption Time: 0.05207
Total Iteration Time: 14.38543

Cumulative Model Updates: 60,918
Cumulative Timesteps: 1,016,131,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1016131078...
Checkpoint 1016131078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262,105.18535
Policy Entropy: 1.06935
Value Function Loss: 2.00015

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.07691
Value Function Update Magnitude: 0.10481

Collected Steps per Second: 4,175.16211
Overall Steps per Second: 3,430.06333

Timestep Collection Time: 11.98564
Timestep Consumption Time: 2.60359
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 14.58923

Cumulative Model Updates: 60,921
Cumulative Timesteps: 1,016,181,120

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690,967.81543
Policy Entropy: 1.07032
Value Function Loss: 1.93789

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.08404
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 4,094.40138
Overall Steps per Second: 3,362.54200

Timestep Collection Time: 12.22157
Timestep Consumption Time: 2.66003
PPO Batch Consumption Time: 0.05234
Total Iteration Time: 14.88160

Cumulative Model Updates: 60,924
Cumulative Timesteps: 1,016,231,160

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1016231160...
Checkpoint 1016231160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382,665.98942
Policy Entropy: 1.07799
Value Function Loss: 1.92467

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.08124
Value Function Update Magnitude: 0.10269

Collected Steps per Second: 4,609.44193
Overall Steps per Second: 3,732.09399

Timestep Collection Time: 10.85337
Timestep Consumption Time: 2.55143
PPO Batch Consumption Time: 0.06811
Total Iteration Time: 13.40481

Cumulative Model Updates: 60,927
Cumulative Timesteps: 1,016,281,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060,935.93433
Policy Entropy: 1.08362
Value Function Loss: 1.92521

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.07219
Value Function Update Magnitude: 0.10288

Collected Steps per Second: 4,182.31057
Overall Steps per Second: 3,496.90536

Timestep Collection Time: 11.95559
Timestep Consumption Time: 2.34334
PPO Batch Consumption Time: 0.04868
Total Iteration Time: 14.29893

Cumulative Model Updates: 60,930
Cumulative Timesteps: 1,016,331,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1016331190...
Checkpoint 1016331190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434,999.47921
Policy Entropy: 1.08389
Value Function Loss: 2.00089

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.06881
Value Function Update Magnitude: 0.09953

Collected Steps per Second: 4,471.56627
Overall Steps per Second: 3,616.26345

Timestep Collection Time: 11.18892
Timestep Consumption Time: 2.64635
PPO Batch Consumption Time: 0.06197
Total Iteration Time: 13.83528

Cumulative Model Updates: 60,933
Cumulative Timesteps: 1,016,381,222

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624,147.85221
Policy Entropy: 1.08055
Value Function Loss: 2.05051

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.07764
Value Function Update Magnitude: 0.09725

Collected Steps per Second: 4,262.44382
Overall Steps per Second: 3,545.36684

Timestep Collection Time: 11.73693
Timestep Consumption Time: 2.37388
PPO Batch Consumption Time: 0.04986
Total Iteration Time: 14.11081

Cumulative Model Updates: 60,936
Cumulative Timesteps: 1,016,431,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1016431250...
Checkpoint 1016431250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712,835.52119
Policy Entropy: 1.07808
Value Function Loss: 2.06434

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.07431
Value Function Update Magnitude: 0.09865

Collected Steps per Second: 4,357.16583
Overall Steps per Second: 3,532.06556

Timestep Collection Time: 11.48407
Timestep Consumption Time: 2.68271
PPO Batch Consumption Time: 0.06234
Total Iteration Time: 14.16678

Cumulative Model Updates: 60,939
Cumulative Timesteps: 1,016,481,288

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443,854.63606
Policy Entropy: 1.07962
Value Function Loss: 1.98861

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.07716
Value Function Update Magnitude: 0.10885

Collected Steps per Second: 4,310.50467
Overall Steps per Second: 3,515.28775

Timestep Collection Time: 11.60607
Timestep Consumption Time: 2.62549
PPO Batch Consumption Time: 0.04995
Total Iteration Time: 14.23155

Cumulative Model Updates: 60,942
Cumulative Timesteps: 1,016,531,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1016531316...
Checkpoint 1016531316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407,462.75792
Policy Entropy: 1.09027
Value Function Loss: 1.96440

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.06991
Value Function Update Magnitude: 0.10642

Collected Steps per Second: 4,364.49452
Overall Steps per Second: 3,585.44467

Timestep Collection Time: 11.45746
Timestep Consumption Time: 2.48949
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 13.94695

Cumulative Model Updates: 60,945
Cumulative Timesteps: 1,016,581,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642,210.75292
Policy Entropy: 1.09335
Value Function Loss: 2.10615

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.06708
Value Function Update Magnitude: 0.10066

Collected Steps per Second: 4,363.67956
Overall Steps per Second: 3,546.15748

Timestep Collection Time: 11.45959
Timestep Consumption Time: 2.64187
PPO Batch Consumption Time: 0.05235
Total Iteration Time: 14.10146

Cumulative Model Updates: 60,948
Cumulative Timesteps: 1,016,631,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1016631328...
Checkpoint 1016631328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361,716.32800
Policy Entropy: 1.07189
Value Function Loss: 2.13754

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.15866
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.09115

Collected Steps per Second: 4,442.31275
Overall Steps per Second: 3,566.65501

Timestep Collection Time: 11.25720
Timestep Consumption Time: 2.76378
PPO Batch Consumption Time: 0.04821
Total Iteration Time: 14.02098

Cumulative Model Updates: 60,951
Cumulative Timesteps: 1,016,681,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568,157.10534
Policy Entropy: 1.06565
Value Function Loss: 2.10044

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.17836
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.09713

Collected Steps per Second: 4,153.58815
Overall Steps per Second: 3,401.85988

Timestep Collection Time: 12.04453
Timestep Consumption Time: 2.66155
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 14.70607

Cumulative Model Updates: 60,954
Cumulative Timesteps: 1,016,731,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1016731364...
Checkpoint 1016731364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293,844.79786
Policy Entropy: 1.08156
Value Function Loss: 1.99811

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.10050

Collected Steps per Second: 4,179.99103
Overall Steps per Second: 3,468.17490

Timestep Collection Time: 11.97084
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.04959
Total Iteration Time: 14.42776

Cumulative Model Updates: 60,957
Cumulative Timesteps: 1,016,781,402

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045,261.30277
Policy Entropy: 1.08559
Value Function Loss: 2.04812

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.11213

Collected Steps per Second: 4,710.90759
Overall Steps per Second: 3,895.34779

Timestep Collection Time: 10.62216
Timestep Consumption Time: 2.22394
PPO Batch Consumption Time: 0.04660
Total Iteration Time: 12.84609

Cumulative Model Updates: 60,960
Cumulative Timesteps: 1,016,831,442

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1016831442...
Checkpoint 1016831442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185,716.89896
Policy Entropy: 1.06772
Value Function Loss: 2.13772

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.11809

Collected Steps per Second: 4,541.27377
Overall Steps per Second: 3,714.29040

Timestep Collection Time: 11.01893
Timestep Consumption Time: 2.45336
PPO Batch Consumption Time: 0.05094
Total Iteration Time: 13.47229

Cumulative Model Updates: 60,963
Cumulative Timesteps: 1,016,881,482

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227,272.38391
Policy Entropy: 1.05321
Value Function Loss: 2.10398

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.16769
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.13178

Collected Steps per Second: 4,422.24253
Overall Steps per Second: 3,565.71379

Timestep Collection Time: 11.31236
Timestep Consumption Time: 2.71737
PPO Batch Consumption Time: 0.04915
Total Iteration Time: 14.02973

Cumulative Model Updates: 60,966
Cumulative Timesteps: 1,016,931,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1016931508...
Checkpoint 1016931508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210,940.39868
Policy Entropy: 1.06494
Value Function Loss: 2.11099

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.13601

Collected Steps per Second: 4,424.02740
Overall Steps per Second: 3,570.10918

Timestep Collection Time: 11.30689
Timestep Consumption Time: 2.70444
PPO Batch Consumption Time: 0.04728
Total Iteration Time: 14.01134

Cumulative Model Updates: 60,969
Cumulative Timesteps: 1,016,981,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,103.93991
Policy Entropy: 1.08079
Value Function Loss: 2.03075

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.13315

Collected Steps per Second: 4,329.05572
Overall Steps per Second: 3,479.28278

Timestep Collection Time: 11.55772
Timestep Consumption Time: 2.82283
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 14.38055

Cumulative Model Updates: 60,972
Cumulative Timesteps: 1,017,031,564

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1017031564...
Checkpoint 1017031564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477,858.70095
Policy Entropy: 1.06476
Value Function Loss: 1.99270

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.06289
Value Function Update Magnitude: 0.12854

Collected Steps per Second: 4,235.72713
Overall Steps per Second: 3,459.05286

Timestep Collection Time: 11.80577
Timestep Consumption Time: 2.65079
PPO Batch Consumption Time: 0.05141
Total Iteration Time: 14.45656

Cumulative Model Updates: 60,975
Cumulative Timesteps: 1,017,081,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446,020.17486
Policy Entropy: 1.08085
Value Function Loss: 2.02668

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.16219
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.12588

Collected Steps per Second: 4,177.55525
Overall Steps per Second: 3,415.24719

Timestep Collection Time: 11.97351
Timestep Consumption Time: 2.67257
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 14.64608

Cumulative Model Updates: 60,978
Cumulative Timesteps: 1,017,131,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1017131590...
Checkpoint 1017131590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204,800.39994
Policy Entropy: 1.07697
Value Function Loss: 2.03351

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 4,038.79315
Overall Steps per Second: 3,319.49304

Timestep Collection Time: 12.38439
Timestep Consumption Time: 2.68357
PPO Batch Consumption Time: 0.05037
Total Iteration Time: 15.06796

Cumulative Model Updates: 60,981
Cumulative Timesteps: 1,017,181,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969,917.21037
Policy Entropy: 1.06297
Value Function Loss: 2.06417

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.13503

Collected Steps per Second: 4,036.57101
Overall Steps per Second: 3,313.45953

Timestep Collection Time: 12.39319
Timestep Consumption Time: 2.70462
PPO Batch Consumption Time: 0.05423
Total Iteration Time: 15.09782

Cumulative Model Updates: 60,984
Cumulative Timesteps: 1,017,231,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1017231634...
Checkpoint 1017231634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245,964.01981
Policy Entropy: 1.06872
Value Function Loss: 1.94924

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.16031
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.14622

Collected Steps per Second: 4,094.20301
Overall Steps per Second: 3,430.61446

Timestep Collection Time: 12.21630
Timestep Consumption Time: 2.36302
PPO Batch Consumption Time: 0.05179
Total Iteration Time: 14.57931

Cumulative Model Updates: 60,987
Cumulative Timesteps: 1,017,281,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581,316.87437
Policy Entropy: 1.07192
Value Function Loss: 1.92827

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.13767

Collected Steps per Second: 4,078.11036
Overall Steps per Second: 3,414.34227

Timestep Collection Time: 12.26058
Timestep Consumption Time: 2.38353
PPO Batch Consumption Time: 0.05169
Total Iteration Time: 14.64411

Cumulative Model Updates: 60,990
Cumulative Timesteps: 1,017,331,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1017331650...
Checkpoint 1017331650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353,656.22140
Policy Entropy: 1.07939
Value Function Loss: 1.92316

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.11693

Collected Steps per Second: 4,012.65338
Overall Steps per Second: 3,358.34318

Timestep Collection Time: 12.47155
Timestep Consumption Time: 2.42985
PPO Batch Consumption Time: 0.05288
Total Iteration Time: 14.90140

Cumulative Model Updates: 60,993
Cumulative Timesteps: 1,017,381,694

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349,595.77634
Policy Entropy: 1.05966
Value Function Loss: 1.92398

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.05876
Value Function Update Magnitude: 0.12928

Collected Steps per Second: 4,071.45777
Overall Steps per Second: 3,349.00730

Timestep Collection Time: 12.28307
Timestep Consumption Time: 2.64971
PPO Batch Consumption Time: 0.05422
Total Iteration Time: 14.93278

Cumulative Model Updates: 60,996
Cumulative Timesteps: 1,017,431,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1017431704...
Checkpoint 1017431704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878,090.31813
Policy Entropy: 1.07337
Value Function Loss: 1.98388

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.12988

Collected Steps per Second: 4,054.16676
Overall Steps per Second: 3,381.35158

Timestep Collection Time: 12.34384
Timestep Consumption Time: 2.45616
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 14.80000

Cumulative Model Updates: 60,999
Cumulative Timesteps: 1,017,481,748

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367,466.41557
Policy Entropy: 1.07957
Value Function Loss: 1.99153

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.12721

Collected Steps per Second: 4,111.40445
Overall Steps per Second: 3,376.78855

Timestep Collection Time: 12.16859
Timestep Consumption Time: 2.64726
PPO Batch Consumption Time: 0.05276
Total Iteration Time: 14.81585

Cumulative Model Updates: 61,002
Cumulative Timesteps: 1,017,531,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1017531778...
Checkpoint 1017531778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537,974.73196
Policy Entropy: 1.08959
Value Function Loss: 1.99646

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.17003
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.11951

Collected Steps per Second: 4,008.23189
Overall Steps per Second: 3,353.45626

Timestep Collection Time: 12.47732
Timestep Consumption Time: 2.43625
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 14.91357

Cumulative Model Updates: 61,005
Cumulative Timesteps: 1,017,581,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505,302.70127
Policy Entropy: 1.06785
Value Function Loss: 1.91995

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.06629
Value Function Update Magnitude: 0.12411

Collected Steps per Second: 4,119.97655
Overall Steps per Second: 3,374.93235

Timestep Collection Time: 12.13842
Timestep Consumption Time: 2.67966
PPO Batch Consumption Time: 0.05831
Total Iteration Time: 14.81807

Cumulative Model Updates: 61,008
Cumulative Timesteps: 1,017,631,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1017631800...
Checkpoint 1017631800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809,572.99902
Policy Entropy: 1.08660
Value Function Loss: 1.92127

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.16847
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.12748

Collected Steps per Second: 4,036.10600
Overall Steps per Second: 3,379.71040

Timestep Collection Time: 12.39363
Timestep Consumption Time: 2.40705
PPO Batch Consumption Time: 0.04992
Total Iteration Time: 14.80068

Cumulative Model Updates: 61,011
Cumulative Timesteps: 1,017,681,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690,326.43958
Policy Entropy: 1.08226
Value Function Loss: 2.05087

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.15773
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.12735

Collected Steps per Second: 4,242.89357
Overall Steps per Second: 3,571.06420

Timestep Collection Time: 11.78865
Timestep Consumption Time: 2.21782
PPO Batch Consumption Time: 0.05164
Total Iteration Time: 14.00647

Cumulative Model Updates: 61,014
Cumulative Timesteps: 1,017,731,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1017731840...
Checkpoint 1017731840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,738.88552
Policy Entropy: 1.07434
Value Function Loss: 2.16412

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.14645
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.14108

Collected Steps per Second: 4,231.89653
Overall Steps per Second: 3,451.76018

Timestep Collection Time: 11.82354
Timestep Consumption Time: 2.67225
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 14.49579

Cumulative Model Updates: 61,017
Cumulative Timesteps: 1,017,781,876

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315,016.25589
Policy Entropy: 1.05240
Value Function Loss: 2.14059

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.17377
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.13976

Collected Steps per Second: 4,145.10756
Overall Steps per Second: 3,405.08869

Timestep Collection Time: 12.06965
Timestep Consumption Time: 2.62307
PPO Batch Consumption Time: 0.04836
Total Iteration Time: 14.69272

Cumulative Model Updates: 61,020
Cumulative Timesteps: 1,017,831,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1017831906...
Checkpoint 1017831906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328,241.51595
Policy Entropy: 1.06571
Value Function Loss: 2.12131

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.13124

Collected Steps per Second: 3,881.54315
Overall Steps per Second: 3,261.09473

Timestep Collection Time: 12.88920
Timestep Consumption Time: 2.45227
PPO Batch Consumption Time: 0.05206
Total Iteration Time: 15.34147

Cumulative Model Updates: 61,023
Cumulative Timesteps: 1,017,881,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141,068.73702
Policy Entropy: 1.07674
Value Function Loss: 1.95293

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.12293

Collected Steps per Second: 3,994.96478
Overall Steps per Second: 3,318.67115

Timestep Collection Time: 12.52427
Timestep Consumption Time: 2.55225
PPO Batch Consumption Time: 0.04850
Total Iteration Time: 15.07652

Cumulative Model Updates: 61,026
Cumulative Timesteps: 1,017,931,970

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1017931970...
Checkpoint 1017931970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347,313.91414
Policy Entropy: 1.07230
Value Function Loss: 1.94470

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.10935

Collected Steps per Second: 4,031.69339
Overall Steps per Second: 3,310.73023

Timestep Collection Time: 12.41513
Timestep Consumption Time: 2.70359
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 15.11872

Cumulative Model Updates: 61,029
Cumulative Timesteps: 1,017,982,024

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413,913.90821
Policy Entropy: 1.07653
Value Function Loss: 2.00204

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.11385

Collected Steps per Second: 4,090.15272
Overall Steps per Second: 3,307.72480

Timestep Collection Time: 12.22448
Timestep Consumption Time: 2.89165
PPO Batch Consumption Time: 0.05984
Total Iteration Time: 15.11613

Cumulative Model Updates: 61,032
Cumulative Timesteps: 1,018,032,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1018032024...
Checkpoint 1018032024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300,792.36632
Policy Entropy: 1.08299
Value Function Loss: 2.05673

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.10468

Collected Steps per Second: 4,037.05999
Overall Steps per Second: 3,375.14958

Timestep Collection Time: 12.38624
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.05190
Total Iteration Time: 14.81534

Cumulative Model Updates: 61,035
Cumulative Timesteps: 1,018,082,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425,738.30344
Policy Entropy: 1.09846
Value Function Loss: 1.99205

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.06268
Value Function Update Magnitude: 0.10160

Collected Steps per Second: 4,113.62909
Overall Steps per Second: 3,368.90255

Timestep Collection Time: 12.16396
Timestep Consumption Time: 2.68895
PPO Batch Consumption Time: 0.05003
Total Iteration Time: 14.85291

Cumulative Model Updates: 61,038
Cumulative Timesteps: 1,018,132,066

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1018132066...
Checkpoint 1018132066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822,952.22302
Policy Entropy: 1.08275
Value Function Loss: 1.79937

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.10891

Collected Steps per Second: 4,248.20930
Overall Steps per Second: 3,433.62409

Timestep Collection Time: 11.78096
Timestep Consumption Time: 2.79489
PPO Batch Consumption Time: 0.05092
Total Iteration Time: 14.57585

Cumulative Model Updates: 61,041
Cumulative Timesteps: 1,018,182,114

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440,034.27826
Policy Entropy: 1.07821
Value Function Loss: 1.84144

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.15696
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.10300

Collected Steps per Second: 4,027.19244
Overall Steps per Second: 3,333.30973

Timestep Collection Time: 12.42354
Timestep Consumption Time: 2.58616
PPO Batch Consumption Time: 0.04979
Total Iteration Time: 15.00971

Cumulative Model Updates: 61,044
Cumulative Timesteps: 1,018,232,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1018232146...
Checkpoint 1018232146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420,480.22620
Policy Entropy: 1.09240
Value Function Loss: 1.90108

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.09736

Collected Steps per Second: 4,092.63142
Overall Steps per Second: 3,417.42174

Timestep Collection Time: 12.22197
Timestep Consumption Time: 2.41480
PPO Batch Consumption Time: 0.05160
Total Iteration Time: 14.63677

Cumulative Model Updates: 61,047
Cumulative Timesteps: 1,018,282,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647,554.36836
Policy Entropy: 1.09363
Value Function Loss: 1.94382

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.11159

Collected Steps per Second: 3,923.04770
Overall Steps per Second: 3,248.85735

Timestep Collection Time: 12.75386
Timestep Consumption Time: 2.64663
PPO Batch Consumption Time: 0.06225
Total Iteration Time: 15.40049

Cumulative Model Updates: 61,050
Cumulative Timesteps: 1,018,332,200

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1018332200...
Checkpoint 1018332200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821,346.58740
Policy Entropy: 1.07376
Value Function Loss: 1.91719

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 3,657.87182
Overall Steps per Second: 3,055.22224

Timestep Collection Time: 13.67352
Timestep Consumption Time: 2.69713
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 16.37066

Cumulative Model Updates: 61,053
Cumulative Timesteps: 1,018,382,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270,952.91178
Policy Entropy: 1.07137
Value Function Loss: 2.01667

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.10219

Collected Steps per Second: 3,706.36422
Overall Steps per Second: 3,170.13664

Timestep Collection Time: 13.49571
Timestep Consumption Time: 2.28279
PPO Batch Consumption Time: 0.05426
Total Iteration Time: 15.77850

Cumulative Model Updates: 61,056
Cumulative Timesteps: 1,018,432,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1018432236...
Checkpoint 1018432236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556,234.09026
Policy Entropy: 1.08449
Value Function Loss: 2.08541

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.10089

Collected Steps per Second: 3,687.41063
Overall Steps per Second: 3,119.55284

Timestep Collection Time: 13.57050
Timestep Consumption Time: 2.47026
PPO Batch Consumption Time: 0.05292
Total Iteration Time: 16.04076

Cumulative Model Updates: 61,059
Cumulative Timesteps: 1,018,482,276

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537,042.22383
Policy Entropy: 1.08628
Value Function Loss: 2.09554

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.06337
Value Function Update Magnitude: 0.10260

Collected Steps per Second: 3,738.94519
Overall Steps per Second: 3,184.22955

Timestep Collection Time: 13.37597
Timestep Consumption Time: 2.33019
PPO Batch Consumption Time: 0.06186
Total Iteration Time: 15.70615

Cumulative Model Updates: 61,062
Cumulative Timesteps: 1,018,532,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1018532288...
Checkpoint 1018532288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,011,782.51699
Policy Entropy: 1.07448
Value Function Loss: 2.04409

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.10254

Collected Steps per Second: 3,727.67644
Overall Steps per Second: 3,126.39529

Timestep Collection Time: 13.42069
Timestep Consumption Time: 2.58112
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 16.00182

Cumulative Model Updates: 61,065
Cumulative Timesteps: 1,018,582,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706,409.58432
Policy Entropy: 1.06781
Value Function Loss: 2.03009

Mean KL Divergence: 0.02674
SB3 Clip Fraction: 0.19044
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.09240

Collected Steps per Second: 3,661.96909
Overall Steps per Second: 3,040.15543

Timestep Collection Time: 13.66314
Timestep Consumption Time: 2.79457
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 16.45771

Cumulative Model Updates: 61,068
Cumulative Timesteps: 1,018,632,350

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1018632350...
Checkpoint 1018632350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395,064.70788
Policy Entropy: 1.08213
Value Function Loss: 2.12439

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 3,829.63168
Overall Steps per Second: 3,177.41433

Timestep Collection Time: 13.06131
Timestep Consumption Time: 2.68105
PPO Batch Consumption Time: 0.06504
Total Iteration Time: 15.74236

Cumulative Model Updates: 61,071
Cumulative Timesteps: 1,018,682,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388,111.16084
Policy Entropy: 1.08630
Value Function Loss: 2.11811

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.09322

Collected Steps per Second: 3,748.15335
Overall Steps per Second: 3,102.30756

Timestep Collection Time: 13.34470
Timestep Consumption Time: 2.77813
PPO Batch Consumption Time: 0.06483
Total Iteration Time: 16.12284

Cumulative Model Updates: 61,074
Cumulative Timesteps: 1,018,732,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1018732388...
Checkpoint 1018732388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420,575.47395
Policy Entropy: 1.06781
Value Function Loss: 2.12936

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.14640
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.12064

Collected Steps per Second: 3,714.20596
Overall Steps per Second: 3,111.05922

Timestep Collection Time: 13.47044
Timestep Consumption Time: 2.61154
PPO Batch Consumption Time: 0.05038
Total Iteration Time: 16.08198

Cumulative Model Updates: 61,077
Cumulative Timesteps: 1,018,782,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308,509.76408
Policy Entropy: 1.06809
Value Function Loss: 2.04825

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.16648
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.12376

Collected Steps per Second: 3,709.16863
Overall Steps per Second: 3,090.57423

Timestep Collection Time: 13.49359
Timestep Consumption Time: 2.70081
PPO Batch Consumption Time: 0.06132
Total Iteration Time: 16.19440

Cumulative Model Updates: 61,080
Cumulative Timesteps: 1,018,832,470

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1018832470...
Checkpoint 1018832470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291,643.00903
Policy Entropy: 1.07605
Value Function Loss: 2.00761

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 3,679.00012
Overall Steps per Second: 3,071.68418

Timestep Collection Time: 13.59065
Timestep Consumption Time: 2.68707
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 16.27772

Cumulative Model Updates: 61,083
Cumulative Timesteps: 1,018,882,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,198.48026
Policy Entropy: 1.07930
Value Function Loss: 1.97642

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.16663
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 3,704.35658
Overall Steps per Second: 3,078.32541

Timestep Collection Time: 13.50950
Timestep Consumption Time: 2.74739
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 16.25689

Cumulative Model Updates: 61,086
Cumulative Timesteps: 1,018,932,514

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1018932514...
Checkpoint 1018932514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903,494.81439
Policy Entropy: 1.03996
Value Function Loss: 1.89193

Mean KL Divergence: 0.04623
SB3 Clip Fraction: 0.22751
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.12570

Collected Steps per Second: 3,780.81383
Overall Steps per Second: 3,155.23735

Timestep Collection Time: 13.23101
Timestep Consumption Time: 2.62326
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 15.85427

Cumulative Model Updates: 61,089
Cumulative Timesteps: 1,018,982,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814,873.48362
Policy Entropy: 1.07877
Value Function Loss: 1.90541

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.17824
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.10499

Collected Steps per Second: 3,682.34105
Overall Steps per Second: 3,111.19697

Timestep Collection Time: 13.58321
Timestep Consumption Time: 2.49356
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 16.07677

Cumulative Model Updates: 61,092
Cumulative Timesteps: 1,019,032,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1019032556...
Checkpoint 1019032556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239,583.73493
Policy Entropy: 1.06376
Value Function Loss: 1.91410

Mean KL Divergence: 0.02815
SB3 Clip Fraction: 0.17794
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.09743

Collected Steps per Second: 3,564.29066
Overall Steps per Second: 3,033.63808

Timestep Collection Time: 14.03701
Timestep Consumption Time: 2.45539
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 16.49241

Cumulative Model Updates: 61,095
Cumulative Timesteps: 1,019,082,588

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494,657.78825
Policy Entropy: 1.08742
Value Function Loss: 1.98074

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.09122

Collected Steps per Second: 3,637.95403
Overall Steps per Second: 3,079.30638

Timestep Collection Time: 13.74619
Timestep Consumption Time: 2.49383
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 16.24002

Cumulative Model Updates: 61,098
Cumulative Timesteps: 1,019,132,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1019132596...
Checkpoint 1019132596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308,262.10231
Policy Entropy: 1.07819
Value Function Loss: 2.00577

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.06739
Value Function Update Magnitude: 0.08789

Collected Steps per Second: 3,610.68997
Overall Steps per Second: 3,023.66941

Timestep Collection Time: 13.85220
Timestep Consumption Time: 2.68929
PPO Batch Consumption Time: 0.06759
Total Iteration Time: 16.54149

Cumulative Model Updates: 61,101
Cumulative Timesteps: 1,019,182,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459,932.57952
Policy Entropy: 1.07342
Value Function Loss: 1.89666

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.07650
Value Function Update Magnitude: 0.09346

Collected Steps per Second: 3,788.46471
Overall Steps per Second: 3,136.70166

Timestep Collection Time: 13.20641
Timestep Consumption Time: 2.74411
PPO Batch Consumption Time: 0.06214
Total Iteration Time: 15.95051

Cumulative Model Updates: 61,104
Cumulative Timesteps: 1,019,232,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1019232644...
Checkpoint 1019232644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156,131.51265
Policy Entropy: 1.06561
Value Function Loss: 1.98075

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.07170
Value Function Update Magnitude: 0.11682

Collected Steps per Second: 3,812.54422
Overall Steps per Second: 3,151.74682

Timestep Collection Time: 13.12352
Timestep Consumption Time: 2.75149
PPO Batch Consumption Time: 0.07412
Total Iteration Time: 15.87501

Cumulative Model Updates: 61,107
Cumulative Timesteps: 1,019,282,678

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493,532.02210
Policy Entropy: 1.07773
Value Function Loss: 1.88777

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.13131

Collected Steps per Second: 3,682.45470
Overall Steps per Second: 3,077.85987

Timestep Collection Time: 13.58931
Timestep Consumption Time: 2.66939
PPO Batch Consumption Time: 0.06849
Total Iteration Time: 16.25870

Cumulative Model Updates: 61,110
Cumulative Timesteps: 1,019,332,720

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1019332720...
Checkpoint 1019332720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559,218.52995
Policy Entropy: 1.07392
Value Function Loss: 1.99932

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.06803
Value Function Update Magnitude: 0.12827

Collected Steps per Second: 3,636.36498
Overall Steps per Second: 3,040.88843

Timestep Collection Time: 13.76209
Timestep Consumption Time: 2.69494
PPO Batch Consumption Time: 0.06335
Total Iteration Time: 16.45703

Cumulative Model Updates: 61,113
Cumulative Timesteps: 1,019,382,764

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638,706.48296
Policy Entropy: 1.07358
Value Function Loss: 2.03588

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.07101
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 3,634.83715
Overall Steps per Second: 3,055.87380

Timestep Collection Time: 13.76403
Timestep Consumption Time: 2.60772
PPO Batch Consumption Time: 0.06163
Total Iteration Time: 16.37175

Cumulative Model Updates: 61,116
Cumulative Timesteps: 1,019,432,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1019432794...
Checkpoint 1019432794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152,534.54024
Policy Entropy: 1.08727
Value Function Loss: 2.12325

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.16786
Policy Update Magnitude: 0.06631
Value Function Update Magnitude: 0.10747

Collected Steps per Second: 3,761.48511
Overall Steps per Second: 3,186.42445

Timestep Collection Time: 13.29688
Timestep Consumption Time: 2.39971
PPO Batch Consumption Time: 0.06197
Total Iteration Time: 15.69659

Cumulative Model Updates: 61,119
Cumulative Timesteps: 1,019,482,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212,339.19133
Policy Entropy: 1.07062
Value Function Loss: 2.10919

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 3,600.44233
Overall Steps per Second: 3,053.27558

Timestep Collection Time: 13.89496
Timestep Consumption Time: 2.49007
PPO Batch Consumption Time: 0.05772
Total Iteration Time: 16.38503

Cumulative Model Updates: 61,122
Cumulative Timesteps: 1,019,532,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1019532838...
Checkpoint 1019532838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325,134.91691
Policy Entropy: 1.06972
Value Function Loss: 2.00048

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.11895

Collected Steps per Second: 3,674.06301
Overall Steps per Second: 3,117.46658

Timestep Collection Time: 13.61218
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.05769
Total Iteration Time: 16.04251

Cumulative Model Updates: 61,125
Cumulative Timesteps: 1,019,582,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437,616.26868
Policy Entropy: 1.08478
Value Function Loss: 2.03438

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.11877

Collected Steps per Second: 3,690.58652
Overall Steps per Second: 3,044.33741

Timestep Collection Time: 13.55774
Timestep Consumption Time: 2.87802
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 16.43576

Cumulative Model Updates: 61,128
Cumulative Timesteps: 1,019,632,886

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1019632886...
Checkpoint 1019632886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160,979.97326
Policy Entropy: 1.08672
Value Function Loss: 2.10643

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14853
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.12099

Collected Steps per Second: 3,695.12287
Overall Steps per Second: 2,926.46977

Timestep Collection Time: 13.54272
Timestep Consumption Time: 3.55707
PPO Batch Consumption Time: 0.06516
Total Iteration Time: 17.09978

Cumulative Model Updates: 61,131
Cumulative Timesteps: 1,019,682,928

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776,114.62329
Policy Entropy: 1.07000
Value Function Loss: 1.98940

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.11878

Collected Steps per Second: 3,645.91739
Overall Steps per Second: 3,027.59171

Timestep Collection Time: 13.71726
Timestep Consumption Time: 2.80148
PPO Batch Consumption Time: 0.05412
Total Iteration Time: 16.51874

Cumulative Model Updates: 61,134
Cumulative Timesteps: 1,019,732,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1019732940...
Checkpoint 1019732940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266,665.88199
Policy Entropy: 1.05924
Value Function Loss: 1.94613

Mean KL Divergence: 0.02479
SB3 Clip Fraction: 0.17679
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.10895

Collected Steps per Second: 4,071.66588
Overall Steps per Second: 3,360.62202

Timestep Collection Time: 12.28785
Timestep Consumption Time: 2.59987
PPO Batch Consumption Time: 0.05230
Total Iteration Time: 14.88772

Cumulative Model Updates: 61,137
Cumulative Timesteps: 1,019,782,972

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545,426.31920
Policy Entropy: 1.08213
Value Function Loss: 1.87428

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.09879

Collected Steps per Second: 3,928.18698
Overall Steps per Second: 3,242.07015

Timestep Collection Time: 12.73565
Timestep Consumption Time: 2.69524
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 15.43088

Cumulative Model Updates: 61,140
Cumulative Timesteps: 1,019,833,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1019833000...
Checkpoint 1019833000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471,491.02050
Policy Entropy: 1.07874
Value Function Loss: 2.03339

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.10012

Collected Steps per Second: 3,987.35852
Overall Steps per Second: 3,309.83383

Timestep Collection Time: 12.54916
Timestep Consumption Time: 2.56882
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 15.11798

Cumulative Model Updates: 61,143
Cumulative Timesteps: 1,019,883,038

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390,271.75455
Policy Entropy: 1.06927
Value Function Loss: 2.01834

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.06562
Value Function Update Magnitude: 0.10418

Collected Steps per Second: 3,762.58880
Overall Steps per Second: 3,123.60953

Timestep Collection Time: 13.29085
Timestep Consumption Time: 2.71883
PPO Batch Consumption Time: 0.06281
Total Iteration Time: 16.00968

Cumulative Model Updates: 61,146
Cumulative Timesteps: 1,019,933,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1019933046...
Checkpoint 1019933046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364,705.40664
Policy Entropy: 1.05345
Value Function Loss: 2.06215

Mean KL Divergence: 0.03127
SB3 Clip Fraction: 0.18921
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.10248

Collected Steps per Second: 3,767.51716
Overall Steps per Second: 3,177.32804

Timestep Collection Time: 13.28143
Timestep Consumption Time: 2.46703
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 15.74845

Cumulative Model Updates: 61,149
Cumulative Timesteps: 1,019,983,084

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308,421.04774
Policy Entropy: 1.07507
Value Function Loss: 2.06014

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.08908

Collected Steps per Second: 3,697.35656
Overall Steps per Second: 3,126.90939

Timestep Collection Time: 13.53616
Timestep Consumption Time: 2.46942
PPO Batch Consumption Time: 0.05376
Total Iteration Time: 16.00558

Cumulative Model Updates: 61,152
Cumulative Timesteps: 1,020,033,132

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1020033132...
Checkpoint 1020033132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281,464.48220
Policy Entropy: 1.07826
Value Function Loss: 2.10557

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.09923

Collected Steps per Second: 3,707.45701
Overall Steps per Second: 3,115.66685

Timestep Collection Time: 13.49712
Timestep Consumption Time: 2.56365
PPO Batch Consumption Time: 0.06119
Total Iteration Time: 16.06077

Cumulative Model Updates: 61,155
Cumulative Timesteps: 1,020,083,172

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266,266.06225
Policy Entropy: 1.06286
Value Function Loss: 2.05463

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.09405

Collected Steps per Second: 3,737.46344
Overall Steps per Second: 3,103.25564

Timestep Collection Time: 13.38287
Timestep Consumption Time: 2.73504
PPO Batch Consumption Time: 0.06169
Total Iteration Time: 16.11791

Cumulative Model Updates: 61,158
Cumulative Timesteps: 1,020,133,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1020133190...
Checkpoint 1020133190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461,883.59205
Policy Entropy: 1.05203
Value Function Loss: 1.99004

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.09302

Collected Steps per Second: 3,811.08895
Overall Steps per Second: 3,134.98260

Timestep Collection Time: 13.12696
Timestep Consumption Time: 2.83103
PPO Batch Consumption Time: 0.05769
Total Iteration Time: 15.95798

Cumulative Model Updates: 61,161
Cumulative Timesteps: 1,020,183,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286,141.37430
Policy Entropy: 1.07512
Value Function Loss: 1.99693

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.09457

Collected Steps per Second: 3,876.19132
Overall Steps per Second: 3,201.89837

Timestep Collection Time: 12.90597
Timestep Consumption Time: 2.71789
PPO Batch Consumption Time: 0.05904
Total Iteration Time: 15.62386

Cumulative Model Updates: 61,164
Cumulative Timesteps: 1,020,233,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1020233244...
Checkpoint 1020233244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040,775.93051
Policy Entropy: 1.08635
Value Function Loss: 2.03288

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14894
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.09351

Collected Steps per Second: 3,726.53929
Overall Steps per Second: 3,085.28720

Timestep Collection Time: 13.43230
Timestep Consumption Time: 2.79180
PPO Batch Consumption Time: 0.05777
Total Iteration Time: 16.22410

Cumulative Model Updates: 61,167
Cumulative Timesteps: 1,020,283,300

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574,083.07530
Policy Entropy: 1.07026
Value Function Loss: 2.02012

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.09624

Collected Steps per Second: 3,754.60004
Overall Steps per Second: 3,132.45309

Timestep Collection Time: 13.32126
Timestep Consumption Time: 2.64578
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 15.96704

Cumulative Model Updates: 61,170
Cumulative Timesteps: 1,020,333,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1020333316...
Checkpoint 1020333316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581,657.70212
Policy Entropy: 1.08046
Value Function Loss: 1.95951

Mean KL Divergence: 0.02546
SB3 Clip Fraction: 0.16625
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.10164

Collected Steps per Second: 3,654.21178
Overall Steps per Second: 3,044.38951

Timestep Collection Time: 13.68886
Timestep Consumption Time: 2.74202
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 16.43088

Cumulative Model Updates: 61,173
Cumulative Timesteps: 1,020,383,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930,112.30965
Policy Entropy: 1.08043
Value Function Loss: 1.91598

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.16454
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.10307

Collected Steps per Second: 3,712.11480
Overall Steps per Second: 3,135.14304

Timestep Collection Time: 13.47210
Timestep Consumption Time: 2.47932
PPO Batch Consumption Time: 0.06624
Total Iteration Time: 15.95143

Cumulative Model Updates: 61,176
Cumulative Timesteps: 1,020,433,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1020433348...
Checkpoint 1020433348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605,167.04389
Policy Entropy: 1.06561
Value Function Loss: 1.90940

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.09640

Collected Steps per Second: 3,663.79561
Overall Steps per Second: 3,053.73153

Timestep Collection Time: 13.66179
Timestep Consumption Time: 2.72931
PPO Batch Consumption Time: 0.06513
Total Iteration Time: 16.39109

Cumulative Model Updates: 61,179
Cumulative Timesteps: 1,020,483,402

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623,383.01462
Policy Entropy: 1.05917
Value Function Loss: 1.98978

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.17347
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.09215

Collected Steps per Second: 7,759.94781
Overall Steps per Second: 6,972.62178

Timestep Collection Time: 6.44334
Timestep Consumption Time: 0.72756
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 7.17090

Cumulative Model Updates: 61,182
Cumulative Timesteps: 1,020,533,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1020533402...
Checkpoint 1020533402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102,451.76590
Policy Entropy: 1.06717
Value Function Loss: 2.03916

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.08681

Collected Steps per Second: 9,846.11390
Overall Steps per Second: 8,484.55670

Timestep Collection Time: 5.07815
Timestep Consumption Time: 0.81491
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.89306

Cumulative Model Updates: 61,185
Cumulative Timesteps: 1,020,583,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494,753.79287
Policy Entropy: 1.08774
Value Function Loss: 2.06130

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.15217
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.09783

Collected Steps per Second: 5,017.99599
Overall Steps per Second: 4,593.87883

Timestep Collection Time: 9.96414
Timestep Consumption Time: 0.91991
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 10.88405

Cumulative Model Updates: 61,188
Cumulative Timesteps: 1,020,633,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1020633402...
Checkpoint 1020633402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667,985.22912
Policy Entropy: 1.06319
Value Function Loss: 1.99024

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.13095

Collected Steps per Second: 9,986.26215
Overall Steps per Second: 8,606.89516

Timestep Collection Time: 5.00908
Timestep Consumption Time: 0.80277
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.81185

Cumulative Model Updates: 61,191
Cumulative Timesteps: 1,020,683,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825,344.04952
Policy Entropy: 1.07844
Value Function Loss: 1.97621

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.12894

Collected Steps per Second: 3,799.96373
Overall Steps per Second: 3,141.94854

Timestep Collection Time: 13.16276
Timestep Consumption Time: 2.75666
PPO Batch Consumption Time: 0.05988
Total Iteration Time: 15.91942

Cumulative Model Updates: 61,194
Cumulative Timesteps: 1,020,733,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1020733442...
Checkpoint 1020733442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606,786.47632
Policy Entropy: 1.08411
Value Function Loss: 1.93205

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.16912
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.10853

Collected Steps per Second: 3,722.55735
Overall Steps per Second: 3,105.68549

Timestep Collection Time: 13.43969
Timestep Consumption Time: 2.66948
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 16.10916

Cumulative Model Updates: 61,197
Cumulative Timesteps: 1,020,783,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689,320.98942
Policy Entropy: 1.05714
Value Function Loss: 1.94079

Mean KL Divergence: 0.02883
SB3 Clip Fraction: 0.17411
Policy Update Magnitude: 0.06323
Value Function Update Magnitude: 0.09548

Collected Steps per Second: 3,708.75615
Overall Steps per Second: 3,096.16945

Timestep Collection Time: 13.49401
Timestep Consumption Time: 2.66983
PPO Batch Consumption Time: 0.05948
Total Iteration Time: 16.16384

Cumulative Model Updates: 61,200
Cumulative Timesteps: 1,020,833,518

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1020833518...
Checkpoint 1020833518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,091,953.73723
Policy Entropy: 1.07112
Value Function Loss: 1.90344

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.08509

Collected Steps per Second: 3,698.68069
Overall Steps per Second: 3,094.38716

Timestep Collection Time: 13.52428
Timestep Consumption Time: 2.64112
PPO Batch Consumption Time: 0.05984
Total Iteration Time: 16.16540

Cumulative Model Updates: 61,203
Cumulative Timesteps: 1,020,883,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782,214.33254
Policy Entropy: 1.06314
Value Function Loss: 1.98593

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.08976

Collected Steps per Second: 3,768.45657
Overall Steps per Second: 3,128.14772

Timestep Collection Time: 13.27387
Timestep Consumption Time: 2.71706
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 15.99093

Cumulative Model Updates: 61,206
Cumulative Timesteps: 1,020,933,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1020933562...
Checkpoint 1020933562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164,600.86302
Policy Entropy: 1.05520
Value Function Loss: 1.96092

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.09397

Collected Steps per Second: 3,697.56065
Overall Steps per Second: 3,083.75873

Timestep Collection Time: 13.53108
Timestep Consumption Time: 2.69327
PPO Batch Consumption Time: 0.05995
Total Iteration Time: 16.22436

Cumulative Model Updates: 61,209
Cumulative Timesteps: 1,020,983,594

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827,567.38441
Policy Entropy: 1.05321
Value Function Loss: 1.92958

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.17419
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.09523

Collected Steps per Second: 3,682.79366
Overall Steps per Second: 3,075.10469

Timestep Collection Time: 13.58208
Timestep Consumption Time: 2.68403
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 16.26611

Cumulative Model Updates: 61,212
Cumulative Timesteps: 1,021,033,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1021033614...
Checkpoint 1021033614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932,698.48623
Policy Entropy: 1.05874
Value Function Loss: 1.89898

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.08854

Collected Steps per Second: 3,722.94212
Overall Steps per Second: 3,140.88152

Timestep Collection Time: 13.43292
Timestep Consumption Time: 2.48936
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 15.92228

Cumulative Model Updates: 61,215
Cumulative Timesteps: 1,021,083,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511,755.84452
Policy Entropy: 1.07028
Value Function Loss: 1.94602

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.15923
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.08894

Collected Steps per Second: 3,690.28701
Overall Steps per Second: 3,128.50878

Timestep Collection Time: 13.55884
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.06559
Total Iteration Time: 15.99356

Cumulative Model Updates: 61,218
Cumulative Timesteps: 1,021,133,660

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1021133660...
Checkpoint 1021133660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348,721.42013
Policy Entropy: 1.06421
Value Function Loss: 1.99247

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.09013

Collected Steps per Second: 3,728.22614
Overall Steps per Second: 3,124.73953

Timestep Collection Time: 13.42086
Timestep Consumption Time: 2.59200
PPO Batch Consumption Time: 0.06027
Total Iteration Time: 16.01285

Cumulative Model Updates: 61,221
Cumulative Timesteps: 1,021,183,696

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,133.45057
Policy Entropy: 1.04694
Value Function Loss: 2.09101

Mean KL Divergence: 0.03022
SB3 Clip Fraction: 0.18414
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.08917

Collected Steps per Second: 3,735.38514
Overall Steps per Second: 3,109.87901

Timestep Collection Time: 13.39353
Timestep Consumption Time: 2.69391
PPO Batch Consumption Time: 0.06020
Total Iteration Time: 16.08744

Cumulative Model Updates: 61,224
Cumulative Timesteps: 1,021,233,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1021233726...
Checkpoint 1021233726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239,527.78592
Policy Entropy: 1.05796
Value Function Loss: 2.18082

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.09017

Collected Steps per Second: 3,674.49180
Overall Steps per Second: 3,065.21887

Timestep Collection Time: 13.62093
Timestep Consumption Time: 2.70743
PPO Batch Consumption Time: 0.05867
Total Iteration Time: 16.32836

Cumulative Model Updates: 61,227
Cumulative Timesteps: 1,021,283,776

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716,000.53274
Policy Entropy: 1.05135
Value Function Loss: 2.22965

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.10262

Collected Steps per Second: 3,720.56325
Overall Steps per Second: 3,108.70190

Timestep Collection Time: 13.45280
Timestep Consumption Time: 2.64781
PPO Batch Consumption Time: 0.06025
Total Iteration Time: 16.10061

Cumulative Model Updates: 61,230
Cumulative Timesteps: 1,021,333,828

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1021333828...
Checkpoint 1021333828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364,905.52279
Policy Entropy: 1.04979
Value Function Loss: 2.10882

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.07332
Value Function Update Magnitude: 0.11862

Collected Steps per Second: 3,806.46890
Overall Steps per Second: 3,180.74960

Timestep Collection Time: 13.14131
Timestep Consumption Time: 2.58517
PPO Batch Consumption Time: 0.06265
Total Iteration Time: 15.72648

Cumulative Model Updates: 61,233
Cumulative Timesteps: 1,021,383,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400,425.45609
Policy Entropy: 1.04116
Value Function Loss: 2.06108

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.15968
Policy Update Magnitude: 0.07236
Value Function Update Magnitude: 0.11723

Collected Steps per Second: 3,721.71727
Overall Steps per Second: 3,112.32022

Timestep Collection Time: 13.44433
Timestep Consumption Time: 2.63242
PPO Batch Consumption Time: 0.05391
Total Iteration Time: 16.07675

Cumulative Model Updates: 61,236
Cumulative Timesteps: 1,021,433,886

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1021433886...
Checkpoint 1021433886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263,728.07956
Policy Entropy: 1.06360
Value Function Loss: 1.99425

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.06171
Value Function Update Magnitude: 0.10778

Collected Steps per Second: 3,716.00820
Overall Steps per Second: 3,119.81181

Timestep Collection Time: 13.46768
Timestep Consumption Time: 2.57367
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 16.04135

Cumulative Model Updates: 61,239
Cumulative Timesteps: 1,021,483,932

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523,757.13671
Policy Entropy: 1.07087
Value Function Loss: 2.01695

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.14858
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.10250

Collected Steps per Second: 3,883.52866
Overall Steps per Second: 3,231.10260

Timestep Collection Time: 12.88467
Timestep Consumption Time: 2.60168
PPO Batch Consumption Time: 0.05842
Total Iteration Time: 15.48635

Cumulative Model Updates: 61,242
Cumulative Timesteps: 1,021,533,970

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1021533970...
Checkpoint 1021533970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473,224.96858
Policy Entropy: 1.06192
Value Function Loss: 1.95785

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.09773

Collected Steps per Second: 4,002.54513
Overall Steps per Second: 3,214.30819

Timestep Collection Time: 12.49255
Timestep Consumption Time: 3.06352
PPO Batch Consumption Time: 0.04744
Total Iteration Time: 15.55607

Cumulative Model Updates: 61,245
Cumulative Timesteps: 1,021,583,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304,793.42028
Policy Entropy: 1.05401
Value Function Loss: 2.02541

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.15276
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.09565

Collected Steps per Second: 3,923.17206
Overall Steps per Second: 3,285.15174

Timestep Collection Time: 12.74836
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.05400
Total Iteration Time: 15.22426

Cumulative Model Updates: 61,248
Cumulative Timesteps: 1,021,633,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1021633986...
Checkpoint 1021633986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156,841.42484
Policy Entropy: 1.06784
Value Function Loss: 1.96376

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.09982

Collected Steps per Second: 3,913.88043
Overall Steps per Second: 3,246.85294

Timestep Collection Time: 12.79038
Timestep Consumption Time: 2.62763
PPO Batch Consumption Time: 0.05087
Total Iteration Time: 15.41801

Cumulative Model Updates: 61,251
Cumulative Timesteps: 1,021,684,046

Timesteps Collected: 50,060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473,606.51385
Policy Entropy: 1.08012
Value Function Loss: 1.91685

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.16111
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.09931

Collected Steps per Second: 3,854.81110
Overall Steps per Second: 3,160.68330

Timestep Collection Time: 12.97703
Timestep Consumption Time: 2.84993
PPO Batch Consumption Time: 0.06301
Total Iteration Time: 15.82696

Cumulative Model Updates: 61,254
Cumulative Timesteps: 1,021,734,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1021734070...
Checkpoint 1021734070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854,384.74713
Policy Entropy: 1.05471
Value Function Loss: 1.87328

Mean KL Divergence: 0.02552
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.09997

Collected Steps per Second: 3,743.22172
Overall Steps per Second: 3,113.39276

Timestep Collection Time: 13.36335
Timestep Consumption Time: 2.70336
PPO Batch Consumption Time: 0.05126
Total Iteration Time: 16.06672

Cumulative Model Updates: 61,257
Cumulative Timesteps: 1,021,784,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,875,916.16371
Policy Entropy: 1.07600
Value Function Loss: 1.88524

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.09434

Collected Steps per Second: 3,674.02142
Overall Steps per Second: 3,043.65147

Timestep Collection Time: 13.62050
Timestep Consumption Time: 2.82094
PPO Batch Consumption Time: 0.05245
Total Iteration Time: 16.44144

Cumulative Model Updates: 61,260
Cumulative Timesteps: 1,021,834,134

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1021834134...
Checkpoint 1021834134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656,749.36710
Policy Entropy: 1.07841
Value Function Loss: 1.84156

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.15316
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.08979

Collected Steps per Second: 3,692.02068
Overall Steps per Second: 3,076.43257

Timestep Collection Time: 13.54434
Timestep Consumption Time: 2.71020
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 16.25454

Cumulative Model Updates: 61,263
Cumulative Timesteps: 1,021,884,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739,499.31141
Policy Entropy: 1.06094
Value Function Loss: 1.79560

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.08912

Collected Steps per Second: 3,745.68164
Overall Steps per Second: 3,126.57200

Timestep Collection Time: 13.35084
Timestep Consumption Time: 2.64367
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 15.99451

Cumulative Model Updates: 61,266
Cumulative Timesteps: 1,021,934,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1021934148...
Checkpoint 1021934148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300,890.92355
Policy Entropy: 1.05506
Value Function Loss: 1.91116

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.17062
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.10003

Collected Steps per Second: 3,545.81294
Overall Steps per Second: 2,966.38617

Timestep Collection Time: 14.11355
Timestep Consumption Time: 2.75681
PPO Batch Consumption Time: 0.06588
Total Iteration Time: 16.87036

Cumulative Model Updates: 61,269
Cumulative Timesteps: 1,021,984,192

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426,341.79551
Policy Entropy: 1.06412
Value Function Loss: 1.92714

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.12385

Collected Steps per Second: 3,502.44878
Overall Steps per Second: 2,919.86373

Timestep Collection Time: 14.28258
Timestep Consumption Time: 2.84973
PPO Batch Consumption Time: 0.05076
Total Iteration Time: 17.13231

Cumulative Model Updates: 61,272
Cumulative Timesteps: 1,022,034,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1022034216...
Checkpoint 1022034216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019,734.08674
Policy Entropy: 1.07243
Value Function Loss: 1.92616

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.16589
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.13259

Collected Steps per Second: 3,621.45768
Overall Steps per Second: 3,074.09596

Timestep Collection Time: 13.81654
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 16.27666

Cumulative Model Updates: 61,275
Cumulative Timesteps: 1,022,084,252

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,123,300.72281
Policy Entropy: 1.03884
Value Function Loss: 1.82335

Mean KL Divergence: 0.04347
SB3 Clip Fraction: 0.21637
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.12664

Collected Steps per Second: 3,432.86603
Overall Steps per Second: 2,916.62995

Timestep Collection Time: 14.57674
Timestep Consumption Time: 2.58005
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 17.15679

Cumulative Model Updates: 61,278
Cumulative Timesteps: 1,022,134,292

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1022134292...
Checkpoint 1022134292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425,134.20344
Policy Entropy: 1.05943
Value Function Loss: 1.84443

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.11637

Collected Steps per Second: 3,672.78305
Overall Steps per Second: 3,052.89031

Timestep Collection Time: 13.62019
Timestep Consumption Time: 2.76559
PPO Batch Consumption Time: 0.06299
Total Iteration Time: 16.38578

Cumulative Model Updates: 61,281
Cumulative Timesteps: 1,022,184,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353,307.66756
Policy Entropy: 1.06233
Value Function Loss: 1.82607

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.06264
Value Function Update Magnitude: 0.11195

Collected Steps per Second: 3,663.82562
Overall Steps per Second: 3,053.89922

Timestep Collection Time: 13.65458
Timestep Consumption Time: 2.72710
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 16.38168

Cumulative Model Updates: 61,284
Cumulative Timesteps: 1,022,234,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1022234344...
Checkpoint 1022234344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273,452.68138
Policy Entropy: 1.05269
Value Function Loss: 1.89347

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.07136
Value Function Update Magnitude: 0.10105

Collected Steps per Second: 3,637.91890
Overall Steps per Second: 3,036.64527

Timestep Collection Time: 13.75292
Timestep Consumption Time: 2.72316
PPO Batch Consumption Time: 0.05409
Total Iteration Time: 16.47608

Cumulative Model Updates: 61,287
Cumulative Timesteps: 1,022,284,376

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624,161.42442
Policy Entropy: 1.03527
Value Function Loss: 1.91772

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.07742
Value Function Update Magnitude: 0.09733

Collected Steps per Second: 3,674.38079
Overall Steps per Second: 3,045.54303

Timestep Collection Time: 13.61427
Timestep Consumption Time: 2.81105
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 16.42531

Cumulative Model Updates: 61,290
Cumulative Timesteps: 1,022,334,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1022334400...
Checkpoint 1022334400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248,100.62124
Policy Entropy: 1.04310
Value Function Loss: 2.00139

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.06612
Value Function Update Magnitude: 0.09139

Collected Steps per Second: 3,575.97900
Overall Steps per Second: 2,991.81470

Timestep Collection Time: 13.99169
Timestep Consumption Time: 2.73194
PPO Batch Consumption Time: 0.05993
Total Iteration Time: 16.72363

Cumulative Model Updates: 61,293
Cumulative Timesteps: 1,022,384,434

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487,857.15525
Policy Entropy: 1.04541
Value Function Loss: 1.94838

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.16321
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.09769

Collected Steps per Second: 3,571.72478
Overall Steps per Second: 2,993.75476

Timestep Collection Time: 14.00556
Timestep Consumption Time: 2.70389
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 16.70945

Cumulative Model Updates: 61,296
Cumulative Timesteps: 1,022,434,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1022434458...
Checkpoint 1022434458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666,310.92278
Policy Entropy: 1.03241
Value Function Loss: 1.91352

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.09163

Collected Steps per Second: 3,584.13677
Overall Steps per Second: 3,002.29689

Timestep Collection Time: 13.96208
Timestep Consumption Time: 2.70583
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 16.66791

Cumulative Model Updates: 61,299
Cumulative Timesteps: 1,022,484,500

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365,070.35233
Policy Entropy: 1.02671
Value Function Loss: 1.89829

Mean KL Divergence: 0.02542
SB3 Clip Fraction: 0.17705
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.10597

Collected Steps per Second: 3,639.83937
Overall Steps per Second: 3,048.58982

Timestep Collection Time: 13.74621
Timestep Consumption Time: 2.66597
PPO Batch Consumption Time: 0.06250
Total Iteration Time: 16.41218

Cumulative Model Updates: 61,302
Cumulative Timesteps: 1,022,534,534

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1022534534...
Checkpoint 1022534534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435,935.42745
Policy Entropy: 1.04574
Value Function Loss: 1.94313

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.10712

Collected Steps per Second: 3,632.37784
Overall Steps per Second: 3,082.96102

Timestep Collection Time: 13.77830
Timestep Consumption Time: 2.45544
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 16.23374

Cumulative Model Updates: 61,305
Cumulative Timesteps: 1,022,584,582

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477,304.60087
Policy Entropy: 1.05226
Value Function Loss: 1.98058

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 3,520.72478
Overall Steps per Second: 3,018.31876

Timestep Collection Time: 14.21412
Timestep Consumption Time: 2.36597
PPO Batch Consumption Time: 0.05851
Total Iteration Time: 16.58009

Cumulative Model Updates: 61,308
Cumulative Timesteps: 1,022,634,626

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1022634626...
Checkpoint 1022634626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001,923.23001
Policy Entropy: 1.04398
Value Function Loss: 1.97452

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.10582

Collected Steps per Second: 3,581.83098
Overall Steps per Second: 3,013.39329

Timestep Collection Time: 13.97386
Timestep Consumption Time: 2.63599
PPO Batch Consumption Time: 0.05218
Total Iteration Time: 16.60985

Cumulative Model Updates: 61,311
Cumulative Timesteps: 1,022,684,678

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223,870.32044
Policy Entropy: 1.03208
Value Function Loss: 1.98668

Mean KL Divergence: 0.02927
SB3 Clip Fraction: 0.19351
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.11596

Collected Steps per Second: 3,750.42936
Overall Steps per Second: 3,083.45591

Timestep Collection Time: 13.33767
Timestep Consumption Time: 2.88503
PPO Batch Consumption Time: 0.05261
Total Iteration Time: 16.22271

Cumulative Model Updates: 61,314
Cumulative Timesteps: 1,022,734,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1022734700...
Checkpoint 1022734700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879,886.91769
Policy Entropy: 1.06422
Value Function Loss: 1.88395

Mean KL Divergence: 0.02410
SB3 Clip Fraction: 0.17372
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.11289

Collected Steps per Second: 4,013.25211
Overall Steps per Second: 3,323.80776

Timestep Collection Time: 12.46072
Timestep Consumption Time: 2.58468
PPO Batch Consumption Time: 0.05219
Total Iteration Time: 15.04539

Cumulative Model Updates: 61,317
Cumulative Timesteps: 1,022,784,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328,676.59659
Policy Entropy: 1.03894
Value Function Loss: 1.88185

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.15914
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.11913

Collected Steps per Second: 3,870.28708
Overall Steps per Second: 3,192.91942

Timestep Collection Time: 12.93134
Timestep Consumption Time: 2.74334
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 15.67468

Cumulative Model Updates: 61,320
Cumulative Timesteps: 1,022,834,756

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1022834756...
Checkpoint 1022834756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377,712.03553
Policy Entropy: 1.06862
Value Function Loss: 1.82276

Mean KL Divergence: 0.02622
SB3 Clip Fraction: 0.17126
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.11099

Collected Steps per Second: 3,921.63557
Overall Steps per Second: 3,220.76888

Timestep Collection Time: 12.75335
Timestep Consumption Time: 2.77524
PPO Batch Consumption Time: 0.05218
Total Iteration Time: 15.52859

Cumulative Model Updates: 61,323
Cumulative Timesteps: 1,022,884,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373,166.28719
Policy Entropy: 1.07488
Value Function Loss: 1.93526

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.15717
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.10889

Collected Steps per Second: 3,694.15215
Overall Steps per Second: 3,068.18692

Timestep Collection Time: 13.54032
Timestep Consumption Time: 2.76247
PPO Batch Consumption Time: 0.05327
Total Iteration Time: 16.30279

Cumulative Model Updates: 61,326
Cumulative Timesteps: 1,022,934,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1022934790...
Checkpoint 1022934790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379,399.67996
Policy Entropy: 1.05998
Value Function Loss: 1.99879

Mean KL Divergence: 0.02444
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.10446

Collected Steps per Second: 3,988.77716
Overall Steps per Second: 3,282.71903

Timestep Collection Time: 12.54670
Timestep Consumption Time: 2.69859
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 15.24529

Cumulative Model Updates: 61,329
Cumulative Timesteps: 1,022,984,836

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685,889.50812
Policy Entropy: 1.05735
Value Function Loss: 2.00882

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.15680
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.10174

Collected Steps per Second: 3,724.59276
Overall Steps per Second: 3,100.25582

Timestep Collection Time: 13.43234
Timestep Consumption Time: 2.70504
PPO Batch Consumption Time: 0.06333
Total Iteration Time: 16.13738

Cumulative Model Updates: 61,332
Cumulative Timesteps: 1,023,034,866

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1023034866...
Checkpoint 1023034866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522,378.15515
Policy Entropy: 1.05483
Value Function Loss: 1.98172

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.09360

Collected Steps per Second: 3,836.69154
Overall Steps per Second: 3,193.92731

Timestep Collection Time: 13.03675
Timestep Consumption Time: 2.62359
PPO Batch Consumption Time: 0.05311
Total Iteration Time: 15.66034

Cumulative Model Updates: 61,335
Cumulative Timesteps: 1,023,084,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430,149.34580
Policy Entropy: 1.06219
Value Function Loss: 1.92273

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.08694

Collected Steps per Second: 3,889.92798
Overall Steps per Second: 3,222.92112

Timestep Collection Time: 12.85885
Timestep Consumption Time: 2.66123
PPO Batch Consumption Time: 0.04730
Total Iteration Time: 15.52008

Cumulative Model Updates: 61,338
Cumulative Timesteps: 1,023,134,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1023134904...
Checkpoint 1023134904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500,453.99332
Policy Entropy: 1.04597
Value Function Loss: 1.92887

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 3,801.52131
Overall Steps per Second: 3,200.29265

Timestep Collection Time: 13.15684
Timestep Consumption Time: 2.47173
PPO Batch Consumption Time: 0.06898
Total Iteration Time: 15.62857

Cumulative Model Updates: 61,341
Cumulative Timesteps: 1,023,184,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539,977.11125
Policy Entropy: 1.03795
Value Function Loss: 1.92760

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.17423
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.08001

Collected Steps per Second: 3,569.20736
Overall Steps per Second: 3,031.03484

Timestep Collection Time: 14.01488
Timestep Consumption Time: 2.48840
PPO Batch Consumption Time: 0.05348
Total Iteration Time: 16.50327

Cumulative Model Updates: 61,344
Cumulative Timesteps: 1,023,234,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1023234942...
Checkpoint 1023234942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266,627.67785
Policy Entropy: 1.04922
Value Function Loss: 1.96024

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.09333

Collected Steps per Second: 3,845.11302
Overall Steps per Second: 3,191.77729

Timestep Collection Time: 13.00924
Timestep Consumption Time: 2.66291
PPO Batch Consumption Time: 0.05127
Total Iteration Time: 15.67215

Cumulative Model Updates: 61,347
Cumulative Timesteps: 1,023,284,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723,156.80801
Policy Entropy: 1.05934
Value Function Loss: 1.92899

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.09323

Collected Steps per Second: 3,801.86011
Overall Steps per Second: 3,214.36739

Timestep Collection Time: 13.15356
Timestep Consumption Time: 2.40409
PPO Batch Consumption Time: 0.04861
Total Iteration Time: 15.55765

Cumulative Model Updates: 61,350
Cumulative Timesteps: 1,023,334,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1023334972...
Checkpoint 1023334972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296,341.63035
Policy Entropy: 1.04170
Value Function Loss: 1.89636

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.09122

Collected Steps per Second: 3,779.44193
Overall Steps per Second: 3,122.44266

Timestep Collection Time: 13.23423
Timestep Consumption Time: 2.78464
PPO Batch Consumption Time: 0.06696
Total Iteration Time: 16.01887

Cumulative Model Updates: 61,353
Cumulative Timesteps: 1,023,384,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268,491.70273
Policy Entropy: 1.03971
Value Function Loss: 1.94823

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.17497
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.09289

Collected Steps per Second: 3,864.28522
Overall Steps per Second: 3,186.52119

Timestep Collection Time: 12.93900
Timestep Consumption Time: 2.75209
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 15.69109

Cumulative Model Updates: 61,356
Cumulative Timesteps: 1,023,434,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1023434990...
Checkpoint 1023434990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710,204.13024
Policy Entropy: 1.05107
Value Function Loss: 1.95894

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.09274

Collected Steps per Second: 3,836.51792
Overall Steps per Second: 3,203.36968

Timestep Collection Time: 13.04621
Timestep Consumption Time: 2.57859
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 15.62480

Cumulative Model Updates: 61,359
Cumulative Timesteps: 1,023,485,042

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584,612.84987
Policy Entropy: 1.05702
Value Function Loss: 2.04553

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.15147
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.09275

Collected Steps per Second: 3,894.44131
Overall Steps per Second: 3,236.51456

Timestep Collection Time: 12.84035
Timestep Consumption Time: 2.61022
PPO Batch Consumption Time: 0.05778
Total Iteration Time: 15.45057

Cumulative Model Updates: 61,362
Cumulative Timesteps: 1,023,535,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1023535048...
Checkpoint 1023535048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512,583.51184
Policy Entropy: 1.03445
Value Function Loss: 1.98647

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.08984

Collected Steps per Second: 3,828.26763
Overall Steps per Second: 3,194.51738

Timestep Collection Time: 13.07171
Timestep Consumption Time: 2.59326
PPO Batch Consumption Time: 0.06767
Total Iteration Time: 15.66496

Cumulative Model Updates: 61,365
Cumulative Timesteps: 1,023,585,090

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494,343.23530
Policy Entropy: 1.03527
Value Function Loss: 1.90666

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.14969
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.08815

Collected Steps per Second: 3,866.09223
Overall Steps per Second: 3,217.64749

Timestep Collection Time: 12.93554
Timestep Consumption Time: 2.60687
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 15.54241

Cumulative Model Updates: 61,368
Cumulative Timesteps: 1,023,635,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1023635100...
Checkpoint 1023635100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577,900.57849
Policy Entropy: 1.05399
Value Function Loss: 1.84898

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.08763

Collected Steps per Second: 3,673.85628
Overall Steps per Second: 3,123.99682

Timestep Collection Time: 13.61458
Timestep Consumption Time: 2.39632
PPO Batch Consumption Time: 0.05363
Total Iteration Time: 16.01090

Cumulative Model Updates: 61,371
Cumulative Timesteps: 1,023,685,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488,278.40669
Policy Entropy: 1.05861
Value Function Loss: 1.86355

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.15805
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.08761

Collected Steps per Second: 3,680.15796
Overall Steps per Second: 3,122.73498

Timestep Collection Time: 13.59887
Timestep Consumption Time: 2.42746
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 16.02634

Cumulative Model Updates: 61,374
Cumulative Timesteps: 1,023,735,164

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1023735164...
Checkpoint 1023735164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764,759.37574
Policy Entropy: 1.03677
Value Function Loss: 1.96849

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.08688

Collected Steps per Second: 3,822.25460
Overall Steps per Second: 3,212.66010

Timestep Collection Time: 13.08704
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.05224
Total Iteration Time: 15.57027

Cumulative Model Updates: 61,377
Cumulative Timesteps: 1,023,785,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227,022.25944
Policy Entropy: 1.03424
Value Function Loss: 1.99925

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.16194
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.08955

Collected Steps per Second: 3,768.71825
Overall Steps per Second: 3,132.65446

Timestep Collection Time: 13.26711
Timestep Consumption Time: 2.69379
PPO Batch Consumption Time: 0.04932
Total Iteration Time: 15.96090

Cumulative Model Updates: 61,380
Cumulative Timesteps: 1,023,835,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1023835186...
Checkpoint 1023835186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535,209.68218
Policy Entropy: 1.05074
Value Function Loss: 1.95455

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.09727

Collected Steps per Second: 3,934.51226
Overall Steps per Second: 3,226.63143

Timestep Collection Time: 12.71568
Timestep Consumption Time: 2.78965
PPO Batch Consumption Time: 0.06390
Total Iteration Time: 15.50533

Cumulative Model Updates: 61,383
Cumulative Timesteps: 1,023,885,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489,519.10681
Policy Entropy: 1.06315
Value Function Loss: 1.88024

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.10460

Collected Steps per Second: 3,809.49906
Overall Steps per Second: 3,157.44000

Timestep Collection Time: 13.12771
Timestep Consumption Time: 2.71107
PPO Batch Consumption Time: 0.04948
Total Iteration Time: 15.83878

Cumulative Model Updates: 61,386
Cumulative Timesteps: 1,023,935,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1023935226...
Checkpoint 1023935226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,823,098.35194
Policy Entropy: 1.04482
Value Function Loss: 1.89385

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.10303

Collected Steps per Second: 3,889.99711
Overall Steps per Second: 3,220.75842

Timestep Collection Time: 12.85348
Timestep Consumption Time: 2.67081
PPO Batch Consumption Time: 0.04961
Total Iteration Time: 15.52429

Cumulative Model Updates: 61,389
Cumulative Timesteps: 1,023,985,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151,384.46478
Policy Entropy: 1.03669
Value Function Loss: 1.85286

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.17169
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.09279

Collected Steps per Second: 3,759.29957
Overall Steps per Second: 3,153.35409

Timestep Collection Time: 13.30833
Timestep Consumption Time: 2.55732
PPO Batch Consumption Time: 0.05324
Total Iteration Time: 15.86565

Cumulative Model Updates: 61,392
Cumulative Timesteps: 1,024,035,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1024035256...
Checkpoint 1024035256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652,863.43665
Policy Entropy: 1.04456
Value Function Loss: 1.91693

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.09629

Collected Steps per Second: 3,810.41228
Overall Steps per Second: 3,184.52831

Timestep Collection Time: 13.13244
Timestep Consumption Time: 2.58104
PPO Batch Consumption Time: 0.05743
Total Iteration Time: 15.71347

Cumulative Model Updates: 61,395
Cumulative Timesteps: 1,024,085,296

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366,000.19702
Policy Entropy: 1.05347
Value Function Loss: 1.80310

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.10870

Collected Steps per Second: 3,801.91731
Overall Steps per Second: 3,156.50327

Timestep Collection Time: 13.15757
Timestep Consumption Time: 2.69034
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 15.84792

Cumulative Model Updates: 61,398
Cumulative Timesteps: 1,024,135,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1024135320...
Checkpoint 1024135320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,741.15203
Policy Entropy: 1.03224
Value Function Loss: 1.82377

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.12498

Collected Steps per Second: 3,865.10628
Overall Steps per Second: 3,231.17094

Timestep Collection Time: 12.94557
Timestep Consumption Time: 2.53984
PPO Batch Consumption Time: 0.05193
Total Iteration Time: 15.48541

Cumulative Model Updates: 61,401
Cumulative Timesteps: 1,024,185,356

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237,559.40484
Policy Entropy: 1.02160
Value Function Loss: 1.77552

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.18519
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.11633

Collected Steps per Second: 3,711.05000
Overall Steps per Second: 3,095.45424

Timestep Collection Time: 13.48621
Timestep Consumption Time: 2.68201
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 16.16822

Cumulative Model Updates: 61,404
Cumulative Timesteps: 1,024,235,404

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1024235404...
Checkpoint 1024235404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516,387.70901
Policy Entropy: 1.03966
Value Function Loss: 1.78759

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.10684

Collected Steps per Second: 3,693.76773
Overall Steps per Second: 3,114.35024

Timestep Collection Time: 13.54606
Timestep Consumption Time: 2.52021
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 16.06627

Cumulative Model Updates: 61,407
Cumulative Timesteps: 1,024,285,440

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478,876.18768
Policy Entropy: 1.05222
Value Function Loss: 1.84679

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.09682

Collected Steps per Second: 3,705.39106
Overall Steps per Second: 3,126.03060

Timestep Collection Time: 13.49709
Timestep Consumption Time: 2.50147
PPO Batch Consumption Time: 0.06486
Total Iteration Time: 15.99856

Cumulative Model Updates: 61,410
Cumulative Timesteps: 1,024,335,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1024335452...
Checkpoint 1024335452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308,760.26494
Policy Entropy: 1.03600
Value Function Loss: 1.87794

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.15068
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.09464

Collected Steps per Second: 3,793.82967
Overall Steps per Second: 3,136.78102

Timestep Collection Time: 13.18457
Timestep Consumption Time: 2.76172
PPO Batch Consumption Time: 0.05894
Total Iteration Time: 15.94628

Cumulative Model Updates: 61,413
Cumulative Timesteps: 1,024,385,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202,558.87020
Policy Entropy: 1.03399
Value Function Loss: 2.04027

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.17335
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.09925

Collected Steps per Second: 3,731.61588
Overall Steps per Second: 3,106.62626

Timestep Collection Time: 13.40331
Timestep Consumption Time: 2.69647
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 16.09978

Cumulative Model Updates: 61,416
Cumulative Timesteps: 1,024,435,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1024435488...
Checkpoint 1024435488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709,455.70274
Policy Entropy: 1.05392
Value Function Loss: 1.96564

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.09997

Collected Steps per Second: 3,957.13993
Overall Steps per Second: 3,282.72087

Timestep Collection Time: 12.63842
Timestep Consumption Time: 2.59650
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 15.23492

Cumulative Model Updates: 61,419
Cumulative Timesteps: 1,024,485,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683,340.77047
Policy Entropy: 1.05267
Value Function Loss: 1.96889

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.06993
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 3,653.70823
Overall Steps per Second: 3,062.76900

Timestep Collection Time: 13.68965
Timestep Consumption Time: 2.64132
PPO Batch Consumption Time: 0.05326
Total Iteration Time: 16.33097

Cumulative Model Updates: 61,422
Cumulative Timesteps: 1,024,535,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1024535518...
Checkpoint 1024535518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500,278.34722
Policy Entropy: 1.04258
Value Function Loss: 1.89252

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.07734
Value Function Update Magnitude: 0.14071

Collected Steps per Second: 3,823.62990
Overall Steps per Second: 3,219.93022

Timestep Collection Time: 13.07815
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 15.53015

Cumulative Model Updates: 61,425
Cumulative Timesteps: 1,024,585,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680,174.34470
Policy Entropy: 1.03948
Value Function Loss: 1.94680

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.07602
Value Function Update Magnitude: 0.13730

Collected Steps per Second: 3,761.47076
Overall Steps per Second: 3,133.16032

Timestep Collection Time: 13.30065
Timestep Consumption Time: 2.66725
PPO Batch Consumption Time: 0.05277
Total Iteration Time: 15.96790

Cumulative Model Updates: 61,428
Cumulative Timesteps: 1,024,635,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1024635554...
Checkpoint 1024635554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,811,325.49307
Policy Entropy: 1.03118
Value Function Loss: 1.92894

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.15319
Policy Update Magnitude: 0.07574
Value Function Update Magnitude: 0.13163

Collected Steps per Second: 3,840.32979
Overall Steps per Second: 3,203.97496

Timestep Collection Time: 13.02649
Timestep Consumption Time: 2.58724
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 15.61373

Cumulative Model Updates: 61,431
Cumulative Timesteps: 1,024,685,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697,887.87181
Policy Entropy: 1.04861
Value Function Loss: 1.91398

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.15818
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.13333

Collected Steps per Second: 3,884.78149
Overall Steps per Second: 3,254.71081

Timestep Collection Time: 12.87486
Timestep Consumption Time: 2.49241
PPO Batch Consumption Time: 0.05335
Total Iteration Time: 15.36726

Cumulative Model Updates: 61,434
Cumulative Timesteps: 1,024,735,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1024735596...
Checkpoint 1024735596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748,715.87459
Policy Entropy: 1.05462
Value Function Loss: 1.86218

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.16458
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.13481

Collected Steps per Second: 3,794.88556
Overall Steps per Second: 3,199.86178

Timestep Collection Time: 13.18459
Timestep Consumption Time: 2.45171
PPO Batch Consumption Time: 0.05893
Total Iteration Time: 15.63630

Cumulative Model Updates: 61,437
Cumulative Timesteps: 1,024,785,630

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433,440.32464
Policy Entropy: 1.04909
Value Function Loss: 1.82752

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.13759

Collected Steps per Second: 3,827.67407
Overall Steps per Second: 3,159.81948

Timestep Collection Time: 13.07321
Timestep Consumption Time: 2.76313
PPO Batch Consumption Time: 0.06487
Total Iteration Time: 15.83635

Cumulative Model Updates: 61,440
Cumulative Timesteps: 1,024,835,670

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1024835670...
Checkpoint 1024835670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,031,613.12645
Policy Entropy: 1.03259
Value Function Loss: 1.80999

Mean KL Divergence: 0.02665
SB3 Clip Fraction: 0.19337
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.13314

Collected Steps per Second: 3,793.69771
Overall Steps per Second: 3,142.25736

Timestep Collection Time: 13.18186
Timestep Consumption Time: 2.73281
PPO Batch Consumption Time: 0.05205
Total Iteration Time: 15.91467

Cumulative Model Updates: 61,443
Cumulative Timesteps: 1,024,885,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264,228.92917
Policy Entropy: 1.03987
Value Function Loss: 1.87140

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.11514

Collected Steps per Second: 3,878.11664
Overall Steps per Second: 3,213.88670

Timestep Collection Time: 12.90575
Timestep Consumption Time: 2.66730
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 15.57304

Cumulative Model Updates: 61,446
Cumulative Timesteps: 1,024,935,728

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1024935728...
Checkpoint 1024935728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401,141.34952
Policy Entropy: 1.03201
Value Function Loss: 1.87880

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.10099

Collected Steps per Second: 3,863.95564
Overall Steps per Second: 3,194.34779

Timestep Collection Time: 12.94684
Timestep Consumption Time: 2.71395
PPO Batch Consumption Time: 0.05238
Total Iteration Time: 15.66079

Cumulative Model Updates: 61,449
Cumulative Timesteps: 1,024,985,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,011.59172
Policy Entropy: 1.02985
Value Function Loss: 1.97809

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.09696

Collected Steps per Second: 3,753.84021
Overall Steps per Second: 3,127.41469

Timestep Collection Time: 13.33301
Timestep Consumption Time: 2.67062
PPO Batch Consumption Time: 0.05305
Total Iteration Time: 16.00363

Cumulative Model Updates: 61,452
Cumulative Timesteps: 1,025,035,804

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1025035804...
Checkpoint 1025035804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124,995.60691
Policy Entropy: 1.04906
Value Function Loss: 1.94935

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.15866
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.11496

Collected Steps per Second: 3,920.78528
Overall Steps per Second: 3,238.09767

Timestep Collection Time: 12.76275
Timestep Consumption Time: 2.69077
PPO Batch Consumption Time: 0.05969
Total Iteration Time: 15.45352

Cumulative Model Updates: 61,455
Cumulative Timesteps: 1,025,085,844

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489,047.43017
Policy Entropy: 1.04958
Value Function Loss: 1.93519

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.16387
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.11622

Collected Steps per Second: 3,719.85229
Overall Steps per Second: 3,121.75405

Timestep Collection Time: 13.45161
Timestep Consumption Time: 2.57720
PPO Batch Consumption Time: 0.05209
Total Iteration Time: 16.02881

Cumulative Model Updates: 61,458
Cumulative Timesteps: 1,025,135,882

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1025135882...
Checkpoint 1025135882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804,374.86081
Policy Entropy: 1.02572
Value Function Loss: 1.82083

Mean KL Divergence: 0.02653
SB3 Clip Fraction: 0.16889
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.10292

Collected Steps per Second: 3,788.56078
Overall Steps per Second: 3,150.45059

Timestep Collection Time: 13.20765
Timestep Consumption Time: 2.67515
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 15.88281

Cumulative Model Updates: 61,461
Cumulative Timesteps: 1,025,185,920

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,598,393.85062
Policy Entropy: 1.02784
Value Function Loss: 1.80639

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.09653

Collected Steps per Second: 3,848.86613
Overall Steps per Second: 3,197.25707

Timestep Collection Time: 12.99500
Timestep Consumption Time: 2.64841
PPO Batch Consumption Time: 0.06263
Total Iteration Time: 15.64341

Cumulative Model Updates: 61,464
Cumulative Timesteps: 1,025,235,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1025235936...
Checkpoint 1025235936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841,054.70243
Policy Entropy: 1.04995
Value Function Loss: 1.82456

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.16275
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.11175

Collected Steps per Second: 3,812.70860
Overall Steps per Second: 3,203.74646

Timestep Collection Time: 13.12295
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.04992
Total Iteration Time: 15.61734

Cumulative Model Updates: 61,467
Cumulative Timesteps: 1,025,285,970

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127,535.30299
Policy Entropy: 1.06392
Value Function Loss: 1.84656

Mean KL Divergence: 0.02143
SB3 Clip Fraction: 0.16982
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.11974

Collected Steps per Second: 3,763.40936
Overall Steps per Second: 3,208.73245

Timestep Collection Time: 13.29433
Timestep Consumption Time: 2.29812
PPO Batch Consumption Time: 0.05821
Total Iteration Time: 15.59245

Cumulative Model Updates: 61,470
Cumulative Timesteps: 1,025,336,002

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1025336002...
Checkpoint 1025336002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467,385.59789
Policy Entropy: 1.04910
Value Function Loss: 1.86546

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.10436

Collected Steps per Second: 3,611.58530
Overall Steps per Second: 3,062.72418

Timestep Collection Time: 13.84655
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 16.32795

Cumulative Model Updates: 61,473
Cumulative Timesteps: 1,025,386,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333,304.70790
Policy Entropy: 1.02929
Value Function Loss: 1.88217

Mean KL Divergence: 0.02502
SB3 Clip Fraction: 0.17777
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.10410

Collected Steps per Second: 3,832.47821
Overall Steps per Second: 3,212.17714

Timestep Collection Time: 13.05317
Timestep Consumption Time: 2.52069
PPO Batch Consumption Time: 0.04949
Total Iteration Time: 15.57386

Cumulative Model Updates: 61,476
Cumulative Timesteps: 1,025,436,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1025436036...
Checkpoint 1025436036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407,463.97973
Policy Entropy: 1.05501
Value Function Loss: 1.91034

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.16973
Policy Update Magnitude: 0.06675
Value Function Update Magnitude: 0.10182

Collected Steps per Second: 3,732.07268
Overall Steps per Second: 3,163.46469

Timestep Collection Time: 13.39845
Timestep Consumption Time: 2.40827
PPO Batch Consumption Time: 0.05426
Total Iteration Time: 15.80672

Cumulative Model Updates: 61,479
Cumulative Timesteps: 1,025,486,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532,204.64238
Policy Entropy: 1.03990
Value Function Loss: 1.86601

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.15074
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.09316

Collected Steps per Second: 3,945.73116
Overall Steps per Second: 3,236.66699

Timestep Collection Time: 12.67699
Timestep Consumption Time: 2.77718
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 15.45417

Cumulative Model Updates: 61,482
Cumulative Timesteps: 1,025,536,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1025536060...
Checkpoint 1025536060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554,229.77968
Policy Entropy: 1.05135
Value Function Loss: 1.80903

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.09287

Collected Steps per Second: 3,736.83997
Overall Steps per Second: 3,109.31190

Timestep Collection Time: 13.38725
Timestep Consumption Time: 2.70184
PPO Batch Consumption Time: 0.06024
Total Iteration Time: 16.08909

Cumulative Model Updates: 61,485
Cumulative Timesteps: 1,025,586,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596,755.05886
Policy Entropy: 1.04378
Value Function Loss: 1.77313

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.07250
Value Function Update Magnitude: 0.11318

Collected Steps per Second: 4,003.81933
Overall Steps per Second: 3,278.50296

Timestep Collection Time: 12.48858
Timestep Consumption Time: 2.76290
PPO Batch Consumption Time: 0.05283
Total Iteration Time: 15.25147

Cumulative Model Updates: 61,488
Cumulative Timesteps: 1,025,636,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1025636088...
Checkpoint 1025636088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022,972.72849
Policy Entropy: 1.04757
Value Function Loss: 1.75300

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.06953
Value Function Update Magnitude: 0.12875

Collected Steps per Second: 3,944.42829
Overall Steps per Second: 3,266.11652

Timestep Collection Time: 12.68016
Timestep Consumption Time: 2.63343
PPO Batch Consumption Time: 0.05311
Total Iteration Time: 15.31360

Cumulative Model Updates: 61,491
Cumulative Timesteps: 1,025,686,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385,428.17349
Policy Entropy: 1.03799
Value Function Loss: 1.78307

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.07491
Value Function Update Magnitude: 0.13266

Collected Steps per Second: 3,787.79088
Overall Steps per Second: 3,162.09588

Timestep Collection Time: 13.20295
Timestep Consumption Time: 2.61251
PPO Batch Consumption Time: 0.05049
Total Iteration Time: 15.81546

Cumulative Model Updates: 61,494
Cumulative Timesteps: 1,025,736,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1025736114...
Checkpoint 1025736114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689,392.18627
Policy Entropy: 1.04790
Value Function Loss: 1.74574

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.07466
Value Function Update Magnitude: 0.12707

Collected Steps per Second: 3,997.17399
Overall Steps per Second: 3,275.86797

Timestep Collection Time: 12.51234
Timestep Consumption Time: 2.75506
PPO Batch Consumption Time: 0.05983
Total Iteration Time: 15.26740

Cumulative Model Updates: 61,497
Cumulative Timesteps: 1,025,786,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326,805.18068
Policy Entropy: 1.05120
Value Function Loss: 1.79489

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.07172
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 3,758.11304
Overall Steps per Second: 3,135.36194

Timestep Collection Time: 13.31200
Timestep Consumption Time: 2.64405
PPO Batch Consumption Time: 0.05382
Total Iteration Time: 15.95605

Cumulative Model Updates: 61,500
Cumulative Timesteps: 1,025,836,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1025836156...
Checkpoint 1025836156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330,890.48144
Policy Entropy: 1.04579
Value Function Loss: 1.80615

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.07296
Value Function Update Magnitude: 0.12336

Collected Steps per Second: 3,747.16758
Overall Steps per Second: 3,155.81026

Timestep Collection Time: 13.34395
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.05835
Total Iteration Time: 15.84443

Cumulative Model Updates: 61,503
Cumulative Timesteps: 1,025,886,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850,521.02258
Policy Entropy: 1.04075
Value Function Loss: 1.88882

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.07857
Value Function Update Magnitude: 0.11027

Collected Steps per Second: 3,734.63732
Overall Steps per Second: 3,186.62615

Timestep Collection Time: 13.38872
Timestep Consumption Time: 2.30249
PPO Batch Consumption Time: 0.05347
Total Iteration Time: 15.69120

Cumulative Model Updates: 61,506
Cumulative Timesteps: 1,025,936,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1025936160...
Checkpoint 1025936160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428,440.99790
Policy Entropy: 1.03789
Value Function Loss: 1.93156

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.07601
Value Function Update Magnitude: 0.09888

Collected Steps per Second: 3,844.95823
Overall Steps per Second: 3,186.08573

Timestep Collection Time: 13.01289
Timestep Consumption Time: 2.69102
PPO Batch Consumption Time: 0.05085
Total Iteration Time: 15.70391

Cumulative Model Updates: 61,509
Cumulative Timesteps: 1,025,986,194

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700,131.02327
Policy Entropy: 1.04759
Value Function Loss: 1.85974

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.06869
Value Function Update Magnitude: 0.10070

Collected Steps per Second: 3,764.04291
Overall Steps per Second: 3,135.86117

Timestep Collection Time: 13.29368
Timestep Consumption Time: 2.66302
PPO Batch Consumption Time: 0.05917
Total Iteration Time: 15.95670

Cumulative Model Updates: 61,512
Cumulative Timesteps: 1,026,036,232

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1026036232...
Checkpoint 1026036232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468,753.23253
Policy Entropy: 1.05515
Value Function Loss: 1.90122

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.09670

Collected Steps per Second: 3,735.71415
Overall Steps per Second: 3,133.03573

Timestep Collection Time: 13.39075
Timestep Consumption Time: 2.57588
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 15.96662

Cumulative Model Updates: 61,515
Cumulative Timesteps: 1,026,086,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466,976.01242
Policy Entropy: 1.07005
Value Function Loss: 1.89177

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.09612

Collected Steps per Second: 3,809.08076
Overall Steps per Second: 3,147.53854

Timestep Collection Time: 13.13230
Timestep Consumption Time: 2.76012
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 15.89242

Cumulative Model Updates: 61,518
Cumulative Timesteps: 1,026,136,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1026136278...
Checkpoint 1026136278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581,033.87175
Policy Entropy: 1.04857
Value Function Loss: 1.96775

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 3,895.54823
Overall Steps per Second: 3,270.63079

Timestep Collection Time: 12.84287
Timestep Consumption Time: 2.45388
PPO Batch Consumption Time: 0.05111
Total Iteration Time: 15.29674

Cumulative Model Updates: 61,521
Cumulative Timesteps: 1,026,186,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256,976.47414
Policy Entropy: 1.05943
Value Function Loss: 1.95320

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.11978

Collected Steps per Second: 3,750.87101
Overall Steps per Second: 3,128.03381

Timestep Collection Time: 13.33983
Timestep Consumption Time: 2.65616
PPO Batch Consumption Time: 0.06206
Total Iteration Time: 15.99599

Cumulative Model Updates: 61,524
Cumulative Timesteps: 1,026,236,344

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1026236344...
Checkpoint 1026236344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933,624.32676
Policy Entropy: 1.06483
Value Function Loss: 1.88414

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.06387
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 3,894.25467
Overall Steps per Second: 3,219.59140

Timestep Collection Time: 12.85021
Timestep Consumption Time: 2.69275
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 15.54297

Cumulative Model Updates: 61,527
Cumulative Timesteps: 1,026,286,386

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491,211.36396
Policy Entropy: 1.07553
Value Function Loss: 1.94081

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.12376

Collected Steps per Second: 3,817.40577
Overall Steps per Second: 3,178.72077

Timestep Collection Time: 13.10576
Timestep Consumption Time: 2.63328
PPO Batch Consumption Time: 0.05782
Total Iteration Time: 15.73904

Cumulative Model Updates: 61,530
Cumulative Timesteps: 1,026,336,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1026336416...
Checkpoint 1026336416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,968,944.24366
Policy Entropy: 1.06398
Value Function Loss: 1.92279

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 3,884.22348
Overall Steps per Second: 3,223.32955

Timestep Collection Time: 12.87362
Timestep Consumption Time: 2.63954
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 15.51315

Cumulative Model Updates: 61,533
Cumulative Timesteps: 1,026,386,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804,324.59957
Policy Entropy: 1.04957
Value Function Loss: 1.98039

Mean KL Divergence: 0.02803
SB3 Clip Fraction: 0.17785
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 3,830.43407
Overall Steps per Second: 3,217.15515

Timestep Collection Time: 13.06275
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.05974
Total Iteration Time: 15.55287

Cumulative Model Updates: 61,536
Cumulative Timesteps: 1,026,436,456

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1026436456...
Checkpoint 1026436456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215,852.01670
Policy Entropy: 1.06335
Value Function Loss: 1.91442

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.10553

Collected Steps per Second: 3,786.43404
Overall Steps per Second: 3,200.66573

Timestep Collection Time: 13.21296
Timestep Consumption Time: 2.41816
PPO Batch Consumption Time: 0.05005
Total Iteration Time: 15.63112

Cumulative Model Updates: 61,539
Cumulative Timesteps: 1,026,486,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294,776.75357
Policy Entropy: 1.05947
Value Function Loss: 1.89748

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.07370
Value Function Update Magnitude: 0.10216

Collected Steps per Second: 3,882.31455
Overall Steps per Second: 2,957.35266

Timestep Collection Time: 12.89128
Timestep Consumption Time: 4.03196
PPO Batch Consumption Time: 0.06051
Total Iteration Time: 16.92324

Cumulative Model Updates: 61,542
Cumulative Timesteps: 1,026,536,534

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1026536534...
Checkpoint 1026536534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267,714.83086
Policy Entropy: 1.06308
Value Function Loss: 1.92409

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.07487
Value Function Update Magnitude: 0.10036

Collected Steps per Second: 4,075.77002
Overall Steps per Second: 3,328.97825

Timestep Collection Time: 12.27498
Timestep Consumption Time: 2.75365
PPO Batch Consumption Time: 0.05422
Total Iteration Time: 15.02864

Cumulative Model Updates: 61,545
Cumulative Timesteps: 1,026,586,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585,368.76956
Policy Entropy: 1.06621
Value Function Loss: 1.97812

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.07603
Value Function Update Magnitude: 0.09078

Collected Steps per Second: 3,853.99333
Overall Steps per Second: 3,190.26185

Timestep Collection Time: 12.97408
Timestep Consumption Time: 2.69925
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 15.67332

Cumulative Model Updates: 61,548
Cumulative Timesteps: 1,026,636,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1026636566...
Checkpoint 1026636566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428,265.82224
Policy Entropy: 1.07465
Value Function Loss: 1.99723

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.08119
Value Function Update Magnitude: 0.09254

Collected Steps per Second: 3,796.69023
Overall Steps per Second: 3,139.98196

Timestep Collection Time: 13.18095
Timestep Consumption Time: 2.75672
PPO Batch Consumption Time: 0.06217
Total Iteration Time: 15.93767

Cumulative Model Updates: 61,551
Cumulative Timesteps: 1,026,686,610

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698,143.28259
Policy Entropy: 1.07030
Value Function Loss: 1.98293

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.08049
Value Function Update Magnitude: 0.09797

Collected Steps per Second: 3,672.63370
Overall Steps per Second: 3,064.72663

Timestep Collection Time: 13.61530
Timestep Consumption Time: 2.70068
PPO Batch Consumption Time: 0.06112
Total Iteration Time: 16.31597

Cumulative Model Updates: 61,554
Cumulative Timesteps: 1,026,736,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1026736614...
Checkpoint 1026736614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717,685.89009
Policy Entropy: 1.07732
Value Function Loss: 1.94234

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.07954
Value Function Update Magnitude: 0.09436

Collected Steps per Second: 3,824.29008
Overall Steps per Second: 3,214.02877

Timestep Collection Time: 13.08792
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.05811
Total Iteration Time: 15.57298

Cumulative Model Updates: 61,557
Cumulative Timesteps: 1,026,786,666

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677,530.48049
Policy Entropy: 1.06442
Value Function Loss: 1.95230

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.07749
Value Function Update Magnitude: 0.08479

Collected Steps per Second: 3,897.70380
Overall Steps per Second: 3,228.92211

Timestep Collection Time: 12.82807
Timestep Consumption Time: 2.65698
PPO Batch Consumption Time: 0.05268
Total Iteration Time: 15.48504

Cumulative Model Updates: 61,560
Cumulative Timesteps: 1,026,836,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1026836666...
Checkpoint 1026836666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021,709.31491
Policy Entropy: 1.08307
Value Function Loss: 1.97183

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.09239

Collected Steps per Second: 3,815.68634
Overall Steps per Second: 3,191.49208

Timestep Collection Time: 13.11324
Timestep Consumption Time: 2.56470
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 15.67793

Cumulative Model Updates: 61,563
Cumulative Timesteps: 1,026,886,702

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204,127.82049
Policy Entropy: 1.07903
Value Function Loss: 1.94922

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.05946
Value Function Update Magnitude: 0.10574

Collected Steps per Second: 3,694.31293
Overall Steps per Second: 3,117.17666

Timestep Collection Time: 13.53973
Timestep Consumption Time: 2.50684
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 16.04657

Cumulative Model Updates: 61,566
Cumulative Timesteps: 1,026,936,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1026936722...
Checkpoint 1026936722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,868,921.77931
Policy Entropy: 1.07051
Value Function Loss: 1.97006

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.12336

Collected Steps per Second: 3,783.49814
Overall Steps per Second: 3,189.79755

Timestep Collection Time: 13.21687
Timestep Consumption Time: 2.45999
PPO Batch Consumption Time: 0.06483
Total Iteration Time: 15.67686

Cumulative Model Updates: 61,569
Cumulative Timesteps: 1,026,986,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171,850.79110
Policy Entropy: 1.05727
Value Function Loss: 2.01293

Mean KL Divergence: 0.03018
SB3 Clip Fraction: 0.18139
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.11412

Collected Steps per Second: 3,670.84329
Overall Steps per Second: 3,169.55037

Timestep Collection Time: 13.63338
Timestep Consumption Time: 2.15624
PPO Batch Consumption Time: 0.05033
Total Iteration Time: 15.78962

Cumulative Model Updates: 61,572
Cumulative Timesteps: 1,027,036,774

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1027036774...
Checkpoint 1027036774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329,385.21390
Policy Entropy: 1.07280
Value Function Loss: 2.01385

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.11027

Collected Steps per Second: 3,825.30021
Overall Steps per Second: 3,237.42587

Timestep Collection Time: 13.08237
Timestep Consumption Time: 2.37559
PPO Batch Consumption Time: 0.05281
Total Iteration Time: 15.45796

Cumulative Model Updates: 61,575
Cumulative Timesteps: 1,027,086,818

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589,243.49182
Policy Entropy: 1.06970
Value Function Loss: 1.95786

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.11495

Collected Steps per Second: 3,873.62455
Overall Steps per Second: 3,229.15152

Timestep Collection Time: 12.92020
Timestep Consumption Time: 2.57861
PPO Batch Consumption Time: 0.05992
Total Iteration Time: 15.49881

Cumulative Model Updates: 61,578
Cumulative Timesteps: 1,027,136,866

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1027136866...
Checkpoint 1027136866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409,936.00242
Policy Entropy: 1.06904
Value Function Loss: 1.96546

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.07324
Value Function Update Magnitude: 0.09884

Collected Steps per Second: 3,783.78717
Overall Steps per Second: 3,165.53153

Timestep Collection Time: 13.22485
Timestep Consumption Time: 2.58293
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 15.80777

Cumulative Model Updates: 61,581
Cumulative Timesteps: 1,027,186,906

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506,288.97861
Policy Entropy: 1.05213
Value Function Loss: 1.97099

Mean KL Divergence: 0.02871
SB3 Clip Fraction: 0.17419
Policy Update Magnitude: 0.06862
Value Function Update Magnitude: 0.09566

Collected Steps per Second: 3,823.22564
Overall Steps per Second: 3,185.27108

Timestep Collection Time: 13.08895
Timestep Consumption Time: 2.62149
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 15.71044

Cumulative Model Updates: 61,584
Cumulative Timesteps: 1,027,236,948

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1027236948...
Checkpoint 1027236948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307,289.38660
Policy Entropy: 1.07533
Value Function Loss: 1.96010

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.09305

Collected Steps per Second: 3,873.00823
Overall Steps per Second: 3,256.72252

Timestep Collection Time: 12.91296
Timestep Consumption Time: 2.44358
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 15.35654

Cumulative Model Updates: 61,587
Cumulative Timesteps: 1,027,286,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665,460.20029
Policy Entropy: 1.06712
Value Function Loss: 1.82773

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.09814

Collected Steps per Second: 3,867.60033
Overall Steps per Second: 3,250.07658

Timestep Collection Time: 12.93257
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 15.38979

Cumulative Model Updates: 61,590
Cumulative Timesteps: 1,027,336,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1027336978...
Checkpoint 1027336978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529,419.73766
Policy Entropy: 1.06113
Value Function Loss: 1.82118

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.09942

Collected Steps per Second: 3,824.24602
Overall Steps per Second: 3,181.79088

Timestep Collection Time: 13.07604
Timestep Consumption Time: 2.64026
PPO Batch Consumption Time: 0.05187
Total Iteration Time: 15.71631

Cumulative Model Updates: 61,593
Cumulative Timesteps: 1,027,386,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360,164.69026
Policy Entropy: 1.05280
Value Function Loss: 1.80574

Mean KL Divergence: 0.02492
SB3 Clip Fraction: 0.17036
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.10200

Collected Steps per Second: 3,781.01281
Overall Steps per Second: 3,191.49601

Timestep Collection Time: 13.23190
Timestep Consumption Time: 2.44413
PPO Batch Consumption Time: 0.06236
Total Iteration Time: 15.67603

Cumulative Model Updates: 61,596
Cumulative Timesteps: 1,027,437,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1027437014...
Checkpoint 1027437014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720,678.47841
Policy Entropy: 1.06914
Value Function Loss: 1.81484

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.10192

Collected Steps per Second: 3,804.17496
Overall Steps per Second: 3,204.96222

Timestep Collection Time: 13.14661
Timestep Consumption Time: 2.45794
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 15.60455

Cumulative Model Updates: 61,599
Cumulative Timesteps: 1,027,487,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075,715.46451
Policy Entropy: 1.07417
Value Function Loss: 1.73237

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.09677

Collected Steps per Second: 3,781.50806
Overall Steps per Second: 3,190.47646

Timestep Collection Time: 13.23282
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.06254
Total Iteration Time: 15.68418

Cumulative Model Updates: 61,602
Cumulative Timesteps: 1,027,537,066

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1027537066...
Checkpoint 1027537066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539,904.04810
Policy Entropy: 1.05805
Value Function Loss: 1.74664

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.09453

Collected Steps per Second: 3,804.72215
Overall Steps per Second: 3,148.13027

Timestep Collection Time: 13.14840
Timestep Consumption Time: 2.74230
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 15.89070

Cumulative Model Updates: 61,605
Cumulative Timesteps: 1,027,587,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262,716.50604
Policy Entropy: 1.05300
Value Function Loss: 1.79328

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.17197
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.10170

Collected Steps per Second: 3,834.27780
Overall Steps per Second: 3,155.97066

Timestep Collection Time: 13.04235
Timestep Consumption Time: 2.80317
PPO Batch Consumption Time: 0.06102
Total Iteration Time: 15.84552

Cumulative Model Updates: 61,608
Cumulative Timesteps: 1,027,637,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1027637100...
Checkpoint 1027637100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,984,300.35451
Policy Entropy: 1.05818
Value Function Loss: 1.94522

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.10003

Collected Steps per Second: 3,902.37340
Overall Steps per Second: 3,211.67540

Timestep Collection Time: 12.81579
Timestep Consumption Time: 2.75614
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 15.57193

Cumulative Model Updates: 61,611
Cumulative Timesteps: 1,027,687,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360,568.58303
Policy Entropy: 1.05980
Value Function Loss: 1.91859

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.06378
Value Function Update Magnitude: 0.10070

Collected Steps per Second: 4,047.96649
Overall Steps per Second: 3,311.40321

Timestep Collection Time: 12.35583
Timestep Consumption Time: 2.74834
PPO Batch Consumption Time: 0.05857
Total Iteration Time: 15.10417

Cumulative Model Updates: 61,614
Cumulative Timesteps: 1,027,737,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1027737128...
Checkpoint 1027737128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507,842.68134
Policy Entropy: 1.04686
Value Function Loss: 1.86828

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.09578

Collected Steps per Second: 3,925.47698
Overall Steps per Second: 3,273.86868

Timestep Collection Time: 12.73832
Timestep Consumption Time: 2.53535
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 15.27367

Cumulative Model Updates: 61,617
Cumulative Timesteps: 1,027,787,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923,371.42694
Policy Entropy: 1.04909
Value Function Loss: 1.77537

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.17643
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.08698

Collected Steps per Second: 3,852.04685
Overall Steps per Second: 3,212.38693

Timestep Collection Time: 12.98894
Timestep Consumption Time: 2.58640
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 15.57533

Cumulative Model Updates: 61,620
Cumulative Timesteps: 1,027,837,166

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1027837166...
Checkpoint 1027837166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798,791.79342
Policy Entropy: 1.06119
Value Function Loss: 1.87474

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.08971

Collected Steps per Second: 3,836.94992
Overall Steps per Second: 3,221.78752

Timestep Collection Time: 13.04005
Timestep Consumption Time: 2.48984
PPO Batch Consumption Time: 0.05224
Total Iteration Time: 15.52989

Cumulative Model Updates: 61,623
Cumulative Timesteps: 1,027,887,200

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285,853.51128
Policy Entropy: 1.06767
Value Function Loss: 1.89747

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.09163

Collected Steps per Second: 3,847.34268
Overall Steps per Second: 3,237.65177

Timestep Collection Time: 12.99598
Timestep Consumption Time: 2.44731
PPO Batch Consumption Time: 0.06633
Total Iteration Time: 15.44329

Cumulative Model Updates: 61,626
Cumulative Timesteps: 1,027,937,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1027937200...
Checkpoint 1027937200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322,969.79328
Policy Entropy: 1.04838
Value Function Loss: 1.82165

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.09233

Collected Steps per Second: 3,876.08405
Overall Steps per Second: 3,175.77927

Timestep Collection Time: 12.90220
Timestep Consumption Time: 2.84512
PPO Batch Consumption Time: 0.06008
Total Iteration Time: 15.74732

Cumulative Model Updates: 61,629
Cumulative Timesteps: 1,027,987,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734,748.91357
Policy Entropy: 1.03851
Value Function Loss: 1.82826

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.08441

Collected Steps per Second: 3,850.24430
Overall Steps per Second: 3,198.22781

Timestep Collection Time: 12.98983
Timestep Consumption Time: 2.64821
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 15.63804

Cumulative Model Updates: 61,632
Cumulative Timesteps: 1,028,037,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1028037224...
Checkpoint 1028037224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303,667.06884
Policy Entropy: 1.05219
Value Function Loss: 1.93878

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 3,672.91955
Overall Steps per Second: 3,070.06469

Timestep Collection Time: 13.61968
Timestep Consumption Time: 2.67444
PPO Batch Consumption Time: 0.05800
Total Iteration Time: 16.29412

Cumulative Model Updates: 61,635
Cumulative Timesteps: 1,028,087,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220,685.94444
Policy Entropy: 1.05594
Value Function Loss: 1.98246

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.16059
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.08889

Collected Steps per Second: 3,801.72371
Overall Steps per Second: 3,141.89601

Timestep Collection Time: 13.15719
Timestep Consumption Time: 2.76313
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 15.92032

Cumulative Model Updates: 61,638
Cumulative Timesteps: 1,028,137,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1028137268...
Checkpoint 1028137268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485,225.78971
Policy Entropy: 1.04838
Value Function Loss: 1.98346

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.09229

Collected Steps per Second: 3,884.80120
Overall Steps per Second: 3,201.49647

Timestep Collection Time: 12.88097
Timestep Consumption Time: 2.74922
PPO Batch Consumption Time: 0.05889
Total Iteration Time: 15.63019

Cumulative Model Updates: 61,641
Cumulative Timesteps: 1,028,187,308

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432,807.59680
Policy Entropy: 1.03558
Value Function Loss: 1.97694

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.16099
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.09827

Collected Steps per Second: 3,842.03291
Overall Steps per Second: 3,201.99744

Timestep Collection Time: 13.02123
Timestep Consumption Time: 2.60277
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 15.62400

Cumulative Model Updates: 61,644
Cumulative Timesteps: 1,028,237,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1028237336...
Checkpoint 1028237336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472,153.70725
Policy Entropy: 1.05377
Value Function Loss: 1.95412

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.09070

Collected Steps per Second: 4,035.60877
Overall Steps per Second: 3,380.24931

Timestep Collection Time: 12.39615
Timestep Consumption Time: 2.40335
PPO Batch Consumption Time: 0.05408
Total Iteration Time: 14.79950

Cumulative Model Updates: 61,647
Cumulative Timesteps: 1,028,287,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360,134.95752
Policy Entropy: 1.06372
Value Function Loss: 1.89428

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.15587
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.08991

Collected Steps per Second: 3,862.71648
Overall Steps per Second: 3,310.56510

Timestep Collection Time: 12.94478
Timestep Consumption Time: 2.15899
PPO Batch Consumption Time: 0.05071
Total Iteration Time: 15.10377

Cumulative Model Updates: 61,650
Cumulative Timesteps: 1,028,337,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1028337364...
Checkpoint 1028337364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846,255.03845
Policy Entropy: 1.04874
Value Function Loss: 1.83483

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.09472

Collected Steps per Second: 3,629.56360
Overall Steps per Second: 3,090.38657

Timestep Collection Time: 13.78623
Timestep Consumption Time: 2.40527
PPO Batch Consumption Time: 0.06072
Total Iteration Time: 16.19150

Cumulative Model Updates: 61,653
Cumulative Timesteps: 1,028,387,402

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551,984.85461
Policy Entropy: 1.05878
Value Function Loss: 1.93517

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.10807

Collected Steps per Second: 3,790.22632
Overall Steps per Second: 3,161.05457

Timestep Collection Time: 13.19763
Timestep Consumption Time: 2.62684
PPO Batch Consumption Time: 0.06377
Total Iteration Time: 15.82447

Cumulative Model Updates: 61,656
Cumulative Timesteps: 1,028,437,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1028437424...
Checkpoint 1028437424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124,966.73490
Policy Entropy: 1.07508
Value Function Loss: 1.89696

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.14933
Policy Update Magnitude: 0.06406
Value Function Update Magnitude: 0.11046

Collected Steps per Second: 3,699.90024
Overall Steps per Second: 3,051.43100

Timestep Collection Time: 13.51820
Timestep Consumption Time: 2.87280
PPO Batch Consumption Time: 0.05345
Total Iteration Time: 16.39100

Cumulative Model Updates: 61,659
Cumulative Timesteps: 1,028,487,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728,303.65201
Policy Entropy: 1.05075
Value Function Loss: 1.89914

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.10829

Collected Steps per Second: 3,923.35041
Overall Steps per Second: 3,227.45539

Timestep Collection Time: 12.74778
Timestep Consumption Time: 2.74864
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 15.49642

Cumulative Model Updates: 61,662
Cumulative Timesteps: 1,028,537,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1028537454...
Checkpoint 1028537454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618,330.27676
Policy Entropy: 1.04196
Value Function Loss: 1.87721

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.17093
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.11973

Collected Steps per Second: 3,804.60933
Overall Steps per Second: 3,192.59812

Timestep Collection Time: 13.14879
Timestep Consumption Time: 2.52058
PPO Batch Consumption Time: 0.05227
Total Iteration Time: 15.66937

Cumulative Model Updates: 61,665
Cumulative Timesteps: 1,028,587,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705,790.27015
Policy Entropy: 1.04498
Value Function Loss: 1.87129

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.12236

Collected Steps per Second: 3,844.05320
Overall Steps per Second: 3,195.29705

Timestep Collection Time: 13.00919
Timestep Consumption Time: 2.64132
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 15.65050

Cumulative Model Updates: 61,668
Cumulative Timesteps: 1,028,637,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1028637488...
Checkpoint 1028637488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820,572.61057
Policy Entropy: 1.05217
Value Function Loss: 1.84822

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.13344

Collected Steps per Second: 3,914.62331
Overall Steps per Second: 3,256.88450

Timestep Collection Time: 12.77977
Timestep Consumption Time: 2.58092
PPO Batch Consumption Time: 0.05965
Total Iteration Time: 15.36069

Cumulative Model Updates: 61,671
Cumulative Timesteps: 1,028,687,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,367,907.52056
Policy Entropy: 1.04296
Value Function Loss: 1.83654

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.13448

Collected Steps per Second: 3,698.98226
Overall Steps per Second: 3,130.32706

Timestep Collection Time: 13.52967
Timestep Consumption Time: 2.45780
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 15.98747

Cumulative Model Updates: 61,674
Cumulative Timesteps: 1,028,737,562

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1028737562...
Checkpoint 1028737562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800,173.95540
Policy Entropy: 1.03157
Value Function Loss: 1.88233

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.17076
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 3,752.03556
Overall Steps per Second: 3,113.71002

Timestep Collection Time: 13.33090
Timestep Consumption Time: 2.73290
PPO Batch Consumption Time: 0.04942
Total Iteration Time: 16.06380

Cumulative Model Updates: 61,677
Cumulative Timesteps: 1,028,787,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146,222.27867
Policy Entropy: 1.04974
Value Function Loss: 1.89128

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.12836

Collected Steps per Second: 3,967.00981
Overall Steps per Second: 3,309.46906

Timestep Collection Time: 12.60395
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.06559
Total Iteration Time: 15.10816

Cumulative Model Updates: 61,680
Cumulative Timesteps: 1,028,837,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1028837580...
Checkpoint 1028837580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181,131.46178
Policy Entropy: 1.06138
Value Function Loss: 1.93866

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.13212

Collected Steps per Second: 3,767.30485
Overall Steps per Second: 3,186.71985

Timestep Collection Time: 13.28217
Timestep Consumption Time: 2.41986
PPO Batch Consumption Time: 0.06298
Total Iteration Time: 15.70204

Cumulative Model Updates: 61,683
Cumulative Timesteps: 1,028,887,618

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604,690.23648
Policy Entropy: 1.04660
Value Function Loss: 1.95248

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.12595

Collected Steps per Second: 3,884.14459
Overall Steps per Second: 3,232.88343

Timestep Collection Time: 12.87439
Timestep Consumption Time: 2.59353
PPO Batch Consumption Time: 0.05789
Total Iteration Time: 15.46793

Cumulative Model Updates: 61,686
Cumulative Timesteps: 1,028,937,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1028937624...
Checkpoint 1028937624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,952,933.70535
Policy Entropy: 1.05955
Value Function Loss: 1.88055

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.16125
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.12455

Collected Steps per Second: 3,780.59483
Overall Steps per Second: 3,174.12752

Timestep Collection Time: 13.23337
Timestep Consumption Time: 2.52844
PPO Batch Consumption Time: 0.05151
Total Iteration Time: 15.76181

Cumulative Model Updates: 61,689
Cumulative Timesteps: 1,028,987,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,100,604.01595
Policy Entropy: 1.05232
Value Function Loss: 1.82365

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.16521
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.11974

Collected Steps per Second: 3,842.91423
Overall Steps per Second: 3,164.39008

Timestep Collection Time: 13.02293
Timestep Consumption Time: 2.79244
PPO Batch Consumption Time: 0.06358
Total Iteration Time: 15.81537

Cumulative Model Updates: 61,692
Cumulative Timesteps: 1,029,037,700

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1029037700...
Checkpoint 1029037700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625,938.37786
Policy Entropy: 1.04799
Value Function Loss: 1.72770

Mean KL Divergence: 0.02491
SB3 Clip Fraction: 0.15341
Policy Update Magnitude: 0.06080
Value Function Update Magnitude: 0.11243

Collected Steps per Second: 3,833.69240
Overall Steps per Second: 3,172.29033

Timestep Collection Time: 13.05321
Timestep Consumption Time: 2.72151
PPO Batch Consumption Time: 0.05298
Total Iteration Time: 15.77472

Cumulative Model Updates: 61,695
Cumulative Timesteps: 1,029,087,742

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540,839.00709
Policy Entropy: 1.04466
Value Function Loss: 1.82431

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.18193
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.10952

Collected Steps per Second: 3,703.51856
Overall Steps per Second: 3,165.32866

Timestep Collection Time: 13.51472
Timestep Consumption Time: 2.29786
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 15.81258

Cumulative Model Updates: 61,698
Cumulative Timesteps: 1,029,137,794

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1029137794...
Checkpoint 1029137794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618,380.64597
Policy Entropy: 1.04795
Value Function Loss: 1.76638

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.09947

Collected Steps per Second: 3,984.33628
Overall Steps per Second: 3,288.96423

Timestep Collection Time: 12.55165
Timestep Consumption Time: 2.65374
PPO Batch Consumption Time: 0.06181
Total Iteration Time: 15.20539

Cumulative Model Updates: 61,701
Cumulative Timesteps: 1,029,187,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347,109.01859
Policy Entropy: 1.05401
Value Function Loss: 1.85547

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.09238

Collected Steps per Second: 3,707.00959
Overall Steps per Second: 3,073.99205

Timestep Collection Time: 13.50037
Timestep Consumption Time: 2.78009
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 16.28046

Cumulative Model Updates: 61,704
Cumulative Timesteps: 1,029,237,850

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1029237850...
Checkpoint 1029237850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279,927.27078
Policy Entropy: 1.03478
Value Function Loss: 1.85212

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.08578

Collected Steps per Second: 3,685.77409
Overall Steps per Second: 3,062.43821

Timestep Collection Time: 13.56838
Timestep Consumption Time: 2.76174
PPO Batch Consumption Time: 0.06364
Total Iteration Time: 16.33013

Cumulative Model Updates: 61,707
Cumulative Timesteps: 1,029,287,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717,316.70392
Policy Entropy: 1.03091
Value Function Loss: 1.87332

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.16272
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.09295

Collected Steps per Second: 3,741.54266
Overall Steps per Second: 3,098.87577

Timestep Collection Time: 13.36828
Timestep Consumption Time: 2.77241
PPO Batch Consumption Time: 0.07325
Total Iteration Time: 16.14069

Cumulative Model Updates: 61,710
Cumulative Timesteps: 1,029,337,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1029337878...
Checkpoint 1029337878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475,562.09727
Policy Entropy: 1.04555
Value Function Loss: 1.91226

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12071
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.11480

Collected Steps per Second: 3,666.26546
Overall Steps per Second: 3,114.29895

Timestep Collection Time: 13.64549
Timestep Consumption Time: 2.41848
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 16.06397

Cumulative Model Updates: 61,713
Cumulative Timesteps: 1,029,387,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746,292.81330
Policy Entropy: 1.05411
Value Function Loss: 1.98152

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.07259
Value Function Update Magnitude: 0.12758

Collected Steps per Second: 3,695.83603
Overall Steps per Second: 3,138.49161

Timestep Collection Time: 13.53740
Timestep Consumption Time: 2.40402
PPO Batch Consumption Time: 0.06065
Total Iteration Time: 15.94142

Cumulative Model Updates: 61,716
Cumulative Timesteps: 1,029,437,938

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1029437938...
Checkpoint 1029437938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754,330.12222
Policy Entropy: 1.04659
Value Function Loss: 1.94124

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.15286
Policy Update Magnitude: 0.06858
Value Function Update Magnitude: 0.12907

Collected Steps per Second: 3,813.70761
Overall Steps per Second: 3,163.45987

Timestep Collection Time: 13.11689
Timestep Consumption Time: 2.69617
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 15.81307

Cumulative Model Updates: 61,719
Cumulative Timesteps: 1,029,487,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899,366.83112
Policy Entropy: 1.03558
Value Function Loss: 1.88497

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.18342
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.11493

Collected Steps per Second: 3,822.52839
Overall Steps per Second: 3,184.43947

Timestep Collection Time: 13.08872
Timestep Consumption Time: 2.62268
PPO Batch Consumption Time: 0.05419
Total Iteration Time: 15.71140

Cumulative Model Updates: 61,722
Cumulative Timesteps: 1,029,537,994

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1029537994...
Checkpoint 1029537994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739,028.01045
Policy Entropy: 1.04194
Value Function Loss: 1.80260

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.10195

Collected Steps per Second: 3,698.67594
Overall Steps per Second: 3,093.64490

Timestep Collection Time: 13.51835
Timestep Consumption Time: 2.64381
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 16.16217

Cumulative Model Updates: 61,725
Cumulative Timesteps: 1,029,587,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203,202.04121
Policy Entropy: 1.05016
Value Function Loss: 1.86680

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.15819
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.09277

Collected Steps per Second: 3,811.46448
Overall Steps per Second: 3,177.36930

Timestep Collection Time: 13.12829
Timestep Consumption Time: 2.61996
PPO Batch Consumption Time: 0.06047
Total Iteration Time: 15.74825

Cumulative Model Updates: 61,728
Cumulative Timesteps: 1,029,638,032

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1029638032...
Checkpoint 1029638032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363,189.84888
Policy Entropy: 1.03879
Value Function Loss: 1.78596

Mean KL Divergence: 0.02369
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.10709

Collected Steps per Second: 3,765.55385
Overall Steps per Second: 3,132.21607

Timestep Collection Time: 13.28357
Timestep Consumption Time: 2.68595
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 15.96952

Cumulative Model Updates: 61,731
Cumulative Timesteps: 1,029,688,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,913,794.35675
Policy Entropy: 1.04840
Value Function Loss: 1.69232

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.11872

Collected Steps per Second: 3,761.95651
Overall Steps per Second: 3,165.05134

Timestep Collection Time: 13.30478
Timestep Consumption Time: 2.50918
PPO Batch Consumption Time: 0.05812
Total Iteration Time: 15.81396

Cumulative Model Updates: 61,734
Cumulative Timesteps: 1,029,738,104

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1029738104...
Checkpoint 1029738104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,940,473.09082
Policy Entropy: 1.04618
Value Function Loss: 1.72494

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.11738

Collected Steps per Second: 3,881.22108
Overall Steps per Second: 3,231.73925

Timestep Collection Time: 12.89388
Timestep Consumption Time: 2.59128
PPO Batch Consumption Time: 0.05029
Total Iteration Time: 15.48516

Cumulative Model Updates: 61,737
Cumulative Timesteps: 1,029,788,148

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449,189.29733
Policy Entropy: 1.04439
Value Function Loss: 1.86334

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 3,828.07860
Overall Steps per Second: 3,183.02360

Timestep Collection Time: 13.06138
Timestep Consumption Time: 2.64695
PPO Batch Consumption Time: 0.06640
Total Iteration Time: 15.70833

Cumulative Model Updates: 61,740
Cumulative Timesteps: 1,029,838,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1029838148...
Checkpoint 1029838148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605,829.13607
Policy Entropy: 1.04091
Value Function Loss: 1.90469

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.07615
Value Function Update Magnitude: 0.11659

Collected Steps per Second: 3,767.37944
Overall Steps per Second: 3,190.46382

Timestep Collection Time: 13.28403
Timestep Consumption Time: 2.40209
PPO Batch Consumption Time: 0.04680
Total Iteration Time: 15.68612

Cumulative Model Updates: 61,743
Cumulative Timesteps: 1,029,888,194

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758,591.21812
Policy Entropy: 1.04243
Value Function Loss: 1.94272

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.07786
Value Function Update Magnitude: 0.11156

Collected Steps per Second: 3,863.59355
Overall Steps per Second: 3,248.62330

Timestep Collection Time: 12.94753
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.05311
Total Iteration Time: 15.39852

Cumulative Model Updates: 61,746
Cumulative Timesteps: 1,029,938,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1029938218...
Checkpoint 1029938218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411,981.37130
Policy Entropy: 1.04700
Value Function Loss: 1.85754

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.07567
Value Function Update Magnitude: 0.10295

Collected Steps per Second: 3,652.42778
Overall Steps per Second: 3,077.99259

Timestep Collection Time: 13.69555
Timestep Consumption Time: 2.55595
PPO Batch Consumption Time: 0.05274
Total Iteration Time: 16.25150

Cumulative Model Updates: 61,749
Cumulative Timesteps: 1,029,988,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649,800.81629
Policy Entropy: 1.05385
Value Function Loss: 1.79600

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.06878
Value Function Update Magnitude: 0.12210

Collected Steps per Second: 3,920.13037
Overall Steps per Second: 3,231.49891

Timestep Collection Time: 12.76080
Timestep Consumption Time: 2.71932
PPO Batch Consumption Time: 0.06098
Total Iteration Time: 15.48012

Cumulative Model Updates: 61,752
Cumulative Timesteps: 1,030,038,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1030038264...
Checkpoint 1030038264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616,825.99889
Policy Entropy: 1.06632
Value Function Loss: 1.75448

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.12186

Collected Steps per Second: 3,674.87255
Overall Steps per Second: 3,064.11648

Timestep Collection Time: 13.61136
Timestep Consumption Time: 2.71309
PPO Batch Consumption Time: 0.05896
Total Iteration Time: 16.32444

Cumulative Model Updates: 61,755
Cumulative Timesteps: 1,030,088,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943,715.46042
Policy Entropy: 1.07311
Value Function Loss: 1.75765

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.13007

Collected Steps per Second: 3,595.88884
Overall Steps per Second: 3,003.41386

Timestep Collection Time: 13.91033
Timestep Consumption Time: 2.74405
PPO Batch Consumption Time: 0.04971
Total Iteration Time: 16.65438

Cumulative Model Updates: 61,758
Cumulative Timesteps: 1,030,138,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1030138304...
Checkpoint 1030138304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092,605.64944
Policy Entropy: 1.06835
Value Function Loss: 1.84890

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.07156
Value Function Update Magnitude: 0.13907

Collected Steps per Second: 3,837.58498
Overall Steps per Second: 3,164.00814

Timestep Collection Time: 13.03737
Timestep Consumption Time: 2.77549
PPO Batch Consumption Time: 0.05403
Total Iteration Time: 15.81285

Cumulative Model Updates: 61,761
Cumulative Timesteps: 1,030,188,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018,403.31209
Policy Entropy: 1.07426
Value Function Loss: 1.86100

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.12380

Collected Steps per Second: 3,691.10998
Overall Steps per Second: 3,115.80115

Timestep Collection Time: 13.55310
Timestep Consumption Time: 2.50248
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 16.05558

Cumulative Model Updates: 61,764
Cumulative Timesteps: 1,030,238,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1030238362...
Checkpoint 1030238362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997,354.15692
Policy Entropy: 1.07518
Value Function Loss: 1.97604

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.17133
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.10821

Collected Steps per Second: 3,783.23408
Overall Steps per Second: 3,137.51139

Timestep Collection Time: 13.22678
Timestep Consumption Time: 2.72217
PPO Batch Consumption Time: 0.05424
Total Iteration Time: 15.94895

Cumulative Model Updates: 61,767
Cumulative Timesteps: 1,030,288,402

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179,919.49791
Policy Entropy: 1.05433
Value Function Loss: 1.94427

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.12859

Collected Steps per Second: 3,744.60332
Overall Steps per Second: 3,133.60297

Timestep Collection Time: 13.35255
Timestep Consumption Time: 2.60352
PPO Batch Consumption Time: 0.06276
Total Iteration Time: 15.95607

Cumulative Model Updates: 61,770
Cumulative Timesteps: 1,030,338,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1030338402...
Checkpoint 1030338402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585,907.83777
Policy Entropy: 1.06714
Value Function Loss: 1.95147

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.06363
Value Function Update Magnitude: 0.13871

Collected Steps per Second: 3,729.73817
Overall Steps per Second: 3,081.36467

Timestep Collection Time: 13.40791
Timestep Consumption Time: 2.82126
PPO Batch Consumption Time: 0.05950
Total Iteration Time: 16.22917

Cumulative Model Updates: 61,773
Cumulative Timesteps: 1,030,388,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558,585.95630
Policy Entropy: 1.07685
Value Function Loss: 1.87632

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.06480
Value Function Update Magnitude: 0.14083

Collected Steps per Second: 3,910.47288
Overall Steps per Second: 3,253.69957

Timestep Collection Time: 12.79487
Timestep Consumption Time: 2.58270
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 15.37757

Cumulative Model Updates: 61,776
Cumulative Timesteps: 1,030,438,444

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1030438444...
Checkpoint 1030438444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,681,884.58361
Policy Entropy: 1.08471
Value Function Loss: 1.91027

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.11681

Collected Steps per Second: 3,836.88346
Overall Steps per Second: 3,232.70776

Timestep Collection Time: 13.03766
Timestep Consumption Time: 2.43667
PPO Batch Consumption Time: 0.06597
Total Iteration Time: 15.47433

Cumulative Model Updates: 61,779
Cumulative Timesteps: 1,030,488,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544,960.54056
Policy Entropy: 1.06396
Value Function Loss: 1.90900

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.06260
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 3,736.64672
Overall Steps per Second: 3,171.39070

Timestep Collection Time: 13.39169
Timestep Consumption Time: 2.38688
PPO Batch Consumption Time: 0.05165
Total Iteration Time: 15.77857

Cumulative Model Updates: 61,782
Cumulative Timesteps: 1,030,538,508

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1030538508...
Checkpoint 1030538508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552,280.59653
Policy Entropy: 1.06826
Value Function Loss: 1.97144

Mean KL Divergence: 0.02291
SB3 Clip Fraction: 0.16385
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 4,018.36718
Overall Steps per Second: 3,318.29108

Timestep Collection Time: 12.44535
Timestep Consumption Time: 2.62566
PPO Batch Consumption Time: 0.05136
Total Iteration Time: 15.07101

Cumulative Model Updates: 61,785
Cumulative Timesteps: 1,030,588,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,315.25521
Policy Entropy: 1.07285
Value Function Loss: 1.90056

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.16219
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.10785

Collected Steps per Second: 3,851.02465
Overall Steps per Second: 3,207.92746

Timestep Collection Time: 12.99446
Timestep Consumption Time: 2.60502
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 15.59948

Cumulative Model Updates: 61,788
Cumulative Timesteps: 1,030,638,560

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1030638560...
Checkpoint 1030638560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670,211.66050
Policy Entropy: 1.06089
Value Function Loss: 1.94479

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.10431

Collected Steps per Second: 3,896.99367
Overall Steps per Second: 3,232.24893

Timestep Collection Time: 12.84015
Timestep Consumption Time: 2.64071
PPO Batch Consumption Time: 0.05802
Total Iteration Time: 15.48086

Cumulative Model Updates: 61,791
Cumulative Timesteps: 1,030,688,598

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753,861.00188
Policy Entropy: 1.06021
Value Function Loss: 1.82488

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.15982
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.09787

Collected Steps per Second: 3,774.75165
Overall Steps per Second: 3,111.51447

Timestep Collection Time: 13.25120
Timestep Consumption Time: 2.82457
PPO Batch Consumption Time: 0.05380
Total Iteration Time: 16.07577

Cumulative Model Updates: 61,794
Cumulative Timesteps: 1,030,738,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1030738618...
Checkpoint 1030738618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604,788.05817
Policy Entropy: 1.07522
Value Function Loss: 1.85327

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.09309

Collected Steps per Second: 4,061.52792
Overall Steps per Second: 3,352.85721

Timestep Collection Time: 12.31408
Timestep Consumption Time: 2.60274
PPO Batch Consumption Time: 0.04908
Total Iteration Time: 14.91683

Cumulative Model Updates: 61,797
Cumulative Timesteps: 1,030,788,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,190,388.62896
Policy Entropy: 1.08557
Value Function Loss: 1.76203

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.09093

Collected Steps per Second: 4,295.91729
Overall Steps per Second: 3,508.80646

Timestep Collection Time: 11.64454
Timestep Consumption Time: 2.61216
PPO Batch Consumption Time: 0.05391
Total Iteration Time: 14.25670

Cumulative Model Updates: 61,800
Cumulative Timesteps: 1,030,838,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1030838656...
Checkpoint 1030838656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852,302.23786
Policy Entropy: 1.06321
Value Function Loss: 1.82383

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.10866

Collected Steps per Second: 3,997.10754
Overall Steps per Second: 3,336.19450

Timestep Collection Time: 12.51905
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.05273
Total Iteration Time: 14.99913

Cumulative Model Updates: 61,803
Cumulative Timesteps: 1,030,888,696

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,915,627.97937
Policy Entropy: 1.06109
Value Function Loss: 1.79422

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.09737

Collected Steps per Second: 3,919.32095
Overall Steps per Second: 3,264.93245

Timestep Collection Time: 12.76139
Timestep Consumption Time: 2.55776
PPO Batch Consumption Time: 0.05877
Total Iteration Time: 15.31915

Cumulative Model Updates: 61,806
Cumulative Timesteps: 1,030,938,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1030938712...
Checkpoint 1030938712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619,185.54448
Policy Entropy: 1.06749
Value Function Loss: 1.83441

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.10129

Collected Steps per Second: 3,861.65558
Overall Steps per Second: 3,166.49559

Timestep Collection Time: 12.96128
Timestep Consumption Time: 2.84547
PPO Batch Consumption Time: 0.06296
Total Iteration Time: 15.80675

Cumulative Model Updates: 61,809
Cumulative Timesteps: 1,030,988,764

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,944,896.72242
Policy Entropy: 1.07890
Value Function Loss: 1.82431

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.10089

Collected Steps per Second: 3,757.69625
Overall Steps per Second: 3,104.03722

Timestep Collection Time: 13.31614
Timestep Consumption Time: 2.80416
PPO Batch Consumption Time: 0.06587
Total Iteration Time: 16.12030

Cumulative Model Updates: 61,812
Cumulative Timesteps: 1,031,038,802

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1031038802...
Checkpoint 1031038802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834,163.47084
Policy Entropy: 1.05888
Value Function Loss: 1.85937

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.09849

Collected Steps per Second: 3,710.16700
Overall Steps per Second: 3,106.60708

Timestep Collection Time: 13.48726
Timestep Consumption Time: 2.62034
PPO Batch Consumption Time: 0.05096
Total Iteration Time: 16.10761

Cumulative Model Updates: 61,815
Cumulative Timesteps: 1,031,088,842

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523,547.31233
Policy Entropy: 1.05141
Value Function Loss: 1.90310

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.15608
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.09288

Collected Steps per Second: 3,768.51799
Overall Steps per Second: 3,116.91222

Timestep Collection Time: 13.27153
Timestep Consumption Time: 2.77448
PPO Batch Consumption Time: 0.06361
Total Iteration Time: 16.04601

Cumulative Model Updates: 61,818
Cumulative Timesteps: 1,031,138,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1031138856...
Checkpoint 1031138856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979,271.94758
Policy Entropy: 1.06730
Value Function Loss: 1.90933

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.09858

Collected Steps per Second: 3,853.85182
Overall Steps per Second: 3,184.76974

Timestep Collection Time: 12.97559
Timestep Consumption Time: 2.72602
PPO Batch Consumption Time: 0.06168
Total Iteration Time: 15.70161

Cumulative Model Updates: 61,821
Cumulative Timesteps: 1,031,188,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338,235.59884
Policy Entropy: 1.08143
Value Function Loss: 1.91992

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.09453

Collected Steps per Second: 3,786.55530
Overall Steps per Second: 3,156.38922

Timestep Collection Time: 13.21201
Timestep Consumption Time: 2.63775
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 15.84976

Cumulative Model Updates: 61,824
Cumulative Timesteps: 1,031,238,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1031238890...
Checkpoint 1031238890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,121,667.53644
Policy Entropy: 1.06872
Value Function Loss: 1.83227

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.05876
Value Function Update Magnitude: 0.09435

Collected Steps per Second: 3,821.36977
Overall Steps per Second: 3,207.89391

Timestep Collection Time: 13.09373
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 15.59777

Cumulative Model Updates: 61,827
Cumulative Timesteps: 1,031,288,926

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499,873.04963
Policy Entropy: 1.06228
Value Function Loss: 1.75373

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.16089
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.09073

Collected Steps per Second: 3,988.15200
Overall Steps per Second: 3,320.49995

Timestep Collection Time: 12.54416
Timestep Consumption Time: 2.52225
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 15.06641

Cumulative Model Updates: 61,830
Cumulative Timesteps: 1,031,338,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1031338954...
Checkpoint 1031338954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716,095.09303
Policy Entropy: 1.06842
Value Function Loss: 1.79985

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.09417

Collected Steps per Second: 4,007.29150
Overall Steps per Second: 3,321.73536

Timestep Collection Time: 12.47875
Timestep Consumption Time: 2.57543
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 15.05418

Cumulative Model Updates: 61,833
Cumulative Timesteps: 1,031,388,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496,082.98277
Policy Entropy: 1.08198
Value Function Loss: 1.87215

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.09727

Collected Steps per Second: 3,987.21419
Overall Steps per Second: 3,310.55346

Timestep Collection Time: 12.54209
Timestep Consumption Time: 2.56354
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 15.10563

Cumulative Model Updates: 61,836
Cumulative Timesteps: 1,031,438,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1031438968...
Checkpoint 1031438968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428,405.22027
Policy Entropy: 1.06271
Value Function Loss: 1.97290

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.09085

Collected Steps per Second: 4,034.66980
Overall Steps per Second: 3,338.53856

Timestep Collection Time: 12.39804
Timestep Consumption Time: 2.58516
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 14.98320

Cumulative Model Updates: 61,839
Cumulative Timesteps: 1,031,488,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215,055.16827
Policy Entropy: 1.04205
Value Function Loss: 1.94242

Mean KL Divergence: 0.02620
SB3 Clip Fraction: 0.19454
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.10952

Collected Steps per Second: 3,815.17057
Overall Steps per Second: 3,169.17342

Timestep Collection Time: 13.11606
Timestep Consumption Time: 2.67355
PPO Batch Consumption Time: 0.05264
Total Iteration Time: 15.78961

Cumulative Model Updates: 61,842
Cumulative Timesteps: 1,031,539,030

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1031539030...
Checkpoint 1031539030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871,791.05333
Policy Entropy: 1.06586
Value Function Loss: 1.87721

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.13522

Collected Steps per Second: 3,787.07087
Overall Steps per Second: 3,143.62029

Timestep Collection Time: 13.21391
Timestep Consumption Time: 2.70468
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 15.91859

Cumulative Model Updates: 61,845
Cumulative Timesteps: 1,031,589,072

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454,648.61093
Policy Entropy: 1.06379
Value Function Loss: 1.80764

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.14285

Collected Steps per Second: 3,784.02526
Overall Steps per Second: 3,121.90657

Timestep Collection Time: 13.22666
Timestep Consumption Time: 2.80521
PPO Batch Consumption Time: 0.06046
Total Iteration Time: 16.03187

Cumulative Model Updates: 61,848
Cumulative Timesteps: 1,031,639,122

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1031639122...
Checkpoint 1031639122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505,726.36024
Policy Entropy: 1.06254
Value Function Loss: 1.77160

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.08574
Value Function Update Magnitude: 0.12481

Collected Steps per Second: 3,886.16469
Overall Steps per Second: 3,212.58280

Timestep Collection Time: 12.86821
Timestep Consumption Time: 2.69808
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 15.56629

Cumulative Model Updates: 61,851
Cumulative Timesteps: 1,031,689,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363,193.23664
Policy Entropy: 1.06127
Value Function Loss: 1.74731

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.08330
Value Function Update Magnitude: 0.10834

Collected Steps per Second: 3,879.65898
Overall Steps per Second: 3,229.48646

Timestep Collection Time: 12.89546
Timestep Consumption Time: 2.59616
PPO Batch Consumption Time: 0.06120
Total Iteration Time: 15.49163

Cumulative Model Updates: 61,854
Cumulative Timesteps: 1,031,739,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1031739160...
Checkpoint 1031739160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562,719.33783
Policy Entropy: 1.07662
Value Function Loss: 1.69997

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.07422
Value Function Update Magnitude: 0.10090

Collected Steps per Second: 3,713.06110
Overall Steps per Second: 3,091.68054

Timestep Collection Time: 13.47783
Timestep Consumption Time: 2.70884
PPO Batch Consumption Time: 0.05054
Total Iteration Time: 16.18667

Cumulative Model Updates: 61,857
Cumulative Timesteps: 1,031,789,204

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261,537.51158
Policy Entropy: 1.08160
Value Function Loss: 1.63940

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.07134
Value Function Update Magnitude: 0.09129

Collected Steps per Second: 3,779.35901
Overall Steps per Second: 3,173.73497

Timestep Collection Time: 13.23240
Timestep Consumption Time: 2.52506
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 15.75746

Cumulative Model Updates: 61,860
Cumulative Timesteps: 1,031,839,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1031839214...
Checkpoint 1031839214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422,170.10319
Policy Entropy: 1.07153
Value Function Loss: 1.72638

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.07427
Value Function Update Magnitude: 0.08972

Collected Steps per Second: 3,851.10927
Overall Steps per Second: 3,239.95991

Timestep Collection Time: 12.98483
Timestep Consumption Time: 2.44931
PPO Batch Consumption Time: 0.06485
Total Iteration Time: 15.43414

Cumulative Model Updates: 61,863
Cumulative Timesteps: 1,031,889,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623,730.81337
Policy Entropy: 1.06361
Value Function Loss: 1.76418

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.15935
Policy Update Magnitude: 0.07413
Value Function Update Magnitude: 0.10636

Collected Steps per Second: 3,777.65816
Overall Steps per Second: 3,203.39522

Timestep Collection Time: 13.23942
Timestep Consumption Time: 2.37339
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 15.61281

Cumulative Model Updates: 61,866
Cumulative Timesteps: 1,031,939,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1031939234...
Checkpoint 1031939234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220,779.42472
Policy Entropy: 1.07236
Value Function Loss: 1.89023

Mean KL Divergence: 0.02415
SB3 Clip Fraction: 0.16027
Policy Update Magnitude: 0.06572
Value Function Update Magnitude: 0.11207

Collected Steps per Second: 3,664.20068
Overall Steps per Second: 3,062.89873

Timestep Collection Time: 13.65755
Timestep Consumption Time: 2.68122
PPO Batch Consumption Time: 0.05342
Total Iteration Time: 16.33877

Cumulative Model Updates: 61,869
Cumulative Timesteps: 1,031,989,278

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230,769.79593
Policy Entropy: 1.07968
Value Function Loss: 1.86421

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.17723
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 3,871.66828
Overall Steps per Second: 3,207.30510

Timestep Collection Time: 12.91846
Timestep Consumption Time: 2.67594
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 15.59440

Cumulative Model Updates: 61,872
Cumulative Timesteps: 1,032,039,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1032039294...
Checkpoint 1032039294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643,200.28780
Policy Entropy: 1.06948
Value Function Loss: 1.78226

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.11396

Collected Steps per Second: 3,695.36235
Overall Steps per Second: 3,074.96059

Timestep Collection Time: 13.53697
Timestep Consumption Time: 2.73121
PPO Batch Consumption Time: 0.06223
Total Iteration Time: 16.26818

Cumulative Model Updates: 61,875
Cumulative Timesteps: 1,032,089,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503,980.52460
Policy Entropy: 1.06719
Value Function Loss: 1.66432

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.15334
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.13521

Collected Steps per Second: 3,863.91644
Overall Steps per Second: 3,211.50731

Timestep Collection Time: 12.94386
Timestep Consumption Time: 2.62951
PPO Batch Consumption Time: 0.05092
Total Iteration Time: 15.57337

Cumulative Model Updates: 61,878
Cumulative Timesteps: 1,032,139,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1032139332...
Checkpoint 1032139332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562,165.64329
Policy Entropy: 1.07711
Value Function Loss: 1.65640

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.13595

Collected Steps per Second: 3,934.69102
Overall Steps per Second: 3,258.04293

Timestep Collection Time: 12.71561
Timestep Consumption Time: 2.64085
PPO Batch Consumption Time: 0.05802
Total Iteration Time: 15.35646

Cumulative Model Updates: 61,881
Cumulative Timesteps: 1,032,189,364

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413,734.52882
Policy Entropy: 1.08503
Value Function Loss: 1.77621

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.14048

Collected Steps per Second: 3,823.45096
Overall Steps per Second: 3,181.43397

Timestep Collection Time: 13.08608
Timestep Consumption Time: 2.64079
PPO Batch Consumption Time: 0.05380
Total Iteration Time: 15.72687

Cumulative Model Updates: 61,884
Cumulative Timesteps: 1,032,239,398

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1032239398...
Checkpoint 1032239398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390,686.61845
Policy Entropy: 1.06491
Value Function Loss: 1.92177

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.15134
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.12490

Collected Steps per Second: 3,839.30157
Overall Steps per Second: 3,205.86521

Timestep Collection Time: 13.02633
Timestep Consumption Time: 2.57383
PPO Batch Consumption Time: 0.05885
Total Iteration Time: 15.60016

Cumulative Model Updates: 61,887
Cumulative Timesteps: 1,032,289,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321,847.23961
Policy Entropy: 1.08749
Value Function Loss: 1.92756

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.17001
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.12353

Collected Steps per Second: 3,694.12372
Overall Steps per Second: 3,140.61266

Timestep Collection Time: 13.54854
Timestep Consumption Time: 2.38784
PPO Batch Consumption Time: 0.04910
Total Iteration Time: 15.93638

Cumulative Model Updates: 61,890
Cumulative Timesteps: 1,032,339,460

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1032339460...
Checkpoint 1032339460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,442,531.53103
Policy Entropy: 1.07837
Value Function Loss: 1.82046

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.15965
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.11601

Collected Steps per Second: 3,854.30529
Overall Steps per Second: 3,254.03524

Timestep Collection Time: 12.98081
Timestep Consumption Time: 2.39456
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 15.37537

Cumulative Model Updates: 61,893
Cumulative Timesteps: 1,032,389,492

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478,059.76939
Policy Entropy: 1.07507
Value Function Loss: 1.69504

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.06611
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 3,781.05497
Overall Steps per Second: 3,161.08506

Timestep Collection Time: 13.22911
Timestep Consumption Time: 2.59457
PPO Batch Consumption Time: 0.05286
Total Iteration Time: 15.82368

Cumulative Model Updates: 61,896
Cumulative Timesteps: 1,032,439,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1032439512...
Checkpoint 1032439512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575,418.39858
Policy Entropy: 1.05371
Value Function Loss: 1.67096

Mean KL Divergence: 0.03928
SB3 Clip Fraction: 0.20716
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.13732

Collected Steps per Second: 3,894.40484
Overall Steps per Second: 3,210.09759

Timestep Collection Time: 12.83996
Timestep Consumption Time: 2.73714
PPO Batch Consumption Time: 0.06057
Total Iteration Time: 15.57710

Cumulative Model Updates: 61,899
Cumulative Timesteps: 1,032,489,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,944,411.90159
Policy Entropy: 1.07944
Value Function Loss: 1.71301

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.16741
Policy Update Magnitude: 0.06447
Value Function Update Magnitude: 0.14998

Collected Steps per Second: 3,758.53112
Overall Steps per Second: 3,121.24974

Timestep Collection Time: 13.30786
Timestep Consumption Time: 2.71713
PPO Batch Consumption Time: 0.06274
Total Iteration Time: 16.02499

Cumulative Model Updates: 61,902
Cumulative Timesteps: 1,032,539,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1032539534...
Checkpoint 1032539534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752,192.09605
Policy Entropy: 1.05428
Value Function Loss: 1.72455

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.15546
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.14475

Collected Steps per Second: 3,735.88894
Overall Steps per Second: 3,078.74516

Timestep Collection Time: 13.39387
Timestep Consumption Time: 2.85886
PPO Batch Consumption Time: 0.06156
Total Iteration Time: 16.25273

Cumulative Model Updates: 61,905
Cumulative Timesteps: 1,032,589,572

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578,892.77191
Policy Entropy: 1.07255
Value Function Loss: 1.74013

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.15435
Policy Update Magnitude: 0.06135
Value Function Update Magnitude: 0.15121

Collected Steps per Second: 3,730.19991
Overall Steps per Second: 3,121.22660

Timestep Collection Time: 13.40947
Timestep Consumption Time: 2.61628
PPO Batch Consumption Time: 0.04912
Total Iteration Time: 16.02575

Cumulative Model Updates: 61,908
Cumulative Timesteps: 1,032,639,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1032639592...
Checkpoint 1032639592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346,944.09309
Policy Entropy: 1.08345
Value Function Loss: 1.77824

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.15456
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.13628

Collected Steps per Second: 3,929.31978
Overall Steps per Second: 3,268.31824

Timestep Collection Time: 12.73147
Timestep Consumption Time: 2.57488
PPO Batch Consumption Time: 0.05883
Total Iteration Time: 15.30634

Cumulative Model Updates: 61,911
Cumulative Timesteps: 1,032,689,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673,567.00798
Policy Entropy: 1.07131
Value Function Loss: 1.71223

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.13590

Collected Steps per Second: 3,766.95172
Overall Steps per Second: 3,168.13340

Timestep Collection Time: 13.28130
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.05068
Total Iteration Time: 15.79163

Cumulative Model Updates: 61,914
Cumulative Timesteps: 1,032,739,648

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1032739648...
Checkpoint 1032739648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179,581.28716
Policy Entropy: 1.06727
Value Function Loss: 1.73077

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.12729

Collected Steps per Second: 3,864.07593
Overall Steps per Second: 3,226.18079

Timestep Collection Time: 12.94488
Timestep Consumption Time: 2.55952
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 15.50440

Cumulative Model Updates: 61,917
Cumulative Timesteps: 1,032,789,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648,051.30102
Policy Entropy: 1.07700
Value Function Loss: 1.79019

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.11238

Collected Steps per Second: 3,924.69169
Overall Steps per Second: 3,313.35735

Timestep Collection Time: 12.74291
Timestep Consumption Time: 2.35114
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 15.09406

Cumulative Model Updates: 61,920
Cumulative Timesteps: 1,032,839,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1032839680...
Checkpoint 1032839680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572,082.97179
Policy Entropy: 1.07654
Value Function Loss: 1.81836

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.10743

Collected Steps per Second: 3,875.85055
Overall Steps per Second: 3,262.88770

Timestep Collection Time: 12.91020
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.05764
Total Iteration Time: 15.33550

Cumulative Model Updates: 61,923
Cumulative Timesteps: 1,032,889,718

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288,449.46522
Policy Entropy: 1.06162
Value Function Loss: 1.81325

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.10292

Collected Steps per Second: 3,875.14032
Overall Steps per Second: 3,285.28367

Timestep Collection Time: 12.90947
Timestep Consumption Time: 2.31783
PPO Batch Consumption Time: 0.04906
Total Iteration Time: 15.22730

Cumulative Model Updates: 61,926
Cumulative Timesteps: 1,032,939,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1032939744...
Checkpoint 1032939744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023,317.44908
Policy Entropy: 1.05172
Value Function Loss: 1.83993

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.16847
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.10480

Collected Steps per Second: 3,748.20434
Overall Steps per Second: 3,110.79785

Timestep Collection Time: 13.35199
Timestep Consumption Time: 2.73584
PPO Batch Consumption Time: 0.04705
Total Iteration Time: 16.08783

Cumulative Model Updates: 61,929
Cumulative Timesteps: 1,032,989,790

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390,623.06062
Policy Entropy: 1.06163
Value Function Loss: 1.88186

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.12002

Collected Steps per Second: 3,775.18065
Overall Steps per Second: 3,127.59200

Timestep Collection Time: 13.24917
Timestep Consumption Time: 2.74333
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 15.99250

Cumulative Model Updates: 61,932
Cumulative Timesteps: 1,033,039,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1033039808...
Checkpoint 1033039808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418,484.62913
Policy Entropy: 1.07215
Value Function Loss: 1.93969

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.16310
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.12414

Collected Steps per Second: 3,798.70913
Overall Steps per Second: 3,103.47650

Timestep Collection Time: 13.17448
Timestep Consumption Time: 2.95131
PPO Batch Consumption Time: 0.06784
Total Iteration Time: 16.12579

Cumulative Model Updates: 61,935
Cumulative Timesteps: 1,033,089,854

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852,621.18435
Policy Entropy: 1.05160
Value Function Loss: 1.91499

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.11373

Collected Steps per Second: 3,725.90989
Overall Steps per Second: 3,079.87869

Timestep Collection Time: 13.42974
Timestep Consumption Time: 2.81700
PPO Batch Consumption Time: 0.05164
Total Iteration Time: 16.24674

Cumulative Model Updates: 61,938
Cumulative Timesteps: 1,033,139,892

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1033139892...
Checkpoint 1033139892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686,847.36372
Policy Entropy: 1.07026
Value Function Loss: 2.04257

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.10128

Collected Steps per Second: 3,784.58249
Overall Steps per Second: 3,162.74808

Timestep Collection Time: 13.21467
Timestep Consumption Time: 2.59816
PPO Batch Consumption Time: 0.05081
Total Iteration Time: 15.81283

Cumulative Model Updates: 61,941
Cumulative Timesteps: 1,033,189,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684,235.31318
Policy Entropy: 1.07770
Value Function Loss: 1.96400

Mean KL Divergence: 0.02701
SB3 Clip Fraction: 0.17813
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.09838

Collected Steps per Second: 3,897.25800
Overall Steps per Second: 3,248.90786

Timestep Collection Time: 12.83159
Timestep Consumption Time: 2.56066
PPO Batch Consumption Time: 0.05097
Total Iteration Time: 15.39225

Cumulative Model Updates: 61,944
Cumulative Timesteps: 1,033,239,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1033239912...
Checkpoint 1033239912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334,629.54956
Policy Entropy: 1.05915
Value Function Loss: 1.88407

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 3,882.75161
Overall Steps per Second: 3,280.39485

Timestep Collection Time: 12.88571
Timestep Consumption Time: 2.36612
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 15.25182

Cumulative Model Updates: 61,947
Cumulative Timesteps: 1,033,289,944

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135,844.63538
Policy Entropy: 1.06370
Value Function Loss: 1.73917

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.15577
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 3,655.39214
Overall Steps per Second: 3,077.97741

Timestep Collection Time: 13.68389
Timestep Consumption Time: 2.56704
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 16.25093

Cumulative Model Updates: 61,950
Cumulative Timesteps: 1,033,339,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1033339964...
Checkpoint 1033339964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423,531.82716
Policy Entropy: 1.06794
Value Function Loss: 1.81110

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.06262
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 3,685.72315
Overall Steps per Second: 3,123.22833

Timestep Collection Time: 13.56857
Timestep Consumption Time: 2.44371
PPO Batch Consumption Time: 0.06938
Total Iteration Time: 16.01228

Cumulative Model Updates: 61,953
Cumulative Timesteps: 1,033,389,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660,931.44438
Policy Entropy: 1.05221
Value Function Loss: 1.84968

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.09914

Collected Steps per Second: 3,925.85506
Overall Steps per Second: 3,242.12137

Timestep Collection Time: 12.73914
Timestep Consumption Time: 2.68657
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 15.42570

Cumulative Model Updates: 61,956
Cumulative Timesteps: 1,033,439,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1033439986...
Checkpoint 1033439986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,333,658.82763
Policy Entropy: 1.05415
Value Function Loss: 1.92725

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.15684
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.09886

Collected Steps per Second: 3,794.12976
Overall Steps per Second: 3,155.64185

Timestep Collection Time: 13.19038
Timestep Consumption Time: 2.66884
PPO Batch Consumption Time: 0.04885
Total Iteration Time: 15.85921

Cumulative Model Updates: 61,959
Cumulative Timesteps: 1,033,490,032

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337,440.46996
Policy Entropy: 1.06951
Value Function Loss: 1.89247

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.11518

Collected Steps per Second: 3,822.10262
Overall Steps per Second: 3,121.58966

Timestep Collection Time: 13.08547
Timestep Consumption Time: 2.93650
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 16.02196

Cumulative Model Updates: 61,962
Cumulative Timesteps: 1,033,540,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1033540046...
Checkpoint 1033540046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429,429.91338
Policy Entropy: 1.07810
Value Function Loss: 1.80276

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.11290

Collected Steps per Second: 3,854.74946
Overall Steps per Second: 3,178.39615

Timestep Collection Time: 12.97361
Timestep Consumption Time: 2.76074
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 15.73435

Cumulative Model Updates: 61,965
Cumulative Timesteps: 1,033,590,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123,429.04038
Policy Entropy: 1.06614
Value Function Loss: 1.71366

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.09864

Collected Steps per Second: 3,874.54116
Overall Steps per Second: 3,199.99396

Timestep Collection Time: 12.91250
Timestep Consumption Time: 2.72191
PPO Batch Consumption Time: 0.06484
Total Iteration Time: 15.63440

Cumulative Model Updates: 61,968
Cumulative Timesteps: 1,033,640,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1033640086...
Checkpoint 1033640086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680,987.95840
Policy Entropy: 1.05804
Value Function Loss: 1.70579

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.16687
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.08915

Collected Steps per Second: 3,737.03569
Overall Steps per Second: 3,158.58268

Timestep Collection Time: 13.38226
Timestep Consumption Time: 2.45079
PPO Batch Consumption Time: 0.06474
Total Iteration Time: 15.83305

Cumulative Model Updates: 61,971
Cumulative Timesteps: 1,033,690,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623,328.05908
Policy Entropy: 1.06486
Value Function Loss: 1.85534

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.09018

Collected Steps per Second: 3,735.19979
Overall Steps per Second: 3,153.49502

Timestep Collection Time: 13.39527
Timestep Consumption Time: 2.47094
PPO Batch Consumption Time: 0.06345
Total Iteration Time: 15.86621

Cumulative Model Updates: 61,974
Cumulative Timesteps: 1,033,740,130

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1033740130...
Checkpoint 1033740130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279,476.97602
Policy Entropy: 1.07578
Value Function Loss: 1.95542

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.15857
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 3,785.26639
Overall Steps per Second: 3,181.31673

Timestep Collection Time: 13.21915
Timestep Consumption Time: 2.50956
PPO Batch Consumption Time: 0.05424
Total Iteration Time: 15.72871

Cumulative Model Updates: 61,977
Cumulative Timesteps: 1,033,790,168

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678,644.03937
Policy Entropy: 1.04587
Value Function Loss: 1.94351

Mean KL Divergence: 0.03257
SB3 Clip Fraction: 0.17987
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.13105

Collected Steps per Second: 3,710.47876
Overall Steps per Second: 3,180.80468

Timestep Collection Time: 13.48613
Timestep Consumption Time: 2.24574
PPO Batch Consumption Time: 0.05285
Total Iteration Time: 15.73187

Cumulative Model Updates: 61,980
Cumulative Timesteps: 1,033,840,208

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1033840208...
Checkpoint 1033840208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464,542.60201
Policy Entropy: 1.06936
Value Function Loss: 1.95623

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.05217
Value Function Update Magnitude: 0.12764

Collected Steps per Second: 3,861.42058
Overall Steps per Second: 3,190.46337

Timestep Collection Time: 12.95482
Timestep Consumption Time: 2.72441
PPO Batch Consumption Time: 0.06152
Total Iteration Time: 15.67923

Cumulative Model Updates: 61,983
Cumulative Timesteps: 1,033,890,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999,126.91124
Policy Entropy: 1.07195
Value Function Loss: 1.98703

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.11541

Collected Steps per Second: 3,793.04599
Overall Steps per Second: 3,138.97008

Timestep Collection Time: 13.19204
Timestep Consumption Time: 2.74886
PPO Batch Consumption Time: 0.05995
Total Iteration Time: 15.94090

Cumulative Model Updates: 61,986
Cumulative Timesteps: 1,033,940,270

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1033940270...
Checkpoint 1033940270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878,667.97317
Policy Entropy: 1.06590
Value Function Loss: 1.97190

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.15056
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.12101

Collected Steps per Second: 3,649.23325
Overall Steps per Second: 3,053.76530

Timestep Collection Time: 13.70425
Timestep Consumption Time: 2.67226
PPO Batch Consumption Time: 0.05916
Total Iteration Time: 16.37650

Cumulative Model Updates: 61,989
Cumulative Timesteps: 1,033,990,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547,728.75868
Policy Entropy: 1.05484
Value Function Loss: 1.93511

Mean KL Divergence: 0.02938
SB3 Clip Fraction: 0.18197
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.12502

Collected Steps per Second: 3,686.77854
Overall Steps per Second: 3,097.07551

Timestep Collection Time: 13.56523
Timestep Consumption Time: 2.58291
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 16.14814

Cumulative Model Updates: 61,992
Cumulative Timesteps: 1,034,040,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1034040292...
Checkpoint 1034040292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570,315.33927
Policy Entropy: 1.07018
Value Function Loss: 1.80298

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.12463

Collected Steps per Second: 3,831.44426
Overall Steps per Second: 3,155.90981

Timestep Collection Time: 13.05983
Timestep Consumption Time: 2.79551
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 15.85533

Cumulative Model Updates: 61,995
Cumulative Timesteps: 1,034,090,330

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258,619.35464
Policy Entropy: 1.07565
Value Function Loss: 1.78680

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.06402
Value Function Update Magnitude: 0.13503

Collected Steps per Second: 3,838.24725
Overall Steps per Second: 3,212.52364

Timestep Collection Time: 13.03512
Timestep Consumption Time: 2.53893
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 15.57405

Cumulative Model Updates: 61,998
Cumulative Timesteps: 1,034,140,362

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1034140362...
Checkpoint 1034140362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923,221.99175
Policy Entropy: 1.06032
Value Function Loss: 1.81541

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.06537
Value Function Update Magnitude: 0.12867

Collected Steps per Second: 3,891.35836
Overall Steps per Second: 3,246.35437

Timestep Collection Time: 12.85721
Timestep Consumption Time: 2.55454
PPO Batch Consumption Time: 0.05294
Total Iteration Time: 15.41175

Cumulative Model Updates: 62,001
Cumulative Timesteps: 1,034,190,394

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509,928.13864
Policy Entropy: 1.06880
Value Function Loss: 1.86381

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.11822

Collected Steps per Second: 3,876.63521
Overall Steps per Second: 3,238.14505

Timestep Collection Time: 12.90294
Timestep Consumption Time: 2.54417
PPO Batch Consumption Time: 0.04811
Total Iteration Time: 15.44712

Cumulative Model Updates: 62,004
Cumulative Timesteps: 1,034,240,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1034240414...
Checkpoint 1034240414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459,365.27828
Policy Entropy: 1.06656
Value Function Loss: 1.80008

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.10649

Collected Steps per Second: 3,938.89570
Overall Steps per Second: 3,220.31134

Timestep Collection Time: 12.69950
Timestep Consumption Time: 2.83378
PPO Batch Consumption Time: 0.06442
Total Iteration Time: 15.53328

Cumulative Model Updates: 62,007
Cumulative Timesteps: 1,034,290,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438,242.17772
Policy Entropy: 1.07624
Value Function Loss: 1.65139

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.06971
Value Function Update Magnitude: 0.09128

Collected Steps per Second: 3,801.56141
Overall Steps per Second: 3,183.95223

Timestep Collection Time: 13.16091
Timestep Consumption Time: 2.55290
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 15.71380

Cumulative Model Updates: 62,010
Cumulative Timesteps: 1,034,340,468

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1034340468...
Checkpoint 1034340468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,949,055.57598
Policy Entropy: 1.07326
Value Function Loss: 1.67092

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.07172
Value Function Update Magnitude: 0.09407

Collected Steps per Second: 3,858.18158
Overall Steps per Second: 3,259.77774

Timestep Collection Time: 12.96932
Timestep Consumption Time: 2.38080
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 15.35013

Cumulative Model Updates: 62,013
Cumulative Timesteps: 1,034,390,506

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462,436.03000
Policy Entropy: 1.06525
Value Function Loss: 1.72887

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.15026
Policy Update Magnitude: 0.06992
Value Function Update Magnitude: 0.09356

Collected Steps per Second: 3,640.38173
Overall Steps per Second: 3,087.49258

Timestep Collection Time: 13.73757
Timestep Consumption Time: 2.46004
PPO Batch Consumption Time: 0.06365
Total Iteration Time: 16.19761

Cumulative Model Updates: 62,016
Cumulative Timesteps: 1,034,440,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1034440516...
Checkpoint 1034440516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869,111.12312
Policy Entropy: 1.07543
Value Function Loss: 1.82624

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.08509

Collected Steps per Second: 3,689.56069
Overall Steps per Second: 3,116.04763

Timestep Collection Time: 13.56259
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 16.05880

Cumulative Model Updates: 62,019
Cumulative Timesteps: 1,034,490,556

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801,623.73187
Policy Entropy: 1.07320
Value Function Loss: 1.80646

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.15716
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.09251

Collected Steps per Second: 3,739.74601
Overall Steps per Second: 3,105.87657

Timestep Collection Time: 13.37203
Timestep Consumption Time: 2.72906
PPO Batch Consumption Time: 0.05808
Total Iteration Time: 16.10109

Cumulative Model Updates: 62,022
Cumulative Timesteps: 1,034,540,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1034540564...
Checkpoint 1034540564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689,271.69785
Policy Entropy: 1.06397
Value Function Loss: 1.71283

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.09772

Collected Steps per Second: 3,842.83474
Overall Steps per Second: 3,160.14269

Timestep Collection Time: 13.01383
Timestep Consumption Time: 2.81140
PPO Batch Consumption Time: 0.06680
Total Iteration Time: 15.82523

Cumulative Model Updates: 62,025
Cumulative Timesteps: 1,034,590,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649,818.08361
Policy Entropy: 1.05132
Value Function Loss: 1.75255

Mean KL Divergence: 0.02366
SB3 Clip Fraction: 0.17164
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.09554

Collected Steps per Second: 3,859.46341
Overall Steps per Second: 3,198.14781

Timestep Collection Time: 12.96087
Timestep Consumption Time: 2.68006
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 15.64093

Cumulative Model Updates: 62,028
Cumulative Timesteps: 1,034,640,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1034640596...
Checkpoint 1034640596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586,836.89804
Policy Entropy: 1.06001
Value Function Loss: 1.80142

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.10802

Collected Steps per Second: 3,847.26794
Overall Steps per Second: 3,180.19463

Timestep Collection Time: 13.00195
Timestep Consumption Time: 2.72727
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 15.72923

Cumulative Model Updates: 62,031
Cumulative Timesteps: 1,034,690,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468,400.54770
Policy Entropy: 1.06862
Value Function Loss: 1.93145

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.06383
Value Function Update Magnitude: 0.12325

Collected Steps per Second: 3,815.73801
Overall Steps per Second: 3,171.30622

Timestep Collection Time: 13.10834
Timestep Consumption Time: 2.66371
PPO Batch Consumption Time: 0.06030
Total Iteration Time: 15.77205

Cumulative Model Updates: 62,034
Cumulative Timesteps: 1,034,740,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1034740636...
Checkpoint 1034740636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358,948.98306
Policy Entropy: 1.06112
Value Function Loss: 1.91942

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.07693
Value Function Update Magnitude: 0.11140

Collected Steps per Second: 3,807.96688
Overall Steps per Second: 3,184.89219

Timestep Collection Time: 13.13404
Timestep Consumption Time: 2.56947
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 15.70351

Cumulative Model Updates: 62,037
Cumulative Timesteps: 1,034,790,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691,633.82728
Policy Entropy: 1.06074
Value Function Loss: 1.91819

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.07647
Value Function Update Magnitude: 0.13008

Collected Steps per Second: 3,965.27854
Overall Steps per Second: 3,286.80889

Timestep Collection Time: 12.61551
Timestep Consumption Time: 2.60412
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 15.21963

Cumulative Model Updates: 62,040
Cumulative Timesteps: 1,034,840,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1034840674...
Checkpoint 1034840674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665,341.56500
Policy Entropy: 1.06087
Value Function Loss: 1.78786

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.06850
Value Function Update Magnitude: 0.13641

Collected Steps per Second: 3,842.97395
Overall Steps per Second: 3,180.81239

Timestep Collection Time: 13.01700
Timestep Consumption Time: 2.70980
PPO Batch Consumption Time: 0.06254
Total Iteration Time: 15.72680

Cumulative Model Updates: 62,043
Cumulative Timesteps: 1,034,890,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481,095.58801
Policy Entropy: 1.07753
Value Function Loss: 1.75257

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.07521
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 3,712.20671
Overall Steps per Second: 3,181.04758

Timestep Collection Time: 13.46962
Timestep Consumption Time: 2.24910
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 15.71872

Cumulative Model Updates: 62,046
Cumulative Timesteps: 1,034,940,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1034940700...
Checkpoint 1034940700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633,973.03978
Policy Entropy: 1.07933
Value Function Loss: 1.74442

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.08222
Value Function Update Magnitude: 0.10030

Collected Steps per Second: 3,822.69281
Overall Steps per Second: 3,213.12956

Timestep Collection Time: 13.08554
Timestep Consumption Time: 2.48246
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 15.56800

Cumulative Model Updates: 62,049
Cumulative Timesteps: 1,034,990,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456,424.41319
Policy Entropy: 1.07770
Value Function Loss: 1.77036

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.08031
Value Function Update Magnitude: 0.10321

Collected Steps per Second: 3,833.23840
Overall Steps per Second: 3,147.12080

Timestep Collection Time: 13.04380
Timestep Consumption Time: 2.84374
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 15.88754

Cumulative Model Updates: 62,052
Cumulative Timesteps: 1,035,040,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1035040722...
Checkpoint 1035040722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742,981.90042
Policy Entropy: 1.07896
Value Function Loss: 1.77245

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.08333
Value Function Update Magnitude: 0.11353

Collected Steps per Second: 3,807.00760
Overall Steps per Second: 3,159.56776

Timestep Collection Time: 13.14523
Timestep Consumption Time: 2.69364
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 15.83888

Cumulative Model Updates: 62,055
Cumulative Timesteps: 1,035,090,766

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478,932.81062
Policy Entropy: 1.07726
Value Function Loss: 1.69574

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.08949
Value Function Update Magnitude: 0.11389

Collected Steps per Second: 3,763.71045
Overall Steps per Second: 3,128.44788

Timestep Collection Time: 13.29326
Timestep Consumption Time: 2.69933
PPO Batch Consumption Time: 0.05310
Total Iteration Time: 15.99259

Cumulative Model Updates: 62,058
Cumulative Timesteps: 1,035,140,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1035140798...
Checkpoint 1035140798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486,993.26496
Policy Entropy: 1.07533
Value Function Loss: 1.74436

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.08394
Value Function Update Magnitude: 0.10523

Collected Steps per Second: 3,824.07575
Overall Steps per Second: 3,189.33557

Timestep Collection Time: 13.07610
Timestep Consumption Time: 2.60240
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 15.67850

Cumulative Model Updates: 62,061
Cumulative Timesteps: 1,035,190,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195,843.67422
Policy Entropy: 1.07138
Value Function Loss: 1.74137

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.08060
Value Function Update Magnitude: 0.10356

Collected Steps per Second: 3,795.61118
Overall Steps per Second: 3,162.33304

Timestep Collection Time: 13.18259
Timestep Consumption Time: 2.63990
PPO Batch Consumption Time: 0.05998
Total Iteration Time: 15.82250

Cumulative Model Updates: 62,064
Cumulative Timesteps: 1,035,240,838

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1035240838...
Checkpoint 1035240838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516,047.35103
Policy Entropy: 1.06670
Value Function Loss: 1.88435

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.07536
Value Function Update Magnitude: 0.09520

Collected Steps per Second: 3,921.22246
Overall Steps per Second: 3,248.94939

Timestep Collection Time: 12.76286
Timestep Consumption Time: 2.64089
PPO Batch Consumption Time: 0.05295
Total Iteration Time: 15.40375

Cumulative Model Updates: 62,067
Cumulative Timesteps: 1,035,290,884

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368,682.35309
Policy Entropy: 1.08328
Value Function Loss: 1.94599

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.15144
Policy Update Magnitude: 0.06526
Value Function Update Magnitude: 0.09540

Collected Steps per Second: 3,764.42262
Overall Steps per Second: 3,152.07642

Timestep Collection Time: 13.29075
Timestep Consumption Time: 2.58196
PPO Batch Consumption Time: 0.05432
Total Iteration Time: 15.87271

Cumulative Model Updates: 62,070
Cumulative Timesteps: 1,035,340,916

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1035340916...
Checkpoint 1035340916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196,451.58774
Policy Entropy: 1.08780
Value Function Loss: 1.95226

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.15191
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.10047

Collected Steps per Second: 3,640.89106
Overall Steps per Second: 3,072.86729

Timestep Collection Time: 13.73785
Timestep Consumption Time: 2.53946
PPO Batch Consumption Time: 0.05812
Total Iteration Time: 16.27731

Cumulative Model Updates: 62,073
Cumulative Timesteps: 1,035,390,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,524,334.83386
Policy Entropy: 1.07666
Value Function Loss: 1.88121

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.10192

Collected Steps per Second: 3,784.44175
Overall Steps per Second: 3,190.49558

Timestep Collection Time: 13.22361
Timestep Consumption Time: 2.46172
PPO Batch Consumption Time: 0.05187
Total Iteration Time: 15.68534

Cumulative Model Updates: 62,076
Cumulative Timesteps: 1,035,440,978

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1035440978...
Checkpoint 1035440978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408,873.39991
Policy Entropy: 1.07137
Value Function Loss: 1.87650

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.17336
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.10041

Collected Steps per Second: 3,750.47703
Overall Steps per Second: 3,163.98981

Timestep Collection Time: 13.33537
Timestep Consumption Time: 2.47189
PPO Batch Consumption Time: 0.05306
Total Iteration Time: 15.80726

Cumulative Model Updates: 62,079
Cumulative Timesteps: 1,035,490,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342,470.72414
Policy Entropy: 1.08655
Value Function Loss: 1.91001

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.11196
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.10505

Collected Steps per Second: 3,806.59031
Overall Steps per Second: 3,140.55741

Timestep Collection Time: 13.14720
Timestep Consumption Time: 2.78819
PPO Batch Consumption Time: 0.06041
Total Iteration Time: 15.93539

Cumulative Model Updates: 62,082
Cumulative Timesteps: 1,035,541,038

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1035541038...
Checkpoint 1035541038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496,814.89914
Policy Entropy: 1.08476
Value Function Loss: 1.92208

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.06902
Value Function Update Magnitude: 0.11050

Collected Steps per Second: 3,925.35928
Overall Steps per Second: 3,222.31234

Timestep Collection Time: 12.74176
Timestep Consumption Time: 2.78001
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 15.52177

Cumulative Model Updates: 62,085
Cumulative Timesteps: 1,035,591,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738,407.20922
Policy Entropy: 1.08505
Value Function Loss: 1.86092

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.07607
Value Function Update Magnitude: 0.11537

Collected Steps per Second: 3,845.11442
Overall Steps per Second: 3,171.36401

Timestep Collection Time: 13.00455
Timestep Consumption Time: 2.76279
PPO Batch Consumption Time: 0.05922
Total Iteration Time: 15.76735

Cumulative Model Updates: 62,088
Cumulative Timesteps: 1,035,641,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1035641058...
Checkpoint 1035641058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839,994.79412
Policy Entropy: 1.08288
Value Function Loss: 1.80455

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.12116
Policy Update Magnitude: 0.08065
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 3,672.86256
Overall Steps per Second: 3,044.83453

Timestep Collection Time: 13.61772
Timestep Consumption Time: 2.80879
PPO Batch Consumption Time: 0.06541
Total Iteration Time: 16.42651

Cumulative Model Updates: 62,091
Cumulative Timesteps: 1,035,691,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331,246.26559
Policy Entropy: 1.09199
Value Function Loss: 1.75404

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.07450
Value Function Update Magnitude: 0.13508

Collected Steps per Second: 4,026.72293
Overall Steps per Second: 3,305.67652

Timestep Collection Time: 12.42400
Timestep Consumption Time: 2.70997
PPO Batch Consumption Time: 0.05242
Total Iteration Time: 15.13397

Cumulative Model Updates: 62,094
Cumulative Timesteps: 1,035,741,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1035741102...
Checkpoint 1035741102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638,257.69274
Policy Entropy: 1.09782
Value Function Loss: 1.75332

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.06980
Value Function Update Magnitude: 0.14665

Collected Steps per Second: 4,010.75387
Overall Steps per Second: 3,304.29835

Timestep Collection Time: 12.47197
Timestep Consumption Time: 2.66649
PPO Batch Consumption Time: 0.04887
Total Iteration Time: 15.13846

Cumulative Model Updates: 62,097
Cumulative Timesteps: 1,035,791,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082,842.69572
Policy Entropy: 1.09359
Value Function Loss: 1.76363

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.07402
Value Function Update Magnitude: 0.13622

Collected Steps per Second: 4,194.50179
Overall Steps per Second: 3,463.26913

Timestep Collection Time: 11.92227
Timestep Consumption Time: 2.51726
PPO Batch Consumption Time: 0.05812
Total Iteration Time: 14.43954

Cumulative Model Updates: 62,100
Cumulative Timesteps: 1,035,841,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1035841132...
Checkpoint 1035841132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193,852.39742
Policy Entropy: 1.09000
Value Function Loss: 1.81444

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.07001
Value Function Update Magnitude: 0.12309

Collected Steps per Second: 4,090.83930
Overall Steps per Second: 3,344.70971

Timestep Collection Time: 12.23123
Timestep Consumption Time: 2.72851
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 14.95974

Cumulative Model Updates: 62,103
Cumulative Timesteps: 1,035,891,168

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,863,343.99683
Policy Entropy: 1.10468
Value Function Loss: 1.85737

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.12080

Collected Steps per Second: 3,831.94932
Overall Steps per Second: 3,192.76386

Timestep Collection Time: 13.05445
Timestep Consumption Time: 2.61348
PPO Batch Consumption Time: 0.05383
Total Iteration Time: 15.66793

Cumulative Model Updates: 62,106
Cumulative Timesteps: 1,035,941,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1035941192...
Checkpoint 1035941192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,460,643.13685
Policy Entropy: 1.11098
Value Function Loss: 1.83872

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.06174
Value Function Update Magnitude: 0.10519

Collected Steps per Second: 3,966.76160
Overall Steps per Second: 3,375.92835

Timestep Collection Time: 12.60726
Timestep Consumption Time: 2.20644
PPO Batch Consumption Time: 0.04829
Total Iteration Time: 14.81370

Cumulative Model Updates: 62,109
Cumulative Timesteps: 1,035,991,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623,983.88935
Policy Entropy: 1.10238
Value Function Loss: 1.81370

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.05972
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 3,736.53514
Overall Steps per Second: 3,188.69400

Timestep Collection Time: 13.39102
Timestep Consumption Time: 2.30068
PPO Batch Consumption Time: 0.06298
Total Iteration Time: 15.69169

Cumulative Model Updates: 62,112
Cumulative Timesteps: 1,036,041,238

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1036041238...
Checkpoint 1036041238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658,944.53725
Policy Entropy: 1.09671
Value Function Loss: 1.76920

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.12757

Collected Steps per Second: 3,697.05451
Overall Steps per Second: 3,151.52690

Timestep Collection Time: 13.52644
Timestep Consumption Time: 2.34142
PPO Batch Consumption Time: 0.05196
Total Iteration Time: 15.86786

Cumulative Model Updates: 62,115
Cumulative Timesteps: 1,036,091,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687,437.98015
Policy Entropy: 1.11312
Value Function Loss: 1.72702

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.12200

Collected Steps per Second: 3,889.83837
Overall Steps per Second: 3,202.01716

Timestep Collection Time: 12.86480
Timestep Consumption Time: 2.76347
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 15.62827

Cumulative Model Updates: 62,118
Cumulative Timesteps: 1,036,141,288

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1036141288...
Checkpoint 1036141288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174,360.60914
Policy Entropy: 1.11106
Value Function Loss: 1.73782

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.11126

Collected Steps per Second: 3,869.98000
Overall Steps per Second: 3,192.35724

Timestep Collection Time: 12.92358
Timestep Consumption Time: 2.74321
PPO Batch Consumption Time: 0.06783
Total Iteration Time: 15.66679

Cumulative Model Updates: 62,121
Cumulative Timesteps: 1,036,191,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538,461.39778
Policy Entropy: 1.10101
Value Function Loss: 1.74931

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.06726
Value Function Update Magnitude: 0.11390

Collected Steps per Second: 3,698.14812
Overall Steps per Second: 3,066.54735

Timestep Collection Time: 13.52839
Timestep Consumption Time: 2.78637
PPO Batch Consumption Time: 0.06284
Total Iteration Time: 16.31477

Cumulative Model Updates: 62,124
Cumulative Timesteps: 1,036,241,332

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1036241332...
Checkpoint 1036241332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612,439.89370
Policy Entropy: 1.08568
Value Function Loss: 1.78789

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.15377
Policy Update Magnitude: 0.06887
Value Function Update Magnitude: 0.12179

Collected Steps per Second: 3,899.85659
Overall Steps per Second: 3,233.64664

Timestep Collection Time: 12.82406
Timestep Consumption Time: 2.64207
PPO Batch Consumption Time: 0.04964
Total Iteration Time: 15.46613

Cumulative Model Updates: 62,127
Cumulative Timesteps: 1,036,291,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397,118.67401
Policy Entropy: 1.11082
Value Function Loss: 1.78437

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.13232

Collected Steps per Second: 3,666.38303
Overall Steps per Second: 3,078.45576

Timestep Collection Time: 13.64833
Timestep Consumption Time: 2.60657
PPO Batch Consumption Time: 0.05198
Total Iteration Time: 16.25490

Cumulative Model Updates: 62,130
Cumulative Timesteps: 1,036,341,384

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1036341384...
Checkpoint 1036341384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591,199.94854
Policy Entropy: 1.10461
Value Function Loss: 1.76258

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.07209
Value Function Update Magnitude: 0.15225

Collected Steps per Second: 4,004.43520
Overall Steps per Second: 3,303.69344

Timestep Collection Time: 12.49415
Timestep Consumption Time: 2.65012
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 15.14426

Cumulative Model Updates: 62,133
Cumulative Timesteps: 1,036,391,416

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368,987.02569
Policy Entropy: 1.10296
Value Function Loss: 1.76677

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.07534
Value Function Update Magnitude: 0.14684

Collected Steps per Second: 3,813.20037
Overall Steps per Second: 3,190.91330

Timestep Collection Time: 13.11444
Timestep Consumption Time: 2.55756
PPO Batch Consumption Time: 0.04945
Total Iteration Time: 15.67200

Cumulative Model Updates: 62,136
Cumulative Timesteps: 1,036,441,424

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1036441424...
Checkpoint 1036441424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178,507.31700
Policy Entropy: 1.08629
Value Function Loss: 1.74037

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.15361
Policy Update Magnitude: 0.07658
Value Function Update Magnitude: 0.14127

Collected Steps per Second: 3,935.48365
Overall Steps per Second: 3,279.78607

Timestep Collection Time: 12.71356
Timestep Consumption Time: 2.54171
PPO Batch Consumption Time: 0.05855
Total Iteration Time: 15.25526

Cumulative Model Updates: 62,139
Cumulative Timesteps: 1,036,491,458

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513,575.88175
Policy Entropy: 1.10248
Value Function Loss: 1.73184

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.06775
Value Function Update Magnitude: 0.13491

Collected Steps per Second: 3,749.10827
Overall Steps per Second: 3,163.16403

Timestep Collection Time: 13.34557
Timestep Consumption Time: 2.47213
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 15.81771

Cumulative Model Updates: 62,142
Cumulative Timesteps: 1,036,541,492

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1036541492...
Checkpoint 1036541492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446,308.98736
Policy Entropy: 1.10261
Value Function Loss: 1.77618

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.07135
Value Function Update Magnitude: 0.13139

Collected Steps per Second: 3,932.53000
Overall Steps per Second: 3,217.34912

Timestep Collection Time: 12.72107
Timestep Consumption Time: 2.82775
PPO Batch Consumption Time: 0.06090
Total Iteration Time: 15.54883

Cumulative Model Updates: 62,145
Cumulative Timesteps: 1,036,591,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278,270.39405
Policy Entropy: 1.09451
Value Function Loss: 1.81654

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.07295
Value Function Update Magnitude: 0.12502

Collected Steps per Second: 3,647.80806
Overall Steps per Second: 3,107.46905

Timestep Collection Time: 13.70960
Timestep Consumption Time: 2.38388
PPO Batch Consumption Time: 0.04688
Total Iteration Time: 16.09348

Cumulative Model Updates: 62,148
Cumulative Timesteps: 1,036,641,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1036641528...
Checkpoint 1036641528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618,923.15747
Policy Entropy: 1.09845
Value Function Loss: 1.77600

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.07155
Value Function Update Magnitude: 0.11754

Collected Steps per Second: 3,778.72116
Overall Steps per Second: 3,133.91950

Timestep Collection Time: 13.24046
Timestep Consumption Time: 2.72421
PPO Batch Consumption Time: 0.06607
Total Iteration Time: 15.96467

Cumulative Model Updates: 62,151
Cumulative Timesteps: 1,036,691,560

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623,104.44341
Policy Entropy: 1.10047
Value Function Loss: 1.77608

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.06882
Value Function Update Magnitude: 0.11336

Collected Steps per Second: 3,690.45101
Overall Steps per Second: 3,063.37972

Timestep Collection Time: 13.54956
Timestep Consumption Time: 2.77358
PPO Batch Consumption Time: 0.05384
Total Iteration Time: 16.32315

Cumulative Model Updates: 62,154
Cumulative Timesteps: 1,036,741,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1036741564...
Checkpoint 1036741564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351,344.04255
Policy Entropy: 1.10109
Value Function Loss: 1.74091

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.07535
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 3,739.93199
Overall Steps per Second: 3,103.77158

Timestep Collection Time: 13.37190
Timestep Consumption Time: 2.74075
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 16.11265

Cumulative Model Updates: 62,157
Cumulative Timesteps: 1,036,791,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355,820.73369
Policy Entropy: 1.10221
Value Function Loss: 1.72714

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.07774
Value Function Update Magnitude: 0.12746

Collected Steps per Second: 3,683.64464
Overall Steps per Second: 3,036.05424

Timestep Collection Time: 13.58654
Timestep Consumption Time: 2.89801
PPO Batch Consumption Time: 0.04985
Total Iteration Time: 16.48455

Cumulative Model Updates: 62,160
Cumulative Timesteps: 1,036,841,622

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1036841622...
Checkpoint 1036841622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237,053.85363
Policy Entropy: 1.10754
Value Function Loss: 1.71115

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.07631
Value Function Update Magnitude: 0.12190

Collected Steps per Second: 3,814.71087
Overall Steps per Second: 3,140.31072

Timestep Collection Time: 13.11711
Timestep Consumption Time: 2.81698
PPO Batch Consumption Time: 0.06682
Total Iteration Time: 15.93409

Cumulative Model Updates: 62,163
Cumulative Timesteps: 1,036,891,660

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584,613.73081
Policy Entropy: 1.12114
Value Function Loss: 1.65802

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.07098
Value Function Update Magnitude: 0.11473

Collected Steps per Second: 3,713.81613
Overall Steps per Second: 3,091.51907

Timestep Collection Time: 13.46916
Timestep Consumption Time: 2.71123
PPO Batch Consumption Time: 0.05210
Total Iteration Time: 16.18040

Cumulative Model Updates: 62,166
Cumulative Timesteps: 1,036,941,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1036941682...
Checkpoint 1036941682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474,202.85532
Policy Entropy: 1.11089
Value Function Loss: 1.69081

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.06454
Value Function Update Magnitude: 0.12094

Collected Steps per Second: 3,816.49798
Overall Steps per Second: 3,168.66607

Timestep Collection Time: 13.11359
Timestep Consumption Time: 2.68107
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 15.79466

Cumulative Model Updates: 62,169
Cumulative Timesteps: 1,036,991,730

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069,741.22802
Policy Entropy: 1.10322
Value Function Loss: 1.68397

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.11898

Collected Steps per Second: 3,786.35778
Overall Steps per Second: 3,164.47674

Timestep Collection Time: 13.20794
Timestep Consumption Time: 2.59562
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 15.80356

Cumulative Model Updates: 62,172
Cumulative Timesteps: 1,037,041,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1037041740...
Checkpoint 1037041740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542,875.74863
Policy Entropy: 1.12078
Value Function Loss: 1.74865

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.11420

Collected Steps per Second: 3,679.26227
Overall Steps per Second: 3,095.06499

Timestep Collection Time: 13.59131
Timestep Consumption Time: 2.56538
PPO Batch Consumption Time: 0.06265
Total Iteration Time: 16.15669

Cumulative Model Updates: 62,175
Cumulative Timesteps: 1,037,091,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990,219.37005
Policy Entropy: 1.10574
Value Function Loss: 1.75288

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.10242

Collected Steps per Second: 3,887.23972
Overall Steps per Second: 3,281.53891

Timestep Collection Time: 12.87237
Timestep Consumption Time: 2.37596
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 15.24833

Cumulative Model Updates: 62,178
Cumulative Timesteps: 1,037,141,784

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1037141784...
Checkpoint 1037141784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,607.97987
Policy Entropy: 1.09541
Value Function Loss: 1.80652

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.07314
Value Function Update Magnitude: 0.10466

Collected Steps per Second: 3,675.66929
Overall Steps per Second: 3,116.07247

Timestep Collection Time: 13.60569
Timestep Consumption Time: 2.44336
PPO Batch Consumption Time: 0.05134
Total Iteration Time: 16.04905

Cumulative Model Updates: 62,181
Cumulative Timesteps: 1,037,191,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227,613.72983
Policy Entropy: 1.07518
Value Function Loss: 1.75663

Mean KL Divergence: 0.02589
SB3 Clip Fraction: 0.15984
Policy Update Magnitude: 0.07139
Value Function Update Magnitude: 0.09778

Collected Steps per Second: 4,008.49334
Overall Steps per Second: 3,303.22434

Timestep Collection Time: 12.47651
Timestep Consumption Time: 2.66385
PPO Batch Consumption Time: 0.05770
Total Iteration Time: 15.14036

Cumulative Model Updates: 62,184
Cumulative Timesteps: 1,037,241,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1037241806...
Checkpoint 1037241806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274,390.20858
Policy Entropy: 1.10032
Value Function Loss: 1.79588

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.10169

Collected Steps per Second: 3,793.38346
Overall Steps per Second: 3,152.30052

Timestep Collection Time: 13.18454
Timestep Consumption Time: 2.68134
PPO Batch Consumption Time: 0.05264
Total Iteration Time: 15.86587

Cumulative Model Updates: 62,187
Cumulative Timesteps: 1,037,291,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316,009.55582
Policy Entropy: 1.11027
Value Function Loss: 1.66911

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.11218

Collected Steps per Second: 3,979.53076
Overall Steps per Second: 3,270.12341

Timestep Collection Time: 12.57284
Timestep Consumption Time: 2.72750
PPO Batch Consumption Time: 0.05139
Total Iteration Time: 15.30034

Cumulative Model Updates: 62,190
Cumulative Timesteps: 1,037,341,854

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1037341854...
Checkpoint 1037341854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014,249.92738
Policy Entropy: 1.09674
Value Function Loss: 1.71138

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.10329

Collected Steps per Second: 3,899.04198
Overall Steps per Second: 3,228.53570

Timestep Collection Time: 12.82931
Timestep Consumption Time: 2.66441
PPO Batch Consumption Time: 0.05799
Total Iteration Time: 15.49371

Cumulative Model Updates: 62,193
Cumulative Timesteps: 1,037,391,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470,330.30162
Policy Entropy: 1.08501
Value Function Loss: 1.74598

Mean KL Divergence: 0.02347
SB3 Clip Fraction: 0.16746
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.09386

Collected Steps per Second: 3,863.66155
Overall Steps per Second: 3,269.39755

Timestep Collection Time: 12.94679
Timestep Consumption Time: 2.35328
PPO Batch Consumption Time: 0.05026
Total Iteration Time: 15.30007

Cumulative Model Updates: 62,196
Cumulative Timesteps: 1,037,441,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1037441898...
Checkpoint 1037441898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191,926.40921
Policy Entropy: 1.08561
Value Function Loss: 1.88126

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.09709

Collected Steps per Second: 3,829.80747
Overall Steps per Second: 3,194.73102

Timestep Collection Time: 13.05601
Timestep Consumption Time: 2.59539
PPO Batch Consumption Time: 0.05190
Total Iteration Time: 15.65140

Cumulative Model Updates: 62,199
Cumulative Timesteps: 1,037,491,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178,744.56708
Policy Entropy: 1.10019
Value Function Loss: 1.91463

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.10037

Collected Steps per Second: 3,826.07452
Overall Steps per Second: 3,169.10359

Timestep Collection Time: 13.07397
Timestep Consumption Time: 2.71030
PPO Batch Consumption Time: 0.06127
Total Iteration Time: 15.78427

Cumulative Model Updates: 62,202
Cumulative Timesteps: 1,037,541,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1037541922...
Checkpoint 1037541922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268,369.34405
Policy Entropy: 1.06522
Value Function Loss: 1.84596

Mean KL Divergence: 0.04496
SB3 Clip Fraction: 0.22285
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.09501

Collected Steps per Second: 3,772.92104
Overall Steps per Second: 3,134.38408

Timestep Collection Time: 13.25392
Timestep Consumption Time: 2.70009
PPO Batch Consumption Time: 0.05092
Total Iteration Time: 15.95401

Cumulative Model Updates: 62,205
Cumulative Timesteps: 1,037,591,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830,170.39367
Policy Entropy: 1.10063
Value Function Loss: 1.79769

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.11020

Collected Steps per Second: 3,739.61539
Overall Steps per Second: 3,150.25214

Timestep Collection Time: 13.37303
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.06183
Total Iteration Time: 15.87492

Cumulative Model Updates: 62,208
Cumulative Timesteps: 1,037,641,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1037641938...
Checkpoint 1037641938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200,487.07242
Policy Entropy: 1.07018
Value Function Loss: 1.76117

Mean KL Divergence: 0.03607
SB3 Clip Fraction: 0.18927
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.10671

Collected Steps per Second: 3,759.63114
Overall Steps per Second: 3,170.68334

Timestep Collection Time: 13.31035
Timestep Consumption Time: 2.47237
PPO Batch Consumption Time: 0.05198
Total Iteration Time: 15.78272

Cumulative Model Updates: 62,211
Cumulative Timesteps: 1,037,691,980

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879,262.99848
Policy Entropy: 1.09032
Value Function Loss: 1.82988

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.09494

Collected Steps per Second: 3,965.00244
Overall Steps per Second: 3,280.95592

Timestep Collection Time: 12.61689
Timestep Consumption Time: 2.63050
PPO Batch Consumption Time: 0.05184
Total Iteration Time: 15.24739

Cumulative Model Updates: 62,214
Cumulative Timesteps: 1,037,742,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1037742006...
Checkpoint 1037742006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199,398.09059
Policy Entropy: 1.08545
Value Function Loss: 1.84614

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.06750
Value Function Update Magnitude: 0.09797

Collected Steps per Second: 4,014.35966
Overall Steps per Second: 3,290.96399

Timestep Collection Time: 12.46077
Timestep Consumption Time: 2.73903
PPO Batch Consumption Time: 0.05423
Total Iteration Time: 15.19980

Cumulative Model Updates: 62,217
Cumulative Timesteps: 1,037,792,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233,061.74071
Policy Entropy: 1.08226
Value Function Loss: 1.82873

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.07335
Value Function Update Magnitude: 0.12088

Collected Steps per Second: 3,858.78084
Overall Steps per Second: 3,201.48335

Timestep Collection Time: 12.96109
Timestep Consumption Time: 2.66104
PPO Batch Consumption Time: 0.05884
Total Iteration Time: 15.62213

Cumulative Model Updates: 62,220
Cumulative Timesteps: 1,037,842,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1037842042...
Checkpoint 1037842042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318,307.71736
Policy Entropy: 1.07519
Value Function Loss: 1.78041

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.07168
Value Function Update Magnitude: 0.11178

Collected Steps per Second: 3,727.19237
Overall Steps per Second: 3,119.41912

Timestep Collection Time: 13.42512
Timestep Consumption Time: 2.61569
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 16.04081

Cumulative Model Updates: 62,223
Cumulative Timesteps: 1,037,892,080

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,873,629.60196
Policy Entropy: 1.08651
Value Function Loss: 1.80850

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.10274

Collected Steps per Second: 3,946.71440
Overall Steps per Second: 3,241.44723

Timestep Collection Time: 12.67586
Timestep Consumption Time: 2.75799
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 15.43385

Cumulative Model Updates: 62,226
Cumulative Timesteps: 1,037,942,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1037942108...
Checkpoint 1037942108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398,964.16004
Policy Entropy: 1.09264
Value Function Loss: 1.85453

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.11482
Policy Update Magnitude: 0.07793
Value Function Update Magnitude: 0.10852

Collected Steps per Second: 3,594.97814
Overall Steps per Second: 3,109.79156

Timestep Collection Time: 13.91719
Timestep Consumption Time: 2.17135
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 16.08854

Cumulative Model Updates: 62,229
Cumulative Timesteps: 1,037,992,140

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292,804.34122
Policy Entropy: 1.09368
Value Function Loss: 1.83903

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.08654
Value Function Update Magnitude: 0.09919

Collected Steps per Second: 4,020.61112
Overall Steps per Second: 3,333.14401

Timestep Collection Time: 12.44736
Timestep Consumption Time: 2.56729
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 15.01465

Cumulative Model Updates: 62,232
Cumulative Timesteps: 1,038,042,186

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1038042186...
Checkpoint 1038042186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828,427.20407
Policy Entropy: 1.08787
Value Function Loss: 1.87475

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.08179
Value Function Update Magnitude: 0.10069

Collected Steps per Second: 3,738.75349
Overall Steps per Second: 3,214.31838

Timestep Collection Time: 13.37772
Timestep Consumption Time: 2.18265
PPO Batch Consumption Time: 0.05004
Total Iteration Time: 15.56038

Cumulative Model Updates: 62,235
Cumulative Timesteps: 1,038,092,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373,132.31554
Policy Entropy: 1.07918
Value Function Loss: 1.84783

Mean KL Divergence: 0.03118
SB3 Clip Fraction: 0.18507
Policy Update Magnitude: 0.07679
Value Function Update Magnitude: 0.11519

Collected Steps per Second: 3,847.87362
Overall Steps per Second: 3,244.37620

Timestep Collection Time: 13.00147
Timestep Consumption Time: 2.41845
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 15.41991

Cumulative Model Updates: 62,238
Cumulative Timesteps: 1,038,142,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1038142230...
Checkpoint 1038142230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455,074.80595
Policy Entropy: 1.09599
Value Function Loss: 1.82241

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.06988
Value Function Update Magnitude: 0.11269

Collected Steps per Second: 3,769.61740
Overall Steps per Second: 3,206.90879

Timestep Collection Time: 13.27243
Timestep Consumption Time: 2.32888
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 15.60132

Cumulative Model Updates: 62,241
Cumulative Timesteps: 1,038,192,262

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237,052.57499
Policy Entropy: 1.09617
Value Function Loss: 1.80221

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.07512
Value Function Update Magnitude: 0.10549

Collected Steps per Second: 3,764.92856
Overall Steps per Second: 3,148.85794

Timestep Collection Time: 13.29215
Timestep Consumption Time: 2.60059
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 15.89275

Cumulative Model Updates: 62,244
Cumulative Timesteps: 1,038,242,306

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1038242306...
Checkpoint 1038242306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628,401.42017
Policy Entropy: 1.08040
Value Function Loss: 1.75739

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.07171
Value Function Update Magnitude: 0.10243

Collected Steps per Second: 3,820.66190
Overall Steps per Second: 3,182.67382

Timestep Collection Time: 13.09459
Timestep Consumption Time: 2.62490
PPO Batch Consumption Time: 0.06305
Total Iteration Time: 15.71949

Cumulative Model Updates: 62,247
Cumulative Timesteps: 1,038,292,336

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557,623.76138
Policy Entropy: 1.06373
Value Function Loss: 1.73181

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.07118
Value Function Update Magnitude: 0.10690

Collected Steps per Second: 3,842.72876
Overall Steps per Second: 3,210.54384

Timestep Collection Time: 13.01731
Timestep Consumption Time: 2.56323
PPO Batch Consumption Time: 0.05256
Total Iteration Time: 15.58054

Cumulative Model Updates: 62,250
Cumulative Timesteps: 1,038,342,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1038342358...
Checkpoint 1038342358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526,422.84100
Policy Entropy: 1.07566
Value Function Loss: 1.73299

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.14761
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.10360

Collected Steps per Second: 3,839.12813
Overall Steps per Second: 3,173.91732

Timestep Collection Time: 13.03629
Timestep Consumption Time: 2.73223
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 15.76853

Cumulative Model Updates: 62,253
Cumulative Timesteps: 1,038,392,406

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552,895.36155
Policy Entropy: 1.07587
Value Function Loss: 1.76353

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.15806
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.10179

Collected Steps per Second: 3,777.59380
Overall Steps per Second: 3,148.00178

Timestep Collection Time: 13.24017
Timestep Consumption Time: 2.64800
PPO Batch Consumption Time: 0.05203
Total Iteration Time: 15.88817

Cumulative Model Updates: 62,256
Cumulative Timesteps: 1,038,442,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1038442422...
Checkpoint 1038442422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,144,089.60226
Policy Entropy: 1.06162
Value Function Loss: 1.81222

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 3,686.03115
Overall Steps per Second: 3,056.43943

Timestep Collection Time: 13.57395
Timestep Consumption Time: 2.79608
PPO Batch Consumption Time: 0.06693
Total Iteration Time: 16.37003

Cumulative Model Updates: 62,259
Cumulative Timesteps: 1,038,492,456

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649,179.64552
Policy Entropy: 1.05073
Value Function Loss: 1.82831

Mean KL Divergence: 0.02617
SB3 Clip Fraction: 0.18908
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.10838

Collected Steps per Second: 3,739.56660
Overall Steps per Second: 3,120.10393

Timestep Collection Time: 13.38176
Timestep Consumption Time: 2.65680
PPO Batch Consumption Time: 0.05079
Total Iteration Time: 16.03857

Cumulative Model Updates: 62,262
Cumulative Timesteps: 1,038,542,498

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1038542498...
Checkpoint 1038542498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389,467.95192
Policy Entropy: 1.06684
Value Function Loss: 1.72626

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.10327

Collected Steps per Second: 3,782.26286
Overall Steps per Second: 3,181.26558

Timestep Collection Time: 13.22436
Timestep Consumption Time: 2.49831
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 15.72267

Cumulative Model Updates: 62,265
Cumulative Timesteps: 1,038,592,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343,044.03522
Policy Entropy: 1.06872
Value Function Loss: 1.67794

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.07626
Value Function Update Magnitude: 0.10914

Collected Steps per Second: 3,635.71222
Overall Steps per Second: 3,084.56646

Timestep Collection Time: 13.75741
Timestep Consumption Time: 2.45815
PPO Batch Consumption Time: 0.06566
Total Iteration Time: 16.21557

Cumulative Model Updates: 62,268
Cumulative Timesteps: 1,038,642,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1038642534...
Checkpoint 1038642534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467,754.11885
Policy Entropy: 1.07086
Value Function Loss: 1.65579

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.06941
Value Function Update Magnitude: 0.10922

Collected Steps per Second: 3,742.59758
Overall Steps per Second: 3,185.27666

Timestep Collection Time: 13.36451
Timestep Consumption Time: 2.33836
PPO Batch Consumption Time: 0.05293
Total Iteration Time: 15.70287

Cumulative Model Updates: 62,271
Cumulative Timesteps: 1,038,692,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208,651.96032
Policy Entropy: 1.07764
Value Function Loss: 1.67851

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.06425
Value Function Update Magnitude: 0.11202

Collected Steps per Second: 3,841.12845
Overall Steps per Second: 3,207.37088

Timestep Collection Time: 13.02430
Timestep Consumption Time: 2.57352
PPO Batch Consumption Time: 0.06728
Total Iteration Time: 15.59782

Cumulative Model Updates: 62,274
Cumulative Timesteps: 1,038,742,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1038742580...
Checkpoint 1038742580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,188,332.26595
Policy Entropy: 1.08196
Value Function Loss: 1.71663

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.10869

Collected Steps per Second: 3,862.39306
Overall Steps per Second: 3,206.14698

Timestep Collection Time: 12.94741
Timestep Consumption Time: 2.65012
PPO Batch Consumption Time: 0.05122
Total Iteration Time: 15.59754

Cumulative Model Updates: 62,277
Cumulative Timesteps: 1,038,792,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570,081.00625
Policy Entropy: 1.08726
Value Function Loss: 1.67457

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.07092
Value Function Update Magnitude: 0.10584

Collected Steps per Second: 3,841.71430
Overall Steps per Second: 3,167.40019

Timestep Collection Time: 13.01554
Timestep Consumption Time: 2.77090
PPO Batch Consumption Time: 0.04929
Total Iteration Time: 15.78645

Cumulative Model Updates: 62,280
Cumulative Timesteps: 1,038,842,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1038842590...
Checkpoint 1038842590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604,438.81490
Policy Entropy: 1.07813
Value Function Loss: 1.68666

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.06627
Value Function Update Magnitude: 0.10264

Collected Steps per Second: 3,795.57921
Overall Steps per Second: 3,156.68158

Timestep Collection Time: 13.18218
Timestep Consumption Time: 2.66801
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 15.85019

Cumulative Model Updates: 62,283
Cumulative Timesteps: 1,038,892,624

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,809.14053
Policy Entropy: 1.06946
Value Function Loss: 1.61787

Mean KL Divergence: 0.02616
SB3 Clip Fraction: 0.18264
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.09241

Collected Steps per Second: 3,860.23963
Overall Steps per Second: 3,183.68178

Timestep Collection Time: 12.95464
Timestep Consumption Time: 2.75296
PPO Batch Consumption Time: 0.05943
Total Iteration Time: 15.70760

Cumulative Model Updates: 62,286
Cumulative Timesteps: 1,038,942,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1038942632...
Checkpoint 1038942632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462,616.67818
Policy Entropy: 1.08343
Value Function Loss: 1.61797

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.08916

Collected Steps per Second: 3,855.82616
Overall Steps per Second: 3,210.46229

Timestep Collection Time: 12.97673
Timestep Consumption Time: 2.60857
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 15.58529

Cumulative Model Updates: 62,289
Cumulative Timesteps: 1,038,992,668

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801,451.39807
Policy Entropy: 1.09019
Value Function Loss: 1.58611

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.08973

Collected Steps per Second: 3,814.18077
Overall Steps per Second: 3,158.11447

Timestep Collection Time: 13.11422
Timestep Consumption Time: 2.72435
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 15.83856

Cumulative Model Updates: 62,292
Cumulative Timesteps: 1,039,042,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1039042688...
Checkpoint 1039042688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326,985.02960
Policy Entropy: 1.06830
Value Function Loss: 1.62132

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.08406

Collected Steps per Second: 3,861.43257
Overall Steps per Second: 3,199.51706

Timestep Collection Time: 12.95530
Timestep Consumption Time: 2.68019
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 15.63548

Cumulative Model Updates: 62,295
Cumulative Timesteps: 1,039,092,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450,643.43204
Policy Entropy: 1.07200
Value Function Loss: 1.60592

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12123
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.07882

Collected Steps per Second: 3,750.86767
Overall Steps per Second: 3,137.83148

Timestep Collection Time: 13.34198
Timestep Consumption Time: 2.60661
PPO Batch Consumption Time: 0.06673
Total Iteration Time: 15.94859

Cumulative Model Updates: 62,298
Cumulative Timesteps: 1,039,142,758

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1039142758...
Checkpoint 1039142758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593,995.93221
Policy Entropy: 1.07989
Value Function Loss: 1.65663

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.07812

Collected Steps per Second: 3,632.96672
Overall Steps per Second: 3,038.53315

Timestep Collection Time: 13.76286
Timestep Consumption Time: 2.69245
PPO Batch Consumption Time: 0.05139
Total Iteration Time: 16.45531

Cumulative Model Updates: 62,301
Cumulative Timesteps: 1,039,192,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386,707.78609
Policy Entropy: 1.08773
Value Function Loss: 1.67541

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.08149

Collected Steps per Second: 3,743.80143
Overall Steps per Second: 3,115.82200

Timestep Collection Time: 13.35541
Timestep Consumption Time: 2.69172
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 16.04713

Cumulative Model Updates: 62,304
Cumulative Timesteps: 1,039,242,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1039242758...
Checkpoint 1039242758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541,575.02100
Policy Entropy: 1.08849
Value Function Loss: 1.59488

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.07705
Value Function Update Magnitude: 0.09102

Collected Steps per Second: 3,668.26500
Overall Steps per Second: 3,072.60619

Timestep Collection Time: 13.64351
Timestep Consumption Time: 2.64495
PPO Batch Consumption Time: 0.06667
Total Iteration Time: 16.28845

Cumulative Model Updates: 62,307
Cumulative Timesteps: 1,039,292,806

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653,569.15761
Policy Entropy: 1.08084
Value Function Loss: 1.53287

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.07886
Value Function Update Magnitude: 0.10968

Collected Steps per Second: 3,751.23993
Overall Steps per Second: 3,188.42266

Timestep Collection Time: 13.32946
Timestep Consumption Time: 2.35290
PPO Batch Consumption Time: 0.05911
Total Iteration Time: 15.68236

Cumulative Model Updates: 62,310
Cumulative Timesteps: 1,039,342,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1039342808...
Checkpoint 1039342808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917,965.36953
Policy Entropy: 1.09753
Value Function Loss: 1.56360

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.06890
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 3,782.48622
Overall Steps per Second: 3,167.30269

Timestep Collection Time: 13.22358
Timestep Consumption Time: 2.56841
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 15.79199

Cumulative Model Updates: 62,313
Cumulative Timesteps: 1,039,392,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614,261.39926
Policy Entropy: 1.09659
Value Function Loss: 1.60303

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.06214
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 3,931.11982
Overall Steps per Second: 3,250.40515

Timestep Collection Time: 12.72869
Timestep Consumption Time: 2.66570
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 15.39439

Cumulative Model Updates: 62,316
Cumulative Timesteps: 1,039,442,864

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1039442864...
Checkpoint 1039442864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187,545.66827
Policy Entropy: 1.08462
Value Function Loss: 1.61440

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.12400

Collected Steps per Second: 3,870.59936
Overall Steps per Second: 3,183.87710

Timestep Collection Time: 12.92461
Timestep Consumption Time: 2.78768
PPO Batch Consumption Time: 0.05085
Total Iteration Time: 15.71229

Cumulative Model Updates: 62,319
Cumulative Timesteps: 1,039,492,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793,630.46358
Policy Entropy: 1.08455
Value Function Loss: 1.46573

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.16317
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.12391

Collected Steps per Second: 3,711.86539
Overall Steps per Second: 3,100.30367

Timestep Collection Time: 13.48486
Timestep Consumption Time: 2.66001
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 16.14487

Cumulative Model Updates: 62,322
Cumulative Timesteps: 1,039,542,944

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1039542944...
Checkpoint 1039542944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760,945.07571
Policy Entropy: 1.09531
Value Function Loss: 1.58853

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.12220

Collected Steps per Second: 3,890.81542
Overall Steps per Second: 3,247.91220

Timestep Collection Time: 12.85952
Timestep Consumption Time: 2.54546
PPO Batch Consumption Time: 0.05808
Total Iteration Time: 15.40497

Cumulative Model Updates: 62,325
Cumulative Timesteps: 1,039,592,978

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329,587.73813
Policy Entropy: 1.09524
Value Function Loss: 1.65580

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.13057

Collected Steps per Second: 3,953.95285
Overall Steps per Second: 3,287.93856

Timestep Collection Time: 12.64911
Timestep Consumption Time: 2.56224
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 15.21135

Cumulative Model Updates: 62,328
Cumulative Timesteps: 1,039,642,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1039642992...
Checkpoint 1039642992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251,246.98747
Policy Entropy: 1.09308
Value Function Loss: 1.69187

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.07319
Value Function Update Magnitude: 0.13172

Collected Steps per Second: 3,834.81272
Overall Steps per Second: 3,182.73106

Timestep Collection Time: 13.04001
Timestep Consumption Time: 2.67165
PPO Batch Consumption Time: 0.06225
Total Iteration Time: 15.71166

Cumulative Model Updates: 62,331
Cumulative Timesteps: 1,039,692,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398,644.30213
Policy Entropy: 1.07490
Value Function Loss: 1.63175

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.08179
Value Function Update Magnitude: 0.12065

Collected Steps per Second: 3,841.16061
Overall Steps per Second: 3,223.00894

Timestep Collection Time: 13.02054
Timestep Consumption Time: 2.49725
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 15.51780

Cumulative Model Updates: 62,334
Cumulative Timesteps: 1,039,743,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1039743012...
Checkpoint 1039743012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271,918.27737
Policy Entropy: 1.09296
Value Function Loss: 1.52075

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.06913
Value Function Update Magnitude: 0.10554

Collected Steps per Second: 3,951.03855
Overall Steps per Second: 3,278.59414

Timestep Collection Time: 12.66351
Timestep Consumption Time: 2.59730
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 15.26081

Cumulative Model Updates: 62,337
Cumulative Timesteps: 1,039,793,046

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480,051.03961
Policy Entropy: 1.08882
Value Function Loss: 1.60735

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.15341
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.09316

Collected Steps per Second: 3,831.11890
Overall Steps per Second: 3,239.24106

Timestep Collection Time: 13.05572
Timestep Consumption Time: 2.38556
PPO Batch Consumption Time: 0.05204
Total Iteration Time: 15.44127

Cumulative Model Updates: 62,340
Cumulative Timesteps: 1,039,843,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1039843064...
Checkpoint 1039843064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407,311.13256
Policy Entropy: 1.08662
Value Function Loss: 1.63414

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.08823

Collected Steps per Second: 3,934.89837
Overall Steps per Second: 3,321.14752

Timestep Collection Time: 12.71392
Timestep Consumption Time: 2.34954
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 15.06347

Cumulative Model Updates: 62,343
Cumulative Timesteps: 1,039,893,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533,294.06914
Policy Entropy: 1.08015
Value Function Loss: 1.70236

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.09211

Collected Steps per Second: 3,792.06303
Overall Steps per Second: 3,203.64841

Timestep Collection Time: 13.19018
Timestep Consumption Time: 2.42264
PPO Batch Consumption Time: 0.04883
Total Iteration Time: 15.61282

Cumulative Model Updates: 62,346
Cumulative Timesteps: 1,039,943,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1039943110...
Checkpoint 1039943110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040,665.23700
Policy Entropy: 1.08712
Value Function Loss: 1.69687

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.09994

Collected Steps per Second: 3,873.83113
Overall Steps per Second: 3,180.45175

Timestep Collection Time: 12.91590
Timestep Consumption Time: 2.81583
PPO Batch Consumption Time: 0.05893
Total Iteration Time: 15.73173

Cumulative Model Updates: 62,349
Cumulative Timesteps: 1,039,993,144

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595,770.50383
Policy Entropy: 1.10037
Value Function Loss: 1.60973

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.09933

Collected Steps per Second: 3,716.17560
Overall Steps per Second: 3,105.69548

Timestep Collection Time: 13.46007
Timestep Consumption Time: 2.64582
PPO Batch Consumption Time: 0.05287
Total Iteration Time: 16.10589

Cumulative Model Updates: 62,352
Cumulative Timesteps: 1,040,043,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1040043164...
Checkpoint 1040043164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249,209.91954
Policy Entropy: 1.06725
Value Function Loss: 1.56405

Mean KL Divergence: 0.04384
SB3 Clip Fraction: 0.21995
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.09232

Collected Steps per Second: 3,823.54063
Overall Steps per Second: 3,172.97678

Timestep Collection Time: 13.07898
Timestep Consumption Time: 2.68162
PPO Batch Consumption Time: 0.05893
Total Iteration Time: 15.76059

Cumulative Model Updates: 62,355
Cumulative Timesteps: 1,040,093,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460,225.70633
Policy Entropy: 1.09990
Value Function Loss: 1.57205

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.10015

Collected Steps per Second: 3,779.20787
Overall Steps per Second: 3,142.94402

Timestep Collection Time: 13.23769
Timestep Consumption Time: 2.67987
PPO Batch Consumption Time: 0.05324
Total Iteration Time: 15.91756

Cumulative Model Updates: 62,358
Cumulative Timesteps: 1,040,143,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1040143200...
Checkpoint 1040143200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540,941.59313
Policy Entropy: 1.07340
Value Function Loss: 1.62221

Mean KL Divergence: 0.02837
SB3 Clip Fraction: 0.16936
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.10006

Collected Steps per Second: 3,896.42879
Overall Steps per Second: 3,249.20994

Timestep Collection Time: 12.84099
Timestep Consumption Time: 2.55783
PPO Batch Consumption Time: 0.05212
Total Iteration Time: 15.39882

Cumulative Model Updates: 62,361
Cumulative Timesteps: 1,040,193,234

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297,247.59870
Policy Entropy: 1.08959
Value Function Loss: 1.64054

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 3,888.86939
Overall Steps per Second: 3,255.17296

Timestep Collection Time: 12.86286
Timestep Consumption Time: 2.50406
PPO Batch Consumption Time: 0.05782
Total Iteration Time: 15.36693

Cumulative Model Updates: 62,364
Cumulative Timesteps: 1,040,243,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1040243256...
Checkpoint 1040243256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581,427.69135
Policy Entropy: 1.08635
Value Function Loss: 1.56579

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.09938

Collected Steps per Second: 3,770.38730
Overall Steps per Second: 3,141.46907

Timestep Collection Time: 13.26442
Timestep Consumption Time: 2.65552
PPO Batch Consumption Time: 0.05137
Total Iteration Time: 15.91994

Cumulative Model Updates: 62,367
Cumulative Timesteps: 1,040,293,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297,324.39848
Policy Entropy: 1.09224
Value Function Loss: 1.53106

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.07606
Value Function Update Magnitude: 0.10419

Collected Steps per Second: 3,893.73123
Overall Steps per Second: 3,219.64130

Timestep Collection Time: 12.84783
Timestep Consumption Time: 2.68992
PPO Batch Consumption Time: 0.05859
Total Iteration Time: 15.53776

Cumulative Model Updates: 62,370
Cumulative Timesteps: 1,040,343,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1040343294...
Checkpoint 1040343294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340,423.68157
Policy Entropy: 1.08675
Value Function Loss: 1.42756

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.07595
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 3,718.48471
Overall Steps per Second: 3,055.24442

Timestep Collection Time: 13.44741
Timestep Consumption Time: 2.91920
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 16.36661

Cumulative Model Updates: 62,373
Cumulative Timesteps: 1,040,393,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702,193.99240
Policy Entropy: 1.09594
Value Function Loss: 1.40175

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.06795
Value Function Update Magnitude: 0.11465

Collected Steps per Second: 3,749.02101
Overall Steps per Second: 3,119.21598

Timestep Collection Time: 13.33682
Timestep Consumption Time: 2.69285
PPO Batch Consumption Time: 0.05928
Total Iteration Time: 16.02967

Cumulative Model Updates: 62,376
Cumulative Timesteps: 1,040,443,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1040443298...
Checkpoint 1040443298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889,158.83654
Policy Entropy: 1.09597
Value Function Loss: 1.42658

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.06620
Value Function Update Magnitude: 0.10407

Collected Steps per Second: 3,823.21690
Overall Steps per Second: 3,222.66761

Timestep Collection Time: 13.08584
Timestep Consumption Time: 2.43857
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 15.52441

Cumulative Model Updates: 62,379
Cumulative Timesteps: 1,040,493,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638,158.23074
Policy Entropy: 1.09658
Value Function Loss: 1.40860

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.06683
Value Function Update Magnitude: 0.09806

Collected Steps per Second: 4,012.89178
Overall Steps per Second: 3,372.36260

Timestep Collection Time: 12.46931
Timestep Consumption Time: 2.36836
PPO Batch Consumption Time: 0.04878
Total Iteration Time: 14.83767

Cumulative Model Updates: 62,382
Cumulative Timesteps: 1,040,543,366

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1040543366...
Checkpoint 1040543366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550,956.88573
Policy Entropy: 1.10479
Value Function Loss: 1.42144

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.07537
Value Function Update Magnitude: 0.10064

Collected Steps per Second: 3,908.24284
Overall Steps per Second: 3,247.54316

Timestep Collection Time: 12.80166
Timestep Consumption Time: 2.60445
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 15.40611

Cumulative Model Updates: 62,385
Cumulative Timesteps: 1,040,593,398

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780,441.53201
Policy Entropy: 1.10228
Value Function Loss: 1.38628

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.07615
Value Function Update Magnitude: 0.09166

Collected Steps per Second: 3,704.82660
Overall Steps per Second: 3,131.45345

Timestep Collection Time: 13.49915
Timestep Consumption Time: 2.47171
PPO Batch Consumption Time: 0.06711
Total Iteration Time: 15.97086

Cumulative Model Updates: 62,388
Cumulative Timesteps: 1,040,643,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1040643410...
Checkpoint 1040643410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266,543.80593
Policy Entropy: 1.09835
Value Function Loss: 1.40323

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.06958
Value Function Update Magnitude: 0.10222

Collected Steps per Second: 3,815.71400
Overall Steps per Second: 3,151.51664

Timestep Collection Time: 13.10633
Timestep Consumption Time: 2.76222
PPO Batch Consumption Time: 0.05398
Total Iteration Time: 15.86855

Cumulative Model Updates: 62,391
Cumulative Timesteps: 1,040,693,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934,870.35620
Policy Entropy: 1.10407
Value Function Loss: 1.35354

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.09507

Collected Steps per Second: 3,818.46291
Overall Steps per Second: 3,179.37031

Timestep Collection Time: 13.10161
Timestep Consumption Time: 2.63358
PPO Batch Consumption Time: 0.05147
Total Iteration Time: 15.73519

Cumulative Model Updates: 62,394
Cumulative Timesteps: 1,040,743,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1040743448...
Checkpoint 1040743448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724,266.91847
Policy Entropy: 1.11482
Value Function Loss: 1.38125

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.06106
Value Function Update Magnitude: 0.08762

Collected Steps per Second: 3,825.26746
Overall Steps per Second: 3,180.32060

Timestep Collection Time: 13.08092
Timestep Consumption Time: 2.65272
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 15.73363

Cumulative Model Updates: 62,397
Cumulative Timesteps: 1,040,793,486

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499,623.72177
Policy Entropy: 1.08412
Value Function Loss: 1.41362

Mean KL Divergence: 0.02690
SB3 Clip Fraction: 0.16575
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.08512

Collected Steps per Second: 3,826.41234
Overall Steps per Second: 3,161.36423

Timestep Collection Time: 13.06864
Timestep Consumption Time: 2.74922
PPO Batch Consumption Time: 0.04813
Total Iteration Time: 15.81785

Cumulative Model Updates: 62,400
Cumulative Timesteps: 1,040,843,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1040843492...
Checkpoint 1040843492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896,264.92545
Policy Entropy: 1.10763
Value Function Loss: 1.46696

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.08604

Collected Steps per Second: 3,849.95627
Overall Steps per Second: 3,203.50755

Timestep Collection Time: 12.99547
Timestep Consumption Time: 2.62241
PPO Batch Consumption Time: 0.06042
Total Iteration Time: 15.61788

Cumulative Model Updates: 62,403
Cumulative Timesteps: 1,040,893,524

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252,573.94252
Policy Entropy: 1.10456
Value Function Loss: 1.39820

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.07747

Collected Steps per Second: 3,899.99025
Overall Steps per Second: 3,196.18070

Timestep Collection Time: 12.82567
Timestep Consumption Time: 2.82426
PPO Batch Consumption Time: 0.05214
Total Iteration Time: 15.64993

Cumulative Model Updates: 62,406
Cumulative Timesteps: 1,040,943,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1040943544...
Checkpoint 1040943544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292,939.65973
Policy Entropy: 1.10481
Value Function Loss: 1.34306

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.14930
Policy Update Magnitude: 0.06143
Value Function Update Magnitude: 0.06812

Collected Steps per Second: 3,637.98018
Overall Steps per Second: 3,039.09068

Timestep Collection Time: 13.74939
Timestep Consumption Time: 2.70948
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 16.45887

Cumulative Model Updates: 62,409
Cumulative Timesteps: 1,040,993,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465,194.14316
Policy Entropy: 1.09833
Value Function Loss: 1.29183

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.16848
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.06128

Collected Steps per Second: 3,758.87465
Overall Steps per Second: 3,164.60235

Timestep Collection Time: 13.31250
Timestep Consumption Time: 2.49992
PPO Batch Consumption Time: 0.06070
Total Iteration Time: 15.81241

Cumulative Model Updates: 62,412
Cumulative Timesteps: 1,041,043,604

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1041043604...
Checkpoint 1041043604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181,694.25605
Policy Entropy: 1.10938
Value Function Loss: 1.35225

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.06438

Collected Steps per Second: 3,705.21159
Overall Steps per Second: 3,069.09429

Timestep Collection Time: 13.50530
Timestep Consumption Time: 2.79918
PPO Batch Consumption Time: 0.05857
Total Iteration Time: 16.30448

Cumulative Model Updates: 62,415
Cumulative Timesteps: 1,041,093,644

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267,856.45817
Policy Entropy: 1.11190
Value Function Loss: 1.29928

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.11873
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.07638

Collected Steps per Second: 3,886.90966
Overall Steps per Second: 3,154.97988

Timestep Collection Time: 12.86626
Timestep Consumption Time: 2.98487
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 15.85113

Cumulative Model Updates: 62,418
Cumulative Timesteps: 1,041,143,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1041143654...
Checkpoint 1041143654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327,531.13469
Policy Entropy: 1.09735
Value Function Loss: 1.23721

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.09326

Collected Steps per Second: 3,966.71355
Overall Steps per Second: 3,300.66992

Timestep Collection Time: 12.60842
Timestep Consumption Time: 2.54426
PPO Batch Consumption Time: 0.05798
Total Iteration Time: 15.15268

Cumulative Model Updates: 62,421
Cumulative Timesteps: 1,041,193,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970,979.16259
Policy Entropy: 1.09265
Value Function Loss: 1.17354

Mean KL Divergence: 0.02268
SB3 Clip Fraction: 0.15729
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.09144

Collected Steps per Second: 4,023.58127
Overall Steps per Second: 3,351.91952

Timestep Collection Time: 12.42724
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.05186
Total Iteration Time: 14.91742

Cumulative Model Updates: 62,424
Cumulative Timesteps: 1,041,243,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1041243670...
Checkpoint 1041243670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,810,905.19553
Policy Entropy: 1.10264
Value Function Loss: 1.18360

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.10231

Collected Steps per Second: 3,998.89940
Overall Steps per Second: 3,305.58217

Timestep Collection Time: 12.51394
Timestep Consumption Time: 2.62469
PPO Batch Consumption Time: 0.06124
Total Iteration Time: 15.13863

Cumulative Model Updates: 62,427
Cumulative Timesteps: 1,041,293,712

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117,695.07251
Policy Entropy: 1.10677
Value Function Loss: 1.19691

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.10964

Collected Steps per Second: 3,847.42605
Overall Steps per Second: 3,149.48601

Timestep Collection Time: 12.99778
Timestep Consumption Time: 2.88037
PPO Batch Consumption Time: 0.05995
Total Iteration Time: 15.87815

Cumulative Model Updates: 62,430
Cumulative Timesteps: 1,041,343,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1041343720...
Checkpoint 1041343720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116,044.72286
Policy Entropy: 1.07690
Value Function Loss: 1.23108

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.10251

Collected Steps per Second: 3,817.43744
Overall Steps per Second: 3,152.57811

Timestep Collection Time: 13.10198
Timestep Consumption Time: 2.76313
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 15.86511

Cumulative Model Updates: 62,433
Cumulative Timesteps: 1,041,393,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283,823.09634
Policy Entropy: 1.09236
Value Function Loss: 1.29029

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.09921

Collected Steps per Second: 3,872.13247
Overall Steps per Second: 3,213.84991

Timestep Collection Time: 12.91846
Timestep Consumption Time: 2.64605
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 15.56451

Cumulative Model Updates: 62,436
Cumulative Timesteps: 1,041,443,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1041443758...
Checkpoint 1041443758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522,043.69997
Policy Entropy: 1.09261
Value Function Loss: 1.33993

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.10016

Collected Steps per Second: 3,804.66562
Overall Steps per Second: 3,182.42414

Timestep Collection Time: 13.14807
Timestep Consumption Time: 2.57077
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 15.71883

Cumulative Model Updates: 62,439
Cumulative Timesteps: 1,041,493,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432,894.73201
Policy Entropy: 1.09561
Value Function Loss: 1.32365

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.10508

Collected Steps per Second: 3,870.98180
Overall Steps per Second: 3,207.01073

Timestep Collection Time: 12.92179
Timestep Consumption Time: 2.67529
PPO Batch Consumption Time: 0.05324
Total Iteration Time: 15.59708

Cumulative Model Updates: 62,442
Cumulative Timesteps: 1,041,543,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1041543802...
Checkpoint 1041543802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502,631.07257
Policy Entropy: 1.09482
Value Function Loss: 1.29931

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.06973
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 3,766.28911
Overall Steps per Second: 3,144.76830

Timestep Collection Time: 13.28363
Timestep Consumption Time: 2.62533
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 15.90896

Cumulative Model Updates: 62,445
Cumulative Timesteps: 1,041,593,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138,121.49584
Policy Entropy: 1.08272
Value Function Loss: 1.25548

Mean KL Divergence: 0.02888
SB3 Clip Fraction: 0.20085
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.10132

Collected Steps per Second: 3,849.42938
Overall Steps per Second: 3,249.57743

Timestep Collection Time: 12.99413
Timestep Consumption Time: 2.39864
PPO Batch Consumption Time: 0.06068
Total Iteration Time: 15.39277

Cumulative Model Updates: 62,448
Cumulative Timesteps: 1,041,643,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1041643852...
Checkpoint 1041643852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658,601.96794
Policy Entropy: 1.09530
Value Function Loss: 1.24375

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.09449

Collected Steps per Second: 3,651.22065
Overall Steps per Second: 3,104.19496

Timestep Collection Time: 13.70008
Timestep Consumption Time: 2.41425
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 16.11432

Cumulative Model Updates: 62,451
Cumulative Timesteps: 1,041,693,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182,788.25861
Policy Entropy: 1.09113
Value Function Loss: 1.20560

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.06629
Value Function Update Magnitude: 0.08586

Collected Steps per Second: 3,736.64852
Overall Steps per Second: 3,086.69498

Timestep Collection Time: 13.38686
Timestep Consumption Time: 2.81882
PPO Batch Consumption Time: 0.06314
Total Iteration Time: 16.20568

Cumulative Model Updates: 62,454
Cumulative Timesteps: 1,041,743,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1041743896...
Checkpoint 1041743896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,944,923.60169
Policy Entropy: 1.08662
Value Function Loss: 1.21944

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.07036
Value Function Update Magnitude: 0.10111

Collected Steps per Second: 3,712.32818
Overall Steps per Second: 3,093.44546

Timestep Collection Time: 13.46864
Timestep Consumption Time: 2.69457
PPO Batch Consumption Time: 0.04927
Total Iteration Time: 16.16321

Cumulative Model Updates: 62,457
Cumulative Timesteps: 1,041,793,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117,367.79153
Policy Entropy: 1.07927
Value Function Loss: 1.22358

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.10829

Collected Steps per Second: 3,839.21991
Overall Steps per Second: 3,185.41349

Timestep Collection Time: 13.02556
Timestep Consumption Time: 2.67350
PPO Batch Consumption Time: 0.05820
Total Iteration Time: 15.69906

Cumulative Model Updates: 62,460
Cumulative Timesteps: 1,041,843,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1041843904...
Checkpoint 1041843904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135,063.95911
Policy Entropy: 1.09060
Value Function Loss: 1.23845

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.10295

Collected Steps per Second: 4,024.62088
Overall Steps per Second: 3,307.35625

Timestep Collection Time: 12.43397
Timestep Consumption Time: 2.69655
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 15.13051

Cumulative Model Updates: 62,463
Cumulative Timesteps: 1,041,893,946

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,799,680.83801
Policy Entropy: 1.09772
Value Function Loss: 1.20347

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.09697

Collected Steps per Second: 3,773.82820
Overall Steps per Second: 3,146.19957

Timestep Collection Time: 13.26134
Timestep Consumption Time: 2.64548
PPO Batch Consumption Time: 0.05894
Total Iteration Time: 15.90681

Cumulative Model Updates: 62,466
Cumulative Timesteps: 1,041,943,992

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1041943992...
Checkpoint 1041943992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,924,078.59348
Policy Entropy: 1.08329
Value Function Loss: 1.18697

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 3,789.21810
Overall Steps per Second: 3,208.18653

Timestep Collection Time: 13.20272
Timestep Consumption Time: 2.39113
PPO Batch Consumption Time: 0.04871
Total Iteration Time: 15.59386

Cumulative Model Updates: 62,469
Cumulative Timesteps: 1,041,994,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750,709.41800
Policy Entropy: 1.07885
Value Function Loss: 1.19454

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 3,986.37077
Overall Steps per Second: 3,292.42576

Timestep Collection Time: 12.54474
Timestep Consumption Time: 2.64406
PPO Batch Consumption Time: 0.05277
Total Iteration Time: 15.18880

Cumulative Model Updates: 62,472
Cumulative Timesteps: 1,042,044,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1042044028...
Checkpoint 1042044028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047,045.51778
Policy Entropy: 1.07814
Value Function Loss: 1.26729

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.07647

Collected Steps per Second: 3,731.09339
Overall Steps per Second: 3,108.65859

Timestep Collection Time: 13.40572
Timestep Consumption Time: 2.68418
PPO Batch Consumption Time: 0.05858
Total Iteration Time: 16.08990

Cumulative Model Updates: 62,475
Cumulative Timesteps: 1,042,094,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279,075.83546
Policy Entropy: 1.08721
Value Function Loss: 1.26570

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.08638

Collected Steps per Second: 3,924.43300
Overall Steps per Second: 3,236.60271

Timestep Collection Time: 12.74069
Timestep Consumption Time: 2.70760
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 15.44830

Cumulative Model Updates: 62,478
Cumulative Timesteps: 1,042,144,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1042144046...
Checkpoint 1042144046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467,186.17015
Policy Entropy: 1.08816
Value Function Loss: 1.30118

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.06860
Value Function Update Magnitude: 0.08995

Collected Steps per Second: 3,839.65003
Overall Steps per Second: 3,173.27957

Timestep Collection Time: 13.02567
Timestep Consumption Time: 2.73531
PPO Batch Consumption Time: 0.04883
Total Iteration Time: 15.76098

Cumulative Model Updates: 62,481
Cumulative Timesteps: 1,042,194,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583,818.35809
Policy Entropy: 1.09553
Value Function Loss: 1.26040

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.11962
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.09929

Collected Steps per Second: 3,868.78075
Overall Steps per Second: 3,246.56663

Timestep Collection Time: 12.92965
Timestep Consumption Time: 2.47801
PPO Batch Consumption Time: 0.05278
Total Iteration Time: 15.40766

Cumulative Model Updates: 62,484
Cumulative Timesteps: 1,042,244,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1042244082...
Checkpoint 1042244082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804,805.53261
Policy Entropy: 1.09238
Value Function Loss: 1.27177

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.06981
Value Function Update Magnitude: 0.09124

Collected Steps per Second: 3,804.94226
Overall Steps per Second: 3,231.02090

Timestep Collection Time: 13.14133
Timestep Consumption Time: 2.33427
PPO Batch Consumption Time: 0.05420
Total Iteration Time: 15.47560

Cumulative Model Updates: 62,487
Cumulative Timesteps: 1,042,294,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832,248.14443
Policy Entropy: 1.10200
Value Function Loss: 1.26924

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.06553
Value Function Update Magnitude: 0.08969

Collected Steps per Second: 3,800.93787
Overall Steps per Second: 3,171.90168

Timestep Collection Time: 13.16465
Timestep Consumption Time: 2.61075
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 15.77539

Cumulative Model Updates: 62,490
Cumulative Timesteps: 1,042,344,122

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1042344122...
Checkpoint 1042344122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328,693.13486
Policy Entropy: 1.09830
Value Function Loss: 1.24778

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.06584
Value Function Update Magnitude: 0.09837

Collected Steps per Second: 3,760.93227
Overall Steps per Second: 3,109.62087

Timestep Collection Time: 13.30521
Timestep Consumption Time: 2.78678
PPO Batch Consumption Time: 0.06358
Total Iteration Time: 16.09199

Cumulative Model Updates: 62,493
Cumulative Timesteps: 1,042,394,162

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475,976.64034
Policy Entropy: 1.09372
Value Function Loss: 1.23883

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.06726
Value Function Update Magnitude: 0.10784

Collected Steps per Second: 3,944.26236
Overall Steps per Second: 3,241.43816

Timestep Collection Time: 12.68273
Timestep Consumption Time: 2.74993
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 15.43266

Cumulative Model Updates: 62,496
Cumulative Timesteps: 1,042,444,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1042444186...
Checkpoint 1042444186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497,495.24319
Policy Entropy: 1.09962
Value Function Loss: 1.26425

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.10420

Collected Steps per Second: 3,788.90028
Overall Steps per Second: 3,153.80530

Timestep Collection Time: 13.20330
Timestep Consumption Time: 2.65880
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 15.86211

Cumulative Model Updates: 62,499
Cumulative Timesteps: 1,042,494,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464,763.56926
Policy Entropy: 1.09563
Value Function Loss: 1.29520

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.09802

Collected Steps per Second: 3,669.51638
Overall Steps per Second: 3,075.36486

Timestep Collection Time: 13.63340
Timestep Consumption Time: 2.63393
PPO Batch Consumption Time: 0.05970
Total Iteration Time: 16.26734

Cumulative Model Updates: 62,502
Cumulative Timesteps: 1,042,544,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1042544240...
Checkpoint 1042544240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330,146.21177
Policy Entropy: 1.10164
Value Function Loss: 1.31618

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.06705
Value Function Update Magnitude: 0.08922

Collected Steps per Second: 3,805.32688
Overall Steps per Second: 3,170.48118

Timestep Collection Time: 13.14158
Timestep Consumption Time: 2.63142
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 15.77300

Cumulative Model Updates: 62,505
Cumulative Timesteps: 1,042,594,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801,566.83563
Policy Entropy: 1.09501
Value Function Loss: 1.30561

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.06751
Value Function Update Magnitude: 0.08001

Collected Steps per Second: 3,814.92520
Overall Steps per Second: 3,174.30563

Timestep Collection Time: 13.11218
Timestep Consumption Time: 2.64622
PPO Batch Consumption Time: 0.06192
Total Iteration Time: 15.75841

Cumulative Model Updates: 62,508
Cumulative Timesteps: 1,042,644,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1042644270...
Checkpoint 1042644270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680,274.87383
Policy Entropy: 1.10831
Value Function Loss: 1.32179

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 3,836.43916
Overall Steps per Second: 3,179.04452

Timestep Collection Time: 13.03917
Timestep Consumption Time: 2.69637
PPO Batch Consumption Time: 0.05841
Total Iteration Time: 15.73555

Cumulative Model Updates: 62,511
Cumulative Timesteps: 1,042,694,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057,046.23750
Policy Entropy: 1.10613
Value Function Loss: 1.28922

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.08842

Collected Steps per Second: 4,020.36599
Overall Steps per Second: 3,379.30333

Timestep Collection Time: 12.44713
Timestep Consumption Time: 2.36125
PPO Batch Consumption Time: 0.05805
Total Iteration Time: 14.80838

Cumulative Model Updates: 62,514
Cumulative Timesteps: 1,042,744,336

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1042744336...
Checkpoint 1042744336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687,984.65329
Policy Entropy: 1.08537
Value Function Loss: 1.26012

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.08362

Collected Steps per Second: 3,855.11724
Overall Steps per Second: 3,249.11547

Timestep Collection Time: 12.98015
Timestep Consumption Time: 2.42096
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 15.40111

Cumulative Model Updates: 62,517
Cumulative Timesteps: 1,042,794,376

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717,722.28618
Policy Entropy: 1.07385
Value Function Loss: 1.28260

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.17720
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.08439

Collected Steps per Second: 3,876.70407
Overall Steps per Second: 3,241.27669

Timestep Collection Time: 12.89910
Timestep Consumption Time: 2.52877
PPO Batch Consumption Time: 0.05886
Total Iteration Time: 15.42787

Cumulative Model Updates: 62,520
Cumulative Timesteps: 1,042,844,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1042844382...
Checkpoint 1042844382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529,640.39168
Policy Entropy: 1.08805
Value Function Loss: 1.27940

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.08072

Collected Steps per Second: 3,877.96664
Overall Steps per Second: 3,167.18799

Timestep Collection Time: 12.90161
Timestep Consumption Time: 2.89537
PPO Batch Consumption Time: 0.05834
Total Iteration Time: 15.79698

Cumulative Model Updates: 62,523
Cumulative Timesteps: 1,042,894,414

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421,139.99391
Policy Entropy: 1.09626
Value Function Loss: 1.31217

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.08353

Collected Steps per Second: 3,586.04602
Overall Steps per Second: 2,975.94469

Timestep Collection Time: 13.94684
Timestep Consumption Time: 2.85925
PPO Batch Consumption Time: 0.05171
Total Iteration Time: 16.80609

Cumulative Model Updates: 62,526
Cumulative Timesteps: 1,042,944,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1042944428...
Checkpoint 1042944428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301,217.26776
Policy Entropy: 1.07644
Value Function Loss: 1.27192

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.09558

Collected Steps per Second: 3,651.26071
Overall Steps per Second: 3,046.21765

Timestep Collection Time: 13.70212
Timestep Consumption Time: 2.72153
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 16.42365

Cumulative Model Updates: 62,529
Cumulative Timesteps: 1,042,994,458

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908,284.67252
Policy Entropy: 1.08182
Value Function Loss: 1.27830

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.10868

Collected Steps per Second: 3,538.03988
Overall Steps per Second: 2,952.43860

Timestep Collection Time: 14.14399
Timestep Consumption Time: 2.80539
PPO Batch Consumption Time: 0.06055
Total Iteration Time: 16.94938

Cumulative Model Updates: 62,532
Cumulative Timesteps: 1,043,044,500

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1043044500...
Checkpoint 1043044500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281,637.18984
Policy Entropy: 1.09272
Value Function Loss: 1.27819

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.12495

Collected Steps per Second: 3,598.58524
Overall Steps per Second: 2,984.08140

Timestep Collection Time: 13.89657
Timestep Consumption Time: 2.86168
PPO Batch Consumption Time: 0.06373
Total Iteration Time: 16.75826

Cumulative Model Updates: 62,535
Cumulative Timesteps: 1,043,094,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261,748.07050
Policy Entropy: 1.07747
Value Function Loss: 1.29937

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.12380

Collected Steps per Second: 3,513.05367
Overall Steps per Second: 2,946.49601

Timestep Collection Time: 14.23377
Timestep Consumption Time: 2.73690
PPO Batch Consumption Time: 0.06527
Total Iteration Time: 16.97067

Cumulative Model Updates: 62,538
Cumulative Timesteps: 1,043,144,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1043144512...
Checkpoint 1043144512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119,312.15784
Policy Entropy: 1.07249
Value Function Loss: 1.31731

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.16886
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.12928

Collected Steps per Second: 3,476.65692
Overall Steps per Second: 2,913.34820

Timestep Collection Time: 14.39486
Timestep Consumption Time: 2.78331
PPO Batch Consumption Time: 0.05795
Total Iteration Time: 17.17817

Cumulative Model Updates: 62,541
Cumulative Timesteps: 1,043,194,558

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,981,579.97101
Policy Entropy: 1.08965
Value Function Loss: 1.32144

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.11842

Collected Steps per Second: 3,662.76572
Overall Steps per Second: 3,029.99271

Timestep Collection Time: 13.65198
Timestep Consumption Time: 2.85103
PPO Batch Consumption Time: 0.06403
Total Iteration Time: 16.50301

Cumulative Model Updates: 62,544
Cumulative Timesteps: 1,043,244,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1043244562...
Checkpoint 1043244562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251,970.05544
Policy Entropy: 1.10046
Value Function Loss: 1.29196

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.10146

Collected Steps per Second: 3,444.44644
Overall Steps per Second: 2,896.32224

Timestep Collection Time: 14.52599
Timestep Consumption Time: 2.74902
PPO Batch Consumption Time: 0.04890
Total Iteration Time: 17.27501

Cumulative Model Updates: 62,547
Cumulative Timesteps: 1,043,294,596

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653,173.59336
Policy Entropy: 1.06681
Value Function Loss: 1.27520

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.17459
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.09181

Collected Steps per Second: 3,469.06310
Overall Steps per Second: 2,907.10233

Timestep Collection Time: 14.41484
Timestep Consumption Time: 2.78648
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 17.20132

Cumulative Model Updates: 62,550
Cumulative Timesteps: 1,043,344,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1043344602...
Checkpoint 1043344602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680,642.80182
Policy Entropy: 1.07892
Value Function Loss: 1.28402

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.09259

Collected Steps per Second: 3,610.57442
Overall Steps per Second: 3,046.56252

Timestep Collection Time: 13.85818
Timestep Consumption Time: 2.56557
PPO Batch Consumption Time: 0.06346
Total Iteration Time: 16.42376

Cumulative Model Updates: 62,553
Cumulative Timesteps: 1,043,394,638

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388,183.83407
Policy Entropy: 1.07657
Value Function Loss: 1.31912

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.14967
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.08793

Collected Steps per Second: 3,386.65286
Overall Steps per Second: 2,900.14969

Timestep Collection Time: 14.76384
Timestep Consumption Time: 2.47665
PPO Batch Consumption Time: 0.06047
Total Iteration Time: 17.24049

Cumulative Model Updates: 62,556
Cumulative Timesteps: 1,043,444,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1043444638...
Checkpoint 1043444638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479,561.39987
Policy Entropy: 1.07351
Value Function Loss: 1.31266

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.08544

Collected Steps per Second: 3,813.21828
Overall Steps per Second: 3,170.55641

Timestep Collection Time: 13.12068
Timestep Consumption Time: 2.65952
PPO Batch Consumption Time: 0.05128
Total Iteration Time: 15.78020

Cumulative Model Updates: 62,559
Cumulative Timesteps: 1,043,494,670

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014,841.27023
Policy Entropy: 1.05954
Value Function Loss: 1.26695

Mean KL Divergence: 0.03045
SB3 Clip Fraction: 0.19612
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.08555

Collected Steps per Second: 3,824.91310
Overall Steps per Second: 3,168.93202

Timestep Collection Time: 13.07272
Timestep Consumption Time: 2.70610
PPO Batch Consumption Time: 0.05104
Total Iteration Time: 15.77882

Cumulative Model Updates: 62,562
Cumulative Timesteps: 1,043,544,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1043544672...
Checkpoint 1043544672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765,076.04459
Policy Entropy: 1.07805
Value Function Loss: 1.34069

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.08352

Collected Steps per Second: 3,804.92868
Overall Steps per Second: 3,186.06883

Timestep Collection Time: 13.14558
Timestep Consumption Time: 2.55339
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 15.69897

Cumulative Model Updates: 62,565
Cumulative Timesteps: 1,043,594,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597,630.05526
Policy Entropy: 1.07257
Value Function Loss: 1.34062

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.08838

Collected Steps per Second: 3,667.68040
Overall Steps per Second: 3,048.08628

Timestep Collection Time: 13.64568
Timestep Consumption Time: 2.77380
PPO Batch Consumption Time: 0.05273
Total Iteration Time: 16.41948

Cumulative Model Updates: 62,568
Cumulative Timesteps: 1,043,644,738

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1043644738...
Checkpoint 1043644738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049,390.12848
Policy Entropy: 1.05578
Value Function Loss: 1.35840

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.17452
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.08050

Collected Steps per Second: 3,801.02109
Overall Steps per Second: 3,134.28851

Timestep Collection Time: 13.16173
Timestep Consumption Time: 2.79979
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 15.96152

Cumulative Model Updates: 62,571
Cumulative Timesteps: 1,043,694,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304,150.71701
Policy Entropy: 1.07307
Value Function Loss: 1.27396

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.08175

Collected Steps per Second: 3,726.99077
Overall Steps per Second: 3,107.16234

Timestep Collection Time: 13.41565
Timestep Consumption Time: 2.67620
PPO Batch Consumption Time: 0.06113
Total Iteration Time: 16.09185

Cumulative Model Updates: 62,574
Cumulative Timesteps: 1,043,744,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1043744766...
Checkpoint 1043744766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496,458.28615
Policy Entropy: 1.07583
Value Function Loss: 1.26030

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 3,907.48866
Overall Steps per Second: 3,230.91034

Timestep Collection Time: 12.80464
Timestep Consumption Time: 2.68139
PPO Batch Consumption Time: 0.05228
Total Iteration Time: 15.48604

Cumulative Model Updates: 62,577
Cumulative Timesteps: 1,043,794,800

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411,878.60021
Policy Entropy: 1.05901
Value Function Loss: 1.17378

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 3,858.44541
Overall Steps per Second: 3,189.57299

Timestep Collection Time: 12.96740
Timestep Consumption Time: 2.71934
PPO Batch Consumption Time: 0.06380
Total Iteration Time: 15.68674

Cumulative Model Updates: 62,580
Cumulative Timesteps: 1,043,844,834

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1043844834...
Checkpoint 1043844834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348,077.33731
Policy Entropy: 1.04810
Value Function Loss: 1.20088

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.17371
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.06632

Collected Steps per Second: 3,748.30936
Overall Steps per Second: 3,163.58470

Timestep Collection Time: 13.33988
Timestep Consumption Time: 2.46561
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 15.80549

Cumulative Model Updates: 62,583
Cumulative Timesteps: 1,043,894,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395,858.47459
Policy Entropy: 1.05879
Value Function Loss: 1.28075

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.06963

Collected Steps per Second: 3,615.49425
Overall Steps per Second: 3,066.93447

Timestep Collection Time: 13.83545
Timestep Consumption Time: 2.47464
PPO Batch Consumption Time: 0.05375
Total Iteration Time: 16.31010

Cumulative Model Updates: 62,586
Cumulative Timesteps: 1,043,944,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1043944858...
Checkpoint 1043944858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710,967.11364
Policy Entropy: 1.06129
Value Function Loss: 1.33863

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.14409
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 3,717.10259
Overall Steps per Second: 3,113.23769

Timestep Collection Time: 13.45618
Timestep Consumption Time: 2.61005
PPO Batch Consumption Time: 0.06286
Total Iteration Time: 16.06623

Cumulative Model Updates: 62,589
Cumulative Timesteps: 1,043,994,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758,783.53592
Policy Entropy: 1.03833
Value Function Loss: 1.32053

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.08706

Collected Steps per Second: 3,696.03612
Overall Steps per Second: 3,086.35226

Timestep Collection Time: 13.53775
Timestep Consumption Time: 2.67427
PPO Batch Consumption Time: 0.05335
Total Iteration Time: 16.21202

Cumulative Model Updates: 62,592
Cumulative Timesteps: 1,044,044,912

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1044044912...
Checkpoint 1044044912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570,741.44857
Policy Entropy: 1.02394
Value Function Loss: 1.31356

Mean KL Divergence: 0.03098
SB3 Clip Fraction: 0.20675
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.08246

Collected Steps per Second: 4,014.69905
Overall Steps per Second: 3,278.11973

Timestep Collection Time: 12.45822
Timestep Consumption Time: 2.79931
PPO Batch Consumption Time: 0.05368
Total Iteration Time: 15.25753

Cumulative Model Updates: 62,595
Cumulative Timesteps: 1,044,094,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186,288.66563
Policy Entropy: 1.05175
Value Function Loss: 1.34372

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.08532

Collected Steps per Second: 3,882.50480
Overall Steps per Second: 3,167.38891

Timestep Collection Time: 12.88756
Timestep Consumption Time: 2.90968
PPO Batch Consumption Time: 0.06159
Total Iteration Time: 15.79724

Cumulative Model Updates: 62,598
Cumulative Timesteps: 1,044,144,964

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1044144964...
Checkpoint 1044144964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601,275.36775
Policy Entropy: 1.05138
Value Function Loss: 1.29802

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 3,695.49311
Overall Steps per Second: 3,112.34279

Timestep Collection Time: 13.54190
Timestep Consumption Time: 2.53731
PPO Batch Consumption Time: 0.05282
Total Iteration Time: 16.07921

Cumulative Model Updates: 62,601
Cumulative Timesteps: 1,044,195,008

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,420,329.10417
Policy Entropy: 1.04450
Value Function Loss: 1.26676

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.06572
Value Function Update Magnitude: 0.09332

Collected Steps per Second: 3,678.49741
Overall Steps per Second: 3,075.01773

Timestep Collection Time: 13.60066
Timestep Consumption Time: 2.66916
PPO Batch Consumption Time: 0.05149
Total Iteration Time: 16.26982

Cumulative Model Updates: 62,604
Cumulative Timesteps: 1,044,245,038

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1044245038...
Checkpoint 1044245038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561,367.31914
Policy Entropy: 1.02823
Value Function Loss: 1.25852

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.16698
Policy Update Magnitude: 0.07165
Value Function Update Magnitude: 0.09013

Collected Steps per Second: 3,774.53278
Overall Steps per Second: 3,132.28205

Timestep Collection Time: 13.25515
Timestep Consumption Time: 2.71787
PPO Batch Consumption Time: 0.05881
Total Iteration Time: 15.97302

Cumulative Model Updates: 62,607
Cumulative Timesteps: 1,044,295,070

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526,706.98411
Policy Entropy: 1.05093
Value Function Loss: 1.30854

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.15232
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.09338

Collected Steps per Second: 3,659.83445
Overall Steps per Second: 3,057.98662

Timestep Collection Time: 13.66291
Timestep Consumption Time: 2.68902
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 16.35194

Cumulative Model Updates: 62,610
Cumulative Timesteps: 1,044,345,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1044345074...
Checkpoint 1044345074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790,681.23512
Policy Entropy: 1.05483
Value Function Loss: 1.26231

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.08904

Collected Steps per Second: 3,740.15656
Overall Steps per Second: 3,137.93213

Timestep Collection Time: 13.37377
Timestep Consumption Time: 2.56666
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 15.94043

Cumulative Model Updates: 62,613
Cumulative Timesteps: 1,044,395,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649,548.04537
Policy Entropy: 1.03718
Value Function Loss: 1.20308

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.14594
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.08477

Collected Steps per Second: 3,764.71265
Overall Steps per Second: 3,150.46965

Timestep Collection Time: 13.29079
Timestep Consumption Time: 2.59129
PPO Batch Consumption Time: 0.05255
Total Iteration Time: 15.88208

Cumulative Model Updates: 62,616
Cumulative Timesteps: 1,044,445,130

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1044445130...
Checkpoint 1044445130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585,542.54633
Policy Entropy: 1.03548
Value Function Loss: 1.18364

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.09081

Collected Steps per Second: 3,762.21476
Overall Steps per Second: 3,124.85682

Timestep Collection Time: 13.29695
Timestep Consumption Time: 2.71210
PPO Batch Consumption Time: 0.06438
Total Iteration Time: 16.00905

Cumulative Model Updates: 62,619
Cumulative Timesteps: 1,044,495,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641,009.81853
Policy Entropy: 1.04550
Value Function Loss: 1.23592

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.09198

Collected Steps per Second: 3,815.29860
Overall Steps per Second: 3,174.98938

Timestep Collection Time: 13.11038
Timestep Consumption Time: 2.64401
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 15.75438

Cumulative Model Updates: 62,622
Cumulative Timesteps: 1,044,545,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1044545176...
Checkpoint 1044545176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,046,035.63540
Policy Entropy: 1.05471
Value Function Loss: 1.22704

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.08518

Collected Steps per Second: 4,006.02907
Overall Steps per Second: 3,289.71442

Timestep Collection Time: 12.48418
Timestep Consumption Time: 2.71835
PPO Batch Consumption Time: 0.04982
Total Iteration Time: 15.20254

Cumulative Model Updates: 62,625
Cumulative Timesteps: 1,044,595,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377,625.58383
Policy Entropy: 1.02941
Value Function Loss: 1.25201

Mean KL Divergence: 0.02761
SB3 Clip Fraction: 0.16689
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.09515

Collected Steps per Second: 4,091.46367
Overall Steps per Second: 3,402.89563

Timestep Collection Time: 12.22985
Timestep Consumption Time: 2.47468
PPO Batch Consumption Time: 0.05288
Total Iteration Time: 14.70454

Cumulative Model Updates: 62,628
Cumulative Timesteps: 1,044,645,226

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1044645226...
Checkpoint 1044645226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853,183.50069
Policy Entropy: 1.05774
Value Function Loss: 1.22006

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.17063
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.08875

Collected Steps per Second: 3,837.42111
Overall Steps per Second: 3,274.73348

Timestep Collection Time: 13.03949
Timestep Consumption Time: 2.24054
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 15.28002

Cumulative Model Updates: 62,631
Cumulative Timesteps: 1,044,695,264

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770,357.18004
Policy Entropy: 1.05159
Value Function Loss: 1.30948

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.16071
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.08791

Collected Steps per Second: 3,724.05847
Overall Steps per Second: 3,120.78081

Timestep Collection Time: 13.42836
Timestep Consumption Time: 2.59583
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 16.02419

Cumulative Model Updates: 62,634
Cumulative Timesteps: 1,044,745,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1044745272...
Checkpoint 1044745272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323,218.34846
Policy Entropy: 1.04962
Value Function Loss: 1.31893

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.06271
Value Function Update Magnitude: 0.09588

Collected Steps per Second: 3,827.79137
Overall Steps per Second: 3,150.59828

Timestep Collection Time: 13.06341
Timestep Consumption Time: 2.80786
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 15.87127

Cumulative Model Updates: 62,637
Cumulative Timesteps: 1,044,795,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604,258.97791
Policy Entropy: 1.02153
Value Function Loss: 1.36963

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.15911
Policy Update Magnitude: 0.06778
Value Function Update Magnitude: 0.08987

Collected Steps per Second: 3,816.18814
Overall Steps per Second: 3,157.20832

Timestep Collection Time: 13.11151
Timestep Consumption Time: 2.73667
PPO Batch Consumption Time: 0.05252
Total Iteration Time: 15.84818

Cumulative Model Updates: 62,640
Cumulative Timesteps: 1,044,845,312

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1044845312...
Checkpoint 1044845312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876,970.37110
Policy Entropy: 1.04769
Value Function Loss: 1.35071

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.15848
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.09072

Collected Steps per Second: 3,817.22542
Overall Steps per Second: 3,168.11778

Timestep Collection Time: 13.10009
Timestep Consumption Time: 2.68404
PPO Batch Consumption Time: 0.04719
Total Iteration Time: 15.78414

Cumulative Model Updates: 62,643
Cumulative Timesteps: 1,044,895,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405,668.53183
Policy Entropy: 1.04348
Value Function Loss: 1.39924

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.06650
Value Function Update Magnitude: 0.10294

Collected Steps per Second: 3,701.46236
Overall Steps per Second: 3,046.86677

Timestep Collection Time: 13.51898
Timestep Consumption Time: 2.90445
PPO Batch Consumption Time: 0.05906
Total Iteration Time: 16.42343

Cumulative Model Updates: 62,646
Cumulative Timesteps: 1,044,945,358

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1044945358...
Checkpoint 1044945358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245,046.36181
Policy Entropy: 1.04660
Value Function Loss: 1.40179

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.07010
Value Function Update Magnitude: 0.09943

Collected Steps per Second: 3,864.15392
Overall Steps per Second: 3,171.42917

Timestep Collection Time: 12.94307
Timestep Consumption Time: 2.82711
PPO Batch Consumption Time: 0.06403
Total Iteration Time: 15.77018

Cumulative Model Updates: 62,649
Cumulative Timesteps: 1,044,995,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,809.10001
Policy Entropy: 1.01786
Value Function Loss: 1.46833

Mean KL Divergence: 0.04227
SB3 Clip Fraction: 0.23309
Policy Update Magnitude: 0.06886
Value Function Update Magnitude: 0.08529

Collected Steps per Second: 3,781.65791
Overall Steps per Second: 3,164.58415

Timestep Collection Time: 13.22647
Timestep Consumption Time: 2.57908
PPO Batch Consumption Time: 0.05243
Total Iteration Time: 15.80555

Cumulative Model Updates: 62,652
Cumulative Timesteps: 1,045,045,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1045045390...
Checkpoint 1045045390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971,674.35322
Policy Entropy: 1.04089
Value Function Loss: 1.40725

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.15999
Policy Update Magnitude: 0.06128
Value Function Update Magnitude: 0.08416

Collected Steps per Second: 3,800.35848
Overall Steps per Second: 3,160.29565

Timestep Collection Time: 13.16086
Timestep Consumption Time: 2.66550
PPO Batch Consumption Time: 0.06411
Total Iteration Time: 15.82637

Cumulative Model Updates: 62,655
Cumulative Timesteps: 1,045,095,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288,417.86383
Policy Entropy: 1.02009
Value Function Loss: 1.47406

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.17579
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.09617

Collected Steps per Second: 3,785.35235
Overall Steps per Second: 3,189.00318

Timestep Collection Time: 13.21779
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.06169
Total Iteration Time: 15.68954

Cumulative Model Updates: 62,658
Cumulative Timesteps: 1,045,145,440

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1045145440...
Checkpoint 1045145440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733,172.61822
Policy Entropy: 1.01537
Value Function Loss: 1.44724

Mean KL Divergence: 0.02450
SB3 Clip Fraction: 0.20065
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.08929

Collected Steps per Second: 3,737.29025
Overall Steps per Second: 3,175.35198

Timestep Collection Time: 13.38724
Timestep Consumption Time: 2.36912
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 15.75636

Cumulative Model Updates: 62,661
Cumulative Timesteps: 1,045,195,472

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,397,584.37680
Policy Entropy: 1.02340
Value Function Loss: 1.43955

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.16058
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.08639

Collected Steps per Second: 3,751.46841
Overall Steps per Second: 3,123.63973

Timestep Collection Time: 13.33558
Timestep Consumption Time: 2.68035
PPO Batch Consumption Time: 0.05049
Total Iteration Time: 16.01593

Cumulative Model Updates: 62,664
Cumulative Timesteps: 1,045,245,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1045245500...
Checkpoint 1045245500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,412,328.86468
Policy Entropy: 1.03404
Value Function Loss: 1.33239

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.16977
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.08844

Collected Steps per Second: 3,881.17811
Overall Steps per Second: 3,175.35606

Timestep Collection Time: 12.88423
Timestep Consumption Time: 2.86392
PPO Batch Consumption Time: 0.06051
Total Iteration Time: 15.74816

Cumulative Model Updates: 62,667
Cumulative Timesteps: 1,045,295,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,902,254.52120
Policy Entropy: 1.02771
Value Function Loss: 1.23604

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.09325

Collected Steps per Second: 3,733.57921
Overall Steps per Second: 3,067.54711

Timestep Collection Time: 13.40376
Timestep Consumption Time: 2.91025
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 16.31401

Cumulative Model Updates: 62,670
Cumulative Timesteps: 1,045,345,550

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1045345550...
Checkpoint 1045345550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673,014.30829
Policy Entropy: 1.01036
Value Function Loss: 1.30832

Mean KL Divergence: 0.03273
SB3 Clip Fraction: 0.21557
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.10123

Collected Steps per Second: 3,879.70168
Overall Steps per Second: 3,216.74629

Timestep Collection Time: 12.89790
Timestep Consumption Time: 2.65819
PPO Batch Consumption Time: 0.04999
Total Iteration Time: 15.55609

Cumulative Model Updates: 62,673
Cumulative Timesteps: 1,045,395,590

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590,203.48226
Policy Entropy: 1.03980
Value Function Loss: 1.34687

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.16259
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.09686

Collected Steps per Second: 3,748.71464
Overall Steps per Second: 3,097.36093

Timestep Collection Time: 13.34164
Timestep Consumption Time: 2.80566
PPO Batch Consumption Time: 0.05351
Total Iteration Time: 16.14729

Cumulative Model Updates: 62,676
Cumulative Timesteps: 1,045,445,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1045445604...
Checkpoint 1045445604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,500,585.98382
Policy Entropy: 1.01381
Value Function Loss: 1.39027

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.17034
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.08953

Collected Steps per Second: 3,871.45405
Overall Steps per Second: 3,262.30453

Timestep Collection Time: 12.92331
Timestep Consumption Time: 2.41309
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 15.33640

Cumulative Model Updates: 62,679
Cumulative Timesteps: 1,045,495,636

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566,563.33139
Policy Entropy: 1.01458
Value Function Loss: 1.30703

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.15529
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.09454

Collected Steps per Second: 3,621.25719
Overall Steps per Second: 3,056.13227

Timestep Collection Time: 13.82117
Timestep Consumption Time: 2.55574
PPO Batch Consumption Time: 0.06243
Total Iteration Time: 16.37691

Cumulative Model Updates: 62,682
Cumulative Timesteps: 1,045,545,686

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1045545686...
Checkpoint 1045545686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676,316.36912
Policy Entropy: 1.02430
Value Function Loss: 1.34868

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.09524

Collected Steps per Second: 3,874.01429
Overall Steps per Second: 3,234.75551

Timestep Collection Time: 12.91838
Timestep Consumption Time: 2.55296
PPO Batch Consumption Time: 0.06100
Total Iteration Time: 15.47134

Cumulative Model Updates: 62,685
Cumulative Timesteps: 1,045,595,732

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512,131.82539
Policy Entropy: 1.03270
Value Function Loss: 1.40271

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.17186
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.09536

Collected Steps per Second: 4,092.23600
Overall Steps per Second: 3,447.47983

Timestep Collection Time: 12.22852
Timestep Consumption Time: 2.28701
PPO Batch Consumption Time: 0.04886
Total Iteration Time: 14.51553

Cumulative Model Updates: 62,688
Cumulative Timesteps: 1,045,645,774

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1045645774...
Checkpoint 1045645774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582,241.61199
Policy Entropy: 1.02299
Value Function Loss: 1.49241

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.10139

Collected Steps per Second: 4,143.20774
Overall Steps per Second: 3,429.89585

Timestep Collection Time: 12.07181
Timestep Consumption Time: 2.51056
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 14.58237

Cumulative Model Updates: 62,691
Cumulative Timesteps: 1,045,695,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527,052.15663
Policy Entropy: 1.00613
Value Function Loss: 1.48224

Mean KL Divergence: 0.02830
SB3 Clip Fraction: 0.20061
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.10663

Collected Steps per Second: 4,136.39659
Overall Steps per Second: 3,456.14073

Timestep Collection Time: 12.09217
Timestep Consumption Time: 2.38004
PPO Batch Consumption Time: 0.05406
Total Iteration Time: 14.47221

Cumulative Model Updates: 62,694
Cumulative Timesteps: 1,045,745,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1045745808...
Checkpoint 1045745808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478,337.55337
Policy Entropy: 1.03132
Value Function Loss: 1.53895

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.10650

Collected Steps per Second: 3,776.09020
Overall Steps per Second: 3,210.87388

Timestep Collection Time: 13.25074
Timestep Consumption Time: 2.33255
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 15.58330

Cumulative Model Updates: 62,697
Cumulative Timesteps: 1,045,795,844

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364,665.71839
Policy Entropy: 1.01292
Value Function Loss: 1.51056

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.11234

Collected Steps per Second: 3,666.96092
Overall Steps per Second: 3,098.55426

Timestep Collection Time: 13.64127
Timestep Consumption Time: 2.50239
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 16.14366

Cumulative Model Updates: 62,700
Cumulative Timesteps: 1,045,845,866

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1045845866...
Checkpoint 1045845866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859,687.97489
Policy Entropy: 1.00320
Value Function Loss: 1.47320

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.12029

Collected Steps per Second: 3,916.96360
Overall Steps per Second: 3,235.94899

Timestep Collection Time: 12.76703
Timestep Consumption Time: 2.68686
PPO Batch Consumption Time: 0.06156
Total Iteration Time: 15.45389

Cumulative Model Updates: 62,703
Cumulative Timesteps: 1,045,895,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,201,165.15912
Policy Entropy: 1.00619
Value Function Loss: 1.51118

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.06260
Value Function Update Magnitude: 0.11276

Collected Steps per Second: 3,632.97136
Overall Steps per Second: 3,057.15998

Timestep Collection Time: 13.76669
Timestep Consumption Time: 2.59294
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 16.35963

Cumulative Model Updates: 62,706
Cumulative Timesteps: 1,045,945,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1045945888...
Checkpoint 1045945888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911,352.81104
Policy Entropy: 1.01405
Value Function Loss: 1.54905

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.07087
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 3,925.26498
Overall Steps per Second: 3,259.06763

Timestep Collection Time: 12.74207
Timestep Consumption Time: 2.60465
PPO Batch Consumption Time: 0.05058
Total Iteration Time: 15.34672

Cumulative Model Updates: 62,709
Cumulative Timesteps: 1,045,995,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,883,275.28223
Policy Entropy: 1.01843
Value Function Loss: 1.50497

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.06951
Value Function Update Magnitude: 0.10574

Collected Steps per Second: 3,591.19328
Overall Steps per Second: 3,000.86887

Timestep Collection Time: 13.92740
Timestep Consumption Time: 2.73977
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 16.66717

Cumulative Model Updates: 62,712
Cumulative Timesteps: 1,046,045,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1046045920...
Checkpoint 1046045920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,730,450.58002
Policy Entropy: 1.03741
Value Function Loss: 1.41795

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.16659
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.09290

Collected Steps per Second: 3,799.78990
Overall Steps per Second: 3,160.11762

Timestep Collection Time: 13.16231
Timestep Consumption Time: 2.66432
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 15.82663

Cumulative Model Updates: 62,715
Cumulative Timesteps: 1,046,095,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677,510.60985
Policy Entropy: 1.03529
Value Function Loss: 1.41450

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.17008
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.08708

Collected Steps per Second: 3,676.52607
Overall Steps per Second: 3,066.26016

Timestep Collection Time: 13.60306
Timestep Consumption Time: 2.70736
PPO Batch Consumption Time: 0.05841
Total Iteration Time: 16.31042

Cumulative Model Updates: 62,718
Cumulative Timesteps: 1,046,145,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1046145946...
Checkpoint 1046145946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621,903.36193
Policy Entropy: 1.01612
Value Function Loss: 1.49390

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.16083
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.08874

Collected Steps per Second: 3,774.04054
Overall Steps per Second: 3,125.50700

Timestep Collection Time: 13.25794
Timestep Consumption Time: 2.75098
PPO Batch Consumption Time: 0.06228
Total Iteration Time: 16.00892

Cumulative Model Updates: 62,721
Cumulative Timesteps: 1,046,195,982

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794,084.17447
Policy Entropy: 1.02823
Value Function Loss: 1.50378

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.17536
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.09641

Collected Steps per Second: 3,625.63506
Overall Steps per Second: 3,038.78835

Timestep Collection Time: 13.79124
Timestep Consumption Time: 2.66335
PPO Batch Consumption Time: 0.05162
Total Iteration Time: 16.45458

Cumulative Model Updates: 62,724
Cumulative Timesteps: 1,046,245,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1046245984...
Checkpoint 1046245984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942,775.99426
Policy Entropy: 1.03999
Value Function Loss: 1.45720

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.18077
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.09113

Collected Steps per Second: 3,678.92696
Overall Steps per Second: 3,096.28403

Timestep Collection Time: 13.59309
Timestep Consumption Time: 2.55788
PPO Batch Consumption Time: 0.05004
Total Iteration Time: 16.15097

Cumulative Model Updates: 62,727
Cumulative Timesteps: 1,046,295,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603,761.95958
Policy Entropy: 1.02305
Value Function Loss: 1.40794

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.09535

Collected Steps per Second: 4,009.89868
Overall Steps per Second: 3,302.99984

Timestep Collection Time: 12.46914
Timestep Consumption Time: 2.66861
PPO Batch Consumption Time: 0.06319
Total Iteration Time: 15.13775

Cumulative Model Updates: 62,730
Cumulative Timesteps: 1,046,345,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1046345992...
Checkpoint 1046345992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864,623.91702
Policy Entropy: 1.02106
Value Function Loss: 1.47880

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.15968
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.10230

Collected Steps per Second: 3,629.73302
Overall Steps per Second: 3,088.62082

Timestep Collection Time: 13.78669
Timestep Consumption Time: 2.41536
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 16.20205

Cumulative Model Updates: 62,733
Cumulative Timesteps: 1,046,396,034

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818,750.19628
Policy Entropy: 1.03894
Value Function Loss: 1.49255

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.10381

Collected Steps per Second: 3,752.46049
Overall Steps per Second: 3,187.69253

Timestep Collection Time: 13.33365
Timestep Consumption Time: 2.36234
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 15.69599

Cumulative Model Updates: 62,736
Cumulative Timesteps: 1,046,446,068

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1046446068...
Checkpoint 1046446068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415,014.67159
Policy Entropy: 1.04212
Value Function Loss: 1.53440

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.10486

Collected Steps per Second: 3,692.20750
Overall Steps per Second: 3,127.73001

Timestep Collection Time: 13.54908
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 15.99435

Cumulative Model Updates: 62,739
Cumulative Timesteps: 1,046,496,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,312,094.74027
Policy Entropy: 1.02255
Value Function Loss: 1.48025

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.16033
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.10632

Collected Steps per Second: 3,866.57316
Overall Steps per Second: 3,246.42095

Timestep Collection Time: 12.93704
Timestep Consumption Time: 2.47132
PPO Batch Consumption Time: 0.06063
Total Iteration Time: 15.40835

Cumulative Model Updates: 62,742
Cumulative Timesteps: 1,046,546,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1046546116...
Checkpoint 1046546116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,286,847.27992
Policy Entropy: 1.01227
Value Function Loss: 1.50041

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.18641
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.09145

Collected Steps per Second: 3,656.79918
Overall Steps per Second: 3,029.01191

Timestep Collection Time: 13.68082
Timestep Consumption Time: 2.83546
PPO Batch Consumption Time: 0.04698
Total Iteration Time: 16.51628

Cumulative Model Updates: 62,745
Cumulative Timesteps: 1,046,596,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250,938.88353
Policy Entropy: 1.02670
Value Function Loss: 1.50967

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.08116

Collected Steps per Second: 3,854.61761
Overall Steps per Second: 3,171.14051

Timestep Collection Time: 12.97146
Timestep Consumption Time: 2.79574
PPO Batch Consumption Time: 0.04875
Total Iteration Time: 15.76720

Cumulative Model Updates: 62,748
Cumulative Timesteps: 1,046,646,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1046646144...
Checkpoint 1046646144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876,312.97526
Policy Entropy: 1.03681
Value Function Loss: 1.49961

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.17331
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.08146

Collected Steps per Second: 3,691.35039
Overall Steps per Second: 3,056.55408

Timestep Collection Time: 13.55168
Timestep Consumption Time: 2.81446
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 16.36614

Cumulative Model Updates: 62,751
Cumulative Timesteps: 1,046,696,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819,335.76725
Policy Entropy: 1.02578
Value Function Loss: 1.48872

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.08625

Collected Steps per Second: 3,753.08963
Overall Steps per Second: 3,112.69983

Timestep Collection Time: 13.33461
Timestep Consumption Time: 2.74339
PPO Batch Consumption Time: 0.06266
Total Iteration Time: 16.07800

Cumulative Model Updates: 62,754
Cumulative Timesteps: 1,046,746,214

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1046746214...
Checkpoint 1046746214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803,687.09530
Policy Entropy: 1.01815
Value Function Loss: 1.44150

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.16498
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.09528

Collected Steps per Second: 3,830.26690
Overall Steps per Second: 3,163.25787

Timestep Collection Time: 13.05862
Timestep Consumption Time: 2.75356
PPO Batch Consumption Time: 0.06641
Total Iteration Time: 15.81218

Cumulative Model Updates: 62,757
Cumulative Timesteps: 1,046,796,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889,120.40163
Policy Entropy: 1.03794
Value Function Loss: 1.48808

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.10286

Collected Steps per Second: 3,807.53369
Overall Steps per Second: 3,154.20972

Timestep Collection Time: 13.13501
Timestep Consumption Time: 2.72062
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 15.85564

Cumulative Model Updates: 62,760
Cumulative Timesteps: 1,046,846,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1046846244...
Checkpoint 1046846244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,598,654.28512
Policy Entropy: 1.04351
Value Function Loss: 1.59969

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.15503
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.10976

Collected Steps per Second: 3,790.12595
Overall Steps per Second: 3,181.61430

Timestep Collection Time: 13.19745
Timestep Consumption Time: 2.52413
PPO Batch Consumption Time: 0.06066
Total Iteration Time: 15.72158

Cumulative Model Updates: 62,763
Cumulative Timesteps: 1,046,896,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,974,730.54587
Policy Entropy: 1.03124
Value Function Loss: 1.66885

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.12561

Collected Steps per Second: 3,821.06677
Overall Steps per Second: 3,176.10474

Timestep Collection Time: 13.08744
Timestep Consumption Time: 2.65763
PPO Batch Consumption Time: 0.04935
Total Iteration Time: 15.74507

Cumulative Model Updates: 62,766
Cumulative Timesteps: 1,046,946,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1046946272...
Checkpoint 1046946272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865,123.14094
Policy Entropy: 1.02318
Value Function Loss: 1.69407

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.16883
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.13827

Collected Steps per Second: 3,742.25554
Overall Steps per Second: 3,084.45403

Timestep Collection Time: 13.36253
Timestep Consumption Time: 2.84974
PPO Batch Consumption Time: 0.05095
Total Iteration Time: 16.21227

Cumulative Model Updates: 62,769
Cumulative Timesteps: 1,046,996,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,784,473.56474
Policy Entropy: 1.03720
Value Function Loss: 1.65020

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.05971
Value Function Update Magnitude: 0.12624

Collected Steps per Second: 3,675.93665
Overall Steps per Second: 3,070.07045

Timestep Collection Time: 13.61014
Timestep Consumption Time: 2.68591
PPO Batch Consumption Time: 0.05254
Total Iteration Time: 16.29604

Cumulative Model Updates: 62,772
Cumulative Timesteps: 1,047,046,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1047046308...
Checkpoint 1047046308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596,399.72051
Policy Entropy: 1.04250
Value Function Loss: 1.66103

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.06338
Value Function Update Magnitude: 0.13321

Collected Steps per Second: 3,786.80811
Overall Steps per Second: 3,137.50099

Timestep Collection Time: 13.21482
Timestep Consumption Time: 2.73481
PPO Batch Consumption Time: 0.06852
Total Iteration Time: 15.94964

Cumulative Model Updates: 62,775
Cumulative Timesteps: 1,047,096,350

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589,297.89494
Policy Entropy: 1.01962
Value Function Loss: 1.67359

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.15593
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.11960

Collected Steps per Second: 3,782.61639
Overall Steps per Second: 3,152.38355

Timestep Collection Time: 13.22735
Timestep Consumption Time: 2.64445
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 15.87180

Cumulative Model Updates: 62,778
Cumulative Timesteps: 1,047,146,384

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1047146384...
Checkpoint 1047146384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602,300.58014
Policy Entropy: 1.01628
Value Function Loss: 1.68116

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.19659
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.11224

Collected Steps per Second: 3,705.40539
Overall Steps per Second: 3,128.32231

Timestep Collection Time: 13.50298
Timestep Consumption Time: 2.49090
PPO Batch Consumption Time: 0.06601
Total Iteration Time: 15.99388

Cumulative Model Updates: 62,781
Cumulative Timesteps: 1,047,196,418

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844,878.44758
Policy Entropy: 1.02804
Value Function Loss: 1.63752

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.09251

Collected Steps per Second: 3,641.00630
Overall Steps per Second: 3,073.99001

Timestep Collection Time: 13.74235
Timestep Consumption Time: 2.53486
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 16.27722

Cumulative Model Updates: 62,784
Cumulative Timesteps: 1,047,246,454

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1047246454...
Checkpoint 1047246454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604,589.07273
Policy Entropy: 1.04623
Value Function Loss: 1.61588

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.06554
Value Function Update Magnitude: 0.08364

Collected Steps per Second: 3,850.07376
Overall Steps per Second: 3,234.12868

Timestep Collection Time: 12.98988
Timestep Consumption Time: 2.47394
PPO Batch Consumption Time: 0.05284
Total Iteration Time: 15.46382

Cumulative Model Updates: 62,787
Cumulative Timesteps: 1,047,296,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,090,653.90252
Policy Entropy: 1.01632
Value Function Loss: 1.59770

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.06447
Value Function Update Magnitude: 0.08568

Collected Steps per Second: 3,844.61035
Overall Steps per Second: 3,170.02122

Timestep Collection Time: 13.01562
Timestep Consumption Time: 2.76976
PPO Batch Consumption Time: 0.06610
Total Iteration Time: 15.78538

Cumulative Model Updates: 62,790
Cumulative Timesteps: 1,047,346,506

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1047346506...
Checkpoint 1047346506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356,131.32466
Policy Entropy: 1.04284
Value Function Loss: 1.62684

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.19087
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.09966

Collected Steps per Second: 3,895.88439
Overall Steps per Second: 3,185.69321

Timestep Collection Time: 12.84073
Timestep Consumption Time: 2.86260
PPO Batch Consumption Time: 0.06171
Total Iteration Time: 15.70333

Cumulative Model Updates: 62,793
Cumulative Timesteps: 1,047,396,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562,542.18257
Policy Entropy: 1.03551
Value Function Loss: 1.61169

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.16133
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.11883

Collected Steps per Second: 3,860.07082
Overall Steps per Second: 3,187.41652

Timestep Collection Time: 12.95883
Timestep Consumption Time: 2.73476
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 15.69359

Cumulative Model Updates: 62,796
Cumulative Timesteps: 1,047,446,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1047446554...
Checkpoint 1047446554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599,669.03069
Policy Entropy: 1.03055
Value Function Loss: 1.58234

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.16539
Policy Update Magnitude: 0.06590
Value Function Update Magnitude: 0.11935

Collected Steps per Second: 3,779.10944
Overall Steps per Second: 3,121.73574

Timestep Collection Time: 13.23592
Timestep Consumption Time: 2.78721
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 16.02314

Cumulative Model Updates: 62,799
Cumulative Timesteps: 1,047,496,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755,736.02691
Policy Entropy: 1.01244
Value Function Loss: 1.67311

Mean KL Divergence: 0.03989
SB3 Clip Fraction: 0.22547
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.12557

Collected Steps per Second: 3,876.95010
Overall Steps per Second: 3,181.67712

Timestep Collection Time: 12.90189
Timestep Consumption Time: 2.81937
PPO Batch Consumption Time: 0.06647
Total Iteration Time: 15.72127

Cumulative Model Updates: 62,802
Cumulative Timesteps: 1,047,546,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1047546594...
Checkpoint 1047546594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,319,836.56402
Policy Entropy: 1.04812
Value Function Loss: 1.68516

Mean KL Divergence: 0.03599
SB3 Clip Fraction: 0.22689
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.12496

Collected Steps per Second: 3,680.23643
Overall Steps per Second: 3,074.75451

Timestep Collection Time: 13.58663
Timestep Consumption Time: 2.67548
PPO Batch Consumption Time: 0.06171
Total Iteration Time: 16.26211

Cumulative Model Updates: 62,805
Cumulative Timesteps: 1,047,596,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,106,257.21746
Policy Entropy: 1.01340
Value Function Loss: 1.71539

Mean KL Divergence: 0.03539
SB3 Clip Fraction: 0.21278
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.12374

Collected Steps per Second: 3,724.87317
Overall Steps per Second: 3,103.79341

Timestep Collection Time: 13.43294
Timestep Consumption Time: 2.68798
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 16.12092

Cumulative Model Updates: 62,808
Cumulative Timesteps: 1,047,646,632

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1047646632...
Checkpoint 1047646632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632,418.61128
Policy Entropy: 1.02947
Value Function Loss: 1.64946

Mean KL Divergence: 0.02408
SB3 Clip Fraction: 0.16334
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 3,676.12369
Overall Steps per Second: 3,102.28150

Timestep Collection Time: 13.61216
Timestep Consumption Time: 2.51790
PPO Batch Consumption Time: 0.05780
Total Iteration Time: 16.13006

Cumulative Model Updates: 62,811
Cumulative Timesteps: 1,047,696,672

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317,729.15203
Policy Entropy: 1.02546
Value Function Loss: 1.66390

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.15623
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.11040

Collected Steps per Second: 3,751.62471
Overall Steps per Second: 3,150.29209

Timestep Collection Time: 13.32863
Timestep Consumption Time: 2.54419
PPO Batch Consumption Time: 0.05764
Total Iteration Time: 15.87281

Cumulative Model Updates: 62,814
Cumulative Timesteps: 1,047,746,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1047746676...
Checkpoint 1047746676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413,960.28560
Policy Entropy: 1.02678
Value Function Loss: 1.67830

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.06683
Value Function Update Magnitude: 0.09422

Collected Steps per Second: 3,845.00490
Overall Steps per Second: 3,215.40336

Timestep Collection Time: 13.01429
Timestep Consumption Time: 2.54830
PPO Batch Consumption Time: 0.05928
Total Iteration Time: 15.56259

Cumulative Model Updates: 62,817
Cumulative Timesteps: 1,047,796,716

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431,643.38748
Policy Entropy: 1.01392
Value Function Loss: 1.68468

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.18232
Policy Update Magnitude: 0.06538
Value Function Update Magnitude: 0.09862

Collected Steps per Second: 3,835.56478
Overall Steps per Second: 3,190.78411

Timestep Collection Time: 13.04267
Timestep Consumption Time: 2.63561
PPO Batch Consumption Time: 0.04782
Total Iteration Time: 15.67828

Cumulative Model Updates: 62,820
Cumulative Timesteps: 1,047,846,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1047846742...
Checkpoint 1047846742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486,611.55707
Policy Entropy: 1.03993
Value Function Loss: 1.64671

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.09102

Collected Steps per Second: 3,793.62999
Overall Steps per Second: 3,129.39265

Timestep Collection Time: 13.18210
Timestep Consumption Time: 2.79800
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 15.98010

Cumulative Model Updates: 62,823
Cumulative Timesteps: 1,047,896,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716,627.97718
Policy Entropy: 1.04071
Value Function Loss: 1.60255

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.09224

Collected Steps per Second: 4,037.24908
Overall Steps per Second: 3,297.34715

Timestep Collection Time: 12.38517
Timestep Consumption Time: 2.77915
PPO Batch Consumption Time: 0.04936
Total Iteration Time: 15.16431

Cumulative Model Updates: 62,826
Cumulative Timesteps: 1,047,946,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1047946752...
Checkpoint 1047946752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073,985.87799
Policy Entropy: 1.04057
Value Function Loss: 1.52153

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.06246
Value Function Update Magnitude: 0.09873

Collected Steps per Second: 4,026.71981
Overall Steps per Second: 3,297.01821

Timestep Collection Time: 12.42202
Timestep Consumption Time: 2.74926
PPO Batch Consumption Time: 0.04693
Total Iteration Time: 15.17128

Cumulative Model Updates: 62,829
Cumulative Timesteps: 1,047,996,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653,846.52942
Policy Entropy: 1.02631
Value Function Loss: 1.51301

Mean KL Divergence: 0.03176
SB3 Clip Fraction: 0.21191
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.10639

Collected Steps per Second: 4,063.08011
Overall Steps per Second: 3,326.05534

Timestep Collection Time: 12.31283
Timestep Consumption Time: 2.72841
PPO Batch Consumption Time: 0.05152
Total Iteration Time: 15.04124

Cumulative Model Updates: 62,832
Cumulative Timesteps: 1,048,046,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1048046800...
Checkpoint 1048046800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,353,880.84214
Policy Entropy: 1.05961
Value Function Loss: 1.51857

Mean KL Divergence: 0.03120
SB3 Clip Fraction: 0.20463
Policy Update Magnitude: 0.06395
Value Function Update Magnitude: 0.10617

Collected Steps per Second: 4,029.79891
Overall Steps per Second: 3,324.50703

Timestep Collection Time: 12.40856
Timestep Consumption Time: 2.63247
PPO Batch Consumption Time: 0.06151
Total Iteration Time: 15.04103

Cumulative Model Updates: 62,835
Cumulative Timesteps: 1,048,096,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517,796.86244
Policy Entropy: 1.02681
Value Function Loss: 1.49820

Mean KL Divergence: 0.02801
SB3 Clip Fraction: 0.18056
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.11031

Collected Steps per Second: 3,847.44737
Overall Steps per Second: 3,244.84044

Timestep Collection Time: 13.00083
Timestep Consumption Time: 2.41441
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 15.41524

Cumulative Model Updates: 62,838
Cumulative Timesteps: 1,048,146,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1048146824...
Checkpoint 1048146824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,657,779.92714
Policy Entropy: 1.04700
Value Function Loss: 1.53476

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.17494
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.10412

Collected Steps per Second: 3,726.17253
Overall Steps per Second: 3,150.90882

Timestep Collection Time: 13.42021
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.04976
Total Iteration Time: 15.87034

Cumulative Model Updates: 62,841
Cumulative Timesteps: 1,048,196,830

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445,629.49168
Policy Entropy: 1.04149
Value Function Loss: 1.51008

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.16492
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.09352

Collected Steps per Second: 3,869.74924
Overall Steps per Second: 3,212.65636

Timestep Collection Time: 12.92332
Timestep Consumption Time: 2.64324
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 15.56656

Cumulative Model Updates: 62,844
Cumulative Timesteps: 1,048,246,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1048246840...
Checkpoint 1048246840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635,258.33050
Policy Entropy: 1.03321
Value Function Loss: 1.53671

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.15028
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.09204

Collected Steps per Second: 3,812.67095
Overall Steps per Second: 3,178.62926

Timestep Collection Time: 13.12308
Timestep Consumption Time: 2.61766
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 15.74075

Cumulative Model Updates: 62,847
Cumulative Timesteps: 1,048,296,874

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373,753.06148
Policy Entropy: 1.02740
Value Function Loss: 1.61062

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.18014
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.08621

Collected Steps per Second: 3,832.52011
Overall Steps per Second: 3,234.10217

Timestep Collection Time: 13.05616
Timestep Consumption Time: 2.41583
PPO Batch Consumption Time: 0.04992
Total Iteration Time: 15.47199

Cumulative Model Updates: 62,850
Cumulative Timesteps: 1,048,346,912

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1048346912...
Checkpoint 1048346912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391,686.24482
Policy Entropy: 1.03901
Value Function Loss: 1.66579

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.10795

Collected Steps per Second: 3,945.18110
Overall Steps per Second: 3,304.00031

Timestep Collection Time: 12.67977
Timestep Consumption Time: 2.46066
PPO Batch Consumption Time: 0.05838
Total Iteration Time: 15.14043

Cumulative Model Updates: 62,853
Cumulative Timesteps: 1,048,396,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733,968.08795
Policy Entropy: 1.04605
Value Function Loss: 1.65186

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.16871
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.11478

Collected Steps per Second: 3,842.23866
Overall Steps per Second: 3,202.79015

Timestep Collection Time: 13.02001
Timestep Consumption Time: 2.59949
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 15.61951

Cumulative Model Updates: 62,856
Cumulative Timesteps: 1,048,446,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1048446962...
Checkpoint 1048446962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707,289.90605
Policy Entropy: 1.02030
Value Function Loss: 1.64832

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.10800

Collected Steps per Second: 3,762.91197
Overall Steps per Second: 3,132.16452

Timestep Collection Time: 13.29715
Timestep Consumption Time: 2.67775
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 15.97490

Cumulative Model Updates: 62,859
Cumulative Timesteps: 1,048,496,998

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,866,366.69547
Policy Entropy: 1.03664
Value Function Loss: 1.60987

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.15544
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.10174

Collected Steps per Second: 3,720.04047
Overall Steps per Second: 3,078.79004

Timestep Collection Time: 13.44286
Timestep Consumption Time: 2.79988
PPO Batch Consumption Time: 0.05399
Total Iteration Time: 16.24274

Cumulative Model Updates: 62,862
Cumulative Timesteps: 1,048,547,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1048547006...
Checkpoint 1048547006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831,099.55484
Policy Entropy: 1.04799
Value Function Loss: 1.62150

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.18915
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.09874

Collected Steps per Second: 3,754.35928
Overall Steps per Second: 3,175.74349

Timestep Collection Time: 13.32318
Timestep Consumption Time: 2.42746
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 15.75064

Cumulative Model Updates: 62,865
Cumulative Timesteps: 1,048,597,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672,784.18776
Policy Entropy: 1.03533
Value Function Loss: 1.54027

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.09825

Collected Steps per Second: 3,836.49623
Overall Steps per Second: 3,179.49243

Timestep Collection Time: 13.03794
Timestep Consumption Time: 2.69413
PPO Batch Consumption Time: 0.05197
Total Iteration Time: 15.73207

Cumulative Model Updates: 62,868
Cumulative Timesteps: 1,048,647,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1048647046...
Checkpoint 1048647046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202,957.81489
Policy Entropy: 1.03476
Value Function Loss: 1.61888

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.10384

Collected Steps per Second: 3,840.01503
Overall Steps per Second: 3,233.91573

Timestep Collection Time: 13.02964
Timestep Consumption Time: 2.44201
PPO Batch Consumption Time: 0.06328
Total Iteration Time: 15.47165

Cumulative Model Updates: 62,871
Cumulative Timesteps: 1,048,697,080

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,345,159.98735
Policy Entropy: 1.04781
Value Function Loss: 1.59749

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.06197
Value Function Update Magnitude: 0.11995

Collected Steps per Second: 3,793.83022
Overall Steps per Second: 3,191.16313

Timestep Collection Time: 13.18298
Timestep Consumption Time: 2.48967
PPO Batch Consumption Time: 0.04965
Total Iteration Time: 15.67266

Cumulative Model Updates: 62,874
Cumulative Timesteps: 1,048,747,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1048747094...
Checkpoint 1048747094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427,659.72044
Policy Entropy: 1.05879
Value Function Loss: 1.64874

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.17012
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.11237

Collected Steps per Second: 3,745.77178
Overall Steps per Second: 3,180.78613

Timestep Collection Time: 13.34892
Timestep Consumption Time: 2.37110
PPO Batch Consumption Time: 0.05769
Total Iteration Time: 15.72001

Cumulative Model Updates: 62,877
Cumulative Timesteps: 1,048,797,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085,610.64716
Policy Entropy: 1.03432
Value Function Loss: 1.58066

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.15199
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.10532

Collected Steps per Second: 3,793.11536
Overall Steps per Second: 3,164.18168

Timestep Collection Time: 13.18494
Timestep Consumption Time: 2.62073
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 15.80567

Cumulative Model Updates: 62,880
Cumulative Timesteps: 1,048,847,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1048847108...
Checkpoint 1048847108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541,558.98788
Policy Entropy: 1.05050
Value Function Loss: 1.64191

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.17058
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.10702

Collected Steps per Second: 3,829.68652
Overall Steps per Second: 3,129.38012

Timestep Collection Time: 13.05903
Timestep Consumption Time: 2.92241
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 15.98144

Cumulative Model Updates: 62,883
Cumulative Timesteps: 1,048,897,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389,667.64397
Policy Entropy: 1.05620
Value Function Loss: 1.57936

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.17493
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.09782

Collected Steps per Second: 3,797.82379
Overall Steps per Second: 3,142.73681

Timestep Collection Time: 13.16859
Timestep Consumption Time: 2.74492
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 15.91352

Cumulative Model Updates: 62,886
Cumulative Timesteps: 1,048,947,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1048947132...
Checkpoint 1048947132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728,107.27900
Policy Entropy: 1.04485
Value Function Loss: 1.59645

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.14333
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.10266

Collected Steps per Second: 3,930.07891
Overall Steps per Second: 3,239.38976

Timestep Collection Time: 12.72748
Timestep Consumption Time: 2.71370
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 15.44118

Cumulative Model Updates: 62,889
Cumulative Timesteps: 1,048,997,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172,367.78107
Policy Entropy: 1.02943
Value Function Loss: 1.61929

Mean KL Divergence: 0.02752
SB3 Clip Fraction: 0.19818
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.10388

Collected Steps per Second: 3,767.85694
Overall Steps per Second: 3,142.56353

Timestep Collection Time: 13.27227
Timestep Consumption Time: 2.64086
PPO Batch Consumption Time: 0.04953
Total Iteration Time: 15.91312

Cumulative Model Updates: 62,892
Cumulative Timesteps: 1,049,047,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1049047160...
Checkpoint 1049047160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574,609.52388
Policy Entropy: 1.04970
Value Function Loss: 1.69697

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.06182
Value Function Update Magnitude: 0.10101

Collected Steps per Second: 3,980.31139
Overall Steps per Second: 3,279.93452

Timestep Collection Time: 12.57238
Timestep Consumption Time: 2.68463
PPO Batch Consumption Time: 0.06141
Total Iteration Time: 15.25701

Cumulative Model Updates: 62,895
Cumulative Timesteps: 1,049,097,202

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413,482.99341
Policy Entropy: 1.04430
Value Function Loss: 1.67613

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.06216
Value Function Update Magnitude: 0.09374

Collected Steps per Second: 3,699.42605
Overall Steps per Second: 3,085.01624

Timestep Collection Time: 13.52696
Timestep Consumption Time: 2.69402
PPO Batch Consumption Time: 0.06090
Total Iteration Time: 16.22098

Cumulative Model Updates: 62,898
Cumulative Timesteps: 1,049,147,244

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1049147244...
Checkpoint 1049147244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776,975.27978
Policy Entropy: 1.02974
Value Function Loss: 1.67435

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.07152
Value Function Update Magnitude: 0.09866

Collected Steps per Second: 3,930.94208
Overall Steps per Second: 3,251.98656

Timestep Collection Time: 12.72672
Timestep Consumption Time: 2.65711
PPO Batch Consumption Time: 0.05946
Total Iteration Time: 15.38383

Cumulative Model Updates: 62,901
Cumulative Timesteps: 1,049,197,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771,475.61250
Policy Entropy: 1.05241
Value Function Loss: 1.65390

Mean KL Divergence: 0.02958
SB3 Clip Fraction: 0.18743
Policy Update Magnitude: 0.06241
Value Function Update Magnitude: 0.09974

Collected Steps per Second: 3,703.55168
Overall Steps per Second: 3,104.43145

Timestep Collection Time: 13.50433
Timestep Consumption Time: 2.60618
PPO Batch Consumption Time: 0.06249
Total Iteration Time: 16.11052

Cumulative Model Updates: 62,904
Cumulative Timesteps: 1,049,247,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1049247286...
Checkpoint 1049247286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122,595.24262
Policy Entropy: 1.04819
Value Function Loss: 1.63607

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.16731
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.10739

Collected Steps per Second: 3,858.95415
Overall Steps per Second: 3,263.12200

Timestep Collection Time: 12.96258
Timestep Consumption Time: 2.36691
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 15.32949

Cumulative Model Updates: 62,907
Cumulative Timesteps: 1,049,297,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488,830.86853
Policy Entropy: 1.04037
Value Function Loss: 1.54814

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.06030
Value Function Update Magnitude: 0.12396

Collected Steps per Second: 3,588.44871
Overall Steps per Second: 3,076.66271

Timestep Collection Time: 13.94474
Timestep Consumption Time: 2.31963
PPO Batch Consumption Time: 0.05012
Total Iteration Time: 16.26438

Cumulative Model Updates: 62,910
Cumulative Timesteps: 1,049,347,348

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1049347348...
Checkpoint 1049347348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468,874.22988
Policy Entropy: 1.01648
Value Function Loss: 1.53717

Mean KL Divergence: 0.03304
SB3 Clip Fraction: 0.19811
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.13539

Collected Steps per Second: 3,682.78225
Overall Steps per Second: 3,115.17504

Timestep Collection Time: 13.58049
Timestep Consumption Time: 2.47446
PPO Batch Consumption Time: 0.06535
Total Iteration Time: 16.05496

Cumulative Model Updates: 62,913
Cumulative Timesteps: 1,049,397,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,671,324.59656
Policy Entropy: 1.03734
Value Function Loss: 1.56749

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13716
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.14177

Collected Steps per Second: 3,661.00170
Overall Steps per Second: 3,063.84018

Timestep Collection Time: 13.65965
Timestep Consumption Time: 2.66235
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 16.32200

Cumulative Model Updates: 62,916
Cumulative Timesteps: 1,049,447,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1049447370...
Checkpoint 1049447370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,784,411.47760
Policy Entropy: 1.03976
Value Function Loss: 1.54224

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.13867

Collected Steps per Second: 3,717.12586
Overall Steps per Second: 3,082.47051

Timestep Collection Time: 13.46094
Timestep Consumption Time: 2.77150
PPO Batch Consumption Time: 0.05301
Total Iteration Time: 16.23243

Cumulative Model Updates: 62,919
Cumulative Timesteps: 1,049,497,406

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689,045.64609
Policy Entropy: 1.03230
Value Function Loss: 1.52803

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.07077
Value Function Update Magnitude: 0.12080

Collected Steps per Second: 3,796.69951
Overall Steps per Second: 3,193.26448

Timestep Collection Time: 13.17671
Timestep Consumption Time: 2.49002
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 15.66673

Cumulative Model Updates: 62,922
Cumulative Timesteps: 1,049,547,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1049547434...
Checkpoint 1049547434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164,569.92072
Policy Entropy: 1.02329
Value Function Loss: 1.55656

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.15484
Policy Update Magnitude: 0.07065
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 3,740.06830
Overall Steps per Second: 3,111.02211

Timestep Collection Time: 13.38050
Timestep Consumption Time: 2.70553
PPO Batch Consumption Time: 0.05816
Total Iteration Time: 16.08603

Cumulative Model Updates: 62,925
Cumulative Timesteps: 1,049,597,478

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608,180.50819
Policy Entropy: 1.03690
Value Function Loss: 1.63562

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.09336

Collected Steps per Second: 4,050.43394
Overall Steps per Second: 3,332.88072

Timestep Collection Time: 12.34781
Timestep Consumption Time: 2.65842
PPO Batch Consumption Time: 0.04970
Total Iteration Time: 15.00624

Cumulative Model Updates: 62,928
Cumulative Timesteps: 1,049,647,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1049647492...
Checkpoint 1049647492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621,982.12932
Policy Entropy: 1.05313
Value Function Loss: 1.61593

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.15842
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.10816

Collected Steps per Second: 4,226.97068
Overall Steps per Second: 3,472.81572

Timestep Collection Time: 11.83353
Timestep Consumption Time: 2.56976
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 14.40330

Cumulative Model Updates: 62,931
Cumulative Timesteps: 1,049,697,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879,353.86517
Policy Entropy: 1.03484
Value Function Loss: 1.59985

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14820
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.14166

Collected Steps per Second: 3,772.39057
Overall Steps per Second: 3,151.91739

Timestep Collection Time: 13.26162
Timestep Consumption Time: 2.61063
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 15.87224

Cumulative Model Updates: 62,934
Cumulative Timesteps: 1,049,747,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1049747540...
Checkpoint 1049747540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,737,184.55478
Policy Entropy: 1.02755
Value Function Loss: 1.57257

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.16875
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.14688

Collected Steps per Second: 3,755.45397
Overall Steps per Second: 3,134.39078

Timestep Collection Time: 13.32196
Timestep Consumption Time: 2.63968
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 15.96163

Cumulative Model Updates: 62,937
Cumulative Timesteps: 1,049,797,570

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667,930.87440
Policy Entropy: 1.03099
Value Function Loss: 1.65775

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.13048

Collected Steps per Second: 3,865.10529
Overall Steps per Second: 3,209.60833

Timestep Collection Time: 12.94040
Timestep Consumption Time: 2.64281
PPO Batch Consumption Time: 0.05809
Total Iteration Time: 15.58321

Cumulative Model Updates: 62,940
Cumulative Timesteps: 1,049,847,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1049847586...
Checkpoint 1049847586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682,775.20320
Policy Entropy: 1.04150
Value Function Loss: 1.64617

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.17015
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.10913

Collected Steps per Second: 3,797.31063
Overall Steps per Second: 3,206.69707

Timestep Collection Time: 13.17511
Timestep Consumption Time: 2.42661
PPO Batch Consumption Time: 0.06589
Total Iteration Time: 15.60172

Cumulative Model Updates: 62,943
Cumulative Timesteps: 1,049,897,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638,613.27791
Policy Entropy: 1.03479
Value Function Loss: 1.65273

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.09769

Collected Steps per Second: 3,701.31887
Overall Steps per Second: 3,094.00191

Timestep Collection Time: 13.51410
Timestep Consumption Time: 2.65266
PPO Batch Consumption Time: 0.06755
Total Iteration Time: 16.16676

Cumulative Model Updates: 62,946
Cumulative Timesteps: 1,049,947,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1049947636...
Checkpoint 1049947636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700,297.73899
Policy Entropy: 1.02805
Value Function Loss: 1.62128

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.17417
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.09523

Collected Steps per Second: 3,680.27714
Overall Steps per Second: 3,110.84322

Timestep Collection Time: 13.59245
Timestep Consumption Time: 2.48807
PPO Batch Consumption Time: 0.06744
Total Iteration Time: 16.08053

Cumulative Model Updates: 62,949
Cumulative Timesteps: 1,049,997,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673,960.12946
Policy Entropy: 1.03821
Value Function Loss: 1.57695

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.10743

Collected Steps per Second: 3,980.50332
Overall Steps per Second: 3,286.60061

Timestep Collection Time: 12.56776
Timestep Consumption Time: 2.65344
PPO Batch Consumption Time: 0.06134
Total Iteration Time: 15.22120

Cumulative Model Updates: 62,952
Cumulative Timesteps: 1,050,047,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1050047686...
Checkpoint 1050047686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548,851.28866
Policy Entropy: 1.04428
Value Function Loss: 1.55887

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.15932
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.10435

Collected Steps per Second: 3,729.55791
Overall Steps per Second: 3,121.62790

Timestep Collection Time: 13.41124
Timestep Consumption Time: 2.61181
PPO Batch Consumption Time: 0.05142
Total Iteration Time: 16.02305

Cumulative Model Updates: 62,955
Cumulative Timesteps: 1,050,097,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672,540.02621
Policy Entropy: 1.02419
Value Function Loss: 1.52785

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.06251
Value Function Update Magnitude: 0.09523

Collected Steps per Second: 3,716.75997
Overall Steps per Second: 3,068.65764

Timestep Collection Time: 13.45688
Timestep Consumption Time: 2.84210
PPO Batch Consumption Time: 0.05994
Total Iteration Time: 16.29898

Cumulative Model Updates: 62,958
Cumulative Timesteps: 1,050,147,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1050147720...
Checkpoint 1050147720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384,115.83988
Policy Entropy: 1.01448
Value Function Loss: 1.63597

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.15934
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.08687

Collected Steps per Second: 3,700.34286
Overall Steps per Second: 3,091.16462

Timestep Collection Time: 13.51713
Timestep Consumption Time: 2.66383
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 16.18096

Cumulative Model Updates: 62,961
Cumulative Timesteps: 1,050,197,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415,546.15883
Policy Entropy: 1.03955
Value Function Loss: 1.64775

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.08993

Collected Steps per Second: 3,831.49995
Overall Steps per Second: 3,191.33792

Timestep Collection Time: 13.04972
Timestep Consumption Time: 2.61769
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 15.66741

Cumulative Model Updates: 62,964
Cumulative Timesteps: 1,050,247,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1050247738...
Checkpoint 1050247738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,913,603.88449
Policy Entropy: 1.04198
Value Function Loss: 1.64889

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.15863
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.11136

Collected Steps per Second: 3,791.59518
Overall Steps per Second: 3,201.09336

Timestep Collection Time: 13.19339
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.04941
Total Iteration Time: 15.62716

Cumulative Model Updates: 62,967
Cumulative Timesteps: 1,050,297,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596,406.55478
Policy Entropy: 1.02321
Value Function Loss: 1.59303

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.12606

Collected Steps per Second: 3,947.97488
Overall Steps per Second: 3,301.93171

Timestep Collection Time: 12.66928
Timestep Consumption Time: 2.47882
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 15.14810

Cumulative Model Updates: 62,970
Cumulative Timesteps: 1,050,347,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1050347780...
Checkpoint 1050347780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156,086.25155
Policy Entropy: 1.00595
Value Function Loss: 1.58675

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.20447
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.13451

Collected Steps per Second: 3,719.63305
Overall Steps per Second: 3,100.82664

Timestep Collection Time: 13.44971
Timestep Consumption Time: 2.68405
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 16.13376

Cumulative Model Updates: 62,973
Cumulative Timesteps: 1,050,397,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,253,871.37344
Policy Entropy: 1.02254
Value Function Loss: 1.58582

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.14087

Collected Steps per Second: 3,684.09352
Overall Steps per Second: 3,081.34048

Timestep Collection Time: 13.57620
Timestep Consumption Time: 2.65569
PPO Batch Consumption Time: 0.06241
Total Iteration Time: 16.23190

Cumulative Model Updates: 62,976
Cumulative Timesteps: 1,050,447,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1050447824...
Checkpoint 1050447824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956,329.77498
Policy Entropy: 1.03288
Value Function Loss: 1.58180

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.13421

Collected Steps per Second: 3,768.64987
Overall Steps per Second: 3,146.73251

Timestep Collection Time: 13.27903
Timestep Consumption Time: 2.62445
PPO Batch Consumption Time: 0.05258
Total Iteration Time: 15.90348

Cumulative Model Updates: 62,979
Cumulative Timesteps: 1,050,497,868

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,977,011.58982
Policy Entropy: 1.02304
Value Function Loss: 1.52315

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 3,790.35370
Overall Steps per Second: 3,156.54787

Timestep Collection Time: 13.19930
Timestep Consumption Time: 2.65030
PPO Batch Consumption Time: 0.05814
Total Iteration Time: 15.84959

Cumulative Model Updates: 62,982
Cumulative Timesteps: 1,050,547,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1050547898...
Checkpoint 1050547898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,094,712.46487
Policy Entropy: 1.00562
Value Function Loss: 1.57242

Mean KL Divergence: 0.02874
SB3 Clip Fraction: 0.19192
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.10755

Collected Steps per Second: 3,832.02965
Overall Steps per Second: 3,176.44790

Timestep Collection Time: 13.05313
Timestep Consumption Time: 2.69401
PPO Batch Consumption Time: 0.05789
Total Iteration Time: 15.74715

Cumulative Model Updates: 62,985
Cumulative Timesteps: 1,050,597,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,691,568.19811
Policy Entropy: 1.02011
Value Function Loss: 1.58825

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.10386

Collected Steps per Second: 3,847.97786
Overall Steps per Second: 3,251.25447

Timestep Collection Time: 12.99540
Timestep Consumption Time: 2.38513
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 15.38052

Cumulative Model Updates: 62,988
Cumulative Timesteps: 1,050,647,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1050647924...
Checkpoint 1050647924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564,921.34874
Policy Entropy: 1.03397
Value Function Loss: 1.66140

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.06383
Value Function Update Magnitude: 0.09552

Collected Steps per Second: 3,752.57508
Overall Steps per Second: 3,174.85595

Timestep Collection Time: 13.32525
Timestep Consumption Time: 2.42476
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 15.75001

Cumulative Model Updates: 62,991
Cumulative Timesteps: 1,050,697,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587,552.47611
Policy Entropy: 1.01006
Value Function Loss: 1.56951

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.15191
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.09527

Collected Steps per Second: 3,799.85394
Overall Steps per Second: 3,137.39225

Timestep Collection Time: 13.16735
Timestep Consumption Time: 2.78029
PPO Batch Consumption Time: 0.06679
Total Iteration Time: 15.94764

Cumulative Model Updates: 62,994
Cumulative Timesteps: 1,050,747,962

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1050747962...
Checkpoint 1050747962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209,992.66376
Policy Entropy: 1.01996
Value Function Loss: 1.57376

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.15222
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.10525

Collected Steps per Second: 3,787.13835
Overall Steps per Second: 3,138.05568

Timestep Collection Time: 13.20786
Timestep Consumption Time: 2.73194
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 15.93981

Cumulative Model Updates: 62,997
Cumulative Timesteps: 1,050,797,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760,147.41457
Policy Entropy: 1.03128
Value Function Loss: 1.57824

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.10411

Collected Steps per Second: 3,793.36475
Overall Steps per Second: 3,133.90157

Timestep Collection Time: 13.18407
Timestep Consumption Time: 2.77431
PPO Batch Consumption Time: 0.05990
Total Iteration Time: 15.95838

Cumulative Model Updates: 63,000
Cumulative Timesteps: 1,050,847,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1050847994...
Checkpoint 1050847994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546,502.61780
Policy Entropy: 1.04626
Value Function Loss: 1.62543

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.06478
Value Function Update Magnitude: 0.09474

Collected Steps per Second: 3,816.91776
Overall Steps per Second: 3,140.58377

Timestep Collection Time: 13.10796
Timestep Consumption Time: 2.82284
PPO Batch Consumption Time: 0.05282
Total Iteration Time: 15.93080

Cumulative Model Updates: 63,003
Cumulative Timesteps: 1,050,898,026

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718,874.28385
Policy Entropy: 1.02461
Value Function Loss: 1.59107

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.16387
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.09998

Collected Steps per Second: 3,701.08177
Overall Steps per Second: 3,131.46875

Timestep Collection Time: 13.52253
Timestep Consumption Time: 2.45974
PPO Batch Consumption Time: 0.06699
Total Iteration Time: 15.98228

Cumulative Model Updates: 63,006
Cumulative Timesteps: 1,050,948,074

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1050948074...
Checkpoint 1050948074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821,558.07072
Policy Entropy: 1.01442
Value Function Loss: 1.51583

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.18490
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.10707

Collected Steps per Second: 3,898.94828
Overall Steps per Second: 3,256.74533

Timestep Collection Time: 12.83731
Timestep Consumption Time: 2.53141
PPO Batch Consumption Time: 0.05381
Total Iteration Time: 15.36872

Cumulative Model Updates: 63,009
Cumulative Timesteps: 1,050,998,126

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641,308.84132
Policy Entropy: 1.02908
Value Function Loss: 1.58287

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.11278

Collected Steps per Second: 3,712.20536
Overall Steps per Second: 3,092.33215

Timestep Collection Time: 13.47124
Timestep Consumption Time: 2.70038
PPO Batch Consumption Time: 0.06017
Total Iteration Time: 16.17161

Cumulative Model Updates: 63,012
Cumulative Timesteps: 1,051,048,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1051048134...
Checkpoint 1051048134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,893,203.34327
Policy Entropy: 1.03978
Value Function Loss: 1.58598

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.17109
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 3,882.00201
Overall Steps per Second: 3,253.12262

Timestep Collection Time: 12.88150
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 15.37169

Cumulative Model Updates: 63,015
Cumulative Timesteps: 1,051,098,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522,257.99926
Policy Entropy: 1.01814
Value Function Loss: 1.70232

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.12608

Collected Steps per Second: 3,841.26912
Overall Steps per Second: 3,223.33307

Timestep Collection Time: 13.02955
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.05387
Total Iteration Time: 15.52741

Cumulative Model Updates: 63,018
Cumulative Timesteps: 1,051,148,190

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1051148190...
Checkpoint 1051148190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114,529.81788
Policy Entropy: 1.01094
Value Function Loss: 1.55292

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.17045
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.12353

Collected Steps per Second: 3,815.09491
Overall Steps per Second: 3,199.26372

Timestep Collection Time: 13.11632
Timestep Consumption Time: 2.52478
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 15.64110

Cumulative Model Updates: 63,021
Cumulative Timesteps: 1,051,198,230

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447,934.72974
Policy Entropy: 1.02647
Value Function Loss: 1.55968

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.11918

Collected Steps per Second: 3,720.41969
Overall Steps per Second: 3,166.85879

Timestep Collection Time: 13.43934
Timestep Consumption Time: 2.34917
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 15.78852

Cumulative Model Updates: 63,024
Cumulative Timesteps: 1,051,248,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1051248230...
Checkpoint 1051248230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,944,322.05478
Policy Entropy: 1.04188
Value Function Loss: 1.40356

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.17160
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 3,741.29612
Overall Steps per Second: 3,088.38639

Timestep Collection Time: 13.36756
Timestep Consumption Time: 2.82601
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 16.19357

Cumulative Model Updates: 63,027
Cumulative Timesteps: 1,051,298,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412,020.42833
Policy Entropy: 1.02377
Value Function Loss: 1.44189

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.11813

Collected Steps per Second: 3,734.29371
Overall Steps per Second: 3,121.70903

Timestep Collection Time: 13.40066
Timestep Consumption Time: 2.62966
PPO Batch Consumption Time: 0.04739
Total Iteration Time: 16.03032

Cumulative Model Updates: 63,030
Cumulative Timesteps: 1,051,348,284

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1051348284...
Checkpoint 1051348284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,776,831.34772
Policy Entropy: 1.02055
Value Function Loss: 1.41475

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.17364
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.10777

Collected Steps per Second: 3,683.64996
Overall Steps per Second: 3,065.36714

Timestep Collection Time: 13.58272
Timestep Consumption Time: 2.73963
PPO Batch Consumption Time: 0.05266
Total Iteration Time: 16.32235

Cumulative Model Updates: 63,033
Cumulative Timesteps: 1,051,398,318

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643,165.87517
Policy Entropy: 1.03166
Value Function Loss: 1.46890

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.09722

Collected Steps per Second: 3,921.55749
Overall Steps per Second: 3,264.65645

Timestep Collection Time: 12.75157
Timestep Consumption Time: 2.56582
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 15.31739

Cumulative Model Updates: 63,036
Cumulative Timesteps: 1,051,448,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1051448324...
Checkpoint 1051448324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478,937.99796
Policy Entropy: 1.03827
Value Function Loss: 1.54694

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.17325
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.09576

Collected Steps per Second: 3,816.93912
Overall Steps per Second: 3,160.80336

Timestep Collection Time: 13.10422
Timestep Consumption Time: 2.72024
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 15.82446

Cumulative Model Updates: 63,039
Cumulative Timesteps: 1,051,498,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669,609.99821
Policy Entropy: 1.01778
Value Function Loss: 1.51686

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.06132
Value Function Update Magnitude: 0.08758

Collected Steps per Second: 3,838.32343
Overall Steps per Second: 3,152.56628

Timestep Collection Time: 13.03173
Timestep Consumption Time: 2.83471
PPO Batch Consumption Time: 0.06249
Total Iteration Time: 15.86644

Cumulative Model Updates: 63,042
Cumulative Timesteps: 1,051,548,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1051548362...
Checkpoint 1051548362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663,318.59835
Policy Entropy: 1.02561
Value Function Loss: 1.57938

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.08322

Collected Steps per Second: 3,746.60158
Overall Steps per Second: 3,141.26506

Timestep Collection Time: 13.34970
Timestep Consumption Time: 2.57255
PPO Batch Consumption Time: 0.06466
Total Iteration Time: 15.92225

Cumulative Model Updates: 63,045
Cumulative Timesteps: 1,051,598,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293,487.83523
Policy Entropy: 1.02839
Value Function Loss: 1.57813

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.06798
Value Function Update Magnitude: 0.08906

Collected Steps per Second: 3,795.99595
Overall Steps per Second: 3,217.97845

Timestep Collection Time: 13.17388
Timestep Consumption Time: 2.36631
PPO Batch Consumption Time: 0.05174
Total Iteration Time: 15.54019

Cumulative Model Updates: 63,048
Cumulative Timesteps: 1,051,648,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1051648386...
Checkpoint 1051648386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253,492.43775
Policy Entropy: 1.03692
Value Function Loss: 1.64629

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.07813
Value Function Update Magnitude: 0.08481

Collected Steps per Second: 3,693.23508
Overall Steps per Second: 3,086.95951

Timestep Collection Time: 13.53989
Timestep Consumption Time: 2.65922
PPO Batch Consumption Time: 0.06243
Total Iteration Time: 16.19911

Cumulative Model Updates: 63,051
Cumulative Timesteps: 1,051,698,392

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463,346.68526
Policy Entropy: 1.03483
Value Function Loss: 1.58311

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.07814
Value Function Update Magnitude: 0.09028

Collected Steps per Second: 3,905.28627
Overall Steps per Second: 3,229.26093

Timestep Collection Time: 12.81596
Timestep Consumption Time: 2.68294
PPO Batch Consumption Time: 0.05365
Total Iteration Time: 15.49890

Cumulative Model Updates: 63,054
Cumulative Timesteps: 1,051,748,442

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1051748442...
Checkpoint 1051748442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457,263.85652
Policy Entropy: 1.05139
Value Function Loss: 1.57890

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.16596
Policy Update Magnitude: 0.07067
Value Function Update Magnitude: 0.09506

Collected Steps per Second: 3,713.84126
Overall Steps per Second: 3,138.10909

Timestep Collection Time: 13.47015
Timestep Consumption Time: 2.47130
PPO Batch Consumption Time: 0.05778
Total Iteration Time: 15.94145

Cumulative Model Updates: 63,057
Cumulative Timesteps: 1,051,798,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,103.20455
Policy Entropy: 1.05299
Value Function Loss: 1.60219

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.06799
Value Function Update Magnitude: 0.09156

Collected Steps per Second: 3,730.34491
Overall Steps per Second: 3,150.26213

Timestep Collection Time: 13.41216
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 15.88185

Cumulative Model Updates: 63,060
Cumulative Timesteps: 1,051,848,500

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1051848500...
Checkpoint 1051848500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,162,717.78866
Policy Entropy: 1.04179
Value Function Loss: 1.60867

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.16589
Policy Update Magnitude: 0.06451
Value Function Update Magnitude: 0.08817

Collected Steps per Second: 3,595.08458
Overall Steps per Second: 3,045.95494

Timestep Collection Time: 13.91400
Timestep Consumption Time: 2.50844
PPO Batch Consumption Time: 0.06835
Total Iteration Time: 16.42244

Cumulative Model Updates: 63,063
Cumulative Timesteps: 1,051,898,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448,974.56049
Policy Entropy: 1.03907
Value Function Loss: 1.59277

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.18391
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.09156

Collected Steps per Second: 3,900.08593
Overall Steps per Second: 3,252.66799

Timestep Collection Time: 12.83356
Timestep Consumption Time: 2.55442
PPO Batch Consumption Time: 0.05402
Total Iteration Time: 15.38798

Cumulative Model Updates: 63,066
Cumulative Timesteps: 1,051,948,574

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1051948574...
Checkpoint 1051948574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490,283.91078
Policy Entropy: 1.04690
Value Function Loss: 1.55377

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.15819
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.09015

Collected Steps per Second: 3,780.17487
Overall Steps per Second: 3,147.82240

Timestep Collection Time: 13.23642
Timestep Consumption Time: 2.65901
PPO Batch Consumption Time: 0.04847
Total Iteration Time: 15.89543

Cumulative Model Updates: 63,069
Cumulative Timesteps: 1,051,998,610

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301,949.91502
Policy Entropy: 1.05449
Value Function Loss: 1.54404

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.17239
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.09605

Collected Steps per Second: 3,956.85369
Overall Steps per Second: 3,280.19215

Timestep Collection Time: 12.64439
Timestep Consumption Time: 2.60838
PPO Batch Consumption Time: 0.05813
Total Iteration Time: 15.25276

Cumulative Model Updates: 63,072
Cumulative Timesteps: 1,052,048,642

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1052048642...
Checkpoint 1052048642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458,011.68176
Policy Entropy: 1.03726
Value Function Loss: 1.52196

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13599
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.10896

Collected Steps per Second: 3,707.76711
Overall Steps per Second: 3,116.45251

Timestep Collection Time: 13.49006
Timestep Consumption Time: 2.55960
PPO Batch Consumption Time: 0.06181
Total Iteration Time: 16.04966

Cumulative Model Updates: 63,075
Cumulative Timesteps: 1,052,098,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722,690.72308
Policy Entropy: 1.04643
Value Function Loss: 1.49707

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.09390

Collected Steps per Second: 3,660.26044
Overall Steps per Second: 3,024.07288

Timestep Collection Time: 13.67444
Timestep Consumption Time: 2.87675
PPO Batch Consumption Time: 0.05828
Total Iteration Time: 16.55119

Cumulative Model Updates: 63,078
Cumulative Timesteps: 1,052,148,712

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1052148712...
Checkpoint 1052148712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032,151.70546
Policy Entropy: 1.05102
Value Function Loss: 1.55527

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.06297
Value Function Update Magnitude: 0.08329

Collected Steps per Second: 3,814.45997
Overall Steps per Second: 3,189.36489

Timestep Collection Time: 13.10802
Timestep Consumption Time: 2.56909
PPO Batch Consumption Time: 0.06021
Total Iteration Time: 15.67710

Cumulative Model Updates: 63,081
Cumulative Timesteps: 1,052,198,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387,946.29926
Policy Entropy: 1.05575
Value Function Loss: 1.51273

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.07377
Value Function Update Magnitude: 0.08538

Collected Steps per Second: 3,758.80228
Overall Steps per Second: 3,140.18477

Timestep Collection Time: 13.30956
Timestep Consumption Time: 2.62199
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 15.93155

Cumulative Model Updates: 63,084
Cumulative Timesteps: 1,052,248,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1052248740...
Checkpoint 1052248740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,485.04291
Policy Entropy: 1.05646
Value Function Loss: 1.61257

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.07001
Value Function Update Magnitude: 0.09779

Collected Steps per Second: 3,733.45348
Overall Steps per Second: 3,099.22303

Timestep Collection Time: 13.40207
Timestep Consumption Time: 2.74262
PPO Batch Consumption Time: 0.05318
Total Iteration Time: 16.14469

Cumulative Model Updates: 63,087
Cumulative Timesteps: 1,052,298,776

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761,197.99232
Policy Entropy: 1.06780
Value Function Loss: 1.52490

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.11869

Collected Steps per Second: 3,688.83839
Overall Steps per Second: 3,081.00113

Timestep Collection Time: 13.55711
Timestep Consumption Time: 2.67462
PPO Batch Consumption Time: 0.06329
Total Iteration Time: 16.23174

Cumulative Model Updates: 63,090
Cumulative Timesteps: 1,052,348,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1052348786...
Checkpoint 1052348786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864,982.08208
Policy Entropy: 1.07417
Value Function Loss: 1.58597

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.17603
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.11696

Collected Steps per Second: 3,804.12427
Overall Steps per Second: 3,168.52056

Timestep Collection Time: 13.14363
Timestep Consumption Time: 2.63661
PPO Batch Consumption Time: 0.05340
Total Iteration Time: 15.78024

Cumulative Model Updates: 63,093
Cumulative Timesteps: 1,052,398,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596,372.82481
Policy Entropy: 1.06552
Value Function Loss: 1.51135

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.12010

Collected Steps per Second: 3,693.26646
Overall Steps per Second: 3,088.44135

Timestep Collection Time: 13.54736
Timestep Consumption Time: 2.65305
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 16.20040

Cumulative Model Updates: 63,096
Cumulative Timesteps: 1,052,448,820

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1052448820...
Checkpoint 1052448820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889,689.35978
Policy Entropy: 1.05685
Value Function Loss: 1.50398

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.16492
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.12061

Collected Steps per Second: 3,776.08407
Overall Steps per Second: 3,167.63475

Timestep Collection Time: 13.25076
Timestep Consumption Time: 2.54525
PPO Batch Consumption Time: 0.06001
Total Iteration Time: 15.79601

Cumulative Model Updates: 63,099
Cumulative Timesteps: 1,052,498,856

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676,207.65419
Policy Entropy: 1.06700
Value Function Loss: 1.46105

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 3,814.69858
Overall Steps per Second: 3,234.83122

Timestep Collection Time: 13.11558
Timestep Consumption Time: 2.35107
PPO Batch Consumption Time: 0.05109
Total Iteration Time: 15.46665

Cumulative Model Updates: 63,102
Cumulative Timesteps: 1,052,548,888

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1052548888...
Checkpoint 1052548888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418,005.74630
Policy Entropy: 1.06768
Value Function Loss: 1.50544

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.11593

Collected Steps per Second: 3,845.24946
Overall Steps per Second: 3,200.78214

Timestep Collection Time: 13.00878
Timestep Consumption Time: 2.61928
PPO Batch Consumption Time: 0.05244
Total Iteration Time: 15.62806

Cumulative Model Updates: 63,105
Cumulative Timesteps: 1,052,598,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003,513.00623
Policy Entropy: 1.05410
Value Function Loss: 1.53659

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.11078

Collected Steps per Second: 3,669.01294
Overall Steps per Second: 3,081.03736

Timestep Collection Time: 13.62873
Timestep Consumption Time: 2.60087
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 16.22960

Cumulative Model Updates: 63,108
Cumulative Timesteps: 1,052,648,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1052648914...
Checkpoint 1052648914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222,713.75608
Policy Entropy: 1.05428
Value Function Loss: 1.52742

Mean KL Divergence: 0.02390
SB3 Clip Fraction: 0.16798
Policy Update Magnitude: 0.05788
Value Function Update Magnitude: 0.10570

Collected Steps per Second: 3,710.22810
Overall Steps per Second: 3,093.02070

Timestep Collection Time: 13.48920
Timestep Consumption Time: 2.69175
PPO Batch Consumption Time: 0.06031
Total Iteration Time: 16.18095

Cumulative Model Updates: 63,111
Cumulative Timesteps: 1,052,698,962

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423,050.33923
Policy Entropy: 1.08032
Value Function Loss: 1.46647

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.10662

Collected Steps per Second: 3,732.48767
Overall Steps per Second: 3,138.03356

Timestep Collection Time: 13.40714
Timestep Consumption Time: 2.53979
PPO Batch Consumption Time: 0.05137
Total Iteration Time: 15.94693

Cumulative Model Updates: 63,114
Cumulative Timesteps: 1,052,749,004

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1052749004...
Checkpoint 1052749004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329,663.31971
Policy Entropy: 1.08852
Value Function Loss: 1.52758

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.14604
Policy Update Magnitude: 0.06740
Value Function Update Magnitude: 0.11018

Collected Steps per Second: 3,823.33858
Overall Steps per Second: 3,217.14544

Timestep Collection Time: 13.08438
Timestep Consumption Time: 2.46543
PPO Batch Consumption Time: 0.05334
Total Iteration Time: 15.54981

Cumulative Model Updates: 63,117
Cumulative Timesteps: 1,052,799,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576,909.59747
Policy Entropy: 1.06504
Value Function Loss: 1.69977

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 4,074.47774
Overall Steps per Second: 3,325.09317

Timestep Collection Time: 12.28378
Timestep Consumption Time: 2.76843
PPO Batch Consumption Time: 0.05394
Total Iteration Time: 15.05221

Cumulative Model Updates: 63,120
Cumulative Timesteps: 1,052,849,080

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1052849080...
Checkpoint 1052849080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716,193.04056
Policy Entropy: 1.05660
Value Function Loss: 1.67244

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.16340
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 3,595.21788
Overall Steps per Second: 3,021.83718

Timestep Collection Time: 13.91293
Timestep Consumption Time: 2.63992
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 16.55284

Cumulative Model Updates: 63,123
Cumulative Timesteps: 1,052,899,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581,947.21559
Policy Entropy: 1.06826
Value Function Loss: 1.68381

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.05926
Value Function Update Magnitude: 0.12361

Collected Steps per Second: 3,740.03896
Overall Steps per Second: 3,137.61735

Timestep Collection Time: 13.37794
Timestep Consumption Time: 2.56856
PPO Batch Consumption Time: 0.05443
Total Iteration Time: 15.94650

Cumulative Model Updates: 63,126
Cumulative Timesteps: 1,052,949,134

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1052949134...
Checkpoint 1052949134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416,383.24709
Policy Entropy: 1.07952
Value Function Loss: 1.51680

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.15273
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.12276

Collected Steps per Second: 3,719.15742
Overall Steps per Second: 3,126.72232

Timestep Collection Time: 13.45305
Timestep Consumption Time: 2.54901
PPO Batch Consumption Time: 0.05277
Total Iteration Time: 16.00206

Cumulative Model Updates: 63,129
Cumulative Timesteps: 1,052,999,168

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279,267.80905
Policy Entropy: 1.06047
Value Function Loss: 1.62402

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.11011

Collected Steps per Second: 3,721.98195
Overall Steps per Second: 3,140.24104

Timestep Collection Time: 13.44499
Timestep Consumption Time: 2.49073
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 15.93572

Cumulative Model Updates: 63,132
Cumulative Timesteps: 1,053,049,210

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1053049210...
Checkpoint 1053049210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415,830.01225
Policy Entropy: 1.05313
Value Function Loss: 1.58070

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.17709
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.10585

Collected Steps per Second: 3,792.00098
Overall Steps per Second: 3,176.12237

Timestep Collection Time: 13.18987
Timestep Consumption Time: 2.55763
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 15.74750

Cumulative Model Updates: 63,135
Cumulative Timesteps: 1,053,099,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840,366.69910
Policy Entropy: 1.06382
Value Function Loss: 1.57122

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.10191

Collected Steps per Second: 3,744.05699
Overall Steps per Second: 3,109.01978

Timestep Collection Time: 13.36411
Timestep Consumption Time: 2.72971
PPO Batch Consumption Time: 0.05254
Total Iteration Time: 16.09382

Cumulative Model Updates: 63,138
Cumulative Timesteps: 1,053,149,262

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1053149262...
Checkpoint 1053149262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629,213.97820
Policy Entropy: 1.08049
Value Function Loss: 1.48063

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.15674
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.10692

Collected Steps per Second: 3,704.54525
Overall Steps per Second: 3,091.73303

Timestep Collection Time: 13.50557
Timestep Consumption Time: 2.67694
PPO Batch Consumption Time: 0.05347
Total Iteration Time: 16.18251

Cumulative Model Updates: 63,141
Cumulative Timesteps: 1,053,199,294

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362,731.55277
Policy Entropy: 1.06359
Value Function Loss: 1.50203

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.09863

Collected Steps per Second: 3,883.55021
Overall Steps per Second: 3,200.99190

Timestep Collection Time: 12.87842
Timestep Consumption Time: 2.74611
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 15.62453

Cumulative Model Updates: 63,144
Cumulative Timesteps: 1,053,249,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1053249308...
Checkpoint 1053249308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513,739.28966
Policy Entropy: 1.06867
Value Function Loss: 1.61098

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.09579

Collected Steps per Second: 3,786.13397
Overall Steps per Second: 3,167.55445

Timestep Collection Time: 13.20820
Timestep Consumption Time: 2.57938
PPO Batch Consumption Time: 0.05113
Total Iteration Time: 15.78757

Cumulative Model Updates: 63,147
Cumulative Timesteps: 1,053,299,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550,949.22283
Policy Entropy: 1.06758
Value Function Loss: 1.62966

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.09298

Collected Steps per Second: 3,952.86861
Overall Steps per Second: 3,247.22554

Timestep Collection Time: 12.66118
Timestep Consumption Time: 2.75136
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 15.41254

Cumulative Model Updates: 63,150
Cumulative Timesteps: 1,053,349,364

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1053349364...
Checkpoint 1053349364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426,493.23280
Policy Entropy: 1.06679
Value Function Loss: 1.61512

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.07014
Value Function Update Magnitude: 0.09246

Collected Steps per Second: 3,714.12829
Overall Steps per Second: 3,140.21799

Timestep Collection Time: 13.46265
Timestep Consumption Time: 2.46045
PPO Batch Consumption Time: 0.05784
Total Iteration Time: 15.92310

Cumulative Model Updates: 63,153
Cumulative Timesteps: 1,053,399,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248,681.59641
Policy Entropy: 1.07012
Value Function Loss: 1.52059

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.07210
Value Function Update Magnitude: 0.07984

Collected Steps per Second: 3,816.16787
Overall Steps per Second: 3,171.67872

Timestep Collection Time: 13.10529
Timestep Consumption Time: 2.66301
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 15.76831

Cumulative Model Updates: 63,156
Cumulative Timesteps: 1,053,449,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1053449378...
Checkpoint 1053449378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451,162.19279
Policy Entropy: 1.07125
Value Function Loss: 1.53771

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.07470
Value Function Update Magnitude: 0.06954

Collected Steps per Second: 3,659.45837
Overall Steps per Second: 3,074.05673

Timestep Collection Time: 13.67361
Timestep Consumption Time: 2.60391
PPO Batch Consumption Time: 0.05938
Total Iteration Time: 16.27751

Cumulative Model Updates: 63,159
Cumulative Timesteps: 1,053,499,416

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742,776.60230
Policy Entropy: 1.06029
Value Function Loss: 1.52970

Mean KL Divergence: 0.03523
SB3 Clip Fraction: 0.20278
Policy Update Magnitude: 0.06765
Value Function Update Magnitude: 0.06509

Collected Steps per Second: 3,776.01728
Overall Steps per Second: 3,174.15807

Timestep Collection Time: 13.24570
Timestep Consumption Time: 2.51155
PPO Batch Consumption Time: 0.05436
Total Iteration Time: 15.75725

Cumulative Model Updates: 63,162
Cumulative Timesteps: 1,053,549,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1053549432...
Checkpoint 1053549432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359,170.37583
Policy Entropy: 1.07457
Value Function Loss: 1.56566

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.06143

Collected Steps per Second: 3,747.93186
Overall Steps per Second: 3,164.91552

Timestep Collection Time: 13.35243
Timestep Consumption Time: 2.45968
PPO Batch Consumption Time: 0.05155
Total Iteration Time: 15.81211

Cumulative Model Updates: 63,165
Cumulative Timesteps: 1,053,599,476

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107,177.38985
Policy Entropy: 1.06939
Value Function Loss: 1.63266

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.06988
Value Function Update Magnitude: 0.06329

Collected Steps per Second: 3,777.21370
Overall Steps per Second: 3,168.31341

Timestep Collection Time: 13.24521
Timestep Consumption Time: 2.54552
PPO Batch Consumption Time: 0.06035
Total Iteration Time: 15.79074

Cumulative Model Updates: 63,168
Cumulative Timesteps: 1,053,649,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1053649506...
Checkpoint 1053649506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482,292.71303
Policy Entropy: 1.06121
Value Function Loss: 1.68511

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.07073
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 3,817.31401
Overall Steps per Second: 3,209.74739

Timestep Collection Time: 13.10345
Timestep Consumption Time: 2.48033
PPO Batch Consumption Time: 0.05187
Total Iteration Time: 15.58378

Cumulative Model Updates: 63,171
Cumulative Timesteps: 1,053,699,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653,217.93198
Policy Entropy: 1.06212
Value Function Loss: 1.68262

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.07447
Value Function Update Magnitude: 0.08783

Collected Steps per Second: 3,732.82255
Overall Steps per Second: 3,105.70192

Timestep Collection Time: 13.39790
Timestep Consumption Time: 2.70538
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 16.10328

Cumulative Model Updates: 63,174
Cumulative Timesteps: 1,053,749,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1053749538...
Checkpoint 1053749538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313,560.85548
Policy Entropy: 1.05930
Value Function Loss: 1.54461

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.07455
Value Function Update Magnitude: 0.09607

Collected Steps per Second: 3,675.64669
Overall Steps per Second: 3,079.37878

Timestep Collection Time: 13.60414
Timestep Consumption Time: 2.63420
PPO Batch Consumption Time: 0.05057
Total Iteration Time: 16.23834

Cumulative Model Updates: 63,177
Cumulative Timesteps: 1,053,799,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014,759.81207
Policy Entropy: 1.05991
Value Function Loss: 1.53704

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.06715
Value Function Update Magnitude: 0.09783

Collected Steps per Second: 3,796.97039
Overall Steps per Second: 3,136.16103

Timestep Collection Time: 13.17050
Timestep Consumption Time: 2.77511
PPO Batch Consumption Time: 0.06430
Total Iteration Time: 15.94561

Cumulative Model Updates: 63,180
Cumulative Timesteps: 1,053,849,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1053849550...
Checkpoint 1053849550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386,646.75457
Policy Entropy: 1.06445
Value Function Loss: 1.58581

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.09648

Collected Steps per Second: 3,907.18460
Overall Steps per Second: 3,229.25364

Timestep Collection Time: 12.80462
Timestep Consumption Time: 2.68813
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 15.49274

Cumulative Model Updates: 63,183
Cumulative Timesteps: 1,053,899,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743,210.09664
Policy Entropy: 1.06920
Value Function Loss: 1.67834

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.06371
Value Function Update Magnitude: 0.09601

Collected Steps per Second: 3,652.74446
Overall Steps per Second: 3,062.54087

Timestep Collection Time: 13.69327
Timestep Consumption Time: 2.63892
PPO Batch Consumption Time: 0.06092
Total Iteration Time: 16.33219

Cumulative Model Updates: 63,186
Cumulative Timesteps: 1,053,949,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1053949598...
Checkpoint 1053949598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785,983.12349
Policy Entropy: 1.05893
Value Function Loss: 1.61775

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.07203
Value Function Update Magnitude: 0.09094

Collected Steps per Second: 3,710.96668
Overall Steps per Second: 3,119.94321

Timestep Collection Time: 13.48005
Timestep Consumption Time: 2.55358
PPO Batch Consumption Time: 0.05908
Total Iteration Time: 16.03363

Cumulative Model Updates: 63,189
Cumulative Timesteps: 1,053,999,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817,062.77044
Policy Entropy: 1.06646
Value Function Loss: 1.55624

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.07256
Value Function Update Magnitude: 0.09485

Collected Steps per Second: 3,717.40789
Overall Steps per Second: 3,102.53692

Timestep Collection Time: 13.45185
Timestep Consumption Time: 2.66593
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 16.11778

Cumulative Model Updates: 63,192
Cumulative Timesteps: 1,054,049,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1054049628...
Checkpoint 1054049628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415,007.81371
Policy Entropy: 1.07036
Value Function Loss: 1.55502

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.07715
Value Function Update Magnitude: 0.09563

Collected Steps per Second: 3,852.85052
Overall Steps per Second: 3,199.55234

Timestep Collection Time: 12.98727
Timestep Consumption Time: 2.65180
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 15.63906

Cumulative Model Updates: 63,195
Cumulative Timesteps: 1,054,099,666

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,370,232.46039
Policy Entropy: 1.07671
Value Function Loss: 1.54745

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.07598
Value Function Update Magnitude: 0.09597

Collected Steps per Second: 3,749.46505
Overall Steps per Second: 3,160.56277

Timestep Collection Time: 13.34324
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.04777
Total Iteration Time: 15.82946

Cumulative Model Updates: 63,198
Cumulative Timesteps: 1,054,149,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1054149696...
Checkpoint 1054149696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789,881.20310
Policy Entropy: 1.08654
Value Function Loss: 1.55057

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.06661
Value Function Update Magnitude: 0.10671

Collected Steps per Second: 3,848.71762
Overall Steps per Second: 3,249.69500

Timestep Collection Time: 12.99134
Timestep Consumption Time: 2.39472
PPO Batch Consumption Time: 0.04966
Total Iteration Time: 15.38606

Cumulative Model Updates: 63,201
Cumulative Timesteps: 1,054,199,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,530,030.84034
Policy Entropy: 1.07631
Value Function Loss: 1.54211

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.10314

Collected Steps per Second: 3,665.79081
Overall Steps per Second: 3,077.30946

Timestep Collection Time: 13.65162
Timestep Consumption Time: 2.61063
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 16.26226

Cumulative Model Updates: 63,204
Cumulative Timesteps: 1,054,249,740

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1054249740...
Checkpoint 1054249740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224,545.12402
Policy Entropy: 1.07533
Value Function Loss: 1.59193

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 3,750.93416
Overall Steps per Second: 3,156.75196

Timestep Collection Time: 13.33108
Timestep Consumption Time: 2.50925
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 15.84033

Cumulative Model Updates: 63,207
Cumulative Timesteps: 1,054,299,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365,774.06633
Policy Entropy: 1.07591
Value Function Loss: 1.61635

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.06784
Value Function Update Magnitude: 0.12090

Collected Steps per Second: 3,672.87237
Overall Steps per Second: 3,023.94364

Timestep Collection Time: 13.61877
Timestep Consumption Time: 2.92254
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 16.54131

Cumulative Model Updates: 63,210
Cumulative Timesteps: 1,054,349,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1054349764...
Checkpoint 1054349764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305,190.79753
Policy Entropy: 1.08351
Value Function Loss: 1.66538

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.06492
Value Function Update Magnitude: 0.10657

Collected Steps per Second: 3,841.47061
Overall Steps per Second: 3,171.88691

Timestep Collection Time: 13.03043
Timestep Consumption Time: 2.75072
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 15.78114

Cumulative Model Updates: 63,213
Cumulative Timesteps: 1,054,399,820

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284,436.84550
Policy Entropy: 1.09112
Value Function Loss: 1.64626

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.06529
Value Function Update Magnitude: 0.11266

Collected Steps per Second: 3,837.91340
Overall Steps per Second: 3,187.87632

Timestep Collection Time: 13.03417
Timestep Consumption Time: 2.65779
PPO Batch Consumption Time: 0.06214
Total Iteration Time: 15.69195

Cumulative Model Updates: 63,216
Cumulative Timesteps: 1,054,449,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1054449844...
Checkpoint 1054449844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641,554.18437
Policy Entropy: 1.08497
Value Function Loss: 1.62368

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.10925
Policy Update Magnitude: 0.07124
Value Function Update Magnitude: 0.11994

Collected Steps per Second: 3,760.81488
Overall Steps per Second: 3,110.93548

Timestep Collection Time: 13.30350
Timestep Consumption Time: 2.77912
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 16.08262

Cumulative Model Updates: 63,219
Cumulative Timesteps: 1,054,499,876

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081,930.32154
Policy Entropy: 1.08407
Value Function Loss: 1.58843

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.07873
Value Function Update Magnitude: 0.10994

Collected Steps per Second: 3,699.81997
Overall Steps per Second: 3,057.88139

Timestep Collection Time: 13.51525
Timestep Consumption Time: 2.83725
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 16.35250

Cumulative Model Updates: 63,222
Cumulative Timesteps: 1,054,549,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1054549880...
Checkpoint 1054549880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291,991.96370
Policy Entropy: 1.08904
Value Function Loss: 1.60792

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.07265
Value Function Update Magnitude: 0.10264

Collected Steps per Second: 3,700.37685
Overall Steps per Second: 3,126.02447

Timestep Collection Time: 13.51484
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.05923
Total Iteration Time: 15.99796

Cumulative Model Updates: 63,225
Cumulative Timesteps: 1,054,599,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204,382.53237
Policy Entropy: 1.10104
Value Function Loss: 1.60689

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.06757
Value Function Update Magnitude: 0.09862

Collected Steps per Second: 3,803.21084
Overall Steps per Second: 3,167.41797

Timestep Collection Time: 13.14942
Timestep Consumption Time: 2.63947
PPO Batch Consumption Time: 0.05933
Total Iteration Time: 15.78889

Cumulative Model Updates: 63,228
Cumulative Timesteps: 1,054,649,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1054649900...
Checkpoint 1054649900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227,637.78974
Policy Entropy: 1.10773
Value Function Loss: 1.66183

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.07272
Value Function Update Magnitude: 0.10031

Collected Steps per Second: 3,904.15085
Overall Steps per Second: 3,229.38962

Timestep Collection Time: 12.80688
Timestep Consumption Time: 2.67592
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 15.48280

Cumulative Model Updates: 63,231
Cumulative Timesteps: 1,054,699,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487,464.88148
Policy Entropy: 1.09010
Value Function Loss: 1.65446

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.07406
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 3,791.32187
Overall Steps per Second: 3,214.59512

Timestep Collection Time: 13.19434
Timestep Consumption Time: 2.36718
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 15.56152

Cumulative Model Updates: 63,234
Cumulative Timesteps: 1,054,749,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1054749924...
Checkpoint 1054749924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149,879.60829
Policy Entropy: 1.07349
Value Function Loss: 1.68767

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.16033
Policy Update Magnitude: 0.07558
Value Function Update Magnitude: 0.09970

Collected Steps per Second: 3,708.20274
Overall Steps per Second: 3,133.94792

Timestep Collection Time: 13.49441
Timestep Consumption Time: 2.47267
PPO Batch Consumption Time: 0.06118
Total Iteration Time: 15.96708

Cumulative Model Updates: 63,237
Cumulative Timesteps: 1,054,799,964

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597,443.14024
Policy Entropy: 1.08460
Value Function Loss: 1.67183

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.11830

Collected Steps per Second: 3,910.48171
Overall Steps per Second: 3,211.73512

Timestep Collection Time: 12.79689
Timestep Consumption Time: 2.78410
PPO Batch Consumption Time: 0.06044
Total Iteration Time: 15.58099

Cumulative Model Updates: 63,240
Cumulative Timesteps: 1,054,850,006

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1054850006...
Checkpoint 1054850006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492,695.17928
Policy Entropy: 1.09485
Value Function Loss: 1.62540

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.11612

Collected Steps per Second: 3,756.26844
Overall Steps per Second: 3,136.80413

Timestep Collection Time: 13.32173
Timestep Consumption Time: 2.63081
PPO Batch Consumption Time: 0.05125
Total Iteration Time: 15.95254

Cumulative Model Updates: 63,243
Cumulative Timesteps: 1,054,900,046

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490,049.58202
Policy Entropy: 1.05895
Value Function Loss: 1.63551

Mean KL Divergence: 0.03878
SB3 Clip Fraction: 0.20325
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.11074

Collected Steps per Second: 3,982.44967
Overall Steps per Second: 3,272.14608

Timestep Collection Time: 12.56061
Timestep Consumption Time: 2.72660
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 15.28721

Cumulative Model Updates: 63,246
Cumulative Timesteps: 1,054,950,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1054950068...
Checkpoint 1054950068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321,416.08129
Policy Entropy: 1.07800
Value Function Loss: 1.59997

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.11142

Collected Steps per Second: 3,704.66389
Overall Steps per Second: 3,073.68165

Timestep Collection Time: 13.50082
Timestep Consumption Time: 2.77152
PPO Batch Consumption Time: 0.05976
Total Iteration Time: 16.27234

Cumulative Model Updates: 63,249
Cumulative Timesteps: 1,055,000,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450,189.01938
Policy Entropy: 1.08155
Value Function Loss: 1.61171

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.11684

Collected Steps per Second: 3,899.76483
Overall Steps per Second: 3,220.80240

Timestep Collection Time: 12.82282
Timestep Consumption Time: 2.70312
PPO Batch Consumption Time: 0.05933
Total Iteration Time: 15.52594

Cumulative Model Updates: 63,252
Cumulative Timesteps: 1,055,050,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1055050090...
Checkpoint 1055050090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616,150.41495
Policy Entropy: 1.07521
Value Function Loss: 1.59014

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.11102

Collected Steps per Second: 3,712.87439
Overall Steps per Second: 3,104.56061

Timestep Collection Time: 13.46827
Timestep Consumption Time: 2.63900
PPO Batch Consumption Time: 0.05904
Total Iteration Time: 16.10727

Cumulative Model Updates: 63,255
Cumulative Timesteps: 1,055,100,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612,475.26709
Policy Entropy: 1.08008
Value Function Loss: 1.56865

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.10295

Collected Steps per Second: 3,786.55119
Overall Steps per Second: 3,172.09204

Timestep Collection Time: 13.21678
Timestep Consumption Time: 2.56019
PPO Batch Consumption Time: 0.06225
Total Iteration Time: 15.77697

Cumulative Model Updates: 63,258
Cumulative Timesteps: 1,055,150,142

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1055150142...
Checkpoint 1055150142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843,648.18936
Policy Entropy: 1.08242
Value Function Loss: 1.55393

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.10772

Collected Steps per Second: 3,736.71991
Overall Steps per Second: 3,130.95574

Timestep Collection Time: 13.39089
Timestep Consumption Time: 2.59081
PPO Batch Consumption Time: 0.05933
Total Iteration Time: 15.98170

Cumulative Model Updates: 63,261
Cumulative Timesteps: 1,055,200,180

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364,971.86479
Policy Entropy: 1.08431
Value Function Loss: 1.60964

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.09882

Collected Steps per Second: 3,866.82611
Overall Steps per Second: 3,269.06637

Timestep Collection Time: 12.94136
Timestep Consumption Time: 2.36637
PPO Batch Consumption Time: 0.06322
Total Iteration Time: 15.30773

Cumulative Model Updates: 63,264
Cumulative Timesteps: 1,055,250,222

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1055250222...
Checkpoint 1055250222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590,122.97906
Policy Entropy: 1.07277
Value Function Loss: 1.59442

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.10655

Collected Steps per Second: 3,700.38513
Overall Steps per Second: 3,178.04009

Timestep Collection Time: 13.51427
Timestep Consumption Time: 2.22122
PPO Batch Consumption Time: 0.05306
Total Iteration Time: 15.73548

Cumulative Model Updates: 63,267
Cumulative Timesteps: 1,055,300,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341,695.91591
Policy Entropy: 1.05922
Value Function Loss: 1.64785

Mean KL Divergence: 0.02611
SB3 Clip Fraction: 0.16149
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.10531

Collected Steps per Second: 3,909.52331
Overall Steps per Second: 3,284.79592

Timestep Collection Time: 12.79798
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.07058
Total Iteration Time: 15.23200

Cumulative Model Updates: 63,270
Cumulative Timesteps: 1,055,350,264

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1055350264...
Checkpoint 1055350264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788,524.03308
Policy Entropy: 1.08211
Value Function Loss: 1.64507

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.10203

Collected Steps per Second: 3,766.73112
Overall Steps per Second: 3,209.59110

Timestep Collection Time: 13.28207
Timestep Consumption Time: 2.30558
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 15.58766

Cumulative Model Updates: 63,273
Cumulative Timesteps: 1,055,400,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400,041.85701
Policy Entropy: 1.08068
Value Function Loss: 1.62731

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.10327

Collected Steps per Second: 3,990.00840
Overall Steps per Second: 3,277.00216

Timestep Collection Time: 12.53381
Timestep Consumption Time: 2.72709
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 15.26090

Cumulative Model Updates: 63,276
Cumulative Timesteps: 1,055,450,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1055450304...
Checkpoint 1055450304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675,443.55706
Policy Entropy: 1.07234
Value Function Loss: 1.60926

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.09469

Collected Steps per Second: 3,713.64677
Overall Steps per Second: 3,101.12352

Timestep Collection Time: 13.46439
Timestep Consumption Time: 2.65944
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 16.12383

Cumulative Model Updates: 63,279
Cumulative Timesteps: 1,055,500,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239,228.63568
Policy Entropy: 1.05808
Value Function Loss: 1.58047

Mean KL Divergence: 0.03165
SB3 Clip Fraction: 0.17975
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.09647

Collected Steps per Second: 3,851.16248
Overall Steps per Second: 3,230.71506

Timestep Collection Time: 12.98673
Timestep Consumption Time: 2.49406
PPO Batch Consumption Time: 0.05881
Total Iteration Time: 15.48078

Cumulative Model Updates: 63,282
Cumulative Timesteps: 1,055,550,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1055550320...
Checkpoint 1055550320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394,500.51852
Policy Entropy: 1.07694
Value Function Loss: 1.67242

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.09812

Collected Steps per Second: 3,966.47434
Overall Steps per Second: 3,289.73037

Timestep Collection Time: 12.61120
Timestep Consumption Time: 2.59430
PPO Batch Consumption Time: 0.04920
Total Iteration Time: 15.20550

Cumulative Model Updates: 63,285
Cumulative Timesteps: 1,055,600,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109,758.51595
Policy Entropy: 1.08505
Value Function Loss: 1.68825

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.09388

Collected Steps per Second: 3,782.96442
Overall Steps per Second: 3,194.07754

Timestep Collection Time: 13.21821
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.05145
Total Iteration Time: 15.65522

Cumulative Model Updates: 63,288
Cumulative Timesteps: 1,055,650,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1055650346...
Checkpoint 1055650346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659,235.97131
Policy Entropy: 1.07658
Value Function Loss: 1.68044

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.09343

Collected Steps per Second: 3,889.50298
Overall Steps per Second: 3,247.39739

Timestep Collection Time: 12.86437
Timestep Consumption Time: 2.54366
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 15.40803

Cumulative Model Updates: 63,291
Cumulative Timesteps: 1,055,700,382

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499,570.24987
Policy Entropy: 1.05002
Value Function Loss: 1.66081

Mean KL Divergence: 0.03013
SB3 Clip Fraction: 0.19345
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.09713

Collected Steps per Second: 3,856.78842
Overall Steps per Second: 3,162.38344

Timestep Collection Time: 12.97556
Timestep Consumption Time: 2.84921
PPO Batch Consumption Time: 0.07025
Total Iteration Time: 15.82477

Cumulative Model Updates: 63,294
Cumulative Timesteps: 1,055,750,426

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1055750426...
Checkpoint 1055750426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,681,363.74613
Policy Entropy: 1.06515
Value Function Loss: 1.60038

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.09679

Collected Steps per Second: 3,810.21278
Overall Steps per Second: 3,190.34937

Timestep Collection Time: 13.13103
Timestep Consumption Time: 2.55127
PPO Batch Consumption Time: 0.05281
Total Iteration Time: 15.68229

Cumulative Model Updates: 63,297
Cumulative Timesteps: 1,055,800,458

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499,972.86743
Policy Entropy: 1.06453
Value Function Loss: 1.66041

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14578
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.11607

Collected Steps per Second: 3,735.71446
Overall Steps per Second: 3,214.91810

Timestep Collection Time: 13.38432
Timestep Consumption Time: 2.16818
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 15.55250

Cumulative Model Updates: 63,300
Cumulative Timesteps: 1,055,850,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1055850458...
Checkpoint 1055850458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514,735.01791
Policy Entropy: 1.06198
Value Function Loss: 1.67724

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.07253
Value Function Update Magnitude: 0.13016

Collected Steps per Second: 3,712.54361
Overall Steps per Second: 3,114.45810

Timestep Collection Time: 13.48078
Timestep Consumption Time: 2.58878
PPO Batch Consumption Time: 0.06252
Total Iteration Time: 16.06957

Cumulative Model Updates: 63,303
Cumulative Timesteps: 1,055,900,506

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779,195.10139
Policy Entropy: 1.05216
Value Function Loss: 1.62320

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.17621
Policy Update Magnitude: 0.06616
Value Function Update Magnitude: 0.12302

Collected Steps per Second: 3,593.40685
Overall Steps per Second: 3,063.24233

Timestep Collection Time: 13.92717
Timestep Consumption Time: 2.41042
PPO Batch Consumption Time: 0.05079
Total Iteration Time: 16.33759

Cumulative Model Updates: 63,306
Cumulative Timesteps: 1,055,950,552

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1055950552...
Checkpoint 1055950552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781,349.55583
Policy Entropy: 1.06810
Value Function Loss: 1.64057

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.10968

Collected Steps per Second: 3,925.75010
Overall Steps per Second: 3,278.56763

Timestep Collection Time: 12.73846
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.05002
Total Iteration Time: 15.25300

Cumulative Model Updates: 63,309
Cumulative Timesteps: 1,056,000,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293,484.61309
Policy Entropy: 1.07877
Value Function Loss: 1.54966

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 3,724.04762
Overall Steps per Second: 3,119.48863

Timestep Collection Time: 13.43699
Timestep Consumption Time: 2.60410
PPO Batch Consumption Time: 0.05268
Total Iteration Time: 16.04109

Cumulative Model Updates: 63,312
Cumulative Timesteps: 1,056,050,600

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1056050600...
Checkpoint 1056050600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617,141.09732
Policy Entropy: 1.05673
Value Function Loss: 1.66967

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.10094

Collected Steps per Second: 3,995.61809
Overall Steps per Second: 3,302.49221

Timestep Collection Time: 12.52522
Timestep Consumption Time: 2.62879
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 15.15401

Cumulative Model Updates: 63,315
Cumulative Timesteps: 1,056,100,646

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579,413.86580
Policy Entropy: 1.06180
Value Function Loss: 1.56727

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.09286

Collected Steps per Second: 3,769.81839
Overall Steps per Second: 3,088.22193

Timestep Collection Time: 13.26907
Timestep Consumption Time: 2.92860
PPO Batch Consumption Time: 0.06467
Total Iteration Time: 16.19767

Cumulative Model Updates: 63,318
Cumulative Timesteps: 1,056,150,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1056150668...
Checkpoint 1056150668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232,050.81666
Policy Entropy: 1.06842
Value Function Loss: 1.55277

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.08772

Collected Steps per Second: 3,873.75365
Overall Steps per Second: 3,216.12773

Timestep Collection Time: 12.90789
Timestep Consumption Time: 2.63937
PPO Batch Consumption Time: 0.06487
Total Iteration Time: 15.54727

Cumulative Model Updates: 63,321
Cumulative Timesteps: 1,056,200,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014,252.02045
Policy Entropy: 1.07665
Value Function Loss: 1.52410

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.08475

Collected Steps per Second: 3,553.12148
Overall Steps per Second: 3,004.57354

Timestep Collection Time: 14.08621
Timestep Consumption Time: 2.57173
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 16.65794

Cumulative Model Updates: 63,324
Cumulative Timesteps: 1,056,250,720

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1056250720...
Checkpoint 1056250720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455,534.94081
Policy Entropy: 1.07491
Value Function Loss: 1.55349

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.06866
Value Function Update Magnitude: 0.08842

Collected Steps per Second: 3,800.25507
Overall Steps per Second: 3,158.34489

Timestep Collection Time: 13.15912
Timestep Consumption Time: 2.67449
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 15.83361

Cumulative Model Updates: 63,327
Cumulative Timesteps: 1,056,300,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571,943.75528
Policy Entropy: 1.06318
Value Function Loss: 1.57986

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.07139
Value Function Update Magnitude: 0.11059

Collected Steps per Second: 3,751.90678
Overall Steps per Second: 3,114.13742

Timestep Collection Time: 13.33935
Timestep Consumption Time: 2.73187
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 16.07122

Cumulative Model Updates: 63,330
Cumulative Timesteps: 1,056,350,776

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1056350776...
Checkpoint 1056350776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634,566.73238
Policy Entropy: 1.05010
Value Function Loss: 1.56416

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.16225
Policy Update Magnitude: 0.07115
Value Function Update Magnitude: 0.10781

Collected Steps per Second: 3,896.97035
Overall Steps per Second: 3,290.00888

Timestep Collection Time: 12.83920
Timestep Consumption Time: 2.36866
PPO Batch Consumption Time: 0.05155
Total Iteration Time: 15.20786

Cumulative Model Updates: 63,333
Cumulative Timesteps: 1,056,400,810

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759,538.07941
Policy Entropy: 1.06660
Value Function Loss: 1.60495

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.15971
Policy Update Magnitude: 0.06379
Value Function Update Magnitude: 0.09858

Collected Steps per Second: 3,656.44613
Overall Steps per Second: 3,090.94780

Timestep Collection Time: 13.67557
Timestep Consumption Time: 2.50199
PPO Batch Consumption Time: 0.05331
Total Iteration Time: 16.17756

Cumulative Model Updates: 63,336
Cumulative Timesteps: 1,056,450,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1056450814...
Checkpoint 1056450814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406,040.94813
Policy Entropy: 1.06415
Value Function Loss: 1.68374

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.15629
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.08526

Collected Steps per Second: 3,757.83029
Overall Steps per Second: 3,143.67755

Timestep Collection Time: 13.30981
Timestep Consumption Time: 2.60022
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 15.91003

Cumulative Model Updates: 63,339
Cumulative Timesteps: 1,056,500,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393,603.55415
Policy Entropy: 1.05260
Value Function Loss: 1.64582

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.07694

Collected Steps per Second: 3,967.15756
Overall Steps per Second: 3,269.23382

Timestep Collection Time: 12.61004
Timestep Consumption Time: 2.69202
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 15.30206

Cumulative Model Updates: 63,342
Cumulative Timesteps: 1,056,550,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1056550856...
Checkpoint 1056550856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,573,045.84506
Policy Entropy: 1.05711
Value Function Loss: 1.62246

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.16653
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.07577

Collected Steps per Second: 3,730.24622
Overall Steps per Second: 3,102.63031

Timestep Collection Time: 13.41198
Timestep Consumption Time: 2.71304
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 16.12503

Cumulative Model Updates: 63,345
Cumulative Timesteps: 1,056,600,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625,794.80632
Policy Entropy: 1.06963
Value Function Loss: 1.57068

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.09745

Collected Steps per Second: 3,763.04515
Overall Steps per Second: 3,126.53109

Timestep Collection Time: 13.28977
Timestep Consumption Time: 2.70559
PPO Batch Consumption Time: 0.05870
Total Iteration Time: 15.99536

Cumulative Model Updates: 63,348
Cumulative Timesteps: 1,056,650,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1056650896...
Checkpoint 1056650896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,479.48317
Policy Entropy: 1.07264
Value Function Loss: 1.64631

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.15263
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.10983

Collected Steps per Second: 3,610.01049
Overall Steps per Second: 2,989.00619

Timestep Collection Time: 13.85536
Timestep Consumption Time: 2.87863
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 16.73399

Cumulative Model Updates: 63,351
Cumulative Timesteps: 1,056,700,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030,709.08187
Policy Entropy: 1.06087
Value Function Loss: 1.59869

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.12274

Collected Steps per Second: 3,888.07771
Overall Steps per Second: 3,207.13713

Timestep Collection Time: 12.87166
Timestep Consumption Time: 2.73291
PPO Batch Consumption Time: 0.05044
Total Iteration Time: 15.60457

Cumulative Model Updates: 63,354
Cumulative Timesteps: 1,056,750,960

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1056750960...
Checkpoint 1056750960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997,053.98902
Policy Entropy: 1.05549
Value Function Loss: 1.61061

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.15191
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.13895

Collected Steps per Second: 3,992.41838
Overall Steps per Second: 3,263.91955

Timestep Collection Time: 12.53025
Timestep Consumption Time: 2.79672
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 15.32697

Cumulative Model Updates: 63,357
Cumulative Timesteps: 1,056,800,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387,478.21211
Policy Entropy: 1.06870
Value Function Loss: 1.60369

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.13266

Collected Steps per Second: 4,016.81465
Overall Steps per Second: 3,309.82889

Timestep Collection Time: 12.45664
Timestep Consumption Time: 2.66076
PPO Batch Consumption Time: 0.05125
Total Iteration Time: 15.11740

Cumulative Model Updates: 63,360
Cumulative Timesteps: 1,056,851,022

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1056851022...
Checkpoint 1056851022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605,032.52778
Policy Entropy: 1.07157
Value Function Loss: 1.58536

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.12696

Collected Steps per Second: 3,668.44946
Overall Steps per Second: 3,069.16898

Timestep Collection Time: 13.63246
Timestep Consumption Time: 2.66185
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 16.29431

Cumulative Model Updates: 63,363
Cumulative Timesteps: 1,056,901,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221,701.76299
Policy Entropy: 1.05817
Value Function Loss: 1.55301

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.13015

Collected Steps per Second: 3,911.56931
Overall Steps per Second: 3,259.38492

Timestep Collection Time: 12.78515
Timestep Consumption Time: 2.55824
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 15.34339

Cumulative Model Updates: 63,366
Cumulative Timesteps: 1,056,951,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1056951042...
Checkpoint 1056951042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253,360.09917
Policy Entropy: 1.04823
Value Function Loss: 1.52315

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.16475
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.11662

Collected Steps per Second: 3,615.02723
Overall Steps per Second: 3,060.72319

Timestep Collection Time: 13.84111
Timestep Consumption Time: 2.50666
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 16.34777

Cumulative Model Updates: 63,369
Cumulative Timesteps: 1,057,001,078

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490,862.71619
Policy Entropy: 1.06086
Value Function Loss: 1.59074

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.10587

Collected Steps per Second: 3,665.56411
Overall Steps per Second: 3,106.79643

Timestep Collection Time: 13.64701
Timestep Consumption Time: 2.45446
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 16.10147

Cumulative Model Updates: 63,372
Cumulative Timesteps: 1,057,051,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1057051102...
Checkpoint 1057051102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741,710.40020
Policy Entropy: 1.06607
Value Function Loss: 1.59889

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.15222
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.11128

Collected Steps per Second: 3,833.42339
Overall Steps per Second: 3,145.07498

Timestep Collection Time: 13.05413
Timestep Consumption Time: 2.85710
PPO Batch Consumption Time: 0.04768
Total Iteration Time: 15.91123

Cumulative Model Updates: 63,375
Cumulative Timesteps: 1,057,101,144

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025,621.52130
Policy Entropy: 1.05099
Value Function Loss: 1.61160

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 3,772.60891
Overall Steps per Second: 3,132.83018

Timestep Collection Time: 13.25979
Timestep Consumption Time: 2.70788
PPO Batch Consumption Time: 0.05769
Total Iteration Time: 15.96767

Cumulative Model Updates: 63,378
Cumulative Timesteps: 1,057,151,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1057151168...
Checkpoint 1057151168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397,066.89698
Policy Entropy: 1.03865
Value Function Loss: 1.65933

Mean KL Divergence: 0.02653
SB3 Clip Fraction: 0.17540
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 3,905.42556
Overall Steps per Second: 3,232.93087

Timestep Collection Time: 12.81602
Timestep Consumption Time: 2.66591
PPO Batch Consumption Time: 0.05345
Total Iteration Time: 15.48193

Cumulative Model Updates: 63,381
Cumulative Timesteps: 1,057,201,220

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488,827.30615
Policy Entropy: 1.06176
Value Function Loss: 1.68509

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.11335

Collected Steps per Second: 3,849.25988
Overall Steps per Second: 3,194.89628

Timestep Collection Time: 12.99159
Timestep Consumption Time: 2.66088
PPO Batch Consumption Time: 0.05105
Total Iteration Time: 15.65246

Cumulative Model Updates: 63,384
Cumulative Timesteps: 1,057,251,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1057251228...
Checkpoint 1057251228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517,946.29188
Policy Entropy: 1.06325
Value Function Loss: 1.69826

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.11480

Collected Steps per Second: 3,771.91682
Overall Steps per Second: 3,193.81924

Timestep Collection Time: 13.26275
Timestep Consumption Time: 2.40063
PPO Batch Consumption Time: 0.05117
Total Iteration Time: 15.66338

Cumulative Model Updates: 63,387
Cumulative Timesteps: 1,057,301,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614,619.42303
Policy Entropy: 1.05819
Value Function Loss: 1.67657

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.06500
Value Function Update Magnitude: 0.11043

Collected Steps per Second: 3,712.36815
Overall Steps per Second: 3,109.23866

Timestep Collection Time: 13.47927
Timestep Consumption Time: 2.61471
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 16.09397

Cumulative Model Updates: 63,390
Cumulative Timesteps: 1,057,351,294

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1057351294...
Checkpoint 1057351294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649,110.29723
Policy Entropy: 1.04612
Value Function Loss: 1.58101

Mean KL Divergence: 0.02934
SB3 Clip Fraction: 0.19752
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.11139

Collected Steps per Second: 3,827.26531
Overall Steps per Second: 3,130.56886

Timestep Collection Time: 13.06625
Timestep Consumption Time: 2.90785
PPO Batch Consumption Time: 0.06106
Total Iteration Time: 15.97409

Cumulative Model Updates: 63,393
Cumulative Timesteps: 1,057,401,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351,991.90019
Policy Entropy: 1.05882
Value Function Loss: 1.47186

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.10949

Collected Steps per Second: 3,851.70123
Overall Steps per Second: 3,228.57399

Timestep Collection Time: 12.98907
Timestep Consumption Time: 2.50694
PPO Batch Consumption Time: 0.05971
Total Iteration Time: 15.49601

Cumulative Model Updates: 63,396
Cumulative Timesteps: 1,057,451,332

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1057451332...
Checkpoint 1057451332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268,614.25902
Policy Entropy: 1.06339
Value Function Loss: 1.50485

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.06752
Value Function Update Magnitude: 0.10249

Collected Steps per Second: 3,851.63333
Overall Steps per Second: 3,244.97573

Timestep Collection Time: 12.98929
Timestep Consumption Time: 2.42839
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 15.41768

Cumulative Model Updates: 63,399
Cumulative Timesteps: 1,057,501,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555,190.20320
Policy Entropy: 1.05832
Value Function Loss: 1.57099

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.07074
Value Function Update Magnitude: 0.08993

Collected Steps per Second: 4,008.62987
Overall Steps per Second: 3,344.54567

Timestep Collection Time: 12.47459
Timestep Consumption Time: 2.47692
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 14.95151

Cumulative Model Updates: 63,402
Cumulative Timesteps: 1,057,551,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1057551368...
Checkpoint 1057551368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921,588.30475
Policy Entropy: 1.04506
Value Function Loss: 1.60228

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.07365
Value Function Update Magnitude: 0.08214

Collected Steps per Second: 3,865.24571
Overall Steps per Second: 3,200.73230

Timestep Collection Time: 12.93993
Timestep Consumption Time: 2.68650
PPO Batch Consumption Time: 0.05226
Total Iteration Time: 15.62642

Cumulative Model Updates: 63,405
Cumulative Timesteps: 1,057,601,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419,059.27829
Policy Entropy: 1.06831
Value Function Loss: 1.51736

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.16603
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.07142

Collected Steps per Second: 3,671.49373
Overall Steps per Second: 3,049.65018

Timestep Collection Time: 13.62225
Timestep Consumption Time: 2.77767
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 16.39991

Cumulative Model Updates: 63,408
Cumulative Timesteps: 1,057,651,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1057651398...
Checkpoint 1057651398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748,405.98508
Policy Entropy: 1.06617
Value Function Loss: 1.56447

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.06866

Collected Steps per Second: 3,939.27670
Overall Steps per Second: 3,239.52033

Timestep Collection Time: 12.69776
Timestep Consumption Time: 2.74279
PPO Batch Consumption Time: 0.05308
Total Iteration Time: 15.44056

Cumulative Model Updates: 63,411
Cumulative Timesteps: 1,057,701,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741,080.44059
Policy Entropy: 1.04745
Value Function Loss: 1.61713

Mean KL Divergence: 0.02584
SB3 Clip Fraction: 0.16300
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.08014

Collected Steps per Second: 3,738.14257
Overall Steps per Second: 3,106.88619

Timestep Collection Time: 13.37563
Timestep Consumption Time: 2.71766
PPO Batch Consumption Time: 0.06046
Total Iteration Time: 16.09328

Cumulative Model Updates: 63,414
Cumulative Timesteps: 1,057,751,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1057751418...
Checkpoint 1057751418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829,049.36464
Policy Entropy: 1.03923
Value Function Loss: 1.63968

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.17059
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.08519

Collected Steps per Second: 3,883.57316
Overall Steps per Second: 3,228.02428

Timestep Collection Time: 12.88350
Timestep Consumption Time: 2.61639
PPO Batch Consumption Time: 0.05096
Total Iteration Time: 15.49988

Cumulative Model Updates: 63,417
Cumulative Timesteps: 1,057,801,452

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349,532.64433
Policy Entropy: 1.05024
Value Function Loss: 1.67388

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.07998

Collected Steps per Second: 3,643.56008
Overall Steps per Second: 3,067.78290

Timestep Collection Time: 13.72284
Timestep Consumption Time: 2.57557
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 16.29842

Cumulative Model Updates: 63,420
Cumulative Timesteps: 1,057,851,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1057851452...
Checkpoint 1057851452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683,767.67870
Policy Entropy: 1.06404
Value Function Loss: 1.61679

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.16069
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.07335

Collected Steps per Second: 4,086.75405
Overall Steps per Second: 3,358.73315

Timestep Collection Time: 12.24395
Timestep Consumption Time: 2.65393
PPO Batch Consumption Time: 0.06056
Total Iteration Time: 14.89788

Cumulative Model Updates: 63,423
Cumulative Timesteps: 1,057,901,490

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397,925.90082
Policy Entropy: 1.04534
Value Function Loss: 1.62185

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.06150
Value Function Update Magnitude: 0.07020

Collected Steps per Second: 3,782.78784
Overall Steps per Second: 3,170.32895

Timestep Collection Time: 13.21776
Timestep Consumption Time: 2.55347
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 15.77123

Cumulative Model Updates: 63,426
Cumulative Timesteps: 1,057,951,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1057951490...
Checkpoint 1057951490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246,865.24546
Policy Entropy: 1.05818
Value Function Loss: 1.61737

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.16933
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.06829

Collected Steps per Second: 3,871.62391
Overall Steps per Second: 3,263.85528

Timestep Collection Time: 12.92016
Timestep Consumption Time: 2.40589
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 15.32605

Cumulative Model Updates: 63,429
Cumulative Timesteps: 1,058,001,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764,489.74242
Policy Entropy: 1.05627
Value Function Loss: 1.61881

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.16795
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 3,637.59321
Overall Steps per Second: 3,105.41249

Timestep Collection Time: 13.75965
Timestep Consumption Time: 2.35802
PPO Batch Consumption Time: 0.05238
Total Iteration Time: 16.11767

Cumulative Model Updates: 63,432
Cumulative Timesteps: 1,058,051,564

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1058051564...
Checkpoint 1058051564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650,095.00875
Policy Entropy: 1.03931
Value Function Loss: 1.60666

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.08412

Collected Steps per Second: 3,794.53136
Overall Steps per Second: 3,129.90642

Timestep Collection Time: 13.18002
Timestep Consumption Time: 2.79873
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 15.97875

Cumulative Model Updates: 63,435
Cumulative Timesteps: 1,058,101,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837,107.17641
Policy Entropy: 1.02689
Value Function Loss: 1.52490

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.19183
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.09091

Collected Steps per Second: 3,736.18457
Overall Steps per Second: 3,116.44921

Timestep Collection Time: 13.39334
Timestep Consumption Time: 2.66339
PPO Batch Consumption Time: 0.05244
Total Iteration Time: 16.05674

Cumulative Model Updates: 63,438
Cumulative Timesteps: 1,058,151,616

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1058151616...
Checkpoint 1058151616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731,191.73270
Policy Entropy: 1.05146
Value Function Loss: 1.63248

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.08905

Collected Steps per Second: 3,960.92790
Overall Steps per Second: 3,253.03811

Timestep Collection Time: 12.62734
Timestep Consumption Time: 2.74782
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 15.37517

Cumulative Model Updates: 63,441
Cumulative Timesteps: 1,058,201,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698,881.11882
Policy Entropy: 1.05680
Value Function Loss: 1.61728

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.09084

Collected Steps per Second: 3,788.87340
Overall Steps per Second: 3,177.13029

Timestep Collection Time: 13.20868
Timestep Consumption Time: 2.54328
PPO Batch Consumption Time: 0.05225
Total Iteration Time: 15.75195

Cumulative Model Updates: 63,444
Cumulative Timesteps: 1,058,251,678

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1058251678...
Checkpoint 1058251678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181,964.32917
Policy Entropy: 1.05530
Value Function Loss: 1.65916

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.07049
Value Function Update Magnitude: 0.09245

Collected Steps per Second: 3,843.89614
Overall Steps per Second: 3,210.31871

Timestep Collection Time: 13.01596
Timestep Consumption Time: 2.56879
PPO Batch Consumption Time: 0.05953
Total Iteration Time: 15.58475

Cumulative Model Updates: 63,447
Cumulative Timesteps: 1,058,301,710

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250,675.41651
Policy Entropy: 1.03785
Value Function Loss: 1.63686

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.07627
Value Function Update Magnitude: 0.08863

Collected Steps per Second: 3,792.14059
Overall Steps per Second: 3,154.09925

Timestep Collection Time: 13.19624
Timestep Consumption Time: 2.66946
PPO Batch Consumption Time: 0.06345
Total Iteration Time: 15.86570

Cumulative Model Updates: 63,450
Cumulative Timesteps: 1,058,351,752

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1058351752...
Checkpoint 1058351752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638,652.45630
Policy Entropy: 1.05131
Value Function Loss: 1.60241

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.09471

Collected Steps per Second: 3,751.29012
Overall Steps per Second: 3,119.13803

Timestep Collection Time: 13.33515
Timestep Consumption Time: 2.70262
PPO Batch Consumption Time: 0.05346
Total Iteration Time: 16.03776

Cumulative Model Updates: 63,453
Cumulative Timesteps: 1,058,401,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596,510.86883
Policy Entropy: 1.05215
Value Function Loss: 1.63344

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.09013

Collected Steps per Second: 3,876.44117
Overall Steps per Second: 3,211.88179

Timestep Collection Time: 12.90668
Timestep Consumption Time: 2.67048
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 15.57716

Cumulative Model Updates: 63,456
Cumulative Timesteps: 1,058,451,808

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1058451808...
Checkpoint 1058451808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,021,436.49700
Policy Entropy: 1.05780
Value Function Loss: 1.54827

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.07044
Value Function Update Magnitude: 0.10256

Collected Steps per Second: 3,701.56961
Overall Steps per Second: 3,107.21131

Timestep Collection Time: 13.51535
Timestep Consumption Time: 2.58526
PPO Batch Consumption Time: 0.05111
Total Iteration Time: 16.10061

Cumulative Model Updates: 63,459
Cumulative Timesteps: 1,058,501,836

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136,797.83757
Policy Entropy: 1.05766
Value Function Loss: 1.57792

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.07112
Value Function Update Magnitude: 0.11117

Collected Steps per Second: 3,744.39133
Overall Steps per Second: 3,121.53203

Timestep Collection Time: 13.36078
Timestep Consumption Time: 2.66596
PPO Batch Consumption Time: 0.05920
Total Iteration Time: 16.02675

Cumulative Model Updates: 63,462
Cumulative Timesteps: 1,058,551,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1058551864...
Checkpoint 1058551864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021,851.94749
Policy Entropy: 1.04703
Value Function Loss: 1.56772

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.07345
Value Function Update Magnitude: 0.12238

Collected Steps per Second: 3,756.65686
Overall Steps per Second: 3,135.82397

Timestep Collection Time: 13.31982
Timestep Consumption Time: 2.63707
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 15.95689

Cumulative Model Updates: 63,465
Cumulative Timesteps: 1,058,601,902

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210,766.04701
Policy Entropy: 1.05239
Value Function Loss: 1.68379

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.07422
Value Function Update Magnitude: 0.12654

Collected Steps per Second: 3,731.47162
Overall Steps per Second: 3,191.62462

Timestep Collection Time: 13.40061
Timestep Consumption Time: 2.26664
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 15.66726

Cumulative Model Updates: 63,468
Cumulative Timesteps: 1,058,651,906

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1058651906...
Checkpoint 1058651906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,295,487.53867
Policy Entropy: 1.05689
Value Function Loss: 1.63499

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.08000
Value Function Update Magnitude: 0.13012

Collected Steps per Second: 3,667.70300
Overall Steps per Second: 3,103.10293

Timestep Collection Time: 13.63251
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.06937
Total Iteration Time: 16.11290

Cumulative Model Updates: 63,471
Cumulative Timesteps: 1,058,701,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256,203.70740
Policy Entropy: 1.05936
Value Function Loss: 1.65876

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.08130
Value Function Update Magnitude: 0.11201

Collected Steps per Second: 3,767.33375
Overall Steps per Second: 3,126.45217

Timestep Collection Time: 13.27942
Timestep Consumption Time: 2.72211
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 16.00152

Cumulative Model Updates: 63,474
Cumulative Timesteps: 1,058,751,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1058751934...
Checkpoint 1058751934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,410.31729
Policy Entropy: 1.06049
Value Function Loss: 1.58081

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.08166
Value Function Update Magnitude: 0.10477

Collected Steps per Second: 3,665.10417
Overall Steps per Second: 3,043.47004

Timestep Collection Time: 13.64927
Timestep Consumption Time: 2.78789
PPO Batch Consumption Time: 0.05356
Total Iteration Time: 16.43716

Cumulative Model Updates: 63,477
Cumulative Timesteps: 1,058,801,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583,034.35675
Policy Entropy: 1.05802
Value Function Loss: 1.66272

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.07825
Value Function Update Magnitude: 0.10257

Collected Steps per Second: 3,674.82745
Overall Steps per Second: 3,058.74616

Timestep Collection Time: 13.60608
Timestep Consumption Time: 2.74049
PPO Batch Consumption Time: 0.06720
Total Iteration Time: 16.34657

Cumulative Model Updates: 63,480
Cumulative Timesteps: 1,058,851,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1058851960...
Checkpoint 1058851960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523,048.23297
Policy Entropy: 1.06016
Value Function Loss: 1.62730

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.07949
Value Function Update Magnitude: 0.10007

Collected Steps per Second: 3,750.43192
Overall Steps per Second: 3,150.11807

Timestep Collection Time: 13.33713
Timestep Consumption Time: 2.54164
PPO Batch Consumption Time: 0.05794
Total Iteration Time: 15.87877

Cumulative Model Updates: 63,483
Cumulative Timesteps: 1,058,901,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149,694.19191
Policy Entropy: 1.05802
Value Function Loss: 1.63059

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.07950
Value Function Update Magnitude: 0.09958

Collected Steps per Second: 3,862.08960
Overall Steps per Second: 3,217.42368

Timestep Collection Time: 12.94740
Timestep Consumption Time: 2.59423
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 15.54163

Cumulative Model Updates: 63,486
Cumulative Timesteps: 1,058,951,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1058951984...
Checkpoint 1058951984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420,080.13429
Policy Entropy: 1.06646
Value Function Loss: 1.61121

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.07952
Value Function Update Magnitude: 0.10207

Collected Steps per Second: 3,906.39388
Overall Steps per Second: 3,283.83554

Timestep Collection Time: 12.80106
Timestep Consumption Time: 2.42686
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 15.22792

Cumulative Model Updates: 63,489
Cumulative Timesteps: 1,059,001,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528,919.82025
Policy Entropy: 1.06368
Value Function Loss: 1.57413

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.08441
Value Function Update Magnitude: 0.10697

Collected Steps per Second: 3,825.09457
Overall Steps per Second: 3,235.00590

Timestep Collection Time: 13.07628
Timestep Consumption Time: 2.38521
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 15.46149

Cumulative Model Updates: 63,492
Cumulative Timesteps: 1,059,052,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1059052008...
Checkpoint 1059052008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645,218.16738
Policy Entropy: 1.06766
Value Function Loss: 1.60917

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.07676
Value Function Update Magnitude: 0.10828

Collected Steps per Second: 4,039.37742
Overall Steps per Second: 3,310.80384

Timestep Collection Time: 12.38706
Timestep Consumption Time: 2.72589
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 15.11295

Cumulative Model Updates: 63,495
Cumulative Timesteps: 1,059,102,044

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558,526.88715
Policy Entropy: 1.08101
Value Function Loss: 1.59599

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.11210

Collected Steps per Second: 3,932.88960
Overall Steps per Second: 3,204.94448

Timestep Collection Time: 12.72042
Timestep Consumption Time: 2.88921
PPO Batch Consumption Time: 0.06458
Total Iteration Time: 15.60963

Cumulative Model Updates: 63,498
Cumulative Timesteps: 1,059,152,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1059152072...
Checkpoint 1059152072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197,837.53399
Policy Entropy: 1.08159
Value Function Loss: 1.66882

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.06685
Value Function Update Magnitude: 0.11560

Collected Steps per Second: 3,801.80121
Overall Steps per Second: 3,127.94501

Timestep Collection Time: 13.16429
Timestep Consumption Time: 2.83599
PPO Batch Consumption Time: 0.04935
Total Iteration Time: 16.00028

Cumulative Model Updates: 63,501
Cumulative Timesteps: 1,059,202,120

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700,434.75603
Policy Entropy: 1.08511
Value Function Loss: 1.59354

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.06769
Value Function Update Magnitude: 0.11736

Collected Steps per Second: 3,908.96452
Overall Steps per Second: 3,244.63311

Timestep Collection Time: 12.79418
Timestep Consumption Time: 2.61958
PPO Batch Consumption Time: 0.04915
Total Iteration Time: 15.41376

Cumulative Model Updates: 63,504
Cumulative Timesteps: 1,059,252,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1059252132...
Checkpoint 1059252132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820,570.70567
Policy Entropy: 1.08610
Value Function Loss: 1.64267

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.06825
Value Function Update Magnitude: 0.10788

Collected Steps per Second: 4,167.18434
Overall Steps per Second: 3,459.26219

Timestep Collection Time: 12.00571
Timestep Consumption Time: 2.45691
PPO Batch Consumption Time: 0.04902
Total Iteration Time: 14.46262

Cumulative Model Updates: 63,507
Cumulative Timesteps: 1,059,302,162

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421,041.86100
Policy Entropy: 1.08384
Value Function Loss: 1.61347

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.07406
Value Function Update Magnitude: 0.10731

Collected Steps per Second: 3,940.38503
Overall Steps per Second: 3,328.30690

Timestep Collection Time: 12.69774
Timestep Consumption Time: 2.33512
PPO Batch Consumption Time: 0.04973
Total Iteration Time: 15.03287

Cumulative Model Updates: 63,510
Cumulative Timesteps: 1,059,352,196

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1059352196...
Checkpoint 1059352196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243,824.71833
Policy Entropy: 1.08049
Value Function Loss: 1.64428

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.07885
Value Function Update Magnitude: 0.10775

Collected Steps per Second: 4,048.19611
Overall Steps per Second: 3,397.07856

Timestep Collection Time: 12.35118
Timestep Consumption Time: 2.36735
PPO Batch Consumption Time: 0.05162
Total Iteration Time: 14.71853

Cumulative Model Updates: 63,513
Cumulative Timesteps: 1,059,402,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622,276.90977
Policy Entropy: 1.08705
Value Function Loss: 1.66692

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.11768
Policy Update Magnitude: 0.07772
Value Function Update Magnitude: 0.09976

Collected Steps per Second: 3,877.42896
Overall Steps per Second: 3,282.62236

Timestep Collection Time: 12.89772
Timestep Consumption Time: 2.33705
PPO Batch Consumption Time: 0.04934
Total Iteration Time: 15.23477

Cumulative Model Updates: 63,516
Cumulative Timesteps: 1,059,452,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1059452206...
Checkpoint 1059452206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512,156.87612
Policy Entropy: 1.08640
Value Function Loss: 1.64211

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.07350
Value Function Update Magnitude: 0.10392

Collected Steps per Second: 4,193.91597
Overall Steps per Second: 3,422.56549

Timestep Collection Time: 11.93491
Timestep Consumption Time: 2.68979
PPO Batch Consumption Time: 0.04852
Total Iteration Time: 14.62470

Cumulative Model Updates: 63,519
Cumulative Timesteps: 1,059,502,260

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430,220.60874
Policy Entropy: 1.09627
Value Function Loss: 1.66587

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.10269

Collected Steps per Second: 4,008.89533
Overall Steps per Second: 3,248.12172

Timestep Collection Time: 12.47625
Timestep Consumption Time: 2.92218
PPO Batch Consumption Time: 0.05837
Total Iteration Time: 15.39844

Cumulative Model Updates: 63,522
Cumulative Timesteps: 1,059,552,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1059552276...
Checkpoint 1059552276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374,812.13207
Policy Entropy: 1.10294
Value Function Loss: 1.64949

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.10328

Collected Steps per Second: 3,797.94827
Overall Steps per Second: 3,155.88242

Timestep Collection Time: 13.17501
Timestep Consumption Time: 2.68046
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 15.85547

Cumulative Model Updates: 63,525
Cumulative Timesteps: 1,059,602,314

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335,374.69829
Policy Entropy: 1.10150
Value Function Loss: 1.74622

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.09947

Collected Steps per Second: 3,701.11852
Overall Steps per Second: 3,085.60708

Timestep Collection Time: 13.51808
Timestep Consumption Time: 2.69656
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 16.21464

Cumulative Model Updates: 63,528
Cumulative Timesteps: 1,059,652,346

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1059652346...
Checkpoint 1059652346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482,002.19941
Policy Entropy: 1.10069
Value Function Loss: 1.77828

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.07495
Value Function Update Magnitude: 0.10845

Collected Steps per Second: 3,831.11121
Overall Steps per Second: 3,173.76721

Timestep Collection Time: 13.05157
Timestep Consumption Time: 2.70321
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 15.75478

Cumulative Model Updates: 63,531
Cumulative Timesteps: 1,059,702,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,456.17134
Policy Entropy: 1.10241
Value Function Loss: 1.70756

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.07954
Value Function Update Magnitude: 0.11430

Collected Steps per Second: 4,043.34534
Overall Steps per Second: 3,343.17606

Timestep Collection Time: 12.37589
Timestep Consumption Time: 2.59191
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 14.96780

Cumulative Model Updates: 63,534
Cumulative Timesteps: 1,059,752,388

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1059752388...
Checkpoint 1059752388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320,051.38934
Policy Entropy: 1.09431
Value Function Loss: 1.55031

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.07753
Value Function Update Magnitude: 0.11787

Collected Steps per Second: 4,124.95946
Overall Steps per Second: 3,394.77868

Timestep Collection Time: 12.12812
Timestep Consumption Time: 2.60863
PPO Batch Consumption Time: 0.05938
Total Iteration Time: 14.73675

Cumulative Model Updates: 63,537
Cumulative Timesteps: 1,059,802,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284,066.79628
Policy Entropy: 1.10254
Value Function Loss: 1.51906

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.06700
Value Function Update Magnitude: 0.10338

Collected Steps per Second: 4,116.26265
Overall Steps per Second: 3,441.11778

Timestep Collection Time: 12.15131
Timestep Consumption Time: 2.38408
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 14.53539

Cumulative Model Updates: 63,540
Cumulative Timesteps: 1,059,852,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1059852434...
Checkpoint 1059852434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269,872.05702
Policy Entropy: 1.09980
Value Function Loss: 1.51565

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.07288
Value Function Update Magnitude: 0.10951

Collected Steps per Second: 3,562.79863
Overall Steps per Second: 3,041.79416

Timestep Collection Time: 14.03672
Timestep Consumption Time: 2.40424
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 16.44095

Cumulative Model Updates: 63,543
Cumulative Timesteps: 1,059,902,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750,416.31754
Policy Entropy: 1.10700
Value Function Loss: 1.53526

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.07566
Value Function Update Magnitude: 0.12946

Collected Steps per Second: 3,695.23042
Overall Steps per Second: 3,107.52447

Timestep Collection Time: 13.53474
Timestep Consumption Time: 2.55974
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 16.09448

Cumulative Model Updates: 63,546
Cumulative Timesteps: 1,059,952,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1059952458...
Checkpoint 1059952458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478,642.36951
Policy Entropy: 1.10250
Value Function Loss: 1.45644

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.07808
Value Function Update Magnitude: 0.13332

Collected Steps per Second: 3,860.95983
Overall Steps per Second: 3,199.17841

Timestep Collection Time: 12.95015
Timestep Consumption Time: 2.67886
PPO Batch Consumption Time: 0.05130
Total Iteration Time: 15.62901

Cumulative Model Updates: 63,549
Cumulative Timesteps: 1,060,002,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389,312.04455
Policy Entropy: 1.10877
Value Function Loss: 1.54264

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.07311
Value Function Update Magnitude: 0.12432

Collected Steps per Second: 3,787.73517
Overall Steps per Second: 3,136.79683

Timestep Collection Time: 13.21370
Timestep Consumption Time: 2.74207
PPO Batch Consumption Time: 0.06240
Total Iteration Time: 15.95577

Cumulative Model Updates: 63,552
Cumulative Timesteps: 1,060,052,508

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1060052508...
Checkpoint 1060052508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266,330.85941
Policy Entropy: 1.11489
Value Function Loss: 1.51716

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.06819
Value Function Update Magnitude: 0.10651

Collected Steps per Second: 3,991.44503
Overall Steps per Second: 3,289.11516

Timestep Collection Time: 12.53331
Timestep Consumption Time: 2.67626
PPO Batch Consumption Time: 0.05993
Total Iteration Time: 15.20956

Cumulative Model Updates: 63,555
Cumulative Timesteps: 1,060,102,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591,842.18324
Policy Entropy: 1.11026
Value Function Loss: 1.55939

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.07070
Value Function Update Magnitude: 0.11252

Collected Steps per Second: 3,920.55537
Overall Steps per Second: 3,224.27332

Timestep Collection Time: 12.76452
Timestep Consumption Time: 2.75650
PPO Batch Consumption Time: 0.04792
Total Iteration Time: 15.52102

Cumulative Model Updates: 63,558
Cumulative Timesteps: 1,060,152,578

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1060152578...
Checkpoint 1060152578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071,614.59921
Policy Entropy: 1.10849
Value Function Loss: 1.56532

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.08342
Value Function Update Magnitude: 0.11517

Collected Steps per Second: 4,084.49088
Overall Steps per Second: 3,349.44318

Timestep Collection Time: 12.24534
Timestep Consumption Time: 2.68729
PPO Batch Consumption Time: 0.06250
Total Iteration Time: 14.93263

Cumulative Model Updates: 63,561
Cumulative Timesteps: 1,060,202,594

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282,081.22181
Policy Entropy: 1.10336
Value Function Loss: 1.63026

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.08334
Value Function Update Magnitude: 0.11291

Collected Steps per Second: 3,821.83689
Overall Steps per Second: 3,216.14960

Timestep Collection Time: 13.09109
Timestep Consumption Time: 2.46540
PPO Batch Consumption Time: 0.06089
Total Iteration Time: 15.55649

Cumulative Model Updates: 63,564
Cumulative Timesteps: 1,060,252,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1060252626...
Checkpoint 1060252626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679,785.72639
Policy Entropy: 1.09584
Value Function Loss: 1.65459

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.09040
Value Function Update Magnitude: 0.10154

Collected Steps per Second: 3,708.97335
Overall Steps per Second: 3,103.05136

Timestep Collection Time: 13.48837
Timestep Consumption Time: 2.63383
PPO Batch Consumption Time: 0.06049
Total Iteration Time: 16.12220

Cumulative Model Updates: 63,567
Cumulative Timesteps: 1,060,302,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,218.54629
Policy Entropy: 1.10306
Value Function Loss: 1.57268

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.07632
Value Function Update Magnitude: 0.09962

Collected Steps per Second: 3,816.01968
Overall Steps per Second: 3,186.63090

Timestep Collection Time: 13.11052
Timestep Consumption Time: 2.58945
PPO Batch Consumption Time: 0.04906
Total Iteration Time: 15.69997

Cumulative Model Updates: 63,570
Cumulative Timesteps: 1,060,352,684

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1060352684...
Checkpoint 1060352684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464,439.04734
Policy Entropy: 1.10892
Value Function Loss: 1.53964

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.06862
Value Function Update Magnitude: 0.11040

Collected Steps per Second: 4,098.18820
Overall Steps per Second: 3,403.46882

Timestep Collection Time: 12.20344
Timestep Consumption Time: 2.49098
PPO Batch Consumption Time: 0.05363
Total Iteration Time: 14.69442

Cumulative Model Updates: 63,573
Cumulative Timesteps: 1,060,402,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172,169.17012
Policy Entropy: 1.12039
Value Function Loss: 1.55257

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.06844
Value Function Update Magnitude: 0.11087

Collected Steps per Second: 3,860.72950
Overall Steps per Second: 3,234.81535

Timestep Collection Time: 12.95662
Timestep Consumption Time: 2.50702
PPO Batch Consumption Time: 0.05279
Total Iteration Time: 15.46363

Cumulative Model Updates: 63,576
Cumulative Timesteps: 1,060,452,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1060452718...
Checkpoint 1060452718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,379.02164
Policy Entropy: 1.11693
Value Function Loss: 1.62343

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.07575
Value Function Update Magnitude: 0.10924

Collected Steps per Second: 4,145.26493
Overall Steps per Second: 3,395.30627

Timestep Collection Time: 12.06485
Timestep Consumption Time: 2.66490
PPO Batch Consumption Time: 0.05035
Total Iteration Time: 14.72975

Cumulative Model Updates: 63,579
Cumulative Timesteps: 1,060,502,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335,026.04427
Policy Entropy: 1.11211
Value Function Loss: 1.63689

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.07435
Value Function Update Magnitude: 0.11738

Collected Steps per Second: 3,847.41769
Overall Steps per Second: 3,199.32877

Timestep Collection Time: 12.99937
Timestep Consumption Time: 2.63329
PPO Batch Consumption Time: 0.05279
Total Iteration Time: 15.63265

Cumulative Model Updates: 63,582
Cumulative Timesteps: 1,060,552,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1060552744...
Checkpoint 1060552744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455,178.31736
Policy Entropy: 1.11374
Value Function Loss: 1.64205

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.11995

Collected Steps per Second: 3,838.40524
Overall Steps per Second: 3,204.67930

Timestep Collection Time: 13.02676
Timestep Consumption Time: 2.57605
PPO Batch Consumption Time: 0.04935
Total Iteration Time: 15.60281

Cumulative Model Updates: 63,585
Cumulative Timesteps: 1,060,602,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333,644.91826
Policy Entropy: 1.12162
Value Function Loss: 1.58620

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.06680
Value Function Update Magnitude: 0.11237

Collected Steps per Second: 3,770.71326
Overall Steps per Second: 3,163.09873

Timestep Collection Time: 13.26858
Timestep Consumption Time: 2.54882
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 15.81740

Cumulative Model Updates: 63,588
Cumulative Timesteps: 1,060,652,778

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1060652778...
Checkpoint 1060652778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222,206.32483
Policy Entropy: 1.12500
Value Function Loss: 1.64856

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.06772
Value Function Update Magnitude: 0.11544

Collected Steps per Second: 3,709.98741
Overall Steps per Second: 3,104.24112

Timestep Collection Time: 13.47713
Timestep Consumption Time: 2.62986
PPO Batch Consumption Time: 0.05390
Total Iteration Time: 16.10700

Cumulative Model Updates: 63,591
Cumulative Timesteps: 1,060,702,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013,699.33593
Policy Entropy: 1.12417
Value Function Loss: 1.67410

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.11938

Collected Steps per Second: 3,770.82702
Overall Steps per Second: 3,189.08805

Timestep Collection Time: 13.25969
Timestep Consumption Time: 2.41877
PPO Batch Consumption Time: 0.06241
Total Iteration Time: 15.67846

Cumulative Model Updates: 63,594
Cumulative Timesteps: 1,060,752,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1060752778...
Checkpoint 1060752778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390,865.84529
Policy Entropy: 1.13111
Value Function Loss: 1.64709

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.11000

Collected Steps per Second: 3,678.36294
Overall Steps per Second: 3,082.39437

Timestep Collection Time: 13.60116
Timestep Consumption Time: 2.62973
PPO Batch Consumption Time: 0.05037
Total Iteration Time: 16.23089

Cumulative Model Updates: 63,597
Cumulative Timesteps: 1,060,802,808

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299,204.05625
Policy Entropy: 1.14120
Value Function Loss: 1.56915

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.12077

Collected Steps per Second: 3,820.02425
Overall Steps per Second: 3,192.45531

Timestep Collection Time: 13.09049
Timestep Consumption Time: 2.57331
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 15.66381

Cumulative Model Updates: 63,600
Cumulative Timesteps: 1,060,852,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1060852814...
Checkpoint 1060852814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451,161.67514
Policy Entropy: 1.13005
Value Function Loss: 1.56372

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.10998

Collected Steps per Second: 3,745.38277
Overall Steps per Second: 3,163.30731

Timestep Collection Time: 13.36152
Timestep Consumption Time: 2.45863
PPO Batch Consumption Time: 0.06328
Total Iteration Time: 15.82015

Cumulative Model Updates: 63,603
Cumulative Timesteps: 1,060,902,858

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634,969.04278
Policy Entropy: 1.12395
Value Function Loss: 1.63590

Mean KL Divergence: 0.02369
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.11367

Collected Steps per Second: 3,834.86950
Overall Steps per Second: 3,228.40245

Timestep Collection Time: 13.04660
Timestep Consumption Time: 2.45085
PPO Batch Consumption Time: 0.05266
Total Iteration Time: 15.49745

Cumulative Model Updates: 63,606
Cumulative Timesteps: 1,060,952,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1060952890...
Checkpoint 1060952890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420,639.46844
Policy Entropy: 1.13636
Value Function Loss: 1.70040

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.10269

Collected Steps per Second: 3,875.86783
Overall Steps per Second: 3,204.08345

Timestep Collection Time: 12.90446
Timestep Consumption Time: 2.70562
PPO Batch Consumption Time: 0.05299
Total Iteration Time: 15.61008

Cumulative Model Updates: 63,609
Cumulative Timesteps: 1,061,002,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968,955.49871
Policy Entropy: 1.14472
Value Function Loss: 1.62663

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.06564
Value Function Update Magnitude: 0.11141

Collected Steps per Second: 3,878.70176
Overall Steps per Second: 3,205.96447

Timestep Collection Time: 12.90071
Timestep Consumption Time: 2.70708
PPO Batch Consumption Time: 0.05078
Total Iteration Time: 15.60778

Cumulative Model Updates: 63,612
Cumulative Timesteps: 1,061,052,944

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1061052944...
Checkpoint 1061052944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261,564.17721
Policy Entropy: 1.13232
Value Function Loss: 1.58619

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 3,866.83249
Overall Steps per Second: 3,216.23022

Timestep Collection Time: 12.94289
Timestep Consumption Time: 2.61818
PPO Batch Consumption Time: 0.05147
Total Iteration Time: 15.56108

Cumulative Model Updates: 63,615
Cumulative Timesteps: 1,061,102,992

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176,308.12245
Policy Entropy: 1.12580
Value Function Loss: 1.54078

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.12065

Collected Steps per Second: 3,721.82343
Overall Steps per Second: 3,103.79084

Timestep Collection Time: 13.43696
Timestep Consumption Time: 2.67559
PPO Batch Consumption Time: 0.05242
Total Iteration Time: 16.11255

Cumulative Model Updates: 63,618
Cumulative Timesteps: 1,061,153,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1061153002...
Checkpoint 1061153002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326,467.13665
Policy Entropy: 1.13360
Value Function Loss: 1.60514

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.11763

Collected Steps per Second: 3,696.19477
Overall Steps per Second: 3,090.05666

Timestep Collection Time: 13.53933
Timestep Consumption Time: 2.65584
PPO Batch Consumption Time: 0.06066
Total Iteration Time: 16.19517

Cumulative Model Updates: 63,621
Cumulative Timesteps: 1,061,203,046

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532,533.56857
Policy Entropy: 1.14753
Value Function Loss: 1.56580

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.06199
Value Function Update Magnitude: 0.10848

Collected Steps per Second: 3,806.79837
Overall Steps per Second: 3,153.96256

Timestep Collection Time: 13.14543
Timestep Consumption Time: 2.72096
PPO Batch Consumption Time: 0.06181
Total Iteration Time: 15.86639

Cumulative Model Updates: 63,624
Cumulative Timesteps: 1,061,253,088

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1061253088...
Checkpoint 1061253088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352,061.00228
Policy Entropy: 1.12051
Value Function Loss: 1.60654

Mean KL Divergence: 0.03252
SB3 Clip Fraction: 0.16662
Policy Update Magnitude: 0.07222
Value Function Update Magnitude: 0.10893

Collected Steps per Second: 3,707.12093
Overall Steps per Second: 3,109.76532

Timestep Collection Time: 13.49349
Timestep Consumption Time: 2.59197
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 16.08546

Cumulative Model Updates: 63,627
Cumulative Timesteps: 1,061,303,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224,659.77793
Policy Entropy: 1.14486
Value Function Loss: 1.60358

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.11258

Collected Steps per Second: 3,792.34195
Overall Steps per Second: 3,217.36546

Timestep Collection Time: 13.19659
Timestep Consumption Time: 2.35837
PPO Batch Consumption Time: 0.04921
Total Iteration Time: 15.55496

Cumulative Model Updates: 63,630
Cumulative Timesteps: 1,061,353,156

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1061353156...
Checkpoint 1061353156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042,659.41681
Policy Entropy: 1.14075
Value Function Loss: 1.63074

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.06371
Value Function Update Magnitude: 0.10895

Collected Steps per Second: 3,745.80383
Overall Steps per Second: 3,087.58538

Timestep Collection Time: 13.35414
Timestep Consumption Time: 2.84687
PPO Batch Consumption Time: 0.05782
Total Iteration Time: 16.20101

Cumulative Model Updates: 63,633
Cumulative Timesteps: 1,061,403,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922,692.32228
Policy Entropy: 1.12746
Value Function Loss: 1.66843

Mean KL Divergence: 0.03848
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.06717
Value Function Update Magnitude: 0.10400

Collected Steps per Second: 3,756.01303
Overall Steps per Second: 3,126.15836

Timestep Collection Time: 13.31731
Timestep Consumption Time: 2.68316
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 16.00047

Cumulative Model Updates: 63,636
Cumulative Timesteps: 1,061,453,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1061453198...
Checkpoint 1061453198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222,724.75300
Policy Entropy: 1.14097
Value Function Loss: 1.67738

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.06265
Value Function Update Magnitude: 0.11212

Collected Steps per Second: 3,696.00856
Overall Steps per Second: 3,104.57834

Timestep Collection Time: 13.53460
Timestep Consumption Time: 2.57838
PPO Batch Consumption Time: 0.06267
Total Iteration Time: 16.11298

Cumulative Model Updates: 63,639
Cumulative Timesteps: 1,061,503,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344,671.34355
Policy Entropy: 1.14066
Value Function Loss: 1.69147

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.10995

Collected Steps per Second: 3,696.18492
Overall Steps per Second: 3,083.30500

Timestep Collection Time: 13.53612
Timestep Consumption Time: 2.69062
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 16.22674

Cumulative Model Updates: 63,642
Cumulative Timesteps: 1,061,553,254

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1061553254...
Checkpoint 1061553254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586,709.38130
Policy Entropy: 1.12729
Value Function Loss: 1.60794

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.15082
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.11694

Collected Steps per Second: 3,794.20534
Overall Steps per Second: 3,175.57174

Timestep Collection Time: 13.18642
Timestep Consumption Time: 2.56885
PPO Batch Consumption Time: 0.05382
Total Iteration Time: 15.75527

Cumulative Model Updates: 63,645
Cumulative Timesteps: 1,061,603,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319,662.91056
Policy Entropy: 1.13990
Value Function Loss: 1.60048

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.10979

Collected Steps per Second: 3,933.30759
Overall Steps per Second: 3,307.38090

Timestep Collection Time: 12.71652
Timestep Consumption Time: 2.40662
PPO Batch Consumption Time: 0.05885
Total Iteration Time: 15.12314

Cumulative Model Updates: 63,648
Cumulative Timesteps: 1,061,653,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1061653304...
Checkpoint 1061653304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194,073.96367
Policy Entropy: 1.14077
Value Function Loss: 1.60512

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.09876

Collected Steps per Second: 3,797.93452
Overall Steps per Second: 3,162.04147

Timestep Collection Time: 13.17190
Timestep Consumption Time: 2.64890
PPO Batch Consumption Time: 0.06110
Total Iteration Time: 15.82079

Cumulative Model Updates: 63,651
Cumulative Timesteps: 1,061,703,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190,323.48823
Policy Entropy: 1.12244
Value Function Loss: 1.60577

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.11152

Collected Steps per Second: 3,691.46033
Overall Steps per Second: 3,145.74034

Timestep Collection Time: 13.55778
Timestep Consumption Time: 2.35199
PPO Batch Consumption Time: 0.06405
Total Iteration Time: 15.90977

Cumulative Model Updates: 63,654
Cumulative Timesteps: 1,061,753,378

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1061753378...
Checkpoint 1061753378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293,358.52189
Policy Entropy: 1.13136
Value Function Loss: 1.63343

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.10173

Collected Steps per Second: 3,750.24979
Overall Steps per Second: 3,149.79989

Timestep Collection Time: 13.34098
Timestep Consumption Time: 2.54321
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 15.88418

Cumulative Model Updates: 63,657
Cumulative Timesteps: 1,061,803,410

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416,430.73611
Policy Entropy: 1.12597
Value Function Loss: 1.61407

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.11081

Collected Steps per Second: 3,827.10484
Overall Steps per Second: 3,209.75325

Timestep Collection Time: 13.06523
Timestep Consumption Time: 2.51292
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 15.57814

Cumulative Model Updates: 63,660
Cumulative Timesteps: 1,061,853,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1061853412...
Checkpoint 1061853412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512,077.31462
Policy Entropy: 1.13740
Value Function Loss: 1.64410

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.12887

Collected Steps per Second: 4,080.19034
Overall Steps per Second: 3,327.27148

Timestep Collection Time: 12.26462
Timestep Consumption Time: 2.77533
PPO Batch Consumption Time: 0.05144
Total Iteration Time: 15.03995

Cumulative Model Updates: 63,663
Cumulative Timesteps: 1,061,903,454

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284,856.48484
Policy Entropy: 1.11653
Value Function Loss: 1.58508

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.12437

Collected Steps per Second: 4,068.11580
Overall Steps per Second: 3,329.91450

Timestep Collection Time: 12.29169
Timestep Consumption Time: 2.72492
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 15.01660

Cumulative Model Updates: 63,666
Cumulative Timesteps: 1,061,953,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1061953458...
Checkpoint 1061953458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224,716.28091
Policy Entropy: 1.13627
Value Function Loss: 1.59966

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.10920

Collected Steps per Second: 3,941.11643
Overall Steps per Second: 3,289.41418

Timestep Collection Time: 12.68930
Timestep Consumption Time: 2.51402
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 15.20331

Cumulative Model Updates: 63,669
Cumulative Timesteps: 1,062,003,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440,931.27384
Policy Entropy: 1.13456
Value Function Loss: 1.56390

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.09898

Collected Steps per Second: 3,887.25180
Overall Steps per Second: 3,224.73987

Timestep Collection Time: 12.87182
Timestep Consumption Time: 2.64447
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 15.51629

Cumulative Model Updates: 63,672
Cumulative Timesteps: 1,062,053,504

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1062053504...
Checkpoint 1062053504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307,727.79511
Policy Entropy: 1.12400
Value Function Loss: 1.54130

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.10164

Collected Steps per Second: 3,795.67121
Overall Steps per Second: 3,197.03430

Timestep Collection Time: 13.17290
Timestep Consumption Time: 2.46659
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 15.63949

Cumulative Model Updates: 63,675
Cumulative Timesteps: 1,062,103,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436,619.83690
Policy Entropy: 1.11774
Value Function Loss: 1.46766

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 3,657.52229
Overall Steps per Second: 3,076.31022

Timestep Collection Time: 13.67100
Timestep Consumption Time: 2.58288
PPO Batch Consumption Time: 0.05324
Total Iteration Time: 16.25389

Cumulative Model Updates: 63,678
Cumulative Timesteps: 1,062,153,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1062153506...
Checkpoint 1062153506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284,674.29572
Policy Entropy: 1.12928
Value Function Loss: 1.51764

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.10502

Collected Steps per Second: 3,898.37811
Overall Steps per Second: 3,252.12689

Timestep Collection Time: 12.83046
Timestep Consumption Time: 2.54962
PPO Batch Consumption Time: 0.05148
Total Iteration Time: 15.38009

Cumulative Model Updates: 63,681
Cumulative Timesteps: 1,062,203,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,598,327.46432
Policy Entropy: 1.13653
Value Function Loss: 1.52609

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.10202

Collected Steps per Second: 3,963.28881
Overall Steps per Second: 3,260.38681

Timestep Collection Time: 12.62840
Timestep Consumption Time: 2.72254
PPO Batch Consumption Time: 0.06494
Total Iteration Time: 15.35094

Cumulative Model Updates: 63,684
Cumulative Timesteps: 1,062,253,574

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1062253574...
Checkpoint 1062253574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165,785.79862
Policy Entropy: 1.10790
Value Function Loss: 1.60153

Mean KL Divergence: 0.02524
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.10746

Collected Steps per Second: 3,795.00659
Overall Steps per Second: 3,217.31283

Timestep Collection Time: 13.17521
Timestep Consumption Time: 2.36571
PPO Batch Consumption Time: 0.05193
Total Iteration Time: 15.54092

Cumulative Model Updates: 63,687
Cumulative Timesteps: 1,062,303,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938,597.94878
Policy Entropy: 1.12683
Value Function Loss: 1.58046

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.10879

Collected Steps per Second: 3,800.54349
Overall Steps per Second: 3,223.87080

Timestep Collection Time: 13.16338
Timestep Consumption Time: 2.35461
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 15.51799

Cumulative Model Updates: 63,690
Cumulative Timesteps: 1,062,353,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1062353602...
Checkpoint 1062353602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405,960.17708
Policy Entropy: 1.12695
Value Function Loss: 1.62122

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.10521

Collected Steps per Second: 3,899.00181
Overall Steps per Second: 3,229.82491

Timestep Collection Time: 12.82841
Timestep Consumption Time: 2.65788
PPO Batch Consumption Time: 0.05253
Total Iteration Time: 15.48629

Cumulative Model Updates: 63,693
Cumulative Timesteps: 1,062,403,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529,869.24300
Policy Entropy: 1.11844
Value Function Loss: 1.55774

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.10070

Collected Steps per Second: 3,776.15886
Overall Steps per Second: 3,144.48731

Timestep Collection Time: 13.25527
Timestep Consumption Time: 2.66275
PPO Batch Consumption Time: 0.05443
Total Iteration Time: 15.91802

Cumulative Model Updates: 63,696
Cumulative Timesteps: 1,062,453,674

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1062453674...
Checkpoint 1062453674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200,993.22582
Policy Entropy: 1.10467
Value Function Loss: 1.57482

Mean KL Divergence: 0.02529
SB3 Clip Fraction: 0.17062
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.10063

Collected Steps per Second: 3,870.08536
Overall Steps per Second: 3,219.79402

Timestep Collection Time: 12.92168
Timestep Consumption Time: 2.60975
PPO Batch Consumption Time: 0.06477
Total Iteration Time: 15.53143

Cumulative Model Updates: 63,699
Cumulative Timesteps: 1,062,503,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959,386.62868
Policy Entropy: 1.11412
Value Function Loss: 1.45860

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.10316

Collected Steps per Second: 3,834.84366
Overall Steps per Second: 3,241.07843

Timestep Collection Time: 13.04825
Timestep Consumption Time: 2.39044
PPO Batch Consumption Time: 0.05248
Total Iteration Time: 15.43869

Cumulative Model Updates: 63,702
Cumulative Timesteps: 1,062,553,720

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1062553720...
Checkpoint 1062553720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286,036.38653
Policy Entropy: 1.12539
Value Function Loss: 1.50417

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.06524
Value Function Update Magnitude: 0.09891

Collected Steps per Second: 3,790.55565
Overall Steps per Second: 3,180.30791

Timestep Collection Time: 13.19543
Timestep Consumption Time: 2.53198
PPO Batch Consumption Time: 0.05394
Total Iteration Time: 15.72741

Cumulative Model Updates: 63,705
Cumulative Timesteps: 1,062,603,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748,702.40260
Policy Entropy: 1.10349
Value Function Loss: 1.47369

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.09527

Collected Steps per Second: 3,960.69745
Overall Steps per Second: 3,266.24711

Timestep Collection Time: 12.62454
Timestep Consumption Time: 2.68416
PPO Batch Consumption Time: 0.05058
Total Iteration Time: 15.30870

Cumulative Model Updates: 63,708
Cumulative Timesteps: 1,062,653,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1062653740...
Checkpoint 1062653740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645,913.46454
Policy Entropy: 1.10645
Value Function Loss: 1.53621

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.10491

Collected Steps per Second: 3,727.50831
Overall Steps per Second: 3,104.38819

Timestep Collection Time: 13.42076
Timestep Consumption Time: 2.69385
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 16.11461

Cumulative Model Updates: 63,711
Cumulative Timesteps: 1,062,703,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530,216.47644
Policy Entropy: 1.10167
Value Function Loss: 1.49289

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.07112
Value Function Update Magnitude: 0.13464

Collected Steps per Second: 3,990.25839
Overall Steps per Second: 3,364.10718

Timestep Collection Time: 12.53152
Timestep Consumption Time: 2.33245
PPO Batch Consumption Time: 0.05918
Total Iteration Time: 14.86397

Cumulative Model Updates: 63,714
Cumulative Timesteps: 1,062,753,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1062753770...
Checkpoint 1062753770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122,835.09931
Policy Entropy: 1.10256
Value Function Loss: 1.52869

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.07671
Value Function Update Magnitude: 0.13652

Collected Steps per Second: 3,602.46279
Overall Steps per Second: 3,057.43051

Timestep Collection Time: 13.88384
Timestep Consumption Time: 2.47500
PPO Batch Consumption Time: 0.06417
Total Iteration Time: 16.35883

Cumulative Model Updates: 63,717
Cumulative Timesteps: 1,062,803,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844,960.90547
Policy Entropy: 1.09405
Value Function Loss: 1.52862

Mean KL Divergence: 0.02522
SB3 Clip Fraction: 0.16799
Policy Update Magnitude: 0.07070
Value Function Update Magnitude: 0.12576

Collected Steps per Second: 3,825.36075
Overall Steps per Second: 3,231.27294

Timestep Collection Time: 13.07119
Timestep Consumption Time: 2.40321
PPO Batch Consumption Time: 0.05072
Total Iteration Time: 15.47440

Cumulative Model Updates: 63,720
Cumulative Timesteps: 1,062,853,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1062853788...
Checkpoint 1062853788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,489.17616
Policy Entropy: 1.11147
Value Function Loss: 1.57400

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.10594

Collected Steps per Second: 3,941.87630
Overall Steps per Second: 3,296.86583

Timestep Collection Time: 12.69040
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.05207
Total Iteration Time: 15.17320

Cumulative Model Updates: 63,723
Cumulative Timesteps: 1,062,903,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380,371.87637
Policy Entropy: 1.11209
Value Function Loss: 1.59736

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.06706
Value Function Update Magnitude: 0.10040

Collected Steps per Second: 3,912.85105
Overall Steps per Second: 3,199.11607

Timestep Collection Time: 12.78301
Timestep Consumption Time: 2.85194
PPO Batch Consumption Time: 0.06128
Total Iteration Time: 15.63494

Cumulative Model Updates: 63,726
Cumulative Timesteps: 1,062,953,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1062953830...
Checkpoint 1062953830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458,726.26545
Policy Entropy: 1.09498
Value Function Loss: 1.67126

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.06739
Value Function Update Magnitude: 0.10045

Collected Steps per Second: 3,836.54475
Overall Steps per Second: 3,147.41668

Timestep Collection Time: 13.03308
Timestep Consumption Time: 2.85360
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 15.88668

Cumulative Model Updates: 63,729
Cumulative Timesteps: 1,063,003,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502,312.77873
Policy Entropy: 1.08882
Value Function Loss: 1.65891

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.15810
Policy Update Magnitude: 0.06515
Value Function Update Magnitude: 0.10432

Collected Steps per Second: 3,813.47061
Overall Steps per Second: 3,176.32696

Timestep Collection Time: 13.11509
Timestep Consumption Time: 2.63077
PPO Batch Consumption Time: 0.05342
Total Iteration Time: 15.74586

Cumulative Model Updates: 63,732
Cumulative Timesteps: 1,063,053,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1063053846...
Checkpoint 1063053846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550,603.35739
Policy Entropy: 1.10821
Value Function Loss: 1.60052

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.12245

Collected Steps per Second: 3,837.87905
Overall Steps per Second: 3,195.75208

Timestep Collection Time: 13.03220
Timestep Consumption Time: 2.61858
PPO Batch Consumption Time: 0.05362
Total Iteration Time: 15.65078

Cumulative Model Updates: 63,735
Cumulative Timesteps: 1,063,103,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039,027.60269
Policy Entropy: 1.11569
Value Function Loss: 1.45362

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.11360

Collected Steps per Second: 3,818.40400
Overall Steps per Second: 3,160.93830

Timestep Collection Time: 13.10024
Timestep Consumption Time: 2.72481
PPO Batch Consumption Time: 0.06645
Total Iteration Time: 15.82505

Cumulative Model Updates: 63,738
Cumulative Timesteps: 1,063,153,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1063153884...
Checkpoint 1063153884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602,349.45967
Policy Entropy: 1.10250
Value Function Loss: 1.43478

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.10802

Collected Steps per Second: 3,927.91042
Overall Steps per Second: 3,253.23411

Timestep Collection Time: 12.72992
Timestep Consumption Time: 2.64001
PPO Batch Consumption Time: 0.05012
Total Iteration Time: 15.36994

Cumulative Model Updates: 63,741
Cumulative Timesteps: 1,063,203,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456,396.01604
Policy Entropy: 1.09756
Value Function Loss: 1.37943

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.11351

Collected Steps per Second: 3,718.28914
Overall Steps per Second: 3,099.74976

Timestep Collection Time: 13.45027
Timestep Consumption Time: 2.68393
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 16.13421

Cumulative Model Updates: 63,744
Cumulative Timesteps: 1,063,253,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1063253898...
Checkpoint 1063253898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242,519.71590
Policy Entropy: 1.10379
Value Function Loss: 1.43710

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.11277

Collected Steps per Second: 3,688.24935
Overall Steps per Second: 3,120.16827

Timestep Collection Time: 13.56036
Timestep Consumption Time: 2.46890
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 16.02926

Cumulative Model Updates: 63,747
Cumulative Timesteps: 1,063,303,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,972,854.39407
Policy Entropy: 1.11017
Value Function Loss: 1.45640

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.09957

Collected Steps per Second: 3,813.45926
Overall Steps per Second: 3,237.25903

Timestep Collection Time: 13.11460
Timestep Consumption Time: 2.33427
PPO Batch Consumption Time: 0.05207
Total Iteration Time: 15.44887

Cumulative Model Updates: 63,750
Cumulative Timesteps: 1,063,353,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1063353924...
Checkpoint 1063353924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999,430.23669
Policy Entropy: 1.09347
Value Function Loss: 1.45797

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.06980
Value Function Update Magnitude: 0.09887

Collected Steps per Second: 3,666.16580
Overall Steps per Second: 3,041.60495

Timestep Collection Time: 13.65296
Timestep Consumption Time: 2.80349
PPO Batch Consumption Time: 0.06549
Total Iteration Time: 16.45644

Cumulative Model Updates: 63,753
Cumulative Timesteps: 1,063,403,978

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159,434.62522
Policy Entropy: 1.09905
Value Function Loss: 1.45275

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.16389
Policy Update Magnitude: 0.06527
Value Function Update Magnitude: 0.11261

Collected Steps per Second: 3,856.02560
Overall Steps per Second: 3,224.00218

Timestep Collection Time: 12.96672
Timestep Consumption Time: 2.54196
PPO Batch Consumption Time: 0.05110
Total Iteration Time: 15.50867

Cumulative Model Updates: 63,756
Cumulative Timesteps: 1,063,453,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1063453978...
Checkpoint 1063453978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,056.64928
Policy Entropy: 1.09894
Value Function Loss: 1.46397

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.15684
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.11658

Collected Steps per Second: 3,691.30749
Overall Steps per Second: 3,095.77174

Timestep Collection Time: 13.55184
Timestep Consumption Time: 2.60698
PPO Batch Consumption Time: 0.04875
Total Iteration Time: 16.15881

Cumulative Model Updates: 63,759
Cumulative Timesteps: 1,063,504,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613,804.05389
Policy Entropy: 1.08308
Value Function Loss: 1.51578

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.12020

Collected Steps per Second: 3,872.74516
Overall Steps per Second: 3,237.12812

Timestep Collection Time: 12.91797
Timestep Consumption Time: 2.53647
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 15.45444

Cumulative Model Updates: 63,762
Cumulative Timesteps: 1,063,554,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1063554030...
Checkpoint 1063554030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,991.67125
Policy Entropy: 1.07920
Value Function Loss: 1.48251

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.11281

Collected Steps per Second: 3,603.71231
Overall Steps per Second: 3,028.95350

Timestep Collection Time: 13.87958
Timestep Consumption Time: 2.63372
PPO Batch Consumption Time: 0.05143
Total Iteration Time: 16.51329

Cumulative Model Updates: 63,765
Cumulative Timesteps: 1,063,604,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458,678.78405
Policy Entropy: 1.09286
Value Function Loss: 1.58901

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.09837

Collected Steps per Second: 3,794.21107
Overall Steps per Second: 3,173.48403

Timestep Collection Time: 13.18904
Timestep Consumption Time: 2.57975
PPO Batch Consumption Time: 0.05843
Total Iteration Time: 15.76879

Cumulative Model Updates: 63,768
Cumulative Timesteps: 1,063,654,090

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1063654090...
Checkpoint 1063654090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724,453.43072
Policy Entropy: 1.09337
Value Function Loss: 1.63068

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.09910

Collected Steps per Second: 3,785.26110
Overall Steps per Second: 3,172.94459

Timestep Collection Time: 13.21388
Timestep Consumption Time: 2.55002
PPO Batch Consumption Time: 0.05097
Total Iteration Time: 15.76391

Cumulative Model Updates: 63,771
Cumulative Timesteps: 1,063,704,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697,081.67927
Policy Entropy: 1.08116
Value Function Loss: 1.63161

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.06160
Value Function Update Magnitude: 0.08513

Collected Steps per Second: 3,735.77949
Overall Steps per Second: 3,160.91717

Timestep Collection Time: 13.38998
Timestep Consumption Time: 2.43518
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 15.82515

Cumulative Model Updates: 63,774
Cumulative Timesteps: 1,063,754,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1063754130...
Checkpoint 1063754130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090,126.71572
Policy Entropy: 1.06571
Value Function Loss: 1.55609

Mean KL Divergence: 0.02574
SB3 Clip Fraction: 0.18617
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.08721

Collected Steps per Second: 3,691.13386
Overall Steps per Second: 3,133.27140

Timestep Collection Time: 13.55031
Timestep Consumption Time: 2.41256
PPO Batch Consumption Time: 0.05399
Total Iteration Time: 15.96287

Cumulative Model Updates: 63,777
Cumulative Timesteps: 1,063,804,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157,743.39344
Policy Entropy: 1.08369
Value Function Loss: 1.49259

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.10230

Collected Steps per Second: 3,813.31955
Overall Steps per Second: 3,151.46066

Timestep Collection Time: 13.11928
Timestep Consumption Time: 2.75527
PPO Batch Consumption Time: 0.05398
Total Iteration Time: 15.87454

Cumulative Model Updates: 63,780
Cumulative Timesteps: 1,063,854,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1063854174...
Checkpoint 1063854174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695,038.32210
Policy Entropy: 1.07755
Value Function Loss: 1.50527

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.07146
Value Function Update Magnitude: 0.11726

Collected Steps per Second: 3,888.60961
Overall Steps per Second: 3,235.05602

Timestep Collection Time: 12.86372
Timestep Consumption Time: 2.59876
PPO Batch Consumption Time: 0.05347
Total Iteration Time: 15.46248

Cumulative Model Updates: 63,783
Cumulative Timesteps: 1,063,904,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,275,005.45068
Policy Entropy: 1.07369
Value Function Loss: 1.51491

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.07669
Value Function Update Magnitude: 0.12362

Collected Steps per Second: 3,864.24161
Overall Steps per Second: 3,202.80539

Timestep Collection Time: 12.95002
Timestep Consumption Time: 2.67441
PPO Batch Consumption Time: 0.05214
Total Iteration Time: 15.62443

Cumulative Model Updates: 63,786
Cumulative Timesteps: 1,063,954,238

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1063954238...
Checkpoint 1063954238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594,978.29058
Policy Entropy: 1.07857
Value Function Loss: 1.52572

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.07182
Value Function Update Magnitude: 0.12821

Collected Steps per Second: 3,787.69908
Overall Steps per Second: 3,136.47523

Timestep Collection Time: 13.20538
Timestep Consumption Time: 2.74182
PPO Batch Consumption Time: 0.05039
Total Iteration Time: 15.94720

Cumulative Model Updates: 63,789
Cumulative Timesteps: 1,064,004,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078,232.04932
Policy Entropy: 1.08758
Value Function Loss: 1.49847

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.07305
Value Function Update Magnitude: 0.13207

Collected Steps per Second: 3,875.99909
Overall Steps per Second: 3,198.47709

Timestep Collection Time: 12.90248
Timestep Consumption Time: 2.73309
PPO Batch Consumption Time: 0.06134
Total Iteration Time: 15.63557

Cumulative Model Updates: 63,792
Cumulative Timesteps: 1,064,054,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1064054266...
Checkpoint 1064054266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912,198.91732
Policy Entropy: 1.08179
Value Function Loss: 1.42856

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.07357
Value Function Update Magnitude: 0.13908

Collected Steps per Second: 3,876.40825
Overall Steps per Second: 3,228.90917

Timestep Collection Time: 12.90060
Timestep Consumption Time: 2.58698
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 15.48758

Cumulative Model Updates: 63,795
Cumulative Timesteps: 1,064,104,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899,492.74560
Policy Entropy: 1.08786
Value Function Loss: 1.44895

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 0.08102
Value Function Update Magnitude: 0.14797

Collected Steps per Second: 3,744.79235
Overall Steps per Second: 3,112.74693

Timestep Collection Time: 13.35775
Timestep Consumption Time: 2.71230
PPO Batch Consumption Time: 0.04905
Total Iteration Time: 16.07005

Cumulative Model Updates: 63,798
Cumulative Timesteps: 1,064,154,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1064154296...
Checkpoint 1064154296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432,274.47806
Policy Entropy: 1.07680
Value Function Loss: 1.45465

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.07502
Value Function Update Magnitude: 0.15422

Collected Steps per Second: 3,962.14926
Overall Steps per Second: 3,287.93346

Timestep Collection Time: 12.62648
Timestep Consumption Time: 2.58916
PPO Batch Consumption Time: 0.05399
Total Iteration Time: 15.21564

Cumulative Model Updates: 63,801
Cumulative Timesteps: 1,064,204,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928,286.13896
Policy Entropy: 1.08466
Value Function Loss: 1.52722

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.07218
Value Function Update Magnitude: 0.14387

Collected Steps per Second: 3,893.88176
Overall Steps per Second: 3,248.20846

Timestep Collection Time: 12.85247
Timestep Consumption Time: 2.55479
PPO Batch Consumption Time: 0.05938
Total Iteration Time: 15.40726

Cumulative Model Updates: 63,804
Cumulative Timesteps: 1,064,254,370

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1064254370...
Checkpoint 1064254370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402,833.06211
Policy Entropy: 1.07853
Value Function Loss: 1.55105

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.17327
Policy Update Magnitude: 0.06243
Value Function Update Magnitude: 0.14644

Collected Steps per Second: 4,023.64438
Overall Steps per Second: 3,351.60083

Timestep Collection Time: 12.42804
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.05101
Total Iteration Time: 14.92003

Cumulative Model Updates: 63,807
Cumulative Timesteps: 1,064,304,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286,646.92675
Policy Entropy: 1.07394
Value Function Loss: 1.54956

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.13423

Collected Steps per Second: 3,704.08760
Overall Steps per Second: 3,143.32174

Timestep Collection Time: 13.50184
Timestep Consumption Time: 2.40872
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 15.91056

Cumulative Model Updates: 63,810
Cumulative Timesteps: 1,064,354,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1064354388...
Checkpoint 1064354388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469,216.87528
Policy Entropy: 1.06027
Value Function Loss: 1.53642

Mean KL Divergence: 0.02913
SB3 Clip Fraction: 0.21608
Policy Update Magnitude: 0.06482
Value Function Update Magnitude: 0.12035

Collected Steps per Second: 3,871.03837
Overall Steps per Second: 3,258.33479

Timestep Collection Time: 12.92728
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.05764
Total Iteration Time: 15.35815

Cumulative Model Updates: 63,813
Cumulative Timesteps: 1,064,404,430

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125,388.73881
Policy Entropy: 1.08909
Value Function Loss: 1.51004

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14998
Policy Update Magnitude: 0.06770
Value Function Update Magnitude: 0.11071

Collected Steps per Second: 3,888.17276
Overall Steps per Second: 3,207.65195

Timestep Collection Time: 12.87031
Timestep Consumption Time: 2.73051
PPO Batch Consumption Time: 0.05783
Total Iteration Time: 15.60082

Cumulative Model Updates: 63,816
Cumulative Timesteps: 1,064,454,472

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1064454472...
Checkpoint 1064454472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578,722.92344
Policy Entropy: 1.07209
Value Function Loss: 1.41361

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.16526
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.10178

Collected Steps per Second: 3,766.42942
Overall Steps per Second: 3,097.23478

Timestep Collection Time: 13.28048
Timestep Consumption Time: 2.86941
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 16.14989

Cumulative Model Updates: 63,819
Cumulative Timesteps: 1,064,504,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900,704.70897
Policy Entropy: 1.07411
Value Function Loss: 1.39474

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.16159
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.09522

Collected Steps per Second: 3,852.58253
Overall Steps per Second: 3,211.90311

Timestep Collection Time: 12.98609
Timestep Consumption Time: 2.59034
PPO Batch Consumption Time: 0.04977
Total Iteration Time: 15.57643

Cumulative Model Updates: 63,822
Cumulative Timesteps: 1,064,554,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1064554522...
Checkpoint 1064554522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552,317.10588
Policy Entropy: 1.08600
Value Function Loss: 1.35354

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.15169
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.09612

Collected Steps per Second: 3,898.53463
Overall Steps per Second: 3,239.68160

Timestep Collection Time: 12.82687
Timestep Consumption Time: 2.60860
PPO Batch Consumption Time: 0.05353
Total Iteration Time: 15.43547

Cumulative Model Updates: 63,825
Cumulative Timesteps: 1,064,604,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,093,754.81268
Policy Entropy: 1.08738
Value Function Loss: 1.42104

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.10064

Collected Steps per Second: 3,624.94901
Overall Steps per Second: 3,065.34487

Timestep Collection Time: 13.80047
Timestep Consumption Time: 2.51939
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 16.31986

Cumulative Model Updates: 63,828
Cumulative Timesteps: 1,064,654,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1064654554...
Checkpoint 1064654554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754,702.70038
Policy Entropy: 1.07666
Value Function Loss: 1.41234

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.12284

Collected Steps per Second: 3,732.98844
Overall Steps per Second: 3,130.75944

Timestep Collection Time: 13.39892
Timestep Consumption Time: 2.57740
PPO Batch Consumption Time: 0.05777
Total Iteration Time: 15.97632

Cumulative Model Updates: 63,831
Cumulative Timesteps: 1,064,704,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422,756.39641
Policy Entropy: 1.07185
Value Function Loss: 1.40357

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.17401
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.12515

Collected Steps per Second: 3,918.24306
Overall Steps per Second: 3,232.38737

Timestep Collection Time: 12.76950
Timestep Consumption Time: 2.70946
PPO Batch Consumption Time: 0.06518
Total Iteration Time: 15.47896

Cumulative Model Updates: 63,834
Cumulative Timesteps: 1,064,754,606

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1064754606...
Checkpoint 1064754606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408,197.38153
Policy Entropy: 1.08067
Value Function Loss: 1.42488

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.11998

Collected Steps per Second: 3,732.51805
Overall Steps per Second: 3,135.47952

Timestep Collection Time: 13.40221
Timestep Consumption Time: 2.55197
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 15.95418

Cumulative Model Updates: 63,837
Cumulative Timesteps: 1,064,804,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030,247.75092
Policy Entropy: 1.09509
Value Function Loss: 1.38046

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.11253

Collected Steps per Second: 4,066.64622
Overall Steps per Second: 3,381.62548

Timestep Collection Time: 12.30498
Timestep Consumption Time: 2.49264
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 14.79762

Cumulative Model Updates: 63,840
Cumulative Timesteps: 1,064,854,670

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1064854670...
Checkpoint 1064854670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528,791.46168
Policy Entropy: 1.06419
Value Function Loss: 1.43881

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.15711
Policy Update Magnitude: 0.06065
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 3,814.61900
Overall Steps per Second: 3,217.95866

Timestep Collection Time: 13.11638
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.06465
Total Iteration Time: 15.54837

Cumulative Model Updates: 63,843
Cumulative Timesteps: 1,064,904,704

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717,579.67905
Policy Entropy: 1.08848
Value Function Loss: 1.36502

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.16874
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.09724

Collected Steps per Second: 4,157.29525
Overall Steps per Second: 3,443.09063

Timestep Collection Time: 12.03330
Timestep Consumption Time: 2.49608
PPO Batch Consumption Time: 0.04846
Total Iteration Time: 14.52939

Cumulative Model Updates: 63,846
Cumulative Timesteps: 1,064,954,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1064954730...
Checkpoint 1064954730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,149,322.63136
Policy Entropy: 1.07172
Value Function Loss: 1.34766

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.09344

Collected Steps per Second: 3,738.47142
Overall Steps per Second: 3,098.89356

Timestep Collection Time: 13.38301
Timestep Consumption Time: 2.76211
PPO Batch Consumption Time: 0.06495
Total Iteration Time: 16.14512

Cumulative Model Updates: 63,849
Cumulative Timesteps: 1,065,004,762

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,760,950.26544
Policy Entropy: 1.07112
Value Function Loss: 1.31714

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.06686
Value Function Update Magnitude: 0.09278

Collected Steps per Second: 3,765.70617
Overall Steps per Second: 3,114.83002

Timestep Collection Time: 13.27932
Timestep Consumption Time: 2.77485
PPO Batch Consumption Time: 0.05338
Total Iteration Time: 16.05417

Cumulative Model Updates: 63,852
Cumulative Timesteps: 1,065,054,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1065054768...
Checkpoint 1065054768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369,972.93372
Policy Entropy: 1.05175
Value Function Loss: 1.44526

Mean KL Divergence: 0.02760
SB3 Clip Fraction: 0.20324
Policy Update Magnitude: 0.06356
Value Function Update Magnitude: 0.09885

Collected Steps per Second: 3,827.68764
Overall Steps per Second: 3,162.99872

Timestep Collection Time: 13.07578
Timestep Consumption Time: 2.74781
PPO Batch Consumption Time: 0.05180
Total Iteration Time: 15.82359

Cumulative Model Updates: 63,855
Cumulative Timesteps: 1,065,104,818

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475,454.54618
Policy Entropy: 1.07812
Value Function Loss: 1.51373

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.06658
Value Function Update Magnitude: 0.10956

Collected Steps per Second: 3,726.50712
Overall Steps per Second: 3,079.63294

Timestep Collection Time: 13.42490
Timestep Consumption Time: 2.81989
PPO Batch Consumption Time: 0.05217
Total Iteration Time: 16.24479

Cumulative Model Updates: 63,858
Cumulative Timesteps: 1,065,154,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1065154846...
Checkpoint 1065154846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,931,493.71211
Policy Entropy: 1.06054
Value Function Loss: 1.54217

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.06400
Value Function Update Magnitude: 0.10615

Collected Steps per Second: 3,674.17368
Overall Steps per Second: 3,037.36224

Timestep Collection Time: 13.62048
Timestep Consumption Time: 2.85566
PPO Batch Consumption Time: 0.06892
Total Iteration Time: 16.47614

Cumulative Model Updates: 63,861
Cumulative Timesteps: 1,065,204,890

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,177,586.24146
Policy Entropy: 1.05295
Value Function Loss: 1.55325

Mean KL Divergence: 0.02570
SB3 Clip Fraction: 0.18610
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.12630

Collected Steps per Second: 3,843.32494
Overall Steps per Second: 3,170.77679

Timestep Collection Time: 13.01061
Timestep Consumption Time: 2.75966
PPO Batch Consumption Time: 0.05903
Total Iteration Time: 15.77027

Cumulative Model Updates: 63,864
Cumulative Timesteps: 1,065,254,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1065254894...
Checkpoint 1065254894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488,942.67932
Policy Entropy: 1.06122
Value Function Loss: 1.60057

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.14472

Collected Steps per Second: 3,717.28783
Overall Steps per Second: 3,096.51595

Timestep Collection Time: 13.45282
Timestep Consumption Time: 2.69694
PPO Batch Consumption Time: 0.04996
Total Iteration Time: 16.14976

Cumulative Model Updates: 63,867
Cumulative Timesteps: 1,065,304,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970,469.41416
Policy Entropy: 1.07301
Value Function Loss: 1.57024

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.16120
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.13838

Collected Steps per Second: 3,785.73729
Overall Steps per Second: 3,164.13534

Timestep Collection Time: 13.21909
Timestep Consumption Time: 2.59692
PPO Batch Consumption Time: 0.05288
Total Iteration Time: 15.81601

Cumulative Model Updates: 63,870
Cumulative Timesteps: 1,065,354,946

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1065354946...
Checkpoint 1065354946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229,554.90306
Policy Entropy: 1.06061
Value Function Loss: 1.49299

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.11933

Collected Steps per Second: 3,666.65019
Overall Steps per Second: 3,098.34910

Timestep Collection Time: 13.64679
Timestep Consumption Time: 2.50310
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 16.14989

Cumulative Model Updates: 63,873
Cumulative Timesteps: 1,065,404,984

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257,570.81905
Policy Entropy: 1.06666
Value Function Loss: 1.47801

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.10719

Collected Steps per Second: 3,729.69580
Overall Steps per Second: 3,180.68740

Timestep Collection Time: 13.41235
Timestep Consumption Time: 2.31506
PPO Batch Consumption Time: 0.05929
Total Iteration Time: 15.72742

Cumulative Model Updates: 63,876
Cumulative Timesteps: 1,065,455,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1065455008...
Checkpoint 1065455008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007,071.92188
Policy Entropy: 1.06966
Value Function Loss: 1.41545

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.10464

Collected Steps per Second: 3,699.09891
Overall Steps per Second: 3,127.05124

Timestep Collection Time: 13.52816
Timestep Consumption Time: 2.47478
PPO Batch Consumption Time: 0.05161
Total Iteration Time: 16.00294

Cumulative Model Updates: 63,879
Cumulative Timesteps: 1,065,505,050

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760,722.28884
Policy Entropy: 1.06434
Value Function Loss: 1.42384

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.07303
Value Function Update Magnitude: 0.11937

Collected Steps per Second: 3,875.70545
Overall Steps per Second: 3,224.42781

Timestep Collection Time: 12.91275
Timestep Consumption Time: 2.60815
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 15.52089

Cumulative Model Updates: 63,882
Cumulative Timesteps: 1,065,555,096

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1065555096...
Checkpoint 1065555096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446,083.78195
Policy Entropy: 1.06657
Value Function Loss: 1.47593

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.07590
Value Function Update Magnitude: 0.13524

Collected Steps per Second: 3,841.41576
Overall Steps per Second: 3,182.93592

Timestep Collection Time: 13.02124
Timestep Consumption Time: 2.69381
PPO Batch Consumption Time: 0.05990
Total Iteration Time: 15.71505

Cumulative Model Updates: 63,885
Cumulative Timesteps: 1,065,605,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622,490.88415
Policy Entropy: 1.06378
Value Function Loss: 1.49675

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.08666
Value Function Update Magnitude: 0.13651

Collected Steps per Second: 3,795.20122
Overall Steps per Second: 3,127.29650

Timestep Collection Time: 13.17506
Timestep Consumption Time: 2.81383
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 15.98889

Cumulative Model Updates: 63,888
Cumulative Timesteps: 1,065,655,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1065655118...
Checkpoint 1065655118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297,835.84617
Policy Entropy: 1.07315
Value Function Loss: 1.51703

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.08871
Value Function Update Magnitude: 0.13129

Collected Steps per Second: 3,696.55678
Overall Steps per Second: 3,074.69844

Timestep Collection Time: 13.52718
Timestep Consumption Time: 2.73588
PPO Batch Consumption Time: 0.05334
Total Iteration Time: 16.26306

Cumulative Model Updates: 63,891
Cumulative Timesteps: 1,065,705,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205,662.49316
Policy Entropy: 1.07270
Value Function Loss: 1.48565

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.08629
Value Function Update Magnitude: 0.13138

Collected Steps per Second: 3,756.51684
Overall Steps per Second: 3,118.56831

Timestep Collection Time: 13.31393
Timestep Consumption Time: 2.72356
PPO Batch Consumption Time: 0.05015
Total Iteration Time: 16.03749

Cumulative Model Updates: 63,894
Cumulative Timesteps: 1,065,755,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1065755136...
Checkpoint 1065755136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,772,824.51963
Policy Entropy: 1.07686
Value Function Loss: 1.46583

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.08259
Value Function Update Magnitude: 0.12558

Collected Steps per Second: 3,818.05889
Overall Steps per Second: 3,185.18264

Timestep Collection Time: 13.10509
Timestep Consumption Time: 2.60390
PPO Batch Consumption Time: 0.05190
Total Iteration Time: 15.70899

Cumulative Model Updates: 63,897
Cumulative Timesteps: 1,065,805,172

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,321,451.29850
Policy Entropy: 1.06976
Value Function Loss: 1.47536

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.08324
Value Function Update Magnitude: 0.12470

Collected Steps per Second: 3,716.37120
Overall Steps per Second: 3,097.90985

Timestep Collection Time: 13.46259
Timestep Consumption Time: 2.68765
PPO Batch Consumption Time: 0.04953
Total Iteration Time: 16.15024

Cumulative Model Updates: 63,900
Cumulative Timesteps: 1,065,855,204

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1065855204...
Checkpoint 1065855204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648,680.44761
Policy Entropy: 1.06833
Value Function Loss: 1.42148

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.08419
Value Function Update Magnitude: 0.13094

Collected Steps per Second: 3,845.41656
Overall Steps per Second: 3,241.73004

Timestep Collection Time: 13.00457
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 15.42633

Cumulative Model Updates: 63,903
Cumulative Timesteps: 1,065,905,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934,247.36881
Policy Entropy: 1.05972
Value Function Loss: 1.44852

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.07800
Value Function Update Magnitude: 0.14845

Collected Steps per Second: 3,692.69775
Overall Steps per Second: 3,118.84086

Timestep Collection Time: 13.54728
Timestep Consumption Time: 2.49266
PPO Batch Consumption Time: 0.05423
Total Iteration Time: 16.03993

Cumulative Model Updates: 63,906
Cumulative Timesteps: 1,065,955,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1065955238...
Checkpoint 1065955238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820,519.76795
Policy Entropy: 1.08443
Value Function Loss: 1.47945

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.15426

Collected Steps per Second: 3,821.48047
Overall Steps per Second: 3,165.49200

Timestep Collection Time: 13.08707
Timestep Consumption Time: 2.71205
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 15.79912

Cumulative Model Updates: 63,909
Cumulative Timesteps: 1,066,005,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932,927.71263
Policy Entropy: 1.08299
Value Function Loss: 1.41693

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.15437

Collected Steps per Second: 3,797.55120
Overall Steps per Second: 3,114.02190

Timestep Collection Time: 13.17270
Timestep Consumption Time: 2.89141
PPO Batch Consumption Time: 0.05777
Total Iteration Time: 16.06411

Cumulative Model Updates: 63,912
Cumulative Timesteps: 1,066,055,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1066055274...
Checkpoint 1066055274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490,534.35186
Policy Entropy: 1.06889
Value Function Loss: 1.44949

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.06523
Value Function Update Magnitude: 0.14861

Collected Steps per Second: 3,723.25187
Overall Steps per Second: 3,111.83918

Timestep Collection Time: 13.44040
Timestep Consumption Time: 2.64076
PPO Batch Consumption Time: 0.06547
Total Iteration Time: 16.08117

Cumulative Model Updates: 63,915
Cumulative Timesteps: 1,066,105,316

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807,563.31264
Policy Entropy: 1.05697
Value Function Loss: 1.42876

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.19887
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.13830

Collected Steps per Second: 4,049.90383
Overall Steps per Second: 3,304.70707

Timestep Collection Time: 12.34992
Timestep Consumption Time: 2.78485
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 15.13478

Cumulative Model Updates: 63,918
Cumulative Timesteps: 1,066,155,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1066155332...
Checkpoint 1066155332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573,326.73770
Policy Entropy: 1.07127
Value Function Loss: 1.52709

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.13792

Collected Steps per Second: 3,787.17776
Overall Steps per Second: 3,128.71799

Timestep Collection Time: 13.20350
Timestep Consumption Time: 2.77877
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 15.98226

Cumulative Model Updates: 63,921
Cumulative Timesteps: 1,066,205,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715,404.94385
Policy Entropy: 1.08090
Value Function Loss: 1.59428

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.06732
Value Function Update Magnitude: 0.14557

Collected Steps per Second: 3,701.26753
Overall Steps per Second: 3,095.34442

Timestep Collection Time: 13.51969
Timestep Consumption Time: 2.64652
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 16.16621

Cumulative Model Updates: 63,924
Cumulative Timesteps: 1,066,255,376

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1066255376...
Checkpoint 1066255376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382,384.78532
Policy Entropy: 1.07108
Value Function Loss: 1.58525

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.07076
Value Function Update Magnitude: 0.15136

Collected Steps per Second: 3,776.80846
Overall Steps per Second: 3,151.11489

Timestep Collection Time: 13.25140
Timestep Consumption Time: 2.63123
PPO Batch Consumption Time: 0.05924
Total Iteration Time: 15.88263

Cumulative Model Updates: 63,927
Cumulative Timesteps: 1,066,305,424

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486,810.57211
Policy Entropy: 1.04761
Value Function Loss: 1.57439

Mean KL Divergence: 0.03762
SB3 Clip Fraction: 0.21525
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.14096

Collected Steps per Second: 3,753.60833
Overall Steps per Second: 3,163.61269

Timestep Collection Time: 13.32425
Timestep Consumption Time: 2.48490
PPO Batch Consumption Time: 0.04973
Total Iteration Time: 15.80914

Cumulative Model Updates: 63,930
Cumulative Timesteps: 1,066,355,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1066355438...
Checkpoint 1066355438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770,109.40672
Policy Entropy: 1.07293
Value Function Loss: 1.47803

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.15752
Policy Update Magnitude: 0.06154
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 3,810.01041
Overall Steps per Second: 3,217.77802

Timestep Collection Time: 13.13592
Timestep Consumption Time: 2.41767
PPO Batch Consumption Time: 0.05014
Total Iteration Time: 15.55359

Cumulative Model Updates: 63,933
Cumulative Timesteps: 1,066,405,486

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603,196.76907
Policy Entropy: 1.05400
Value Function Loss: 1.49985

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.16342
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.11180

Collected Steps per Second: 3,960.67771
Overall Steps per Second: 3,325.40962

Timestep Collection Time: 12.62612
Timestep Consumption Time: 2.41203
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 15.03815

Cumulative Model Updates: 63,936
Cumulative Timesteps: 1,066,455,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1066455494...
Checkpoint 1066455494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954,895.50961
Policy Entropy: 1.05148
Value Function Loss: 1.52148

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.15908
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.10896

Collected Steps per Second: 3,963.00893
Overall Steps per Second: 3,286.06831

Timestep Collection Time: 12.62727
Timestep Consumption Time: 2.60126
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 15.22853

Cumulative Model Updates: 63,939
Cumulative Timesteps: 1,066,505,536

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570,391.70523
Policy Entropy: 1.05701
Value Function Loss: 1.49256

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.10379

Collected Steps per Second: 3,746.21546
Overall Steps per Second: 3,156.81284

Timestep Collection Time: 13.34787
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.05199
Total Iteration Time: 15.84003

Cumulative Model Updates: 63,942
Cumulative Timesteps: 1,066,555,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1066555540...
Checkpoint 1066555540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553,658.26944
Policy Entropy: 1.06269
Value Function Loss: 1.40836

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.09746

Collected Steps per Second: 3,709.85186
Overall Steps per Second: 3,090.92905

Timestep Collection Time: 13.47817
Timestep Consumption Time: 2.69885
PPO Batch Consumption Time: 0.05823
Total Iteration Time: 16.17701

Cumulative Model Updates: 63,945
Cumulative Timesteps: 1,066,605,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030,430.86011
Policy Entropy: 1.04991
Value Function Loss: 1.38562

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.09332

Collected Steps per Second: 3,868.09121
Overall Steps per Second: 3,182.59010

Timestep Collection Time: 12.93713
Timestep Consumption Time: 2.78654
PPO Batch Consumption Time: 0.05842
Total Iteration Time: 15.72367

Cumulative Model Updates: 63,948
Cumulative Timesteps: 1,066,655,584

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1066655584...
Checkpoint 1066655584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387,904.62845
Policy Entropy: 1.03779
Value Function Loss: 1.45753

Mean KL Divergence: 0.02437
SB3 Clip Fraction: 0.18139
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.10282

Collected Steps per Second: 3,740.97414
Overall Steps per Second: 3,107.22058

Timestep Collection Time: 13.37085
Timestep Consumption Time: 2.72714
PPO Batch Consumption Time: 0.04850
Total Iteration Time: 16.09799

Cumulative Model Updates: 63,951
Cumulative Timesteps: 1,066,705,604

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320,120.02088
Policy Entropy: 1.05281
Value Function Loss: 1.47972

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.10388

Collected Steps per Second: 3,957.41686
Overall Steps per Second: 3,231.41153

Timestep Collection Time: 12.64006
Timestep Consumption Time: 2.83986
PPO Batch Consumption Time: 0.06016
Total Iteration Time: 15.47992

Cumulative Model Updates: 63,954
Cumulative Timesteps: 1,066,755,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1066755626...
Checkpoint 1066755626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481,336.80612
Policy Entropy: 1.05983
Value Function Loss: 1.48849

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.10180

Collected Steps per Second: 3,828.93157
Overall Steps per Second: 3,175.36397

Timestep Collection Time: 13.06474
Timestep Consumption Time: 2.68904
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 15.75378

Cumulative Model Updates: 63,957
Cumulative Timesteps: 1,066,805,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433,513.11637
Policy Entropy: 1.04945
Value Function Loss: 1.44351

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.10591

Collected Steps per Second: 3,675.76098
Overall Steps per Second: 3,086.69161

Timestep Collection Time: 13.60535
Timestep Consumption Time: 2.59647
PPO Batch Consumption Time: 0.06235
Total Iteration Time: 16.20181

Cumulative Model Updates: 63,960
Cumulative Timesteps: 1,066,855,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1066855660...
Checkpoint 1066855660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,255,157.06275
Policy Entropy: 1.03538
Value Function Loss: 1.49550

Mean KL Divergence: 0.02719
SB3 Clip Fraction: 0.20393
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.10156

Collected Steps per Second: 3,681.70801
Overall Steps per Second: 3,087.33953

Timestep Collection Time: 13.58120
Timestep Consumption Time: 2.61462
PPO Batch Consumption Time: 0.05001
Total Iteration Time: 16.19582

Cumulative Model Updates: 63,963
Cumulative Timesteps: 1,066,905,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180,921.06441
Policy Entropy: 1.05217
Value Function Loss: 1.50884

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.09758

Collected Steps per Second: 3,878.87103
Overall Steps per Second: 3,216.86357

Timestep Collection Time: 12.89911
Timestep Consumption Time: 2.65455
PPO Batch Consumption Time: 0.05803
Total Iteration Time: 15.55366

Cumulative Model Updates: 63,966
Cumulative Timesteps: 1,066,955,696

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1066955696...
Checkpoint 1066955696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583,229.46314
Policy Entropy: 1.06291
Value Function Loss: 1.47160

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.10400

Collected Steps per Second: 3,751.92059
Overall Steps per Second: 3,123.91206

Timestep Collection Time: 13.32864
Timestep Consumption Time: 2.67949
PPO Batch Consumption Time: 0.05895
Total Iteration Time: 16.00813

Cumulative Model Updates: 63,969
Cumulative Timesteps: 1,067,005,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673,455.99868
Policy Entropy: 1.05346
Value Function Loss: 1.44386

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.10425

Collected Steps per Second: 3,665.27580
Overall Steps per Second: 3,056.60137

Timestep Collection Time: 13.64809
Timestep Consumption Time: 2.71780
PPO Batch Consumption Time: 0.05140
Total Iteration Time: 16.36589

Cumulative Model Updates: 63,972
Cumulative Timesteps: 1,067,055,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1067055728...
Checkpoint 1067055728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939,325.67811
Policy Entropy: 1.04085
Value Function Loss: 1.42185

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.18969
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.10480

Collected Steps per Second: 3,717.89201
Overall Steps per Second: 3,192.96040

Timestep Collection Time: 13.46085
Timestep Consumption Time: 2.21300
PPO Batch Consumption Time: 0.05135
Total Iteration Time: 15.67386

Cumulative Model Updates: 63,975
Cumulative Timesteps: 1,067,105,774

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549,494.27262
Policy Entropy: 1.05209
Value Function Loss: 1.42008

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.10139

Collected Steps per Second: 3,805.01338
Overall Steps per Second: 3,192.63520

Timestep Collection Time: 13.14161
Timestep Consumption Time: 2.52069
PPO Batch Consumption Time: 0.05815
Total Iteration Time: 15.66230

Cumulative Model Updates: 63,978
Cumulative Timesteps: 1,067,155,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1067155778...
Checkpoint 1067155778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531,806.66506
Policy Entropy: 1.06052
Value Function Loss: 1.43475

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.09629

Collected Steps per Second: 3,703.01039
Overall Steps per Second: 3,130.19445

Timestep Collection Time: 13.51063
Timestep Consumption Time: 2.47240
PPO Batch Consumption Time: 0.05394
Total Iteration Time: 15.98303

Cumulative Model Updates: 63,981
Cumulative Timesteps: 1,067,205,808

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579,059.17167
Policy Entropy: 1.04155
Value Function Loss: 1.43459

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.10678

Collected Steps per Second: 3,783.10064
Overall Steps per Second: 3,127.74556

Timestep Collection Time: 13.22672
Timestep Consumption Time: 2.77139
PPO Batch Consumption Time: 0.05369
Total Iteration Time: 15.99810

Cumulative Model Updates: 63,984
Cumulative Timesteps: 1,067,255,846

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1067255846...
Checkpoint 1067255846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379,741.22119
Policy Entropy: 1.03037
Value Function Loss: 1.47506

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.18329
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.12127

Collected Steps per Second: 4,013.36183
Overall Steps per Second: 3,312.68112

Timestep Collection Time: 12.46137
Timestep Consumption Time: 2.63576
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 15.09714

Cumulative Model Updates: 63,987
Cumulative Timesteps: 1,067,305,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,220,683.50669
Policy Entropy: 1.04734
Value Function Loss: 1.39884

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.11094

Collected Steps per Second: 4,091.00169
Overall Steps per Second: 3,368.78859

Timestep Collection Time: 12.22341
Timestep Consumption Time: 2.62050
PPO Batch Consumption Time: 0.04911
Total Iteration Time: 14.84391

Cumulative Model Updates: 63,990
Cumulative Timesteps: 1,067,355,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1067355864...
Checkpoint 1067355864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157,391.52586
Policy Entropy: 1.05441
Value Function Loss: 1.36856

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.09669

Collected Steps per Second: 3,926.14891
Overall Steps per Second: 3,254.46936

Timestep Collection Time: 12.74277
Timestep Consumption Time: 2.62994
PPO Batch Consumption Time: 0.04658
Total Iteration Time: 15.37271

Cumulative Model Updates: 63,993
Cumulative Timesteps: 1,067,405,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,095,631.06641
Policy Entropy: 1.02714
Value Function Loss: 1.35913

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.18004
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 3,719.92106
Overall Steps per Second: 3,103.39900

Timestep Collection Time: 13.44867
Timestep Consumption Time: 2.67172
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 16.12039

Cumulative Model Updates: 63,996
Cumulative Timesteps: 1,067,455,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1067455922...
Checkpoint 1067455922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,904,510.96470
Policy Entropy: 1.05095
Value Function Loss: 1.44810

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.16169
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.07525

Collected Steps per Second: 3,708.93069
Overall Steps per Second: 3,118.99146

Timestep Collection Time: 13.49068
Timestep Consumption Time: 2.55168
PPO Batch Consumption Time: 0.05896
Total Iteration Time: 16.04237

Cumulative Model Updates: 63,999
Cumulative Timesteps: 1,067,505,958

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,901,210.31584
Policy Entropy: 1.04173
Value Function Loss: 1.51029

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.07105

Collected Steps per Second: 3,656.35239
Overall Steps per Second: 3,049.37387

Timestep Collection Time: 13.68522
Timestep Consumption Time: 2.72405
PPO Batch Consumption Time: 0.06402
Total Iteration Time: 16.40927

Cumulative Model Updates: 64,002
Cumulative Timesteps: 1,067,555,996

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1067555996...
Checkpoint 1067555996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658,010.85465
Policy Entropy: 1.03573
Value Function Loss: 1.52331

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.16667
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.07220

Collected Steps per Second: 3,785.76611
Overall Steps per Second: 3,136.56741

Timestep Collection Time: 13.21318
Timestep Consumption Time: 2.73483
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 15.94801

Cumulative Model Updates: 64,005
Cumulative Timesteps: 1,067,606,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,222,213.22525
Policy Entropy: 1.03252
Value Function Loss: 1.44090

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.19031
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.07550

Collected Steps per Second: 3,755.31419
Overall Steps per Second: 3,112.10900

Timestep Collection Time: 13.31660
Timestep Consumption Time: 2.75225
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 16.06885

Cumulative Model Updates: 64,008
Cumulative Timesteps: 1,067,656,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1067656026...
Checkpoint 1067656026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,344,922.29717
Policy Entropy: 1.04738
Value Function Loss: 1.35999

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.08633

Collected Steps per Second: 3,671.48717
Overall Steps per Second: 3,078.31988

Timestep Collection Time: 13.62990
Timestep Consumption Time: 2.62637
PPO Batch Consumption Time: 0.05165
Total Iteration Time: 16.25627

Cumulative Model Updates: 64,011
Cumulative Timesteps: 1,067,706,068

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252,053.14508
Policy Entropy: 1.05884
Value Function Loss: 1.33397

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15266
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.11745

Collected Steps per Second: 3,823.77764
Overall Steps per Second: 3,240.11711

Timestep Collection Time: 13.08392
Timestep Consumption Time: 2.35688
PPO Batch Consumption Time: 0.05845
Total Iteration Time: 15.44080

Cumulative Model Updates: 64,014
Cumulative Timesteps: 1,067,756,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1067756098...
Checkpoint 1067756098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316,444.09030
Policy Entropy: 1.03910
Value Function Loss: 1.36710

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.13278

Collected Steps per Second: 3,729.39178
Overall Steps per Second: 3,177.66046

Timestep Collection Time: 13.41827
Timestep Consumption Time: 2.32979
PPO Batch Consumption Time: 0.05021
Total Iteration Time: 15.74806

Cumulative Model Updates: 64,017
Cumulative Timesteps: 1,067,806,140

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,411,314.28877
Policy Entropy: 1.03830
Value Function Loss: 1.31439

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.14927

Collected Steps per Second: 3,620.40515
Overall Steps per Second: 3,093.05990

Timestep Collection Time: 13.81669
Timestep Consumption Time: 2.35565
PPO Batch Consumption Time: 0.05124
Total Iteration Time: 16.17233

Cumulative Model Updates: 64,020
Cumulative Timesteps: 1,067,856,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1067856162...
Checkpoint 1067856162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,094,929.78436
Policy Entropy: 1.05071
Value Function Loss: 1.27891

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.13037

Collected Steps per Second: 3,940.82749
Overall Steps per Second: 3,257.22843

Timestep Collection Time: 12.69277
Timestep Consumption Time: 2.66385
PPO Batch Consumption Time: 0.05794
Total Iteration Time: 15.35661

Cumulative Model Updates: 64,023
Cumulative Timesteps: 1,067,906,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,208,674.17114
Policy Entropy: 1.05207
Value Function Loss: 1.34387

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.15307
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.11252

Collected Steps per Second: 3,817.20811
Overall Steps per Second: 3,161.59903

Timestep Collection Time: 13.10382
Timestep Consumption Time: 2.71729
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 15.82111

Cumulative Model Updates: 64,026
Cumulative Timesteps: 1,067,956,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1067956202...
Checkpoint 1067956202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939,769.00735
Policy Entropy: 1.02720
Value Function Loss: 1.42026

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.10599

Collected Steps per Second: 3,855.18284
Overall Steps per Second: 3,183.20174

Timestep Collection Time: 12.97215
Timestep Consumption Time: 2.73845
PPO Batch Consumption Time: 0.06612
Total Iteration Time: 15.71060

Cumulative Model Updates: 64,029
Cumulative Timesteps: 1,068,006,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,775,938.14904
Policy Entropy: 1.03825
Value Function Loss: 1.41010

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.15505
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.09477

Collected Steps per Second: 3,679.54709
Overall Steps per Second: 3,079.15126

Timestep Collection Time: 13.59189
Timestep Consumption Time: 2.65025
PPO Batch Consumption Time: 0.05216
Total Iteration Time: 16.24214

Cumulative Model Updates: 64,032
Cumulative Timesteps: 1,068,056,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1068056224...
Checkpoint 1068056224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604,032.15715
Policy Entropy: 1.04836
Value Function Loss: 1.36628

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.09141

Collected Steps per Second: 3,791.66597
Overall Steps per Second: 3,128.55177

Timestep Collection Time: 13.19262
Timestep Consumption Time: 2.79625
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 15.98887

Cumulative Model Updates: 64,035
Cumulative Timesteps: 1,068,106,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831,152.74440
Policy Entropy: 1.05185
Value Function Loss: 1.42882

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.07291
Value Function Update Magnitude: 0.09434

Collected Steps per Second: 3,691.11217
Overall Steps per Second: 3,118.54687

Timestep Collection Time: 13.55906
Timestep Consumption Time: 2.48944
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 16.04850

Cumulative Model Updates: 64,038
Cumulative Timesteps: 1,068,156,294

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1068156294...
Checkpoint 1068156294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700,149.89864
Policy Entropy: 1.04169
Value Function Loss: 1.54302

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.16085
Policy Update Magnitude: 0.06954
Value Function Update Magnitude: 0.08835

Collected Steps per Second: 3,791.51721
Overall Steps per Second: 3,174.68116

Timestep Collection Time: 13.18733
Timestep Consumption Time: 2.56228
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 15.74961

Cumulative Model Updates: 64,041
Cumulative Timesteps: 1,068,206,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759,050.83061
Policy Entropy: 1.04961
Value Function Loss: 1.58359

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.09797

Collected Steps per Second: 3,714.03647
Overall Steps per Second: 3,134.63301

Timestep Collection Time: 13.47106
Timestep Consumption Time: 2.48998
PPO Batch Consumption Time: 0.04773
Total Iteration Time: 15.96104

Cumulative Model Updates: 64,044
Cumulative Timesteps: 1,068,256,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1068256326...
Checkpoint 1068256326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922,035.34397
Policy Entropy: 1.05448
Value Function Loss: 1.50994

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.16383
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.10589

Collected Steps per Second: 3,771.68695
Overall Steps per Second: 3,188.28756

Timestep Collection Time: 13.26356
Timestep Consumption Time: 2.42699
PPO Batch Consumption Time: 0.05200
Total Iteration Time: 15.69055

Cumulative Model Updates: 64,047
Cumulative Timesteps: 1,068,306,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,115,283.76650
Policy Entropy: 1.03948
Value Function Loss: 1.48743

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.09458

Collected Steps per Second: 3,854.47668
Overall Steps per Second: 3,270.36889

Timestep Collection Time: 12.97349
Timestep Consumption Time: 2.31714
PPO Batch Consumption Time: 0.06245
Total Iteration Time: 15.29063

Cumulative Model Updates: 64,050
Cumulative Timesteps: 1,068,356,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1068356358...
Checkpoint 1068356358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903,394.44666
Policy Entropy: 1.03040
Value Function Loss: 1.49471

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.17146
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.09057

Collected Steps per Second: 3,741.11706
Overall Steps per Second: 3,122.62159

Timestep Collection Time: 13.36660
Timestep Consumption Time: 2.64751
PPO Batch Consumption Time: 0.05778
Total Iteration Time: 16.01411

Cumulative Model Updates: 64,053
Cumulative Timesteps: 1,068,406,364

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948,840.80781
Policy Entropy: 1.03932
Value Function Loss: 1.50337

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.08515

Collected Steps per Second: 3,886.44669
Overall Steps per Second: 3,251.68659

Timestep Collection Time: 12.87500
Timestep Consumption Time: 2.51332
PPO Batch Consumption Time: 0.05330
Total Iteration Time: 15.38832

Cumulative Model Updates: 64,056
Cumulative Timesteps: 1,068,456,402

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1068456402...
Checkpoint 1068456402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673,264.74281
Policy Entropy: 1.05295
Value Function Loss: 1.46339

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.15863
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.08874

Collected Steps per Second: 3,904.61531
Overall Steps per Second: 3,231.05178

Timestep Collection Time: 12.80536
Timestep Consumption Time: 2.66948
PPO Batch Consumption Time: 0.05425
Total Iteration Time: 15.47484

Cumulative Model Updates: 64,059
Cumulative Timesteps: 1,068,506,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758,404.12323
Policy Entropy: 1.03936
Value Function Loss: 1.42225

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.08412

Collected Steps per Second: 3,836.47656
Overall Steps per Second: 3,204.10519

Timestep Collection Time: 13.04426
Timestep Consumption Time: 2.57445
PPO Batch Consumption Time: 0.05055
Total Iteration Time: 15.61871

Cumulative Model Updates: 64,062
Cumulative Timesteps: 1,068,556,446

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1068556446...
Checkpoint 1068556446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385,385.13539
Policy Entropy: 1.04406
Value Function Loss: 1.45637

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.09472

Collected Steps per Second: 3,792.05046
Overall Steps per Second: 3,150.94163

Timestep Collection Time: 13.19761
Timestep Consumption Time: 2.68526
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 15.88287

Cumulative Model Updates: 64,065
Cumulative Timesteps: 1,068,606,492

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842,896.80534
Policy Entropy: 1.05281
Value Function Loss: 1.47113

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.15614
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.10840

Collected Steps per Second: 3,872.27496
Overall Steps per Second: 3,213.10060

Timestep Collection Time: 12.91386
Timestep Consumption Time: 2.64930
PPO Batch Consumption Time: 0.05030
Total Iteration Time: 15.56316

Cumulative Model Updates: 64,068
Cumulative Timesteps: 1,068,656,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1068656498...
Checkpoint 1068656498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523,992.61303
Policy Entropy: 1.05208
Value Function Loss: 1.46101

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.11283

Collected Steps per Second: 3,777.64019
Overall Steps per Second: 3,123.46886

Timestep Collection Time: 13.24795
Timestep Consumption Time: 2.77462
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 16.02257

Cumulative Model Updates: 64,071
Cumulative Timesteps: 1,068,706,544

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680,137.15136
Policy Entropy: 1.03793
Value Function Loss: 1.49958

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.10324

Collected Steps per Second: 3,626.56447
Overall Steps per Second: 3,053.60209

Timestep Collection Time: 13.78715
Timestep Consumption Time: 2.58695
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 16.37410

Cumulative Model Updates: 64,074
Cumulative Timesteps: 1,068,756,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1068756544...
Checkpoint 1068756544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628,139.50315
Policy Entropy: 1.02554
Value Function Loss: 1.49884

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.19743
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.08946

Collected Steps per Second: 3,628.70178
Overall Steps per Second: 3,097.77454

Timestep Collection Time: 13.78289
Timestep Consumption Time: 2.36225
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 16.14514

Cumulative Model Updates: 64,077
Cumulative Timesteps: 1,068,806,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751,784.37919
Policy Entropy: 1.05040
Value Function Loss: 1.55193

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.06792
Value Function Update Magnitude: 0.08621

Collected Steps per Second: 3,731.34117
Overall Steps per Second: 3,117.11421

Timestep Collection Time: 13.40590
Timestep Consumption Time: 2.64163
PPO Batch Consumption Time: 0.05046
Total Iteration Time: 16.04754

Cumulative Model Updates: 64,080
Cumulative Timesteps: 1,068,856,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1068856580...
Checkpoint 1068856580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,275,116.95638
Policy Entropy: 1.05090
Value Function Loss: 1.49608

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.07158
Value Function Update Magnitude: 0.08572

Collected Steps per Second: 3,684.95632
Overall Steps per Second: 3,083.60273

Timestep Collection Time: 13.57574
Timestep Consumption Time: 2.64749
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 16.22323

Cumulative Model Updates: 64,083
Cumulative Timesteps: 1,068,906,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847,778.21494
Policy Entropy: 1.04708
Value Function Loss: 1.54845

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.07528
Value Function Update Magnitude: 0.09131

Collected Steps per Second: 3,785.95396
Overall Steps per Second: 3,175.63242

Timestep Collection Time: 13.20935
Timestep Consumption Time: 2.53869
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 15.74804

Cumulative Model Updates: 64,086
Cumulative Timesteps: 1,068,956,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1068956616...
Checkpoint 1068956616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033,407.46065
Policy Entropy: 1.02621
Value Function Loss: 1.54567

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.15786
Policy Update Magnitude: 0.08005
Value Function Update Magnitude: 0.09256

Collected Steps per Second: 3,683.39196
Overall Steps per Second: 3,107.67658

Timestep Collection Time: 13.58313
Timestep Consumption Time: 2.51636
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 16.09949

Cumulative Model Updates: 64,089
Cumulative Timesteps: 1,069,006,648

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590,884.83925
Policy Entropy: 1.04565
Value Function Loss: 1.50516

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.16833
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.09677

Collected Steps per Second: 3,671.29908
Overall Steps per Second: 3,135.73507

Timestep Collection Time: 13.62569
Timestep Consumption Time: 2.32718
PPO Batch Consumption Time: 0.06408
Total Iteration Time: 15.95288

Cumulative Model Updates: 64,092
Cumulative Timesteps: 1,069,056,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1069056672...
Checkpoint 1069056672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535,011.44497
Policy Entropy: 1.03839
Value Function Loss: 1.42198

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.09845

Collected Steps per Second: 3,848.37542
Overall Steps per Second: 3,185.21060

Timestep Collection Time: 12.99509
Timestep Consumption Time: 2.70559
PPO Batch Consumption Time: 0.04897
Total Iteration Time: 15.70069

Cumulative Model Updates: 64,095
Cumulative Timesteps: 1,069,106,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672,232.56855
Policy Entropy: 1.02500
Value Function Loss: 1.40478

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.15393
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.09631

Collected Steps per Second: 3,687.93242
Overall Steps per Second: 3,090.23089

Timestep Collection Time: 13.56532
Timestep Consumption Time: 2.62376
PPO Batch Consumption Time: 0.05348
Total Iteration Time: 16.18908

Cumulative Model Updates: 64,098
Cumulative Timesteps: 1,069,156,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1069156710...
Checkpoint 1069156710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591,300.73826
Policy Entropy: 1.02176
Value Function Loss: 1.40488

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.10160

Collected Steps per Second: 3,893.23878
Overall Steps per Second: 3,211.49841

Timestep Collection Time: 12.84483
Timestep Consumption Time: 2.72672
PPO Batch Consumption Time: 0.05921
Total Iteration Time: 15.57155

Cumulative Model Updates: 64,101
Cumulative Timesteps: 1,069,206,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847,991.10383
Policy Entropy: 1.03201
Value Function Loss: 1.46631

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.10102

Collected Steps per Second: 3,818.29131
Overall Steps per Second: 3,184.30724

Timestep Collection Time: 13.10377
Timestep Consumption Time: 2.60891
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 15.71268

Cumulative Model Updates: 64,104
Cumulative Timesteps: 1,069,256,752

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1069256752...
Checkpoint 1069256752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029,585.71561
Policy Entropy: 1.04073
Value Function Loss: 1.43990

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.15997
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.11523

Collected Steps per Second: 3,942.26035
Overall Steps per Second: 3,249.93645

Timestep Collection Time: 12.68409
Timestep Consumption Time: 2.70205
PPO Batch Consumption Time: 0.06135
Total Iteration Time: 15.38615

Cumulative Model Updates: 64,107
Cumulative Timesteps: 1,069,306,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858,689.18048
Policy Entropy: 1.03105
Value Function Loss: 1.39204

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.06391
Value Function Update Magnitude: 0.12319

Collected Steps per Second: 3,663.09199
Overall Steps per Second: 3,058.84365

Timestep Collection Time: 13.65568
Timestep Consumption Time: 2.69756
PPO Batch Consumption Time: 0.05084
Total Iteration Time: 16.35324

Cumulative Model Updates: 64,110
Cumulative Timesteps: 1,069,356,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1069356778...
Checkpoint 1069356778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,280,791.14010
Policy Entropy: 1.01481
Value Function Loss: 1.36490

Mean KL Divergence: 0.03044
SB3 Clip Fraction: 0.20750
Policy Update Magnitude: 0.06197
Value Function Update Magnitude: 0.11873

Collected Steps per Second: 3,766.96979
Overall Steps per Second: 3,121.16878

Timestep Collection Time: 13.27327
Timestep Consumption Time: 2.74637
PPO Batch Consumption Time: 0.06814
Total Iteration Time: 16.01964

Cumulative Model Updates: 64,113
Cumulative Timesteps: 1,069,406,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923,324.96019
Policy Entropy: 1.04321
Value Function Loss: 1.38503

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 3,890.96972
Overall Steps per Second: 3,224.75797

Timestep Collection Time: 12.85284
Timestep Consumption Time: 2.65530
PPO Batch Consumption Time: 0.05396
Total Iteration Time: 15.50814

Cumulative Model Updates: 64,116
Cumulative Timesteps: 1,069,456,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1069456788...
Checkpoint 1069456788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455,835.64240
Policy Entropy: 1.02688
Value Function Loss: 1.40043

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.11149

Collected Steps per Second: 3,851.88056
Overall Steps per Second: 3,210.75258

Timestep Collection Time: 12.98846
Timestep Consumption Time: 2.59356
PPO Batch Consumption Time: 0.04926
Total Iteration Time: 15.58202

Cumulative Model Updates: 64,119
Cumulative Timesteps: 1,069,506,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,072,496.92719
Policy Entropy: 1.01685
Value Function Loss: 1.40572

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.18717
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.12573

Collected Steps per Second: 3,701.24742
Overall Steps per Second: 3,103.70106

Timestep Collection Time: 13.52301
Timestep Consumption Time: 2.60354
PPO Batch Consumption Time: 0.05317
Total Iteration Time: 16.12655

Cumulative Model Updates: 64,122
Cumulative Timesteps: 1,069,556,870

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1069556870...
Checkpoint 1069556870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562,312.06853
Policy Entropy: 1.03049
Value Function Loss: 1.33433

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.11115

Collected Steps per Second: 3,833.74529
Overall Steps per Second: 3,226.99200

Timestep Collection Time: 13.04990
Timestep Consumption Time: 2.45370
PPO Batch Consumption Time: 0.05982
Total Iteration Time: 15.50360

Cumulative Model Updates: 64,125
Cumulative Timesteps: 1,069,606,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888,988.94457
Policy Entropy: 1.03876
Value Function Loss: 1.40552

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.15210
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.10275

Collected Steps per Second: 3,875.96061
Overall Steps per Second: 3,233.13923

Timestep Collection Time: 12.90158
Timestep Consumption Time: 2.56513
PPO Batch Consumption Time: 0.06380
Total Iteration Time: 15.46670

Cumulative Model Updates: 64,128
Cumulative Timesteps: 1,069,656,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1069656906...
Checkpoint 1069656906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989,855.77970
Policy Entropy: 1.02425
Value Function Loss: 1.34522

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.15281
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.09314

Collected Steps per Second: 3,975.70394
Overall Steps per Second: 3,266.80911

Timestep Collection Time: 12.58293
Timestep Consumption Time: 2.73049
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 15.31341

Cumulative Model Updates: 64,131
Cumulative Timesteps: 1,069,706,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,005,552.24324
Policy Entropy: 1.02147
Value Function Loss: 1.43276

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.16707
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.11004

Collected Steps per Second: 3,791.39079
Overall Steps per Second: 3,147.25318

Timestep Collection Time: 13.19199
Timestep Consumption Time: 2.69996
PPO Batch Consumption Time: 0.05280
Total Iteration Time: 15.89195

Cumulative Model Updates: 64,134
Cumulative Timesteps: 1,069,756,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1069756948...
Checkpoint 1069756948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,988,955.14640
Policy Entropy: 1.02829
Value Function Loss: 1.41999

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 3,834.58215
Overall Steps per Second: 3,193.08258

Timestep Collection Time: 13.04549
Timestep Consumption Time: 2.62088
PPO Batch Consumption Time: 0.05321
Total Iteration Time: 15.66637

Cumulative Model Updates: 64,137
Cumulative Timesteps: 1,069,806,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585,160.48413
Policy Entropy: 1.03512
Value Function Loss: 1.41458

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.16351
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.11101

Collected Steps per Second: 3,715.29423
Overall Steps per Second: 3,119.23349

Timestep Collection Time: 13.46757
Timestep Consumption Time: 2.57355
PPO Batch Consumption Time: 0.05109
Total Iteration Time: 16.04112

Cumulative Model Updates: 64,140
Cumulative Timesteps: 1,069,857,008

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1069857008...
Checkpoint 1069857008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736,066.97605
Policy Entropy: 1.00428
Value Function Loss: 1.41696

Mean KL Divergence: 0.03032
SB3 Clip Fraction: 0.18844
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 3,706.54434
Overall Steps per Second: 3,097.58515

Timestep Collection Time: 13.49451
Timestep Consumption Time: 2.65291
PPO Batch Consumption Time: 0.05190
Total Iteration Time: 16.14742

Cumulative Model Updates: 64,143
Cumulative Timesteps: 1,069,907,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,062,937.92222
Policy Entropy: 1.03012
Value Function Loss: 1.39770

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.16297
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.11294

Collected Steps per Second: 3,942.72915
Overall Steps per Second: 3,275.47625

Timestep Collection Time: 12.68817
Timestep Consumption Time: 2.58473
PPO Batch Consumption Time: 0.05799
Total Iteration Time: 15.27289

Cumulative Model Updates: 64,146
Cumulative Timesteps: 1,069,957,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1069957052...
Checkpoint 1069957052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769,029.60986
Policy Entropy: 1.02691
Value Function Loss: 1.41634

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.15759
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.10065

Collected Steps per Second: 3,759.11791
Overall Steps per Second: 3,178.16058

Timestep Collection Time: 13.30844
Timestep Consumption Time: 2.43274
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 15.74118

Cumulative Model Updates: 64,149
Cumulative Timesteps: 1,070,007,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821,282.39569
Policy Entropy: 1.02830
Value Function Loss: 1.41436

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.09115

Collected Steps per Second: 3,907.46723
Overall Steps per Second: 3,242.32804

Timestep Collection Time: 12.80727
Timestep Consumption Time: 2.62732
PPO Batch Consumption Time: 0.05266
Total Iteration Time: 15.43459

Cumulative Model Updates: 64,152
Cumulative Timesteps: 1,070,057,124

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1070057124...
Checkpoint 1070057124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603,814.13622
Policy Entropy: 1.00686
Value Function Loss: 1.40591

Mean KL Divergence: 0.03023
SB3 Clip Fraction: 0.20759
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.09053

Collected Steps per Second: 3,874.16816
Overall Steps per Second: 3,257.63362

Timestep Collection Time: 12.91477
Timestep Consumption Time: 2.44423
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 15.35900

Cumulative Model Updates: 64,155
Cumulative Timesteps: 1,070,107,158

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239,008.71659
Policy Entropy: 1.03001
Value Function Loss: 1.41407

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.15398
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.09046

Collected Steps per Second: 3,892.68941
Overall Steps per Second: 3,318.16133

Timestep Collection Time: 12.84613
Timestep Consumption Time: 2.22426
PPO Batch Consumption Time: 0.05408
Total Iteration Time: 15.07039

Cumulative Model Updates: 64,158
Cumulative Timesteps: 1,070,157,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1070157164...
Checkpoint 1070157164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626,132.50348
Policy Entropy: 1.00828
Value Function Loss: 1.39614

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.15143
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.09123

Collected Steps per Second: 3,801.97384
Overall Steps per Second: 3,190.33855

Timestep Collection Time: 13.15790
Timestep Consumption Time: 2.52257
PPO Batch Consumption Time: 0.04842
Total Iteration Time: 15.68047

Cumulative Model Updates: 64,161
Cumulative Timesteps: 1,070,207,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195,518.92558
Policy Entropy: 1.00398
Value Function Loss: 1.42808

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.17588
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.09096

Collected Steps per Second: 3,712.92971
Overall Steps per Second: 3,130.30810

Timestep Collection Time: 13.47777
Timestep Consumption Time: 2.50852
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 15.98629

Cumulative Model Updates: 64,164
Cumulative Timesteps: 1,070,257,232

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1070257232...
Checkpoint 1070257232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,492,864.37939
Policy Entropy: 1.02208
Value Function Loss: 1.46925

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.08904

Collected Steps per Second: 3,641.25233
Overall Steps per Second: 3,065.26471

Timestep Collection Time: 13.74198
Timestep Consumption Time: 2.58223
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 16.32420

Cumulative Model Updates: 64,167
Cumulative Timesteps: 1,070,307,270

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885,128.35568
Policy Entropy: 1.02344
Value Function Loss: 1.46195

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15149
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.10081

Collected Steps per Second: 3,840.94747
Overall Steps per Second: 3,217.93996

Timestep Collection Time: 13.02804
Timestep Consumption Time: 2.52229
PPO Batch Consumption Time: 0.06121
Total Iteration Time: 15.55032

Cumulative Model Updates: 64,170
Cumulative Timesteps: 1,070,357,310

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1070357310...
Checkpoint 1070357310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,341,301.87660
Policy Entropy: 1.00826
Value Function Loss: 1.38463

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.09557

Collected Steps per Second: 3,740.54505
Overall Steps per Second: 3,098.32560

Timestep Collection Time: 13.37024
Timestep Consumption Time: 2.77138
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 16.14162

Cumulative Model Updates: 64,173
Cumulative Timesteps: 1,070,407,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553,576.99267
Policy Entropy: 0.99732
Value Function Loss: 1.35033

Mean KL Divergence: 0.02340
SB3 Clip Fraction: 0.19121
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.09668

Collected Steps per Second: 3,788.61607
Overall Steps per Second: 3,148.61021

Timestep Collection Time: 13.20429
Timestep Consumption Time: 2.68399
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 15.88828

Cumulative Model Updates: 64,176
Cumulative Timesteps: 1,070,457,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1070457348...
Checkpoint 1070457348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212,010.70937
Policy Entropy: 1.01485
Value Function Loss: 1.27721

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.09329

Collected Steps per Second: 3,734.44629
Overall Steps per Second: 3,116.66422

Timestep Collection Time: 13.39529
Timestep Consumption Time: 2.65520
PPO Batch Consumption Time: 0.05366
Total Iteration Time: 16.05049

Cumulative Model Updates: 64,179
Cumulative Timesteps: 1,070,507,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,968,877.49935
Policy Entropy: 1.03114
Value Function Loss: 1.33743

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.08912

Collected Steps per Second: 3,713.07741
Overall Steps per Second: 3,103.30101

Timestep Collection Time: 13.47615
Timestep Consumption Time: 2.64797
PPO Batch Consumption Time: 0.05159
Total Iteration Time: 16.12412

Cumulative Model Updates: 64,182
Cumulative Timesteps: 1,070,557,410

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1070557410...
Checkpoint 1070557410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254,667.24838
Policy Entropy: 1.00472
Value Function Loss: 1.34656

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.14699
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.09082

Collected Steps per Second: 3,857.91875
Overall Steps per Second: 3,206.98716

Timestep Collection Time: 12.96087
Timestep Consumption Time: 2.63071
PPO Batch Consumption Time: 0.04734
Total Iteration Time: 15.59158

Cumulative Model Updates: 64,185
Cumulative Timesteps: 1,070,607,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,052,830.19859
Policy Entropy: 0.99568
Value Function Loss: 1.36913

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.18663
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.08278

Collected Steps per Second: 3,875.55832
Overall Steps per Second: 3,237.66188

Timestep Collection Time: 12.90188
Timestep Consumption Time: 2.54198
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 15.44386

Cumulative Model Updates: 64,188
Cumulative Timesteps: 1,070,657,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1070657414...
Checkpoint 1070657414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605,206.14221
Policy Entropy: 1.00044
Value Function Loss: 1.34395

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.09237

Collected Steps per Second: 3,803.97461
Overall Steps per Second: 3,195.92540

Timestep Collection Time: 13.15361
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 15.65619

Cumulative Model Updates: 64,191
Cumulative Timesteps: 1,070,707,450

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357,809.29118
Policy Entropy: 1.01280
Value Function Loss: 1.32606

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.17773
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.10098

Collected Steps per Second: 3,825.18646
Overall Steps per Second: 3,178.28852

Timestep Collection Time: 13.08119
Timestep Consumption Time: 2.66250
PPO Batch Consumption Time: 0.05148
Total Iteration Time: 15.74369

Cumulative Model Updates: 64,194
Cumulative Timesteps: 1,070,757,488

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1070757488...
Checkpoint 1070757488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991,181.31423
Policy Entropy: 0.99988
Value Function Loss: 1.35915

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.11327

Collected Steps per Second: 3,830.92192
Overall Steps per Second: 3,174.96363

Timestep Collection Time: 13.05325
Timestep Consumption Time: 2.69685
PPO Batch Consumption Time: 0.05049
Total Iteration Time: 15.75010

Cumulative Model Updates: 64,197
Cumulative Timesteps: 1,070,807,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,442,777.05099
Policy Entropy: 1.01620
Value Function Loss: 1.40052

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.15899
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.10541

Collected Steps per Second: 3,800.30794
Overall Steps per Second: 3,209.72365

Timestep Collection Time: 13.15788
Timestep Consumption Time: 2.42103
PPO Batch Consumption Time: 0.04925
Total Iteration Time: 15.57891

Cumulative Model Updates: 64,200
Cumulative Timesteps: 1,070,857,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1070857498...
Checkpoint 1070857498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655,274.56579
Policy Entropy: 1.02483
Value Function Loss: 1.42399

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.06132
Value Function Update Magnitude: 0.10649

Collected Steps per Second: 3,774.01092
Overall Steps per Second: 3,180.43169

Timestep Collection Time: 13.25327
Timestep Consumption Time: 2.47352
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 15.72680

Cumulative Model Updates: 64,203
Cumulative Timesteps: 1,070,907,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277,158.56449
Policy Entropy: 1.00023
Value Function Loss: 1.39141

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.17987
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.09736

Collected Steps per Second: 3,863.94186
Overall Steps per Second: 3,263.41634

Timestep Collection Time: 12.94015
Timestep Consumption Time: 2.38121
PPO Batch Consumption Time: 0.05822
Total Iteration Time: 15.32137

Cumulative Model Updates: 64,206
Cumulative Timesteps: 1,070,957,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1070957516...
Checkpoint 1070957516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022,299.87827
Policy Entropy: 1.00427
Value Function Loss: 1.40225

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.16445
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.08583

Collected Steps per Second: 3,759.10974
Overall Steps per Second: 3,206.50685

Timestep Collection Time: 13.31219
Timestep Consumption Time: 2.29420
PPO Batch Consumption Time: 0.05304
Total Iteration Time: 15.60639

Cumulative Model Updates: 64,209
Cumulative Timesteps: 1,071,007,558

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,290,072.90965
Policy Entropy: 1.00672
Value Function Loss: 1.41343

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.15127
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.09189

Collected Steps per Second: 3,840.78594
Overall Steps per Second: 3,200.26514

Timestep Collection Time: 13.02077
Timestep Consumption Time: 2.60606
PPO Batch Consumption Time: 0.04922
Total Iteration Time: 15.62683

Cumulative Model Updates: 64,212
Cumulative Timesteps: 1,071,057,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1071057568...
Checkpoint 1071057568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,147,320.91771
Policy Entropy: 1.01920
Value Function Loss: 1.46361

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.09587

Collected Steps per Second: 3,763.40432
Overall Steps per Second: 3,134.82347

Timestep Collection Time: 13.29860
Timestep Consumption Time: 2.66658
PPO Batch Consumption Time: 0.05962
Total Iteration Time: 15.96517

Cumulative Model Updates: 64,215
Cumulative Timesteps: 1,071,107,616

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782,049.40162
Policy Entropy: 1.00608
Value Function Loss: 1.41214

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.15322
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.09028

Collected Steps per Second: 3,812.95476
Overall Steps per Second: 3,174.12506

Timestep Collection Time: 13.12578
Timestep Consumption Time: 2.64172
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 15.76749

Cumulative Model Updates: 64,218
Cumulative Timesteps: 1,071,157,664

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1071157664...
Checkpoint 1071157664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421,268.44014
Policy Entropy: 0.99997
Value Function Loss: 1.46004

Mean KL Divergence: 0.02393
SB3 Clip Fraction: 0.18896
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.09907

Collected Steps per Second: 3,909.49070
Overall Steps per Second: 3,240.63578

Timestep Collection Time: 12.79553
Timestep Consumption Time: 2.64095
PPO Batch Consumption Time: 0.04942
Total Iteration Time: 15.43648

Cumulative Model Updates: 64,221
Cumulative Timesteps: 1,071,207,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315,580.49699
Policy Entropy: 1.01712
Value Function Loss: 1.46146

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.09199

Collected Steps per Second: 3,684.43884
Overall Steps per Second: 3,092.55205

Timestep Collection Time: 13.57764
Timestep Consumption Time: 2.59864
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 16.17628

Cumulative Model Updates: 64,224
Cumulative Timesteps: 1,071,257,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1071257714...
Checkpoint 1071257714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579,529.14945
Policy Entropy: 1.02152
Value Function Loss: 1.51203

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.16559
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.09199

Collected Steps per Second: 3,827.52126
Overall Steps per Second: 3,165.36333

Timestep Collection Time: 13.07269
Timestep Consumption Time: 2.73466
PPO Batch Consumption Time: 0.05783
Total Iteration Time: 15.80735

Cumulative Model Updates: 64,227
Cumulative Timesteps: 1,071,307,750

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688,496.09377
Policy Entropy: 0.99312
Value Function Loss: 1.44312

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.10181

Collected Steps per Second: 3,936.79772
Overall Steps per Second: 3,257.87550

Timestep Collection Time: 12.70322
Timestep Consumption Time: 2.64728
PPO Batch Consumption Time: 0.05265
Total Iteration Time: 15.35049

Cumulative Model Updates: 64,230
Cumulative Timesteps: 1,071,357,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1071357760...
Checkpoint 1071357760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356,165.04378
Policy Entropy: 1.00299
Value Function Loss: 1.33341

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 4,113.52990
Overall Steps per Second: 3,380.85134

Timestep Collection Time: 12.15744
Timestep Consumption Time: 2.63469
PPO Batch Consumption Time: 0.05203
Total Iteration Time: 14.79213

Cumulative Model Updates: 64,233
Cumulative Timesteps: 1,071,407,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780,787.26350
Policy Entropy: 1.00891
Value Function Loss: 1.32070

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.11460

Collected Steps per Second: 3,947.29261
Overall Steps per Second: 3,317.16084

Timestep Collection Time: 12.67198
Timestep Consumption Time: 2.40718
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 15.07916

Cumulative Model Updates: 64,236
Cumulative Timesteps: 1,071,457,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1071457790...
Checkpoint 1071457790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840,185.26240
Policy Entropy: 1.03256
Value Function Loss: 1.25300

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.15645
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.11358

Collected Steps per Second: 3,824.75743
Overall Steps per Second: 3,196.43705

Timestep Collection Time: 13.07482
Timestep Consumption Time: 2.57010
PPO Batch Consumption Time: 0.04977
Total Iteration Time: 15.64492

Cumulative Model Updates: 64,239
Cumulative Timesteps: 1,071,507,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,561,285.99892
Policy Entropy: 1.00602
Value Function Loss: 1.34831

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14279
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.10242

Collected Steps per Second: 3,933.35957
Overall Steps per Second: 3,296.91328

Timestep Collection Time: 12.71890
Timestep Consumption Time: 2.45530
PPO Batch Consumption Time: 0.05814
Total Iteration Time: 15.17419

Cumulative Model Updates: 64,242
Cumulative Timesteps: 1,071,557,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1071557826...
Checkpoint 1071557826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,411,650.10522
Policy Entropy: 0.99953
Value Function Loss: 1.37190

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.19421
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.10064

Collected Steps per Second: 3,932.04512
Overall Steps per Second: 3,306.58335

Timestep Collection Time: 12.71654
Timestep Consumption Time: 2.40542
PPO Batch Consumption Time: 0.05070
Total Iteration Time: 15.12195

Cumulative Model Updates: 64,245
Cumulative Timesteps: 1,071,607,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287,592.30984
Policy Entropy: 1.01124
Value Function Loss: 1.41192

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.10967

Collected Steps per Second: 3,708.48603
Overall Steps per Second: 3,121.64584

Timestep Collection Time: 13.48475
Timestep Consumption Time: 2.53501
PPO Batch Consumption Time: 0.05403
Total Iteration Time: 16.01975

Cumulative Model Updates: 64,248
Cumulative Timesteps: 1,071,657,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1071657836...
Checkpoint 1071657836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462,874.44340
Policy Entropy: 1.02789
Value Function Loss: 1.36710

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.16225
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.11824

Collected Steps per Second: 3,773.94007
Overall Steps per Second: 3,117.72214

Timestep Collection Time: 13.25776
Timestep Consumption Time: 2.79049
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 16.04826

Cumulative Model Updates: 64,251
Cumulative Timesteps: 1,071,707,870

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470,525.14828
Policy Entropy: 1.01170
Value Function Loss: 1.34334

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.11862

Collected Steps per Second: 3,683.04839
Overall Steps per Second: 3,066.96577

Timestep Collection Time: 13.57680
Timestep Consumption Time: 2.72727
PPO Batch Consumption Time: 0.05825
Total Iteration Time: 16.30406

Cumulative Model Updates: 64,254
Cumulative Timesteps: 1,071,757,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1071757874...
Checkpoint 1071757874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,375,077.53302
Policy Entropy: 1.00498
Value Function Loss: 1.36054

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15382
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.12319

Collected Steps per Second: 3,998.02682
Overall Steps per Second: 3,269.61102

Timestep Collection Time: 12.51217
Timestep Consumption Time: 2.78751
PPO Batch Consumption Time: 0.05373
Total Iteration Time: 15.29968

Cumulative Model Updates: 64,257
Cumulative Timesteps: 1,071,807,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,354,336.46652
Policy Entropy: 1.01939
Value Function Loss: 1.41494

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.14179

Collected Steps per Second: 3,665.64484
Overall Steps per Second: 3,042.23917

Timestep Collection Time: 13.64344
Timestep Consumption Time: 2.79577
PPO Batch Consumption Time: 0.06193
Total Iteration Time: 16.43921

Cumulative Model Updates: 64,260
Cumulative Timesteps: 1,071,857,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1071857910...
Checkpoint 1071857910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667,676.51335
Policy Entropy: 1.02114
Value Function Loss: 1.40853

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.17426
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.14183

Collected Steps per Second: 3,900.30330
Overall Steps per Second: 3,221.64088

Timestep Collection Time: 12.83182
Timestep Consumption Time: 2.70312
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 15.53494

Cumulative Model Updates: 64,263
Cumulative Timesteps: 1,071,907,958

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664,721.26455
Policy Entropy: 1.00537
Value Function Loss: 1.43469

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.13378

Collected Steps per Second: 3,715.55577
Overall Steps per Second: 3,117.55655

Timestep Collection Time: 13.46501
Timestep Consumption Time: 2.58281
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 16.04782

Cumulative Model Updates: 64,266
Cumulative Timesteps: 1,071,957,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1071957988...
Checkpoint 1071957988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,153,037.44035
Policy Entropy: 0.99281
Value Function Loss: 1.35181

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.16511
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.13313

Collected Steps per Second: 3,709.16123
Overall Steps per Second: 3,103.53267

Timestep Collection Time: 13.49038
Timestep Consumption Time: 2.63254
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 16.12292

Cumulative Model Updates: 64,269
Cumulative Timesteps: 1,072,008,026

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,884,193.70498
Policy Entropy: 1.00700
Value Function Loss: 1.38081

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.13738

Collected Steps per Second: 3,853.22134
Overall Steps per Second: 3,205.20682

Timestep Collection Time: 12.98290
Timestep Consumption Time: 2.62483
PPO Batch Consumption Time: 0.06270
Total Iteration Time: 15.60773

Cumulative Model Updates: 64,272
Cumulative Timesteps: 1,072,058,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1072058052...
Checkpoint 1072058052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417,174.40582
Policy Entropy: 1.01692
Value Function Loss: 1.32877

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.15847
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.14592

Collected Steps per Second: 3,742.34260
Overall Steps per Second: 3,134.70890

Timestep Collection Time: 13.37023
Timestep Consumption Time: 2.59169
PPO Batch Consumption Time: 0.05771
Total Iteration Time: 15.96193

Cumulative Model Updates: 64,275
Cumulative Timesteps: 1,072,108,088

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659,401.60599
Policy Entropy: 1.00869
Value Function Loss: 1.43036

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.15155

Collected Steps per Second: 3,965.52867
Overall Steps per Second: 3,239.83484

Timestep Collection Time: 12.60967
Timestep Consumption Time: 2.82445
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 15.43412

Cumulative Model Updates: 64,278
Cumulative Timesteps: 1,072,158,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1072158092...
Checkpoint 1072158092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,480,425.74972
Policy Entropy: 1.00260
Value Function Loss: 1.33814

Mean KL Divergence: 0.02525
SB3 Clip Fraction: 0.19510
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.14083

Collected Steps per Second: 3,764.23300
Overall Steps per Second: 3,160.02698

Timestep Collection Time: 13.29036
Timestep Consumption Time: 2.54115
PPO Batch Consumption Time: 0.06569
Total Iteration Time: 15.83151

Cumulative Model Updates: 64,281
Cumulative Timesteps: 1,072,208,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676,428.11323
Policy Entropy: 1.01553
Value Function Loss: 1.37183

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.13151

Collected Steps per Second: 3,874.47633
Overall Steps per Second: 3,261.30515

Timestep Collection Time: 12.90600
Timestep Consumption Time: 2.42651
PPO Batch Consumption Time: 0.05905
Total Iteration Time: 15.33251

Cumulative Model Updates: 64,284
Cumulative Timesteps: 1,072,258,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1072258124...
Checkpoint 1072258124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584,337.13215
Policy Entropy: 1.01484
Value Function Loss: 1.34465

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.17131
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.14023

Collected Steps per Second: 3,689.59013
Overall Steps per Second: 3,130.46235

Timestep Collection Time: 13.55760
Timestep Consumption Time: 2.42151
PPO Batch Consumption Time: 0.06015
Total Iteration Time: 15.97911

Cumulative Model Updates: 64,287
Cumulative Timesteps: 1,072,308,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162,625.97423
Policy Entropy: 0.99278
Value Function Loss: 1.38567

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14861
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.13396

Collected Steps per Second: 3,640.48524
Overall Steps per Second: 3,093.20911

Timestep Collection Time: 13.74762
Timestep Consumption Time: 2.43234
PPO Batch Consumption Time: 0.05403
Total Iteration Time: 16.17996

Cumulative Model Updates: 64,290
Cumulative Timesteps: 1,072,358,194

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1072358194...
Checkpoint 1072358194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,973,362.10508
Policy Entropy: 0.99970
Value Function Loss: 1.36802

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.13144

Collected Steps per Second: 3,726.45644
Overall Steps per Second: 3,087.84261

Timestep Collection Time: 13.43045
Timestep Consumption Time: 2.77763
PPO Batch Consumption Time: 0.06289
Total Iteration Time: 16.20808

Cumulative Model Updates: 64,293
Cumulative Timesteps: 1,072,408,242

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764,474.45466
Policy Entropy: 1.01719
Value Function Loss: 1.35271

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.14845

Collected Steps per Second: 3,760.65633
Overall Steps per Second: 3,117.43046

Timestep Collection Time: 13.30193
Timestep Consumption Time: 2.74462
PPO Batch Consumption Time: 0.05243
Total Iteration Time: 16.04655

Cumulative Model Updates: 64,296
Cumulative Timesteps: 1,072,458,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1072458266...
Checkpoint 1072458266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,541,203.55563
Policy Entropy: 1.02501
Value Function Loss: 1.38897

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.15089

Collected Steps per Second: 3,855.88301
Overall Steps per Second: 3,197.73204

Timestep Collection Time: 12.97135
Timestep Consumption Time: 2.66974
PPO Batch Consumption Time: 0.05076
Total Iteration Time: 15.64109

Cumulative Model Updates: 64,299
Cumulative Timesteps: 1,072,508,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499,039.36469
Policy Entropy: 1.03024
Value Function Loss: 1.35658

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.06246
Value Function Update Magnitude: 0.15025

Collected Steps per Second: 3,760.72296
Overall Steps per Second: 3,110.28987

Timestep Collection Time: 13.30542
Timestep Consumption Time: 2.78247
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 16.08789

Cumulative Model Updates: 64,302
Cumulative Timesteps: 1,072,558,320

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1072558320...
Checkpoint 1072558320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912,468.29017
Policy Entropy: 1.00892
Value Function Loss: 1.39582

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.13656

Collected Steps per Second: 3,731.63925
Overall Steps per Second: 3,102.87527

Timestep Collection Time: 13.40537
Timestep Consumption Time: 2.71645
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 16.12182

Cumulative Model Updates: 64,305
Cumulative Timesteps: 1,072,608,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,526,639.94146
Policy Entropy: 0.97924
Value Function Loss: 1.36070

Mean KL Divergence: 0.03162
SB3 Clip Fraction: 0.21268
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.13115

Collected Steps per Second: 3,882.34803
Overall Steps per Second: 3,211.76340

Timestep Collection Time: 12.88293
Timestep Consumption Time: 2.68983
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 15.57275

Cumulative Model Updates: 64,308
Cumulative Timesteps: 1,072,658,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1072658360...
Checkpoint 1072658360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246,073.18760
Policy Entropy: 0.99469
Value Function Loss: 1.43997

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 3,701.70144
Overall Steps per Second: 3,072.18634

Timestep Collection Time: 13.52135
Timestep Consumption Time: 2.77063
PPO Batch Consumption Time: 0.05837
Total Iteration Time: 16.29198

Cumulative Model Updates: 64,311
Cumulative Timesteps: 1,072,708,412

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041,806.01217
Policy Entropy: 1.00811
Value Function Loss: 1.44712

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.12011

Collected Steps per Second: 3,813.85639
Overall Steps per Second: 3,186.29667

Timestep Collection Time: 13.11743
Timestep Consumption Time: 2.58355
PPO Batch Consumption Time: 0.05970
Total Iteration Time: 15.70099

Cumulative Model Updates: 64,314
Cumulative Timesteps: 1,072,758,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1072758440...
Checkpoint 1072758440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,906,428.05263
Policy Entropy: 0.99446
Value Function Loss: 1.49738

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.15877
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 3,757.72177
Overall Steps per Second: 3,132.52182

Timestep Collection Time: 13.31232
Timestep Consumption Time: 2.65692
PPO Batch Consumption Time: 0.05819
Total Iteration Time: 15.96924

Cumulative Model Updates: 64,317
Cumulative Timesteps: 1,072,808,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832,323.86060
Policy Entropy: 0.99544
Value Function Loss: 1.44511

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.18273
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.12486

Collected Steps per Second: 3,718.81300
Overall Steps per Second: 3,132.41152

Timestep Collection Time: 13.44838
Timestep Consumption Time: 2.51760
PPO Batch Consumption Time: 0.06917
Total Iteration Time: 15.96597

Cumulative Model Updates: 64,320
Cumulative Timesteps: 1,072,858,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1072858476...
Checkpoint 1072858476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318,442.78540
Policy Entropy: 1.00753
Value Function Loss: 1.36015

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.15071
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 3,832.26705
Overall Steps per Second: 3,237.47612

Timestep Collection Time: 13.05546
Timestep Consumption Time: 2.39856
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 15.45401

Cumulative Model Updates: 64,323
Cumulative Timesteps: 1,072,908,508

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698,580.12521
Policy Entropy: 1.02203
Value Function Loss: 1.23485

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.16129
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.09937

Collected Steps per Second: 3,678.67414
Overall Steps per Second: 3,116.50745

Timestep Collection Time: 13.60001
Timestep Consumption Time: 2.45322
PPO Batch Consumption Time: 0.04805
Total Iteration Time: 16.05323

Cumulative Model Updates: 64,326
Cumulative Timesteps: 1,072,958,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1072958538...
Checkpoint 1072958538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954,409.11026
Policy Entropy: 1.00730
Value Function Loss: 1.20015

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.10574

Collected Steps per Second: 3,806.17358
Overall Steps per Second: 3,136.36940

Timestep Collection Time: 13.13865
Timestep Consumption Time: 2.80590
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 15.94455

Cumulative Model Updates: 64,329
Cumulative Timesteps: 1,073,008,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,101,696.43921
Policy Entropy: 0.98990
Value Function Loss: 1.20438

Mean KL Divergence: 0.03338
SB3 Clip Fraction: 0.20187
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.10731

Collected Steps per Second: 3,723.02703
Overall Steps per Second: 3,097.43828

Timestep Collection Time: 13.44068
Timestep Consumption Time: 2.71461
PPO Batch Consumption Time: 0.05914
Total Iteration Time: 16.15529

Cumulative Model Updates: 64,332
Cumulative Timesteps: 1,073,058,586

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1073058586...
Checkpoint 1073058586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,124,992.32993
Policy Entropy: 1.00293
Value Function Loss: 1.29473

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.09768

Collected Steps per Second: 3,897.41476
Overall Steps per Second: 3,253.65245

Timestep Collection Time: 12.83466
Timestep Consumption Time: 2.53944
PPO Batch Consumption Time: 0.06269
Total Iteration Time: 15.37411

Cumulative Model Updates: 64,335
Cumulative Timesteps: 1,073,108,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204,072.37171
Policy Entropy: 0.99688
Value Function Loss: 1.35614

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.06136
Value Function Update Magnitude: 0.08970

Collected Steps per Second: 3,662.73362
Overall Steps per Second: 3,035.85738

Timestep Collection Time: 13.65264
Timestep Consumption Time: 2.81914
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 16.47179

Cumulative Model Updates: 64,338
Cumulative Timesteps: 1,073,158,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1073158614...
Checkpoint 1073158614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480,087.89266
Policy Entropy: 0.98294
Value Function Loss: 1.39876

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.16859
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.09619

Collected Steps per Second: 3,966.05626
Overall Steps per Second: 3,251.37529

Timestep Collection Time: 12.61959
Timestep Consumption Time: 2.77390
PPO Batch Consumption Time: 0.06317
Total Iteration Time: 15.39349

Cumulative Model Updates: 64,341
Cumulative Timesteps: 1,073,208,664

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504,812.51192
Policy Entropy: 0.99072
Value Function Loss: 1.43057

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.09841

Collected Steps per Second: 3,722.09346
Overall Steps per Second: 3,082.17330

Timestep Collection Time: 13.43814
Timestep Consumption Time: 2.79002
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 16.22816

Cumulative Model Updates: 64,344
Cumulative Timesteps: 1,073,258,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1073258682...
Checkpoint 1073258682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128,010.29941
Policy Entropy: 0.99651
Value Function Loss: 1.42522

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.18622
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.09010

Collected Steps per Second: 3,790.75959
Overall Steps per Second: 3,171.67373

Timestep Collection Time: 13.19155
Timestep Consumption Time: 2.57489
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 15.76644

Cumulative Model Updates: 64,347
Cumulative Timesteps: 1,073,308,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580,618.09631
Policy Entropy: 0.99332
Value Function Loss: 1.38010

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.09894

Collected Steps per Second: 3,743.22934
Overall Steps per Second: 3,116.03646

Timestep Collection Time: 13.36867
Timestep Consumption Time: 2.69083
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 16.05950

Cumulative Model Updates: 64,350
Cumulative Timesteps: 1,073,358,730

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1073358730...
Checkpoint 1073358730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104,671.31332
Policy Entropy: 0.98200
Value Function Loss: 1.29361

Mean KL Divergence: 0.02533
SB3 Clip Fraction: 0.19479
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.09738

Collected Steps per Second: 3,648.27794
Overall Steps per Second: 3,042.74980

Timestep Collection Time: 13.71222
Timestep Consumption Time: 2.72883
PPO Batch Consumption Time: 0.05439
Total Iteration Time: 16.44105

Cumulative Model Updates: 64,353
Cumulative Timesteps: 1,073,408,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,428,071.01200
Policy Entropy: 0.99469
Value Function Loss: 1.26803

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.09202

Collected Steps per Second: 3,592.01512
Overall Steps per Second: 3,060.04958

Timestep Collection Time: 13.92143
Timestep Consumption Time: 2.42013
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 16.34157

Cumulative Model Updates: 64,356
Cumulative Timesteps: 1,073,458,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1073458762...
Checkpoint 1073458762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819,453.57358
Policy Entropy: 1.00585
Value Function Loss: 1.30077

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.06622
Value Function Update Magnitude: 0.10271

Collected Steps per Second: 3,693.21129
Overall Steps per Second: 3,129.20131

Timestep Collection Time: 13.54918
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 15.99130

Cumulative Model Updates: 64,359
Cumulative Timesteps: 1,073,508,802

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,064,310.88258
Policy Entropy: 0.98832
Value Function Loss: 1.34295

Mean KL Divergence: 0.02602
SB3 Clip Fraction: 0.17797
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.09143

Collected Steps per Second: 3,808.34847
Overall Steps per Second: 3,205.98066

Timestep Collection Time: 13.13798
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.05137
Total Iteration Time: 15.60646

Cumulative Model Updates: 64,362
Cumulative Timesteps: 1,073,558,836

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1073558836...
Checkpoint 1073558836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649,195.50506
Policy Entropy: 1.00176
Value Function Loss: 1.34579

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.16380
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.09238

Collected Steps per Second: 3,755.20935
Overall Steps per Second: 3,146.13570

Timestep Collection Time: 13.32336
Timestep Consumption Time: 2.57932
PPO Batch Consumption Time: 0.04776
Total Iteration Time: 15.90268

Cumulative Model Updates: 64,365
Cumulative Timesteps: 1,073,608,868

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764,902.83032
Policy Entropy: 1.00655
Value Function Loss: 1.38065

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.16913
Policy Update Magnitude: 0.06565
Value Function Update Magnitude: 0.09026

Collected Steps per Second: 3,820.63307
Overall Steps per Second: 3,148.75298

Timestep Collection Time: 13.08945
Timestep Consumption Time: 2.79302
PPO Batch Consumption Time: 0.05043
Total Iteration Time: 15.88248

Cumulative Model Updates: 64,368
Cumulative Timesteps: 1,073,658,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1073658878...
Checkpoint 1073658878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,992,316.49218
Policy Entropy: 1.01759
Value Function Loss: 1.40047

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.18975
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 3,744.52811
Overall Steps per Second: 3,124.03385

Timestep Collection Time: 13.36190
Timestep Consumption Time: 2.65393
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 16.01583

Cumulative Model Updates: 64,371
Cumulative Timesteps: 1,073,708,912

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156,329.50361
Policy Entropy: 0.99156
Value Function Loss: 1.38502

Mean KL Divergence: 0.02552
SB3 Clip Fraction: 0.16564
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.14237

Collected Steps per Second: 4,005.62267
Overall Steps per Second: 3,354.12873

Timestep Collection Time: 12.49194
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 14.91833

Cumulative Model Updates: 64,374
Cumulative Timesteps: 1,073,758,950

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1073758950...
Checkpoint 1073758950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469,294.96965
Policy Entropy: 1.01374
Value Function Loss: 1.37933

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.18399
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.13414

Collected Steps per Second: 3,657.79347
Overall Steps per Second: 3,080.95209

Timestep Collection Time: 13.67163
Timestep Consumption Time: 2.55972
PPO Batch Consumption Time: 0.06437
Total Iteration Time: 16.23135

Cumulative Model Updates: 64,377
Cumulative Timesteps: 1,073,808,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652,089.06560
Policy Entropy: 1.01352
Value Function Loss: 1.39389

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.17763
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.11241

Collected Steps per Second: 3,710.74495
Overall Steps per Second: 3,132.37923

Timestep Collection Time: 13.47816
Timestep Consumption Time: 2.48862
PPO Batch Consumption Time: 0.06566
Total Iteration Time: 15.96678

Cumulative Model Updates: 64,380
Cumulative Timesteps: 1,073,858,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1073858972...
Checkpoint 1073858972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,487,863.80706
Policy Entropy: 1.00079
Value Function Loss: 1.40137

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.15421
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.09987

Collected Steps per Second: 3,732.54476
Overall Steps per Second: 3,118.27982

Timestep Collection Time: 13.40051
Timestep Consumption Time: 2.63974
PPO Batch Consumption Time: 0.05113
Total Iteration Time: 16.04025

Cumulative Model Updates: 64,383
Cumulative Timesteps: 1,073,908,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,039,542.26073
Policy Entropy: 0.99883
Value Function Loss: 1.36008

Mean KL Divergence: 0.02639
SB3 Clip Fraction: 0.19589
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.11165

Collected Steps per Second: 3,697.67584
Overall Steps per Second: 3,086.91317

Timestep Collection Time: 13.53553
Timestep Consumption Time: 2.67808
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 16.21361

Cumulative Model Updates: 64,386
Cumulative Timesteps: 1,073,959,040

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1073959040...
Checkpoint 1073959040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746,534.76667
Policy Entropy: 1.01375
Value Function Loss: 1.43028

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 3,676.66722
Overall Steps per Second: 3,103.28994

Timestep Collection Time: 13.60036
Timestep Consumption Time: 2.51286
PPO Batch Consumption Time: 0.05132
Total Iteration Time: 16.11322

Cumulative Model Updates: 64,389
Cumulative Timesteps: 1,074,009,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,242,425.96387
Policy Entropy: 1.02004
Value Function Loss: 1.39831

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.15825
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.10440

Collected Steps per Second: 3,706.51809
Overall Steps per Second: 3,134.03868

Timestep Collection Time: 13.49730
Timestep Consumption Time: 2.46549
PPO Batch Consumption Time: 0.05140
Total Iteration Time: 15.96279

Cumulative Model Updates: 64,392
Cumulative Timesteps: 1,074,059,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1074059072...
Checkpoint 1074059072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879,259.53014
Policy Entropy: 1.00743
Value Function Loss: 1.38061

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.11021

Collected Steps per Second: 3,725.40300
Overall Steps per Second: 3,058.23049

Timestep Collection Time: 13.42566
Timestep Consumption Time: 2.92889
PPO Batch Consumption Time: 0.05965
Total Iteration Time: 16.35456

Cumulative Model Updates: 64,395
Cumulative Timesteps: 1,074,109,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,731,802.27794
Policy Entropy: 0.99131
Value Function Loss: 1.39871

Mean KL Divergence: 0.02447
SB3 Clip Fraction: 0.18245
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.10947

Collected Steps per Second: 3,688.70483
Overall Steps per Second: 3,066.41316

Timestep Collection Time: 13.56574
Timestep Consumption Time: 2.75300
PPO Batch Consumption Time: 0.05160
Total Iteration Time: 16.31874

Cumulative Model Updates: 64,398
Cumulative Timesteps: 1,074,159,128

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1074159128...
Checkpoint 1074159128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354,338.23999
Policy Entropy: 1.00884
Value Function Loss: 1.41381

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.10333

Collected Steps per Second: 3,753.39745
Overall Steps per Second: 3,128.34736

Timestep Collection Time: 13.32606
Timestep Consumption Time: 2.66257
PPO Batch Consumption Time: 0.04952
Total Iteration Time: 15.98863

Cumulative Model Updates: 64,401
Cumulative Timesteps: 1,074,209,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273,315.81702
Policy Entropy: 1.02112
Value Function Loss: 1.36688

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.16555
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.10634

Collected Steps per Second: 3,857.19396
Overall Steps per Second: 3,194.47239

Timestep Collection Time: 12.97057
Timestep Consumption Time: 2.69086
PPO Batch Consumption Time: 0.05165
Total Iteration Time: 15.66143

Cumulative Model Updates: 64,404
Cumulative Timesteps: 1,074,259,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1074259176...
Checkpoint 1074259176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197,331.38251
Policy Entropy: 1.00756
Value Function Loss: 1.29282

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.11467

Collected Steps per Second: 3,951.53042
Overall Steps per Second: 3,255.79516

Timestep Collection Time: 12.65737
Timestep Consumption Time: 2.70477
PPO Batch Consumption Time: 0.04683
Total Iteration Time: 15.36215

Cumulative Model Updates: 64,407
Cumulative Timesteps: 1,074,309,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729,052.85427
Policy Entropy: 1.00107
Value Function Loss: 1.36217

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.17525
Policy Update Magnitude: 0.06301
Value Function Update Magnitude: 0.11139

Collected Steps per Second: 4,117.20794
Overall Steps per Second: 3,386.81061

Timestep Collection Time: 12.14901
Timestep Consumption Time: 2.62005
PPO Batch Consumption Time: 0.05346
Total Iteration Time: 14.76906

Cumulative Model Updates: 64,410
Cumulative Timesteps: 1,074,359,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1074359212...
Checkpoint 1074359212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466,528.19082
Policy Entropy: 1.01807
Value Function Loss: 1.37391

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.10755

Collected Steps per Second: 4,075.89694
Overall Steps per Second: 3,359.66883

Timestep Collection Time: 12.26920
Timestep Consumption Time: 2.61560
PPO Batch Consumption Time: 0.05963
Total Iteration Time: 14.88480

Cumulative Model Updates: 64,413
Cumulative Timesteps: 1,074,409,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,566,973.80927
Policy Entropy: 1.02678
Value Function Loss: 1.28531

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.15477
Policy Update Magnitude: 0.06626
Value Function Update Magnitude: 0.10248

Collected Steps per Second: 3,629.32087
Overall Steps per Second: 3,038.75618

Timestep Collection Time: 13.78054
Timestep Consumption Time: 2.67817
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 16.45871

Cumulative Model Updates: 64,416
Cumulative Timesteps: 1,074,459,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1074459234...
Checkpoint 1074459234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,131,588.63547
Policy Entropy: 1.01628
Value Function Loss: 1.25225

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.15498
Policy Update Magnitude: 0.06523
Value Function Update Magnitude: 0.10228

Collected Steps per Second: 3,818.96920
Overall Steps per Second: 3,090.80919

Timestep Collection Time: 13.10615
Timestep Consumption Time: 3.08766
PPO Batch Consumption Time: 0.06780
Total Iteration Time: 16.19382

Cumulative Model Updates: 64,419
Cumulative Timesteps: 1,074,509,286

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,420,275.86272
Policy Entropy: 1.00158
Value Function Loss: 1.32310

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.18117
Policy Update Magnitude: 0.05989
Value Function Update Magnitude: 0.12106

Collected Steps per Second: 3,690.44826
Overall Steps per Second: 3,119.16272

Timestep Collection Time: 13.54957
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.05225
Total Iteration Time: 16.03123

Cumulative Model Updates: 64,422
Cumulative Timesteps: 1,074,559,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1074559290...
Checkpoint 1074559290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888,203.15642
Policy Entropy: 1.01558
Value Function Loss: 1.36145

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.13564

Collected Steps per Second: 3,894.80359
Overall Steps per Second: 3,266.41368

Timestep Collection Time: 12.84583
Timestep Consumption Time: 2.47127
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 15.31710

Cumulative Model Updates: 64,425
Cumulative Timesteps: 1,074,609,322

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684,776.57762
Policy Entropy: 1.01262
Value Function Loss: 1.37543

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.12644

Collected Steps per Second: 4,056.79704
Overall Steps per Second: 3,304.17742

Timestep Collection Time: 12.32845
Timestep Consumption Time: 2.80815
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 15.13660

Cumulative Model Updates: 64,428
Cumulative Timesteps: 1,074,659,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1074659336...
Checkpoint 1074659336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674,654.70379
Policy Entropy: 1.00214
Value Function Loss: 1.31542

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.11882

Collected Steps per Second: 3,789.77319
Overall Steps per Second: 3,138.01770

Timestep Collection Time: 13.19498
Timestep Consumption Time: 2.74055
PPO Batch Consumption Time: 0.04914
Total Iteration Time: 15.93554

Cumulative Model Updates: 64,431
Cumulative Timesteps: 1,074,709,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098,278.40623
Policy Entropy: 0.99592
Value Function Loss: 1.36277

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.17434
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.11330

Collected Steps per Second: 3,684.34713
Overall Steps per Second: 3,047.15407

Timestep Collection Time: 13.57527
Timestep Consumption Time: 2.83874
PPO Batch Consumption Time: 0.07327
Total Iteration Time: 16.41400

Cumulative Model Updates: 64,434
Cumulative Timesteps: 1,074,759,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1074759358...
Checkpoint 1074759358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,339,274.09704
Policy Entropy: 1.01573
Value Function Loss: 1.39252

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 3,808.68835
Overall Steps per Second: 3,142.86722

Timestep Collection Time: 13.14048
Timestep Consumption Time: 2.78383
PPO Batch Consumption Time: 0.05783
Total Iteration Time: 15.92431

Cumulative Model Updates: 64,437
Cumulative Timesteps: 1,074,809,406

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,960,622.69603
Policy Entropy: 1.01997
Value Function Loss: 1.50033

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.15409
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.12877

Collected Steps per Second: 3,626.77055
Overall Steps per Second: 3,030.24625

Timestep Collection Time: 13.78637
Timestep Consumption Time: 2.71394
PPO Batch Consumption Time: 0.06062
Total Iteration Time: 16.50031

Cumulative Model Updates: 64,440
Cumulative Timesteps: 1,074,859,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1074859406...
Checkpoint 1074859406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674,432.45645
Policy Entropy: 1.00116
Value Function Loss: 1.45124

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.13490

Collected Steps per Second: 3,700.59046
Overall Steps per Second: 3,087.12494

Timestep Collection Time: 13.52217
Timestep Consumption Time: 2.68709
PPO Batch Consumption Time: 0.04902
Total Iteration Time: 16.20926

Cumulative Model Updates: 64,443
Cumulative Timesteps: 1,074,909,446

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563,784.17178
Policy Entropy: 0.99988
Value Function Loss: 1.49526

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.13254

Collected Steps per Second: 3,719.60673
Overall Steps per Second: 3,116.15246

Timestep Collection Time: 13.45411
Timestep Consumption Time: 2.60544
PPO Batch Consumption Time: 0.05365
Total Iteration Time: 16.05955

Cumulative Model Updates: 64,446
Cumulative Timesteps: 1,074,959,490

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1074959490...
Checkpoint 1074959490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,442,113.89372
Policy Entropy: 1.01198
Value Function Loss: 1.45396

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.12106

Collected Steps per Second: 3,863.26886
Overall Steps per Second: 3,208.74044

Timestep Collection Time: 12.94603
Timestep Consumption Time: 2.64077
PPO Batch Consumption Time: 0.05304
Total Iteration Time: 15.58680

Cumulative Model Updates: 64,449
Cumulative Timesteps: 1,075,009,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087,094.22587
Policy Entropy: 1.02627
Value Function Loss: 1.42519

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.17345
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.10278

Collected Steps per Second: 3,731.36048
Overall Steps per Second: 3,083.38062

Timestep Collection Time: 13.40959
Timestep Consumption Time: 2.81806
PPO Batch Consumption Time: 0.05783
Total Iteration Time: 16.22764

Cumulative Model Updates: 64,452
Cumulative Timesteps: 1,075,059,540

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1075059540...
Checkpoint 1075059540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889,990.03201
Policy Entropy: 1.01683
Value Function Loss: 1.34590

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.09419

Collected Steps per Second: 3,814.63647
Overall Steps per Second: 3,186.24956

Timestep Collection Time: 13.11947
Timestep Consumption Time: 2.58740
PPO Batch Consumption Time: 0.06245
Total Iteration Time: 15.70687

Cumulative Model Updates: 64,455
Cumulative Timesteps: 1,075,109,586

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,908,415.94849
Policy Entropy: 1.02715
Value Function Loss: 1.35924

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.10896

Collected Steps per Second: 3,683.99347
Overall Steps per Second: 3,143.19416

Timestep Collection Time: 13.57549
Timestep Consumption Time: 2.33572
PPO Batch Consumption Time: 0.05995
Total Iteration Time: 15.91120

Cumulative Model Updates: 64,458
Cumulative Timesteps: 1,075,159,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1075159598...
Checkpoint 1075159598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782,279.34957
Policy Entropy: 1.03204
Value Function Loss: 1.38264

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.10616

Collected Steps per Second: 3,772.93977
Overall Steps per Second: 3,186.50672

Timestep Collection Time: 13.25280
Timestep Consumption Time: 2.43900
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 15.69179

Cumulative Model Updates: 64,461
Cumulative Timesteps: 1,075,209,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,454,038.61910
Policy Entropy: 1.02809
Value Function Loss: 1.45159

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.09818

Collected Steps per Second: 3,961.34994
Overall Steps per Second: 3,353.36626

Timestep Collection Time: 12.62347
Timestep Consumption Time: 2.28871
PPO Batch Consumption Time: 0.04955
Total Iteration Time: 14.91218

Cumulative Model Updates: 64,464
Cumulative Timesteps: 1,075,259,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1075259606...
Checkpoint 1075259606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415,990.98008
Policy Entropy: 1.02792
Value Function Loss: 1.34479

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.07652
Value Function Update Magnitude: 0.09532

Collected Steps per Second: 4,273.28414
Overall Steps per Second: 3,478.11091

Timestep Collection Time: 11.70060
Timestep Consumption Time: 2.67502
PPO Batch Consumption Time: 0.05165
Total Iteration Time: 14.37562

Cumulative Model Updates: 64,467
Cumulative Timesteps: 1,075,309,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,082,115.98579
Policy Entropy: 1.02294
Value Function Loss: 1.37749

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.07686
Value Function Update Magnitude: 0.09240

Collected Steps per Second: 3,985.62335
Overall Steps per Second: 3,346.15350

Timestep Collection Time: 12.54659
Timestep Consumption Time: 2.39773
PPO Batch Consumption Time: 0.06188
Total Iteration Time: 14.94432

Cumulative Model Updates: 64,470
Cumulative Timesteps: 1,075,359,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1075359612...
Checkpoint 1075359612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650,081.66772
Policy Entropy: 1.00947
Value Function Loss: 1.35574

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.17259
Policy Update Magnitude: 0.07182
Value Function Update Magnitude: 0.09660

Collected Steps per Second: 3,801.53726
Overall Steps per Second: 3,166.33288

Timestep Collection Time: 13.15889
Timestep Consumption Time: 2.63983
PPO Batch Consumption Time: 0.05850
Total Iteration Time: 15.79872

Cumulative Model Updates: 64,473
Cumulative Timesteps: 1,075,409,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523,466.02516
Policy Entropy: 1.02678
Value Function Loss: 1.49843

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.16639
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.09091

Collected Steps per Second: 3,781.91759
Overall Steps per Second: 3,105.12522

Timestep Collection Time: 13.23350
Timestep Consumption Time: 2.88437
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 16.11787

Cumulative Model Updates: 64,476
Cumulative Timesteps: 1,075,459,684

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1075459684...
Checkpoint 1075459684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665,709.32100
Policy Entropy: 1.03309
Value Function Loss: 1.52785

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.18139
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.09380

Collected Steps per Second: 3,863.10886
Overall Steps per Second: 3,171.82390

Timestep Collection Time: 12.94916
Timestep Consumption Time: 2.82221
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 15.77137

Cumulative Model Updates: 64,479
Cumulative Timesteps: 1,075,509,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269,489.30003
Policy Entropy: 1.01560
Value Function Loss: 1.54452

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.09094

Collected Steps per Second: 3,902.94265
Overall Steps per Second: 3,219.44682

Timestep Collection Time: 12.81085
Timestep Consumption Time: 2.71977
PPO Batch Consumption Time: 0.06772
Total Iteration Time: 15.53062

Cumulative Model Updates: 64,482
Cumulative Timesteps: 1,075,559,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1075559708...
Checkpoint 1075559708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,002,520.74220
Policy Entropy: 1.01005
Value Function Loss: 1.49666

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.18619
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.10257

Collected Steps per Second: 3,788.94108
Overall Steps per Second: 3,159.55285

Timestep Collection Time: 13.20686
Timestep Consumption Time: 2.63083
PPO Batch Consumption Time: 0.05175
Total Iteration Time: 15.83768

Cumulative Model Updates: 64,485
Cumulative Timesteps: 1,075,609,748

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034,858.01403
Policy Entropy: 1.03243
Value Function Loss: 1.43572

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.12085

Collected Steps per Second: 3,870.41213
Overall Steps per Second: 3,203.94075

Timestep Collection Time: 12.92472
Timestep Consumption Time: 2.68855
PPO Batch Consumption Time: 0.06036
Total Iteration Time: 15.61327

Cumulative Model Updates: 64,488
Cumulative Timesteps: 1,075,659,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1075659772...
Checkpoint 1075659772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,601,945.76900
Policy Entropy: 1.03938
Value Function Loss: 1.37472

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.06911
Value Function Update Magnitude: 0.12240

Collected Steps per Second: 3,733.87164
Overall Steps per Second: 3,120.99545

Timestep Collection Time: 13.39360
Timestep Consumption Time: 2.63013
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 16.02373

Cumulative Model Updates: 64,491
Cumulative Timesteps: 1,075,709,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086,358.94139
Policy Entropy: 1.03389
Value Function Loss: 1.35867

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.07607
Value Function Update Magnitude: 0.12304

Collected Steps per Second: 3,775.66318
Overall Steps per Second: 3,195.33379

Timestep Collection Time: 13.25171
Timestep Consumption Time: 2.40675
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 15.65846

Cumulative Model Updates: 64,494
Cumulative Timesteps: 1,075,759,816

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1075759816...
Checkpoint 1075759816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371,192.83277
Policy Entropy: 1.02644
Value Function Loss: 1.42033

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.07224
Value Function Update Magnitude: 0.12799

Collected Steps per Second: 3,713.97741
Overall Steps per Second: 3,139.82326

Timestep Collection Time: 13.46750
Timestep Consumption Time: 2.46269
PPO Batch Consumption Time: 0.06444
Total Iteration Time: 15.93020

Cumulative Model Updates: 64,497
Cumulative Timesteps: 1,075,809,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,932.30467
Policy Entropy: 1.01833
Value Function Loss: 1.39717

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.17543
Policy Update Magnitude: 0.06819
Value Function Update Magnitude: 0.12683

Collected Steps per Second: 3,788.43683
Overall Steps per Second: 3,146.84208

Timestep Collection Time: 13.20914
Timestep Consumption Time: 2.69315
PPO Batch Consumption Time: 0.06027
Total Iteration Time: 15.90229

Cumulative Model Updates: 64,500
Cumulative Timesteps: 1,075,859,876

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1075859876...
Checkpoint 1075859876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,667,840.92665
Policy Entropy: 1.03352
Value Function Loss: 1.43203

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 3,849.42268
Overall Steps per Second: 3,170.17745

Timestep Collection Time: 12.99312
Timestep Consumption Time: 2.78392
PPO Batch Consumption Time: 0.05969
Total Iteration Time: 15.77703

Cumulative Model Updates: 64,503
Cumulative Timesteps: 1,075,909,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468,955.39250
Policy Entropy: 1.03924
Value Function Loss: 1.37277

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.10065

Collected Steps per Second: 3,834.33249
Overall Steps per Second: 3,161.80249

Timestep Collection Time: 13.04321
Timestep Consumption Time: 2.77435
PPO Batch Consumption Time: 0.05192
Total Iteration Time: 15.81756

Cumulative Model Updates: 64,506
Cumulative Timesteps: 1,075,959,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1075959904...
Checkpoint 1075959904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,038,428.67277
Policy Entropy: 1.03568
Value Function Loss: 1.39663

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.09731

Collected Steps per Second: 3,963.03502
Overall Steps per Second: 3,251.10654

Timestep Collection Time: 12.62114
Timestep Consumption Time: 2.76378
PPO Batch Consumption Time: 0.06081
Total Iteration Time: 15.38492

Cumulative Model Updates: 64,509
Cumulative Timesteps: 1,076,009,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526,132.58922
Policy Entropy: 1.02863
Value Function Loss: 1.33506

Mean KL Divergence: 0.02410
SB3 Clip Fraction: 0.18443
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.09026

Collected Steps per Second: 3,789.19130
Overall Steps per Second: 3,146.57886

Timestep Collection Time: 13.20915
Timestep Consumption Time: 2.69765
PPO Batch Consumption Time: 0.05358
Total Iteration Time: 15.90680

Cumulative Model Updates: 64,512
Cumulative Timesteps: 1,076,059,974

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1076059974...
Checkpoint 1076059974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692,647.23975
Policy Entropy: 1.03791
Value Function Loss: 1.37173

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.08388

Collected Steps per Second: 3,903.99207
Overall Steps per Second: 3,237.16440

Timestep Collection Time: 12.81509
Timestep Consumption Time: 2.63980
PPO Batch Consumption Time: 0.04766
Total Iteration Time: 15.45488

Cumulative Model Updates: 64,515
Cumulative Timesteps: 1,076,110,004

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278,375.51062
Policy Entropy: 1.04101
Value Function Loss: 1.39770

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 3,802.78809
Overall Steps per Second: 3,193.95372

Timestep Collection Time: 13.15614
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 15.66397

Cumulative Model Updates: 64,518
Cumulative Timesteps: 1,076,160,034

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1076160034...
Checkpoint 1076160034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653,927.58977
Policy Entropy: 1.02987
Value Function Loss: 1.43564

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.11568

Collected Steps per Second: 3,687.05217
Overall Steps per Second: 3,093.00232

Timestep Collection Time: 13.57019
Timestep Consumption Time: 2.60633
PPO Batch Consumption Time: 0.04982
Total Iteration Time: 16.17652

Cumulative Model Updates: 64,521
Cumulative Timesteps: 1,076,210,068

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,952,821.60063
Policy Entropy: 1.02195
Value Function Loss: 1.38946

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.18511
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.13919

Collected Steps per Second: 3,753.66793
Overall Steps per Second: 3,122.14335

Timestep Collection Time: 13.33203
Timestep Consumption Time: 2.69671
PPO Batch Consumption Time: 0.06294
Total Iteration Time: 16.02873

Cumulative Model Updates: 64,524
Cumulative Timesteps: 1,076,260,112

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1076260112...
Checkpoint 1076260112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,372,568.19767
Policy Entropy: 1.03005
Value Function Loss: 1.41117

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.13767

Collected Steps per Second: 3,831.91837
Overall Steps per Second: 3,241.02745

Timestep Collection Time: 13.05560
Timestep Consumption Time: 2.38024
PPO Batch Consumption Time: 0.04928
Total Iteration Time: 15.43585

Cumulative Model Updates: 64,527
Cumulative Timesteps: 1,076,310,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846,843.09213
Policy Entropy: 1.03165
Value Function Loss: 1.42564

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.11908
Policy Update Magnitude: 0.07010
Value Function Update Magnitude: 0.12174

Collected Steps per Second: 3,681.18050
Overall Steps per Second: 3,117.55782

Timestep Collection Time: 13.58586
Timestep Consumption Time: 2.45618
PPO Batch Consumption Time: 0.06097
Total Iteration Time: 16.04204

Cumulative Model Updates: 64,530
Cumulative Timesteps: 1,076,360,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1076360152...
Checkpoint 1076360152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578,336.28000
Policy Entropy: 1.02727
Value Function Loss: 1.45077

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.07605
Value Function Update Magnitude: 0.10354

Collected Steps per Second: 3,787.91788
Overall Steps per Second: 3,125.42251

Timestep Collection Time: 13.20673
Timestep Consumption Time: 2.79943
PPO Batch Consumption Time: 0.05215
Total Iteration Time: 16.00616

Cumulative Model Updates: 64,533
Cumulative Timesteps: 1,076,410,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,758,490.12614
Policy Entropy: 1.02711
Value Function Loss: 1.40021

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.07433
Value Function Update Magnitude: 0.10001

Collected Steps per Second: 3,924.44238
Overall Steps per Second: 3,225.96577

Timestep Collection Time: 12.75086
Timestep Consumption Time: 2.76078
PPO Batch Consumption Time: 0.06492
Total Iteration Time: 15.51163

Cumulative Model Updates: 64,536
Cumulative Timesteps: 1,076,460,218

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1076460218...
Checkpoint 1076460218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,413,847.27613
Policy Entropy: 1.01999
Value Function Loss: 1.31985

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.15040
Policy Update Magnitude: 0.07351
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 3,698.43062
Overall Steps per Second: 3,080.81753

Timestep Collection Time: 13.53006
Timestep Consumption Time: 2.71238
PPO Batch Consumption Time: 0.05419
Total Iteration Time: 16.24244

Cumulative Model Updates: 64,539
Cumulative Timesteps: 1,076,510,258

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,404,403.27122
Policy Entropy: 1.03690
Value Function Loss: 1.41420

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.10388

Collected Steps per Second: 3,761.32972
Overall Steps per Second: 3,127.59915

Timestep Collection Time: 13.30487
Timestep Consumption Time: 2.69590
PPO Batch Consumption Time: 0.06141
Total Iteration Time: 16.00077

Cumulative Model Updates: 64,542
Cumulative Timesteps: 1,076,560,302

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1076560302...
Checkpoint 1076560302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614,083.64830
Policy Entropy: 1.04163
Value Function Loss: 1.39019

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.15920
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.09727

Collected Steps per Second: 3,755.36935
Overall Steps per Second: 3,114.43438

Timestep Collection Time: 13.32545
Timestep Consumption Time: 2.74231
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 16.06777

Cumulative Model Updates: 64,545
Cumulative Timesteps: 1,076,610,344

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523,210.11961
Policy Entropy: 1.02407
Value Function Loss: 1.43928

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.15936
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.08958

Collected Steps per Second: 3,615.82445
Overall Steps per Second: 3,028.28732

Timestep Collection Time: 13.83861
Timestep Consumption Time: 2.68492
PPO Batch Consumption Time: 0.05966
Total Iteration Time: 16.52353

Cumulative Model Updates: 64,548
Cumulative Timesteps: 1,076,660,382

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1076660382...
Checkpoint 1076660382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642,883.60822
Policy Entropy: 1.01533
Value Function Loss: 1.33864

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.16829
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.08909

Collected Steps per Second: 3,782.97733
Overall Steps per Second: 3,140.61621

Timestep Collection Time: 13.22450
Timestep Consumption Time: 2.70485
PPO Batch Consumption Time: 0.04908
Total Iteration Time: 15.92936

Cumulative Model Updates: 64,551
Cumulative Timesteps: 1,076,710,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492,801.55497
Policy Entropy: 1.03268
Value Function Loss: 1.34616

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.10729

Collected Steps per Second: 3,738.53708
Overall Steps per Second: 3,137.15682

Timestep Collection Time: 13.38010
Timestep Consumption Time: 2.56491
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 15.94501

Cumulative Model Updates: 64,554
Cumulative Timesteps: 1,076,760,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1076760432...
Checkpoint 1076760432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844,523.31156
Policy Entropy: 1.04356
Value Function Loss: 1.41970

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.15781
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.11013

Collected Steps per Second: 3,926.00668
Overall Steps per Second: 3,265.73559

Timestep Collection Time: 12.74629
Timestep Consumption Time: 2.57706
PPO Batch Consumption Time: 0.05353
Total Iteration Time: 15.32335

Cumulative Model Updates: 64,557
Cumulative Timesteps: 1,076,810,474

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756,369.37874
Policy Entropy: 1.03118
Value Function Loss: 1.49484

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.11240

Collected Steps per Second: 4,086.15967
Overall Steps per Second: 3,418.64822

Timestep Collection Time: 12.23790
Timestep Consumption Time: 2.38952
PPO Batch Consumption Time: 0.05088
Total Iteration Time: 14.62742

Cumulative Model Updates: 64,560
Cumulative Timesteps: 1,076,860,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1076860480...
Checkpoint 1076860480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,413,853.68273
Policy Entropy: 1.02123
Value Function Loss: 1.52202

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.12106

Collected Steps per Second: 4,136.60096
Overall Steps per Second: 3,480.91124

Timestep Collection Time: 12.09544
Timestep Consumption Time: 2.27838
PPO Batch Consumption Time: 0.04694
Total Iteration Time: 14.37382

Cumulative Model Updates: 64,563
Cumulative Timesteps: 1,076,910,514

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258,882.40377
Policy Entropy: 1.03845
Value Function Loss: 1.38674

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.10498

Collected Steps per Second: 4,044.84103
Overall Steps per Second: 3,341.07686

Timestep Collection Time: 12.36291
Timestep Consumption Time: 2.60412
PPO Batch Consumption Time: 0.04805
Total Iteration Time: 14.96703

Cumulative Model Updates: 64,566
Cumulative Timesteps: 1,076,960,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1076960520...
Checkpoint 1076960520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481,298.24496
Policy Entropy: 1.04650
Value Function Loss: 1.32952

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.15401
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.09271

Collected Steps per Second: 3,842.48352
Overall Steps per Second: 3,179.41677

Timestep Collection Time: 13.02023
Timestep Consumption Time: 2.71537
PPO Batch Consumption Time: 0.05235
Total Iteration Time: 15.73559

Cumulative Model Updates: 64,569
Cumulative Timesteps: 1,077,010,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640,765.46404
Policy Entropy: 1.03613
Value Function Loss: 1.32932

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.10095

Collected Steps per Second: 3,670.89456
Overall Steps per Second: 3,074.95353

Timestep Collection Time: 13.62938
Timestep Consumption Time: 2.64144
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 16.27081

Cumulative Model Updates: 64,572
Cumulative Timesteps: 1,077,060,582

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1077060582...
Checkpoint 1077060582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999,670.04185
Policy Entropy: 1.01688
Value Function Loss: 1.40812

Mean KL Divergence: 0.03090
SB3 Clip Fraction: 0.20909
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.10534

Collected Steps per Second: 3,904.08128
Overall Steps per Second: 3,215.97939

Timestep Collection Time: 12.82043
Timestep Consumption Time: 2.74310
PPO Batch Consumption Time: 0.06941
Total Iteration Time: 15.56353

Cumulative Model Updates: 64,575
Cumulative Timesteps: 1,077,110,634

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422,451.97056
Policy Entropy: 1.04044
Value Function Loss: 1.41308

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.16918
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.10151

Collected Steps per Second: 3,646.67881
Overall Steps per Second: 3,023.85854

Timestep Collection Time: 13.71495
Timestep Consumption Time: 2.82485
PPO Batch Consumption Time: 0.05146
Total Iteration Time: 16.53979

Cumulative Model Updates: 64,578
Cumulative Timesteps: 1,077,160,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1077160648...
Checkpoint 1077160648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412,357.10229
Policy Entropy: 1.01883
Value Function Loss: 1.40572

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.16391
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.09326

Collected Steps per Second: 3,950.65347
Overall Steps per Second: 3,254.94115

Timestep Collection Time: 12.65765
Timestep Consumption Time: 2.70545
PPO Batch Consumption Time: 0.05443
Total Iteration Time: 15.36310

Cumulative Model Updates: 64,581
Cumulative Timesteps: 1,077,210,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828,016.29132
Policy Entropy: 1.02023
Value Function Loss: 1.38330

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.16597
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.09092

Collected Steps per Second: 3,675.43817
Overall Steps per Second: 3,099.01259

Timestep Collection Time: 13.60709
Timestep Consumption Time: 2.53096
PPO Batch Consumption Time: 0.06683
Total Iteration Time: 16.13804

Cumulative Model Updates: 64,584
Cumulative Timesteps: 1,077,260,666

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1077260666...
Checkpoint 1077260666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400,313.76582
Policy Entropy: 1.03190
Value Function Loss: 1.42286

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.15833
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.09228

Collected Steps per Second: 3,738.98330
Overall Steps per Second: 3,111.46479

Timestep Collection Time: 13.37797
Timestep Consumption Time: 2.69806
PPO Batch Consumption Time: 0.06134
Total Iteration Time: 16.07603

Cumulative Model Updates: 64,587
Cumulative Timesteps: 1,077,310,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,984,162.93852
Policy Entropy: 1.04132
Value Function Loss: 1.43114

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.17223
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.09069

Collected Steps per Second: 3,988.46869
Overall Steps per Second: 3,227.95916

Timestep Collection Time: 12.53815
Timestep Consumption Time: 2.95400
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 15.49214

Cumulative Model Updates: 64,590
Cumulative Timesteps: 1,077,360,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1077360694...
Checkpoint 1077360694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007,442.79757
Policy Entropy: 1.01851
Value Function Loss: 1.41311

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.09142

Collected Steps per Second: 3,761.28267
Overall Steps per Second: 3,132.37746

Timestep Collection Time: 13.30610
Timestep Consumption Time: 2.67154
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 15.97764

Cumulative Model Updates: 64,593
Cumulative Timesteps: 1,077,410,742

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879,636.37631
Policy Entropy: 1.04405
Value Function Loss: 1.37362

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.18341
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.09239

Collected Steps per Second: 3,942.31064
Overall Steps per Second: 3,242.13048

Timestep Collection Time: 12.68495
Timestep Consumption Time: 2.73948
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 15.42443

Cumulative Model Updates: 64,596
Cumulative Timesteps: 1,077,460,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1077460750...
Checkpoint 1077460750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,054,903.30155
Policy Entropy: 1.03467
Value Function Loss: 1.36850

Mean KL Divergence: 0.02659
SB3 Clip Fraction: 0.18300
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 3,688.02582
Overall Steps per Second: 3,113.50499

Timestep Collection Time: 13.56932
Timestep Consumption Time: 2.50388
PPO Batch Consumption Time: 0.05401
Total Iteration Time: 16.07320

Cumulative Model Updates: 64,599
Cumulative Timesteps: 1,077,510,794

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622,036.24716
Policy Entropy: 1.03970
Value Function Loss: 1.39595

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.07454
Value Function Update Magnitude: 0.10897

Collected Steps per Second: 3,699.95368
Overall Steps per Second: 3,159.30190

Timestep Collection Time: 13.51476
Timestep Consumption Time: 2.31278
PPO Batch Consumption Time: 0.06203
Total Iteration Time: 15.82755

Cumulative Model Updates: 64,602
Cumulative Timesteps: 1,077,560,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1077560798...
Checkpoint 1077560798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,612,944.23836
Policy Entropy: 1.03799
Value Function Loss: 1.31988

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.07329
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 3,534.81386
Overall Steps per Second: 3,006.01763

Timestep Collection Time: 14.15181
Timestep Consumption Time: 2.48948
PPO Batch Consumption Time: 0.05372
Total Iteration Time: 16.64129

Cumulative Model Updates: 64,605
Cumulative Timesteps: 1,077,610,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491,497.25988
Policy Entropy: 1.04433
Value Function Loss: 1.26758

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.07534
Value Function Update Magnitude: 0.08851

Collected Steps per Second: 3,739.23575
Overall Steps per Second: 3,138.96381

Timestep Collection Time: 13.38348
Timestep Consumption Time: 2.55936
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 15.94284

Cumulative Model Updates: 64,608
Cumulative Timesteps: 1,077,660,866

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1077660866...
Checkpoint 1077660866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502,391.43472
Policy Entropy: 1.03964
Value Function Loss: 1.25427

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.08057
Value Function Update Magnitude: 0.08893

Collected Steps per Second: 3,860.81316
Overall Steps per Second: 3,204.53876

Timestep Collection Time: 12.95789
Timestep Consumption Time: 2.65372
PPO Batch Consumption Time: 0.04701
Total Iteration Time: 15.61161

Cumulative Model Updates: 64,611
Cumulative Timesteps: 1,077,710,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616,100.17812
Policy Entropy: 1.04327
Value Function Loss: 1.28274

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.07847
Value Function Update Magnitude: 0.09884

Collected Steps per Second: 3,907.45178
Overall Steps per Second: 3,232.10899

Timestep Collection Time: 12.79811
Timestep Consumption Time: 2.67414
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 15.47225

Cumulative Model Updates: 64,614
Cumulative Timesteps: 1,077,760,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1077760902...
Checkpoint 1077760902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,129,455.70804
Policy Entropy: 1.04346
Value Function Loss: 1.37161

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.08023
Value Function Update Magnitude: 0.08849

Collected Steps per Second: 3,700.09983
Overall Steps per Second: 3,062.94264

Timestep Collection Time: 13.51477
Timestep Consumption Time: 2.81136
PPO Batch Consumption Time: 0.05363
Total Iteration Time: 16.32613

Cumulative Model Updates: 64,617
Cumulative Timesteps: 1,077,810,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945,891.68517
Policy Entropy: 1.04813
Value Function Loss: 1.35081

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.07461
Value Function Update Magnitude: 0.09655

Collected Steps per Second: 3,761.09653
Overall Steps per Second: 3,144.15286

Timestep Collection Time: 13.29665
Timestep Consumption Time: 2.60906
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 15.90572

Cumulative Model Updates: 64,620
Cumulative Timesteps: 1,077,860,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1077860918...
Checkpoint 1077860918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613,969.29082
Policy Entropy: 1.04694
Value Function Loss: 1.40880

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.07203
Value Function Update Magnitude: 0.10624

Collected Steps per Second: 3,820.68818
Overall Steps per Second: 3,179.31889

Timestep Collection Time: 13.09345
Timestep Consumption Time: 2.64136
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 15.73482

Cumulative Model Updates: 64,623
Cumulative Timesteps: 1,077,910,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109,474.62876
Policy Entropy: 1.05434
Value Function Loss: 1.38600

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.06985
Value Function Update Magnitude: 0.09709

Collected Steps per Second: 3,730.22683
Overall Steps per Second: 3,108.75706

Timestep Collection Time: 13.40562
Timestep Consumption Time: 2.67991
PPO Batch Consumption Time: 0.05170
Total Iteration Time: 16.08553

Cumulative Model Updates: 64,626
Cumulative Timesteps: 1,077,960,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1077960950...
Checkpoint 1077960950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775,497.83607
Policy Entropy: 1.04832
Value Function Loss: 1.42539

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.07286
Value Function Update Magnitude: 0.09407

Collected Steps per Second: 3,713.50076
Overall Steps per Second: 3,128.89620

Timestep Collection Time: 13.46546
Timestep Consumption Time: 2.51589
PPO Batch Consumption Time: 0.05909
Total Iteration Time: 15.98135

Cumulative Model Updates: 64,629
Cumulative Timesteps: 1,078,010,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212,141.77886
Policy Entropy: 1.04785
Value Function Loss: 1.45761

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.09516

Collected Steps per Second: 3,770.03251
Overall Steps per Second: 3,157.95248

Timestep Collection Time: 13.27628
Timestep Consumption Time: 2.57323
PPO Batch Consumption Time: 0.06146
Total Iteration Time: 15.84951

Cumulative Model Updates: 64,632
Cumulative Timesteps: 1,078,061,006

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1078061006...
Checkpoint 1078061006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069,495.98319
Policy Entropy: 1.03332
Value Function Loss: 1.45607

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.16608
Policy Update Magnitude: 0.07015
Value Function Update Magnitude: 0.09087

Collected Steps per Second: 3,551.71593
Overall Steps per Second: 3,048.54040

Timestep Collection Time: 14.08896
Timestep Consumption Time: 2.32545
PPO Batch Consumption Time: 0.05042
Total Iteration Time: 16.41441

Cumulative Model Updates: 64,635
Cumulative Timesteps: 1,078,111,046

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,856,223.49738
Policy Entropy: 1.04284
Value Function Loss: 1.45202

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.14927
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.09696

Collected Steps per Second: 3,762.60579
Overall Steps per Second: 3,185.95030

Timestep Collection Time: 13.29185
Timestep Consumption Time: 2.40582
PPO Batch Consumption Time: 0.05430
Total Iteration Time: 15.69767

Cumulative Model Updates: 64,638
Cumulative Timesteps: 1,078,161,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1078161058...
Checkpoint 1078161058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317,750.61899
Policy Entropy: 1.04973
Value Function Loss: 1.45384

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.17155
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.10084

Collected Steps per Second: 3,995.90538
Overall Steps per Second: 3,343.17981

Timestep Collection Time: 12.51631
Timestep Consumption Time: 2.44370
PPO Batch Consumption Time: 0.05288
Total Iteration Time: 14.96001

Cumulative Model Updates: 64,641
Cumulative Timesteps: 1,078,211,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531,634.39282
Policy Entropy: 1.03358
Value Function Loss: 1.46809

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.09694

Collected Steps per Second: 4,177.81362
Overall Steps per Second: 3,422.16908

Timestep Collection Time: 11.97229
Timestep Consumption Time: 2.64359
PPO Batch Consumption Time: 0.04925
Total Iteration Time: 14.61588

Cumulative Model Updates: 64,644
Cumulative Timesteps: 1,078,261,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1078261090...
Checkpoint 1078261090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652,989.37017
Policy Entropy: 1.02337
Value Function Loss: 1.52213

Mean KL Divergence: 0.03055
SB3 Clip Fraction: 0.20262
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.09775

Collected Steps per Second: 4,076.82111
Overall Steps per Second: 3,289.08319

Timestep Collection Time: 12.27329
Timestep Consumption Time: 2.93946
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 15.21275

Cumulative Model Updates: 64,647
Cumulative Timesteps: 1,078,311,126

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541,654.23699
Policy Entropy: 1.06095
Value Function Loss: 1.46399

Mean KL Divergence: 0.02522
SB3 Clip Fraction: 0.17539
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.10141

Collected Steps per Second: 4,128.73331
Overall Steps per Second: 3,385.63345

Timestep Collection Time: 12.11025
Timestep Consumption Time: 2.65803
PPO Batch Consumption Time: 0.05940
Total Iteration Time: 14.76829

Cumulative Model Updates: 64,650
Cumulative Timesteps: 1,078,361,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1078361126...
Checkpoint 1078361126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,987,380.79826
Policy Entropy: 1.03860
Value Function Loss: 1.45644

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.16353
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.10209

Collected Steps per Second: 4,044.01781
Overall Steps per Second: 3,330.30102

Timestep Collection Time: 12.37334
Timestep Consumption Time: 2.65173
PPO Batch Consumption Time: 0.05134
Total Iteration Time: 15.02507

Cumulative Model Updates: 64,653
Cumulative Timesteps: 1,078,411,164

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666,219.56202
Policy Entropy: 1.06991
Value Function Loss: 1.38741

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.17085
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.10537

Collected Steps per Second: 3,994.42192
Overall Steps per Second: 3,286.57842

Timestep Collection Time: 12.52697
Timestep Consumption Time: 2.69798
PPO Batch Consumption Time: 0.05265
Total Iteration Time: 15.22495

Cumulative Model Updates: 64,656
Cumulative Timesteps: 1,078,461,202

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1078461202...
Checkpoint 1078461202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060,522.46573
Policy Entropy: 1.06293
Value Function Loss: 1.41504

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.15316
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.09943

Collected Steps per Second: 3,868.28176
Overall Steps per Second: 3,186.63967

Timestep Collection Time: 12.93804
Timestep Consumption Time: 2.76753
PPO Batch Consumption Time: 0.05856
Total Iteration Time: 15.70557

Cumulative Model Updates: 64,659
Cumulative Timesteps: 1,078,511,250

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181,448.10030
Policy Entropy: 1.05371
Value Function Loss: 1.39445

Mean KL Divergence: 0.02860
SB3 Clip Fraction: 0.17352
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.10555

Collected Steps per Second: 3,778.40705
Overall Steps per Second: 3,138.04405

Timestep Collection Time: 13.23891
Timestep Consumption Time: 2.70159
PPO Batch Consumption Time: 0.05806
Total Iteration Time: 15.94050

Cumulative Model Updates: 64,662
Cumulative Timesteps: 1,078,561,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1078561272...
Checkpoint 1078561272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328,839.71433
Policy Entropy: 1.04570
Value Function Loss: 1.42961

Mean KL Divergence: 0.02907
SB3 Clip Fraction: 0.19244
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.11174

Collected Steps per Second: 3,821.46728
Overall Steps per Second: 3,181.14257

Timestep Collection Time: 13.09078
Timestep Consumption Time: 2.63501
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 15.72580

Cumulative Model Updates: 64,665
Cumulative Timesteps: 1,078,611,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900,298.16707
Policy Entropy: 1.06404
Value Function Loss: 1.38864

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 3,764.10465
Overall Steps per Second: 3,146.41754

Timestep Collection Time: 13.28656
Timestep Consumption Time: 2.60834
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 15.89490

Cumulative Model Updates: 64,668
Cumulative Timesteps: 1,078,661,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1078661310...
Checkpoint 1078661310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927,650.79824
Policy Entropy: 1.07405
Value Function Loss: 1.40043

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.10409

Collected Steps per Second: 3,788.09681
Overall Steps per Second: 3,167.04096

Timestep Collection Time: 13.20610
Timestep Consumption Time: 2.58971
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 15.79582

Cumulative Model Updates: 64,671
Cumulative Timesteps: 1,078,711,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837,058.16599
Policy Entropy: 1.04887
Value Function Loss: 1.40896

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.09991

Collected Steps per Second: 3,972.83769
Overall Steps per Second: 3,287.05382

Timestep Collection Time: 12.59452
Timestep Consumption Time: 2.62762
PPO Batch Consumption Time: 0.05076
Total Iteration Time: 15.22214

Cumulative Model Updates: 64,674
Cumulative Timesteps: 1,078,761,372

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1078761372...
Checkpoint 1078761372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607,146.48865
Policy Entropy: 1.04715
Value Function Loss: 1.48991

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.09771

Collected Steps per Second: 3,855.85973
Overall Steps per Second: 3,255.31533

Timestep Collection Time: 12.97350
Timestep Consumption Time: 2.39337
PPO Batch Consumption Time: 0.05881
Total Iteration Time: 15.36687

Cumulative Model Updates: 64,677
Cumulative Timesteps: 1,078,811,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576,613.10833
Policy Entropy: 1.05597
Value Function Loss: 1.47449

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.11512

Collected Steps per Second: 3,797.44900
Overall Steps per Second: 3,205.71146

Timestep Collection Time: 13.16989
Timestep Consumption Time: 2.43101
PPO Batch Consumption Time: 0.05295
Total Iteration Time: 15.60090

Cumulative Model Updates: 64,680
Cumulative Timesteps: 1,078,861,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1078861408...
Checkpoint 1078861408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689,422.08262
Policy Entropy: 1.06051
Value Function Loss: 1.48736

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.06629
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 3,783.31465
Overall Steps per Second: 3,214.83618

Timestep Collection Time: 13.22438
Timestep Consumption Time: 2.33846
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 15.56285

Cumulative Model Updates: 64,683
Cumulative Timesteps: 1,078,911,440

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650,198.52230
Policy Entropy: 1.06249
Value Function Loss: 1.45617

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.11249

Collected Steps per Second: 3,891.29508
Overall Steps per Second: 3,209.85901

Timestep Collection Time: 12.85896
Timestep Consumption Time: 2.72989
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 15.58885

Cumulative Model Updates: 64,686
Cumulative Timesteps: 1,078,961,478

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1078961478...
Checkpoint 1078961478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,543,423.25608
Policy Entropy: 1.05064
Value Function Loss: 1.42974

Mean KL Divergence: 0.02585
SB3 Clip Fraction: 0.15166
Policy Update Magnitude: 0.08025
Value Function Update Magnitude: 0.10593

Collected Steps per Second: 3,793.70531
Overall Steps per Second: 3,161.18874

Timestep Collection Time: 13.18131
Timestep Consumption Time: 2.63742
PPO Batch Consumption Time: 0.05268
Total Iteration Time: 15.81873

Cumulative Model Updates: 64,689
Cumulative Timesteps: 1,079,011,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344,875.41927
Policy Entropy: 1.06332
Value Function Loss: 1.45963

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.09416

Collected Steps per Second: 3,894.34427
Overall Steps per Second: 3,156.45205

Timestep Collection Time: 12.84735
Timestep Consumption Time: 3.00336
PPO Batch Consumption Time: 0.05387
Total Iteration Time: 15.85071

Cumulative Model Updates: 64,692
Cumulative Timesteps: 1,079,061,516

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1079061516...
Checkpoint 1079061516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456,053.41767
Policy Entropy: 1.07699
Value Function Loss: 1.39834

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.06949
Value Function Update Magnitude: 0.09244

Collected Steps per Second: 3,832.24115
Overall Steps per Second: 3,131.73437

Timestep Collection Time: 13.05659
Timestep Consumption Time: 2.92050
PPO Batch Consumption Time: 0.05291
Total Iteration Time: 15.97709

Cumulative Model Updates: 64,695
Cumulative Timesteps: 1,079,111,552

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544,171.26353
Policy Entropy: 1.07369
Value Function Loss: 1.41381

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.07794
Value Function Update Magnitude: 0.09267

Collected Steps per Second: 3,847.80843
Overall Steps per Second: 3,201.14884

Timestep Collection Time: 13.00377
Timestep Consumption Time: 2.62687
PPO Batch Consumption Time: 0.04699
Total Iteration Time: 15.63064

Cumulative Model Updates: 64,698
Cumulative Timesteps: 1,079,161,588

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1079161588...
Checkpoint 1079161588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239,212.46662
Policy Entropy: 1.06884
Value Function Loss: 1.38068

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.08080
Value Function Update Magnitude: 0.09519

Collected Steps per Second: 3,825.96094
Overall Steps per Second: 3,202.64964

Timestep Collection Time: 13.07175
Timestep Consumption Time: 2.54407
PPO Batch Consumption Time: 0.05880
Total Iteration Time: 15.61582

Cumulative Model Updates: 64,701
Cumulative Timesteps: 1,079,211,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840,910.92483
Policy Entropy: 1.06516
Value Function Loss: 1.39429

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.14118
Policy Update Magnitude: 0.07430
Value Function Update Magnitude: 0.08879

Collected Steps per Second: 3,714.55442
Overall Steps per Second: 3,104.70223

Timestep Collection Time: 13.46110
Timestep Consumption Time: 2.64415
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 16.10525

Cumulative Model Updates: 64,704
Cumulative Timesteps: 1,079,261,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1079261602...
Checkpoint 1079261602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491,549.50422
Policy Entropy: 1.07307
Value Function Loss: 1.40247

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.06799
Value Function Update Magnitude: 0.09230

Collected Steps per Second: 3,928.69976
Overall Steps per Second: 3,262.55156

Timestep Collection Time: 12.72686
Timestep Consumption Time: 2.59857
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 15.32543

Cumulative Model Updates: 64,707
Cumulative Timesteps: 1,079,311,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976,920.18023
Policy Entropy: 1.07363
Value Function Loss: 1.36860

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.09427

Collected Steps per Second: 3,747.09582
Overall Steps per Second: 3,212.23658

Timestep Collection Time: 13.34367
Timestep Consumption Time: 2.22181
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 15.56548

Cumulative Model Updates: 64,710
Cumulative Timesteps: 1,079,361,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1079361602...
Checkpoint 1079361602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320,437.99215
Policy Entropy: 1.07677
Value Function Loss: 1.40736

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.07308
Value Function Update Magnitude: 0.10881

Collected Steps per Second: 3,781.03296
Overall Steps per Second: 3,185.68542

Timestep Collection Time: 13.22443
Timestep Consumption Time: 2.47141
PPO Batch Consumption Time: 0.04759
Total Iteration Time: 15.69584

Cumulative Model Updates: 64,713
Cumulative Timesteps: 1,079,411,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427,555.29161
Policy Entropy: 1.07424
Value Function Loss: 1.43635

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.07227
Value Function Update Magnitude: 0.10443

Collected Steps per Second: 3,689.80847
Overall Steps per Second: 3,117.73288

Timestep Collection Time: 13.56114
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.05996
Total Iteration Time: 16.04948

Cumulative Model Updates: 64,716
Cumulative Timesteps: 1,079,461,642

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1079461642...
Checkpoint 1079461642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,957,197.05324
Policy Entropy: 1.08828
Value Function Loss: 1.41413

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.06300
Value Function Update Magnitude: 0.10682

Collected Steps per Second: 3,678.47711
Overall Steps per Second: 3,117.04188

Timestep Collection Time: 13.60346
Timestep Consumption Time: 2.45023
PPO Batch Consumption Time: 0.05267
Total Iteration Time: 16.05368

Cumulative Model Updates: 64,719
Cumulative Timesteps: 1,079,511,682

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303,757.35083
Policy Entropy: 1.08706
Value Function Loss: 1.39869

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.12294

Collected Steps per Second: 3,840.63610
Overall Steps per Second: 3,190.50539

Timestep Collection Time: 13.02441
Timestep Consumption Time: 2.65399
PPO Batch Consumption Time: 0.05898
Total Iteration Time: 15.67839

Cumulative Model Updates: 64,722
Cumulative Timesteps: 1,079,561,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1079561704...
Checkpoint 1079561704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382,332.76613
Policy Entropy: 1.07630
Value Function Loss: 1.33689

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.13011

Collected Steps per Second: 3,724.37560
Overall Steps per Second: 3,097.64822

Timestep Collection Time: 13.43312
Timestep Consumption Time: 2.71784
PPO Batch Consumption Time: 0.06012
Total Iteration Time: 16.15096

Cumulative Model Updates: 64,725
Cumulative Timesteps: 1,079,611,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742,923.81952
Policy Entropy: 1.07043
Value Function Loss: 1.47094

Mean KL Divergence: 0.02634
SB3 Clip Fraction: 0.17318
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.13429

Collected Steps per Second: 4,014.24113
Overall Steps per Second: 3,309.85953

Timestep Collection Time: 12.45864
Timestep Consumption Time: 2.65136
PPO Batch Consumption Time: 0.05964
Total Iteration Time: 15.11001

Cumulative Model Updates: 64,728
Cumulative Timesteps: 1,079,661,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1079661746...
Checkpoint 1079661746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260,744.82311
Policy Entropy: 1.08530
Value Function Loss: 1.47643

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.12198

Collected Steps per Second: 3,778.76084
Overall Steps per Second: 3,133.38516

Timestep Collection Time: 13.23397
Timestep Consumption Time: 2.72577
PPO Batch Consumption Time: 0.05793
Total Iteration Time: 15.95974

Cumulative Model Updates: 64,731
Cumulative Timesteps: 1,079,711,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,711,254.37948
Policy Entropy: 1.09838
Value Function Loss: 1.47976

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.11682

Collected Steps per Second: 3,917.64319
Overall Steps per Second: 3,208.93959

Timestep Collection Time: 12.76380
Timestep Consumption Time: 2.81892
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 15.58272

Cumulative Model Updates: 64,734
Cumulative Timesteps: 1,079,761,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1079761758...
Checkpoint 1079761758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,884,875.35809
Policy Entropy: 1.07674
Value Function Loss: 1.40221

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.06300
Value Function Update Magnitude: 0.10857

Collected Steps per Second: 4,017.45407
Overall Steps per Second: 3,305.38311

Timestep Collection Time: 12.45665
Timestep Consumption Time: 2.68351
PPO Batch Consumption Time: 0.05776
Total Iteration Time: 15.14015

Cumulative Model Updates: 64,737
Cumulative Timesteps: 1,079,811,802

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476,206.47498
Policy Entropy: 1.06015
Value Function Loss: 1.35675

Mean KL Divergence: 0.02905
SB3 Clip Fraction: 0.17192
Policy Update Magnitude: 0.06208
Value Function Update Magnitude: 0.09518

Collected Steps per Second: 4,007.01771
Overall Steps per Second: 3,306.13165

Timestep Collection Time: 12.48060
Timestep Consumption Time: 2.64584
PPO Batch Consumption Time: 0.05152
Total Iteration Time: 15.12644

Cumulative Model Updates: 64,740
Cumulative Timesteps: 1,079,861,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1079861812...
Checkpoint 1079861812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939,868.17316
Policy Entropy: 1.07174
Value Function Loss: 1.31130

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.08874

Collected Steps per Second: 4,012.70464
Overall Steps per Second: 3,315.74035

Timestep Collection Time: 12.46042
Timestep Consumption Time: 2.61916
PPO Batch Consumption Time: 0.05785
Total Iteration Time: 15.07959

Cumulative Model Updates: 64,743
Cumulative Timesteps: 1,079,911,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,873,243.03029
Policy Entropy: 1.08236
Value Function Loss: 1.26747

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14880
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.08985

Collected Steps per Second: 3,951.83014
Overall Steps per Second: 3,313.13940

Timestep Collection Time: 12.65793
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.05062
Total Iteration Time: 15.09807

Cumulative Model Updates: 64,746
Cumulative Timesteps: 1,079,961,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1079961834...
Checkpoint 1079961834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817,321.13276
Policy Entropy: 1.06255
Value Function Loss: 1.27314

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.05783
Value Function Update Magnitude: 0.09662

Collected Steps per Second: 3,790.59365
Overall Steps per Second: 3,206.01565

Timestep Collection Time: 13.19741
Timestep Consumption Time: 2.40639
PPO Batch Consumption Time: 0.05194
Total Iteration Time: 15.60379

Cumulative Model Updates: 64,749
Cumulative Timesteps: 1,080,011,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580,760.86438
Policy Entropy: 1.07294
Value Function Loss: 1.34374

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.11930

Collected Steps per Second: 3,674.59155
Overall Steps per Second: 3,136.68483

Timestep Collection Time: 13.60968
Timestep Consumption Time: 2.33391
PPO Batch Consumption Time: 0.05223
Total Iteration Time: 15.94358

Cumulative Model Updates: 64,752
Cumulative Timesteps: 1,080,061,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1080061870...
Checkpoint 1080061870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,198,119.61564
Policy Entropy: 1.06835
Value Function Loss: 1.39660

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.06616
Value Function Update Magnitude: 0.13729

Collected Steps per Second: 3,925.27158
Overall Steps per Second: 3,228.95011

Timestep Collection Time: 12.74256
Timestep Consumption Time: 2.74793
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 15.49048

Cumulative Model Updates: 64,755
Cumulative Timesteps: 1,080,111,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616,757.77775
Policy Entropy: 1.07814
Value Function Loss: 1.44236

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.06845
Value Function Update Magnitude: 0.14644

Collected Steps per Second: 3,837.96898
Overall Steps per Second: 3,186.88907

Timestep Collection Time: 13.03137
Timestep Consumption Time: 2.66230
PPO Batch Consumption Time: 0.04980
Total Iteration Time: 15.69367

Cumulative Model Updates: 64,758
Cumulative Timesteps: 1,080,161,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1080161902...
Checkpoint 1080161902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283,058.59012
Policy Entropy: 1.07609
Value Function Loss: 1.43725

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.06917
Value Function Update Magnitude: 0.15255

Collected Steps per Second: 3,908.56171
Overall Steps per Second: 3,239.32706

Timestep Collection Time: 12.80318
Timestep Consumption Time: 2.64510
PPO Batch Consumption Time: 0.06133
Total Iteration Time: 15.44827

Cumulative Model Updates: 64,761
Cumulative Timesteps: 1,080,211,944

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650,537.49383
Policy Entropy: 1.08650
Value Function Loss: 1.37606

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.06783
Value Function Update Magnitude: 0.14886

Collected Steps per Second: 3,729.34773
Overall Steps per Second: 3,086.44420

Timestep Collection Time: 13.41414
Timestep Consumption Time: 2.79415
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 16.20830

Cumulative Model Updates: 64,764
Cumulative Timesteps: 1,080,261,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1080261970...
Checkpoint 1080261970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089,816.74198
Policy Entropy: 1.08239
Value Function Loss: 1.36999

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.13698

Collected Steps per Second: 3,958.62686
Overall Steps per Second: 3,260.38284

Timestep Collection Time: 12.64176
Timestep Consumption Time: 2.70736
PPO Batch Consumption Time: 0.06105
Total Iteration Time: 15.34912

Cumulative Model Updates: 64,767
Cumulative Timesteps: 1,080,312,014

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402,401.91781
Policy Entropy: 1.08676
Value Function Loss: 1.41810

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.07982
Value Function Update Magnitude: 0.11556

Collected Steps per Second: 3,819.58121
Overall Steps per Second: 3,172.02933

Timestep Collection Time: 13.09201
Timestep Consumption Time: 2.67266
PPO Batch Consumption Time: 0.05842
Total Iteration Time: 15.76467

Cumulative Model Updates: 64,770
Cumulative Timesteps: 1,080,362,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1080362020...
Checkpoint 1080362020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605,509.11294
Policy Entropy: 1.08330
Value Function Loss: 1.44170

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.08535
Value Function Update Magnitude: 0.10271

Collected Steps per Second: 3,667.96597
Overall Steps per Second: 3,083.33776

Timestep Collection Time: 13.64026
Timestep Consumption Time: 2.58631
PPO Batch Consumption Time: 0.06103
Total Iteration Time: 16.22657

Cumulative Model Updates: 64,773
Cumulative Timesteps: 1,080,412,052

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779,421.96760
Policy Entropy: 1.08396
Value Function Loss: 1.39968

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.08726
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 3,772.88539
Overall Steps per Second: 3,142.67235

Timestep Collection Time: 13.26147
Timestep Consumption Time: 2.65938
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 15.92085

Cumulative Model Updates: 64,776
Cumulative Timesteps: 1,080,462,086

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1080462086...
Checkpoint 1080462086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683,154.35735
Policy Entropy: 1.06543
Value Function Loss: 1.39837

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.15777
Policy Update Magnitude: 0.08220
Value Function Update Magnitude: 0.11726

Collected Steps per Second: 3,766.83831
Overall Steps per Second: 3,171.47267

Timestep Collection Time: 13.27479
Timestep Consumption Time: 2.49201
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 15.76681

Cumulative Model Updates: 64,779
Cumulative Timesteps: 1,080,512,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292,092.41637
Policy Entropy: 1.08485
Value Function Loss: 1.42139

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.15610
Policy Update Magnitude: 0.07046
Value Function Update Magnitude: 0.11825

Collected Steps per Second: 3,705.35761
Overall Steps per Second: 3,134.66668

Timestep Collection Time: 13.49937
Timestep Consumption Time: 2.45767
PPO Batch Consumption Time: 0.06055
Total Iteration Time: 15.95704

Cumulative Model Updates: 64,782
Cumulative Timesteps: 1,080,562,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1080562110...
Checkpoint 1080562110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509,389.13784
Policy Entropy: 1.08724
Value Function Loss: 1.47452

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.06932
Value Function Update Magnitude: 0.10554

Collected Steps per Second: 3,776.34178
Overall Steps per Second: 3,185.63214

Timestep Collection Time: 13.25251
Timestep Consumption Time: 2.45740
PPO Batch Consumption Time: 0.05230
Total Iteration Time: 15.70991

Cumulative Model Updates: 64,785
Cumulative Timesteps: 1,080,612,156

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247,491.51451
Policy Entropy: 1.06675
Value Function Loss: 1.42423

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.06438
Value Function Update Magnitude: 0.09890

Collected Steps per Second: 3,657.27095
Overall Steps per Second: 3,096.07222

Timestep Collection Time: 13.67686
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.04827
Total Iteration Time: 16.15595

Cumulative Model Updates: 64,788
Cumulative Timesteps: 1,080,662,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1080662176...
Checkpoint 1080662176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486,382.09997
Policy Entropy: 1.05936
Value Function Loss: 1.43840

Mean KL Divergence: 0.02445
SB3 Clip Fraction: 0.16849
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.10105

Collected Steps per Second: 3,806.98688
Overall Steps per Second: 3,184.26749

Timestep Collection Time: 13.14058
Timestep Consumption Time: 2.56979
PPO Batch Consumption Time: 0.05875
Total Iteration Time: 15.71036

Cumulative Model Updates: 64,791
Cumulative Timesteps: 1,080,712,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734,769.58007
Policy Entropy: 1.06637
Value Function Loss: 1.39687

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.10350

Collected Steps per Second: 3,708.34305
Overall Steps per Second: 3,084.09256

Timestep Collection Time: 13.49120
Timestep Consumption Time: 2.73075
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 16.22195

Cumulative Model Updates: 64,794
Cumulative Timesteps: 1,080,762,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1080762232...
Checkpoint 1080762232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494,247.74439
Policy Entropy: 1.08537
Value Function Loss: 1.38657

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.09840

Collected Steps per Second: 3,809.07074
Overall Steps per Second: 3,131.69729

Timestep Collection Time: 13.13129
Timestep Consumption Time: 2.84024
PPO Batch Consumption Time: 0.05198
Total Iteration Time: 15.97153

Cumulative Model Updates: 64,797
Cumulative Timesteps: 1,080,812,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485,819.91644
Policy Entropy: 1.06088
Value Function Loss: 1.38538

Mean KL Divergence: 0.02695
SB3 Clip Fraction: 0.15871
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.10449

Collected Steps per Second: 3,844.03572
Overall Steps per Second: 3,137.96884

Timestep Collection Time: 13.00768
Timestep Consumption Time: 2.92683
PPO Batch Consumption Time: 0.04990
Total Iteration Time: 15.93451

Cumulative Model Updates: 64,800
Cumulative Timesteps: 1,080,862,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1080862252...
Checkpoint 1080862252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729,113.97224
Policy Entropy: 1.09445
Value Function Loss: 1.39973

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.12191

Collected Steps per Second: 4,013.35648
Overall Steps per Second: 3,272.11900

Timestep Collection Time: 12.46936
Timestep Consumption Time: 2.82470
PPO Batch Consumption Time: 0.05261
Total Iteration Time: 15.29406

Cumulative Model Updates: 64,803
Cumulative Timesteps: 1,080,912,296

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937,963.05128
Policy Entropy: 1.08282
Value Function Loss: 1.40230

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.11992

Collected Steps per Second: 3,982.72932
Overall Steps per Second: 3,286.65379

Timestep Collection Time: 12.56726
Timestep Consumption Time: 2.66160
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 15.22886

Cumulative Model Updates: 64,806
Cumulative Timesteps: 1,080,962,348

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1080962348...
Checkpoint 1080962348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525,542.05875
Policy Entropy: 1.07480
Value Function Loss: 1.31593

Mean KL Divergence: 0.02595
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.06038
Value Function Update Magnitude: 0.09965

Collected Steps per Second: 3,992.69404
Overall Steps per Second: 3,292.07371

Timestep Collection Time: 12.53289
Timestep Consumption Time: 2.66725
PPO Batch Consumption Time: 0.05810
Total Iteration Time: 15.20015

Cumulative Model Updates: 64,809
Cumulative Timesteps: 1,081,012,388

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686,545.75321
Policy Entropy: 1.06523
Value Function Loss: 1.22901

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.17459
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.09883

Collected Steps per Second: 3,879.48153
Overall Steps per Second: 3,228.97104

Timestep Collection Time: 12.90018
Timestep Consumption Time: 2.59888
PPO Batch Consumption Time: 0.05428
Total Iteration Time: 15.49906

Cumulative Model Updates: 64,812
Cumulative Timesteps: 1,081,062,434

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1081062434...
Checkpoint 1081062434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107,178.36551
Policy Entropy: 1.07283
Value Function Loss: 1.24548

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.10099

Collected Steps per Second: 3,888.91890
Overall Steps per Second: 3,212.68499

Timestep Collection Time: 12.86116
Timestep Consumption Time: 2.70713
PPO Batch Consumption Time: 0.05298
Total Iteration Time: 15.56829

Cumulative Model Updates: 64,815
Cumulative Timesteps: 1,081,112,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687,516.57480
Policy Entropy: 1.08582
Value Function Loss: 1.38873

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 3,979.71567
Overall Steps per Second: 3,303.08457

Timestep Collection Time: 12.57075
Timestep Consumption Time: 2.57510
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 15.14584

Cumulative Model Updates: 64,818
Cumulative Timesteps: 1,081,162,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1081162478...
Checkpoint 1081162478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314,515.60620
Policy Entropy: 1.06686
Value Function Loss: 1.55037

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.11094

Collected Steps per Second: 3,788.49764
Overall Steps per Second: 3,191.74104

Timestep Collection Time: 13.21051
Timestep Consumption Time: 2.46996
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 15.68047

Cumulative Model Updates: 64,821
Cumulative Timesteps: 1,081,212,526

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670,226.73627
Policy Entropy: 1.08173
Value Function Loss: 1.57221

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.16617
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.14417

Collected Steps per Second: 3,565.07230
Overall Steps per Second: 3,006.02191

Timestep Collection Time: 14.03338
Timestep Consumption Time: 2.60988
PPO Batch Consumption Time: 0.07346
Total Iteration Time: 16.64326

Cumulative Model Updates: 64,824
Cumulative Timesteps: 1,081,262,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1081262556...
Checkpoint 1081262556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522,371.14040
Policy Entropy: 1.06968
Value Function Loss: 1.51570

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.16699
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.14147

Collected Steps per Second: 3,891.17798
Overall Steps per Second: 3,323.14803

Timestep Collection Time: 12.85575
Timestep Consumption Time: 2.19745
PPO Batch Consumption Time: 0.05100
Total Iteration Time: 15.05320

Cumulative Model Updates: 64,827
Cumulative Timesteps: 1,081,312,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633,812.36803
Policy Entropy: 1.06446
Value Function Loss: 1.41590

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.07308
Value Function Update Magnitude: 0.11976

Collected Steps per Second: 3,815.72144
Overall Steps per Second: 3,208.71555

Timestep Collection Time: 13.10578
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.05146
Total Iteration Time: 15.58505

Cumulative Model Updates: 64,830
Cumulative Timesteps: 1,081,362,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1081362588...
Checkpoint 1081362588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,451,638.91797
Policy Entropy: 1.04020
Value Function Loss: 1.36006

Mean KL Divergence: 0.04248
SB3 Clip Fraction: 0.23387
Policy Update Magnitude: 0.07238
Value Function Update Magnitude: 0.11894

Collected Steps per Second: 3,828.20732
Overall Steps per Second: 3,217.09810

Timestep Collection Time: 13.07035
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 15.55315

Cumulative Model Updates: 64,833
Cumulative Timesteps: 1,081,412,624

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739,575.85831
Policy Entropy: 1.06861
Value Function Loss: 1.32835

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.15015
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.11235

Collected Steps per Second: 3,814.05703
Overall Steps per Second: 3,194.75856

Timestep Collection Time: 13.11622
Timestep Consumption Time: 2.54256
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 15.65877

Cumulative Model Updates: 64,836
Cumulative Timesteps: 1,081,462,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1081462650...
Checkpoint 1081462650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488,468.51197
Policy Entropy: 1.04597
Value Function Loss: 1.28156

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.16597
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.11761

Collected Steps per Second: 3,700.59574
Overall Steps per Second: 3,076.87510

Timestep Collection Time: 13.52215
Timestep Consumption Time: 2.74111
PPO Batch Consumption Time: 0.05783
Total Iteration Time: 16.26325

Cumulative Model Updates: 64,839
Cumulative Timesteps: 1,081,512,690

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,530,304.62997
Policy Entropy: 1.04301
Value Function Loss: 1.29619

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.15881
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.12324

Collected Steps per Second: 3,869.37744
Overall Steps per Second: 3,199.34370

Timestep Collection Time: 12.92663
Timestep Consumption Time: 2.70720
PPO Batch Consumption Time: 0.05823
Total Iteration Time: 15.63383

Cumulative Model Updates: 64,842
Cumulative Timesteps: 1,081,562,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1081562708...
Checkpoint 1081562708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,281,276.88929
Policy Entropy: 1.04828
Value Function Loss: 1.27404

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.11210

Collected Steps per Second: 3,701.95325
Overall Steps per Second: 3,126.26561

Timestep Collection Time: 13.50908
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.05161
Total Iteration Time: 15.99672

Cumulative Model Updates: 64,845
Cumulative Timesteps: 1,081,612,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,666,530.62368
Policy Entropy: 1.06177
Value Function Loss: 1.35667

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.15638
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.10692

Collected Steps per Second: 4,007.95744
Overall Steps per Second: 3,297.60432

Timestep Collection Time: 12.47818
Timestep Consumption Time: 2.68799
PPO Batch Consumption Time: 0.06216
Total Iteration Time: 15.16616

Cumulative Model Updates: 64,848
Cumulative Timesteps: 1,081,662,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1081662730...
Checkpoint 1081662730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,902,444.86821
Policy Entropy: 1.04792
Value Function Loss: 1.37060

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.10055

Collected Steps per Second: 3,738.02449
Overall Steps per Second: 3,116.31458

Timestep Collection Time: 13.38193
Timestep Consumption Time: 2.66972
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 16.05165

Cumulative Model Updates: 64,851
Cumulative Timesteps: 1,081,712,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430,545.81413
Policy Entropy: 1.04225
Value Function Loss: 1.40730

Mean KL Divergence: 0.02316
SB3 Clip Fraction: 0.17921
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.10618

Collected Steps per Second: 4,050.86967
Overall Steps per Second: 3,322.05888

Timestep Collection Time: 12.34402
Timestep Consumption Time: 2.70810
PPO Batch Consumption Time: 0.04995
Total Iteration Time: 15.05211

Cumulative Model Updates: 64,854
Cumulative Timesteps: 1,081,762,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1081762756...
Checkpoint 1081762756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673,279.98590
Policy Entropy: 1.04963
Value Function Loss: 1.31351

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.10607

Collected Steps per Second: 3,733.27502
Overall Steps per Second: 3,136.08480

Timestep Collection Time: 13.39682
Timestep Consumption Time: 2.55109
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 15.94791

Cumulative Model Updates: 64,857
Cumulative Timesteps: 1,081,812,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928,695.45651
Policy Entropy: 1.06379
Value Function Loss: 1.25414

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.16438
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.10292

Collected Steps per Second: 3,969.39359
Overall Steps per Second: 3,329.80479

Timestep Collection Time: 12.60545
Timestep Consumption Time: 2.42125
PPO Batch Consumption Time: 0.05308
Total Iteration Time: 15.02671

Cumulative Model Updates: 64,860
Cumulative Timesteps: 1,081,862,806

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1081862806...
Checkpoint 1081862806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559,851.36382
Policy Entropy: 1.04295
Value Function Loss: 1.24884

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.06135
Value Function Update Magnitude: 0.09832

Collected Steps per Second: 3,733.93238
Overall Steps per Second: 3,151.27119

Timestep Collection Time: 13.39285
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.06460
Total Iteration Time: 15.86915

Cumulative Model Updates: 64,863
Cumulative Timesteps: 1,081,912,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078,019.13050
Policy Entropy: 1.04363
Value Function Loss: 1.32694

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.09490

Collected Steps per Second: 3,747.92251
Overall Steps per Second: 3,160.17222

Timestep Collection Time: 13.34339
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 15.82509

Cumulative Model Updates: 64,866
Cumulative Timesteps: 1,081,962,824

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1081962824...
Checkpoint 1081962824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682,177.46368
Policy Entropy: 1.04727
Value Function Loss: 1.34939

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.10622

Collected Steps per Second: 3,826.07738
Overall Steps per Second: 3,171.30634

Timestep Collection Time: 13.08024
Timestep Consumption Time: 2.70064
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 15.78088

Cumulative Model Updates: 64,869
Cumulative Timesteps: 1,082,012,870

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896,819.57835
Policy Entropy: 1.04440
Value Function Loss: 1.34454

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.11314

Collected Steps per Second: 3,784.19031
Overall Steps per Second: 3,141.58029

Timestep Collection Time: 13.22608
Timestep Consumption Time: 2.70539
PPO Batch Consumption Time: 0.05416
Total Iteration Time: 15.93147

Cumulative Model Updates: 64,872
Cumulative Timesteps: 1,082,062,920

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1082062920...
Checkpoint 1082062920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,784,532.85273
Policy Entropy: 1.03985
Value Function Loss: 1.35234

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.07714
Value Function Update Magnitude: 0.13162

Collected Steps per Second: 3,678.61114
Overall Steps per Second: 3,050.55031

Timestep Collection Time: 13.59752
Timestep Consumption Time: 2.79952
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 16.39704

Cumulative Model Updates: 64,875
Cumulative Timesteps: 1,082,112,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864,947.12094
Policy Entropy: 1.04072
Value Function Loss: 1.35871

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.07754
Value Function Update Magnitude: 0.13730

Collected Steps per Second: 3,806.59069
Overall Steps per Second: 3,187.90444

Timestep Collection Time: 13.14720
Timestep Consumption Time: 2.55152
PPO Batch Consumption Time: 0.05264
Total Iteration Time: 15.69871

Cumulative Model Updates: 64,878
Cumulative Timesteps: 1,082,162,986

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1082162986...
Checkpoint 1082162986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029,190.90034
Policy Entropy: 1.04130
Value Function Loss: 1.36520

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.07644
Value Function Update Magnitude: 0.13194

Collected Steps per Second: 3,712.66074
Overall Steps per Second: 3,086.48003

Timestep Collection Time: 13.47767
Timestep Consumption Time: 2.73433
PPO Batch Consumption Time: 0.05228
Total Iteration Time: 16.21200

Cumulative Model Updates: 64,881
Cumulative Timesteps: 1,082,213,024

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216,034.03951
Policy Entropy: 1.04409
Value Function Loss: 1.39909

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.07538
Value Function Update Magnitude: 0.13357

Collected Steps per Second: 3,859.72912
Overall Steps per Second: 3,211.41378

Timestep Collection Time: 12.95531
Timestep Consumption Time: 2.61540
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 15.57071

Cumulative Model Updates: 64,884
Cumulative Timesteps: 1,082,263,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1082263028...
Checkpoint 1082263028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514,987.70502
Policy Entropy: 1.05589
Value Function Loss: 1.43235

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.06864
Value Function Update Magnitude: 0.13205

Collected Steps per Second: 3,903.62113
Overall Steps per Second: 3,252.37483

Timestep Collection Time: 12.82040
Timestep Consumption Time: 2.56712
PPO Batch Consumption Time: 0.04612
Total Iteration Time: 15.38753

Cumulative Model Updates: 64,887
Cumulative Timesteps: 1,082,313,074

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530,922.32783
Policy Entropy: 1.06260
Value Function Loss: 1.51345

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.06833
Value Function Update Magnitude: 0.11566

Collected Steps per Second: 3,780.13920
Overall Steps per Second: 3,199.70313

Timestep Collection Time: 13.23073
Timestep Consumption Time: 2.40010
PPO Batch Consumption Time: 0.05925
Total Iteration Time: 15.63083

Cumulative Model Updates: 64,890
Cumulative Timesteps: 1,082,363,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1082363088...
Checkpoint 1082363088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845,025.77035
Policy Entropy: 1.06658
Value Function Loss: 1.42183

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.08119
Value Function Update Magnitude: 0.10801

Collected Steps per Second: 3,617.10556
Overall Steps per Second: 3,078.17408

Timestep Collection Time: 13.82929
Timestep Consumption Time: 2.42125
PPO Batch Consumption Time: 0.05902
Total Iteration Time: 16.25054

Cumulative Model Updates: 64,893
Cumulative Timesteps: 1,082,413,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214,198.69451
Policy Entropy: 1.06228
Value Function Loss: 1.45179

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.08071
Value Function Update Magnitude: 0.10949

Collected Steps per Second: 3,715.59464
Overall Steps per Second: 3,144.02610

Timestep Collection Time: 13.46702
Timestep Consumption Time: 2.44824
PPO Batch Consumption Time: 0.05342
Total Iteration Time: 15.91526

Cumulative Model Updates: 64,896
Cumulative Timesteps: 1,082,463,148

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1082463148...
Checkpoint 1082463148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040,046.54795
Policy Entropy: 1.06728
Value Function Loss: 1.40118

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.08395
Value Function Update Magnitude: 0.11206

Collected Steps per Second: 3,979.59354
Overall Steps per Second: 3,279.11958

Timestep Collection Time: 12.57365
Timestep Consumption Time: 2.68594
PPO Batch Consumption Time: 0.05201
Total Iteration Time: 15.25958

Cumulative Model Updates: 64,899
Cumulative Timesteps: 1,082,513,186

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424,330.73210
Policy Entropy: 1.06932
Value Function Loss: 1.42739

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.08751
Value Function Update Magnitude: 0.12818

Collected Steps per Second: 4,089.67487
Overall Steps per Second: 3,374.65776

Timestep Collection Time: 12.22640
Timestep Consumption Time: 2.59051
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 14.81691

Cumulative Model Updates: 64,902
Cumulative Timesteps: 1,082,563,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1082563188...
Checkpoint 1082563188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,906,275.55712
Policy Entropy: 1.06937
Value Function Loss: 1.29202

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.08743
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 3,909.26488
Overall Steps per Second: 3,223.31253

Timestep Collection Time: 12.79422
Timestep Consumption Time: 2.72274
PPO Batch Consumption Time: 0.06053
Total Iteration Time: 15.51696

Cumulative Model Updates: 64,905
Cumulative Timesteps: 1,082,613,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932,116.46844
Policy Entropy: 1.07143
Value Function Loss: 1.23130

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.09156
Value Function Update Magnitude: 0.12907

Collected Steps per Second: 3,763.03069
Overall Steps per Second: 3,133.19432

Timestep Collection Time: 13.29939
Timestep Consumption Time: 2.67345
PPO Batch Consumption Time: 0.06090
Total Iteration Time: 15.97284

Cumulative Model Updates: 64,908
Cumulative Timesteps: 1,082,663,250

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1082663250...
Checkpoint 1082663250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519,112.54810
Policy Entropy: 1.07115
Value Function Loss: 1.12495

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.08522
Value Function Update Magnitude: 0.12831

Collected Steps per Second: 3,809.57590
Overall Steps per Second: 3,169.60160

Timestep Collection Time: 13.12692
Timestep Consumption Time: 2.65046
PPO Batch Consumption Time: 0.05358
Total Iteration Time: 15.77738

Cumulative Model Updates: 64,911
Cumulative Timesteps: 1,082,713,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508,187.64529
Policy Entropy: 1.07373
Value Function Loss: 1.12111

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.07584
Value Function Update Magnitude: 0.11402

Collected Steps per Second: 3,653.36360
Overall Steps per Second: 3,036.48482

Timestep Collection Time: 13.68711
Timestep Consumption Time: 2.78061
PPO Batch Consumption Time: 0.05345
Total Iteration Time: 16.46773

Cumulative Model Updates: 64,914
Cumulative Timesteps: 1,082,763,262

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1082763262...
Checkpoint 1082763262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516,710.31659
Policy Entropy: 1.09177
Value Function Loss: 1.10895

Mean KL Divergence: 0.02529
SB3 Clip Fraction: 0.16613
Policy Update Magnitude: 0.06512
Value Function Update Magnitude: 0.09924

Collected Steps per Second: 3,663.41230
Overall Steps per Second: 3,077.04345

Timestep Collection Time: 13.65284
Timestep Consumption Time: 2.60172
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 16.25456

Cumulative Model Updates: 64,917
Cumulative Timesteps: 1,082,813,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918,083.65776
Policy Entropy: 1.08731
Value Function Loss: 1.10475

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.11122

Collected Steps per Second: 3,693.58277
Overall Steps per Second: 3,091.57186

Timestep Collection Time: 13.54782
Timestep Consumption Time: 2.63812
PPO Batch Consumption Time: 0.05354
Total Iteration Time: 16.18594

Cumulative Model Updates: 64,920
Cumulative Timesteps: 1,082,863,318

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1082863318...
Checkpoint 1082863318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,345,952.45257
Policy Entropy: 1.07723
Value Function Loss: 1.08640

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.14719
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.11579

Collected Steps per Second: 3,849.71791
Overall Steps per Second: 3,186.53458

Timestep Collection Time: 12.99887
Timestep Consumption Time: 2.70533
PPO Batch Consumption Time: 0.05005
Total Iteration Time: 15.70421

Cumulative Model Updates: 64,923
Cumulative Timesteps: 1,082,913,360

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956,980.77683
Policy Entropy: 1.06386
Value Function Loss: 1.04014

Mean KL Divergence: 0.02913
SB3 Clip Fraction: 0.19473
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.11890

Collected Steps per Second: 3,773.63744
Overall Steps per Second: 3,164.62997

Timestep Collection Time: 13.26042
Timestep Consumption Time: 2.55186
PPO Batch Consumption Time: 0.05934
Total Iteration Time: 15.81228

Cumulative Model Updates: 64,926
Cumulative Timesteps: 1,082,963,400

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1082963400...
Checkpoint 1082963400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635,490.85644
Policy Entropy: 1.07647
Value Function Loss: 1.11323

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.11735

Collected Steps per Second: 3,864.56176
Overall Steps per Second: 3,280.95773

Timestep Collection Time: 12.94636
Timestep Consumption Time: 2.30285
PPO Batch Consumption Time: 0.04880
Total Iteration Time: 15.24921

Cumulative Model Updates: 64,929
Cumulative Timesteps: 1,083,013,432

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506,801.15927
Policy Entropy: 1.07950
Value Function Loss: 1.12185

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.06772
Value Function Update Magnitude: 0.11233

Collected Steps per Second: 3,611.74498
Overall Steps per Second: 3,042.98890

Timestep Collection Time: 13.84926
Timestep Consumption Time: 2.58852
PPO Batch Consumption Time: 0.05169
Total Iteration Time: 16.43779

Cumulative Model Updates: 64,932
Cumulative Timesteps: 1,083,063,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1083063452...
Checkpoint 1083063452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856,820.95702
Policy Entropy: 1.07371
Value Function Loss: 1.11807

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.06809
Value Function Update Magnitude: 0.10930

Collected Steps per Second: 3,807.78560
Overall Steps per Second: 3,207.65983

Timestep Collection Time: 13.13204
Timestep Consumption Time: 2.45689
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 15.58893

Cumulative Model Updates: 64,935
Cumulative Timesteps: 1,083,113,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,984,377.25707
Policy Entropy: 1.06957
Value Function Loss: 1.06514

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.07274
Value Function Update Magnitude: 0.10130

Collected Steps per Second: 3,757.18540
Overall Steps per Second: 3,148.67921

Timestep Collection Time: 13.30837
Timestep Consumption Time: 2.57194
PPO Batch Consumption Time: 0.06233
Total Iteration Time: 15.88031

Cumulative Model Updates: 64,938
Cumulative Timesteps: 1,083,163,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1083163458...
Checkpoint 1083163458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845,154.48995
Policy Entropy: 1.05492
Value Function Loss: 1.07896

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.15189
Policy Update Magnitude: 0.06885
Value Function Update Magnitude: 0.09936

Collected Steps per Second: 3,809.73941
Overall Steps per Second: 3,170.25167

Timestep Collection Time: 13.12636
Timestep Consumption Time: 2.64778
PPO Batch Consumption Time: 0.05102
Total Iteration Time: 15.77414

Cumulative Model Updates: 64,941
Cumulative Timesteps: 1,083,213,466

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,214,666.63843
Policy Entropy: 1.07276
Value Function Loss: 1.06178

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14759
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.09408

Collected Steps per Second: 3,920.96449
Overall Steps per Second: 3,231.78842

Timestep Collection Time: 12.75656
Timestep Consumption Time: 2.72032
PPO Batch Consumption Time: 0.05341
Total Iteration Time: 15.47688

Cumulative Model Updates: 64,944
Cumulative Timesteps: 1,083,263,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1083263484...
Checkpoint 1083263484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650,621.95007
Policy Entropy: 1.07104
Value Function Loss: 1.07364

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.09716

Collected Steps per Second: 4,018.59770
Overall Steps per Second: 3,288.08210

Timestep Collection Time: 12.45459
Timestep Consumption Time: 2.76705
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 15.22164

Cumulative Model Updates: 64,947
Cumulative Timesteps: 1,083,313,534

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,996,277.72830
Policy Entropy: 1.05896
Value Function Loss: 1.07401

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.15044
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.10091

Collected Steps per Second: 4,050.20381
Overall Steps per Second: 3,313.47918

Timestep Collection Time: 12.34950
Timestep Consumption Time: 2.74581
PPO Batch Consumption Time: 0.05121
Total Iteration Time: 15.09531

Cumulative Model Updates: 64,950
Cumulative Timesteps: 1,083,363,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1083363552...
Checkpoint 1083363552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472,814.26620
Policy Entropy: 1.06078
Value Function Loss: 1.03544

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.09700

Collected Steps per Second: 4,149.02940
Overall Steps per Second: 3,423.16667

Timestep Collection Time: 12.05872
Timestep Consumption Time: 2.55698
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 14.61571

Cumulative Model Updates: 64,953
Cumulative Timesteps: 1,083,413,584

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,859,267.34741
Policy Entropy: 1.07503
Value Function Loss: 1.04571

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.08761

Collected Steps per Second: 3,748.61548
Overall Steps per Second: 3,123.50290

Timestep Collection Time: 13.34519
Timestep Consumption Time: 2.67080
PPO Batch Consumption Time: 0.06202
Total Iteration Time: 16.01599

Cumulative Model Updates: 64,956
Cumulative Timesteps: 1,083,463,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1083463610...
Checkpoint 1083463610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523,323.05053
Policy Entropy: 1.08409
Value Function Loss: 1.01481

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.09167

Collected Steps per Second: 3,788.90645
Overall Steps per Second: 3,153.63114

Timestep Collection Time: 13.19748
Timestep Consumption Time: 2.65853
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 15.85601

Cumulative Model Updates: 64,959
Cumulative Timesteps: 1,083,513,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471,755.32013
Policy Entropy: 1.06446
Value Function Loss: 1.07470

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.14769
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.09088

Collected Steps per Second: 3,922.78708
Overall Steps per Second: 3,227.90168

Timestep Collection Time: 12.75522
Timestep Consumption Time: 2.74587
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 15.50109

Cumulative Model Updates: 64,962
Cumulative Timesteps: 1,083,563,650

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1083563650...
Checkpoint 1083563650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878,656.31548
Policy Entropy: 1.08297
Value Function Loss: 1.05188

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.16181
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.08892

Collected Steps per Second: 3,815.14351
Overall Steps per Second: 3,155.47581

Timestep Collection Time: 13.11772
Timestep Consumption Time: 2.74232
PPO Batch Consumption Time: 0.06308
Total Iteration Time: 15.86005

Cumulative Model Updates: 64,965
Cumulative Timesteps: 1,083,613,696

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,949,819.21845
Policy Entropy: 1.08020
Value Function Loss: 1.09521

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.10831

Collected Steps per Second: 3,769.03726
Overall Steps per Second: 3,150.85565

Timestep Collection Time: 13.27819
Timestep Consumption Time: 2.60511
PPO Batch Consumption Time: 0.05755
Total Iteration Time: 15.88330

Cumulative Model Updates: 64,968
Cumulative Timesteps: 1,083,663,742

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1083663742...
Checkpoint 1083663742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638,928.64732
Policy Entropy: 1.05784
Value Function Loss: 1.07732

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.15904
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.10939

Collected Steps per Second: 3,732.72267
Overall Steps per Second: 3,173.16607

Timestep Collection Time: 13.40094
Timestep Consumption Time: 2.36312
PPO Batch Consumption Time: 0.04883
Total Iteration Time: 15.76407

Cumulative Model Updates: 64,971
Cumulative Timesteps: 1,083,713,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,256,248.49829
Policy Entropy: 1.05696
Value Function Loss: 1.10902

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.15652
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.09479

Collected Steps per Second: 3,822.30481
Overall Steps per Second: 3,247.21250

Timestep Collection Time: 13.08582
Timestep Consumption Time: 2.31754
PPO Batch Consumption Time: 0.05071
Total Iteration Time: 15.40337

Cumulative Model Updates: 64,974
Cumulative Timesteps: 1,083,763,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1083763782...
Checkpoint 1083763782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,234,587.31574
Policy Entropy: 1.06480
Value Function Loss: 1.13194

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.09563

Collected Steps per Second: 3,840.43683
Overall Steps per Second: 3,194.41401

Timestep Collection Time: 13.02925
Timestep Consumption Time: 2.63497
PPO Batch Consumption Time: 0.05311
Total Iteration Time: 15.66422

Cumulative Model Updates: 64,977
Cumulative Timesteps: 1,083,813,820

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198,469.33724
Policy Entropy: 1.06643
Value Function Loss: 1.18616

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.15915
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.08692

Collected Steps per Second: 3,826.92542
Overall Steps per Second: 3,204.53342

Timestep Collection Time: 13.07211
Timestep Consumption Time: 2.53890
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 15.61101

Cumulative Model Updates: 64,980
Cumulative Timesteps: 1,083,863,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1083863846...
Checkpoint 1083863846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687,342.08638
Policy Entropy: 1.04347
Value Function Loss: 1.16334

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.15040
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.08408

Collected Steps per Second: 3,869.75444
Overall Steps per Second: 3,154.03563

Timestep Collection Time: 12.92433
Timestep Consumption Time: 2.93281
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 15.85714

Cumulative Model Updates: 64,983
Cumulative Timesteps: 1,083,913,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358,736.45503
Policy Entropy: 1.06572
Value Function Loss: 1.12532

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.16082
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.08233

Collected Steps per Second: 3,831.26786
Overall Steps per Second: 3,148.33688

Timestep Collection Time: 13.06043
Timestep Consumption Time: 2.83304
PPO Batch Consumption Time: 0.06294
Total Iteration Time: 15.89347

Cumulative Model Updates: 64,986
Cumulative Timesteps: 1,083,963,898

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1083963898...
Checkpoint 1083963898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948,670.97984
Policy Entropy: 1.06991
Value Function Loss: 1.07722

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 3,755.59756
Overall Steps per Second: 3,081.20203

Timestep Collection Time: 13.32624
Timestep Consumption Time: 2.91677
PPO Batch Consumption Time: 0.05219
Total Iteration Time: 16.24301

Cumulative Model Updates: 64,989
Cumulative Timesteps: 1,084,013,946

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499,527.72083
Policy Entropy: 1.05579
Value Function Loss: 1.07859

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.16153
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.08307

Collected Steps per Second: 3,730.92089
Overall Steps per Second: 3,100.52673

Timestep Collection Time: 13.40366
Timestep Consumption Time: 2.72521
PPO Batch Consumption Time: 0.06052
Total Iteration Time: 16.12887

Cumulative Model Updates: 64,992
Cumulative Timesteps: 1,084,063,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1084063954...
Checkpoint 1084063954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894,149.49741
Policy Entropy: 1.04147
Value Function Loss: 1.09930

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.18117
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.09491

Collected Steps per Second: 3,655.91128
Overall Steps per Second: 3,028.10509

Timestep Collection Time: 13.68852
Timestep Consumption Time: 2.83799
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 16.52651

Cumulative Model Updates: 64,995
Cumulative Timesteps: 1,084,113,998

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264,007.12331
Policy Entropy: 1.04451
Value Function Loss: 1.13269

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.10957

Collected Steps per Second: 3,838.69045
Overall Steps per Second: 3,174.97896

Timestep Collection Time: 13.03413
Timestep Consumption Time: 2.72471
PPO Batch Consumption Time: 0.06077
Total Iteration Time: 15.75884

Cumulative Model Updates: 64,998
Cumulative Timesteps: 1,084,164,032

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1084164032...
Checkpoint 1084164032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212,922.22752
Policy Entropy: 1.05884
Value Function Loss: 1.15711

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.11927

Collected Steps per Second: 3,680.88127
Overall Steps per Second: 3,116.09303

Timestep Collection Time: 13.58859
Timestep Consumption Time: 2.46292
PPO Batch Consumption Time: 0.05439
Total Iteration Time: 16.05151

Cumulative Model Updates: 65,001
Cumulative Timesteps: 1,084,214,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787,310.66621
Policy Entropy: 1.04922
Value Function Loss: 1.13414

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.13866

Collected Steps per Second: 3,580.96782
Overall Steps per Second: 3,042.32452

Timestep Collection Time: 13.96550
Timestep Consumption Time: 2.47259
PPO Batch Consumption Time: 0.06044
Total Iteration Time: 16.43809

Cumulative Model Updates: 65,004
Cumulative Timesteps: 1,084,264,060

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1084264060...
Checkpoint 1084264060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421,740.80357
Policy Entropy: 1.04151
Value Function Loss: 1.11345

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.16736
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.13337

Collected Steps per Second: 3,581.97690
Overall Steps per Second: 3,038.43290

Timestep Collection Time: 13.96715
Timestep Consumption Time: 2.49858
PPO Batch Consumption Time: 0.06199
Total Iteration Time: 16.46572

Cumulative Model Updates: 65,007
Cumulative Timesteps: 1,084,314,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298,331.82019
Policy Entropy: 1.05772
Value Function Loss: 1.16514

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.13482

Collected Steps per Second: 3,701.40962
Overall Steps per Second: 3,085.39827

Timestep Collection Time: 13.52188
Timestep Consumption Time: 2.69969
PPO Batch Consumption Time: 0.06022
Total Iteration Time: 16.22157

Cumulative Model Updates: 65,010
Cumulative Timesteps: 1,084,364,140

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1084364140...
Checkpoint 1084364140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529,682.51280
Policy Entropy: 1.06182
Value Function Loss: 1.20817

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.15747
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.12724

Collected Steps per Second: 3,813.16161
Overall Steps per Second: 3,143.55007

Timestep Collection Time: 13.11248
Timestep Consumption Time: 2.79311
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 15.90558

Cumulative Model Updates: 65,013
Cumulative Timesteps: 1,084,414,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588,571.42005
Policy Entropy: 1.04997
Value Function Loss: 1.27775

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.11362

Collected Steps per Second: 3,726.43764
Overall Steps per Second: 3,145.69117

Timestep Collection Time: 13.42515
Timestep Consumption Time: 2.47850
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 15.90366

Cumulative Model Updates: 65,016
Cumulative Timesteps: 1,084,464,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1084464168...
Checkpoint 1084464168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536,414.30083
Policy Entropy: 1.03937
Value Function Loss: 1.25339

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.17579
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.10539

Collected Steps per Second: 3,817.17327
Overall Steps per Second: 3,159.95461

Timestep Collection Time: 13.10394
Timestep Consumption Time: 2.72540
PPO Batch Consumption Time: 0.06020
Total Iteration Time: 15.82934

Cumulative Model Updates: 65,019
Cumulative Timesteps: 1,084,514,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932,180.35348
Policy Entropy: 1.05527
Value Function Loss: 1.19175

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 3,718.16618
Overall Steps per Second: 3,104.81337

Timestep Collection Time: 13.45771
Timestep Consumption Time: 2.65856
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 16.11627

Cumulative Model Updates: 65,022
Cumulative Timesteps: 1,084,564,226

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1084564226...
Checkpoint 1084564226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402,199.84387
Policy Entropy: 1.05642
Value Function Loss: 1.10400

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.06395
Value Function Update Magnitude: 0.10362

Collected Steps per Second: 3,797.29185
Overall Steps per Second: 3,147.00816

Timestep Collection Time: 13.17729
Timestep Consumption Time: 2.72290
PPO Batch Consumption Time: 0.06177
Total Iteration Time: 15.90018

Cumulative Model Updates: 65,025
Cumulative Timesteps: 1,084,614,264

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210,873.41023
Policy Entropy: 1.04398
Value Function Loss: 1.06008

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.10532

Collected Steps per Second: 3,821.63391
Overall Steps per Second: 3,209.56697

Timestep Collection Time: 13.09597
Timestep Consumption Time: 2.49741
PPO Batch Consumption Time: 0.06829
Total Iteration Time: 15.59338

Cumulative Model Updates: 65,028
Cumulative Timesteps: 1,084,664,312

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1084664312...
Checkpoint 1084664312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273,032.82445
Policy Entropy: 1.02829
Value Function Loss: 1.08832

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.17234
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.09618

Collected Steps per Second: 3,829.79594
Overall Steps per Second: 3,179.94725

Timestep Collection Time: 13.06127
Timestep Consumption Time: 2.66918
PPO Batch Consumption Time: 0.05826
Total Iteration Time: 15.73045

Cumulative Model Updates: 65,031
Cumulative Timesteps: 1,084,714,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023,371.49735
Policy Entropy: 1.04370
Value Function Loss: 1.14395

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.14558
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.09101

Collected Steps per Second: 3,841.14439
Overall Steps per Second: 3,155.07650

Timestep Collection Time: 13.01800
Timestep Consumption Time: 2.83075
PPO Batch Consumption Time: 0.05376
Total Iteration Time: 15.84874

Cumulative Model Updates: 65,034
Cumulative Timesteps: 1,084,764,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1084764338...
Checkpoint 1084764338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199,969.33139
Policy Entropy: 1.05548
Value Function Loss: 1.16487

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.17066
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.08195

Collected Steps per Second: 3,881.07193
Overall Steps per Second: 3,250.14759

Timestep Collection Time: 12.88974
Timestep Consumption Time: 2.50218
PPO Batch Consumption Time: 0.05017
Total Iteration Time: 15.39192

Cumulative Model Updates: 65,037
Cumulative Timesteps: 1,084,814,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,378,922.58622
Policy Entropy: 1.04292
Value Function Loss: 1.16889

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.07679

Collected Steps per Second: 3,676.08407
Overall Steps per Second: 3,030.59065

Timestep Collection Time: 13.61231
Timestep Consumption Time: 2.89932
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 16.51163

Cumulative Model Updates: 65,040
Cumulative Timesteps: 1,084,864,404

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1084864404...
Checkpoint 1084864404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460,039.49163
Policy Entropy: 1.06061
Value Function Loss: 1.18533

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.17599
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.07228

Collected Steps per Second: 3,713.26395
Overall Steps per Second: 3,045.87174

Timestep Collection Time: 13.47548
Timestep Consumption Time: 2.95266
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 16.42814

Cumulative Model Updates: 65,043
Cumulative Timesteps: 1,084,914,442

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241,141.21127
Policy Entropy: 1.05588
Value Function Loss: 1.20971

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.16836
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.07303

Collected Steps per Second: 3,683.14832
Overall Steps per Second: 3,174.82645

Timestep Collection Time: 13.58240
Timestep Consumption Time: 2.17468
PPO Batch Consumption Time: 0.04681
Total Iteration Time: 15.75708

Cumulative Model Updates: 65,046
Cumulative Timesteps: 1,084,964,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1084964468...
Checkpoint 1084964468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870,965.09193
Policy Entropy: 1.04473
Value Function Loss: 1.29339

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.07751

Collected Steps per Second: 3,855.41214
Overall Steps per Second: 3,168.17470

Timestep Collection Time: 12.97760
Timestep Consumption Time: 2.81509
PPO Batch Consumption Time: 0.04932
Total Iteration Time: 15.79269

Cumulative Model Updates: 65,049
Cumulative Timesteps: 1,085,014,502

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,344,132.06647
Policy Entropy: 1.03093
Value Function Loss: 1.26631

Mean KL Divergence: 0.02987
SB3 Clip Fraction: 0.19264
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.08044

Collected Steps per Second: 3,714.80911
Overall Steps per Second: 3,067.63612

Timestep Collection Time: 13.46018
Timestep Consumption Time: 2.83967
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 16.29985

Cumulative Model Updates: 65,052
Cumulative Timesteps: 1,085,064,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1085064504...
Checkpoint 1085064504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485,978.63871
Policy Entropy: 1.04144
Value Function Loss: 1.33138

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.11069

Collected Steps per Second: 3,825.29627
Overall Steps per Second: 3,169.74315

Timestep Collection Time: 13.08395
Timestep Consumption Time: 2.70597
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 15.78992

Cumulative Model Updates: 65,055
Cumulative Timesteps: 1,085,114,554

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265,882.86234
Policy Entropy: 1.03974
Value Function Loss: 1.29695

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.12422

Collected Steps per Second: 4,057.13154
Overall Steps per Second: 3,309.39704

Timestep Collection Time: 12.33532
Timestep Consumption Time: 2.78708
PPO Batch Consumption Time: 0.06426
Total Iteration Time: 15.12239

Cumulative Model Updates: 65,058
Cumulative Timesteps: 1,085,164,600

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1085164600...
Checkpoint 1085164600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495,360.27749
Policy Entropy: 1.02599
Value Function Loss: 1.36908

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.07008
Value Function Update Magnitude: 0.13432

Collected Steps per Second: 3,831.38357
Overall Steps per Second: 3,184.81293

Timestep Collection Time: 13.06212
Timestep Consumption Time: 2.65183
PPO Batch Consumption Time: 0.05403
Total Iteration Time: 15.71395

Cumulative Model Updates: 65,061
Cumulative Timesteps: 1,085,214,646

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706,317.40995
Policy Entropy: 1.04359
Value Function Loss: 1.29010

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.12513

Collected Steps per Second: 3,845.90213
Overall Steps per Second: 3,174.79528

Timestep Collection Time: 13.00605
Timestep Consumption Time: 2.74930
PPO Batch Consumption Time: 0.05139
Total Iteration Time: 15.75535

Cumulative Model Updates: 65,064
Cumulative Timesteps: 1,085,264,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1085264666...
Checkpoint 1085264666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983,964.65112
Policy Entropy: 1.03704
Value Function Loss: 1.23760

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.11544

Collected Steps per Second: 3,701.65847
Overall Steps per Second: 3,119.63226

Timestep Collection Time: 13.51124
Timestep Consumption Time: 2.52078
PPO Batch Consumption Time: 0.05764
Total Iteration Time: 16.03202

Cumulative Model Updates: 65,067
Cumulative Timesteps: 1,085,314,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888,451.38046
Policy Entropy: 1.05203
Value Function Loss: 1.22400

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.06399
Value Function Update Magnitude: 0.11168

Collected Steps per Second: 3,937.74224
Overall Steps per Second: 3,267.65126

Timestep Collection Time: 12.70373
Timestep Consumption Time: 2.60513
PPO Batch Consumption Time: 0.06053
Total Iteration Time: 15.30886

Cumulative Model Updates: 65,070
Cumulative Timesteps: 1,085,364,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1085364704...
Checkpoint 1085364704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429,172.39837
Policy Entropy: 1.04916
Value Function Loss: 1.20737

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.06335
Value Function Update Magnitude: 0.11932

Collected Steps per Second: 3,750.99331
Overall Steps per Second: 3,115.28611

Timestep Collection Time: 13.33034
Timestep Consumption Time: 2.72020
PPO Batch Consumption Time: 0.05816
Total Iteration Time: 16.05053

Cumulative Model Updates: 65,073
Cumulative Timesteps: 1,085,414,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569,687.53146
Policy Entropy: 1.06232
Value Function Loss: 1.18676

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.06994
Value Function Update Magnitude: 0.12866

Collected Steps per Second: 3,921.76628
Overall Steps per Second: 3,278.75851

Timestep Collection Time: 12.74936
Timestep Consumption Time: 2.50032
PPO Batch Consumption Time: 0.05919
Total Iteration Time: 15.24967

Cumulative Model Updates: 65,076
Cumulative Timesteps: 1,085,464,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1085464706...
Checkpoint 1085464706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724,928.58130
Policy Entropy: 1.06021
Value Function Loss: 1.13406

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.08075
Value Function Update Magnitude: 0.11595

Collected Steps per Second: 3,680.74580
Overall Steps per Second: 3,131.19251

Timestep Collection Time: 13.59453
Timestep Consumption Time: 2.38597
PPO Batch Consumption Time: 0.05079
Total Iteration Time: 15.98049

Cumulative Model Updates: 65,079
Cumulative Timesteps: 1,085,514,744

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678,427.94904
Policy Entropy: 1.06396
Value Function Loss: 1.20502

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.08700
Value Function Update Magnitude: 0.10460

Collected Steps per Second: 3,782.75795
Overall Steps per Second: 3,257.11858

Timestep Collection Time: 13.22686
Timestep Consumption Time: 2.13457
PPO Batch Consumption Time: 0.05195
Total Iteration Time: 15.36143

Cumulative Model Updates: 65,082
Cumulative Timesteps: 1,085,564,778

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1085564778...
Checkpoint 1085564778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933,329.02395
Policy Entropy: 1.05933
Value Function Loss: 1.23656

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.08247
Value Function Update Magnitude: 0.09848

Collected Steps per Second: 3,752.30339
Overall Steps per Second: 3,091.93318

Timestep Collection Time: 13.33208
Timestep Consumption Time: 2.84744
PPO Batch Consumption Time: 0.05309
Total Iteration Time: 16.17952

Cumulative Model Updates: 65,085
Cumulative Timesteps: 1,085,614,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418,115.77827
Policy Entropy: 1.05209
Value Function Loss: 1.24874

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.07705
Value Function Update Magnitude: 0.09417

Collected Steps per Second: 3,731.56531
Overall Steps per Second: 3,144.01125

Timestep Collection Time: 13.39920
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 15.90325

Cumulative Model Updates: 65,088
Cumulative Timesteps: 1,085,664,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1085664804...
Checkpoint 1085664804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948,142.43020
Policy Entropy: 1.06550
Value Function Loss: 1.22519

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.15480
Policy Update Magnitude: 0.06631
Value Function Update Magnitude: 0.09403

Collected Steps per Second: 3,732.60781
Overall Steps per Second: 3,085.83607

Timestep Collection Time: 13.40511
Timestep Consumption Time: 2.80963
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 16.21473

Cumulative Model Updates: 65,091
Cumulative Timesteps: 1,085,714,840

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614,831.83728
Policy Entropy: 1.06789
Value Function Loss: 1.25177

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.08857

Collected Steps per Second: 3,856.96352
Overall Steps per Second: 3,165.40494

Timestep Collection Time: 12.97083
Timestep Consumption Time: 2.83379
PPO Batch Consumption Time: 0.06365
Total Iteration Time: 15.80461

Cumulative Model Updates: 65,094
Cumulative Timesteps: 1,085,764,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1085764868...
Checkpoint 1085764868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898,959.79464
Policy Entropy: 1.06394
Value Function Loss: 1.25298

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.07372
Value Function Update Magnitude: 0.09356

Collected Steps per Second: 3,888.82172
Overall Steps per Second: 3,195.10365

Timestep Collection Time: 12.85994
Timestep Consumption Time: 2.79214
PPO Batch Consumption Time: 0.04943
Total Iteration Time: 15.65207

Cumulative Model Updates: 65,097
Cumulative Timesteps: 1,085,814,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941,945.68788
Policy Entropy: 1.05915
Value Function Loss: 1.24524

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.09716

Collected Steps per Second: 3,806.14648
Overall Steps per Second: 3,156.16350

Timestep Collection Time: 13.13770
Timestep Consumption Time: 2.70559
PPO Batch Consumption Time: 0.05800
Total Iteration Time: 15.84329

Cumulative Model Updates: 65,100
Cumulative Timesteps: 1,085,864,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1085864882...
Checkpoint 1085864882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398,257.83081
Policy Entropy: 1.07163
Value Function Loss: 1.19231

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.10099

Collected Steps per Second: 3,670.93480
Overall Steps per Second: 3,040.16156

Timestep Collection Time: 13.62432
Timestep Consumption Time: 2.82678
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 16.45110

Cumulative Model Updates: 65,103
Cumulative Timesteps: 1,085,914,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898,582.39954
Policy Entropy: 1.06998
Value Function Loss: 1.23420

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.07461
Value Function Update Magnitude: 0.09104

Collected Steps per Second: 3,704.66458
Overall Steps per Second: 3,124.59586

Timestep Collection Time: 13.50460
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 16.01167

Cumulative Model Updates: 65,106
Cumulative Timesteps: 1,085,964,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1085964926...
Checkpoint 1085964926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729,546.40328
Policy Entropy: 1.07387
Value Function Loss: 1.23108

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.07434
Value Function Update Magnitude: 0.10374

Collected Steps per Second: 3,877.17333
Overall Steps per Second: 3,233.56406

Timestep Collection Time: 12.90425
Timestep Consumption Time: 2.56846
PPO Batch Consumption Time: 0.04964
Total Iteration Time: 15.47271

Cumulative Model Updates: 65,109
Cumulative Timesteps: 1,086,014,958

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277,462.96526
Policy Entropy: 1.07063
Value Function Loss: 1.28572

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.08309
Value Function Update Magnitude: 0.10874

Collected Steps per Second: 3,644.57965
Overall Steps per Second: 3,095.25876

Timestep Collection Time: 13.72230
Timestep Consumption Time: 2.43532
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 16.15762

Cumulative Model Updates: 65,112
Cumulative Timesteps: 1,086,064,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1086064970...
Checkpoint 1086064970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,136.74735
Policy Entropy: 1.07906
Value Function Loss: 1.29281

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.08739
Value Function Update Magnitude: 0.10648

Collected Steps per Second: 4,085.50901
Overall Steps per Second: 3,492.63580

Timestep Collection Time: 12.24376
Timestep Consumption Time: 2.07837
PPO Batch Consumption Time: 0.05042
Total Iteration Time: 14.32213

Cumulative Model Updates: 65,115
Cumulative Timesteps: 1,086,114,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,180.38587
Policy Entropy: 1.06293
Value Function Loss: 1.29987

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.08825
Value Function Update Magnitude: 0.10205

Collected Steps per Second: 4,350.96119
Overall Steps per Second: 3,516.13791

Timestep Collection Time: 11.49953
Timestep Consumption Time: 2.73029
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 14.22982

Cumulative Model Updates: 65,118
Cumulative Timesteps: 1,086,165,026

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1086165026...
Checkpoint 1086165026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593,095.81161
Policy Entropy: 1.06823
Value Function Loss: 1.29240

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.08357
Value Function Update Magnitude: 0.10252

Collected Steps per Second: 4,175.86158
Overall Steps per Second: 3,412.81443

Timestep Collection Time: 11.97837
Timestep Consumption Time: 2.67816
PPO Batch Consumption Time: 0.06125
Total Iteration Time: 14.65652

Cumulative Model Updates: 65,121
Cumulative Timesteps: 1,086,215,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,895,041.56181
Policy Entropy: 1.05654
Value Function Loss: 1.24967

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.08244
Value Function Update Magnitude: 0.09511

Collected Steps per Second: 3,994.37037
Overall Steps per Second: 3,255.85419

Timestep Collection Time: 12.51912
Timestep Consumption Time: 2.83968
PPO Batch Consumption Time: 0.05386
Total Iteration Time: 15.35880

Cumulative Model Updates: 65,124
Cumulative Timesteps: 1,086,265,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1086265052...
Checkpoint 1086265052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691,617.46783
Policy Entropy: 1.05769
Value Function Loss: 1.23286

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.08046
Value Function Update Magnitude: 0.10633

Collected Steps per Second: 3,761.42762
Overall Steps per Second: 3,134.29096

Timestep Collection Time: 13.29602
Timestep Consumption Time: 2.66038
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 15.95640

Cumulative Model Updates: 65,127
Cumulative Timesteps: 1,086,315,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558,274.36090
Policy Entropy: 1.05554
Value Function Loss: 1.21483

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.08075
Value Function Update Magnitude: 0.10598

Collected Steps per Second: 3,693.40849
Overall Steps per Second: 3,072.00477

Timestep Collection Time: 13.54034
Timestep Consumption Time: 2.73893
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 16.27927

Cumulative Model Updates: 65,130
Cumulative Timesteps: 1,086,365,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1086365074...
Checkpoint 1086365074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,711,222.73661
Policy Entropy: 1.03684
Value Function Loss: 1.23266

Mean KL Divergence: 0.03799
SB3 Clip Fraction: 0.21053
Policy Update Magnitude: 0.07373
Value Function Update Magnitude: 0.09828

Collected Steps per Second: 3,877.05028
Overall Steps per Second: 3,236.75327

Timestep Collection Time: 12.90775
Timestep Consumption Time: 2.55342
PPO Batch Consumption Time: 0.05849
Total Iteration Time: 15.46117

Cumulative Model Updates: 65,133
Cumulative Timesteps: 1,086,415,118

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051,756.55261
Policy Entropy: 1.05678
Value Function Loss: 1.24620

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.06567
Value Function Update Magnitude: 0.10273

Collected Steps per Second: 3,713.00344
Overall Steps per Second: 3,099.27379

Timestep Collection Time: 13.47588
Timestep Consumption Time: 2.66854
PPO Batch Consumption Time: 0.05365
Total Iteration Time: 16.14443

Cumulative Model Updates: 65,136
Cumulative Timesteps: 1,086,465,154

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1086465154...
Checkpoint 1086465154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533,774.46318
Policy Entropy: 1.04730
Value Function Loss: 1.27981

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.06903
Value Function Update Magnitude: 0.10076

Collected Steps per Second: 3,807.98426
Overall Steps per Second: 3,147.91842

Timestep Collection Time: 13.13136
Timestep Consumption Time: 2.75343
PPO Batch Consumption Time: 0.05274
Total Iteration Time: 15.88478

Cumulative Model Updates: 65,139
Cumulative Timesteps: 1,086,515,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620,958.61291
Policy Entropy: 1.03269
Value Function Loss: 1.33011

Mean KL Divergence: 0.03060
SB3 Clip Fraction: 0.18324
Policy Update Magnitude: 0.06822
Value Function Update Magnitude: 0.10091

Collected Steps per Second: 3,683.21986
Overall Steps per Second: 3,067.93627

Timestep Collection Time: 13.58540
Timestep Consumption Time: 2.72459
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 16.30999

Cumulative Model Updates: 65,142
Cumulative Timesteps: 1,086,565,196

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1086565196...
Checkpoint 1086565196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439,335.85955
Policy Entropy: 1.04961
Value Function Loss: 1.36662

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.06125
Value Function Update Magnitude: 0.10593

Collected Steps per Second: 3,775.36604
Overall Steps per Second: 3,190.89882

Timestep Collection Time: 13.25275
Timestep Consumption Time: 2.42747
PPO Batch Consumption Time: 0.06111
Total Iteration Time: 15.68022

Cumulative Model Updates: 65,145
Cumulative Timesteps: 1,086,615,230

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629,796.89261
Policy Entropy: 1.06013
Value Function Loss: 1.27294

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.15227
Policy Update Magnitude: 0.06080
Value Function Update Magnitude: 0.11604

Collected Steps per Second: 3,643.21704
Overall Steps per Second: 3,077.09656

Timestep Collection Time: 13.73402
Timestep Consumption Time: 2.52677
PPO Batch Consumption Time: 0.05292
Total Iteration Time: 16.26078

Cumulative Model Updates: 65,148
Cumulative Timesteps: 1,086,665,266

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1086665266...
Checkpoint 1086665266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729,498.02552
Policy Entropy: 1.04872
Value Function Loss: 1.16415

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.12708

Collected Steps per Second: 3,802.26763
Overall Steps per Second: 3,217.10984

Timestep Collection Time: 13.15005
Timestep Consumption Time: 2.39185
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 15.54190

Cumulative Model Updates: 65,151
Cumulative Timesteps: 1,086,715,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937,682.68736
Policy Entropy: 1.03537
Value Function Loss: 1.10858

Mean KL Divergence: 0.02780
SB3 Clip Fraction: 0.18867
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.13145

Collected Steps per Second: 3,829.92802
Overall Steps per Second: 3,192.64000

Timestep Collection Time: 13.06343
Timestep Consumption Time: 2.60761
PPO Batch Consumption Time: 0.05224
Total Iteration Time: 15.67104

Cumulative Model Updates: 65,154
Cumulative Timesteps: 1,086,765,298

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1086765298...
Checkpoint 1086765298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501,120.02852
Policy Entropy: 1.04777
Value Function Loss: 1.08275

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.11472

Collected Steps per Second: 3,692.96358
Overall Steps per Second: 3,078.98055

Timestep Collection Time: 13.54143
Timestep Consumption Time: 2.70031
PPO Batch Consumption Time: 0.05097
Total Iteration Time: 16.24174

Cumulative Model Updates: 65,157
Cumulative Timesteps: 1,086,815,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665,829.25331
Policy Entropy: 1.05195
Value Function Loss: 1.09665

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.10148

Collected Steps per Second: 3,733.93093
Overall Steps per Second: 3,108.89163

Timestep Collection Time: 13.39821
Timestep Consumption Time: 2.69370
PPO Batch Consumption Time: 0.04937
Total Iteration Time: 16.09191

Cumulative Model Updates: 65,160
Cumulative Timesteps: 1,086,865,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1086865334...
Checkpoint 1086865334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,392,346.24970
Policy Entropy: 1.04193
Value Function Loss: 1.08068

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.07040
Value Function Update Magnitude: 0.09450

Collected Steps per Second: 3,844.40994
Overall Steps per Second: 3,182.68048

Timestep Collection Time: 13.01370
Timestep Consumption Time: 2.70575
PPO Batch Consumption Time: 0.05780
Total Iteration Time: 15.71945

Cumulative Model Updates: 65,163
Cumulative Timesteps: 1,086,915,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532,594.36194
Policy Entropy: 1.04291
Value Function Loss: 1.18692

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.17690
Policy Update Magnitude: 0.06459
Value Function Update Magnitude: 0.09622

Collected Steps per Second: 3,883.49738
Overall Steps per Second: 3,246.27429

Timestep Collection Time: 12.88684
Timestep Consumption Time: 2.52960
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 15.41644

Cumulative Model Updates: 65,166
Cumulative Timesteps: 1,086,965,410

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1086965410...
Checkpoint 1086965410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645,093.49853
Policy Entropy: 1.05189
Value Function Loss: 1.18009

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.10770

Collected Steps per Second: 3,745.33765
Overall Steps per Second: 3,118.13996

Timestep Collection Time: 13.35260
Timestep Consumption Time: 2.68581
PPO Batch Consumption Time: 0.05347
Total Iteration Time: 16.03841

Cumulative Model Updates: 65,169
Cumulative Timesteps: 1,087,015,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603,360.33867
Policy Entropy: 1.05340
Value Function Loss: 1.21050

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.07105
Value Function Update Magnitude: 0.10144

Collected Steps per Second: 3,842.60407
Overall Steps per Second: 3,182.14774

Timestep Collection Time: 13.01513
Timestep Consumption Time: 2.70130
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 15.71643

Cumulative Model Updates: 65,172
Cumulative Timesteps: 1,087,065,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1087065432...
Checkpoint 1087065432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579,020.90076
Policy Entropy: 1.04845
Value Function Loss: 1.18029

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.07345
Value Function Update Magnitude: 0.09809

Collected Steps per Second: 3,861.03996
Overall Steps per Second: 3,203.61638

Timestep Collection Time: 12.96179
Timestep Consumption Time: 2.65993
PPO Batch Consumption Time: 0.05047
Total Iteration Time: 15.62172

Cumulative Model Updates: 65,175
Cumulative Timesteps: 1,087,115,478

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,165,709.53189
Policy Entropy: 1.04788
Value Function Loss: 1.23121

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.07740
Value Function Update Magnitude: 0.09152

Collected Steps per Second: 3,836.23222
Overall Steps per Second: 3,184.94239

Timestep Collection Time: 13.04613
Timestep Consumption Time: 2.66781
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 15.71394

Cumulative Model Updates: 65,178
Cumulative Timesteps: 1,087,165,526

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1087165526...
Checkpoint 1087165526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568,546.21076
Policy Entropy: 1.04145
Value Function Loss: 1.20291

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.07775
Value Function Update Magnitude: 0.08596

Collected Steps per Second: 3,756.36979
Overall Steps per Second: 3,131.05776

Timestep Collection Time: 13.31072
Timestep Consumption Time: 2.65832
PPO Batch Consumption Time: 0.05844
Total Iteration Time: 15.96904

Cumulative Model Updates: 65,181
Cumulative Timesteps: 1,087,215,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809,742.94259
Policy Entropy: 1.03696
Value Function Loss: 1.16968

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.08194
Value Function Update Magnitude: 0.09335

Collected Steps per Second: 3,779.27459
Overall Steps per Second: 3,185.77652

Timestep Collection Time: 13.23429
Timestep Consumption Time: 2.46550
PPO Batch Consumption Time: 0.05341
Total Iteration Time: 15.69978

Cumulative Model Updates: 65,184
Cumulative Timesteps: 1,087,265,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1087265542...
Checkpoint 1087265542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815,603.08290
Policy Entropy: 1.04118
Value Function Loss: 1.16023

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.07304
Value Function Update Magnitude: 0.09390

Collected Steps per Second: 3,619.57249
Overall Steps per Second: 3,078.64987

Timestep Collection Time: 13.82815
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.05007
Total Iteration Time: 16.25778

Cumulative Model Updates: 65,187
Cumulative Timesteps: 1,087,315,594

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921,281.62160
Policy Entropy: 1.05257
Value Function Loss: 1.15181

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.07108
Value Function Update Magnitude: 0.09633

Collected Steps per Second: 3,884.05864
Overall Steps per Second: 3,271.97804

Timestep Collection Time: 12.87880
Timestep Consumption Time: 2.40920
PPO Batch Consumption Time: 0.06351
Total Iteration Time: 15.28800

Cumulative Model Updates: 65,190
Cumulative Timesteps: 1,087,365,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1087365616...
Checkpoint 1087365616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473,099.15482
Policy Entropy: 1.05638
Value Function Loss: 1.16760

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.06996
Value Function Update Magnitude: 0.11138

Collected Steps per Second: 3,744.53240
Overall Steps per Second: 3,121.07085

Timestep Collection Time: 13.36242
Timestep Consumption Time: 2.66926
PPO Batch Consumption Time: 0.05358
Total Iteration Time: 16.03168

Cumulative Model Updates: 65,193
Cumulative Timesteps: 1,087,415,652

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027,924.89767
Policy Entropy: 1.07498
Value Function Loss: 1.14378

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.16898
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.10193

Collected Steps per Second: 3,749.69248
Overall Steps per Second: 3,114.88364

Timestep Collection Time: 13.34189
Timestep Consumption Time: 2.71906
PPO Batch Consumption Time: 0.04890
Total Iteration Time: 16.06095

Cumulative Model Updates: 65,196
Cumulative Timesteps: 1,087,465,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1087465680...
Checkpoint 1087465680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446,552.74055
Policy Entropy: 1.04890
Value Function Loss: 1.19041

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.14978
Policy Update Magnitude: 0.06453
Value Function Update Magnitude: 0.09726

Collected Steps per Second: 3,990.77166
Overall Steps per Second: 3,271.80986

Timestep Collection Time: 12.53392
Timestep Consumption Time: 2.75426
PPO Batch Consumption Time: 0.05013
Total Iteration Time: 15.28817

Cumulative Model Updates: 65,199
Cumulative Timesteps: 1,087,515,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699,209.71973
Policy Entropy: 1.06848
Value Function Loss: 1.16634

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.17050
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.09758

Collected Steps per Second: 3,847.93384
Overall Steps per Second: 3,211.37429

Timestep Collection Time: 13.00542
Timestep Consumption Time: 2.57794
PPO Batch Consumption Time: 0.05805
Total Iteration Time: 15.58336

Cumulative Model Updates: 65,202
Cumulative Timesteps: 1,087,565,744

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1087565744...
Checkpoint 1087565744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523,007.19598
Policy Entropy: 1.05815
Value Function Loss: 1.19335

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.08974

Collected Steps per Second: 3,893.22453
Overall Steps per Second: 3,191.57891

Timestep Collection Time: 12.85207
Timestep Consumption Time: 2.82544
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 15.67751

Cumulative Model Updates: 65,205
Cumulative Timesteps: 1,087,615,780

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,919,338.47633
Policy Entropy: 1.05980
Value Function Loss: 1.19313

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.06695
Value Function Update Magnitude: 0.09086

Collected Steps per Second: 3,723.77947
Overall Steps per Second: 3,095.82489

Timestep Collection Time: 13.43957
Timestep Consumption Time: 2.72607
PPO Batch Consumption Time: 0.05228
Total Iteration Time: 16.16564

Cumulative Model Updates: 65,208
Cumulative Timesteps: 1,087,665,826

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1087665826...
Checkpoint 1087665826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274,991.91519
Policy Entropy: 1.04528
Value Function Loss: 1.21114

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.07515
Value Function Update Magnitude: 0.09509

Collected Steps per Second: 3,879.44014
Overall Steps per Second: 3,241.86309

Timestep Collection Time: 12.89980
Timestep Consumption Time: 2.53700
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 15.43680

Cumulative Model Updates: 65,211
Cumulative Timesteps: 1,087,715,870

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,031,864.92523
Policy Entropy: 1.04008
Value Function Loss: 1.21733

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.15214
Policy Update Magnitude: 0.07218
Value Function Update Magnitude: 0.08585

Collected Steps per Second: 3,815.54439
Overall Steps per Second: 3,166.59096

Timestep Collection Time: 13.11268
Timestep Consumption Time: 2.68728
PPO Batch Consumption Time: 0.06327
Total Iteration Time: 15.79996

Cumulative Model Updates: 65,214
Cumulative Timesteps: 1,087,765,902

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1087765902...
Checkpoint 1087765902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616,246.20867
Policy Entropy: 1.06124
Value Function Loss: 1.21900

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.08794

Collected Steps per Second: 3,743.89885
Overall Steps per Second: 3,118.57801

Timestep Collection Time: 13.36681
Timestep Consumption Time: 2.68024
PPO Batch Consumption Time: 0.05015
Total Iteration Time: 16.04706

Cumulative Model Updates: 65,217
Cumulative Timesteps: 1,087,815,946

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643,457.56009
Policy Entropy: 1.06975
Value Function Loss: 1.16178

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.06849
Value Function Update Magnitude: 0.09069

Collected Steps per Second: 3,844.48586
Overall Steps per Second: 3,203.32863

Timestep Collection Time: 13.01500
Timestep Consumption Time: 2.60500
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 15.62000

Cumulative Model Updates: 65,220
Cumulative Timesteps: 1,087,865,982

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1087865982...
Checkpoint 1087865982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,059,002.37252
Policy Entropy: 1.06576
Value Function Loss: 1.04995

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.15755
Policy Update Magnitude: 0.06658
Value Function Update Magnitude: 0.09338

Collected Steps per Second: 3,798.01567
Overall Steps per Second: 3,182.83586

Timestep Collection Time: 13.16898
Timestep Consumption Time: 2.54531
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 15.71429

Cumulative Model Updates: 65,223
Cumulative Timesteps: 1,087,915,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,173,876.12873
Policy Entropy: 1.06483
Value Function Loss: 1.01317

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.17495
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.09312

Collected Steps per Second: 3,818.63786
Overall Steps per Second: 3,207.07922

Timestep Collection Time: 13.09367
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.04741
Total Iteration Time: 15.59051

Cumulative Model Updates: 65,226
Cumulative Timesteps: 1,087,965,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1087965998...
Checkpoint 1087965998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434,367.46296
Policy Entropy: 1.06813
Value Function Loss: 1.06674

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.15905
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.08788

Collected Steps per Second: 3,703.63187
Overall Steps per Second: 3,116.23764

Timestep Collection Time: 13.51430
Timestep Consumption Time: 2.54737
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 16.06168

Cumulative Model Updates: 65,229
Cumulative Timesteps: 1,088,016,050

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517,646.71308
Policy Entropy: 1.07672
Value Function Loss: 1.10521

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.16500
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.09028

Collected Steps per Second: 3,670.21610
Overall Steps per Second: 3,106.84224

Timestep Collection Time: 13.63680
Timestep Consumption Time: 2.47281
PPO Batch Consumption Time: 0.06069
Total Iteration Time: 16.10960

Cumulative Model Updates: 65,232
Cumulative Timesteps: 1,088,066,100

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1088066100...
Checkpoint 1088066100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627,880.08021
Policy Entropy: 1.07298
Value Function Loss: 1.11322

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.08294

Collected Steps per Second: 3,855.06610
Overall Steps per Second: 3,195.80695

Timestep Collection Time: 12.97462
Timestep Consumption Time: 2.67652
PPO Batch Consumption Time: 0.06149
Total Iteration Time: 15.65113

Cumulative Model Updates: 65,235
Cumulative Timesteps: 1,088,116,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,217,039.91466
Policy Entropy: 1.05028
Value Function Loss: 1.14118

Mean KL Divergence: 0.03661
SB3 Clip Fraction: 0.21148
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.08374

Collected Steps per Second: 3,686.69250
Overall Steps per Second: 3,165.15207

Timestep Collection Time: 13.57097
Timestep Consumption Time: 2.23617
PPO Batch Consumption Time: 0.05124
Total Iteration Time: 15.80714

Cumulative Model Updates: 65,238
Cumulative Timesteps: 1,088,166,150

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1088166150...
Checkpoint 1088166150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717,477.79766
Policy Entropy: 1.07550
Value Function Loss: 1.19670

Mean KL Divergence: 0.03993
SB3 Clip Fraction: 0.22512
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.09186

Collected Steps per Second: 4,033.95065
Overall Steps per Second: 3,359.76271

Timestep Collection Time: 12.39678
Timestep Consumption Time: 2.48760
PPO Batch Consumption Time: 0.05220
Total Iteration Time: 14.88438

Cumulative Model Updates: 65,241
Cumulative Timesteps: 1,088,216,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,301,345.46139
Policy Entropy: 1.03297
Value Function Loss: 1.18301

Mean KL Divergence: 0.07476
SB3 Clip Fraction: 0.28333
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.10487

Collected Steps per Second: 3,826.57848
Overall Steps per Second: 3,149.87690

Timestep Collection Time: 13.06650
Timestep Consumption Time: 2.80713
PPO Batch Consumption Time: 0.05985
Total Iteration Time: 15.87364

Cumulative Model Updates: 65,244
Cumulative Timesteps: 1,088,266,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1088266158...
Checkpoint 1088266158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580,089.76029
Policy Entropy: 1.06519
Value Function Loss: 1.12457

Mean KL Divergence: 0.05238
SB3 Clip Fraction: 0.25600
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.10511

Collected Steps per Second: 3,788.19997
Overall Steps per Second: 3,131.33117

Timestep Collection Time: 13.20152
Timestep Consumption Time: 2.76932
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 15.97084

Cumulative Model Updates: 65,247
Cumulative Timesteps: 1,088,316,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446,457.90032
Policy Entropy: 1.05861
Value Function Loss: 1.10797

Mean KL Divergence: 0.04511
SB3 Clip Fraction: 0.23153
Policy Update Magnitude: 0.04328
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 3,661.07581
Overall Steps per Second: 3,070.43686

Timestep Collection Time: 13.66702
Timestep Consumption Time: 2.62903
PPO Batch Consumption Time: 0.05429
Total Iteration Time: 16.29605

Cumulative Model Updates: 65,250
Cumulative Timesteps: 1,088,366,204

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1088366204...
Checkpoint 1088366204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668,875.07988
Policy Entropy: 1.08802
Value Function Loss: 1.15622

Mean KL Divergence: 0.03935
SB3 Clip Fraction: 0.21577
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.12826

Collected Steps per Second: 3,762.76958
Overall Steps per Second: 3,148.28159

Timestep Collection Time: 13.28862
Timestep Consumption Time: 2.59370
PPO Batch Consumption Time: 0.05960
Total Iteration Time: 15.88231

Cumulative Model Updates: 65,253
Cumulative Timesteps: 1,088,416,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343,533.75890
Policy Entropy: 1.06983
Value Function Loss: 1.20705

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.12112

Collected Steps per Second: 3,742.26258
Overall Steps per Second: 3,120.49774

Timestep Collection Time: 13.37212
Timestep Consumption Time: 2.66442
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 16.03654

Cumulative Model Updates: 65,256
Cumulative Timesteps: 1,088,466,248

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1088466248...
Checkpoint 1088466248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639,908.61892
Policy Entropy: 1.08931
Value Function Loss: 1.21180

Mean KL Divergence: 0.02830
SB3 Clip Fraction: 0.18021
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.10472

Collected Steps per Second: 3,713.32116
Overall Steps per Second: 3,083.11221

Timestep Collection Time: 13.47311
Timestep Consumption Time: 2.75400
PPO Batch Consumption Time: 0.05409
Total Iteration Time: 16.22711

Cumulative Model Updates: 65,259
Cumulative Timesteps: 1,088,516,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189,896.92706
Policy Entropy: 1.08032
Value Function Loss: 1.17210

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.10224

Collected Steps per Second: 3,832.99223
Overall Steps per Second: 3,229.70041

Timestep Collection Time: 13.05560
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.06127
Total Iteration Time: 15.49432

Cumulative Model Updates: 65,262
Cumulative Timesteps: 1,088,566,320

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1088566320...
Checkpoint 1088566320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356,624.37818
Policy Entropy: 1.07146
Value Function Loss: 1.14969

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.10142

Collected Steps per Second: 3,819.55752
Overall Steps per Second: 3,227.67284

Timestep Collection Time: 13.09942
Timestep Consumption Time: 2.40215
PPO Batch Consumption Time: 0.04853
Total Iteration Time: 15.50157

Cumulative Model Updates: 65,265
Cumulative Timesteps: 1,088,616,354

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460,847.42371
Policy Entropy: 1.05015
Value Function Loss: 1.12226

Mean KL Divergence: 0.04096
SB3 Clip Fraction: 0.21616
Policy Update Magnitude: 0.06458
Value Function Update Magnitude: 0.09343

Collected Steps per Second: 3,856.58870
Overall Steps per Second: 3,233.82238

Timestep Collection Time: 12.96690
Timestep Consumption Time: 2.49715
PPO Batch Consumption Time: 0.05252
Total Iteration Time: 15.46405

Cumulative Model Updates: 65,268
Cumulative Timesteps: 1,088,666,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1088666362...
Checkpoint 1088666362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025,037.35414
Policy Entropy: 1.09337
Value Function Loss: 1.08859

Mean KL Divergence: 0.03398
SB3 Clip Fraction: 0.20887
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.08467

Collected Steps per Second: 4,135.29916
Overall Steps per Second: 3,343.22685

Timestep Collection Time: 12.10215
Timestep Consumption Time: 2.86722
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 14.96937

Cumulative Model Updates: 65,271
Cumulative Timesteps: 1,088,716,408

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668,264.87371
Policy Entropy: 1.05399
Value Function Loss: 1.14336

Mean KL Divergence: 0.06388
SB3 Clip Fraction: 0.26723
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.08011

Collected Steps per Second: 4,115.88314
Overall Steps per Second: 3,354.29407

Timestep Collection Time: 12.15584
Timestep Consumption Time: 2.75997
PPO Batch Consumption Time: 0.05041
Total Iteration Time: 14.91581

Cumulative Model Updates: 65,274
Cumulative Timesteps: 1,088,766,440

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1088766440...
Checkpoint 1088766440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741,109.42122
Policy Entropy: 1.08639
Value Function Loss: 1.17804

Mean KL Divergence: 0.04774
SB3 Clip Fraction: 0.24591
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.07730

Collected Steps per Second: 4,049.63143
Overall Steps per Second: 3,309.96815

Timestep Collection Time: 12.35075
Timestep Consumption Time: 2.75997
PPO Batch Consumption Time: 0.05057
Total Iteration Time: 15.11072

Cumulative Model Updates: 65,277
Cumulative Timesteps: 1,088,816,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348,930.05307
Policy Entropy: 1.04856
Value Function Loss: 1.28440

Mean KL Divergence: 0.06275
SB3 Clip Fraction: 0.25165
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.09520

Collected Steps per Second: 3,652.50807
Overall Steps per Second: 3,037.50193

Timestep Collection Time: 13.69579
Timestep Consumption Time: 2.77300
PPO Batch Consumption Time: 0.05312
Total Iteration Time: 16.46880

Cumulative Model Updates: 65,280
Cumulative Timesteps: 1,088,866,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1088866480...
Checkpoint 1088866480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936,883.71597
Policy Entropy: 1.07399
Value Function Loss: 1.24173

Mean KL Divergence: 0.03889
SB3 Clip Fraction: 0.20903
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.10884

Collected Steps per Second: 3,766.33545
Overall Steps per Second: 3,011.00643

Timestep Collection Time: 13.28719
Timestep Consumption Time: 3.33317
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 16.62036

Cumulative Model Updates: 65,283
Cumulative Timesteps: 1,088,916,524

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397,370.98830
Policy Entropy: 1.05181
Value Function Loss: 1.28573

Mean KL Divergence: 0.03106
SB3 Clip Fraction: 0.17471
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.10959

Collected Steps per Second: 3,761.01062
Overall Steps per Second: 3,207.07242

Timestep Collection Time: 13.30493
Timestep Consumption Time: 2.29808
PPO Batch Consumption Time: 0.05440
Total Iteration Time: 15.60302

Cumulative Model Updates: 65,286
Cumulative Timesteps: 1,088,966,564

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1088966564...
Checkpoint 1088966564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825,489.47678
Policy Entropy: 1.07183
Value Function Loss: 1.27667

Mean KL Divergence: 0.02882
SB3 Clip Fraction: 0.17951
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.10956

Collected Steps per Second: 3,865.83275
Overall Steps per Second: 3,231.68818

Timestep Collection Time: 12.94365
Timestep Consumption Time: 2.53989
PPO Batch Consumption Time: 0.05253
Total Iteration Time: 15.48355

Cumulative Model Updates: 65,289
Cumulative Timesteps: 1,089,016,602

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506,391.56663
Policy Entropy: 1.05713
Value Function Loss: 1.28185

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.16307
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 3,978.07500
Overall Steps per Second: 3,298.58167

Timestep Collection Time: 12.57744
Timestep Consumption Time: 2.59090
PPO Batch Consumption Time: 0.06424
Total Iteration Time: 15.16834

Cumulative Model Updates: 65,292
Cumulative Timesteps: 1,089,066,636

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1089066636...
Checkpoint 1089066636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617,072.01984
Policy Entropy: 1.04854
Value Function Loss: 1.24852

Mean KL Divergence: 0.02566
SB3 Clip Fraction: 0.16257
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.11258

Collected Steps per Second: 3,722.91694
Overall Steps per Second: 3,107.19635

Timestep Collection Time: 13.44322
Timestep Consumption Time: 2.66390
PPO Batch Consumption Time: 0.05412
Total Iteration Time: 16.10712

Cumulative Model Updates: 65,295
Cumulative Timesteps: 1,089,116,684

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,130,938.53974
Policy Entropy: 1.04079
Value Function Loss: 1.25718

Mean KL Divergence: 0.02966
SB3 Clip Fraction: 0.19834
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.10206

Collected Steps per Second: 3,777.11695
Overall Steps per Second: 3,206.11838

Timestep Collection Time: 13.23867
Timestep Consumption Time: 2.35776
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 15.59643

Cumulative Model Updates: 65,298
Cumulative Timesteps: 1,089,166,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1089166688...
Checkpoint 1089166688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,108,846.83473
Policy Entropy: 1.05381
Value Function Loss: 1.26319

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.10690

Collected Steps per Second: 3,730.33347
Overall Steps per Second: 3,196.39643

Timestep Collection Time: 13.40684
Timestep Consumption Time: 2.23953
PPO Batch Consumption Time: 0.05820
Total Iteration Time: 15.64637

Cumulative Model Updates: 65,301
Cumulative Timesteps: 1,089,216,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,187,608.43387
Policy Entropy: 1.05699
Value Function Loss: 1.28441

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.10484

Collected Steps per Second: 3,709.29749
Overall Steps per Second: 3,124.41795

Timestep Collection Time: 13.48719
Timestep Consumption Time: 2.52475
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 16.01194

Cumulative Model Updates: 65,304
Cumulative Timesteps: 1,089,266,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1089266728...
Checkpoint 1089266728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510,491.97985
Policy Entropy: 1.03897
Value Function Loss: 1.29890

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.11460

Collected Steps per Second: 3,771.13427
Overall Steps per Second: 3,132.73775

Timestep Collection Time: 13.26816
Timestep Consumption Time: 2.70382
PPO Batch Consumption Time: 0.05830
Total Iteration Time: 15.97197

Cumulative Model Updates: 65,307
Cumulative Timesteps: 1,089,316,764

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259,907.44479
Policy Entropy: 1.03557
Value Function Loss: 1.27193

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.16323
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.10805

Collected Steps per Second: 3,928.22362
Overall Steps per Second: 3,250.25460

Timestep Collection Time: 12.74113
Timestep Consumption Time: 2.65767
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 15.39879

Cumulative Model Updates: 65,310
Cumulative Timesteps: 1,089,366,814

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1089366814...
Checkpoint 1089366814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,961,323.51876
Policy Entropy: 1.04705
Value Function Loss: 1.25779

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.10732

Collected Steps per Second: 3,620.62202
Overall Steps per Second: 3,031.30603

Timestep Collection Time: 13.82083
Timestep Consumption Time: 2.68691
PPO Batch Consumption Time: 0.05761
Total Iteration Time: 16.50774

Cumulative Model Updates: 65,313
Cumulative Timesteps: 1,089,416,854

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,848,374.40356
Policy Entropy: 1.05292
Value Function Loss: 1.25926

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.15183
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.11214

Collected Steps per Second: 3,807.63264
Overall Steps per Second: 3,181.00129

Timestep Collection Time: 13.13835
Timestep Consumption Time: 2.58815
PPO Batch Consumption Time: 0.04974
Total Iteration Time: 15.72649

Cumulative Model Updates: 65,316
Cumulative Timesteps: 1,089,466,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1089466880...
Checkpoint 1089466880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644,829.41326
Policy Entropy: 1.03787
Value Function Loss: 1.26343

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.10970

Collected Steps per Second: 3,691.21395
Overall Steps per Second: 3,111.14931

Timestep Collection Time: 13.54947
Timestep Consumption Time: 2.52626
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 16.07573

Cumulative Model Updates: 65,319
Cumulative Timesteps: 1,089,516,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380,806.00688
Policy Entropy: 1.03284
Value Function Loss: 1.25251

Mean KL Divergence: 0.03428
SB3 Clip Fraction: 0.20212
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.09991

Collected Steps per Second: 3,883.74402
Overall Steps per Second: 3,232.08318

Timestep Collection Time: 12.88447
Timestep Consumption Time: 2.59780
PPO Batch Consumption Time: 0.06628
Total Iteration Time: 15.48227

Cumulative Model Updates: 65,322
Cumulative Timesteps: 1,089,566,934

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1089566934...
Checkpoint 1089566934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619,208.97955
Policy Entropy: 1.05621
Value Function Loss: 1.26911

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.06300
Value Function Update Magnitude: 0.08409

Collected Steps per Second: 3,983.16380
Overall Steps per Second: 3,294.07921

Timestep Collection Time: 12.55936
Timestep Consumption Time: 2.62728
PPO Batch Consumption Time: 0.05006
Total Iteration Time: 15.18664

Cumulative Model Updates: 65,325
Cumulative Timesteps: 1,089,616,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909,695.45306
Policy Entropy: 1.04588
Value Function Loss: 1.29282

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.07559
Value Function Update Magnitude: 0.08662

Collected Steps per Second: 3,830.09684
Overall Steps per Second: 3,201.12790

Timestep Collection Time: 13.06547
Timestep Consumption Time: 2.56715
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 15.63262

Cumulative Model Updates: 65,328
Cumulative Timesteps: 1,089,667,002

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1089667002...
Checkpoint 1089667002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608,820.68607
Policy Entropy: 1.03827
Value Function Loss: 1.25833

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.15368
Policy Update Magnitude: 0.06900
Value Function Update Magnitude: 0.09531

Collected Steps per Second: 3,695.35883
Overall Steps per Second: 3,117.62671

Timestep Collection Time: 13.53698
Timestep Consumption Time: 2.50856
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 16.04554

Cumulative Model Updates: 65,331
Cumulative Timesteps: 1,089,717,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630,944.74860
Policy Entropy: 1.04592
Value Function Loss: 1.27949

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.14599
Policy Update Magnitude: 0.06420
Value Function Update Magnitude: 0.09057

Collected Steps per Second: 3,803.02586
Overall Steps per Second: 3,224.17883

Timestep Collection Time: 13.15321
Timestep Consumption Time: 2.36144
PPO Batch Consumption Time: 0.05190
Total Iteration Time: 15.51465

Cumulative Model Updates: 65,334
Cumulative Timesteps: 1,089,767,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1089767048...
Checkpoint 1089767048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209,111.58247
Policy Entropy: 1.05587
Value Function Loss: 1.36397

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.06597
Value Function Update Magnitude: 0.09268

Collected Steps per Second: 3,882.82769
Overall Steps per Second: 3,283.45146

Timestep Collection Time: 12.88597
Timestep Consumption Time: 2.35226
PPO Batch Consumption Time: 0.06113
Total Iteration Time: 15.23823

Cumulative Model Updates: 65,337
Cumulative Timesteps: 1,089,817,082

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528,494.84659
Policy Entropy: 1.06245
Value Function Loss: 1.37973

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.07980
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 3,692.70046
Overall Steps per Second: 3,134.63606

Timestep Collection Time: 13.54943
Timestep Consumption Time: 2.41223
PPO Batch Consumption Time: 0.05964
Total Iteration Time: 15.96166

Cumulative Model Updates: 65,340
Cumulative Timesteps: 1,089,867,116

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1089867116...
Checkpoint 1089867116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592,227.88032
Policy Entropy: 1.05312
Value Function Loss: 1.35085

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.08305
Value Function Update Magnitude: 0.14209

Collected Steps per Second: 3,851.59592
Overall Steps per Second: 3,196.70339

Timestep Collection Time: 12.98267
Timestep Consumption Time: 2.65969
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 15.64236

Cumulative Model Updates: 65,343
Cumulative Timesteps: 1,089,917,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496,048.88810
Policy Entropy: 1.03332
Value Function Loss: 1.31179

Mean KL Divergence: 0.02917
SB3 Clip Fraction: 0.18985
Policy Update Magnitude: 0.07759
Value Function Update Magnitude: 0.14907

Collected Steps per Second: 3,695.02127
Overall Steps per Second: 3,075.55935

Timestep Collection Time: 13.53551
Timestep Consumption Time: 2.72625
PPO Batch Consumption Time: 0.06008
Total Iteration Time: 16.26176

Cumulative Model Updates: 65,346
Cumulative Timesteps: 1,089,967,134

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1089967134...
Checkpoint 1089967134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270,607.87813
Policy Entropy: 1.04740
Value Function Loss: 1.39313

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.06496
Value Function Update Magnitude: 0.14057

Collected Steps per Second: 3,731.73668
Overall Steps per Second: 3,088.28022

Timestep Collection Time: 13.40020
Timestep Consumption Time: 2.79199
PPO Batch Consumption Time: 0.05981
Total Iteration Time: 16.19218

Cumulative Model Updates: 65,349
Cumulative Timesteps: 1,090,017,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332,282.87728
Policy Entropy: 1.04859
Value Function Loss: 1.39237

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.06998
Value Function Update Magnitude: 0.12767

Collected Steps per Second: 3,654.65125
Overall Steps per Second: 3,080.81778

Timestep Collection Time: 13.68120
Timestep Consumption Time: 2.54826
PPO Batch Consumption Time: 0.06116
Total Iteration Time: 16.22946

Cumulative Model Updates: 65,352
Cumulative Timesteps: 1,090,067,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1090067140...
Checkpoint 1090067140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,768,187.82624
Policy Entropy: 1.03239
Value Function Loss: 1.43011

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.15747
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.11269

Collected Steps per Second: 3,760.12048
Overall Steps per Second: 3,136.65208

Timestep Collection Time: 13.30968
Timestep Consumption Time: 2.64555
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 15.95523

Cumulative Model Updates: 65,355
Cumulative Timesteps: 1,090,117,186

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571,287.63930
Policy Entropy: 1.02417
Value Function Loss: 1.37838

Mean KL Divergence: 0.02588
SB3 Clip Fraction: 0.18234
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.12228

Collected Steps per Second: 3,704.13265
Overall Steps per Second: 3,174.49854

Timestep Collection Time: 13.50330
Timestep Consumption Time: 2.25289
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 15.75619

Cumulative Model Updates: 65,358
Cumulative Timesteps: 1,090,167,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1090167204...
Checkpoint 1090167204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163,989.94393
Policy Entropy: 1.04379
Value Function Loss: 1.42354

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.12385

Collected Steps per Second: 3,917.27582
Overall Steps per Second: 3,295.86488

Timestep Collection Time: 12.76755
Timestep Consumption Time: 2.40723
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 15.17477

Cumulative Model Updates: 65,361
Cumulative Timesteps: 1,090,217,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528,823.83975
Policy Entropy: 1.05413
Value Function Loss: 1.39671

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.16765
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.10593

Collected Steps per Second: 3,968.68130
Overall Steps per Second: 3,312.08462

Timestep Collection Time: 12.60419
Timestep Consumption Time: 2.49869
PPO Batch Consumption Time: 0.05435
Total Iteration Time: 15.10288

Cumulative Model Updates: 65,364
Cumulative Timesteps: 1,090,267,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1090267240...
Checkpoint 1090267240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474,691.09759
Policy Entropy: 1.03557
Value Function Loss: 1.36632

Mean KL Divergence: 0.04016
SB3 Clip Fraction: 0.21800
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.09136

Collected Steps per Second: 4,086.47223
Overall Steps per Second: 3,344.91083

Timestep Collection Time: 12.24234
Timestep Consumption Time: 2.71411
PPO Batch Consumption Time: 0.05102
Total Iteration Time: 14.95645

Cumulative Model Updates: 65,367
Cumulative Timesteps: 1,090,317,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710,057.83470
Policy Entropy: 1.06315
Value Function Loss: 1.26210

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.06654
Value Function Update Magnitude: 0.09593

Collected Steps per Second: 4,016.54488
Overall Steps per Second: 3,300.70339

Timestep Collection Time: 12.45299
Timestep Consumption Time: 2.70075
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 15.15374

Cumulative Model Updates: 65,370
Cumulative Timesteps: 1,090,367,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1090367286...
Checkpoint 1090367286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,990,750.81623
Policy Entropy: 1.05422
Value Function Loss: 1.21637

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.17066
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.11303

Collected Steps per Second: 4,095.51321
Overall Steps per Second: 3,370.05834

Timestep Collection Time: 12.21630
Timestep Consumption Time: 2.62974
PPO Batch Consumption Time: 0.06875
Total Iteration Time: 14.84603

Cumulative Model Updates: 65,373
Cumulative Timesteps: 1,090,417,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630,325.13579
Policy Entropy: 1.04790
Value Function Loss: 1.13501

Mean KL Divergence: 0.02928
SB3 Clip Fraction: 0.19399
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.12632

Collected Steps per Second: 3,642.33826
Overall Steps per Second: 3,019.82124

Timestep Collection Time: 13.72909
Timestep Consumption Time: 2.83017
PPO Batch Consumption Time: 0.06673
Total Iteration Time: 16.55926

Cumulative Model Updates: 65,376
Cumulative Timesteps: 1,090,467,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1090467324...
Checkpoint 1090467324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724,505.00170
Policy Entropy: 1.05023
Value Function Loss: 1.16258

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.12082

Collected Steps per Second: 4,015.18685
Overall Steps per Second: 3,322.68081

Timestep Collection Time: 12.46418
Timestep Consumption Time: 2.59776
PPO Batch Consumption Time: 0.05187
Total Iteration Time: 15.06193

Cumulative Model Updates: 65,379
Cumulative Timesteps: 1,090,517,370

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606,745.23019
Policy Entropy: 1.05791
Value Function Loss: 1.19523

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.17686
Policy Update Magnitude: 0.05875
Value Function Update Magnitude: 0.11372

Collected Steps per Second: 4,202.92736
Overall Steps per Second: 3,450.21176

Timestep Collection Time: 11.90075
Timestep Consumption Time: 2.59633
PPO Batch Consumption Time: 0.06014
Total Iteration Time: 14.49708

Cumulative Model Updates: 65,382
Cumulative Timesteps: 1,090,567,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1090567388...
Checkpoint 1090567388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151,398.38825
Policy Entropy: 1.03184
Value Function Loss: 1.27244

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.15629
Policy Update Magnitude: 0.06862
Value Function Update Magnitude: 0.12247

Collected Steps per Second: 3,847.08438
Overall Steps per Second: 3,227.06177

Timestep Collection Time: 12.99997
Timestep Consumption Time: 2.49771
PPO Batch Consumption Time: 0.05755
Total Iteration Time: 15.49769

Cumulative Model Updates: 65,385
Cumulative Timesteps: 1,090,617,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319,396.31238
Policy Entropy: 1.04772
Value Function Loss: 1.35078

Mean KL Divergence: 0.02662
SB3 Clip Fraction: 0.17445
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.13918

Collected Steps per Second: 3,707.56275
Overall Steps per Second: 3,104.38937

Timestep Collection Time: 13.48865
Timestep Consumption Time: 2.62080
PPO Batch Consumption Time: 0.05255
Total Iteration Time: 16.10945

Cumulative Model Updates: 65,388
Cumulative Timesteps: 1,090,667,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1090667410...
Checkpoint 1090667410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374,784.07388
Policy Entropy: 1.04600
Value Function Loss: 1.32393

Mean KL Divergence: 0.02408
SB3 Clip Fraction: 0.17432
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.14209

Collected Steps per Second: 4,018.83020
Overall Steps per Second: 3,323.85222

Timestep Collection Time: 12.44193
Timestep Consumption Time: 2.60146
PPO Batch Consumption Time: 0.06168
Total Iteration Time: 15.04339

Cumulative Model Updates: 65,391
Cumulative Timesteps: 1,090,717,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567,928.11406
Policy Entropy: 1.04227
Value Function Loss: 1.37443

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.13773

Collected Steps per Second: 4,198.79449
Overall Steps per Second: 3,484.31148

Timestep Collection Time: 11.91580
Timestep Consumption Time: 2.44342
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 14.35922

Cumulative Model Updates: 65,394
Cumulative Timesteps: 1,090,767,444

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1090767444...
Checkpoint 1090767444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331,338.34274
Policy Entropy: 1.03179
Value Function Loss: 1.38231

Mean KL Divergence: 0.02942
SB3 Clip Fraction: 0.19791
Policy Update Magnitude: 0.06447
Value Function Update Magnitude: 0.12936

Collected Steps per Second: 4,297.73191
Overall Steps per Second: 3,498.91542

Timestep Collection Time: 11.63404
Timestep Consumption Time: 2.65610
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 14.29014

Cumulative Model Updates: 65,397
Cumulative Timesteps: 1,090,817,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,202,437.96866
Policy Entropy: 1.04605
Value Function Loss: 1.43889

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.06373
Value Function Update Magnitude: 0.12376

Collected Steps per Second: 4,207.55089
Overall Steps per Second: 3,473.71137

Timestep Collection Time: 11.88387
Timestep Consumption Time: 2.51053
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 14.39440

Cumulative Model Updates: 65,400
Cumulative Timesteps: 1,090,867,446

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1090867446...
Checkpoint 1090867446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421,331.10893
Policy Entropy: 1.05370
Value Function Loss: 1.40262

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.06779
Value Function Update Magnitude: 0.12349

Collected Steps per Second: 4,033.65085
Overall Steps per Second: 3,343.76320

Timestep Collection Time: 12.40117
Timestep Consumption Time: 2.55862
PPO Batch Consumption Time: 0.05417
Total Iteration Time: 14.95979

Cumulative Model Updates: 65,403
Cumulative Timesteps: 1,090,917,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738,127.85849
Policy Entropy: 1.03958
Value Function Loss: 1.31963

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14603
Policy Update Magnitude: 0.07108
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 4,000.27196
Overall Steps per Second: 3,326.03206

Timestep Collection Time: 12.50315
Timestep Consumption Time: 2.53459
PPO Batch Consumption Time: 0.04610
Total Iteration Time: 15.03774

Cumulative Model Updates: 65,406
Cumulative Timesteps: 1,090,967,484

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1090967484...
Checkpoint 1090967484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725,337.91988
Policy Entropy: 1.01687
Value Function Loss: 1.28240

Mean KL Divergence: 0.02931
SB3 Clip Fraction: 0.19457
Policy Update Magnitude: 0.07132
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 3,974.22083
Overall Steps per Second: 3,285.17866

Timestep Collection Time: 12.58259
Timestep Consumption Time: 2.63911
PPO Batch Consumption Time: 0.04658
Total Iteration Time: 15.22170

Cumulative Model Updates: 65,409
Cumulative Timesteps: 1,091,017,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540,466.86976
Policy Entropy: 1.02910
Value Function Loss: 1.24798

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.13053

Collected Steps per Second: 3,687.91824
Overall Steps per Second: 3,062.27409

Timestep Collection Time: 13.57188
Timestep Consumption Time: 2.77283
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 16.34472

Cumulative Model Updates: 65,412
Cumulative Timesteps: 1,091,067,542

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1091067542...
Checkpoint 1091067542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939,092.57496
Policy Entropy: 1.03933
Value Function Loss: 1.23073

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.15125
Policy Update Magnitude: 0.06429
Value Function Update Magnitude: 0.14259

Collected Steps per Second: 3,824.80116
Overall Steps per Second: 3,160.80166

Timestep Collection Time: 13.07310
Timestep Consumption Time: 2.74631
PPO Batch Consumption Time: 0.05783
Total Iteration Time: 15.81940

Cumulative Model Updates: 65,415
Cumulative Timesteps: 1,091,117,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712,536.07934
Policy Entropy: 1.02550
Value Function Loss: 1.24938

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.15298
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.13519

Collected Steps per Second: 3,620.49048
Overall Steps per Second: 3,011.29780

Timestep Collection Time: 13.81360
Timestep Consumption Time: 2.79452
PPO Batch Consumption Time: 0.05082
Total Iteration Time: 16.60812

Cumulative Model Updates: 65,418
Cumulative Timesteps: 1,091,167,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1091167556...
Checkpoint 1091167556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629,439.70888
Policy Entropy: 1.02751
Value Function Loss: 1.22896

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.16380
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.13009

Collected Steps per Second: 3,755.68764
Overall Steps per Second: 3,141.93860

Timestep Collection Time: 13.32060
Timestep Consumption Time: 2.60206
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 15.92265

Cumulative Model Updates: 65,421
Cumulative Timesteps: 1,091,217,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548,393.77792
Policy Entropy: 1.04398
Value Function Loss: 1.31313

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.14729
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.12454

Collected Steps per Second: 3,815.52176
Overall Steps per Second: 3,189.39191

Timestep Collection Time: 13.11380
Timestep Consumption Time: 2.57445
PPO Batch Consumption Time: 0.06150
Total Iteration Time: 15.68826

Cumulative Model Updates: 65,424
Cumulative Timesteps: 1,091,267,620

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1091267620...
Checkpoint 1091267620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791,665.15696
Policy Entropy: 1.05146
Value Function Loss: 1.28682

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.12372

Collected Steps per Second: 3,748.96426
Overall Steps per Second: 3,132.06797

Timestep Collection Time: 13.33915
Timestep Consumption Time: 2.62730
PPO Batch Consumption Time: 0.05761
Total Iteration Time: 15.96645

Cumulative Model Updates: 65,427
Cumulative Timesteps: 1,091,317,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473,137.50025
Policy Entropy: 1.03678
Value Function Loss: 1.29408

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.11255

Collected Steps per Second: 3,739.84258
Overall Steps per Second: 3,130.04152

Timestep Collection Time: 13.36955
Timestep Consumption Time: 2.60468
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 15.97423

Cumulative Model Updates: 65,430
Cumulative Timesteps: 1,091,367,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1091367628...
Checkpoint 1091367628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,795,100.81984
Policy Entropy: 1.03584
Value Function Loss: 1.26718

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.15939
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.10325

Collected Steps per Second: 3,770.73045
Overall Steps per Second: 3,144.31374

Timestep Collection Time: 13.26799
Timestep Consumption Time: 2.64328
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 15.91126

Cumulative Model Updates: 65,433
Cumulative Timesteps: 1,091,417,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763,832.24642
Policy Entropy: 1.04795
Value Function Loss: 1.23574

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.10193

Collected Steps per Second: 3,771.28935
Overall Steps per Second: 3,149.86893

Timestep Collection Time: 13.25860
Timestep Consumption Time: 2.61572
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 15.87431

Cumulative Model Updates: 65,436
Cumulative Timesteps: 1,091,467,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1091467660...
Checkpoint 1091467660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,473,138.71277
Policy Entropy: 1.05250
Value Function Loss: 1.20904

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.15471
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.11537

Collected Steps per Second: 3,958.59168
Overall Steps per Second: 3,302.15728

Timestep Collection Time: 12.63429
Timestep Consumption Time: 2.51157
PPO Batch Consumption Time: 0.05974
Total Iteration Time: 15.14586

Cumulative Model Updates: 65,439
Cumulative Timesteps: 1,091,517,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439,010.24042
Policy Entropy: 1.03541
Value Function Loss: 1.19500

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.11626

Collected Steps per Second: 3,860.18649
Overall Steps per Second: 3,280.39088

Timestep Collection Time: 12.95378
Timestep Consumption Time: 2.28953
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 15.24331

Cumulative Model Updates: 65,442
Cumulative Timesteps: 1,091,567,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1091567678...
Checkpoint 1091567678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317,466.28348
Policy Entropy: 1.02405
Value Function Loss: 1.21516

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.18113
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.10623

Collected Steps per Second: 4,103.19811
Overall Steps per Second: 3,406.00981

Timestep Collection Time: 12.19488
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 14.69109

Cumulative Model Updates: 65,445
Cumulative Timesteps: 1,091,617,716

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579,151.81437
Policy Entropy: 1.03380
Value Function Loss: 1.28244

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.10558

Collected Steps per Second: 3,785.72772
Overall Steps per Second: 3,148.49675

Timestep Collection Time: 13.21807
Timestep Consumption Time: 2.67523
PPO Batch Consumption Time: 0.05191
Total Iteration Time: 15.89330

Cumulative Model Updates: 65,448
Cumulative Timesteps: 1,091,667,756

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1091667756...
Checkpoint 1091667756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683,624.74548
Policy Entropy: 1.03655
Value Function Loss: 1.29700

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.16850
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.09702

Collected Steps per Second: 3,776.02527
Overall Steps per Second: 3,130.93990

Timestep Collection Time: 13.24144
Timestep Consumption Time: 2.72821
PPO Batch Consumption Time: 0.06118
Total Iteration Time: 15.96965

Cumulative Model Updates: 65,451
Cumulative Timesteps: 1,091,717,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729,741.25255
Policy Entropy: 1.02037
Value Function Loss: 1.33529

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.10951

Collected Steps per Second: 3,781.85549
Overall Steps per Second: 3,141.52440

Timestep Collection Time: 13.22737
Timestep Consumption Time: 2.69611
PPO Batch Consumption Time: 0.05981
Total Iteration Time: 15.92348

Cumulative Model Updates: 65,454
Cumulative Timesteps: 1,091,767,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1091767780...
Checkpoint 1091767780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430,106.55574
Policy Entropy: 1.00395
Value Function Loss: 1.30549

Mean KL Divergence: 0.03624
SB3 Clip Fraction: 0.20428
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.12015

Collected Steps per Second: 3,686.97254
Overall Steps per Second: 3,089.59917

Timestep Collection Time: 13.56180
Timestep Consumption Time: 2.62217
PPO Batch Consumption Time: 0.05170
Total Iteration Time: 16.18398

Cumulative Model Updates: 65,457
Cumulative Timesteps: 1,091,817,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,873,118.45274
Policy Entropy: 1.03539
Value Function Loss: 1.29467

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.11918

Collected Steps per Second: 3,724.36779
Overall Steps per Second: 3,127.18528

Timestep Collection Time: 13.42510
Timestep Consumption Time: 2.56372
PPO Batch Consumption Time: 0.05247
Total Iteration Time: 15.98882

Cumulative Model Updates: 65,460
Cumulative Timesteps: 1,091,867,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1091867782...
Checkpoint 1091867782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,043,817.37730
Policy Entropy: 1.02569
Value Function Loss: 1.21891

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.10332

Collected Steps per Second: 3,915.43591
Overall Steps per Second: 3,246.98540

Timestep Collection Time: 12.78172
Timestep Consumption Time: 2.63135
PPO Batch Consumption Time: 0.05091
Total Iteration Time: 15.41307

Cumulative Model Updates: 65,463
Cumulative Timesteps: 1,091,917,828

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473,644.67886
Policy Entropy: 1.02142
Value Function Loss: 1.24303

Mean KL Divergence: 0.03462
SB3 Clip Fraction: 0.20445
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.09413

Collected Steps per Second: 3,771.55597
Overall Steps per Second: 3,155.25836

Timestep Collection Time: 13.26932
Timestep Consumption Time: 2.59182
PPO Batch Consumption Time: 0.04941
Total Iteration Time: 15.86114

Cumulative Model Updates: 65,466
Cumulative Timesteps: 1,091,967,874

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1091967874...
Checkpoint 1091967874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395,292.47352
Policy Entropy: 1.03661
Value Function Loss: 1.28415

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.10638

Collected Steps per Second: 4,074.60841
Overall Steps per Second: 3,357.65149

Timestep Collection Time: 12.27701
Timestep Consumption Time: 2.62150
PPO Batch Consumption Time: 0.05904
Total Iteration Time: 14.89851

Cumulative Model Updates: 65,469
Cumulative Timesteps: 1,092,017,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094,023.90501
Policy Entropy: 1.03897
Value Function Loss: 1.34644

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.15508
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.11667

Collected Steps per Second: 3,896.28482
Overall Steps per Second: 3,311.82630

Timestep Collection Time: 12.84198
Timestep Consumption Time: 2.26630
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 15.10828

Cumulative Model Updates: 65,472
Cumulative Timesteps: 1,092,067,934

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1092067934...
Checkpoint 1092067934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,038,941.54496
Policy Entropy: 1.02554
Value Function Loss: 1.29896

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.06135
Value Function Update Magnitude: 0.12961

Collected Steps per Second: 3,745.60310
Overall Steps per Second: 3,207.13310

Timestep Collection Time: 13.36073
Timestep Consumption Time: 2.24324
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 15.60397

Cumulative Model Updates: 65,475
Cumulative Timesteps: 1,092,117,978

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030,171.59138
Policy Entropy: 1.00018
Value Function Loss: 1.26716

Mean KL Divergence: 0.03270
SB3 Clip Fraction: 0.19249
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 3,766.59718
Overall Steps per Second: 3,195.70221

Timestep Collection Time: 13.27671
Timestep Consumption Time: 2.37181
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 15.64852

Cumulative Model Updates: 65,478
Cumulative Timesteps: 1,092,167,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1092167986...
Checkpoint 1092167986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769,699.36067
Policy Entropy: 1.01020
Value Function Loss: 1.26625

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.11171

Collected Steps per Second: 4,027.09448
Overall Steps per Second: 3,320.65247

Timestep Collection Time: 12.42683
Timestep Consumption Time: 2.64371
PPO Batch Consumption Time: 0.04788
Total Iteration Time: 15.07053

Cumulative Model Updates: 65,481
Cumulative Timesteps: 1,092,218,030

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669,712.22577
Policy Entropy: 1.01385
Value Function Loss: 1.33756

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.16149
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.14289

Collected Steps per Second: 3,799.04860
Overall Steps per Second: 3,144.67391

Timestep Collection Time: 13.17014
Timestep Consumption Time: 2.74057
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 15.91071

Cumulative Model Updates: 65,484
Cumulative Timesteps: 1,092,268,064

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1092268064...
Checkpoint 1092268064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821,409.09196
Policy Entropy: 1.00364
Value Function Loss: 1.32917

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.14948

Collected Steps per Second: 3,907.03387
Overall Steps per Second: 3,228.90792

Timestep Collection Time: 12.80255
Timestep Consumption Time: 2.68875
PPO Batch Consumption Time: 0.04807
Total Iteration Time: 15.49131

Cumulative Model Updates: 65,487
Cumulative Timesteps: 1,092,318,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675,323.08677
Policy Entropy: 0.98830
Value Function Loss: 1.31796

Mean KL Divergence: 0.03093
SB3 Clip Fraction: 0.21151
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.15958

Collected Steps per Second: 3,742.87339
Overall Steps per Second: 3,132.06680

Timestep Collection Time: 13.35925
Timestep Consumption Time: 2.60528
PPO Batch Consumption Time: 0.05832
Total Iteration Time: 15.96454

Cumulative Model Updates: 65,490
Cumulative Timesteps: 1,092,368,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1092368086...
Checkpoint 1092368086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481,724.30018
Policy Entropy: 1.01658
Value Function Loss: 1.27820

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.06492
Value Function Update Magnitude: 0.15408

Collected Steps per Second: 3,611.19018
Overall Steps per Second: 3,019.51575

Timestep Collection Time: 13.84807
Timestep Consumption Time: 2.71353
PPO Batch Consumption Time: 0.05106
Total Iteration Time: 16.56160

Cumulative Model Updates: 65,493
Cumulative Timesteps: 1,092,418,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796,391.01457
Policy Entropy: 1.00756
Value Function Loss: 1.26134

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.13442

Collected Steps per Second: 3,722.01824
Overall Steps per Second: 3,099.14398

Timestep Collection Time: 13.44486
Timestep Consumption Time: 2.70218
PPO Batch Consumption Time: 0.05932
Total Iteration Time: 16.14704

Cumulative Model Updates: 65,496
Cumulative Timesteps: 1,092,468,136

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1092468136...
Checkpoint 1092468136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,039,572.60883
Policy Entropy: 1.00214
Value Function Loss: 1.28017

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.07130
Value Function Update Magnitude: 0.12601

Collected Steps per Second: 3,692.57490
Overall Steps per Second: 3,094.28510

Timestep Collection Time: 13.54177
Timestep Consumption Time: 2.61834
PPO Batch Consumption Time: 0.05410
Total Iteration Time: 16.16011

Cumulative Model Updates: 65,499
Cumulative Timesteps: 1,092,518,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080,186.38361
Policy Entropy: 0.98718
Value Function Loss: 1.25112

Mean KL Divergence: 0.03187
SB3 Clip Fraction: 0.20893
Policy Update Magnitude: 0.06535
Value Function Update Magnitude: 0.12677

Collected Steps per Second: 3,673.58600
Overall Steps per Second: 3,067.70081

Timestep Collection Time: 13.61939
Timestep Consumption Time: 2.68989
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 16.30928

Cumulative Model Updates: 65,502
Cumulative Timesteps: 1,092,568,172

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1092568172...
Checkpoint 1092568172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720,434.44215
Policy Entropy: 1.01189
Value Function Loss: 1.22606

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.13648

Collected Steps per Second: 3,776.05702
Overall Steps per Second: 3,156.27992

Timestep Collection Time: 13.25457
Timestep Consumption Time: 2.60271
PPO Batch Consumption Time: 0.05370
Total Iteration Time: 15.85728

Cumulative Model Updates: 65,505
Cumulative Timesteps: 1,092,618,222

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,075,298.30879
Policy Entropy: 1.02328
Value Function Loss: 1.23010

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.17230
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.12894

Collected Steps per Second: 3,624.69835
Overall Steps per Second: 3,068.04621

Timestep Collection Time: 13.80032
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 16.30419

Cumulative Model Updates: 65,508
Cumulative Timesteps: 1,092,668,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1092668244...
Checkpoint 1092668244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976,512.78396
Policy Entropy: 1.00502
Value Function Loss: 1.30135

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.13552

Collected Steps per Second: 3,698.88413
Overall Steps per Second: 3,127.14874

Timestep Collection Time: 13.52894
Timestep Consumption Time: 2.47349
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 16.00244

Cumulative Model Updates: 65,511
Cumulative Timesteps: 1,092,718,286

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,763,578.38335
Policy Entropy: 1.00173
Value Function Loss: 1.36770

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.15276
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.14745

Collected Steps per Second: 3,619.14919
Overall Steps per Second: 3,070.22185

Timestep Collection Time: 13.82424
Timestep Consumption Time: 2.47165
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 16.29589

Cumulative Model Updates: 65,514
Cumulative Timesteps: 1,092,768,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1092768318...
Checkpoint 1092768318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053,046.00149
Policy Entropy: 1.01363
Value Function Loss: 1.32595

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.13670

Collected Steps per Second: 3,872.59184
Overall Steps per Second: 3,273.99220

Timestep Collection Time: 12.91383
Timestep Consumption Time: 2.36110
PPO Batch Consumption Time: 0.05156
Total Iteration Time: 15.27493

Cumulative Model Updates: 65,517
Cumulative Timesteps: 1,092,818,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,281,678.79091
Policy Entropy: 1.02737
Value Function Loss: 1.33096

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.18213
Policy Update Magnitude: 0.06436
Value Function Update Magnitude: 0.12102

Collected Steps per Second: 3,786.29510
Overall Steps per Second: 3,166.71533

Timestep Collection Time: 13.21186
Timestep Consumption Time: 2.58495
PPO Batch Consumption Time: 0.06426
Total Iteration Time: 15.79681

Cumulative Model Updates: 65,520
Cumulative Timesteps: 1,092,868,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1092868352...
Checkpoint 1092868352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,913,945.24531
Policy Entropy: 1.00196
Value Function Loss: 1.30161

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.10418

Collected Steps per Second: 3,799.15487
Overall Steps per Second: 3,184.40389

Timestep Collection Time: 13.16661
Timestep Consumption Time: 2.54182
PPO Batch Consumption Time: 0.04969
Total Iteration Time: 15.70843

Cumulative Model Updates: 65,523
Cumulative Timesteps: 1,092,918,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552,969.65857
Policy Entropy: 1.00407
Value Function Loss: 1.27997

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.10042

Collected Steps per Second: 3,721.87091
Overall Steps per Second: 3,094.38908

Timestep Collection Time: 13.43518
Timestep Consumption Time: 2.72439
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 16.15957

Cumulative Model Updates: 65,526
Cumulative Timesteps: 1,092,968,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1092968378...
Checkpoint 1092968378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,113,280.51242
Policy Entropy: 1.02239
Value Function Loss: 1.18630

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.15920
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.09506

Collected Steps per Second: 3,789.73139
Overall Steps per Second: 3,181.56435

Timestep Collection Time: 13.19460
Timestep Consumption Time: 2.52219
PPO Batch Consumption Time: 0.06005
Total Iteration Time: 15.71680

Cumulative Model Updates: 65,529
Cumulative Timesteps: 1,093,018,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491,420.19434
Policy Entropy: 1.03614
Value Function Loss: 1.18241

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.16484
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.09605

Collected Steps per Second: 3,805.71887
Overall Steps per Second: 3,188.38775

Timestep Collection Time: 13.14180
Timestep Consumption Time: 2.54450
PPO Batch Consumption Time: 0.05008
Total Iteration Time: 15.68630

Cumulative Model Updates: 65,532
Cumulative Timesteps: 1,093,068,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1093068396...
Checkpoint 1093068396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846,808.71876
Policy Entropy: 1.00623
Value Function Loss: 1.18411

Mean KL Divergence: 0.02578
SB3 Clip Fraction: 0.17195
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.09358

Collected Steps per Second: 3,889.79616
Overall Steps per Second: 3,227.13138

Timestep Collection Time: 12.86031
Timestep Consumption Time: 2.64076
PPO Batch Consumption Time: 0.05247
Total Iteration Time: 15.50107

Cumulative Model Updates: 65,535
Cumulative Timesteps: 1,093,118,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305,979.97809
Policy Entropy: 1.02542
Value Function Loss: 1.21994

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.17268
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.09398

Collected Steps per Second: 3,680.20869
Overall Steps per Second: 3,077.81020

Timestep Collection Time: 13.58999
Timestep Consumption Time: 2.65987
PPO Batch Consumption Time: 0.06350
Total Iteration Time: 16.24986

Cumulative Model Updates: 65,538
Cumulative Timesteps: 1,093,168,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1093168434...
Checkpoint 1093168434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,165,485.96779
Policy Entropy: 1.01862
Value Function Loss: 1.23085

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.16721
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.09350

Collected Steps per Second: 3,666.96139
Overall Steps per Second: 3,069.55692

Timestep Collection Time: 13.64836
Timestep Consumption Time: 2.65628
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 16.30463

Cumulative Model Updates: 65,541
Cumulative Timesteps: 1,093,218,482

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694,186.63717
Policy Entropy: 1.01736
Value Function Loss: 1.25119

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.06634
Value Function Update Magnitude: 0.09497

Collected Steps per Second: 3,784.19523
Overall Steps per Second: 3,172.40912

Timestep Collection Time: 13.21443
Timestep Consumption Time: 2.54835
PPO Batch Consumption Time: 0.05831
Total Iteration Time: 15.76278

Cumulative Model Updates: 65,544
Cumulative Timesteps: 1,093,268,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1093268488...
Checkpoint 1093268488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638,106.83758
Policy Entropy: 0.99388
Value Function Loss: 1.24384

Mean KL Divergence: 0.02818
SB3 Clip Fraction: 0.19617
Policy Update Magnitude: 0.06601
Value Function Update Magnitude: 0.10421

Collected Steps per Second: 3,773.76191
Overall Steps per Second: 3,165.90509

Timestep Collection Time: 13.26051
Timestep Consumption Time: 2.54603
PPO Batch Consumption Time: 0.05129
Total Iteration Time: 15.80654

Cumulative Model Updates: 65,547
Cumulative Timesteps: 1,093,318,530

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,671,033.03745
Policy Entropy: 1.01024
Value Function Loss: 1.22861

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.09440

Collected Steps per Second: 4,144.97657
Overall Steps per Second: 3,411.43091

Timestep Collection Time: 12.06376
Timestep Consumption Time: 2.59402
PPO Batch Consumption Time: 0.05339
Total Iteration Time: 14.65778

Cumulative Model Updates: 65,550
Cumulative Timesteps: 1,093,368,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1093368534...
Checkpoint 1093368534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,250,168.10372
Policy Entropy: 1.01252
Value Function Loss: 1.23941

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.08895

Collected Steps per Second: 4,119.67971
Overall Steps per Second: 3,408.12831

Timestep Collection Time: 12.13784
Timestep Consumption Time: 2.53415
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 14.67198

Cumulative Model Updates: 65,553
Cumulative Timesteps: 1,093,418,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,481,216.82302
Policy Entropy: 0.99600
Value Function Loss: 1.21165

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.10461

Collected Steps per Second: 4,054.13253
Overall Steps per Second: 3,366.71260

Timestep Collection Time: 12.34345
Timestep Consumption Time: 2.52030
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 14.86376

Cumulative Model Updates: 65,556
Cumulative Timesteps: 1,093,468,580

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1093468580...
Checkpoint 1093468580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834,427.11708
Policy Entropy: 0.98042
Value Function Loss: 1.21952

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.19708
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.11389

Collected Steps per Second: 4,094.74012
Overall Steps per Second: 3,398.41372

Timestep Collection Time: 12.21958
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.06015
Total Iteration Time: 14.72334

Cumulative Model Updates: 65,559
Cumulative Timesteps: 1,093,518,616

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,259,525.67581
Policy Entropy: 1.00492
Value Function Loss: 1.21513

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.05683
Value Function Update Magnitude: 0.12164

Collected Steps per Second: 3,897.80946
Overall Steps per Second: 3,279.88005

Timestep Collection Time: 12.83028
Timestep Consumption Time: 2.41723
PPO Batch Consumption Time: 0.05329
Total Iteration Time: 15.24751

Cumulative Model Updates: 65,562
Cumulative Timesteps: 1,093,568,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1093568626...
Checkpoint 1093568626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349,356.63797
Policy Entropy: 1.01872
Value Function Loss: 1.22326

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.16241
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.12233

Collected Steps per Second: 3,868.20321
Overall Steps per Second: 3,222.75396

Timestep Collection Time: 12.93520
Timestep Consumption Time: 2.59065
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 15.52585

Cumulative Model Updates: 65,565
Cumulative Timesteps: 1,093,618,662

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,940,390.47016
Policy Entropy: 1.00876
Value Function Loss: 1.27276

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.11861

Collected Steps per Second: 3,906.13192
Overall Steps per Second: 3,228.83929

Timestep Collection Time: 12.81268
Timestep Consumption Time: 2.68763
PPO Batch Consumption Time: 0.05117
Total Iteration Time: 15.50031

Cumulative Model Updates: 65,568
Cumulative Timesteps: 1,093,668,710

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1093668710...
Checkpoint 1093668710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519,166.03999
Policy Entropy: 0.99437
Value Function Loss: 1.26683

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.18585
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.10004

Collected Steps per Second: 3,812.43119
Overall Steps per Second: 3,152.21357

Timestep Collection Time: 13.11761
Timestep Consumption Time: 2.74743
PPO Batch Consumption Time: 0.06293
Total Iteration Time: 15.86504

Cumulative Model Updates: 65,571
Cumulative Timesteps: 1,093,718,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736,703.70122
Policy Entropy: 1.00924
Value Function Loss: 1.25529

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.09034

Collected Steps per Second: 3,815.76909
Overall Steps per Second: 3,179.89396

Timestep Collection Time: 13.10404
Timestep Consumption Time: 2.62038
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 15.72442

Cumulative Model Updates: 65,574
Cumulative Timesteps: 1,093,768,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1093768722...
Checkpoint 1093768722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,143,494.71397
Policy Entropy: 1.01850
Value Function Loss: 1.15914

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.06500
Value Function Update Magnitude: 0.08875

Collected Steps per Second: 3,700.91521
Overall Steps per Second: 3,106.70416

Timestep Collection Time: 13.51666
Timestep Consumption Time: 2.58530
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 16.10195

Cumulative Model Updates: 65,577
Cumulative Timesteps: 1,093,818,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954,440.71790
Policy Entropy: 1.00607
Value Function Loss: 1.15472

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.09321

Collected Steps per Second: 3,774.50854
Overall Steps per Second: 3,154.71108

Timestep Collection Time: 13.25894
Timestep Consumption Time: 2.60495
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 15.86389

Cumulative Model Updates: 65,580
Cumulative Timesteps: 1,093,868,792

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1093868792...
Checkpoint 1093868792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814,791.09705
Policy Entropy: 0.98838
Value Function Loss: 1.21409

Mean KL Divergence: 0.02763
SB3 Clip Fraction: 0.19851
Policy Update Magnitude: 0.06316
Value Function Update Magnitude: 0.09976

Collected Steps per Second: 3,790.18212
Overall Steps per Second: 3,182.31450

Timestep Collection Time: 13.19989
Timestep Consumption Time: 2.52137
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 15.72126

Cumulative Model Updates: 65,583
Cumulative Timesteps: 1,093,918,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,916,616.85753
Policy Entropy: 1.00493
Value Function Loss: 1.22247

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.06400
Value Function Update Magnitude: 0.09932

Collected Steps per Second: 3,774.38222
Overall Steps per Second: 3,143.26987

Timestep Collection Time: 13.25674
Timestep Consumption Time: 2.66172
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 15.91846

Cumulative Model Updates: 65,586
Cumulative Timesteps: 1,093,968,858

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1093968858...
Checkpoint 1093968858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164,788.09588
Policy Entropy: 1.01594
Value Function Loss: 1.23488

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.17117
Policy Update Magnitude: 0.06877
Value Function Update Magnitude: 0.10716

Collected Steps per Second: 3,761.42779
Overall Steps per Second: 3,168.62886

Timestep Collection Time: 13.30293
Timestep Consumption Time: 2.48876
PPO Batch Consumption Time: 0.05940
Total Iteration Time: 15.79169

Cumulative Model Updates: 65,589
Cumulative Timesteps: 1,094,018,896

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111,639.16284
Policy Entropy: 0.99604
Value Function Loss: 1.19649

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.16327
Policy Update Magnitude: 0.06474
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 3,996.12135
Overall Steps per Second: 3,369.91467

Timestep Collection Time: 12.52064
Timestep Consumption Time: 2.32662
PPO Batch Consumption Time: 0.05836
Total Iteration Time: 14.84726

Cumulative Model Updates: 65,592
Cumulative Timesteps: 1,094,068,930

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1094068930...
Checkpoint 1094068930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,198,941.34970
Policy Entropy: 1.01433
Value Function Loss: 1.20855

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.15250
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.10386

Collected Steps per Second: 3,791.57780
Overall Steps per Second: 3,153.84311

Timestep Collection Time: 13.19556
Timestep Consumption Time: 2.66826
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 15.86382

Cumulative Model Updates: 65,595
Cumulative Timesteps: 1,094,118,962

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834,074.20522
Policy Entropy: 1.02078
Value Function Loss: 1.27366

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.06251
Value Function Update Magnitude: 0.09315

Collected Steps per Second: 3,916.93850
Overall Steps per Second: 3,266.99553

Timestep Collection Time: 12.76558
Timestep Consumption Time: 2.53961
PPO Batch Consumption Time: 0.04953
Total Iteration Time: 15.30519

Cumulative Model Updates: 65,598
Cumulative Timesteps: 1,094,168,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1094168964...
Checkpoint 1094168964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804,327.22636
Policy Entropy: 1.01770
Value Function Loss: 1.29499

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.07335
Value Function Update Magnitude: 0.09883

Collected Steps per Second: 3,735.49036
Overall Steps per Second: 3,118.75596

Timestep Collection Time: 13.38834
Timestep Consumption Time: 2.64755
PPO Batch Consumption Time: 0.05269
Total Iteration Time: 16.03588

Cumulative Model Updates: 65,601
Cumulative Timesteps: 1,094,218,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450,865.65817
Policy Entropy: 1.01516
Value Function Loss: 1.38683

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.07614
Value Function Update Magnitude: 0.12769

Collected Steps per Second: 3,785.09306
Overall Steps per Second: 3,126.14329

Timestep Collection Time: 13.21130
Timestep Consumption Time: 2.78477
PPO Batch Consumption Time: 0.05162
Total Iteration Time: 15.99607

Cumulative Model Updates: 65,604
Cumulative Timesteps: 1,094,268,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1094268982...
Checkpoint 1094268982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463,612.18945
Policy Entropy: 1.00943
Value Function Loss: 1.33730

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.08439
Value Function Update Magnitude: 0.13866

Collected Steps per Second: 3,875.07572
Overall Steps per Second: 3,236.51916

Timestep Collection Time: 12.90917
Timestep Consumption Time: 2.54694
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 15.45611

Cumulative Model Updates: 65,607
Cumulative Timesteps: 1,094,319,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239,556.40186
Policy Entropy: 0.99903
Value Function Loss: 1.36897

Mean KL Divergence: 0.02798
SB3 Clip Fraction: 0.17650
Policy Update Magnitude: 0.08355
Value Function Update Magnitude: 0.12819

Collected Steps per Second: 3,897.27990
Overall Steps per Second: 3,241.06183

Timestep Collection Time: 12.83100
Timestep Consumption Time: 2.59789
PPO Batch Consumption Time: 0.05862
Total Iteration Time: 15.42889

Cumulative Model Updates: 65,610
Cumulative Timesteps: 1,094,369,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1094369012...
Checkpoint 1094369012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,644.46050
Policy Entropy: 1.01840
Value Function Loss: 1.37339

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.07200
Value Function Update Magnitude: 0.12152

Collected Steps per Second: 3,710.27852
Overall Steps per Second: 3,110.31818

Timestep Collection Time: 13.48039
Timestep Consumption Time: 2.60028
PPO Batch Consumption Time: 0.05157
Total Iteration Time: 16.08067

Cumulative Model Updates: 65,613
Cumulative Timesteps: 1,094,419,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621,894.65794
Policy Entropy: 1.02708
Value Function Loss: 1.40121

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.18653
Policy Update Magnitude: 0.06711
Value Function Update Magnitude: 0.10597

Collected Steps per Second: 3,782.99693
Overall Steps per Second: 3,126.91235

Timestep Collection Time: 13.22655
Timestep Consumption Time: 2.77518
PPO Batch Consumption Time: 0.05071
Total Iteration Time: 16.00173

Cumulative Model Updates: 65,616
Cumulative Timesteps: 1,094,469,064

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1094469064...
Checkpoint 1094469064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865,653.44846
Policy Entropy: 1.00392
Value Function Loss: 1.40469

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.10686

Collected Steps per Second: 3,716.60001
Overall Steps per Second: 3,143.83354

Timestep Collection Time: 13.45369
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.05817
Total Iteration Time: 15.90479

Cumulative Model Updates: 65,619
Cumulative Timesteps: 1,094,519,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,377,372.38168
Policy Entropy: 0.99774
Value Function Loss: 1.29542

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.18511
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.09558

Collected Steps per Second: 3,638.38864
Overall Steps per Second: 3,071.31738

Timestep Collection Time: 13.75224
Timestep Consumption Time: 2.53914
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 16.29138

Cumulative Model Updates: 65,622
Cumulative Timesteps: 1,094,569,102

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1094569102...
Checkpoint 1094569102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707,849.06601
Policy Entropy: 1.01846
Value Function Loss: 1.25701

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.06543
Value Function Update Magnitude: 0.08757

Collected Steps per Second: 3,781.21025
Overall Steps per Second: 3,192.56893

Timestep Collection Time: 13.23703
Timestep Consumption Time: 2.44063
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 15.67766

Cumulative Model Updates: 65,625
Cumulative Timesteps: 1,094,619,154

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813,300.79902
Policy Entropy: 1.02535
Value Function Loss: 1.23431

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.07389
Value Function Update Magnitude: 0.09191

Collected Steps per Second: 3,891.78770
Overall Steps per Second: 3,215.42470

Timestep Collection Time: 12.85322
Timestep Consumption Time: 2.70367
PPO Batch Consumption Time: 0.06140
Total Iteration Time: 15.55689

Cumulative Model Updates: 65,628
Cumulative Timesteps: 1,094,669,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1094669176...
Checkpoint 1094669176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788,352.74434
Policy Entropy: 1.00856
Value Function Loss: 1.21358

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.16783
Policy Update Magnitude: 0.07153
Value Function Update Magnitude: 0.08939

Collected Steps per Second: 3,766.46102
Overall Steps per Second: 3,145.93816

Timestep Collection Time: 13.28674
Timestep Consumption Time: 2.62075
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 15.90750

Cumulative Model Updates: 65,631
Cumulative Timesteps: 1,094,719,220

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,359,011.79823
Policy Entropy: 0.99436
Value Function Loss: 1.24917

Mean KL Divergence: 0.03033
SB3 Clip Fraction: 0.21001
Policy Update Magnitude: 0.06458
Value Function Update Magnitude: 0.09145

Collected Steps per Second: 3,518.02208
Overall Steps per Second: 2,966.30108

Timestep Collection Time: 14.21424
Timestep Consumption Time: 2.64380
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 16.85803

Cumulative Model Updates: 65,634
Cumulative Timesteps: 1,094,769,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1094769226...
Checkpoint 1094769226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,186,530.59196
Policy Entropy: 1.00971
Value Function Loss: 1.29392

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.06679
Value Function Update Magnitude: 0.08404

Collected Steps per Second: 3,757.61271
Overall Steps per Second: 3,140.39972

Timestep Collection Time: 13.31697
Timestep Consumption Time: 2.61731
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 15.93428

Cumulative Model Updates: 65,637
Cumulative Timesteps: 1,094,819,266

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803,420.02586
Policy Entropy: 1.03284
Value Function Loss: 1.30049

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.16915
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.08222

Collected Steps per Second: 3,686.81292
Overall Steps per Second: 3,079.85635

Timestep Collection Time: 13.56510
Timestep Consumption Time: 2.67332
PPO Batch Consumption Time: 0.05980
Total Iteration Time: 16.23842

Cumulative Model Updates: 65,640
Cumulative Timesteps: 1,094,869,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1094869278...
Checkpoint 1094869278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,264,110.50463
Policy Entropy: 1.02296
Value Function Loss: 1.23170

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.08116

Collected Steps per Second: 3,884.07203
Overall Steps per Second: 3,190.27444

Timestep Collection Time: 12.87927
Timestep Consumption Time: 2.80089
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 15.68016

Cumulative Model Updates: 65,643
Cumulative Timesteps: 1,094,919,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,711,838.84491
Policy Entropy: 1.01836
Value Function Loss: 1.12760

Mean KL Divergence: 0.02493
SB3 Clip Fraction: 0.17989
Policy Update Magnitude: 0.07006
Value Function Update Magnitude: 0.09779

Collected Steps per Second: 4,049.84938
Overall Steps per Second: 3,357.18238

Timestep Collection Time: 12.34762
Timestep Consumption Time: 2.54761
PPO Batch Consumption Time: 0.04905
Total Iteration Time: 14.89523

Cumulative Model Updates: 65,646
Cumulative Timesteps: 1,094,969,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1094969308...
Checkpoint 1094969308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,239,005.12704
Policy Entropy: 1.03485
Value Function Loss: 1.15098

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 4,137.20227
Overall Steps per Second: 3,380.16409

Timestep Collection Time: 12.08546
Timestep Consumption Time: 2.70672
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 14.79218

Cumulative Model Updates: 65,649
Cumulative Timesteps: 1,095,019,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,076,136.66985
Policy Entropy: 1.03611
Value Function Loss: 1.18799

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.06661
Value Function Update Magnitude: 0.08657

Collected Steps per Second: 4,063.30284
Overall Steps per Second: 3,317.42709

Timestep Collection Time: 12.31363
Timestep Consumption Time: 2.76854
PPO Batch Consumption Time: 0.05429
Total Iteration Time: 15.08217

Cumulative Model Updates: 65,652
Cumulative Timesteps: 1,095,069,342

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1095069342...
Checkpoint 1095069342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,225,999.84000
Policy Entropy: 1.01437
Value Function Loss: 1.20759

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.15048
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.08165

Collected Steps per Second: 3,908.27364
Overall Steps per Second: 3,289.46596

Timestep Collection Time: 12.79695
Timestep Consumption Time: 2.40734
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 15.20429

Cumulative Model Updates: 65,655
Cumulative Timesteps: 1,095,119,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532,157.65573
Policy Entropy: 0.99467
Value Function Loss: 1.27029

Mean KL Divergence: 0.02898
SB3 Clip Fraction: 0.19532
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.07589

Collected Steps per Second: 3,698.68394
Overall Steps per Second: 3,160.21552

Timestep Collection Time: 13.52535
Timestep Consumption Time: 2.30458
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 15.82993

Cumulative Model Updates: 65,658
Cumulative Timesteps: 1,095,169,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1095169382...
Checkpoint 1095169382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697,156.25224
Policy Entropy: 1.00966
Value Function Loss: 1.23036

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 3,930.19308
Overall Steps per Second: 3,290.04828

Timestep Collection Time: 12.72711
Timestep Consumption Time: 2.47631
PPO Batch Consumption Time: 0.05831
Total Iteration Time: 15.20342

Cumulative Model Updates: 65,661
Cumulative Timesteps: 1,095,219,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499,228.11560
Policy Entropy: 1.01957
Value Function Loss: 1.21761

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.16861
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.08733

Collected Steps per Second: 3,659.77291
Overall Steps per Second: 3,112.46769

Timestep Collection Time: 13.66369
Timestep Consumption Time: 2.40266
PPO Batch Consumption Time: 0.05921
Total Iteration Time: 16.06635

Cumulative Model Updates: 65,664
Cumulative Timesteps: 1,095,269,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1095269408...
Checkpoint 1095269408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472,901.63377
Policy Entropy: 1.00768
Value Function Loss: 1.17625

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.08920

Collected Steps per Second: 3,745.57178
Overall Steps per Second: 3,100.31424

Timestep Collection Time: 13.35390
Timestep Consumption Time: 2.77930
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 16.13320

Cumulative Model Updates: 65,667
Cumulative Timesteps: 1,095,319,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388,899.90631
Policy Entropy: 1.01186
Value Function Loss: 1.29765

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.09376

Collected Steps per Second: 3,846.59598
Overall Steps per Second: 3,202.90237

Timestep Collection Time: 13.00786
Timestep Consumption Time: 2.61422
PPO Batch Consumption Time: 0.05346
Total Iteration Time: 15.62208

Cumulative Model Updates: 65,670
Cumulative Timesteps: 1,095,369,462

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1095369462...
Checkpoint 1095369462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559,984.76334
Policy Entropy: 1.01918
Value Function Loss: 1.39596

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.09027

Collected Steps per Second: 3,875.10221
Overall Steps per Second: 3,216.11795

Timestep Collection Time: 12.91372
Timestep Consumption Time: 2.64603
PPO Batch Consumption Time: 0.05094
Total Iteration Time: 15.55975

Cumulative Model Updates: 65,673
Cumulative Timesteps: 1,095,419,504

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733,284.66399
Policy Entropy: 1.01744
Value Function Loss: 1.41404

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.07367
Value Function Update Magnitude: 0.09811

Collected Steps per Second: 3,836.95690
Overall Steps per Second: 3,168.53108

Timestep Collection Time: 13.03689
Timestep Consumption Time: 2.75023
PPO Batch Consumption Time: 0.05362
Total Iteration Time: 15.78713

Cumulative Model Updates: 65,676
Cumulative Timesteps: 1,095,469,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1095469526...
Checkpoint 1095469526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836,569.63535
Policy Entropy: 1.01755
Value Function Loss: 1.29885

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.07894
Value Function Update Magnitude: 0.10389

Collected Steps per Second: 3,633.88283
Overall Steps per Second: 3,055.48867

Timestep Collection Time: 13.76544
Timestep Consumption Time: 2.60575
PPO Batch Consumption Time: 0.04890
Total Iteration Time: 16.37119

Cumulative Model Updates: 65,679
Cumulative Timesteps: 1,095,519,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723,564.98237
Policy Entropy: 1.01967
Value Function Loss: 1.28927

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.08985
Value Function Update Magnitude: 0.10524

Collected Steps per Second: 3,871.64153
Overall Steps per Second: 3,207.08565

Timestep Collection Time: 12.91597
Timestep Consumption Time: 2.67638
PPO Batch Consumption Time: 0.06073
Total Iteration Time: 15.59235

Cumulative Model Updates: 65,682
Cumulative Timesteps: 1,095,569,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1095569554...
Checkpoint 1095569554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014,659.58872
Policy Entropy: 1.01039
Value Function Loss: 1.29687

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.08437
Value Function Update Magnitude: 0.09548

Collected Steps per Second: 3,699.38492
Overall Steps per Second: 3,087.02697

Timestep Collection Time: 13.52711
Timestep Consumption Time: 2.68331
PPO Batch Consumption Time: 0.06254
Total Iteration Time: 16.21042

Cumulative Model Updates: 65,685
Cumulative Timesteps: 1,095,619,596

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835,088.15912
Policy Entropy: 1.02629
Value Function Loss: 1.30615

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.16771
Policy Update Magnitude: 0.07621
Value Function Update Magnitude: 0.08985

Collected Steps per Second: 3,839.92714
Overall Steps per Second: 3,217.07908

Timestep Collection Time: 13.02941
Timestep Consumption Time: 2.52258
PPO Batch Consumption Time: 0.05259
Total Iteration Time: 15.55200

Cumulative Model Updates: 65,688
Cumulative Timesteps: 1,095,669,628

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1095669628...
Checkpoint 1095669628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,901,264.41248
Policy Entropy: 1.03432
Value Function Loss: 1.34704

Mean KL Divergence: 0.02520
SB3 Clip Fraction: 0.18238
Policy Update Magnitude: 0.06977
Value Function Update Magnitude: 0.08860

Collected Steps per Second: 3,605.29565
Overall Steps per Second: 3,037.69661

Timestep Collection Time: 13.87903
Timestep Consumption Time: 2.59332
PPO Batch Consumption Time: 0.05131
Total Iteration Time: 16.47235

Cumulative Model Updates: 65,691
Cumulative Timesteps: 1,095,719,666

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,349,828.68544
Policy Entropy: 1.01974
Value Function Loss: 1.34316

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.09246

Collected Steps per Second: 3,822.02754
Overall Steps per Second: 3,251.67818

Timestep Collection Time: 13.08729
Timestep Consumption Time: 2.29553
PPO Batch Consumption Time: 0.05259
Total Iteration Time: 15.38283

Cumulative Model Updates: 65,694
Cumulative Timesteps: 1,095,769,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1095769686...
Checkpoint 1095769686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578,690.69110
Policy Entropy: 1.01572
Value Function Loss: 1.31089

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.16709
Policy Update Magnitude: 0.05922
Value Function Update Magnitude: 0.09654

Collected Steps per Second: 3,634.81003
Overall Steps per Second: 3,090.90514

Timestep Collection Time: 13.76248
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 16.18426

Cumulative Model Updates: 65,697
Cumulative Timesteps: 1,095,819,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935,050.65582
Policy Entropy: 1.02559
Value Function Loss: 1.27322

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.10089

Collected Steps per Second: 3,726.55880
Overall Steps per Second: 3,202.45233

Timestep Collection Time: 13.43008
Timestep Consumption Time: 2.19794
PPO Batch Consumption Time: 0.06142
Total Iteration Time: 15.62802

Cumulative Model Updates: 65,700
Cumulative Timesteps: 1,095,869,758

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1095869758...
Checkpoint 1095869758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,891,801.55428
Policy Entropy: 1.03826
Value Function Loss: 1.26926

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.17600
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.11635

Collected Steps per Second: 3,805.22107
Overall Steps per Second: 3,152.90693

Timestep Collection Time: 13.15193
Timestep Consumption Time: 2.72104
PPO Batch Consumption Time: 0.04798
Total Iteration Time: 15.87297

Cumulative Model Updates: 65,703
Cumulative Timesteps: 1,095,919,804

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922,807.31255
Policy Entropy: 1.00518
Value Function Loss: 1.33727

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.16588
Policy Update Magnitude: 0.06076
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 4,025.21274
Overall Steps per Second: 3,342.43380

Timestep Collection Time: 12.42468
Timestep Consumption Time: 2.53806
PPO Batch Consumption Time: 0.04853
Total Iteration Time: 14.96275

Cumulative Model Updates: 65,706
Cumulative Timesteps: 1,095,969,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1095969816...
Checkpoint 1095969816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120,264.57835
Policy Entropy: 1.03094
Value Function Loss: 1.32982

Mean KL Divergence: 0.02657
SB3 Clip Fraction: 0.17400
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.09882

Collected Steps per Second: 3,722.40802
Overall Steps per Second: 3,097.92575

Timestep Collection Time: 13.44130
Timestep Consumption Time: 2.70951
PPO Batch Consumption Time: 0.04684
Total Iteration Time: 16.15081

Cumulative Model Updates: 65,709
Cumulative Timesteps: 1,096,019,850

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753,854.35420
Policy Entropy: 1.03111
Value Function Loss: 1.32391

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.16976
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.09939

Collected Steps per Second: 3,770.37252
Overall Steps per Second: 3,131.75868

Timestep Collection Time: 13.26341
Timestep Consumption Time: 2.70461
PPO Batch Consumption Time: 0.05212
Total Iteration Time: 15.96802

Cumulative Model Updates: 65,712
Cumulative Timesteps: 1,096,069,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1096069858...
Checkpoint 1096069858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673,989.31083
Policy Entropy: 1.02910
Value Function Loss: 1.31507

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.15530
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.11874

Collected Steps per Second: 3,668.93923
Overall Steps per Second: 3,061.44843

Timestep Collection Time: 13.63446
Timestep Consumption Time: 2.70552
PPO Batch Consumption Time: 0.05013
Total Iteration Time: 16.33998

Cumulative Model Updates: 65,715
Cumulative Timesteps: 1,096,119,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421,354.90032
Policy Entropy: 1.01251
Value Function Loss: 1.35967

Mean KL Divergence: 0.02593
SB3 Clip Fraction: 0.18206
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.13650

Collected Steps per Second: 3,647.47195
Overall Steps per Second: 3,078.13411

Timestep Collection Time: 13.71251
Timestep Consumption Time: 2.53629
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 16.24880

Cumulative Model Updates: 65,718
Cumulative Timesteps: 1,096,169,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1096169898...
Checkpoint 1096169898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412,917.31943
Policy Entropy: 1.02924
Value Function Loss: 1.41530

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.06277
Value Function Update Magnitude: 0.12474

Collected Steps per Second: 3,959.46631
Overall Steps per Second: 3,296.43752

Timestep Collection Time: 12.63100
Timestep Consumption Time: 2.54053
PPO Batch Consumption Time: 0.05335
Total Iteration Time: 15.17153

Cumulative Model Updates: 65,721
Cumulative Timesteps: 1,096,219,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928,097.97358
Policy Entropy: 1.04662
Value Function Loss: 1.38469

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.15676
Policy Update Magnitude: 0.06764
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 3,959.42718
Overall Steps per Second: 3,319.45797

Timestep Collection Time: 12.63213
Timestep Consumption Time: 2.43539
PPO Batch Consumption Time: 0.05409
Total Iteration Time: 15.06752

Cumulative Model Updates: 65,724
Cumulative Timesteps: 1,096,269,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1096269926...
Checkpoint 1096269926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264,156.00649
Policy Entropy: 1.02842
Value Function Loss: 1.38134

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.14994
Policy Update Magnitude: 0.06234
Value Function Update Magnitude: 0.12082

Collected Steps per Second: 3,708.31546
Overall Steps per Second: 3,177.36402

Timestep Collection Time: 13.48375
Timestep Consumption Time: 2.25319
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 15.73694

Cumulative Model Updates: 65,727
Cumulative Timesteps: 1,096,319,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332,221.65830
Policy Entropy: 1.01997
Value Function Loss: 1.34809

Mean KL Divergence: 0.02711
SB3 Clip Fraction: 0.19087
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.12879

Collected Steps per Second: 3,586.64696
Overall Steps per Second: 3,061.81465

Timestep Collection Time: 13.95565
Timestep Consumption Time: 2.39217
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 16.34782

Cumulative Model Updates: 65,730
Cumulative Timesteps: 1,096,369,982

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1096369982...
Checkpoint 1096369982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503,016.11073
Policy Entropy: 1.02989
Value Function Loss: 1.37725

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.12554

Collected Steps per Second: 3,875.15911
Overall Steps per Second: 3,184.46635

Timestep Collection Time: 12.90734
Timestep Consumption Time: 2.79953
PPO Batch Consumption Time: 0.05388
Total Iteration Time: 15.70687

Cumulative Model Updates: 65,733
Cumulative Timesteps: 1,096,420,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654,057.22222
Policy Entropy: 1.03123
Value Function Loss: 1.34514

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.11310

Collected Steps per Second: 3,681.13376
Overall Steps per Second: 3,123.73559

Timestep Collection Time: 13.59092
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.04975
Total Iteration Time: 16.01608

Cumulative Model Updates: 65,736
Cumulative Timesteps: 1,096,470,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1096470030...
Checkpoint 1096470030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,166,552.02618
Policy Entropy: 1.02110
Value Function Loss: 1.31538

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.06561
Value Function Update Magnitude: 0.11386

Collected Steps per Second: 3,817.74367
Overall Steps per Second: 3,178.71603

Timestep Collection Time: 13.10669
Timestep Consumption Time: 2.63488
PPO Batch Consumption Time: 0.05901
Total Iteration Time: 15.74158

Cumulative Model Updates: 65,739
Cumulative Timesteps: 1,096,520,068

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210,951.71678
Policy Entropy: 1.01767
Value Function Loss: 1.33192

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.08266
Value Function Update Magnitude: 0.11372

Collected Steps per Second: 3,828.26538
Overall Steps per Second: 3,163.33557

Timestep Collection Time: 13.06179
Timestep Consumption Time: 2.74557
PPO Batch Consumption Time: 0.05782
Total Iteration Time: 15.80736

Cumulative Model Updates: 65,742
Cumulative Timesteps: 1,096,570,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1096570072...
Checkpoint 1096570072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518,199.26786
Policy Entropy: 1.02505
Value Function Loss: 1.31691

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.08134
Value Function Update Magnitude: 0.11849

Collected Steps per Second: 3,851.19043
Overall Steps per Second: 3,205.43937

Timestep Collection Time: 12.98508
Timestep Consumption Time: 2.61591
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 15.60098

Cumulative Model Updates: 65,745
Cumulative Timesteps: 1,096,620,080

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602,032.07077
Policy Entropy: 1.02318
Value Function Loss: 1.29652

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.08260
Value Function Update Magnitude: 0.12048

Collected Steps per Second: 3,687.27483
Overall Steps per Second: 3,093.02043

Timestep Collection Time: 13.57263
Timestep Consumption Time: 2.60768
PPO Batch Consumption Time: 0.05294
Total Iteration Time: 16.18030

Cumulative Model Updates: 65,748
Cumulative Timesteps: 1,096,670,126

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1096670126...
Checkpoint 1096670126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733,618.55310
Policy Entropy: 1.02557
Value Function Loss: 1.21612

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.07562
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 3,775.09627
Overall Steps per Second: 3,156.10123

Timestep Collection Time: 13.25052
Timestep Consumption Time: 2.59878
PPO Batch Consumption Time: 0.05431
Total Iteration Time: 15.84930

Cumulative Model Updates: 65,751
Cumulative Timesteps: 1,096,720,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020,460.69415
Policy Entropy: 1.03263
Value Function Loss: 1.21033

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.16192
Policy Update Magnitude: 0.07010
Value Function Update Magnitude: 0.12853

Collected Steps per Second: 3,681.46672
Overall Steps per Second: 3,135.32448

Timestep Collection Time: 13.58969
Timestep Consumption Time: 2.36719
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 15.95688

Cumulative Model Updates: 65,754
Cumulative Timesteps: 1,096,770,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1096770178...
Checkpoint 1096770178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416,318.29323
Policy Entropy: 1.03554
Value Function Loss: 1.26460

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.18568
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.12765

Collected Steps per Second: 3,975.01685
Overall Steps per Second: 3,355.15836

Timestep Collection Time: 12.58510
Timestep Consumption Time: 2.32507
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 14.91018

Cumulative Model Updates: 65,757
Cumulative Timesteps: 1,096,820,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,826,430.06487
Policy Entropy: 1.02117
Value Function Loss: 1.22994

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.06811
Value Function Update Magnitude: 0.12176

Collected Steps per Second: 3,620.47394
Overall Steps per Second: 3,093.12175

Timestep Collection Time: 13.82250
Timestep Consumption Time: 2.35662
PPO Batch Consumption Time: 0.05218
Total Iteration Time: 16.17912

Cumulative Model Updates: 65,760
Cumulative Timesteps: 1,096,870,248

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1096870248...
Checkpoint 1096870248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678,455.52251
Policy Entropy: 1.00287
Value Function Loss: 1.24165

Mean KL Divergence: 0.03211
SB3 Clip Fraction: 0.20765
Policy Update Magnitude: 0.06263
Value Function Update Magnitude: 0.11118

Collected Steps per Second: 3,845.85339
Overall Steps per Second: 3,285.45475

Timestep Collection Time: 13.00466
Timestep Consumption Time: 2.21820
PPO Batch Consumption Time: 0.05186
Total Iteration Time: 15.22285

Cumulative Model Updates: 65,763
Cumulative Timesteps: 1,096,920,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414,311.22628
Policy Entropy: 1.01929
Value Function Loss: 1.18883

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.11017

Collected Steps per Second: 3,685.00489
Overall Steps per Second: 3,075.32325

Timestep Collection Time: 13.57882
Timestep Consumption Time: 2.69199
PPO Batch Consumption Time: 0.05355
Total Iteration Time: 16.27081

Cumulative Model Updates: 65,766
Cumulative Timesteps: 1,096,970,300

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1096970300...
Checkpoint 1096970300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,160,950.73149
Policy Entropy: 1.01630
Value Function Loss: 1.23251

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.06237
Value Function Update Magnitude: 0.12541

Collected Steps per Second: 3,749.05613
Overall Steps per Second: 3,132.74036

Timestep Collection Time: 13.33776
Timestep Consumption Time: 2.62399
PPO Batch Consumption Time: 0.05161
Total Iteration Time: 15.96174

Cumulative Model Updates: 65,769
Cumulative Timesteps: 1,097,020,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,875,030.72649
Policy Entropy: 1.00595
Value Function Loss: 1.25245

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.06874
Value Function Update Magnitude: 0.12097

Collected Steps per Second: 3,871.97476
Overall Steps per Second: 3,219.43676

Timestep Collection Time: 12.92415
Timestep Consumption Time: 2.61956
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 15.54371

Cumulative Model Updates: 65,772
Cumulative Timesteps: 1,097,070,346

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1097070346...
Checkpoint 1097070346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871,631.41499
Policy Entropy: 1.01862
Value Function Loss: 1.25393

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.15925
Policy Update Magnitude: 0.06368
Value Function Update Magnitude: 0.11927

Collected Steps per Second: 4,053.79074
Overall Steps per Second: 3,347.96382

Timestep Collection Time: 12.33463
Timestep Consumption Time: 2.60042
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 14.93505

Cumulative Model Updates: 65,775
Cumulative Timesteps: 1,097,120,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634,717.95106
Policy Entropy: 1.01890
Value Function Loss: 1.26973

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.12936

Collected Steps per Second: 4,031.81831
Overall Steps per Second: 3,307.61771

Timestep Collection Time: 12.40532
Timestep Consumption Time: 2.71614
PPO Batch Consumption Time: 0.05784
Total Iteration Time: 15.12146

Cumulative Model Updates: 65,778
Cumulative Timesteps: 1,097,170,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1097170364...
Checkpoint 1097170364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781,596.96932
Policy Entropy: 1.02245
Value Function Loss: 1.24990

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12619
Policy Update Magnitude: 0.06753
Value Function Update Magnitude: 0.12728

Collected Steps per Second: 4,074.69743
Overall Steps per Second: 3,343.88256

Timestep Collection Time: 12.28018
Timestep Consumption Time: 2.68387
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 14.96404

Cumulative Model Updates: 65,781
Cumulative Timesteps: 1,097,220,402

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391,339.43830
Policy Entropy: 1.02884
Value Function Loss: 1.27669

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.07052
Value Function Update Magnitude: 0.11692

Collected Steps per Second: 4,105.85655
Overall Steps per Second: 3,386.12095

Timestep Collection Time: 12.18503
Timestep Consumption Time: 2.58999
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 14.77502

Cumulative Model Updates: 65,784
Cumulative Timesteps: 1,097,270,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1097270432...
Checkpoint 1097270432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,419,036.16736
Policy Entropy: 1.02547
Value Function Loss: 1.26988

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.06808
Value Function Update Magnitude: 0.11060

Collected Steps per Second: 3,934.07991
Overall Steps per Second: 3,307.10952

Timestep Collection Time: 12.71047
Timestep Consumption Time: 2.40968
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 15.12015

Cumulative Model Updates: 65,787
Cumulative Timesteps: 1,097,320,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,149,713.10005
Policy Entropy: 1.01368
Value Function Loss: 1.24160

Mean KL Divergence: 0.02783
SB3 Clip Fraction: 0.18193
Policy Update Magnitude: 0.06518
Value Function Update Magnitude: 0.11978

Collected Steps per Second: 3,961.19750
Overall Steps per Second: 3,260.90646

Timestep Collection Time: 12.62346
Timestep Consumption Time: 2.71093
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 15.33439

Cumulative Model Updates: 65,790
Cumulative Timesteps: 1,097,370,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1097370440...
Checkpoint 1097370440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660,246.97053
Policy Entropy: 1.03004
Value Function Loss: 1.21083

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.16174
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 3,805.71031
Overall Steps per Second: 3,226.00701

Timestep Collection Time: 13.14078
Timestep Consumption Time: 2.36136
PPO Batch Consumption Time: 0.06230
Total Iteration Time: 15.50214

Cumulative Model Updates: 65,793
Cumulative Timesteps: 1,097,420,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440,304.15808
Policy Entropy: 1.03389
Value Function Loss: 1.18858

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.17758
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.11237

Collected Steps per Second: 3,814.48710
Overall Steps per Second: 3,240.28132

Timestep Collection Time: 13.11526
Timestep Consumption Time: 2.32414
PPO Batch Consumption Time: 0.05254
Total Iteration Time: 15.43940

Cumulative Model Updates: 65,796
Cumulative Timesteps: 1,097,470,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1097470478...
Checkpoint 1097470478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,147,232.60716
Policy Entropy: 1.02069
Value Function Loss: 1.24109

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.10860

Collected Steps per Second: 3,751.73648
Overall Steps per Second: 3,197.42187

Timestep Collection Time: 13.33249
Timestep Consumption Time: 2.31136
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 15.64385

Cumulative Model Updates: 65,799
Cumulative Timesteps: 1,097,520,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326,041.51502
Policy Entropy: 1.01209
Value Function Loss: 1.28646

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.18451
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.11019

Collected Steps per Second: 3,896.86853
Overall Steps per Second: 3,246.76924

Timestep Collection Time: 12.84005
Timestep Consumption Time: 2.57096
PPO Batch Consumption Time: 0.05944
Total Iteration Time: 15.41101

Cumulative Model Updates: 65,802
Cumulative Timesteps: 1,097,570,534

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1097570534...
Checkpoint 1097570534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246,401.02002
Policy Entropy: 1.02844
Value Function Loss: 1.26518

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.05876
Value Function Update Magnitude: 0.11052

Collected Steps per Second: 4,138.68631
Overall Steps per Second: 3,378.74984

Timestep Collection Time: 12.08403
Timestep Consumption Time: 2.71790
PPO Batch Consumption Time: 0.05351
Total Iteration Time: 14.80192

Cumulative Model Updates: 65,805
Cumulative Timesteps: 1,097,620,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071,018.62472
Policy Entropy: 1.03138
Value Function Loss: 1.29765

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14749
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.11262

Collected Steps per Second: 4,054.80014
Overall Steps per Second: 3,304.36005

Timestep Collection Time: 12.33452
Timestep Consumption Time: 2.80124
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 15.13576

Cumulative Model Updates: 65,808
Cumulative Timesteps: 1,097,670,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1097670560...
Checkpoint 1097670560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800,119.90508
Policy Entropy: 1.01505
Value Function Loss: 1.27046

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.15838
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.11688

Collected Steps per Second: 3,945.16224
Overall Steps per Second: 3,261.15220

Timestep Collection Time: 12.68288
Timestep Consumption Time: 2.66017
PPO Batch Consumption Time: 0.05852
Total Iteration Time: 15.34304

Cumulative Model Updates: 65,811
Cumulative Timesteps: 1,097,720,596

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679,759.05893
Policy Entropy: 1.01469
Value Function Loss: 1.34200

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.17535
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.10765

Collected Steps per Second: 3,841.55264
Overall Steps per Second: 3,227.52244

Timestep Collection Time: 13.02026
Timestep Consumption Time: 2.47708
PPO Batch Consumption Time: 0.05848
Total Iteration Time: 15.49734

Cumulative Model Updates: 65,814
Cumulative Timesteps: 1,097,770,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1097770614...
Checkpoint 1097770614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,795,129.68664
Policy Entropy: 1.02423
Value Function Loss: 1.30125

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.10027

Collected Steps per Second: 3,727.96439
Overall Steps per Second: 3,116.14877

Timestep Collection Time: 13.41483
Timestep Consumption Time: 2.63383
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 16.04866

Cumulative Model Updates: 65,817
Cumulative Timesteps: 1,097,820,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070,718.27022
Policy Entropy: 1.02413
Value Function Loss: 1.26136

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.17103
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.10045

Collected Steps per Second: 3,860.72441
Overall Steps per Second: 3,211.87768

Timestep Collection Time: 12.96389
Timestep Consumption Time: 2.61890
PPO Batch Consumption Time: 0.05888
Total Iteration Time: 15.58279

Cumulative Model Updates: 65,820
Cumulative Timesteps: 1,097,870,674

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1097870674...
Checkpoint 1097870674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541,087.31648
Policy Entropy: 0.99386
Value Function Loss: 1.19059

Mean KL Divergence: 0.02764
SB3 Clip Fraction: 0.17955
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.11995

Collected Steps per Second: 3,745.11051
Overall Steps per Second: 3,151.89226

Timestep Collection Time: 13.36569
Timestep Consumption Time: 2.51556
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 15.88125

Cumulative Model Updates: 65,823
Cumulative Timesteps: 1,097,920,730

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431,036.59646
Policy Entropy: 1.01508
Value Function Loss: 1.20400

Mean KL Divergence: 0.02667
SB3 Clip Fraction: 0.17761
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.13680

Collected Steps per Second: 4,003.63714
Overall Steps per Second: 3,303.10670

Timestep Collection Time: 12.49764
Timestep Consumption Time: 2.65053
PPO Batch Consumption Time: 0.05858
Total Iteration Time: 15.14816

Cumulative Model Updates: 65,826
Cumulative Timesteps: 1,097,970,766

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1097970766...
Checkpoint 1097970766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,202,633.51602
Policy Entropy: 1.01098
Value Function Loss: 1.21501

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.16931
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.12345

Collected Steps per Second: 3,655.75245
Overall Steps per Second: 3,060.93653

Timestep Collection Time: 13.68583
Timestep Consumption Time: 2.65950
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 16.34532

Cumulative Model Updates: 65,829
Cumulative Timesteps: 1,098,020,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,101,013.41644
Policy Entropy: 0.99732
Value Function Loss: 1.28686

Mean KL Divergence: 0.03073
SB3 Clip Fraction: 0.17485
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.10200

Collected Steps per Second: 3,805.39496
Overall Steps per Second: 3,204.04002

Timestep Collection Time: 13.15133
Timestep Consumption Time: 2.46833
PPO Batch Consumption Time: 0.04877
Total Iteration Time: 15.61966

Cumulative Model Updates: 65,832
Cumulative Timesteps: 1,098,070,844

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1098070844...
Checkpoint 1098070844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532,294.98314
Policy Entropy: 0.99469
Value Function Loss: 1.29498

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.18317
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.11203

Collected Steps per Second: 3,576.48512
Overall Steps per Second: 3,045.31060

Timestep Collection Time: 13.98971
Timestep Consumption Time: 2.44014
PPO Batch Consumption Time: 0.06134
Total Iteration Time: 16.42985

Cumulative Model Updates: 65,835
Cumulative Timesteps: 1,098,120,878

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584,392.95632
Policy Entropy: 1.01376
Value Function Loss: 1.32825

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.13225

Collected Steps per Second: 3,810.14339
Overall Steps per Second: 3,237.77856

Timestep Collection Time: 13.13389
Timestep Consumption Time: 2.32177
PPO Batch Consumption Time: 0.04939
Total Iteration Time: 15.45566

Cumulative Model Updates: 65,838
Cumulative Timesteps: 1,098,170,920

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1098170920...
Checkpoint 1098170920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167,671.34714
Policy Entropy: 1.01812
Value Function Loss: 1.27938

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.17243
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.13005

Collected Steps per Second: 3,728.05985
Overall Steps per Second: 3,160.23611

Timestep Collection Time: 13.41878
Timestep Consumption Time: 2.41105
PPO Batch Consumption Time: 0.05843
Total Iteration Time: 15.82983

Cumulative Model Updates: 65,841
Cumulative Timesteps: 1,098,220,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,839,238.65698
Policy Entropy: 1.00184
Value Function Loss: 1.22718

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.13406

Collected Steps per Second: 3,846.52174
Overall Steps per Second: 3,197.39417

Timestep Collection Time: 13.00240
Timestep Consumption Time: 2.63972
PPO Batch Consumption Time: 0.06053
Total Iteration Time: 15.64211

Cumulative Model Updates: 65,844
Cumulative Timesteps: 1,098,270,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1098270960...
Checkpoint 1098270960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,895,572.79980
Policy Entropy: 0.98737
Value Function Loss: 1.20768

Mean KL Divergence: 0.03094
SB3 Clip Fraction: 0.19686
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.12956

Collected Steps per Second: 3,847.39962
Overall Steps per Second: 3,175.52766

Timestep Collection Time: 13.00463
Timestep Consumption Time: 2.75149
PPO Batch Consumption Time: 0.06474
Total Iteration Time: 15.75612

Cumulative Model Updates: 65,847
Cumulative Timesteps: 1,098,320,994

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932,354.70925
Policy Entropy: 1.00789
Value Function Loss: 1.19078

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.12813

Collected Steps per Second: 3,790.56116
Overall Steps per Second: 3,161.42771

Timestep Collection Time: 13.20279
Timestep Consumption Time: 2.62740
PPO Batch Consumption Time: 0.04808
Total Iteration Time: 15.83019

Cumulative Model Updates: 65,850
Cumulative Timesteps: 1,098,371,040

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1098371040...
Checkpoint 1098371040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,594,243.80809
Policy Entropy: 1.01578
Value Function Loss: 1.20318

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.12414

Collected Steps per Second: 3,729.47743
Overall Steps per Second: 2,998.37644

Timestep Collection Time: 13.41046
Timestep Consumption Time: 3.26990
PPO Batch Consumption Time: 0.05387
Total Iteration Time: 16.68036

Cumulative Model Updates: 65,853
Cumulative Timesteps: 1,098,421,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,965,491.59737
Policy Entropy: 1.00085
Value Function Loss: 1.15185

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.05930
Value Function Update Magnitude: 0.11466

Collected Steps per Second: 3,645.59736
Overall Steps per Second: 3,068.88532

Timestep Collection Time: 13.72176
Timestep Consumption Time: 2.57862
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 16.30038

Cumulative Model Updates: 65,856
Cumulative Timesteps: 1,098,471,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1098471078...
Checkpoint 1098471078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,526,853.49581
Policy Entropy: 0.98898
Value Function Loss: 1.17611

Mean KL Divergence: 0.03270
SB3 Clip Fraction: 0.20111
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.10347

Collected Steps per Second: 3,823.25633
Overall Steps per Second: 3,184.79229

Timestep Collection Time: 13.07786
Timestep Consumption Time: 2.62175
PPO Batch Consumption Time: 0.06140
Total Iteration Time: 15.69961

Cumulative Model Updates: 65,859
Cumulative Timesteps: 1,098,521,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730,674.47723
Policy Entropy: 1.00999
Value Function Loss: 1.18382

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.09220

Collected Steps per Second: 3,770.53825
Overall Steps per Second: 3,144.68699

Timestep Collection Time: 13.26389
Timestep Consumption Time: 2.63976
PPO Batch Consumption Time: 0.05943
Total Iteration Time: 15.90365

Cumulative Model Updates: 65,862
Cumulative Timesteps: 1,098,571,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1098571090...
Checkpoint 1098571090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537,475.92405
Policy Entropy: 0.99772
Value Function Loss: 1.22943

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.05930
Value Function Update Magnitude: 0.08757

Collected Steps per Second: 3,964.85820
Overall Steps per Second: 3,296.42625

Timestep Collection Time: 12.61281
Timestep Consumption Time: 2.55756
PPO Batch Consumption Time: 0.05291
Total Iteration Time: 15.17037

Cumulative Model Updates: 65,865
Cumulative Timesteps: 1,098,621,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617,056.40536
Policy Entropy: 0.98607
Value Function Loss: 1.21697

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.16555
Policy Update Magnitude: 0.06705
Value Function Update Magnitude: 0.09454

Collected Steps per Second: 3,640.70043
Overall Steps per Second: 3,075.66594

Timestep Collection Time: 13.74296
Timestep Consumption Time: 2.52474
PPO Batch Consumption Time: 0.05028
Total Iteration Time: 16.26770

Cumulative Model Updates: 65,868
Cumulative Timesteps: 1,098,671,132

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1098671132...
Checkpoint 1098671132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356,088.48030
Policy Entropy: 0.99548
Value Function Loss: 1.19521

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.17629
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.09104

Collected Steps per Second: 4,055.21650
Overall Steps per Second: 3,350.49821

Timestep Collection Time: 12.33818
Timestep Consumption Time: 2.59512
PPO Batch Consumption Time: 0.06126
Total Iteration Time: 14.93330

Cumulative Model Updates: 65,871
Cumulative Timesteps: 1,098,721,166

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662,866.24481
Policy Entropy: 1.01162
Value Function Loss: 1.15499

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.19737
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.09538

Collected Steps per Second: 3,524.37706
Overall Steps per Second: 3,002.25332

Timestep Collection Time: 14.19882
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.06835
Total Iteration Time: 16.66815

Cumulative Model Updates: 65,874
Cumulative Timesteps: 1,098,771,208

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1098771208...
Checkpoint 1098771208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531,157.98619
Policy Entropy: 0.99287
Value Function Loss: 1.18378

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.05993
Value Function Update Magnitude: 0.10328

Collected Steps per Second: 4,085.62792
Overall Steps per Second: 3,331.93086

Timestep Collection Time: 12.24194
Timestep Consumption Time: 2.76918
PPO Batch Consumption Time: 0.05903
Total Iteration Time: 15.01112

Cumulative Model Updates: 65,877
Cumulative Timesteps: 1,098,821,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400,312.71384
Policy Entropy: 0.98179
Value Function Loss: 1.16059

Mean KL Divergence: 0.02716
SB3 Clip Fraction: 0.19565
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.12098

Collected Steps per Second: 3,724.39814
Overall Steps per Second: 3,102.97806

Timestep Collection Time: 13.43573
Timestep Consumption Time: 2.69072
PPO Batch Consumption Time: 0.05862
Total Iteration Time: 16.12644

Cumulative Model Updates: 65,880
Cumulative Timesteps: 1,098,871,264

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1098871264...
Checkpoint 1098871264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120,599.26626
Policy Entropy: 0.98939
Value Function Loss: 1.16556

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.11658

Collected Steps per Second: 3,946.21998
Overall Steps per Second: 3,312.53768

Timestep Collection Time: 12.67846
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.05310
Total Iteration Time: 15.10383

Cumulative Model Updates: 65,883
Cumulative Timesteps: 1,098,921,296

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,055,339.45989
Policy Entropy: 1.00373
Value Function Loss: 1.13686

Mean KL Divergence: 0.02269
SB3 Clip Fraction: 0.19013
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.10323

Collected Steps per Second: 3,683.07840
Overall Steps per Second: 3,119.22214

Timestep Collection Time: 13.57723
Timestep Consumption Time: 2.45433
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 16.03156

Cumulative Model Updates: 65,886
Cumulative Timesteps: 1,098,971,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1098971302...
Checkpoint 1098971302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757,703.77782
Policy Entropy: 0.98614
Value Function Loss: 1.14699

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.09567

Collected Steps per Second: 3,805.37202
Overall Steps per Second: 3,177.83156

Timestep Collection Time: 13.13985
Timestep Consumption Time: 2.59478
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 15.73463

Cumulative Model Updates: 65,889
Cumulative Timesteps: 1,099,021,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,580,447.89950
Policy Entropy: 0.98372
Value Function Loss: 1.13628

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.15685
Policy Update Magnitude: 0.06706
Value Function Update Magnitude: 0.08845

Collected Steps per Second: 3,716.82815
Overall Steps per Second: 3,120.31169

Timestep Collection Time: 13.46202
Timestep Consumption Time: 2.57356
PPO Batch Consumption Time: 0.04996
Total Iteration Time: 16.03558

Cumulative Model Updates: 65,892
Cumulative Timesteps: 1,099,071,340

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1099071340...
Checkpoint 1099071340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223,620.31384
Policy Entropy: 1.01467
Value Function Loss: 1.14722

Mean KL Divergence: 0.02553
SB3 Clip Fraction: 0.17941
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.08811

Collected Steps per Second: 4,054.42293
Overall Steps per Second: 3,353.98868

Timestep Collection Time: 12.33813
Timestep Consumption Time: 2.57665
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 14.91478

Cumulative Model Updates: 65,895
Cumulative Timesteps: 1,099,121,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749,790.34236
Policy Entropy: 1.01161
Value Function Loss: 1.21072

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.17111
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.08023

Collected Steps per Second: 3,814.94897
Overall Steps per Second: 3,184.89473

Timestep Collection Time: 13.11210
Timestep Consumption Time: 2.59391
PPO Batch Consumption Time: 0.05030
Total Iteration Time: 15.70601

Cumulative Model Updates: 65,898
Cumulative Timesteps: 1,099,171,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1099171386...
Checkpoint 1099171386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561,238.55232
Policy Entropy: 1.00496
Value Function Loss: 1.24329

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.06844
Value Function Update Magnitude: 0.08439

Collected Steps per Second: 3,879.06255
Overall Steps per Second: 3,282.10594

Timestep Collection Time: 12.89538
Timestep Consumption Time: 2.34544
PPO Batch Consumption Time: 0.05004
Total Iteration Time: 15.24082

Cumulative Model Updates: 65,901
Cumulative Timesteps: 1,099,221,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,413,147.24039
Policy Entropy: 0.99079
Value Function Loss: 1.20768

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.07252
Value Function Update Magnitude: 0.08601

Collected Steps per Second: 3,670.44898
Overall Steps per Second: 3,115.30331

Timestep Collection Time: 13.62831
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 16.05686

Cumulative Model Updates: 65,904
Cumulative Timesteps: 1,099,271,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1099271430...
Checkpoint 1099271430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,621,888.87804
Policy Entropy: 0.99982
Value Function Loss: 1.16775

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.15145
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.09599

Collected Steps per Second: 3,808.73210
Overall Steps per Second: 3,160.86923

Timestep Collection Time: 13.13088
Timestep Consumption Time: 2.69135
PPO Batch Consumption Time: 0.05953
Total Iteration Time: 15.82223

Cumulative Model Updates: 65,907
Cumulative Timesteps: 1,099,321,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051,694.23578
Policy Entropy: 0.99234
Value Function Loss: 1.19111

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.07055
Value Function Update Magnitude: 0.11535

Collected Steps per Second: 3,731.45306
Overall Steps per Second: 3,126.31683

Timestep Collection Time: 13.40925
Timestep Consumption Time: 2.59552
PPO Batch Consumption Time: 0.05244
Total Iteration Time: 16.00478

Cumulative Model Updates: 65,910
Cumulative Timesteps: 1,099,371,478

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1099371478...
Checkpoint 1099371478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409,064.23542
Policy Entropy: 0.99181
Value Function Loss: 1.30439

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.07412
Value Function Update Magnitude: 0.11264

Collected Steps per Second: 3,915.61148
Overall Steps per Second: 3,236.90455

Timestep Collection Time: 12.78115
Timestep Consumption Time: 2.67992
PPO Batch Consumption Time: 0.06262
Total Iteration Time: 15.46107

Cumulative Model Updates: 65,913
Cumulative Timesteps: 1,099,421,524

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889,281.71249
Policy Entropy: 0.99794
Value Function Loss: 1.30643

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.08040
Value Function Update Magnitude: 0.10710

Collected Steps per Second: 3,778.94466
Overall Steps per Second: 3,154.02351

Timestep Collection Time: 13.24391
Timestep Consumption Time: 2.62408
PPO Batch Consumption Time: 0.04895
Total Iteration Time: 15.86799

Cumulative Model Updates: 65,916
Cumulative Timesteps: 1,099,471,572

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1099471572...
Checkpoint 1099471572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467,740.39051
Policy Entropy: 1.00389
Value Function Loss: 1.30621

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.08448
Value Function Update Magnitude: 0.10192

Collected Steps per Second: 3,680.84383
Overall Steps per Second: 3,066.68343

Timestep Collection Time: 13.58982
Timestep Consumption Time: 2.72161
PPO Batch Consumption Time: 0.05770
Total Iteration Time: 16.31143

Cumulative Model Updates: 65,919
Cumulative Timesteps: 1,099,521,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808,427.56249
Policy Entropy: 1.00579
Value Function Loss: 1.21453

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.07898
Value Function Update Magnitude: 0.09969

Collected Steps per Second: 3,820.98516
Overall Steps per Second: 3,154.27408

Timestep Collection Time: 13.08982
Timestep Consumption Time: 2.76676
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 15.85658

Cumulative Model Updates: 65,922
Cumulative Timesteps: 1,099,571,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1099571610...
Checkpoint 1099571610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,182,418.66478
Policy Entropy: 1.00728
Value Function Loss: 1.23580

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.07888
Value Function Update Magnitude: 0.10077

Collected Steps per Second: 3,615.61319
Overall Steps per Second: 3,046.52347

Timestep Collection Time: 13.83057
Timestep Consumption Time: 2.58355
PPO Batch Consumption Time: 0.05771
Total Iteration Time: 16.41412

Cumulative Model Updates: 65,925
Cumulative Timesteps: 1,099,621,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829,752.31260
Policy Entropy: 1.01749
Value Function Loss: 1.21824

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.07829
Value Function Update Magnitude: 0.09167

Collected Steps per Second: 3,970.05733
Overall Steps per Second: 3,282.01922

Timestep Collection Time: 12.60234
Timestep Consumption Time: 2.64194
PPO Batch Consumption Time: 0.05358
Total Iteration Time: 15.24427

Cumulative Model Updates: 65,928
Cumulative Timesteps: 1,099,671,648

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1099671648...
Checkpoint 1099671648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909,664.14900
Policy Entropy: 1.02006
Value Function Loss: 1.26078

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.07875
Value Function Update Magnitude: 0.09384

Collected Steps per Second: 3,709.14733
Overall Steps per Second: 3,134.54331

Timestep Collection Time: 13.48828
Timestep Consumption Time: 2.47258
PPO Batch Consumption Time: 0.06179
Total Iteration Time: 15.96086

Cumulative Model Updates: 65,931
Cumulative Timesteps: 1,099,721,678

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,589,956.90129
Policy Entropy: 1.02237
Value Function Loss: 1.20475

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.08511
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 3,999.69878
Overall Steps per Second: 3,339.66139

Timestep Collection Time: 12.50244
Timestep Consumption Time: 2.47093
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 14.97337

Cumulative Model Updates: 65,934
Cumulative Timesteps: 1,099,771,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1099771684...
Checkpoint 1099771684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,517,788.68967
Policy Entropy: 1.01380
Value Function Loss: 1.18359

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.08741
Value Function Update Magnitude: 0.12390

Collected Steps per Second: 3,755.91764
Overall Steps per Second: 3,119.01752

Timestep Collection Time: 13.31925
Timestep Consumption Time: 2.71978
PPO Batch Consumption Time: 0.05022
Total Iteration Time: 16.03903

Cumulative Model Updates: 65,937
Cumulative Timesteps: 1,099,821,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964,596.45540
Policy Entropy: 1.02042
Value Function Loss: 1.14986

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.08596
Value Function Update Magnitude: 0.10671

Collected Steps per Second: 3,893.50104
Overall Steps per Second: 3,249.40307

Timestep Collection Time: 12.84191
Timestep Consumption Time: 2.54553
PPO Batch Consumption Time: 0.05202
Total Iteration Time: 15.38744

Cumulative Model Updates: 65,940
Cumulative Timesteps: 1,099,871,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1099871710...
Checkpoint 1099871710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662,895.85712
Policy Entropy: 1.01604
Value Function Loss: 1.22435

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.08733
Value Function Update Magnitude: 0.10023

Collected Steps per Second: 3,692.40312
Overall Steps per Second: 3,077.40052

Timestep Collection Time: 13.55269
Timestep Consumption Time: 2.70844
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 16.26113

Cumulative Model Updates: 65,943
Cumulative Timesteps: 1,099,921,752

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706,584.92767
Policy Entropy: 1.01813
Value Function Loss: 1.24889

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.09369
Value Function Update Magnitude: 0.09943

Collected Steps per Second: 3,854.03754
Overall Steps per Second: 3,194.39542

Timestep Collection Time: 12.97600
Timestep Consumption Time: 2.67954
PPO Batch Consumption Time: 0.06934
Total Iteration Time: 15.65554

Cumulative Model Updates: 65,946
Cumulative Timesteps: 1,099,971,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1099971762...
Checkpoint 1099971762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707,822.24779
Policy Entropy: 1.01917
Value Function Loss: 1.23309

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.08858
Value Function Update Magnitude: 0.09841

Collected Steps per Second: 3,783.33954
Overall Steps per Second: 3,132.86595

Timestep Collection Time: 13.22112
Timestep Consumption Time: 2.74509
PPO Batch Consumption Time: 0.05862
Total Iteration Time: 15.96621

Cumulative Model Updates: 65,949
Cumulative Timesteps: 1,100,021,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086,745.26257
Policy Entropy: 1.03258
Value Function Loss: 1.19973

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.15647
Policy Update Magnitude: 0.08160
Value Function Update Magnitude: 0.09490

Collected Steps per Second: 3,996.51085
Overall Steps per Second: 3,317.51352

Timestep Collection Time: 12.51642
Timestep Consumption Time: 2.56174
PPO Batch Consumption Time: 0.05839
Total Iteration Time: 15.07816

Cumulative Model Updates: 65,952
Cumulative Timesteps: 1,100,071,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1100071804...
Checkpoint 1100071804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573,596.32606
Policy Entropy: 1.03126
Value Function Loss: 1.15991

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.07981
Value Function Update Magnitude: 0.08904

Collected Steps per Second: 3,711.47773
Overall Steps per Second: 3,128.72306

Timestep Collection Time: 13.47711
Timestep Consumption Time: 2.51024
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 15.98735

Cumulative Model Updates: 65,955
Cumulative Timesteps: 1,100,121,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,773,841.87202
Policy Entropy: 1.03550
Value Function Loss: 1.16830

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.08420
Value Function Update Magnitude: 0.09141

Collected Steps per Second: 3,684.77261
Overall Steps per Second: 3,102.46634

Timestep Collection Time: 13.58293
Timestep Consumption Time: 2.54940
PPO Batch Consumption Time: 0.05134
Total Iteration Time: 16.13233

Cumulative Model Updates: 65,958
Cumulative Timesteps: 1,100,171,874

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1100171874...
Checkpoint 1100171874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473,305.94987
Policy Entropy: 1.02541
Value Function Loss: 1.17167

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.08052
Value Function Update Magnitude: 0.09140

Collected Steps per Second: 3,766.86035
Overall Steps per Second: 3,159.56074

Timestep Collection Time: 13.28003
Timestep Consumption Time: 2.55256
PPO Batch Consumption Time: 0.05258
Total Iteration Time: 15.83258

Cumulative Model Updates: 65,961
Cumulative Timesteps: 1,100,221,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,988,568.21025
Policy Entropy: 1.04730
Value Function Loss: 1.21222

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.07123
Value Function Update Magnitude: 0.08501

Collected Steps per Second: 3,871.69505
Overall Steps per Second: 3,238.35211

Timestep Collection Time: 12.92509
Timestep Consumption Time: 2.52783
PPO Batch Consumption Time: 0.05912
Total Iteration Time: 15.45292

Cumulative Model Updates: 65,964
Cumulative Timesteps: 1,100,271,940

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1100271940...
Checkpoint 1100271940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,276,205.25530
Policy Entropy: 1.05466
Value Function Loss: 1.25382

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.07182
Value Function Update Magnitude: 0.09504

Collected Steps per Second: 3,706.95679
Overall Steps per Second: 3,150.28629

Timestep Collection Time: 13.49625
Timestep Consumption Time: 2.38485
PPO Batch Consumption Time: 0.06003
Total Iteration Time: 15.88110

Cumulative Model Updates: 65,967
Cumulative Timesteps: 1,100,321,970

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544,131.12389
Policy Entropy: 1.06047
Value Function Loss: 1.20084

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.07072
Value Function Update Magnitude: 0.12716

Collected Steps per Second: 3,847.42014
Overall Steps per Second: 3,257.05773

Timestep Collection Time: 12.99676
Timestep Consumption Time: 2.35575
PPO Batch Consumption Time: 0.05849
Total Iteration Time: 15.35251

Cumulative Model Updates: 65,970
Cumulative Timesteps: 1,100,371,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1100371974...
Checkpoint 1100371974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465,402.99550
Policy Entropy: 1.05239
Value Function Loss: 1.20578

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.07176
Value Function Update Magnitude: 0.12805

Collected Steps per Second: 3,729.25540
Overall Steps per Second: 3,150.04229

Timestep Collection Time: 13.41662
Timestep Consumption Time: 2.46698
PPO Batch Consumption Time: 0.06390
Total Iteration Time: 15.88360

Cumulative Model Updates: 65,973
Cumulative Timesteps: 1,100,422,008

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432,966.72398
Policy Entropy: 1.03655
Value Function Loss: 1.16064

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.07279
Value Function Update Magnitude: 0.12294

Collected Steps per Second: 3,844.18916
Overall Steps per Second: 3,205.37340

Timestep Collection Time: 13.01185
Timestep Consumption Time: 2.59320
PPO Batch Consumption Time: 0.05382
Total Iteration Time: 15.60505

Cumulative Model Updates: 65,976
Cumulative Timesteps: 1,100,472,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1100472028...
Checkpoint 1100472028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477,174.36615
Policy Entropy: 1.05029
Value Function Loss: 1.24527

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.12625

Collected Steps per Second: 4,045.44636
Overall Steps per Second: 3,311.44455

Timestep Collection Time: 12.36699
Timestep Consumption Time: 2.74122
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 15.10821

Cumulative Model Updates: 65,979
Cumulative Timesteps: 1,100,522,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,863,982.22915
Policy Entropy: 1.05633
Value Function Loss: 1.19081

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.17387
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.12963

Collected Steps per Second: 4,275.23109
Overall Steps per Second: 3,467.12367

Timestep Collection Time: 11.69808
Timestep Consumption Time: 2.72656
PPO Batch Consumption Time: 0.05235
Total Iteration Time: 14.42464

Cumulative Model Updates: 65,982
Cumulative Timesteps: 1,100,572,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1100572070...
Checkpoint 1100572070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504,273.50427
Policy Entropy: 1.05013
Value Function Loss: 1.22779

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.13296

Collected Steps per Second: 4,153.11773
Overall Steps per Second: 3,384.22306

Timestep Collection Time: 12.04830
Timestep Consumption Time: 2.73737
PPO Batch Consumption Time: 0.05276
Total Iteration Time: 14.78567

Cumulative Model Updates: 65,985
Cumulative Timesteps: 1,100,622,108

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939,611.15576
Policy Entropy: 1.04565
Value Function Loss: 1.18804

Mean KL Divergence: 0.02850
SB3 Clip Fraction: 0.18341
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.12741

Collected Steps per Second: 3,784.89417
Overall Steps per Second: 3,155.18327

Timestep Collection Time: 13.21992
Timestep Consumption Time: 2.63843
PPO Batch Consumption Time: 0.05422
Total Iteration Time: 15.85835

Cumulative Model Updates: 65,988
Cumulative Timesteps: 1,100,672,144

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1100672144...
Checkpoint 1100672144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634,974.48220
Policy Entropy: 1.06956
Value Function Loss: 1.22588

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.10864

Collected Steps per Second: 3,846.76217
Overall Steps per Second: 3,202.99794

Timestep Collection Time: 12.99794
Timestep Consumption Time: 2.61243
PPO Batch Consumption Time: 0.05007
Total Iteration Time: 15.61038

Cumulative Model Updates: 65,991
Cumulative Timesteps: 1,100,722,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037,005.92433
Policy Entropy: 1.05006
Value Function Loss: 1.30807

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.06438
Value Function Update Magnitude: 0.11157

Collected Steps per Second: 3,610.64383
Overall Steps per Second: 3,045.57025

Timestep Collection Time: 13.86124
Timestep Consumption Time: 2.57181
PPO Batch Consumption Time: 0.04917
Total Iteration Time: 16.43305

Cumulative Model Updates: 65,994
Cumulative Timesteps: 1,100,772,192

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1100772192...
Checkpoint 1100772192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231,451.38289
Policy Entropy: 1.03885
Value Function Loss: 1.27024

Mean KL Divergence: 0.02859
SB3 Clip Fraction: 0.18979
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.11702

Collected Steps per Second: 4,122.87497
Overall Steps per Second: 3,454.55339

Timestep Collection Time: 12.12794
Timestep Consumption Time: 2.34629
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 14.47423

Cumulative Model Updates: 65,997
Cumulative Timesteps: 1,100,822,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278,100.36840
Policy Entropy: 1.05773
Value Function Loss: 1.25839

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.14581
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.10546

Collected Steps per Second: 4,236.57633
Overall Steps per Second: 3,529.47697

Timestep Collection Time: 11.80340
Timestep Consumption Time: 2.36471
PPO Batch Consumption Time: 0.04693
Total Iteration Time: 14.16810

Cumulative Model Updates: 66,000
Cumulative Timesteps: 1,100,872,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1100872200...
Checkpoint 1100872200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889,200.94568
Policy Entropy: 1.06316
Value Function Loss: 1.15984

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.16758
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.11656

Collected Steps per Second: 4,161.03612
Overall Steps per Second: 3,465.43234

Timestep Collection Time: 12.02489
Timestep Consumption Time: 2.41371
PPO Batch Consumption Time: 0.04889
Total Iteration Time: 14.43860

Cumulative Model Updates: 66,003
Cumulative Timesteps: 1,100,922,236

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629,950.75517
Policy Entropy: 1.05043
Value Function Loss: 1.12543

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 4,159.44355
Overall Steps per Second: 3,409.82471

Timestep Collection Time: 12.02372
Timestep Consumption Time: 2.64331
PPO Batch Consumption Time: 0.05384
Total Iteration Time: 14.66703

Cumulative Model Updates: 66,006
Cumulative Timesteps: 1,100,972,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1100972248...
Checkpoint 1100972248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251,055.98513
Policy Entropy: 1.05620
Value Function Loss: 1.11446

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.06196
Value Function Update Magnitude: 0.11653

Collected Steps per Second: 4,227.30008
Overall Steps per Second: 3,458.90846

Timestep Collection Time: 11.83214
Timestep Consumption Time: 2.62849
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 14.46063

Cumulative Model Updates: 66,009
Cumulative Timesteps: 1,101,022,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723,261.67150
Policy Entropy: 1.06532
Value Function Loss: 1.13873

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.11387

Collected Steps per Second: 4,097.30122
Overall Steps per Second: 3,336.65836

Timestep Collection Time: 12.20804
Timestep Consumption Time: 2.78301
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 14.99105

Cumulative Model Updates: 66,012
Cumulative Timesteps: 1,101,072,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1101072286...
Checkpoint 1101072286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487,641.13647
Policy Entropy: 1.06609
Value Function Loss: 1.22922

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.07373
Value Function Update Magnitude: 0.11184

Collected Steps per Second: 3,862.09189
Overall Steps per Second: 3,243.23547

Timestep Collection Time: 12.95464
Timestep Consumption Time: 2.47193
PPO Batch Consumption Time: 0.04665
Total Iteration Time: 15.42657

Cumulative Model Updates: 66,015
Cumulative Timesteps: 1,101,122,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747,643.54566
Policy Entropy: 1.06553
Value Function Loss: 1.20788

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.07788
Value Function Update Magnitude: 0.10424

Collected Steps per Second: 3,643.39358
Overall Steps per Second: 3,065.68029

Timestep Collection Time: 13.72731
Timestep Consumption Time: 2.58685
PPO Batch Consumption Time: 0.04802
Total Iteration Time: 16.31416

Cumulative Model Updates: 66,018
Cumulative Timesteps: 1,101,172,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1101172332...
Checkpoint 1101172332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914,434.43922
Policy Entropy: 1.06252
Value Function Loss: 1.22230

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.08164
Value Function Update Magnitude: 0.09933

Collected Steps per Second: 4,075.83501
Overall Steps per Second: 3,366.51866

Timestep Collection Time: 12.27429
Timestep Consumption Time: 2.58616
PPO Batch Consumption Time: 0.06218
Total Iteration Time: 14.86046

Cumulative Model Updates: 66,021
Cumulative Timesteps: 1,101,222,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807,361.45574
Policy Entropy: 1.04832
Value Function Loss: 1.20661

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.15041
Policy Update Magnitude: 0.08332
Value Function Update Magnitude: 0.10256

Collected Steps per Second: 3,658.60807
Overall Steps per Second: 3,064.58462

Timestep Collection Time: 13.67569
Timestep Consumption Time: 2.65083
PPO Batch Consumption Time: 0.05149
Total Iteration Time: 16.32652

Cumulative Model Updates: 66,024
Cumulative Timesteps: 1,101,272,394

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1101272394...
Checkpoint 1101272394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730,246.06134
Policy Entropy: 1.07373
Value Function Loss: 1.26109

Mean KL Divergence: 0.02524
SB3 Clip Fraction: 0.16150
Policy Update Magnitude: 0.06982
Value Function Update Magnitude: 0.13799

Collected Steps per Second: 3,965.52674
Overall Steps per Second: 3,273.75568

Timestep Collection Time: 12.60917
Timestep Consumption Time: 2.66442
PPO Batch Consumption Time: 0.06037
Total Iteration Time: 15.27359

Cumulative Model Updates: 66,027
Cumulative Timesteps: 1,101,322,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162,663.63861
Policy Entropy: 1.07418
Value Function Loss: 1.24222

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.15371
Policy Update Magnitude: 0.06474
Value Function Update Magnitude: 0.13393

Collected Steps per Second: 3,677.31421
Overall Steps per Second: 3,122.40065

Timestep Collection Time: 13.60286
Timestep Consumption Time: 2.41750
PPO Batch Consumption Time: 0.05880
Total Iteration Time: 16.02037

Cumulative Model Updates: 66,030
Cumulative Timesteps: 1,101,372,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1101372418...
Checkpoint 1101372418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326,189.86656
Policy Entropy: 1.07307
Value Function Loss: 1.19994

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.15073
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.13093

Collected Steps per Second: 3,991.59139
Overall Steps per Second: 3,319.38169

Timestep Collection Time: 12.53335
Timestep Consumption Time: 2.53813
PPO Batch Consumption Time: 0.06671
Total Iteration Time: 15.07148

Cumulative Model Updates: 66,033
Cumulative Timesteps: 1,101,422,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272,358.58174
Policy Entropy: 1.06082
Value Function Loss: 1.12615

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.16812
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.13284

Collected Steps per Second: 3,677.95403
Overall Steps per Second: 3,099.79474

Timestep Collection Time: 13.59941
Timestep Consumption Time: 2.53650
PPO Batch Consumption Time: 0.06133
Total Iteration Time: 16.13591

Cumulative Model Updates: 66,036
Cumulative Timesteps: 1,101,472,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1101472464...
Checkpoint 1101472464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,862,479.82363
Policy Entropy: 1.07745
Value Function Loss: 1.10550

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.12787

Collected Steps per Second: 3,749.99882
Overall Steps per Second: 3,141.31881

Timestep Collection Time: 13.34240
Timestep Consumption Time: 2.58530
PPO Batch Consumption Time: 0.05197
Total Iteration Time: 15.92771

Cumulative Model Updates: 66,039
Cumulative Timesteps: 1,101,522,498

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742,909.19488
Policy Entropy: 1.07625
Value Function Loss: 1.08910

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.06825
Value Function Update Magnitude: 0.12026

Collected Steps per Second: 3,633.88283
Overall Steps per Second: 3,047.45523

Timestep Collection Time: 13.76709
Timestep Consumption Time: 2.64923
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 16.41632

Cumulative Model Updates: 66,042
Cumulative Timesteps: 1,101,572,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1101572526...
Checkpoint 1101572526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643,925.11637
Policy Entropy: 1.07149
Value Function Loss: 1.11715

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.07147
Value Function Update Magnitude: 0.12229

Collected Steps per Second: 3,804.62644
Overall Steps per Second: 3,187.70468

Timestep Collection Time: 13.14189
Timestep Consumption Time: 2.54337
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 15.68527

Cumulative Model Updates: 66,045
Cumulative Timesteps: 1,101,622,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910,153.31660
Policy Entropy: 1.06028
Value Function Loss: 1.11190

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.15065
Policy Update Magnitude: 0.07471
Value Function Update Magnitude: 0.11326

Collected Steps per Second: 3,742.08086
Overall Steps per Second: 3,107.35094

Timestep Collection Time: 13.37491
Timestep Consumption Time: 2.73206
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 16.10697

Cumulative Model Updates: 66,048
Cumulative Timesteps: 1,101,672,576

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1101672576...
Checkpoint 1101672576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,108,704.46455
Policy Entropy: 1.08721
Value Function Loss: 1.12452

Mean KL Divergence: 0.02143
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.06595
Value Function Update Magnitude: 0.11220

Collected Steps per Second: 3,875.51315
Overall Steps per Second: 3,240.46302

Timestep Collection Time: 12.91339
Timestep Consumption Time: 2.53070
PPO Batch Consumption Time: 0.05434
Total Iteration Time: 15.44409

Cumulative Model Updates: 66,051
Cumulative Timesteps: 1,101,722,622

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486,321.58353
Policy Entropy: 1.09144
Value Function Loss: 1.16276

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.06467
Value Function Update Magnitude: 0.10778

Collected Steps per Second: 3,747.52173
Overall Steps per Second: 3,125.68871

Timestep Collection Time: 13.34962
Timestep Consumption Time: 2.65581
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 16.00543

Cumulative Model Updates: 66,054
Cumulative Timesteps: 1,101,772,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1101772650...
Checkpoint 1101772650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410,223.03394
Policy Entropy: 1.08523
Value Function Loss: 1.09187

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.10331

Collected Steps per Second: 3,652.91646
Overall Steps per Second: 3,056.64186

Timestep Collection Time: 13.69864
Timestep Consumption Time: 2.67226
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 16.37091

Cumulative Model Updates: 66,057
Cumulative Timesteps: 1,101,822,690

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738,547.76517
Policy Entropy: 1.08112
Value Function Loss: 1.08848

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.10796

Collected Steps per Second: 3,936.56260
Overall Steps per Second: 3,308.42879

Timestep Collection Time: 12.70906
Timestep Consumption Time: 2.41292
PPO Batch Consumption Time: 0.05384
Total Iteration Time: 15.12198

Cumulative Model Updates: 66,060
Cumulative Timesteps: 1,101,872,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1101872720...
Checkpoint 1101872720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475,946.86908
Policy Entropy: 1.09976
Value Function Loss: 0.97613

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.10646

Collected Steps per Second: 3,810.45243
Overall Steps per Second: 3,178.71838

Timestep Collection Time: 13.12705
Timestep Consumption Time: 2.60885
PPO Batch Consumption Time: 0.06214
Total Iteration Time: 15.73590

Cumulative Model Updates: 66,063
Cumulative Timesteps: 1,101,922,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433,718.29069
Policy Entropy: 1.10341
Value Function Loss: 1.03805

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.10059

Collected Steps per Second: 3,835.92590
Overall Steps per Second: 3,173.90706

Timestep Collection Time: 13.03936
Timestep Consumption Time: 2.71977
PPO Batch Consumption Time: 0.05353
Total Iteration Time: 15.75913

Cumulative Model Updates: 66,066
Cumulative Timesteps: 1,101,972,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1101972758...
Checkpoint 1101972758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,220,380.62831
Policy Entropy: 1.07591
Value Function Loss: 1.09204

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.11472

Collected Steps per Second: 3,834.58579
Overall Steps per Second: 3,203.65326

Timestep Collection Time: 13.04078
Timestep Consumption Time: 2.56827
PPO Batch Consumption Time: 0.05896
Total Iteration Time: 15.60906

Cumulative Model Updates: 66,069
Cumulative Timesteps: 1,102,022,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793,232.39662
Policy Entropy: 1.06090
Value Function Loss: 1.12617

Mean KL Divergence: 0.03280
SB3 Clip Fraction: 0.16872
Policy Update Magnitude: 0.06316
Value Function Update Magnitude: 0.11646

Collected Steps per Second: 3,710.22543
Overall Steps per Second: 3,151.38252

Timestep Collection Time: 13.48489
Timestep Consumption Time: 2.39131
PPO Batch Consumption Time: 0.04981
Total Iteration Time: 15.87621

Cumulative Model Updates: 66,072
Cumulative Timesteps: 1,102,072,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1102072796...
Checkpoint 1102072796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833,419.28845
Policy Entropy: 1.07731
Value Function Loss: 1.16769

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.10802

Collected Steps per Second: 3,739.44521
Overall Steps per Second: 3,138.07852

Timestep Collection Time: 13.37525
Timestep Consumption Time: 2.56317
PPO Batch Consumption Time: 0.06231
Total Iteration Time: 15.93842

Cumulative Model Updates: 66,075
Cumulative Timesteps: 1,102,122,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635,863.52530
Policy Entropy: 1.08200
Value Function Loss: 1.14305

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.09484

Collected Steps per Second: 3,986.00745
Overall Steps per Second: 3,317.38380

Timestep Collection Time: 12.55642
Timestep Consumption Time: 2.53077
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 15.08719

Cumulative Model Updates: 66,078
Cumulative Timesteps: 1,102,172,862

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1102172862...
Checkpoint 1102172862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,206,041.96227
Policy Entropy: 1.06747
Value Function Loss: 1.14216

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.06861
Value Function Update Magnitude: 0.08702

Collected Steps per Second: 4,116.71295
Overall Steps per Second: 3,353.24370

Timestep Collection Time: 12.15679
Timestep Consumption Time: 2.76787
PPO Batch Consumption Time: 0.05208
Total Iteration Time: 14.92465

Cumulative Model Updates: 66,081
Cumulative Timesteps: 1,102,222,908

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889,868.47506
Policy Entropy: 1.05720
Value Function Loss: 1.13625

Mean KL Divergence: 0.03322
SB3 Clip Fraction: 0.17660
Policy Update Magnitude: 0.06739
Value Function Update Magnitude: 0.08750

Collected Steps per Second: 4,072.70696
Overall Steps per Second: 3,340.58556

Timestep Collection Time: 12.27979
Timestep Consumption Time: 2.69123
PPO Batch Consumption Time: 0.05263
Total Iteration Time: 14.97103

Cumulative Model Updates: 66,084
Cumulative Timesteps: 1,102,272,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1102272920...
Checkpoint 1102272920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497,305.77396
Policy Entropy: 1.07321
Value Function Loss: 1.14148

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.09581

Collected Steps per Second: 4,001.40154
Overall Steps per Second: 3,285.85066

Timestep Collection Time: 12.50312
Timestep Consumption Time: 2.72277
PPO Batch Consumption Time: 0.04797
Total Iteration Time: 15.22589

Cumulative Model Updates: 66,087
Cumulative Timesteps: 1,102,322,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929,233.51580
Policy Entropy: 1.07776
Value Function Loss: 1.10168

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.09957

Collected Steps per Second: 3,817.91452
Overall Steps per Second: 3,199.29759

Timestep Collection Time: 13.10035
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.05080
Total Iteration Time: 15.63343

Cumulative Model Updates: 66,090
Cumulative Timesteps: 1,102,372,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1102372966...
Checkpoint 1102372966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178,882.31154
Policy Entropy: 1.05936
Value Function Loss: 1.06146

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.09708

Collected Steps per Second: 3,739.91844
Overall Steps per Second: 3,105.15077

Timestep Collection Time: 13.37516
Timestep Consumption Time: 2.73420
PPO Batch Consumption Time: 0.06410
Total Iteration Time: 16.10936

Cumulative Model Updates: 66,093
Cumulative Timesteps: 1,102,422,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660,098.74875
Policy Entropy: 1.05401
Value Function Loss: 1.02924

Mean KL Divergence: 0.02716
SB3 Clip Fraction: 0.17844
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.09524

Collected Steps per Second: 3,674.46409
Overall Steps per Second: 3,065.52888

Timestep Collection Time: 13.60906
Timestep Consumption Time: 2.70330
PPO Batch Consumption Time: 0.05906
Total Iteration Time: 16.31236

Cumulative Model Updates: 66,096
Cumulative Timesteps: 1,102,472,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1102472994...
Checkpoint 1102472994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923,758.56464
Policy Entropy: 1.06840
Value Function Loss: 1.14151

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.09370

Collected Steps per Second: 3,704.77061
Overall Steps per Second: 3,137.19038

Timestep Collection Time: 13.50907
Timestep Consumption Time: 2.44406
PPO Batch Consumption Time: 0.05318
Total Iteration Time: 15.95313

Cumulative Model Updates: 66,099
Cumulative Timesteps: 1,102,523,042

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,919,405.24800
Policy Entropy: 1.06717
Value Function Loss: 1.13525

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.06467
Value Function Update Magnitude: 0.10645

Collected Steps per Second: 3,862.81111
Overall Steps per Second: 3,183.41782

Timestep Collection Time: 12.94912
Timestep Consumption Time: 2.76355
PPO Batch Consumption Time: 0.05963
Total Iteration Time: 15.71267

Cumulative Model Updates: 66,102
Cumulative Timesteps: 1,102,573,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1102573062...
Checkpoint 1102573062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224,226.61963
Policy Entropy: 1.05572
Value Function Loss: 1.11787

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.12265

Collected Steps per Second: 3,634.63074
Overall Steps per Second: 3,061.12108

Timestep Collection Time: 13.76756
Timestep Consumption Time: 2.57939
PPO Batch Consumption Time: 0.05974
Total Iteration Time: 16.34695

Cumulative Model Updates: 66,105
Cumulative Timesteps: 1,102,623,102

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,263,191.72318
Policy Entropy: 1.04518
Value Function Loss: 1.11303

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.16195
Policy Update Magnitude: 0.06904
Value Function Update Magnitude: 0.10843

Collected Steps per Second: 3,870.99551
Overall Steps per Second: 3,256.47614

Timestep Collection Time: 12.93052
Timestep Consumption Time: 2.44008
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 15.37060

Cumulative Model Updates: 66,108
Cumulative Timesteps: 1,102,673,156

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1102673156...
Checkpoint 1102673156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405,332.46512
Policy Entropy: 1.07071
Value Function Loss: 1.12381

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.15853
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 3,710.00620
Overall Steps per Second: 3,162.81823

Timestep Collection Time: 13.47814
Timestep Consumption Time: 2.33181
PPO Batch Consumption Time: 0.05073
Total Iteration Time: 15.80995

Cumulative Model Updates: 66,111
Cumulative Timesteps: 1,102,723,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382,760.57555
Policy Entropy: 1.06753
Value Function Loss: 1.16170

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.12774

Collected Steps per Second: 4,078.79845
Overall Steps per Second: 3,349.72797

Timestep Collection Time: 12.25900
Timestep Consumption Time: 2.66818
PPO Batch Consumption Time: 0.05858
Total Iteration Time: 14.92718

Cumulative Model Updates: 66,114
Cumulative Timesteps: 1,102,773,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1102773162...
Checkpoint 1102773162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628,308.35084
Policy Entropy: 1.05771
Value Function Loss: 1.09333

Mean KL Divergence: 0.02636
SB3 Clip Fraction: 0.15939
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.12054

Collected Steps per Second: 3,595.89612
Overall Steps per Second: 3,052.40791

Timestep Collection Time: 13.91642
Timestep Consumption Time: 2.47785
PPO Batch Consumption Time: 0.05284
Total Iteration Time: 16.39427

Cumulative Model Updates: 66,117
Cumulative Timesteps: 1,102,823,204

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457,505.30046
Policy Entropy: 1.04900
Value Function Loss: 1.07014

Mean KL Divergence: 0.02542
SB3 Clip Fraction: 0.18593
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.12586

Collected Steps per Second: 3,664.44368
Overall Steps per Second: 3,080.87672

Timestep Collection Time: 13.64627
Timestep Consumption Time: 2.58482
PPO Batch Consumption Time: 0.04968
Total Iteration Time: 16.23109

Cumulative Model Updates: 66,120
Cumulative Timesteps: 1,102,873,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1102873210...
Checkpoint 1102873210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644,911.37081
Policy Entropy: 1.05889
Value Function Loss: 1.08342

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.12826

Collected Steps per Second: 3,724.62824
Overall Steps per Second: 3,092.46847

Timestep Collection Time: 13.42792
Timestep Consumption Time: 2.74492
PPO Batch Consumption Time: 0.06302
Total Iteration Time: 16.17284

Cumulative Model Updates: 66,123
Cumulative Timesteps: 1,102,923,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384,271.74232
Policy Entropy: 1.06300
Value Function Loss: 1.06572

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.04811
Value Function Update Magnitude: 0.12635

Collected Steps per Second: 3,792.57704
Overall Steps per Second: 3,178.67355

Timestep Collection Time: 13.19367
Timestep Consumption Time: 2.54812
PPO Batch Consumption Time: 0.05994
Total Iteration Time: 15.74179

Cumulative Model Updates: 66,126
Cumulative Timesteps: 1,102,973,262

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1102973262...
Checkpoint 1102973262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,329,183.88223
Policy Entropy: 1.04903
Value Function Loss: 1.07421

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.12517

Collected Steps per Second: 3,768.17090
Overall Steps per Second: 3,149.88806

Timestep Collection Time: 13.28071
Timestep Consumption Time: 2.60683
PPO Batch Consumption Time: 0.05355
Total Iteration Time: 15.88755

Cumulative Model Updates: 66,129
Cumulative Timesteps: 1,103,023,306

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449,480.67432
Policy Entropy: 1.03420
Value Function Loss: 0.99779

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.17784
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.11630

Collected Steps per Second: 3,679.00630
Overall Steps per Second: 3,090.43573

Timestep Collection Time: 13.59334
Timestep Consumption Time: 2.58884
PPO Batch Consumption Time: 0.04802
Total Iteration Time: 16.18218

Cumulative Model Updates: 66,132
Cumulative Timesteps: 1,103,073,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1103073316...
Checkpoint 1103073316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935,252.24937
Policy Entropy: 1.04261
Value Function Loss: 1.04438

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.11335

Collected Steps per Second: 3,989.24815
Overall Steps per Second: 3,294.60325

Timestep Collection Time: 12.53920
Timestep Consumption Time: 2.64381
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 15.18301

Cumulative Model Updates: 66,135
Cumulative Timesteps: 1,103,123,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,774.18019
Policy Entropy: 1.05760
Value Function Loss: 1.05938

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.11161

Collected Steps per Second: 3,635.48285
Overall Steps per Second: 3,073.63878

Timestep Collection Time: 13.75718
Timestep Consumption Time: 2.51474
PPO Batch Consumption Time: 0.05379
Total Iteration Time: 16.27192

Cumulative Model Updates: 66,138
Cumulative Timesteps: 1,103,173,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1103173352...
Checkpoint 1103173352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280,113.19637
Policy Entropy: 1.03747
Value Function Loss: 1.15368

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.15362
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.11936

Collected Steps per Second: 3,891.57833
Overall Steps per Second: 3,247.34933

Timestep Collection Time: 12.85185
Timestep Consumption Time: 2.54963
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 15.40148

Cumulative Model Updates: 66,141
Cumulative Timesteps: 1,103,223,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050,680.90040
Policy Entropy: 1.03767
Value Function Loss: 1.12534

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.15320
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.12110

Collected Steps per Second: 3,722.93308
Overall Steps per Second: 3,186.09990

Timestep Collection Time: 13.43296
Timestep Consumption Time: 2.26335
PPO Batch Consumption Time: 0.05232
Total Iteration Time: 15.69631

Cumulative Model Updates: 66,144
Cumulative Timesteps: 1,103,273,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1103273376...
Checkpoint 1103273376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565,848.30379
Policy Entropy: 1.04321
Value Function Loss: 1.15400

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.10972

Collected Steps per Second: 3,846.83664
Overall Steps per Second: 3,250.60178

Timestep Collection Time: 13.00601
Timestep Consumption Time: 2.38560
PPO Batch Consumption Time: 0.05153
Total Iteration Time: 15.39161

Cumulative Model Updates: 66,147
Cumulative Timesteps: 1,103,323,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,777,078.91382
Policy Entropy: 1.04865
Value Function Loss: 1.13328

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.15984
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.11339

Collected Steps per Second: 3,667.06063
Overall Steps per Second: 3,071.37923

Timestep Collection Time: 13.63926
Timestep Consumption Time: 2.64528
PPO Batch Consumption Time: 0.05896
Total Iteration Time: 16.28454

Cumulative Model Updates: 66,150
Cumulative Timesteps: 1,103,373,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1103373424...
Checkpoint 1103373424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779,715.68549
Policy Entropy: 1.02552
Value Function Loss: 1.15829

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.10731

Collected Steps per Second: 3,850.09186
Overall Steps per Second: 3,204.06339

Timestep Collection Time: 12.99346
Timestep Consumption Time: 2.61984
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 15.61330

Cumulative Model Updates: 66,153
Cumulative Timesteps: 1,103,423,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487,378.69478
Policy Entropy: 1.01027
Value Function Loss: 1.20268

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.18574
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.10828

Collected Steps per Second: 3,678.57426
Overall Steps per Second: 3,101.03029

Timestep Collection Time: 13.59875
Timestep Consumption Time: 2.53267
PPO Batch Consumption Time: 0.05907
Total Iteration Time: 16.13141

Cumulative Model Updates: 66,156
Cumulative Timesteps: 1,103,473,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1103473474...
Checkpoint 1103473474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588,393.45922
Policy Entropy: 1.03100
Value Function Loss: 1.21566

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 4,078.08762
Overall Steps per Second: 3,329.19072

Timestep Collection Time: 12.27046
Timestep Consumption Time: 2.76022
PPO Batch Consumption Time: 0.06256
Total Iteration Time: 15.03068

Cumulative Model Updates: 66,159
Cumulative Timesteps: 1,103,523,514

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650,721.33786
Policy Entropy: 1.03994
Value Function Loss: 1.26952

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.07442
Value Function Update Magnitude: 0.11144

Collected Steps per Second: 3,776.91252
Overall Steps per Second: 3,140.92535

Timestep Collection Time: 13.24945
Timestep Consumption Time: 2.68280
PPO Batch Consumption Time: 0.06280
Total Iteration Time: 15.93225

Cumulative Model Updates: 66,162
Cumulative Timesteps: 1,103,573,556

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1103573556...
Checkpoint 1103573556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129,318.47970
Policy Entropy: 1.02512
Value Function Loss: 1.21674

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.07399
Value Function Update Magnitude: 0.10100

Collected Steps per Second: 3,696.53198
Overall Steps per Second: 3,092.44252

Timestep Collection Time: 13.52673
Timestep Consumption Time: 2.64236
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 16.16910

Cumulative Model Updates: 66,165
Cumulative Timesteps: 1,103,623,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921,384.49276
Policy Entropy: 1.00906
Value Function Loss: 1.24641

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.16471
Policy Update Magnitude: 0.07311
Value Function Update Magnitude: 0.09046

Collected Steps per Second: 3,746.06291
Overall Steps per Second: 3,135.26897

Timestep Collection Time: 13.34735
Timestep Consumption Time: 2.60025
PPO Batch Consumption Time: 0.05225
Total Iteration Time: 15.94760

Cumulative Model Updates: 66,168
Cumulative Timesteps: 1,103,673,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1103673558...
Checkpoint 1103673558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,797,919.66353
Policy Entropy: 1.02183
Value Function Loss: 1.23809

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.16320
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.08236

Collected Steps per Second: 3,679.64861
Overall Steps per Second: 3,063.31881

Timestep Collection Time: 13.58825
Timestep Consumption Time: 2.73391
PPO Batch Consumption Time: 0.05417
Total Iteration Time: 16.32217

Cumulative Model Updates: 66,171
Cumulative Timesteps: 1,103,723,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856,190.22893
Policy Entropy: 1.02715
Value Function Loss: 1.26862

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.09586

Collected Steps per Second: 3,851.26112
Overall Steps per Second: 3,207.79230

Timestep Collection Time: 12.98276
Timestep Consumption Time: 2.60428
PPO Batch Consumption Time: 0.04698
Total Iteration Time: 15.58704

Cumulative Model Updates: 66,174
Cumulative Timesteps: 1,103,773,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1103773558...
Checkpoint 1103773558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585,276.10566
Policy Entropy: 1.01170
Value Function Loss: 1.26174

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.17207
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.08786

Collected Steps per Second: 4,084.91270
Overall Steps per Second: 3,343.79321

Timestep Collection Time: 12.25045
Timestep Consumption Time: 2.71519
PPO Batch Consumption Time: 0.05908
Total Iteration Time: 14.96564

Cumulative Model Updates: 66,177
Cumulative Timesteps: 1,103,823,600

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,866,936.87822
Policy Entropy: 0.99282
Value Function Loss: 1.27887

Mean KL Divergence: 0.03420
SB3 Clip Fraction: 0.21393
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.10003

Collected Steps per Second: 4,034.34009
Overall Steps per Second: 3,361.02180

Timestep Collection Time: 12.39757
Timestep Consumption Time: 2.48362
PPO Batch Consumption Time: 0.05085
Total Iteration Time: 14.88119

Cumulative Model Updates: 66,180
Cumulative Timesteps: 1,103,873,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1103873616...
Checkpoint 1103873616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818,555.05856
Policy Entropy: 1.00085
Value Function Loss: 1.25059

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.15198
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.10445

Collected Steps per Second: 3,922.05084
Overall Steps per Second: 3,281.51039

Timestep Collection Time: 12.75404
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.05290
Total Iteration Time: 15.24359

Cumulative Model Updates: 66,183
Cumulative Timesteps: 1,103,923,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674,650.03567
Policy Entropy: 1.02108
Value Function Loss: 1.21107

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.16692
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.09773

Collected Steps per Second: 3,687.42687
Overall Steps per Second: 3,120.27597

Timestep Collection Time: 13.56068
Timestep Consumption Time: 2.46483
PPO Batch Consumption Time: 0.04986
Total Iteration Time: 16.02551

Cumulative Model Updates: 66,186
Cumulative Timesteps: 1,103,973,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1103973642...
Checkpoint 1103973642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894,252.74219
Policy Entropy: 0.99966
Value Function Loss: 1.16944

Mean KL Divergence: 0.02652
SB3 Clip Fraction: 0.18565
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.08761

Collected Steps per Second: 3,936.91550
Overall Steps per Second: 3,280.08962

Timestep Collection Time: 12.70081
Timestep Consumption Time: 2.54329
PPO Batch Consumption Time: 0.06368
Total Iteration Time: 15.24410

Cumulative Model Updates: 66,189
Cumulative Timesteps: 1,104,023,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833,346.61469
Policy Entropy: 1.02694
Value Function Loss: 1.14824

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.16963
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.10150

Collected Steps per Second: 3,753.31656
Overall Steps per Second: 3,171.47123

Timestep Collection Time: 13.33061
Timestep Consumption Time: 2.44566
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 15.77627

Cumulative Model Updates: 66,192
Cumulative Timesteps: 1,104,073,678

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1104073678...
Checkpoint 1104073678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,046,814.49794
Policy Entropy: 1.02055
Value Function Loss: 1.19688

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.15695
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.08874

Collected Steps per Second: 3,669.33738
Overall Steps per Second: 3,051.86487

Timestep Collection Time: 13.63897
Timestep Consumption Time: 2.75952
PPO Batch Consumption Time: 0.05883
Total Iteration Time: 16.39850

Cumulative Model Updates: 66,195
Cumulative Timesteps: 1,104,123,724

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426,111.21130
Policy Entropy: 1.00530
Value Function Loss: 1.24712

Mean KL Divergence: 0.02618
SB3 Clip Fraction: 0.17455
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.09144

Collected Steps per Second: 3,970.27558
Overall Steps per Second: 3,282.27296

Timestep Collection Time: 12.60114
Timestep Consumption Time: 2.64135
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 15.24249

Cumulative Model Updates: 66,198
Cumulative Timesteps: 1,104,173,754

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1104173754...
Checkpoint 1104173754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829,613.10230
Policy Entropy: 1.00226
Value Function Loss: 1.26537

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.18314
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.09683

Collected Steps per Second: 3,794.87907
Overall Steps per Second: 3,168.46347

Timestep Collection Time: 13.18725
Timestep Consumption Time: 2.60716
PPO Batch Consumption Time: 0.05122
Total Iteration Time: 15.79441

Cumulative Model Updates: 66,201
Cumulative Timesteps: 1,104,223,798

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318,846.80213
Policy Entropy: 1.00460
Value Function Loss: 1.25454

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.14373
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.10257

Collected Steps per Second: 4,012.88359
Overall Steps per Second: 3,300.66128

Timestep Collection Time: 12.46386
Timestep Consumption Time: 2.68947
PPO Batch Consumption Time: 0.05433
Total Iteration Time: 15.15333

Cumulative Model Updates: 66,204
Cumulative Timesteps: 1,104,273,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1104273814...
Checkpoint 1104273814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979,501.51161
Policy Entropy: 1.02017
Value Function Loss: 1.23756

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.17764
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.09088

Collected Steps per Second: 3,624.97482
Overall Steps per Second: 3,040.81680

Timestep Collection Time: 13.79430
Timestep Consumption Time: 2.64996
PPO Batch Consumption Time: 0.06878
Total Iteration Time: 16.44427

Cumulative Model Updates: 66,207
Cumulative Timesteps: 1,104,323,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798,714.96013
Policy Entropy: 0.98905
Value Function Loss: 1.29822

Mean KL Divergence: 0.02869
SB3 Clip Fraction: 0.19287
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.08485

Collected Steps per Second: 4,001.82823
Overall Steps per Second: 3,303.13082

Timestep Collection Time: 12.49579
Timestep Consumption Time: 2.64318
PPO Batch Consumption Time: 0.05438
Total Iteration Time: 15.13897

Cumulative Model Updates: 66,210
Cumulative Timesteps: 1,104,373,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1104373824...
Checkpoint 1104373824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109,099.75756
Policy Entropy: 1.01449
Value Function Loss: 1.32853

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.15342
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.09325

Collected Steps per Second: 3,732.61511
Overall Steps per Second: 3,115.66029

Timestep Collection Time: 13.40294
Timestep Consumption Time: 2.65401
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 16.05695

Cumulative Model Updates: 66,213
Cumulative Timesteps: 1,104,423,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557,465.95950
Policy Entropy: 1.01742
Value Function Loss: 1.33702

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.16956
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.09713

Collected Steps per Second: 3,859.62072
Overall Steps per Second: 3,262.77372

Timestep Collection Time: 12.96086
Timestep Consumption Time: 2.37088
PPO Batch Consumption Time: 0.04767
Total Iteration Time: 15.33174

Cumulative Model Updates: 66,216
Cumulative Timesteps: 1,104,473,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1104473876...
Checkpoint 1104473876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730,849.25659
Policy Entropy: 0.99312
Value Function Loss: 1.32344

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.16001
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.09754

Collected Steps per Second: 3,635.52772
Overall Steps per Second: 3,096.76358

Timestep Collection Time: 13.75646
Timestep Consumption Time: 2.39330
PPO Batch Consumption Time: 0.05134
Total Iteration Time: 16.14976

Cumulative Model Updates: 66,219
Cumulative Timesteps: 1,104,523,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652,300.36102
Policy Entropy: 0.98629
Value Function Loss: 1.28997

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.18104
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.09406

Collected Steps per Second: 3,684.08335
Overall Steps per Second: 3,133.36331

Timestep Collection Time: 13.58655
Timestep Consumption Time: 2.38797
PPO Batch Consumption Time: 0.06023
Total Iteration Time: 15.97453

Cumulative Model Updates: 66,222
Cumulative Timesteps: 1,104,573,942

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1104573942...
Checkpoint 1104573942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,942,897.02336
Policy Entropy: 1.00157
Value Function Loss: 1.21902

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 3,683.95826
Overall Steps per Second: 3,084.60821

Timestep Collection Time: 13.57290
Timestep Consumption Time: 2.63726
PPO Batch Consumption Time: 0.05061
Total Iteration Time: 16.21016

Cumulative Model Updates: 66,225
Cumulative Timesteps: 1,104,623,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,060,189.05749
Policy Entropy: 1.01759
Value Function Loss: 1.19708

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.18305
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.09952

Collected Steps per Second: 3,976.72348
Overall Steps per Second: 3,308.32735

Timestep Collection Time: 12.58121
Timestep Consumption Time: 2.54184
PPO Batch Consumption Time: 0.05008
Total Iteration Time: 15.12305

Cumulative Model Updates: 66,228
Cumulative Timesteps: 1,104,673,976

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1104673976...
Checkpoint 1104673976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696,705.33514
Policy Entropy: 0.98365
Value Function Loss: 1.22410

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.10299

Collected Steps per Second: 3,748.85604
Overall Steps per Second: 3,160.08158

Timestep Collection Time: 13.34914
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 15.83630

Cumulative Model Updates: 66,231
Cumulative Timesteps: 1,104,724,020

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602,807.24132
Policy Entropy: 0.99729
Value Function Loss: 1.21757

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.17609
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.09667

Collected Steps per Second: 3,766.46958
Overall Steps per Second: 3,118.49298

Timestep Collection Time: 13.28459
Timestep Consumption Time: 2.76034
PPO Batch Consumption Time: 0.06074
Total Iteration Time: 16.04493

Cumulative Model Updates: 66,234
Cumulative Timesteps: 1,104,774,056

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1104774056...
Checkpoint 1104774056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063,873.17900
Policy Entropy: 0.99542
Value Function Loss: 1.22545

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.18052
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.10633

Collected Steps per Second: 3,788.78949
Overall Steps per Second: 3,175.90202

Timestep Collection Time: 13.19999
Timestep Consumption Time: 2.54734
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 15.74734

Cumulative Model Updates: 66,237
Cumulative Timesteps: 1,104,824,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308,993.23506
Policy Entropy: 0.99503
Value Function Loss: 1.13954

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.15844
Policy Update Magnitude: 0.06265
Value Function Update Magnitude: 0.12109

Collected Steps per Second: 3,895.68665
Overall Steps per Second: 3,211.30626

Timestep Collection Time: 12.83727
Timestep Consumption Time: 2.73583
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 15.57310

Cumulative Model Updates: 66,240
Cumulative Timesteps: 1,104,874,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1104874078...
Checkpoint 1104874078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885,356.14831
Policy Entropy: 0.97539
Value Function Loss: 1.19997

Mean KL Divergence: 0.02685
SB3 Clip Fraction: 0.19646
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.10832

Collected Steps per Second: 3,829.10622
Overall Steps per Second: 3,175.38650

Timestep Collection Time: 13.05788
Timestep Consumption Time: 2.68824
PPO Batch Consumption Time: 0.05346
Total Iteration Time: 15.74611

Cumulative Model Updates: 66,243
Cumulative Timesteps: 1,104,924,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971,610.83796
Policy Entropy: 0.99343
Value Function Loss: 1.20300

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14330
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.11465

Collected Steps per Second: 3,618.88513
Overall Steps per Second: 3,036.78720

Timestep Collection Time: 13.82138
Timestep Consumption Time: 2.64931
PPO Batch Consumption Time: 0.06197
Total Iteration Time: 16.47070

Cumulative Model Updates: 66,246
Cumulative Timesteps: 1,104,974,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1104974096...
Checkpoint 1104974096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,403,962.15518
Policy Entropy: 0.98854
Value Function Loss: 1.18406

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.14906
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 3,729.70750
Overall Steps per Second: 3,134.35024

Timestep Collection Time: 13.40588
Timestep Consumption Time: 2.54639
PPO Batch Consumption Time: 0.04795
Total Iteration Time: 15.95227

Cumulative Model Updates: 66,249
Cumulative Timesteps: 1,105,024,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,023,411.13743
Policy Entropy: 0.98536
Value Function Loss: 1.10034

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 3,995.41355
Overall Steps per Second: 3,315.02270

Timestep Collection Time: 12.52236
Timestep Consumption Time: 2.57015
PPO Batch Consumption Time: 0.05197
Total Iteration Time: 15.09251

Cumulative Model Updates: 66,252
Cumulative Timesteps: 1,105,074,128

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1105074128...
Checkpoint 1105074128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832,469.02939
Policy Entropy: 0.98158
Value Function Loss: 1.10862

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.07578
Value Function Update Magnitude: 0.10010

Collected Steps per Second: 3,792.11232
Overall Steps per Second: 3,164.26766

Timestep Collection Time: 13.19212
Timestep Consumption Time: 2.61754
PPO Batch Consumption Time: 0.05172
Total Iteration Time: 15.80966

Cumulative Model Updates: 66,255
Cumulative Timesteps: 1,105,124,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652,069.48090
Policy Entropy: 0.97301
Value Function Loss: 1.08741

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.07619
Value Function Update Magnitude: 0.09894

Collected Steps per Second: 3,908.67010
Overall Steps per Second: 3,288.63085

Timestep Collection Time: 12.80538
Timestep Consumption Time: 2.41433
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 15.21971

Cumulative Model Updates: 66,258
Cumulative Timesteps: 1,105,174,206

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1105174206...
Checkpoint 1105174206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966,222.04693
Policy Entropy: 0.98778
Value Function Loss: 1.12566

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.16656
Policy Update Magnitude: 0.06960
Value Function Update Magnitude: 0.09481

Collected Steps per Second: 3,718.97552
Overall Steps per Second: 3,142.14010

Timestep Collection Time: 13.45155
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.06049
Total Iteration Time: 15.92100

Cumulative Model Updates: 66,261
Cumulative Timesteps: 1,105,224,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,302,417.34140
Policy Entropy: 1.01636
Value Function Loss: 1.05739

Mean KL Divergence: 0.02439
SB3 Clip Fraction: 0.19275
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.09515

Collected Steps per Second: 3,818.03967
Overall Steps per Second: 3,176.10486

Timestep Collection Time: 13.10044
Timestep Consumption Time: 2.64778
PPO Batch Consumption Time: 0.05170
Total Iteration Time: 15.74822

Cumulative Model Updates: 66,264
Cumulative Timesteps: 1,105,274,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1105274250...
Checkpoint 1105274250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,862,319.98107
Policy Entropy: 0.98653
Value Function Loss: 1.11376

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.08851

Collected Steps per Second: 3,880.36625
Overall Steps per Second: 3,210.01944

Timestep Collection Time: 12.88796
Timestep Consumption Time: 2.69139
PPO Batch Consumption Time: 0.05959
Total Iteration Time: 15.57934

Cumulative Model Updates: 66,267
Cumulative Timesteps: 1,105,324,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971,710.46407
Policy Entropy: 0.99766
Value Function Loss: 1.12911

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.08002

Collected Steps per Second: 3,668.23952
Overall Steps per Second: 3,029.00928

Timestep Collection Time: 13.63597
Timestep Consumption Time: 2.87768
PPO Batch Consumption Time: 0.06470
Total Iteration Time: 16.51365

Cumulative Model Updates: 66,270
Cumulative Timesteps: 1,105,374,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1105374280...
Checkpoint 1105374280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085,142.27581
Policy Entropy: 0.99532
Value Function Loss: 1.21256

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.06787
Value Function Update Magnitude: 0.07759

Collected Steps per Second: 3,780.01712
Overall Steps per Second: 3,153.34557

Timestep Collection Time: 13.23222
Timestep Consumption Time: 2.62967
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 15.86188

Cumulative Model Updates: 66,273
Cumulative Timesteps: 1,105,424,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,557,459.60758
Policy Entropy: 1.01071
Value Function Loss: 1.25092

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.07632
Value Function Update Magnitude: 0.06935

Collected Steps per Second: 3,618.47108
Overall Steps per Second: 3,033.72806

Timestep Collection Time: 13.82131
Timestep Consumption Time: 2.66402
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 16.48533

Cumulative Model Updates: 66,276
Cumulative Timesteps: 1,105,474,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1105474310...
Checkpoint 1105474310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,726,549.05566
Policy Entropy: 1.01866
Value Function Loss: 1.24543

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.08215
Value Function Update Magnitude: 0.06554

Collected Steps per Second: 3,810.20624
Overall Steps per Second: 3,145.89184

Timestep Collection Time: 13.13577
Timestep Consumption Time: 2.77387
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 15.90964

Cumulative Model Updates: 66,279
Cumulative Timesteps: 1,105,524,360

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755,409.13245
Policy Entropy: 1.01671
Value Function Loss: 1.19259

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.09282
Value Function Update Magnitude: 0.07489

Collected Steps per Second: 3,638.69209
Overall Steps per Second: 3,068.86163

Timestep Collection Time: 13.74615
Timestep Consumption Time: 2.55240
PPO Batch Consumption Time: 0.04773
Total Iteration Time: 16.29855

Cumulative Model Updates: 66,282
Cumulative Timesteps: 1,105,574,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1105574378...
Checkpoint 1105574378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722,058.03983
Policy Entropy: 1.00846
Value Function Loss: 1.21172

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.08702
Value Function Update Magnitude: 0.07542

Collected Steps per Second: 3,695.79868
Overall Steps per Second: 3,087.57242

Timestep Collection Time: 13.53429
Timestep Consumption Time: 2.66614
PPO Batch Consumption Time: 0.06672
Total Iteration Time: 16.20043

Cumulative Model Updates: 66,285
Cumulative Timesteps: 1,105,624,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134,803.48295
Policy Entropy: 1.00204
Value Function Loss: 1.24597

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.08623
Value Function Update Magnitude: 0.09054

Collected Steps per Second: 3,832.60719
Overall Steps per Second: 3,191.41806

Timestep Collection Time: 13.05639
Timestep Consumption Time: 2.62316
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 15.67955

Cumulative Model Updates: 66,288
Cumulative Timesteps: 1,105,674,438

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1105674438...
Checkpoint 1105674438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634,300.93027
Policy Entropy: 0.99469
Value Function Loss: 1.30850

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.16523
Policy Update Magnitude: 0.08093
Value Function Update Magnitude: 0.11005

Collected Steps per Second: 3,805.72029
Overall Steps per Second: 3,193.45581

Timestep Collection Time: 13.13969
Timestep Consumption Time: 2.51920
PPO Batch Consumption Time: 0.05989
Total Iteration Time: 15.65890

Cumulative Model Updates: 66,291
Cumulative Timesteps: 1,105,724,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126,517.51584
Policy Entropy: 1.01659
Value Function Loss: 1.25497

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.16635
Policy Update Magnitude: 0.06788
Value Function Update Magnitude: 0.11250

Collected Steps per Second: 3,668.02031
Overall Steps per Second: 3,066.15118

Timestep Collection Time: 13.63569
Timestep Consumption Time: 2.67661
PPO Batch Consumption Time: 0.06188
Total Iteration Time: 16.31231

Cumulative Model Updates: 66,294
Cumulative Timesteps: 1,105,774,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1105774460...
Checkpoint 1105774460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522,428.28993
Policy Entropy: 1.01553
Value Function Loss: 1.18134

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.16193
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.10238

Collected Steps per Second: 3,850.99985
Overall Steps per Second: 3,224.83121

Timestep Collection Time: 12.99351
Timestep Consumption Time: 2.52296
PPO Batch Consumption Time: 0.06045
Total Iteration Time: 15.51647

Cumulative Model Updates: 66,297
Cumulative Timesteps: 1,105,824,498

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,532,220.25040
Policy Entropy: 1.00923
Value Function Loss: 1.17189

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.15193
Policy Update Magnitude: 0.06929
Value Function Update Magnitude: 0.09266

Collected Steps per Second: 3,779.28792
Overall Steps per Second: 3,207.13985

Timestep Collection Time: 13.23741
Timestep Consumption Time: 2.36153
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 15.59895

Cumulative Model Updates: 66,300
Cumulative Timesteps: 1,105,874,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1105874526...
Checkpoint 1105874526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,836,600.71154
Policy Entropy: 1.00162
Value Function Loss: 1.18483

Mean KL Divergence: 0.02753
SB3 Clip Fraction: 0.21045
Policy Update Magnitude: 0.06244
Value Function Update Magnitude: 0.09164

Collected Steps per Second: 3,731.50200
Overall Steps per Second: 3,141.59772

Timestep Collection Time: 13.40747
Timestep Consumption Time: 2.51755
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 15.92502

Cumulative Model Updates: 66,303
Cumulative Timesteps: 1,105,924,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506,345.63129
Policy Entropy: 1.01044
Value Function Loss: 1.24160

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.06785
Value Function Update Magnitude: 0.09922

Collected Steps per Second: 3,997.97548
Overall Steps per Second: 3,262.57497

Timestep Collection Time: 12.51633
Timestep Consumption Time: 2.82124
PPO Batch Consumption Time: 0.05090
Total Iteration Time: 15.33758

Cumulative Model Updates: 66,306
Cumulative Timesteps: 1,105,974,596

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1105974596...
Checkpoint 1105974596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871,688.48636
Policy Entropy: 1.02359
Value Function Loss: 1.24440

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.07165
Value Function Update Magnitude: 0.09639

Collected Steps per Second: 4,090.33086
Overall Steps per Second: 3,313.89627

Timestep Collection Time: 12.23128
Timestep Consumption Time: 2.86575
PPO Batch Consumption Time: 0.05941
Total Iteration Time: 15.09703

Cumulative Model Updates: 66,309
Cumulative Timesteps: 1,106,024,626

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,986,637.62372
Policy Entropy: 1.00054
Value Function Loss: 1.22111

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.16446
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.10418

Collected Steps per Second: 3,890.16852
Overall Steps per Second: 3,216.53190

Timestep Collection Time: 12.86165
Timestep Consumption Time: 2.69361
PPO Batch Consumption Time: 0.05843
Total Iteration Time: 15.55526

Cumulative Model Updates: 66,312
Cumulative Timesteps: 1,106,074,660

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1106074660...
Checkpoint 1106074660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518,905.91236
Policy Entropy: 1.00120
Value Function Loss: 1.20803

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.17876
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.11932

Collected Steps per Second: 3,731.03616
Overall Steps per Second: 3,129.26351

Timestep Collection Time: 13.40539
Timestep Consumption Time: 2.57792
PPO Batch Consumption Time: 0.06228
Total Iteration Time: 15.98331

Cumulative Model Updates: 66,315
Cumulative Timesteps: 1,106,124,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026,695.91720
Policy Entropy: 1.01683
Value Function Loss: 1.18556

Mean KL Divergence: 0.02414
SB3 Clip Fraction: 0.17195
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.13685

Collected Steps per Second: 3,703.24235
Overall Steps per Second: 3,108.75126

Timestep Collection Time: 13.50762
Timestep Consumption Time: 2.58308
PPO Batch Consumption Time: 0.05800
Total Iteration Time: 16.09071

Cumulative Model Updates: 66,318
Cumulative Timesteps: 1,106,174,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1106174698...
Checkpoint 1106174698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925,206.62665
Policy Entropy: 1.01906
Value Function Loss: 1.21152

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.17355
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.12926

Collected Steps per Second: 3,693.69603
Overall Steps per Second: 3,089.76813

Timestep Collection Time: 13.53658
Timestep Consumption Time: 2.64587
PPO Batch Consumption Time: 0.04992
Total Iteration Time: 16.18244

Cumulative Model Updates: 66,321
Cumulative Timesteps: 1,106,224,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238,805.98491
Policy Entropy: 1.01492
Value Function Loss: 1.26016

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.11911

Collected Steps per Second: 3,731.05501
Overall Steps per Second: 3,098.25783

Timestep Collection Time: 13.41604
Timestep Consumption Time: 2.74013
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 16.15618

Cumulative Model Updates: 66,324
Cumulative Timesteps: 1,106,274,754

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1106274754...
Checkpoint 1106274754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756,327.94733
Policy Entropy: 1.00334
Value Function Loss: 1.25252

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.18511
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.12743

Collected Steps per Second: 3,611.20344
Overall Steps per Second: 3,015.00734

Timestep Collection Time: 13.85411
Timestep Consumption Time: 2.73955
PPO Batch Consumption Time: 0.05968
Total Iteration Time: 16.59366

Cumulative Model Updates: 66,327
Cumulative Timesteps: 1,106,324,784

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,178,417.68853
Policy Entropy: 1.02161
Value Function Loss: 1.20219

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.12981

Collected Steps per Second: 3,898.67900
Overall Steps per Second: 3,229.05478

Timestep Collection Time: 12.82896
Timestep Consumption Time: 2.66040
PPO Batch Consumption Time: 0.05896
Total Iteration Time: 15.48936

Cumulative Model Updates: 66,330
Cumulative Timesteps: 1,106,374,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1106374800...
Checkpoint 1106374800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,082,414.23097
Policy Entropy: 1.01611
Value Function Loss: 1.23943

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.12020

Collected Steps per Second: 3,814.73004
Overall Steps per Second: 3,200.24213

Timestep Collection Time: 13.11285
Timestep Consumption Time: 2.51784
PPO Batch Consumption Time: 0.04803
Total Iteration Time: 15.63069

Cumulative Model Updates: 66,333
Cumulative Timesteps: 1,106,424,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713,159.99225
Policy Entropy: 1.00973
Value Function Loss: 1.27134

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.06484
Value Function Update Magnitude: 0.11050

Collected Steps per Second: 3,909.77547
Overall Steps per Second: 3,331.89733

Timestep Collection Time: 12.79562
Timestep Consumption Time: 2.21925
PPO Batch Consumption Time: 0.05363
Total Iteration Time: 15.01487

Cumulative Model Updates: 66,336
Cumulative Timesteps: 1,106,474,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1106474850...
Checkpoint 1106474850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687,959.55565
Policy Entropy: 0.99949
Value Function Loss: 1.28314

Mean KL Divergence: 0.02611
SB3 Clip Fraction: 0.19169
Policy Update Magnitude: 0.06278
Value Function Update Magnitude: 0.11576

Collected Steps per Second: 3,599.93392
Overall Steps per Second: 3,069.96202

Timestep Collection Time: 13.90081
Timestep Consumption Time: 2.39972
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 16.30053

Cumulative Model Updates: 66,339
Cumulative Timesteps: 1,106,524,892

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922,011.79757
Policy Entropy: 1.02432
Value Function Loss: 1.20947

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.06907
Value Function Update Magnitude: 0.12064

Collected Steps per Second: 3,681.30896
Overall Steps per Second: 3,135.54663

Timestep Collection Time: 13.58593
Timestep Consumption Time: 2.36472
PPO Batch Consumption Time: 0.06580
Total Iteration Time: 15.95065

Cumulative Model Updates: 66,342
Cumulative Timesteps: 1,106,574,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1106574906...
Checkpoint 1106574906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948,811.30004
Policy Entropy: 1.03260
Value Function Loss: 1.18887

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.06576
Value Function Update Magnitude: 0.12557

Collected Steps per Second: 3,703.94799
Overall Steps per Second: 3,194.34025

Timestep Collection Time: 13.51045
Timestep Consumption Time: 2.15538
PPO Batch Consumption Time: 0.05941
Total Iteration Time: 15.66583

Cumulative Model Updates: 66,345
Cumulative Timesteps: 1,106,624,948

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734,641.86345
Policy Entropy: 1.01107
Value Function Loss: 1.18250

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.06337
Value Function Update Magnitude: 0.13603

Collected Steps per Second: 3,618.12457
Overall Steps per Second: 3,001.16070

Timestep Collection Time: 13.82429
Timestep Consumption Time: 2.84193
PPO Batch Consumption Time: 0.05891
Total Iteration Time: 16.66622

Cumulative Model Updates: 66,348
Cumulative Timesteps: 1,106,674,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1106674966...
Checkpoint 1106674966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,045,992.58099
Policy Entropy: 1.00141
Value Function Loss: 1.15564

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.16917
Policy Update Magnitude: 0.06600
Value Function Update Magnitude: 0.14792

Collected Steps per Second: 4,007.85481
Overall Steps per Second: 3,287.74733

Timestep Collection Time: 12.47999
Timestep Consumption Time: 2.73346
PPO Batch Consumption Time: 0.05151
Total Iteration Time: 15.21346

Cumulative Model Updates: 66,351
Cumulative Timesteps: 1,106,724,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,519,466.98228
Policy Entropy: 1.01689
Value Function Loss: 1.23596

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.14735

Collected Steps per Second: 4,156.58047
Overall Steps per Second: 3,396.17022

Timestep Collection Time: 12.03634
Timestep Consumption Time: 2.69496
PPO Batch Consumption Time: 0.05062
Total Iteration Time: 14.73130

Cumulative Model Updates: 66,354
Cumulative Timesteps: 1,106,775,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1106775014...
Checkpoint 1106775014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136,780.89530
Policy Entropy: 1.02347
Value Function Loss: 1.27296

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.16144
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.14132

Collected Steps per Second: 4,030.17368
Overall Steps per Second: 3,303.69886

Timestep Collection Time: 12.41237
Timestep Consumption Time: 2.72945
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 15.14182

Cumulative Model Updates: 66,357
Cumulative Timesteps: 1,106,825,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699,984.79949
Policy Entropy: 1.00440
Value Function Loss: 1.28047

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.13145

Collected Steps per Second: 4,036.34219
Overall Steps per Second: 3,332.47040

Timestep Collection Time: 12.39191
Timestep Consumption Time: 2.61737
PPO Batch Consumption Time: 0.05362
Total Iteration Time: 15.00929

Cumulative Model Updates: 66,360
Cumulative Timesteps: 1,106,875,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1106875056...
Checkpoint 1106875056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731,598.54166
Policy Entropy: 0.99789
Value Function Loss: 1.19103

Mean KL Divergence: 0.02391
SB3 Clip Fraction: 0.16082
Policy Update Magnitude: 0.06461
Value Function Update Magnitude: 0.12603

Collected Steps per Second: 3,834.97725
Overall Steps per Second: 3,195.81479

Timestep Collection Time: 13.04206
Timestep Consumption Time: 2.60841
PPO Batch Consumption Time: 0.05268
Total Iteration Time: 15.65047

Cumulative Model Updates: 66,363
Cumulative Timesteps: 1,106,925,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,789,467.79488
Policy Entropy: 1.01390
Value Function Loss: 1.20098

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.11076

Collected Steps per Second: 3,664.10087
Overall Steps per Second: 3,081.17148

Timestep Collection Time: 13.65410
Timestep Consumption Time: 2.58323
PPO Batch Consumption Time: 0.06244
Total Iteration Time: 16.23733

Cumulative Model Updates: 66,366
Cumulative Timesteps: 1,106,975,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1106975102...
Checkpoint 1106975102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609,466.30968
Policy Entropy: 1.02377
Value Function Loss: 1.28135

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.15953
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.10762

Collected Steps per Second: 3,991.78227
Overall Steps per Second: 3,308.92156

Timestep Collection Time: 12.53475
Timestep Consumption Time: 2.58679
PPO Batch Consumption Time: 0.04945
Total Iteration Time: 15.12154

Cumulative Model Updates: 66,369
Cumulative Timesteps: 1,107,025,138

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997,233.01725
Policy Entropy: 1.00559
Value Function Loss: 1.27846

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.12029

Collected Steps per Second: 3,725.02833
Overall Steps per Second: 3,175.11492

Timestep Collection Time: 13.42916
Timestep Consumption Time: 2.32586
PPO Batch Consumption Time: 0.05260
Total Iteration Time: 15.75502

Cumulative Model Updates: 66,372
Cumulative Timesteps: 1,107,075,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1107075162...
Checkpoint 1107075162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,187,326.93338
Policy Entropy: 1.01398
Value Function Loss: 1.21022

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13930
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.12847

Collected Steps per Second: 3,675.59804
Overall Steps per Second: 3,101.89415

Timestep Collection Time: 13.61085
Timestep Consumption Time: 2.51736
PPO Batch Consumption Time: 0.05912
Total Iteration Time: 16.12821

Cumulative Model Updates: 66,375
Cumulative Timesteps: 1,107,125,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829,728.45443
Policy Entropy: 1.02743
Value Function Loss: 1.24709

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.06127
Value Function Update Magnitude: 0.12894

Collected Steps per Second: 3,852.75565
Overall Steps per Second: 3,208.72517

Timestep Collection Time: 12.98136
Timestep Consumption Time: 2.60552
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 15.58688

Cumulative Model Updates: 66,378
Cumulative Timesteps: 1,107,175,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1107175204...
Checkpoint 1107175204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465,796.35010
Policy Entropy: 1.02850
Value Function Loss: 1.31012

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.07063
Value Function Update Magnitude: 0.12835

Collected Steps per Second: 3,895.89129
Overall Steps per Second: 3,243.43617

Timestep Collection Time: 12.84019
Timestep Consumption Time: 2.58296
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 15.42315

Cumulative Model Updates: 66,381
Cumulative Timesteps: 1,107,225,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495,763.24594
Policy Entropy: 1.01869
Value Function Loss: 1.42986

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.15409
Policy Update Magnitude: 0.07333
Value Function Update Magnitude: 0.13249

Collected Steps per Second: 3,730.02317
Overall Steps per Second: 3,110.00720

Timestep Collection Time: 13.41279
Timestep Consumption Time: 2.67399
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 16.08678

Cumulative Model Updates: 66,384
Cumulative Timesteps: 1,107,275,258

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1107275258...
Checkpoint 1107275258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493,496.41895
Policy Entropy: 1.00090
Value Function Loss: 1.41352

Mean KL Divergence: 0.03254
SB3 Clip Fraction: 0.20193
Policy Update Magnitude: 0.06914
Value Function Update Magnitude: 0.13442

Collected Steps per Second: 3,890.27678
Overall Steps per Second: 3,241.33777

Timestep Collection Time: 12.86489
Timestep Consumption Time: 2.57564
PPO Batch Consumption Time: 0.05044
Total Iteration Time: 15.44054

Cumulative Model Updates: 66,387
Cumulative Timesteps: 1,107,325,306

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490,849.73148
Policy Entropy: 1.01946
Value Function Loss: 1.38082

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.06627
Value Function Update Magnitude: 0.12123

Collected Steps per Second: 3,926.64468
Overall Steps per Second: 3,292.02233

Timestep Collection Time: 12.74320
Timestep Consumption Time: 2.45658
PPO Batch Consumption Time: 0.05329
Total Iteration Time: 15.19978

Cumulative Model Updates: 66,390
Cumulative Timesteps: 1,107,375,344

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1107375344...
Checkpoint 1107375344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485,528.67503
Policy Entropy: 1.01728
Value Function Loss: 1.36654

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.07043
Value Function Update Magnitude: 0.10728

Collected Steps per Second: 3,813.17851
Overall Steps per Second: 3,167.98408

Timestep Collection Time: 13.12606
Timestep Consumption Time: 2.67326
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 15.79932

Cumulative Model Updates: 66,393
Cumulative Timesteps: 1,107,425,396

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470,561.56164
Policy Entropy: 1.00798
Value Function Loss: 1.32023

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.07492
Value Function Update Magnitude: 0.11482

Collected Steps per Second: 3,977.16943
Overall Steps per Second: 3,288.45325

Timestep Collection Time: 12.57980
Timestep Consumption Time: 2.63465
PPO Batch Consumption Time: 0.05132
Total Iteration Time: 15.21445

Cumulative Model Updates: 66,396
Cumulative Timesteps: 1,107,475,428

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1107475428...
Checkpoint 1107475428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639,883.36779
Policy Entropy: 1.00445
Value Function Loss: 1.30975

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.08147
Value Function Update Magnitude: 0.13017

Collected Steps per Second: 3,890.15035
Overall Steps per Second: 3,262.34475

Timestep Collection Time: 12.85914
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 15.33376

Cumulative Model Updates: 66,399
Cumulative Timesteps: 1,107,525,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707,257.80055
Policy Entropy: 1.00900
Value Function Loss: 1.25129

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.08109
Value Function Update Magnitude: 0.13137

Collected Steps per Second: 3,958.46636
Overall Steps per Second: 3,264.16866

Timestep Collection Time: 12.63368
Timestep Consumption Time: 2.68722
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 15.32090

Cumulative Model Updates: 66,402
Cumulative Timesteps: 1,107,575,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1107575462...
Checkpoint 1107575462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,239,778.83724
Policy Entropy: 1.01251
Value Function Loss: 1.22299

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.07959
Value Function Update Magnitude: 0.12107

Collected Steps per Second: 3,724.95191
Overall Steps per Second: 3,161.54541

Timestep Collection Time: 13.42299
Timestep Consumption Time: 2.39206
PPO Batch Consumption Time: 0.05307
Total Iteration Time: 15.81505

Cumulative Model Updates: 66,405
Cumulative Timesteps: 1,107,625,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154,295.39573
Policy Entropy: 0.99645
Value Function Loss: 1.24147

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.16904
Policy Update Magnitude: 0.07734
Value Function Update Magnitude: 0.10790

Collected Steps per Second: 3,817.14654
Overall Steps per Second: 3,227.75123

Timestep Collection Time: 13.10141
Timestep Consumption Time: 2.39235
PPO Batch Consumption Time: 0.04797
Total Iteration Time: 15.49376

Cumulative Model Updates: 66,408
Cumulative Timesteps: 1,107,675,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1107675472...
Checkpoint 1107675472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374,990.00957
Policy Entropy: 1.01541
Value Function Loss: 1.24949

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.16606
Policy Update Magnitude: 0.06689
Value Function Update Magnitude: 0.10920

Collected Steps per Second: 3,912.89774
Overall Steps per Second: 3,282.22444

Timestep Collection Time: 12.78694
Timestep Consumption Time: 2.45699
PPO Batch Consumption Time: 0.05172
Total Iteration Time: 15.24393

Cumulative Model Updates: 66,411
Cumulative Timesteps: 1,107,725,506

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,709,286.61887
Policy Entropy: 1.00597
Value Function Loss: 1.29685

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.16885
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.11741

Collected Steps per Second: 4,082.04641
Overall Steps per Second: 3,390.97289

Timestep Collection Time: 12.25219
Timestep Consumption Time: 2.49697
PPO Batch Consumption Time: 0.04416
Total Iteration Time: 14.74916

Cumulative Model Updates: 66,414
Cumulative Timesteps: 1,107,775,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1107775520...
Checkpoint 1107775520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,859,966.66067
Policy Entropy: 0.99862
Value Function Loss: 1.31556

Mean KL Divergence: 0.02254
SB3 Clip Fraction: 0.15208
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.11694

Collected Steps per Second: 3,829.34121
Overall Steps per Second: 3,008.93929

Timestep Collection Time: 13.05760
Timestep Consumption Time: 3.56022
PPO Batch Consumption Time: 0.05264
Total Iteration Time: 16.61782

Cumulative Model Updates: 66,417
Cumulative Timesteps: 1,107,825,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,810,024.59815
Policy Entropy: 0.99757
Value Function Loss: 1.23930

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.18598
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.12207

Collected Steps per Second: 3,972.98914
Overall Steps per Second: 3,227.17322

Timestep Collection Time: 12.59102
Timestep Consumption Time: 2.90985
PPO Batch Consumption Time: 0.05361
Total Iteration Time: 15.50087

Cumulative Model Updates: 66,420
Cumulative Timesteps: 1,107,875,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1107875546...
Checkpoint 1107875546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545,417.20728
Policy Entropy: 1.01465
Value Function Loss: 1.23537

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.12035

Collected Steps per Second: 3,963.63187
Overall Steps per Second: 3,097.34965

Timestep Collection Time: 12.61520
Timestep Consumption Time: 3.52828
PPO Batch Consumption Time: 0.06863
Total Iteration Time: 16.14348

Cumulative Model Updates: 66,423
Cumulative Timesteps: 1,107,925,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568,448.11301
Policy Entropy: 1.01443
Value Function Loss: 1.20111

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.16895
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.12176

Collected Steps per Second: 3,929.77882
Overall Steps per Second: 3,146.99800

Timestep Collection Time: 12.72794
Timestep Consumption Time: 3.16593
PPO Batch Consumption Time: 0.05380
Total Iteration Time: 15.89388

Cumulative Model Updates: 66,426
Cumulative Timesteps: 1,107,975,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1107975566...
Checkpoint 1107975566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,161,022.07932
Policy Entropy: 0.99702
Value Function Loss: 1.19318

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.12464

Collected Steps per Second: 4,059.40264
Overall Steps per Second: 3,213.58941

Timestep Collection Time: 12.32004
Timestep Consumption Time: 3.24262
PPO Batch Consumption Time: 0.05942
Total Iteration Time: 15.56266

Cumulative Model Updates: 66,429
Cumulative Timesteps: 1,108,025,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609,322.11080
Policy Entropy: 0.98968
Value Function Loss: 1.14296

Mean KL Divergence: 0.02447
SB3 Clip Fraction: 0.18727
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.11083

Collected Steps per Second: 3,881.89274
Overall Steps per Second: 3,237.51754

Timestep Collection Time: 12.88598
Timestep Consumption Time: 2.56475
PPO Batch Consumption Time: 0.04651
Total Iteration Time: 15.45073

Cumulative Model Updates: 66,432
Cumulative Timesteps: 1,108,075,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1108075600...
Checkpoint 1108075600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744,660.01974
Policy Entropy: 1.00383
Value Function Loss: 1.14075

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.05972
Value Function Update Magnitude: 0.09560

Collected Steps per Second: 3,750.71295
Overall Steps per Second: 3,161.65092

Timestep Collection Time: 13.34306
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 15.82907

Cumulative Model Updates: 66,435
Cumulative Timesteps: 1,108,125,646

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872,914.12654
Policy Entropy: 1.02149
Value Function Loss: 1.19968

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.15887
Policy Update Magnitude: 0.06849
Value Function Update Magnitude: 0.09607

Collected Steps per Second: 3,819.77830
Overall Steps per Second: 3,196.28735

Timestep Collection Time: 13.09710
Timestep Consumption Time: 2.55481
PPO Batch Consumption Time: 0.06152
Total Iteration Time: 15.65191

Cumulative Model Updates: 66,438
Cumulative Timesteps: 1,108,175,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1108175674...
Checkpoint 1108175674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022,026.37756
Policy Entropy: 0.99632
Value Function Loss: 1.20252

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.15746
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.10117

Collected Steps per Second: 3,888.23963
Overall Steps per Second: 3,263.30821

Timestep Collection Time: 12.86906
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.05930
Total Iteration Time: 15.33352

Cumulative Model Updates: 66,441
Cumulative Timesteps: 1,108,225,712

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278,644.64962
Policy Entropy: 1.00853
Value Function Loss: 1.14928

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.09980

Collected Steps per Second: 3,920.64980
Overall Steps per Second: 3,275.78962

Timestep Collection Time: 12.75452
Timestep Consumption Time: 2.51081
PPO Batch Consumption Time: 0.06269
Total Iteration Time: 15.26533

Cumulative Model Updates: 66,444
Cumulative Timesteps: 1,108,275,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1108275718...
Checkpoint 1108275718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505,272.99626
Policy Entropy: 1.02538
Value Function Loss: 1.22012

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.16031
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.09813

Collected Steps per Second: 3,646.66530
Overall Steps per Second: 3,109.18401

Timestep Collection Time: 13.72322
Timestep Consumption Time: 2.37232
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 16.09554

Cumulative Model Updates: 66,447
Cumulative Timesteps: 1,108,325,762

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147,152.15825
Policy Entropy: 1.02482
Value Function Loss: 1.25866

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.17211
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.09063

Collected Steps per Second: 3,977.38743
Overall Steps per Second: 3,288.63797

Timestep Collection Time: 12.58263
Timestep Consumption Time: 2.63522
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 15.21785

Cumulative Model Updates: 66,450
Cumulative Timesteps: 1,108,375,808

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1108375808...
Checkpoint 1108375808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702,849.30995
Policy Entropy: 1.01357
Value Function Loss: 1.32175

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.15306
Policy Update Magnitude: 0.06514
Value Function Update Magnitude: 0.11115

Collected Steps per Second: 3,897.88024
Overall Steps per Second: 3,212.95730

Timestep Collection Time: 12.83723
Timestep Consumption Time: 2.73658
PPO Batch Consumption Time: 0.05134
Total Iteration Time: 15.57381

Cumulative Model Updates: 66,453
Cumulative Timesteps: 1,108,425,846

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003,943.30302
Policy Entropy: 1.01094
Value Function Loss: 1.32508

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.11643

Collected Steps per Second: 3,909.35575
Overall Steps per Second: 3,245.10707

Timestep Collection Time: 12.79392
Timestep Consumption Time: 2.61882
PPO Batch Consumption Time: 0.05002
Total Iteration Time: 15.41274

Cumulative Model Updates: 66,456
Cumulative Timesteps: 1,108,475,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1108475862...
Checkpoint 1108475862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,681,687.58209
Policy Entropy: 1.01981
Value Function Loss: 1.28685

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.07446
Value Function Update Magnitude: 0.12520

Collected Steps per Second: 3,800.50006
Overall Steps per Second: 3,135.88065

Timestep Collection Time: 13.16248
Timestep Consumption Time: 2.78966
PPO Batch Consumption Time: 0.06017
Total Iteration Time: 15.95214

Cumulative Model Updates: 66,459
Cumulative Timesteps: 1,108,525,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655,669.13422
Policy Entropy: 1.01981
Value Function Loss: 1.28895

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.07842
Value Function Update Magnitude: 0.13508

Collected Steps per Second: 3,791.14314
Overall Steps per Second: 3,148.83347

Timestep Collection Time: 13.19022
Timestep Consumption Time: 2.69058
PPO Batch Consumption Time: 0.05914
Total Iteration Time: 15.88080

Cumulative Model Updates: 66,462
Cumulative Timesteps: 1,108,575,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1108575892...
Checkpoint 1108575892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077,350.25146
Policy Entropy: 1.02796
Value Function Loss: 1.24125

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.07549
Value Function Update Magnitude: 0.12775

Collected Steps per Second: 3,656.69978
Overall Steps per Second: 3,095.37358

Timestep Collection Time: 13.68830
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.04767
Total Iteration Time: 16.17058

Cumulative Model Updates: 66,465
Cumulative Timesteps: 1,108,625,946

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930,773.42637
Policy Entropy: 1.02910
Value Function Loss: 1.25294

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.08062
Value Function Update Magnitude: 0.10868

Collected Steps per Second: 3,817.71705
Overall Steps per Second: 3,210.60130

Timestep Collection Time: 13.10469
Timestep Consumption Time: 2.47806
PPO Batch Consumption Time: 0.06330
Total Iteration Time: 15.58275

Cumulative Model Updates: 66,468
Cumulative Timesteps: 1,108,675,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1108675976...
Checkpoint 1108675976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,190,592.87027
Policy Entropy: 1.02809
Value Function Loss: 1.27758

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.08072
Value Function Update Magnitude: 0.09849

Collected Steps per Second: 3,730.30105
Overall Steps per Second: 3,153.84329

Timestep Collection Time: 13.41339
Timestep Consumption Time: 2.45169
PPO Batch Consumption Time: 0.06114
Total Iteration Time: 15.86509

Cumulative Model Updates: 66,471
Cumulative Timesteps: 1,108,726,012

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,244,520.95976
Policy Entropy: 1.02273
Value Function Loss: 1.23131

Mean KL Divergence: 0.02725
SB3 Clip Fraction: 0.17269
Policy Update Magnitude: 0.07141
Value Function Update Magnitude: 0.11687

Collected Steps per Second: 3,691.95565
Overall Steps per Second: 3,073.68564

Timestep Collection Time: 13.55704
Timestep Consumption Time: 2.72699
PPO Batch Consumption Time: 0.05970
Total Iteration Time: 16.28403

Cumulative Model Updates: 66,474
Cumulative Timesteps: 1,108,776,064

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1108776064...
Checkpoint 1108776064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,130,076.83563
Policy Entropy: 1.03664
Value Function Loss: 1.25948

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.06346
Value Function Update Magnitude: 0.12999

Collected Steps per Second: 3,748.04296
Overall Steps per Second: 3,160.10055

Timestep Collection Time: 13.34403
Timestep Consumption Time: 2.48268
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 15.82671

Cumulative Model Updates: 66,477
Cumulative Timesteps: 1,108,826,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511,094.70898
Policy Entropy: 1.03590
Value Function Loss: 1.19337

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.06825
Value Function Update Magnitude: 0.13916

Collected Steps per Second: 3,956.72407
Overall Steps per Second: 3,323.96123

Timestep Collection Time: 12.64683
Timestep Consumption Time: 2.40750
PPO Batch Consumption Time: 0.05965
Total Iteration Time: 15.05433

Cumulative Model Updates: 66,480
Cumulative Timesteps: 1,108,876,118

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1108876118...
Checkpoint 1108876118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,565,108.35558
Policy Entropy: 1.02592
Value Function Loss: 1.24155

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.06372
Value Function Update Magnitude: 0.13868

Collected Steps per Second: 3,832.47960
Overall Steps per Second: 3,222.68359

Timestep Collection Time: 13.05160
Timestep Consumption Time: 2.46962
PPO Batch Consumption Time: 0.06215
Total Iteration Time: 15.52123

Cumulative Model Updates: 66,483
Cumulative Timesteps: 1,108,926,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617,534.65125
Policy Entropy: 1.01205
Value Function Loss: 1.22953

Mean KL Divergence: 0.02788
SB3 Clip Fraction: 0.18279
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.12706

Collected Steps per Second: 3,573.59205
Overall Steps per Second: 3,054.70156

Timestep Collection Time: 14.00160
Timestep Consumption Time: 2.37840
PPO Batch Consumption Time: 0.05308
Total Iteration Time: 16.38000

Cumulative Model Updates: 66,486
Cumulative Timesteps: 1,108,976,174

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1108976174...
Checkpoint 1108976174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376,183.61336
Policy Entropy: 1.03303
Value Function Loss: 1.25199

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.12181

Collected Steps per Second: 3,792.78013
Overall Steps per Second: 3,209.94496

Timestep Collection Time: 13.19296
Timestep Consumption Time: 2.39547
PPO Batch Consumption Time: 0.05285
Total Iteration Time: 15.58843

Cumulative Model Updates: 66,489
Cumulative Timesteps: 1,109,026,212

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528,991.68083
Policy Entropy: 1.03871
Value Function Loss: 1.20098

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 3,806.29058
Overall Steps per Second: 3,194.68958

Timestep Collection Time: 13.14456
Timestep Consumption Time: 2.51643
PPO Batch Consumption Time: 0.04854
Total Iteration Time: 15.66099

Cumulative Model Updates: 66,492
Cumulative Timesteps: 1,109,076,244

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1109076244...
Checkpoint 1109076244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828,129.58208
Policy Entropy: 1.03045
Value Function Loss: 1.20052

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.10570

Collected Steps per Second: 3,748.91336
Overall Steps per Second: 3,158.70148

Timestep Collection Time: 13.34040
Timestep Consumption Time: 2.49269
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 15.83309

Cumulative Model Updates: 66,495
Cumulative Timesteps: 1,109,126,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247,986.48686
Policy Entropy: 1.01601
Value Function Loss: 1.16765

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.17834
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.10515

Collected Steps per Second: 3,732.29600
Overall Steps per Second: 3,124.51263

Timestep Collection Time: 13.39926
Timestep Consumption Time: 2.60644
PPO Batch Consumption Time: 0.04912
Total Iteration Time: 16.00570

Cumulative Model Updates: 66,498
Cumulative Timesteps: 1,109,176,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1109176266...
Checkpoint 1109176266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,348,001.31515
Policy Entropy: 1.03442
Value Function Loss: 1.13910

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.09707

Collected Steps per Second: 3,828.79075
Overall Steps per Second: 3,183.14879

Timestep Collection Time: 13.05895
Timestep Consumption Time: 2.64876
PPO Batch Consumption Time: 0.06001
Total Iteration Time: 15.70772

Cumulative Model Updates: 66,501
Cumulative Timesteps: 1,109,226,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,564,785.39771
Policy Entropy: 1.04558
Value Function Loss: 1.10830

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.17024
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.09650

Collected Steps per Second: 3,733.58382
Overall Steps per Second: 3,119.42300

Timestep Collection Time: 13.40428
Timestep Consumption Time: 2.63907
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 16.04335

Cumulative Model Updates: 66,504
Cumulative Timesteps: 1,109,276,312

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1109276312...
Checkpoint 1109276312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,237,221.06896
Policy Entropy: 1.00997
Value Function Loss: 1.19103

Mean KL Divergence: 0.02844
SB3 Clip Fraction: 0.18138
Policy Update Magnitude: 0.06722
Value Function Update Magnitude: 0.09629

Collected Steps per Second: 3,931.95056
Overall Steps per Second: 3,261.80639

Timestep Collection Time: 12.72040
Timestep Consumption Time: 2.61343
PPO Batch Consumption Time: 0.05991
Total Iteration Time: 15.33383

Cumulative Model Updates: 66,507
Cumulative Timesteps: 1,109,326,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709,990.68358
Policy Entropy: 1.03316
Value Function Loss: 1.29859

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.09752

Collected Steps per Second: 3,759.84301
Overall Steps per Second: 3,126.12558

Timestep Collection Time: 13.29843
Timestep Consumption Time: 2.69581
PPO Batch Consumption Time: 0.05412
Total Iteration Time: 15.99424

Cumulative Model Updates: 66,510
Cumulative Timesteps: 1,109,376,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1109376328...
Checkpoint 1109376328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269,074.04789
Policy Entropy: 1.02626
Value Function Loss: 1.39995

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.15284
Policy Update Magnitude: 0.06620
Value Function Update Magnitude: 0.09933

Collected Steps per Second: 3,788.71541
Overall Steps per Second: 3,153.93680

Timestep Collection Time: 13.20289
Timestep Consumption Time: 2.65729
PPO Batch Consumption Time: 0.05288
Total Iteration Time: 15.86018

Cumulative Model Updates: 66,513
Cumulative Timesteps: 1,109,426,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534,411.33394
Policy Entropy: 1.01827
Value Function Loss: 1.33245

Mean KL Divergence: 0.02629
SB3 Clip Fraction: 0.17367
Policy Update Magnitude: 0.06352
Value Function Update Magnitude: 0.10015

Collected Steps per Second: 3,798.64467
Overall Steps per Second: 3,152.50665

Timestep Collection Time: 13.16364
Timestep Consumption Time: 2.69802
PPO Batch Consumption Time: 0.06474
Total Iteration Time: 15.86166

Cumulative Model Updates: 66,516
Cumulative Timesteps: 1,109,476,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1109476354...
Checkpoint 1109476354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372,895.37800
Policy Entropy: 1.02022
Value Function Loss: 1.31870

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.17919
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.10125

Collected Steps per Second: 3,731.85983
Overall Steps per Second: 3,147.15580

Timestep Collection Time: 13.40565
Timestep Consumption Time: 2.49061
PPO Batch Consumption Time: 0.06061
Total Iteration Time: 15.89626

Cumulative Model Updates: 66,519
Cumulative Timesteps: 1,109,526,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782,605.26026
Policy Entropy: 1.02866
Value Function Loss: 1.22992

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.14933
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.09816

Collected Steps per Second: 3,918.67076
Overall Steps per Second: 3,292.46505

Timestep Collection Time: 12.76759
Timestep Consumption Time: 2.42831
PPO Batch Consumption Time: 0.04968
Total Iteration Time: 15.19591

Cumulative Model Updates: 66,522
Cumulative Timesteps: 1,109,576,414

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1109576414...
Checkpoint 1109576414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970,584.25359
Policy Entropy: 1.03097
Value Function Loss: 1.27250

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.17243
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.09576

Collected Steps per Second: 4,009.71487
Overall Steps per Second: 3,308.40936

Timestep Collection Time: 12.48169
Timestep Consumption Time: 2.64583
PPO Batch Consumption Time: 0.06360
Total Iteration Time: 15.12751

Cumulative Model Updates: 66,525
Cumulative Timesteps: 1,109,626,462

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,837,503.25457
Policy Entropy: 1.01311
Value Function Loss: 1.23717

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.06691
Value Function Update Magnitude: 0.10591

Collected Steps per Second: 3,934.19869
Overall Steps per Second: 3,251.29933

Timestep Collection Time: 12.70958
Timestep Consumption Time: 2.66951
PPO Batch Consumption Time: 0.06284
Total Iteration Time: 15.37908

Cumulative Model Updates: 66,528
Cumulative Timesteps: 1,109,676,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1109676464...
Checkpoint 1109676464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706,376.40710
Policy Entropy: 1.00590
Value Function Loss: 1.25859

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.17737
Policy Update Magnitude: 0.06552
Value Function Update Magnitude: 0.10547

Collected Steps per Second: 3,941.34273
Overall Steps per Second: 3,225.72295

Timestep Collection Time: 12.69111
Timestep Consumption Time: 2.81549
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 15.50660

Cumulative Model Updates: 66,531
Cumulative Timesteps: 1,109,726,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458,857.55930
Policy Entropy: 1.01776
Value Function Loss: 1.18970

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.10831

Collected Steps per Second: 3,641.70796
Overall Steps per Second: 3,044.91114

Timestep Collection Time: 13.74081
Timestep Consumption Time: 2.69317
PPO Batch Consumption Time: 0.04799
Total Iteration Time: 16.43398

Cumulative Model Updates: 66,534
Cumulative Timesteps: 1,109,776,524

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1109776524...
Checkpoint 1109776524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469,714.94331
Policy Entropy: 1.03733
Value Function Loss: 1.16854

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.10780

Collected Steps per Second: 4,067.04270
Overall Steps per Second: 3,315.26441

Timestep Collection Time: 12.29739
Timestep Consumption Time: 2.78859
PPO Batch Consumption Time: 0.05301
Total Iteration Time: 15.08598

Cumulative Model Updates: 66,537
Cumulative Timesteps: 1,109,826,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,972,305.24169
Policy Entropy: 1.02240
Value Function Loss: 1.14216

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.10567

Collected Steps per Second: 3,712.06561
Overall Steps per Second: 3,122.33298

Timestep Collection Time: 13.46959
Timestep Consumption Time: 2.54408
PPO Batch Consumption Time: 0.06503
Total Iteration Time: 16.01367

Cumulative Model Updates: 66,540
Cumulative Timesteps: 1,109,876,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1109876538...
Checkpoint 1109876538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,624,694.05125
Policy Entropy: 1.02053
Value Function Loss: 1.15381

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.15436
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.09595

Collected Steps per Second: 3,651.38202
Overall Steps per Second: 3,073.59979

Timestep Collection Time: 13.69345
Timestep Consumption Time: 2.57412
PPO Batch Consumption Time: 0.05842
Total Iteration Time: 16.26757

Cumulative Model Updates: 66,543
Cumulative Timesteps: 1,109,926,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040,803.90499
Policy Entropy: 1.02587
Value Function Loss: 1.16619

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.09589

Collected Steps per Second: 3,974.96020
Overall Steps per Second: 3,311.15843

Timestep Collection Time: 12.57975
Timestep Consumption Time: 2.52191
PPO Batch Consumption Time: 0.05284
Total Iteration Time: 15.10166

Cumulative Model Updates: 66,546
Cumulative Timesteps: 1,109,976,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1109976542...
Checkpoint 1109976542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763,651.53275
Policy Entropy: 1.02960
Value Function Loss: 1.25620

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.07045
Value Function Update Magnitude: 0.10005

Collected Steps per Second: 3,758.55517
Overall Steps per Second: 3,185.28904

Timestep Collection Time: 13.31416
Timestep Consumption Time: 2.39619
PPO Batch Consumption Time: 0.05026
Total Iteration Time: 15.71035

Cumulative Model Updates: 66,549
Cumulative Timesteps: 1,110,026,584

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587,923.27233
Policy Entropy: 1.01886
Value Function Loss: 1.27239

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.16561
Policy Update Magnitude: 0.06690
Value Function Update Magnitude: 0.10296

Collected Steps per Second: 3,724.30190
Overall Steps per Second: 3,162.86928

Timestep Collection Time: 13.43608
Timestep Consumption Time: 2.38500
PPO Batch Consumption Time: 0.04935
Total Iteration Time: 15.82108

Cumulative Model Updates: 66,552
Cumulative Timesteps: 1,110,076,624

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1110076624...
Checkpoint 1110076624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230,753.77385
Policy Entropy: 1.01652
Value Function Loss: 1.25927

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.18980
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.13025

Collected Steps per Second: 3,659.96139
Overall Steps per Second: 3,085.65413

Timestep Collection Time: 13.66954
Timestep Consumption Time: 2.54420
PPO Batch Consumption Time: 0.05894
Total Iteration Time: 16.21374

Cumulative Model Updates: 66,555
Cumulative Timesteps: 1,110,126,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943,554.35313
Policy Entropy: 1.02556
Value Function Loss: 1.17114

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 3,717.56940
Overall Steps per Second: 3,161.26590

Timestep Collection Time: 13.45126
Timestep Consumption Time: 2.36708
PPO Batch Consumption Time: 0.05107
Total Iteration Time: 15.81835

Cumulative Model Updates: 66,558
Cumulative Timesteps: 1,110,176,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1110176660...
Checkpoint 1110176660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301,306.94337
Policy Entropy: 1.04356
Value Function Loss: 1.28174

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.18257
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.10096

Collected Steps per Second: 3,745.35342
Overall Steps per Second: 3,144.24190

Timestep Collection Time: 13.35949
Timestep Consumption Time: 2.55405
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 15.91353

Cumulative Model Updates: 66,561
Cumulative Timesteps: 1,110,226,696

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380,303.79471
Policy Entropy: 1.01509
Value Function Loss: 1.30688

Mean KL Divergence: 0.03394
SB3 Clip Fraction: 0.18562
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.10797

Collected Steps per Second: 3,850.20770
Overall Steps per Second: 2,962.07462

Timestep Collection Time: 12.98631
Timestep Consumption Time: 3.89375
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 16.88006

Cumulative Model Updates: 66,564
Cumulative Timesteps: 1,110,276,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1110276696...
Checkpoint 1110276696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388,516.29116
Policy Entropy: 1.04611
Value Function Loss: 1.25655

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.12539

Collected Steps per Second: 3,982.22596
Overall Steps per Second: 3,274.60590

Timestep Collection Time: 12.56081
Timestep Consumption Time: 2.71431
PPO Batch Consumption Time: 0.04805
Total Iteration Time: 15.27512

Cumulative Model Updates: 66,567
Cumulative Timesteps: 1,110,326,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,241,660.28317
Policy Entropy: 1.04391
Value Function Loss: 1.16900

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.06282
Value Function Update Magnitude: 0.13629

Collected Steps per Second: 4,132.33857
Overall Steps per Second: 3,375.74501

Timestep Collection Time: 12.10791
Timestep Consumption Time: 2.71370
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 14.82162

Cumulative Model Updates: 66,570
Cumulative Timesteps: 1,110,376,750

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1110376750...
Checkpoint 1110376750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102,567.87895
Policy Entropy: 1.03307
Value Function Loss: 1.20894

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.07710
Value Function Update Magnitude: 0.12660

Collected Steps per Second: 4,202.15342
Overall Steps per Second: 3,257.84773

Timestep Collection Time: 11.90437
Timestep Consumption Time: 3.45055
PPO Batch Consumption Time: 0.06623
Total Iteration Time: 15.35492

Cumulative Model Updates: 66,573
Cumulative Timesteps: 1,110,426,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071,325.40717
Policy Entropy: 1.02326
Value Function Loss: 1.29317

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.16113
Policy Update Magnitude: 0.07443
Value Function Update Magnitude: 0.11700

Collected Steps per Second: 3,810.53313
Overall Steps per Second: 3,179.60757

Timestep Collection Time: 13.12677
Timestep Consumption Time: 2.60473
PPO Batch Consumption Time: 0.06030
Total Iteration Time: 15.73150

Cumulative Model Updates: 66,576
Cumulative Timesteps: 1,110,476,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1110476794...
Checkpoint 1110476794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078,965.01852
Policy Entropy: 1.03470
Value Function Loss: 1.32425

Mean KL Divergence: 0.02450
SB3 Clip Fraction: 0.16819
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.10638

Collected Steps per Second: 3,688.94786
Overall Steps per Second: 3,083.93050

Timestep Collection Time: 13.55508
Timestep Consumption Time: 2.65929
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 16.21437

Cumulative Model Updates: 66,579
Cumulative Timesteps: 1,110,526,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719,779.21856
Policy Entropy: 1.04057
Value Function Loss: 1.32037

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.15722
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.10987

Collected Steps per Second: 3,867.89198
Overall Steps per Second: 3,198.16422

Timestep Collection Time: 12.93728
Timestep Consumption Time: 2.70920
PPO Batch Consumption Time: 0.06106
Total Iteration Time: 15.64648

Cumulative Model Updates: 66,582
Cumulative Timesteps: 1,110,576,838

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1110576838...
Checkpoint 1110576838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705,930.25670
Policy Entropy: 1.02869
Value Function Loss: 1.26920

Mean KL Divergence: 0.02536
SB3 Clip Fraction: 0.15552
Policy Update Magnitude: 0.06154
Value Function Update Magnitude: 0.12001

Collected Steps per Second: 3,715.41631
Overall Steps per Second: 3,088.24654

Timestep Collection Time: 13.46283
Timestep Consumption Time: 2.73407
PPO Batch Consumption Time: 0.05077
Total Iteration Time: 16.19689

Cumulative Model Updates: 66,585
Cumulative Timesteps: 1,110,626,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610,858.63832
Policy Entropy: 1.02814
Value Function Loss: 1.31890

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.17403
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.11927

Collected Steps per Second: 3,805.06938
Overall Steps per Second: 3,185.37078

Timestep Collection Time: 13.15245
Timestep Consumption Time: 2.55875
PPO Batch Consumption Time: 0.05118
Total Iteration Time: 15.71120

Cumulative Model Updates: 66,588
Cumulative Timesteps: 1,110,676,904

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1110676904...
Checkpoint 1110676904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510,913.46151
Policy Entropy: 1.03184
Value Function Loss: 1.31206

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.14339
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 3,787.65278
Overall Steps per Second: 3,177.59065

Timestep Collection Time: 13.20501
Timestep Consumption Time: 2.53522
PPO Batch Consumption Time: 0.05059
Total Iteration Time: 15.74023

Cumulative Model Updates: 66,591
Cumulative Timesteps: 1,110,726,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,304,710.90464
Policy Entropy: 1.04418
Value Function Loss: 1.28519

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.15872
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.12135

Collected Steps per Second: 3,769.43540
Overall Steps per Second: 3,195.12522

Timestep Collection Time: 13.27095
Timestep Consumption Time: 2.38540
PPO Batch Consumption Time: 0.05376
Total Iteration Time: 15.65635

Cumulative Model Updates: 66,594
Cumulative Timesteps: 1,110,776,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1110776944...
Checkpoint 1110776944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466,380.39530
Policy Entropy: 1.03257
Value Function Loss: 1.18683

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.11396

Collected Steps per Second: 3,700.13752
Overall Steps per Second: 3,134.69827

Timestep Collection Time: 13.51896
Timestep Consumption Time: 2.43856
PPO Batch Consumption Time: 0.04995
Total Iteration Time: 15.95752

Cumulative Model Updates: 66,597
Cumulative Timesteps: 1,110,826,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510,917.62383
Policy Entropy: 1.02351
Value Function Loss: 1.12863

Mean KL Divergence: 0.03110
SB3 Clip Fraction: 0.19536
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.11680

Collected Steps per Second: 3,638.43379
Overall Steps per Second: 3,086.44177

Timestep Collection Time: 13.74932
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.05115
Total Iteration Time: 16.20831

Cumulative Model Updates: 66,600
Cumulative Timesteps: 1,110,876,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1110876992...
Checkpoint 1110876992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,993,983.04735
Policy Entropy: 1.03579
Value Function Loss: 1.09028

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.11883

Collected Steps per Second: 4,105.62325
Overall Steps per Second: 3,327.31864

Timestep Collection Time: 12.18962
Timestep Consumption Time: 2.85132
PPO Batch Consumption Time: 0.05238
Total Iteration Time: 15.04094

Cumulative Model Updates: 66,603
Cumulative Timesteps: 1,110,927,038

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656,346.08833
Policy Entropy: 1.02604
Value Function Loss: 1.19553

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.10890

Collected Steps per Second: 3,819.87859
Overall Steps per Second: 3,180.10231

Timestep Collection Time: 13.09518
Timestep Consumption Time: 2.63450
PPO Batch Consumption Time: 0.04941
Total Iteration Time: 15.72968

Cumulative Model Updates: 66,606
Cumulative Timesteps: 1,110,977,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1110977060...
Checkpoint 1110977060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,883,854.20807
Policy Entropy: 1.01925
Value Function Loss: 1.17074

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.09456

Collected Steps per Second: 4,257.45399
Overall Steps per Second: 3,464.97459

Timestep Collection Time: 11.74834
Timestep Consumption Time: 2.68698
PPO Batch Consumption Time: 0.04907
Total Iteration Time: 14.43532

Cumulative Model Updates: 66,609
Cumulative Timesteps: 1,111,027,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,360,351.57430
Policy Entropy: 1.00636
Value Function Loss: 1.21978

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.06508
Value Function Update Magnitude: 0.10047

Collected Steps per Second: 3,942.93344
Overall Steps per Second: 3,322.51266

Timestep Collection Time: 12.68446
Timestep Consumption Time: 2.36860
PPO Batch Consumption Time: 0.04902
Total Iteration Time: 15.05307

Cumulative Model Updates: 66,612
Cumulative Timesteps: 1,111,077,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1111077092...
Checkpoint 1111077092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473,140.30544
Policy Entropy: 1.03076
Value Function Loss: 1.15740

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.16247
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.09526

Collected Steps per Second: 3,745.46095
Overall Steps per Second: 3,139.30444

Timestep Collection Time: 13.35590
Timestep Consumption Time: 2.57884
PPO Batch Consumption Time: 0.06530
Total Iteration Time: 15.93474

Cumulative Model Updates: 66,615
Cumulative Timesteps: 1,111,127,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384,329.78167
Policy Entropy: 1.03200
Value Function Loss: 1.16230

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.16709
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.10462

Collected Steps per Second: 3,716.64039
Overall Steps per Second: 3,124.52394

Timestep Collection Time: 13.45516
Timestep Consumption Time: 2.54984
PPO Batch Consumption Time: 0.05057
Total Iteration Time: 16.00500

Cumulative Model Updates: 66,618
Cumulative Timesteps: 1,111,177,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1111177124...
Checkpoint 1111177124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386,226.10268
Policy Entropy: 1.02663
Value Function Loss: 1.14101

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.14769
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.09712

Collected Steps per Second: 3,939.58839
Overall Steps per Second: 3,235.19296

Timestep Collection Time: 12.69523
Timestep Consumption Time: 2.76412
PPO Batch Consumption Time: 0.06134
Total Iteration Time: 15.45936

Cumulative Model Updates: 66,621
Cumulative Timesteps: 1,111,227,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696,146.43016
Policy Entropy: 1.00953
Value Function Loss: 1.14854

Mean KL Divergence: 0.02880
SB3 Clip Fraction: 0.19557
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.10585

Collected Steps per Second: 3,714.88684
Overall Steps per Second: 3,152.08943

Timestep Collection Time: 13.46744
Timestep Consumption Time: 2.40458
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 15.87201

Cumulative Model Updates: 66,624
Cumulative Timesteps: 1,111,277,168

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1111277168...
Checkpoint 1111277168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154,083.08310
Policy Entropy: 1.04217
Value Function Loss: 1.19365

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.06197
Value Function Update Magnitude: 0.11721

Collected Steps per Second: 3,956.53801
Overall Steps per Second: 3,304.72939

Timestep Collection Time: 12.64793
Timestep Consumption Time: 2.49461
PPO Batch Consumption Time: 0.05297
Total Iteration Time: 15.14254

Cumulative Model Updates: 66,627
Cumulative Timesteps: 1,111,327,210

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580,547.70722
Policy Entropy: 1.03582
Value Function Loss: 1.16745

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.12554

Collected Steps per Second: 3,682.75570
Overall Steps per Second: 3,118.55166

Timestep Collection Time: 13.58657
Timestep Consumption Time: 2.45806
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 16.04463

Cumulative Model Updates: 66,630
Cumulative Timesteps: 1,111,377,246

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1111377246...
Checkpoint 1111377246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616,851.35184
Policy Entropy: 1.02766
Value Function Loss: 1.14773

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.06536
Value Function Update Magnitude: 0.11171

Collected Steps per Second: 3,730.04263
Overall Steps per Second: 3,174.94817

Timestep Collection Time: 13.41379
Timestep Consumption Time: 2.34521
PPO Batch Consumption Time: 0.05314
Total Iteration Time: 15.75900

Cumulative Model Updates: 66,633
Cumulative Timesteps: 1,111,427,280

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252,173.08564
Policy Entropy: 1.01915
Value Function Loss: 1.15558

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.06801
Value Function Update Magnitude: 0.10608

Collected Steps per Second: 3,816.43465
Overall Steps per Second: 3,212.04382

Timestep Collection Time: 13.10228
Timestep Consumption Time: 2.46538
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 15.56766

Cumulative Model Updates: 66,636
Cumulative Timesteps: 1,111,477,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1111477284...
Checkpoint 1111477284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646,087.93141
Policy Entropy: 1.02561
Value Function Loss: 1.24125

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.07104
Value Function Update Magnitude: 0.11053

Collected Steps per Second: 4,008.91724
Overall Steps per Second: 3,356.53094

Timestep Collection Time: 12.48118
Timestep Consumption Time: 2.42588
PPO Batch Consumption Time: 0.05395
Total Iteration Time: 14.90706

Cumulative Model Updates: 66,639
Cumulative Timesteps: 1,111,527,320

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780,951.63289
Policy Entropy: 1.03314
Value Function Loss: 1.22842

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.06794
Value Function Update Magnitude: 0.10261

Collected Steps per Second: 4,160.60120
Overall Steps per Second: 3,420.74352

Timestep Collection Time: 12.02807
Timestep Consumption Time: 2.60150
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 14.62957

Cumulative Model Updates: 66,642
Cumulative Timesteps: 1,111,577,364

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1111577364...
Checkpoint 1111577364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,712,828.70281
Policy Entropy: 1.03271
Value Function Loss: 1.24302

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.06810
Value Function Update Magnitude: 0.10266

Collected Steps per Second: 4,077.50772
Overall Steps per Second: 3,288.27107

Timestep Collection Time: 12.27171
Timestep Consumption Time: 2.94540
PPO Batch Consumption Time: 0.05907
Total Iteration Time: 15.21712

Cumulative Model Updates: 66,645
Cumulative Timesteps: 1,111,627,402

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,220,878.24182
Policy Entropy: 1.03315
Value Function Loss: 1.25641

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.07245
Value Function Update Magnitude: 0.09568

Collected Steps per Second: 3,552.01809
Overall Steps per Second: 2,979.51094

Timestep Collection Time: 14.09171
Timestep Consumption Time: 2.70769
PPO Batch Consumption Time: 0.05438
Total Iteration Time: 16.79940

Cumulative Model Updates: 66,648
Cumulative Timesteps: 1,111,677,456

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1111677456...
Checkpoint 1111677456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631,602.81088
Policy Entropy: 1.02523
Value Function Loss: 1.29514

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.08143
Value Function Update Magnitude: 0.09013

Collected Steps per Second: 3,893.06127
Overall Steps per Second: 3,226.85638

Timestep Collection Time: 12.85312
Timestep Consumption Time: 2.65361
PPO Batch Consumption Time: 0.06353
Total Iteration Time: 15.50673

Cumulative Model Updates: 66,651
Cumulative Timesteps: 1,111,727,494

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359,967.17436
Policy Entropy: 1.03224
Value Function Loss: 1.32352

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.09336
Value Function Update Magnitude: 0.08701

Collected Steps per Second: 3,968.24720
Overall Steps per Second: 3,294.79455

Timestep Collection Time: 12.60456
Timestep Consumption Time: 2.57636
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 15.18092

Cumulative Model Updates: 66,654
Cumulative Timesteps: 1,111,777,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1111777512...
Checkpoint 1111777512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867,869.99124
Policy Entropy: 1.04416
Value Function Loss: 1.27884

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.15485
Policy Update Magnitude: 0.08128
Value Function Update Magnitude: 0.08337

Collected Steps per Second: 3,902.12183
Overall Steps per Second: 3,241.45176

Timestep Collection Time: 12.82584
Timestep Consumption Time: 2.61415
PPO Batch Consumption Time: 0.05224
Total Iteration Time: 15.44000

Cumulative Model Updates: 66,657
Cumulative Timesteps: 1,111,827,560

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562,718.39024
Policy Entropy: 1.04962
Value Function Loss: 1.29000

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.08385
Value Function Update Magnitude: 0.08977

Collected Steps per Second: 3,841.13761
Overall Steps per Second: 3,242.94171

Timestep Collection Time: 13.02270
Timestep Consumption Time: 2.40218
PPO Batch Consumption Time: 0.04810
Total Iteration Time: 15.42488

Cumulative Model Updates: 66,660
Cumulative Timesteps: 1,111,877,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1111877582...
Checkpoint 1111877582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,928,291.29134
Policy Entropy: 1.04505
Value Function Loss: 1.25792

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.08409
Value Function Update Magnitude: 0.09109

Collected Steps per Second: 3,699.94593
Overall Steps per Second: 3,165.17205

Timestep Collection Time: 13.51371
Timestep Consumption Time: 2.28322
PPO Batch Consumption Time: 0.05213
Total Iteration Time: 15.79693

Cumulative Model Updates: 66,663
Cumulative Timesteps: 1,111,927,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,740,009.15746
Policy Entropy: 1.03643
Value Function Loss: 1.30628

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.07844
Value Function Update Magnitude: 0.09210

Collected Steps per Second: 3,909.05333
Overall Steps per Second: 3,313.22879

Timestep Collection Time: 12.79184
Timestep Consumption Time: 2.30038
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 15.09223

Cumulative Model Updates: 66,666
Cumulative Timesteps: 1,111,977,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1111977586...
Checkpoint 1111977586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933,227.81951
Policy Entropy: 1.05937
Value Function Loss: 1.39643

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.15086
Policy Update Magnitude: 0.06731
Value Function Update Magnitude: 0.09940

Collected Steps per Second: 3,696.91987
Overall Steps per Second: 3,079.28750

Timestep Collection Time: 13.52802
Timestep Consumption Time: 2.71340
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 16.24142

Cumulative Model Updates: 66,669
Cumulative Timesteps: 1,112,027,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707,349.89684
Policy Entropy: 1.06302
Value Function Loss: 1.41660

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.16733
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 4,072.17513
Overall Steps per Second: 3,377.18829

Timestep Collection Time: 12.27943
Timestep Consumption Time: 2.52697
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 14.80640

Cumulative Model Updates: 66,672
Cumulative Timesteps: 1,112,077,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1112077602...
Checkpoint 1112077602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,292,913.21141
Policy Entropy: 1.05226
Value Function Loss: 1.37022

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.14152

Collected Steps per Second: 3,771.93390
Overall Steps per Second: 3,121.66476

Timestep Collection Time: 13.26216
Timestep Consumption Time: 2.76262
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 16.02478

Cumulative Model Updates: 66,675
Cumulative Timesteps: 1,112,127,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302,514.27720
Policy Entropy: 1.04731
Value Function Loss: 1.31176

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.16056
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.13441

Collected Steps per Second: 3,929.67709
Overall Steps per Second: 3,235.95129

Timestep Collection Time: 12.73591
Timestep Consumption Time: 2.73033
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 15.46624

Cumulative Model Updates: 66,678
Cumulative Timesteps: 1,112,177,674

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1112177674...
Checkpoint 1112177674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,058,535.41919
Policy Entropy: 1.05834
Value Function Loss: 1.36304

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 3,771.83712
Overall Steps per Second: 3,147.26291

Timestep Collection Time: 13.25667
Timestep Consumption Time: 2.63079
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 15.88746

Cumulative Model Updates: 66,681
Cumulative Timesteps: 1,112,227,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290,593.59564
Policy Entropy: 1.07068
Value Function Loss: 1.41940

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.11061

Collected Steps per Second: 3,810.95461
Overall Steps per Second: 3,184.85967

Timestep Collection Time: 13.12270
Timestep Consumption Time: 2.57972
PPO Batch Consumption Time: 0.05391
Total Iteration Time: 15.70242

Cumulative Model Updates: 66,684
Cumulative Timesteps: 1,112,277,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1112277686...
Checkpoint 1112277686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369,782.00002
Policy Entropy: 1.05236
Value Function Loss: 1.41152

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.11529

Collected Steps per Second: 3,732.11052
Overall Steps per Second: 3,191.47431

Timestep Collection Time: 13.40528
Timestep Consumption Time: 2.27086
PPO Batch Consumption Time: 0.05428
Total Iteration Time: 15.67614

Cumulative Model Updates: 66,687
Cumulative Timesteps: 1,112,327,716

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,311,396.10330
Policy Entropy: 1.05332
Value Function Loss: 1.38855

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.17225
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.11547

Collected Steps per Second: 3,665.59066
Overall Steps per Second: 3,123.08183

Timestep Collection Time: 13.65237
Timestep Consumption Time: 2.37155
PPO Batch Consumption Time: 0.05849
Total Iteration Time: 16.02392

Cumulative Model Updates: 66,690
Cumulative Timesteps: 1,112,377,760

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1112377760...
Checkpoint 1112377760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717,838.04822
Policy Entropy: 1.06268
Value Function Loss: 1.38529

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.12342

Collected Steps per Second: 3,659.95286
Overall Steps per Second: 3,076.47436

Timestep Collection Time: 13.66575
Timestep Consumption Time: 2.59182
PPO Batch Consumption Time: 0.06524
Total Iteration Time: 16.25757

Cumulative Model Updates: 66,693
Cumulative Timesteps: 1,112,427,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327,529.42540
Policy Entropy: 1.07559
Value Function Loss: 1.36891

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.16486
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.14053

Collected Steps per Second: 3,768.97711
Overall Steps per Second: 3,159.57550

Timestep Collection Time: 13.27734
Timestep Consumption Time: 2.56086
PPO Batch Consumption Time: 0.04696
Total Iteration Time: 15.83820

Cumulative Model Updates: 66,696
Cumulative Timesteps: 1,112,477,818

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1112477818...
Checkpoint 1112477818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688,804.60584
Policy Entropy: 1.05617
Value Function Loss: 1.36143

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.13480

Collected Steps per Second: 3,750.89707
Overall Steps per Second: 3,109.72012

Timestep Collection Time: 13.33014
Timestep Consumption Time: 2.74847
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 16.07862

Cumulative Model Updates: 66,699
Cumulative Timesteps: 1,112,527,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879,635.59459
Policy Entropy: 1.04873
Value Function Loss: 1.30368

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.06402
Value Function Update Magnitude: 0.12674

Collected Steps per Second: 3,787.51684
Overall Steps per Second: 3,218.69021

Timestep Collection Time: 13.20390
Timestep Consumption Time: 2.33347
PPO Batch Consumption Time: 0.05207
Total Iteration Time: 15.53738

Cumulative Model Updates: 66,702
Cumulative Timesteps: 1,112,577,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1112577828...
Checkpoint 1112577828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366,842.53287
Policy Entropy: 1.05856
Value Function Loss: 1.22947

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.12374

Collected Steps per Second: 3,831.16547
Overall Steps per Second: 3,187.42486

Timestep Collection Time: 13.05660
Timestep Consumption Time: 2.63695
PPO Batch Consumption Time: 0.05396
Total Iteration Time: 15.69355

Cumulative Model Updates: 66,705
Cumulative Timesteps: 1,112,627,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346,504.75898
Policy Entropy: 1.05642
Value Function Loss: 1.19999

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.12030

Collected Steps per Second: 3,950.65978
Overall Steps per Second: 3,284.14330

Timestep Collection Time: 12.65763
Timestep Consumption Time: 2.56886
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 15.22650

Cumulative Model Updates: 66,708
Cumulative Timesteps: 1,112,677,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1112677856...
Checkpoint 1112677856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,016,319.08905
Policy Entropy: 1.05443
Value Function Loss: 1.17588

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.07655
Value Function Update Magnitude: 0.10893

Collected Steps per Second: 4,003.87481
Overall Steps per Second: 3,119.03921

Timestep Collection Time: 12.49340
Timestep Consumption Time: 3.54423
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 16.03763

Cumulative Model Updates: 66,711
Cumulative Timesteps: 1,112,727,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807,381.42978
Policy Entropy: 1.05348
Value Function Loss: 1.28717

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.07494
Value Function Update Magnitude: 0.11420

Collected Steps per Second: 4,306.76748
Overall Steps per Second: 3,547.45712

Timestep Collection Time: 11.61474
Timestep Consumption Time: 2.48606
PPO Batch Consumption Time: 0.04974
Total Iteration Time: 14.10080

Cumulative Model Updates: 66,714
Cumulative Timesteps: 1,112,777,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1112777900...
Checkpoint 1112777900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663,693.52148
Policy Entropy: 1.05003
Value Function Loss: 1.28645

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.07758
Value Function Update Magnitude: 0.12593

Collected Steps per Second: 4,298.45473
Overall Steps per Second: 3,572.26176

Timestep Collection Time: 11.63302
Timestep Consumption Time: 2.36484
PPO Batch Consumption Time: 0.05132
Total Iteration Time: 13.99785

Cumulative Model Updates: 66,717
Cumulative Timesteps: 1,112,827,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,168,393.40631
Policy Entropy: 1.04881
Value Function Loss: 1.29040

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.14685
Policy Update Magnitude: 0.07188
Value Function Update Magnitude: 0.13543

Collected Steps per Second: 4,106.53669
Overall Steps per Second: 3,420.87633

Timestep Collection Time: 12.18691
Timestep Consumption Time: 2.44267
PPO Batch Consumption Time: 0.05242
Total Iteration Time: 14.62958

Cumulative Model Updates: 66,720
Cumulative Timesteps: 1,112,877,950

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1112877950...
Checkpoint 1112877950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732,505.74512
Policy Entropy: 1.06849
Value Function Loss: 1.28778

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.06400
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 3,684.62303
Overall Steps per Second: 3,091.91622

Timestep Collection Time: 13.57425
Timestep Consumption Time: 2.60212
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 16.17638

Cumulative Model Updates: 66,723
Cumulative Timesteps: 1,112,927,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272,741.46076
Policy Entropy: 1.07593
Value Function Loss: 1.31586

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.15851
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.11635

Collected Steps per Second: 3,876.38388
Overall Steps per Second: 3,198.77831

Timestep Collection Time: 12.90429
Timestep Consumption Time: 2.73355
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 15.63785

Cumulative Model Updates: 66,726
Cumulative Timesteps: 1,112,977,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1112977988...
Checkpoint 1112977988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393,417.01850
Policy Entropy: 1.07017
Value Function Loss: 1.32116

Mean KL Divergence: 0.02199
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.06236
Value Function Update Magnitude: 0.13412

Collected Steps per Second: 3,731.20541
Overall Steps per Second: 3,104.99139

Timestep Collection Time: 13.40210
Timestep Consumption Time: 2.70293
PPO Batch Consumption Time: 0.05784
Total Iteration Time: 16.10504

Cumulative Model Updates: 66,729
Cumulative Timesteps: 1,113,027,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312,147.84045
Policy Entropy: 1.06511
Value Function Loss: 1.22939

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.16602
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.12872

Collected Steps per Second: 3,817.63920
Overall Steps per Second: 3,188.18232

Timestep Collection Time: 13.10653
Timestep Consumption Time: 2.58768
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 15.69421

Cumulative Model Updates: 66,732
Cumulative Timesteps: 1,113,078,030

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1113078030...
Checkpoint 1113078030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605,372.96879
Policy Entropy: 1.07317
Value Function Loss: 1.18265

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.12232

Collected Steps per Second: 3,917.83985
Overall Steps per Second: 3,248.41574

Timestep Collection Time: 12.76265
Timestep Consumption Time: 2.63009
PPO Batch Consumption Time: 0.06703
Total Iteration Time: 15.39273

Cumulative Model Updates: 66,735
Cumulative Timesteps: 1,113,128,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,891,725.81919
Policy Entropy: 1.07388
Value Function Loss: 1.18480

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.11138

Collected Steps per Second: 3,762.85828
Overall Steps per Second: 3,145.21716

Timestep Collection Time: 13.29628
Timestep Consumption Time: 2.61105
PPO Batch Consumption Time: 0.05964
Total Iteration Time: 15.90733

Cumulative Model Updates: 66,738
Cumulative Timesteps: 1,113,178,064

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1113178064...
Checkpoint 1113178064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422,899.99451
Policy Entropy: 1.05618
Value Function Loss: 1.25548

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.11458

Collected Steps per Second: 3,933.85677
Overall Steps per Second: 3,262.16861

Timestep Collection Time: 12.71272
Timestep Consumption Time: 2.61758
PPO Batch Consumption Time: 0.05173
Total Iteration Time: 15.33029

Cumulative Model Updates: 66,741
Cumulative Timesteps: 1,113,228,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278,148.80263
Policy Entropy: 1.04880
Value Function Loss: 1.27748

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.17111
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.11175

Collected Steps per Second: 3,754.39979
Overall Steps per Second: 3,125.22665

Timestep Collection Time: 13.32517
Timestep Consumption Time: 2.68263
PPO Batch Consumption Time: 0.05135
Total Iteration Time: 16.00780

Cumulative Model Updates: 66,744
Cumulative Timesteps: 1,113,278,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1113278102...
Checkpoint 1113278102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385,098.29711
Policy Entropy: 1.06494
Value Function Loss: 1.25234

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.11021

Collected Steps per Second: 3,984.27048
Overall Steps per Second: 3,334.36877

Timestep Collection Time: 12.56089
Timestep Consumption Time: 2.44824
PPO Batch Consumption Time: 0.04963
Total Iteration Time: 15.00914

Cumulative Model Updates: 66,747
Cumulative Timesteps: 1,113,328,148

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544,761.80454
Policy Entropy: 1.08260
Value Function Loss: 1.15206

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.16457
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.10115

Collected Steps per Second: 3,717.80769
Overall Steps per Second: 3,136.73013

Timestep Collection Time: 13.45309
Timestep Consumption Time: 2.49218
PPO Batch Consumption Time: 0.05913
Total Iteration Time: 15.94527

Cumulative Model Updates: 66,750
Cumulative Timesteps: 1,113,378,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1113378164...
Checkpoint 1113378164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637,462.39619
Policy Entropy: 1.05624
Value Function Loss: 1.13374

Mean KL Divergence: 0.04205
SB3 Clip Fraction: 0.19254
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.11512

Collected Steps per Second: 3,990.42674
Overall Steps per Second: 3,413.61394

Timestep Collection Time: 12.54152
Timestep Consumption Time: 2.11919
PPO Batch Consumption Time: 0.05045
Total Iteration Time: 14.66071

Cumulative Model Updates: 66,753
Cumulative Timesteps: 1,113,428,210

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204,628.79180
Policy Entropy: 1.07907
Value Function Loss: 1.12918

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.15127
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.13188

Collected Steps per Second: 3,927.93319
Overall Steps per Second: 3,257.76681

Timestep Collection Time: 12.74156
Timestep Consumption Time: 2.62111
PPO Batch Consumption Time: 0.04797
Total Iteration Time: 15.36267

Cumulative Model Updates: 66,756
Cumulative Timesteps: 1,113,478,258

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1113478258...
Checkpoint 1113478258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732,419.82974
Policy Entropy: 1.06243
Value Function Loss: 1.15184

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.06333
Value Function Update Magnitude: 0.14088

Collected Steps per Second: 3,832.15648
Overall Steps per Second: 3,183.04782

Timestep Collection Time: 13.05949
Timestep Consumption Time: 2.66318
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 15.72267

Cumulative Model Updates: 66,759
Cumulative Timesteps: 1,113,528,304

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669,090.05402
Policy Entropy: 1.05153
Value Function Loss: 1.15914

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.14261

Collected Steps per Second: 4,022.34344
Overall Steps per Second: 3,309.70134

Timestep Collection Time: 12.43951
Timestep Consumption Time: 2.67847
PPO Batch Consumption Time: 0.04790
Total Iteration Time: 15.11798

Cumulative Model Updates: 66,762
Cumulative Timesteps: 1,113,578,340

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1113578340...
Checkpoint 1113578340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491,485.92991
Policy Entropy: 1.06512
Value Function Loss: 1.15577

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.13651

Collected Steps per Second: 3,916.26137
Overall Steps per Second: 3,245.15996

Timestep Collection Time: 12.76830
Timestep Consumption Time: 2.64049
PPO Batch Consumption Time: 0.04844
Total Iteration Time: 15.40879

Cumulative Model Updates: 66,765
Cumulative Timesteps: 1,113,628,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709,036.45838
Policy Entropy: 1.06956
Value Function Loss: 1.20025

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.06562
Value Function Update Magnitude: 0.12586

Collected Steps per Second: 3,737.06128
Overall Steps per Second: 3,118.89310

Timestep Collection Time: 13.38324
Timestep Consumption Time: 2.65257
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 16.03582

Cumulative Model Updates: 66,768
Cumulative Timesteps: 1,113,678,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1113678358...
Checkpoint 1113678358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426,657.72439
Policy Entropy: 1.06846
Value Function Loss: 1.23258

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.07127
Value Function Update Magnitude: 0.12117

Collected Steps per Second: 3,861.21727
Overall Steps per Second: 3,206.06612

Timestep Collection Time: 12.96120
Timestep Consumption Time: 2.64859
PPO Batch Consumption Time: 0.06090
Total Iteration Time: 15.60978

Cumulative Model Updates: 66,771
Cumulative Timesteps: 1,113,728,404

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388,736.83239
Policy Entropy: 1.06333
Value Function Loss: 1.27537

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.07110
Value Function Update Magnitude: 0.11829

Collected Steps per Second: 3,688.66464
Overall Steps per Second: 3,088.48376

Timestep Collection Time: 13.55829
Timestep Consumption Time: 2.63477
PPO Batch Consumption Time: 0.05194
Total Iteration Time: 16.19306

Cumulative Model Updates: 66,774
Cumulative Timesteps: 1,113,778,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1113778416...
Checkpoint 1113778416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194,443.27682
Policy Entropy: 1.06146
Value Function Loss: 1.27168

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.07013
Value Function Update Magnitude: 0.11182

Collected Steps per Second: 3,798.60775
Overall Steps per Second: 3,223.77606

Timestep Collection Time: 13.16272
Timestep Consumption Time: 2.34704
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 15.50976

Cumulative Model Updates: 66,777
Cumulative Timesteps: 1,113,828,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,420,768.01827
Policy Entropy: 1.07864
Value Function Loss: 1.18026

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.14333
Policy Update Magnitude: 0.06820
Value Function Update Magnitude: 0.10845

Collected Steps per Second: 3,642.11174
Overall Steps per Second: 3,072.06607

Timestep Collection Time: 13.73544
Timestep Consumption Time: 2.54872
PPO Batch Consumption Time: 0.06192
Total Iteration Time: 16.28416

Cumulative Model Updates: 66,780
Cumulative Timesteps: 1,113,878,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1113878442...
Checkpoint 1113878442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786,493.02055
Policy Entropy: 1.07987
Value Function Loss: 1.19943

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.06746
Value Function Update Magnitude: 0.10904

Collected Steps per Second: 3,864.06081
Overall Steps per Second: 3,287.41848

Timestep Collection Time: 12.94286
Timestep Consumption Time: 2.27029
PPO Batch Consumption Time: 0.05329
Total Iteration Time: 15.21315

Cumulative Model Updates: 66,783
Cumulative Timesteps: 1,113,928,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078,270.90237
Policy Entropy: 1.08180
Value Function Loss: 1.21218

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.07518
Value Function Update Magnitude: 0.10175

Collected Steps per Second: 3,637.06832
Overall Steps per Second: 3,089.15298

Timestep Collection Time: 13.75888
Timestep Consumption Time: 2.44038
PPO Batch Consumption Time: 0.05232
Total Iteration Time: 16.19926

Cumulative Model Updates: 66,786
Cumulative Timesteps: 1,113,978,496

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1113978496...
Checkpoint 1113978496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752,740.27609
Policy Entropy: 1.07293
Value Function Loss: 1.35053

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.07813
Value Function Update Magnitude: 0.11096

Collected Steps per Second: 3,777.10960
Overall Steps per Second: 3,123.73749

Timestep Collection Time: 13.24134
Timestep Consumption Time: 2.76961
PPO Batch Consumption Time: 0.06430
Total Iteration Time: 16.01095

Cumulative Model Updates: 66,789
Cumulative Timesteps: 1,114,028,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,795,304.40209
Policy Entropy: 1.06132
Value Function Loss: 1.29339

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.15614
Policy Update Magnitude: 0.07291
Value Function Update Magnitude: 0.11760

Collected Steps per Second: 3,685.69031
Overall Steps per Second: 3,124.18718

Timestep Collection Time: 13.57249
Timestep Consumption Time: 2.43935
PPO Batch Consumption Time: 0.05169
Total Iteration Time: 16.01184

Cumulative Model Updates: 66,792
Cumulative Timesteps: 1,114,078,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1114078534...
Checkpoint 1114078534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800,488.62599
Policy Entropy: 1.07463
Value Function Loss: 1.32229

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.14236
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.10493

Collected Steps per Second: 3,985.42099
Overall Steps per Second: 3,253.89682

Timestep Collection Time: 12.55325
Timestep Consumption Time: 2.82216
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 15.37541

Cumulative Model Updates: 66,795
Cumulative Timesteps: 1,114,128,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684,641.01519
Policy Entropy: 1.07878
Value Function Loss: 1.22618

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.09523

Collected Steps per Second: 3,822.94499
Overall Steps per Second: 3,193.78397

Timestep Collection Time: 13.08572
Timestep Consumption Time: 2.57783
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 15.66355

Cumulative Model Updates: 66,798
Cumulative Timesteps: 1,114,178,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1114178590...
Checkpoint 1114178590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776,942.29502
Policy Entropy: 1.07286
Value Function Loss: 1.29684

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.09330

Collected Steps per Second: 3,777.26313
Overall Steps per Second: 3,154.92225

Timestep Collection Time: 13.24451
Timestep Consumption Time: 2.61262
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 15.85713

Cumulative Model Updates: 66,801
Cumulative Timesteps: 1,114,228,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659,224.44940
Policy Entropy: 1.06582
Value Function Loss: 1.29311

Mean KL Divergence: 0.03006
SB3 Clip Fraction: 0.18884
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.10991

Collected Steps per Second: 3,771.37006
Overall Steps per Second: 3,182.44856

Timestep Collection Time: 13.26521
Timestep Consumption Time: 2.45477
PPO Batch Consumption Time: 0.04907
Total Iteration Time: 15.71997

Cumulative Model Updates: 66,804
Cumulative Timesteps: 1,114,278,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1114278646...
Checkpoint 1114278646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591,762.37926
Policy Entropy: 1.07259
Value Function Loss: 1.28291

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.12242

Collected Steps per Second: 3,980.67950
Overall Steps per Second: 3,301.61758

Timestep Collection Time: 12.56620
Timestep Consumption Time: 2.58456
PPO Batch Consumption Time: 0.06102
Total Iteration Time: 15.15076

Cumulative Model Updates: 66,807
Cumulative Timesteps: 1,114,328,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552,869.61785
Policy Entropy: 1.07651
Value Function Loss: 1.21598

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.13150

Collected Steps per Second: 3,803.61364
Overall Steps per Second: 3,154.16407

Timestep Collection Time: 13.15118
Timestep Consumption Time: 2.70786
PPO Batch Consumption Time: 0.05762
Total Iteration Time: 15.85904

Cumulative Model Updates: 66,810
Cumulative Timesteps: 1,114,378,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1114378690...
Checkpoint 1114378690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334,756.37801
Policy Entropy: 1.05610
Value Function Loss: 1.12568

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.13454

Collected Steps per Second: 3,823.48221
Overall Steps per Second: 3,142.24342

Timestep Collection Time: 13.08075
Timestep Consumption Time: 2.83591
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 15.91665

Cumulative Model Updates: 66,813
Cumulative Timesteps: 1,114,428,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,019,532.06150
Policy Entropy: 1.06844
Value Function Loss: 1.17769

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.12378

Collected Steps per Second: 3,969.84964
Overall Steps per Second: 3,249.30511

Timestep Collection Time: 12.60400
Timestep Consumption Time: 2.79498
PPO Batch Consumption Time: 0.05198
Total Iteration Time: 15.39898

Cumulative Model Updates: 66,816
Cumulative Timesteps: 1,114,478,740

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1114478740...
Checkpoint 1114478740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431,679.85733
Policy Entropy: 1.07774
Value Function Loss: 1.21714

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.06576
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 3,696.76678
Overall Steps per Second: 3,167.76951

Timestep Collection Time: 13.52750
Timestep Consumption Time: 2.25901
PPO Batch Consumption Time: 0.06022
Total Iteration Time: 15.78650

Cumulative Model Updates: 66,819
Cumulative Timesteps: 1,114,528,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593,277.18052
Policy Entropy: 1.07822
Value Function Loss: 1.27591

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.07932
Value Function Update Magnitude: 0.11237

Collected Steps per Second: 3,685.26681
Overall Steps per Second: 3,128.16119

Timestep Collection Time: 13.56971
Timestep Consumption Time: 2.41668
PPO Batch Consumption Time: 0.05184
Total Iteration Time: 15.98639

Cumulative Model Updates: 66,822
Cumulative Timesteps: 1,114,578,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1114578756...
Checkpoint 1114578756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615,859.34252
Policy Entropy: 1.08237
Value Function Loss: 1.30596

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.07975
Value Function Update Magnitude: 0.10674

Collected Steps per Second: 3,739.25552
Overall Steps per Second: 3,154.02507

Timestep Collection Time: 13.37165
Timestep Consumption Time: 2.48111
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 15.85276

Cumulative Model Updates: 66,825
Cumulative Timesteps: 1,114,628,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066,224.85109
Policy Entropy: 1.08142
Value Function Loss: 1.29980

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.07687
Value Function Update Magnitude: 0.09617

Collected Steps per Second: 4,123.59056
Overall Steps per Second: 3,422.09070

Timestep Collection Time: 12.13118
Timestep Consumption Time: 2.48679
PPO Batch Consumption Time: 0.05029
Total Iteration Time: 14.61796

Cumulative Model Updates: 66,828
Cumulative Timesteps: 1,114,678,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1114678780...
Checkpoint 1114678780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481,058.16492
Policy Entropy: 1.07287
Value Function Loss: 1.28329

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.07389
Value Function Update Magnitude: 0.09015

Collected Steps per Second: 4,038.68304
Overall Steps per Second: 3,344.41538

Timestep Collection Time: 12.39166
Timestep Consumption Time: 2.57239
PPO Batch Consumption Time: 0.05280
Total Iteration Time: 14.96405

Cumulative Model Updates: 66,831
Cumulative Timesteps: 1,114,728,826

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272,588.28234
Policy Entropy: 1.08784
Value Function Loss: 1.19584

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.08912

Collected Steps per Second: 3,787.32960
Overall Steps per Second: 3,162.36587

Timestep Collection Time: 13.20403
Timestep Consumption Time: 2.60945
PPO Batch Consumption Time: 0.05368
Total Iteration Time: 15.81348

Cumulative Model Updates: 66,834
Cumulative Timesteps: 1,114,778,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1114778834...
Checkpoint 1114778834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,096,684.14353
Policy Entropy: 1.09149
Value Function Loss: 1.12943

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.09378

Collected Steps per Second: 3,617.70727
Overall Steps per Second: 3,091.02258

Timestep Collection Time: 13.82146
Timestep Consumption Time: 2.35506
PPO Batch Consumption Time: 0.05016
Total Iteration Time: 16.17652

Cumulative Model Updates: 66,837
Cumulative Timesteps: 1,114,828,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,790,745.97821
Policy Entropy: 1.07377
Value Function Loss: 1.10736

Mean KL Divergence: 0.02254
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.05843
Value Function Update Magnitude: 0.08800

Collected Steps per Second: 3,914.39417
Overall Steps per Second: 3,237.40875

Timestep Collection Time: 12.77899
Timestep Consumption Time: 2.67226
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 15.45125

Cumulative Model Updates: 66,840
Cumulative Timesteps: 1,114,878,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1114878858...
Checkpoint 1114878858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658,527.02071
Policy Entropy: 1.07890
Value Function Loss: 1.16621

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.09419

Collected Steps per Second: 3,726.51970
Overall Steps per Second: 3,126.23148

Timestep Collection Time: 13.42540
Timestep Consumption Time: 2.57790
PPO Batch Consumption Time: 0.05097
Total Iteration Time: 16.00329

Cumulative Model Updates: 66,843
Cumulative Timesteps: 1,114,928,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446,334.31370
Policy Entropy: 1.08970
Value Function Loss: 1.22333

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.11121

Collected Steps per Second: 3,980.01401
Overall Steps per Second: 3,292.77984

Timestep Collection Time: 12.56578
Timestep Consumption Time: 2.62260
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 15.18838

Cumulative Model Updates: 66,846
Cumulative Timesteps: 1,114,978,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1114978900...
Checkpoint 1114978900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559,817.20658
Policy Entropy: 1.09116
Value Function Loss: 1.21951

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.07042
Value Function Update Magnitude: 0.12090

Collected Steps per Second: 3,750.20446
Overall Steps per Second: 3,166.96215

Timestep Collection Time: 13.33261
Timestep Consumption Time: 2.45539
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 15.78800

Cumulative Model Updates: 66,849
Cumulative Timesteps: 1,115,028,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729,501.26651
Policy Entropy: 1.08716
Value Function Loss: 1.11890

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.07346
Value Function Update Magnitude: 0.11298

Collected Steps per Second: 3,940.71977
Overall Steps per Second: 3,297.21722

Timestep Collection Time: 12.69870
Timestep Consumption Time: 2.47835
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 15.17704

Cumulative Model Updates: 66,852
Cumulative Timesteps: 1,115,078,942

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1115078942...
Checkpoint 1115078942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,147,032.04092
Policy Entropy: 1.06328
Value Function Loss: 1.07676

Mean KL Divergence: 0.03592
SB3 Clip Fraction: 0.18446
Policy Update Magnitude: 0.07148
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 3,724.75056
Overall Steps per Second: 3,118.17306

Timestep Collection Time: 13.43499
Timestep Consumption Time: 2.61351
PPO Batch Consumption Time: 0.05162
Total Iteration Time: 16.04850

Cumulative Model Updates: 66,855
Cumulative Timesteps: 1,115,128,984

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018,017.95364
Policy Entropy: 1.08518
Value Function Loss: 1.08912

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.09951

Collected Steps per Second: 3,892.72079
Overall Steps per Second: 3,281.92071

Timestep Collection Time: 12.85425
Timestep Consumption Time: 2.39231
PPO Batch Consumption Time: 0.06167
Total Iteration Time: 15.24656

Cumulative Model Updates: 66,858
Cumulative Timesteps: 1,115,179,022

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1115179022...
Checkpoint 1115179022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090,357.30361
Policy Entropy: 1.07733
Value Function Loss: 1.14251

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.06567
Value Function Update Magnitude: 0.08910

Collected Steps per Second: 3,711.00436
Overall Steps per Second: 3,157.42503

Timestep Collection Time: 13.48422
Timestep Consumption Time: 2.36414
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 15.84836

Cumulative Model Updates: 66,861
Cumulative Timesteps: 1,115,229,062

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970,212.98668
Policy Entropy: 1.07670
Value Function Loss: 1.10434

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.07227
Value Function Update Magnitude: 0.09666

Collected Steps per Second: 3,916.05778
Overall Steps per Second: 3,293.55517

Timestep Collection Time: 12.76947
Timestep Consumption Time: 2.41351
PPO Batch Consumption Time: 0.05137
Total Iteration Time: 15.18299

Cumulative Model Updates: 66,864
Cumulative Timesteps: 1,115,279,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1115279068...
Checkpoint 1115279068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535,086.03980
Policy Entropy: 1.07667
Value Function Loss: 1.04622

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.15254
Policy Update Magnitude: 0.07162
Value Function Update Magnitude: 0.11382

Collected Steps per Second: 3,673.57859
Overall Steps per Second: 3,065.82839

Timestep Collection Time: 13.61833
Timestep Consumption Time: 2.69961
PPO Batch Consumption Time: 0.04994
Total Iteration Time: 16.31794

Cumulative Model Updates: 66,867
Cumulative Timesteps: 1,115,329,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,806,251.68422
Policy Entropy: 1.08406
Value Function Loss: 1.09408

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.11654

Collected Steps per Second: 3,849.96441
Overall Steps per Second: 3,179.55426

Timestep Collection Time: 12.98817
Timestep Consumption Time: 2.73856
PPO Batch Consumption Time: 0.04641
Total Iteration Time: 15.72673

Cumulative Model Updates: 66,870
Cumulative Timesteps: 1,115,379,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1115379100...
Checkpoint 1115379100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276,563.56640
Policy Entropy: 1.09303
Value Function Loss: 1.15375

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.10430

Collected Steps per Second: 3,643.12274
Overall Steps per Second: 3,030.05029

Timestep Collection Time: 13.73382
Timestep Consumption Time: 2.77878
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 16.51260

Cumulative Model Updates: 66,873
Cumulative Timesteps: 1,115,429,134

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635,928.75068
Policy Entropy: 1.07998
Value Function Loss: 1.20362

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.06335
Value Function Update Magnitude: 0.10807

Collected Steps per Second: 3,751.94599
Overall Steps per Second: 3,149.21653

Timestep Collection Time: 13.33175
Timestep Consumption Time: 2.55157
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 15.88332

Cumulative Model Updates: 66,876
Cumulative Timesteps: 1,115,479,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1115479154...
Checkpoint 1115479154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252,519.52319
Policy Entropy: 1.07707
Value Function Loss: 1.15129

Mean KL Divergence: 0.03162
SB3 Clip Fraction: 0.17660
Policy Update Magnitude: 0.06535
Value Function Update Magnitude: 0.11148

Collected Steps per Second: 3,917.57365
Overall Steps per Second: 3,229.97374

Timestep Collection Time: 12.76760
Timestep Consumption Time: 2.71798
PPO Batch Consumption Time: 0.05295
Total Iteration Time: 15.48557

Cumulative Model Updates: 66,879
Cumulative Timesteps: 1,115,529,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651,620.49698
Policy Entropy: 1.09455
Value Function Loss: 1.08536

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.10447

Collected Steps per Second: 3,842.55206
Overall Steps per Second: 3,199.64431

Timestep Collection Time: 13.01843
Timestep Consumption Time: 2.61581
PPO Batch Consumption Time: 0.05215
Total Iteration Time: 15.63424

Cumulative Model Updates: 66,882
Cumulative Timesteps: 1,115,579,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1115579196...
Checkpoint 1115579196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636,214.81032
Policy Entropy: 1.08341
Value Function Loss: 1.18243

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.06337
Value Function Update Magnitude: 0.11235

Collected Steps per Second: 3,953.95340
Overall Steps per Second: 3,299.46256

Timestep Collection Time: 12.65215
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.05781
Total Iteration Time: 15.16186

Cumulative Model Updates: 66,885
Cumulative Timesteps: 1,115,629,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474,959.75951
Policy Entropy: 1.05627
Value Function Loss: 1.16585

Mean KL Divergence: 0.03393
SB3 Clip Fraction: 0.17263
Policy Update Magnitude: 0.06559
Value Function Update Magnitude: 0.11493

Collected Steps per Second: 3,851.99899
Overall Steps per Second: 3,192.58843

Timestep Collection Time: 12.98131
Timestep Consumption Time: 2.68121
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 15.66253

Cumulative Model Updates: 66,888
Cumulative Timesteps: 1,115,679,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1115679226...
Checkpoint 1115679226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,237,110.81471
Policy Entropy: 1.06513
Value Function Loss: 1.23746

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.10054

Collected Steps per Second: 3,979.32165
Overall Steps per Second: 3,269.44697

Timestep Collection Time: 12.57199
Timestep Consumption Time: 2.72968
PPO Batch Consumption Time: 0.05121
Total Iteration Time: 15.30167

Cumulative Model Updates: 66,891
Cumulative Timesteps: 1,115,729,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,254,261.19748
Policy Entropy: 1.07360
Value Function Loss: 1.14063

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.10153

Collected Steps per Second: 4,071.94822
Overall Steps per Second: 3,351.70126

Timestep Collection Time: 12.28257
Timestep Consumption Time: 2.63940
PPO Batch Consumption Time: 0.05282
Total Iteration Time: 14.92197

Cumulative Model Updates: 66,894
Cumulative Timesteps: 1,115,779,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1115779268...
Checkpoint 1115779268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213,240.05821
Policy Entropy: 1.06517
Value Function Loss: 1.16171

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.14716
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 4,129.38163
Overall Steps per Second: 3,436.74506

Timestep Collection Time: 12.11029
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.05437
Total Iteration Time: 14.55098

Cumulative Model Updates: 66,897
Cumulative Timesteps: 1,115,829,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300,370.07182
Policy Entropy: 1.05536
Value Function Loss: 1.16317

Mean KL Divergence: 0.02363
SB3 Clip Fraction: 0.16803
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.10825

Collected Steps per Second: 4,068.08658
Overall Steps per Second: 3,366.60785

Timestep Collection Time: 12.30111
Timestep Consumption Time: 2.56311
PPO Batch Consumption Time: 0.04894
Total Iteration Time: 14.86422

Cumulative Model Updates: 66,900
Cumulative Timesteps: 1,115,879,318

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1115879318...
Checkpoint 1115879318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530,461.99456
Policy Entropy: 1.06684
Value Function Loss: 1.17834

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.10742

Collected Steps per Second: 3,751.98777
Overall Steps per Second: 3,216.71739

Timestep Collection Time: 13.33320
Timestep Consumption Time: 2.21868
PPO Batch Consumption Time: 0.05115
Total Iteration Time: 15.55188

Cumulative Model Updates: 66,903
Cumulative Timesteps: 1,115,929,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787,635.33853
Policy Entropy: 1.06938
Value Function Loss: 1.18725

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.10898

Collected Steps per Second: 3,792.00118
Overall Steps per Second: 3,159.84209

Timestep Collection Time: 13.18776
Timestep Consumption Time: 2.63835
PPO Batch Consumption Time: 0.06568
Total Iteration Time: 15.82611

Cumulative Model Updates: 66,906
Cumulative Timesteps: 1,115,979,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1115979352...
Checkpoint 1115979352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499,021.18362
Policy Entropy: 1.05168
Value Function Loss: 1.20075

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.06355
Value Function Update Magnitude: 0.12767

Collected Steps per Second: 3,919.83093
Overall Steps per Second: 3,216.62366

Timestep Collection Time: 12.76586
Timestep Consumption Time: 2.79083
PPO Batch Consumption Time: 0.04905
Total Iteration Time: 15.55668

Cumulative Model Updates: 66,909
Cumulative Timesteps: 1,116,029,392

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145,401.02276
Policy Entropy: 1.06285
Value Function Loss: 1.18571

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.11829

Collected Steps per Second: 3,659.13344
Overall Steps per Second: 3,083.21849

Timestep Collection Time: 13.67318
Timestep Consumption Time: 2.55402
PPO Batch Consumption Time: 0.05020
Total Iteration Time: 16.22720

Cumulative Model Updates: 66,912
Cumulative Timesteps: 1,116,079,424

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1116079424...
Checkpoint 1116079424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473,797.15014
Policy Entropy: 1.07153
Value Function Loss: 1.22229

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.10680

Collected Steps per Second: 4,040.36844
Overall Steps per Second: 3,333.69424

Timestep Collection Time: 12.38352
Timestep Consumption Time: 2.62505
PPO Batch Consumption Time: 0.05121
Total Iteration Time: 15.00857

Cumulative Model Updates: 66,915
Cumulative Timesteps: 1,116,129,458

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625,821.96172
Policy Entropy: 1.07466
Value Function Loss: 1.16995

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.11492

Collected Steps per Second: 3,815.61073
Overall Steps per Second: 3,175.58975

Timestep Collection Time: 13.10563
Timestep Consumption Time: 2.64136
PPO Batch Consumption Time: 0.06232
Total Iteration Time: 15.74700

Cumulative Model Updates: 66,918
Cumulative Timesteps: 1,116,179,464

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1116179464...
Checkpoint 1116179464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427,359.93086
Policy Entropy: 1.06409
Value Function Loss: 1.15720

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.06919
Value Function Update Magnitude: 0.13434

Collected Steps per Second: 3,927.14987
Overall Steps per Second: 3,268.38871

Timestep Collection Time: 12.74156
Timestep Consumption Time: 2.56813
PPO Batch Consumption Time: 0.05179
Total Iteration Time: 15.30968

Cumulative Model Updates: 66,921
Cumulative Timesteps: 1,116,229,502

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452,018.41677
Policy Entropy: 1.05821
Value Function Loss: 1.11932

Mean KL Divergence: 0.02983
SB3 Clip Fraction: 0.19071
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.12554

Collected Steps per Second: 3,599.52098
Overall Steps per Second: 3,001.56989

Timestep Collection Time: 13.89629
Timestep Consumption Time: 2.76832
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 16.66461

Cumulative Model Updates: 66,924
Cumulative Timesteps: 1,116,279,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1116279522...
Checkpoint 1116279522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483,371.09553
Policy Entropy: 1.07142
Value Function Loss: 1.18206

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.10637

Collected Steps per Second: 3,998.43857
Overall Steps per Second: 3,372.32135

Timestep Collection Time: 12.51288
Timestep Consumption Time: 2.32319
PPO Batch Consumption Time: 0.05387
Total Iteration Time: 14.83607

Cumulative Model Updates: 66,927
Cumulative Timesteps: 1,116,329,554

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649,339.52802
Policy Entropy: 1.08461
Value Function Loss: 1.20469

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.06309
Value Function Update Magnitude: 0.10181

Collected Steps per Second: 3,661.42417
Overall Steps per Second: 3,097.03804

Timestep Collection Time: 13.66627
Timestep Consumption Time: 2.49046
PPO Batch Consumption Time: 0.05272
Total Iteration Time: 16.15673

Cumulative Model Updates: 66,930
Cumulative Timesteps: 1,116,379,592

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1116379592...
Checkpoint 1116379592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434,146.75265
Policy Entropy: 1.06775
Value Function Loss: 1.22341

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.10613

Collected Steps per Second: 3,910.76116
Overall Steps per Second: 3,265.28861

Timestep Collection Time: 12.79700
Timestep Consumption Time: 2.52967
PPO Batch Consumption Time: 0.05369
Total Iteration Time: 15.32667

Cumulative Model Updates: 66,933
Cumulative Timesteps: 1,116,429,638

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085,847.51844
Policy Entropy: 1.04990
Value Function Loss: 1.22600

Mean KL Divergence: 0.02624
SB3 Clip Fraction: 0.16641
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.10857

Collected Steps per Second: 3,798.90136
Overall Steps per Second: 3,110.53770

Timestep Collection Time: 13.17328
Timestep Consumption Time: 2.91525
PPO Batch Consumption Time: 0.05116
Total Iteration Time: 16.08854

Cumulative Model Updates: 66,936
Cumulative Timesteps: 1,116,479,682

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1116479682...
Checkpoint 1116479682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,280,802.44036
Policy Entropy: 1.05397
Value Function Loss: 1.26407

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.09843

Collected Steps per Second: 4,064.42729
Overall Steps per Second: 3,351.90605

Timestep Collection Time: 12.30333
Timestep Consumption Time: 2.61534
PPO Batch Consumption Time: 0.05103
Total Iteration Time: 14.91868

Cumulative Model Updates: 66,939
Cumulative Timesteps: 1,116,529,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041,405.94900
Policy Entropy: 1.06028
Value Function Loss: 1.27562

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.15261
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.10486

Collected Steps per Second: 3,779.30586
Overall Steps per Second: 3,134.05770

Timestep Collection Time: 13.23206
Timestep Consumption Time: 2.72425
PPO Batch Consumption Time: 0.05177
Total Iteration Time: 15.95631

Cumulative Model Updates: 66,942
Cumulative Timesteps: 1,116,579,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1116579696...
Checkpoint 1116579696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425,470.13154
Policy Entropy: 1.04454
Value Function Loss: 1.18224

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.14846
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.10290

Collected Steps per Second: 3,894.09427
Overall Steps per Second: 3,199.46661

Timestep Collection Time: 12.85228
Timestep Consumption Time: 2.79032
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 15.64261

Cumulative Model Updates: 66,945
Cumulative Timesteps: 1,116,629,744

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,360,297.47225
Policy Entropy: 1.04456
Value Function Loss: 1.10819

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.16510
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.10332

Collected Steps per Second: 3,764.41357
Overall Steps per Second: 3,158.92159

Timestep Collection Time: 13.29450
Timestep Consumption Time: 2.54825
PPO Batch Consumption Time: 0.06374
Total Iteration Time: 15.84275

Cumulative Model Updates: 66,948
Cumulative Timesteps: 1,116,679,790

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1116679790...
Checkpoint 1116679790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012,947.61719
Policy Entropy: 1.05882
Value Function Loss: 1.13264

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.09650

Collected Steps per Second: 4,015.28558
Overall Steps per Second: 3,318.73248

Timestep Collection Time: 12.45341
Timestep Consumption Time: 2.61379
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 15.06720

Cumulative Model Updates: 66,951
Cumulative Timesteps: 1,116,729,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545,427.80316
Policy Entropy: 1.06509
Value Function Loss: 1.17176

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.09580

Collected Steps per Second: 3,733.41841
Overall Steps per Second: 3,113.75798

Timestep Collection Time: 13.40487
Timestep Consumption Time: 2.66767
PPO Batch Consumption Time: 0.06685
Total Iteration Time: 16.07254

Cumulative Model Updates: 66,954
Cumulative Timesteps: 1,116,779,840

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1116779840...
Checkpoint 1116779840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,775,704.37061
Policy Entropy: 1.04653
Value Function Loss: 1.20428

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.09821

Collected Steps per Second: 3,775.06756
Overall Steps per Second: 3,141.07941

Timestep Collection Time: 13.25645
Timestep Consumption Time: 2.67565
PPO Batch Consumption Time: 0.05086
Total Iteration Time: 15.93210

Cumulative Model Updates: 66,957
Cumulative Timesteps: 1,116,829,884

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703,238.98264
Policy Entropy: 1.04624
Value Function Loss: 1.15908

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.17256
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.10633

Collected Steps per Second: 3,744.83801
Overall Steps per Second: 3,144.71531

Timestep Collection Time: 13.36293
Timestep Consumption Time: 2.55012
PPO Batch Consumption Time: 0.05306
Total Iteration Time: 15.91305

Cumulative Model Updates: 66,960
Cumulative Timesteps: 1,116,879,926

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1116879926...
Checkpoint 1116879926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015,759.13907
Policy Entropy: 1.05973
Value Function Loss: 1.22029

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 3,729.68543
Overall Steps per Second: 3,153.60471

Timestep Collection Time: 13.40810
Timestep Consumption Time: 2.44931
PPO Batch Consumption Time: 0.04740
Total Iteration Time: 15.85741

Cumulative Model Updates: 66,963
Cumulative Timesteps: 1,116,929,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650,779.10400
Policy Entropy: 1.06285
Value Function Loss: 1.23777

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.13358

Collected Steps per Second: 3,796.13904
Overall Steps per Second: 3,223.27321

Timestep Collection Time: 13.18339
Timestep Consumption Time: 2.34306
PPO Batch Consumption Time: 0.06011
Total Iteration Time: 15.52645

Cumulative Model Updates: 66,966
Cumulative Timesteps: 1,116,979,980

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1116979980...
Checkpoint 1116979980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,065,576.79274
Policy Entropy: 1.04989
Value Function Loss: 1.25662

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.12983

Collected Steps per Second: 3,676.62310
Overall Steps per Second: 3,122.66319

Timestep Collection Time: 13.60760
Timestep Consumption Time: 2.41399
PPO Batch Consumption Time: 0.05106
Total Iteration Time: 16.02158

Cumulative Model Updates: 66,969
Cumulative Timesteps: 1,117,030,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781,752.94779
Policy Entropy: 1.03689
Value Function Loss: 1.20510

Mean KL Divergence: 0.02790
SB3 Clip Fraction: 0.17645
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.11242

Collected Steps per Second: 4,041.07034
Overall Steps per Second: 3,316.26626

Timestep Collection Time: 12.38434
Timestep Consumption Time: 2.70673
PPO Batch Consumption Time: 0.05079
Total Iteration Time: 15.09107

Cumulative Model Updates: 66,972
Cumulative Timesteps: 1,117,080,056

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1117080056...
Checkpoint 1117080056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945,249.58314
Policy Entropy: 1.06528
Value Function Loss: 1.17177

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.10604

Collected Steps per Second: 3,621.82923
Overall Steps per Second: 3,031.41237

Timestep Collection Time: 13.81512
Timestep Consumption Time: 2.69072
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 16.50584

Cumulative Model Updates: 66,975
Cumulative Timesteps: 1,117,130,092

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,230,543.15136
Policy Entropy: 1.06011
Value Function Loss: 1.13112

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.10623

Collected Steps per Second: 3,742.55645
Overall Steps per Second: 3,131.20418

Timestep Collection Time: 13.37107
Timestep Consumption Time: 2.61064
PPO Batch Consumption Time: 0.05154
Total Iteration Time: 15.98171

Cumulative Model Updates: 66,978
Cumulative Timesteps: 1,117,180,134

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1117180134...
Checkpoint 1117180134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644,047.78723
Policy Entropy: 1.06002
Value Function Loss: 1.14386

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.06683
Value Function Update Magnitude: 0.09636

Collected Steps per Second: 3,831.31369
Overall Steps per Second: 3,150.97107

Timestep Collection Time: 13.05035
Timestep Consumption Time: 2.81777
PPO Batch Consumption Time: 0.06063
Total Iteration Time: 15.86812

Cumulative Model Updates: 66,981
Cumulative Timesteps: 1,117,230,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,119,571.53878
Policy Entropy: 1.04581
Value Function Loss: 1.18793

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.07683
Value Function Update Magnitude: 0.09244

Collected Steps per Second: 3,851.18005
Overall Steps per Second: 3,222.08817

Timestep Collection Time: 12.99498
Timestep Consumption Time: 2.53719
PPO Batch Consumption Time: 0.05807
Total Iteration Time: 15.53216

Cumulative Model Updates: 66,984
Cumulative Timesteps: 1,117,280,180

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1117280180...
Checkpoint 1117280180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542,555.55510
Policy Entropy: 1.05138
Value Function Loss: 1.16509

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.07003
Value Function Update Magnitude: 0.08961

Collected Steps per Second: 3,823.22872
Overall Steps per Second: 3,184.37343

Timestep Collection Time: 13.08528
Timestep Consumption Time: 2.62519
PPO Batch Consumption Time: 0.05384
Total Iteration Time: 15.71047

Cumulative Model Updates: 66,987
Cumulative Timesteps: 1,117,330,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,796,183.70200
Policy Entropy: 1.04833
Value Function Loss: 1.13882

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.07250
Value Function Update Magnitude: 0.08759

Collected Steps per Second: 3,806.33739
Overall Steps per Second: 3,180.94626

Timestep Collection Time: 13.14650
Timestep Consumption Time: 2.58467
PPO Batch Consumption Time: 0.04861
Total Iteration Time: 15.73117

Cumulative Model Updates: 66,990
Cumulative Timesteps: 1,117,380,248

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1117380248...
Checkpoint 1117380248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429,304.29254
Policy Entropy: 1.06294
Value Function Loss: 1.12643

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.15436
Policy Update Magnitude: 0.06752
Value Function Update Magnitude: 0.08557

Collected Steps per Second: 4,036.71867
Overall Steps per Second: 3,260.26178

Timestep Collection Time: 12.39472
Timestep Consumption Time: 2.95190
PPO Batch Consumption Time: 0.05211
Total Iteration Time: 15.34662

Cumulative Model Updates: 66,993
Cumulative Timesteps: 1,117,430,282

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041,621.92055
Policy Entropy: 1.04857
Value Function Loss: 1.18887

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.06273
Value Function Update Magnitude: 0.08263

Collected Steps per Second: 4,034.67110
Overall Steps per Second: 3,325.27684

Timestep Collection Time: 12.39655
Timestep Consumption Time: 2.64460
PPO Batch Consumption Time: 0.06359
Total Iteration Time: 15.04115

Cumulative Model Updates: 66,996
Cumulative Timesteps: 1,117,480,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1117480298...
Checkpoint 1117480298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357,394.92492
Policy Entropy: 1.04136
Value Function Loss: 1.19651

Mean KL Divergence: 0.02599
SB3 Clip Fraction: 0.17918
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.08110

Collected Steps per Second: 3,915.94414
Overall Steps per Second: 3,265.53863

Timestep Collection Time: 12.77342
Timestep Consumption Time: 2.54411
PPO Batch Consumption Time: 0.05232
Total Iteration Time: 15.31753

Cumulative Model Updates: 66,999
Cumulative Timesteps: 1,117,530,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881,170.04270
Policy Entropy: 1.05814
Value Function Loss: 1.24193

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.09618

Collected Steps per Second: 4,010.43090
Overall Steps per Second: 3,354.35976

Timestep Collection Time: 12.47297
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.06380
Total Iteration Time: 14.91253

Cumulative Model Updates: 67,002
Cumulative Timesteps: 1,117,580,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1117580340...
Checkpoint 1117580340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469,448.97934
Policy Entropy: 1.05938
Value Function Loss: 1.22962

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.09687

Collected Steps per Second: 3,647.97736
Overall Steps per Second: 3,096.10111

Timestep Collection Time: 13.71829
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.05114
Total Iteration Time: 16.16355

Cumulative Model Updates: 67,005
Cumulative Timesteps: 1,117,630,384

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,045,816.52382
Policy Entropy: 1.04367
Value Function Loss: 1.28209

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 3,600.38787
Overall Steps per Second: 3,068.39320

Timestep Collection Time: 13.89350
Timestep Consumption Time: 2.40884
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 16.30234

Cumulative Model Updates: 67,008
Cumulative Timesteps: 1,117,680,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1117680406...
Checkpoint 1117680406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499,840.16525
Policy Entropy: 1.02939
Value Function Loss: 1.22067

Mean KL Divergence: 0.02833
SB3 Clip Fraction: 0.18385
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.11994

Collected Steps per Second: 3,672.66041
Overall Steps per Second: 3,118.51012

Timestep Collection Time: 13.62064
Timestep Consumption Time: 2.42035
PPO Batch Consumption Time: 0.05060
Total Iteration Time: 16.04099

Cumulative Model Updates: 67,011
Cumulative Timesteps: 1,117,730,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,193,767.45981
Policy Entropy: 1.04238
Value Function Loss: 1.20945

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.12654

Collected Steps per Second: 3,800.40719
Overall Steps per Second: 3,173.21344

Timestep Collection Time: 13.15701
Timestep Consumption Time: 2.60052
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 15.75753

Cumulative Model Updates: 67,014
Cumulative Timesteps: 1,117,780,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1117780432...
Checkpoint 1117780432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951,808.74453
Policy Entropy: 1.04663
Value Function Loss: 1.19874

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.15157
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.12522

Collected Steps per Second: 3,923.29038
Overall Steps per Second: 3,241.89653

Timestep Collection Time: 12.74695
Timestep Consumption Time: 2.67920
PPO Batch Consumption Time: 0.05929
Total Iteration Time: 15.42616

Cumulative Model Updates: 67,017
Cumulative Timesteps: 1,117,830,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397,460.49978
Policy Entropy: 1.03499
Value Function Loss: 1.19347

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.13086

Collected Steps per Second: 3,664.77752
Overall Steps per Second: 3,078.28546

Timestep Collection Time: 13.64776
Timestep Consumption Time: 2.60025
PPO Batch Consumption Time: 0.05103
Total Iteration Time: 16.24801

Cumulative Model Updates: 67,020
Cumulative Timesteps: 1,117,880,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1117880458...
Checkpoint 1117880458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451,259.17207
Policy Entropy: 1.02648
Value Function Loss: 1.16711

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.16601
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.12344

Collected Steps per Second: 4,095.70499
Overall Steps per Second: 3,394.34281

Timestep Collection Time: 12.21914
Timestep Consumption Time: 2.52480
PPO Batch Consumption Time: 0.06105
Total Iteration Time: 14.74394

Cumulative Model Updates: 67,023
Cumulative Timesteps: 1,117,930,504

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,992,320.09764
Policy Entropy: 1.04371
Value Function Loss: 1.15599

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.06030
Value Function Update Magnitude: 0.10615

Collected Steps per Second: 3,710.11990
Overall Steps per Second: 3,169.65681

Timestep Collection Time: 13.48474
Timestep Consumption Time: 2.29930
PPO Batch Consumption Time: 0.05115
Total Iteration Time: 15.78404

Cumulative Model Updates: 67,026
Cumulative Timesteps: 1,117,980,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1117980534...
Checkpoint 1117980534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,676,560.32970
Policy Entropy: 1.05350
Value Function Loss: 1.10929

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.10473

Collected Steps per Second: 3,853.27113
Overall Steps per Second: 3,210.48296

Timestep Collection Time: 12.98118
Timestep Consumption Time: 2.59903
PPO Batch Consumption Time: 0.05806
Total Iteration Time: 15.58021

Cumulative Model Updates: 67,029
Cumulative Timesteps: 1,118,030,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969,910.85291
Policy Entropy: 1.03970
Value Function Loss: 1.16333

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.11137

Collected Steps per Second: 3,769.56680
Overall Steps per Second: 3,161.40670

Timestep Collection Time: 13.26572
Timestep Consumption Time: 2.55193
PPO Batch Consumption Time: 0.05190
Total Iteration Time: 15.81764

Cumulative Model Updates: 67,032
Cumulative Timesteps: 1,118,080,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1118080560...
Checkpoint 1118080560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512,186.85227
Policy Entropy: 1.03187
Value Function Loss: 1.15911

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.18238
Policy Update Magnitude: 0.05843
Value Function Update Magnitude: 0.10748

Collected Steps per Second: 3,859.13171
Overall Steps per Second: 3,239.10940

Timestep Collection Time: 12.95680
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 15.43696

Cumulative Model Updates: 67,035
Cumulative Timesteps: 1,118,130,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693,363.98517
Policy Entropy: 1.04142
Value Function Loss: 1.20593

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.10290

Collected Steps per Second: 3,709.90285
Overall Steps per Second: 3,135.35119

Timestep Collection Time: 13.48930
Timestep Consumption Time: 2.47191
PPO Batch Consumption Time: 0.06105
Total Iteration Time: 15.96121

Cumulative Model Updates: 67,038
Cumulative Timesteps: 1,118,180,606

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1118180606...
Checkpoint 1118180606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889,631.24245
Policy Entropy: 1.04812
Value Function Loss: 1.13219

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.10267

Collected Steps per Second: 3,724.36010
Overall Steps per Second: 3,149.16333

Timestep Collection Time: 13.43211
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 15.88549

Cumulative Model Updates: 67,041
Cumulative Timesteps: 1,118,230,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158,100.86600
Policy Entropy: 1.02691
Value Function Loss: 1.09567

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.10808

Collected Steps per Second: 3,810.95038
Overall Steps per Second: 3,191.19659

Timestep Collection Time: 13.12481
Timestep Consumption Time: 2.54893
PPO Batch Consumption Time: 0.06043
Total Iteration Time: 15.67374

Cumulative Model Updates: 67,044
Cumulative Timesteps: 1,118,280,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1118280650...
Checkpoint 1118280650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426,771.85739
Policy Entropy: 1.02287
Value Function Loss: 1.08265

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.18312
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 3,740.76233
Overall Steps per Second: 3,144.55876

Timestep Collection Time: 13.37909
Timestep Consumption Time: 2.53666
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 15.91575

Cumulative Model Updates: 67,047
Cumulative Timesteps: 1,118,330,698

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653,507.27317
Policy Entropy: 1.03065
Value Function Loss: 1.11096

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.13282

Collected Steps per Second: 3,763.14949
Overall Steps per Second: 3,134.50016

Timestep Collection Time: 13.28781
Timestep Consumption Time: 2.66498
PPO Batch Consumption Time: 0.04535
Total Iteration Time: 15.95278

Cumulative Model Updates: 67,050
Cumulative Timesteps: 1,118,380,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1118380702...
Checkpoint 1118380702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,889,085.78322
Policy Entropy: 1.03602
Value Function Loss: 1.06889

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.16404
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.12733

Collected Steps per Second: 3,826.40829
Overall Steps per Second: 3,216.05886

Timestep Collection Time: 13.07283
Timestep Consumption Time: 2.48099
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 15.55382

Cumulative Model Updates: 67,053
Cumulative Timesteps: 1,118,430,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509,186.98920
Policy Entropy: 1.01790
Value Function Loss: 1.09183

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.15734
Policy Update Magnitude: 0.06236
Value Function Update Magnitude: 0.11724

Collected Steps per Second: 3,645.21715
Overall Steps per Second: 3,035.25558

Timestep Collection Time: 13.72209
Timestep Consumption Time: 2.75758
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 16.47967

Cumulative Model Updates: 67,056
Cumulative Timesteps: 1,118,480,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1118480744...
Checkpoint 1118480744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041,504.72765
Policy Entropy: 1.02998
Value Function Loss: 1.13139

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.18039
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.12359

Collected Steps per Second: 3,940.50780
Overall Steps per Second: 3,245.10126

Timestep Collection Time: 12.69227
Timestep Consumption Time: 2.71988
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 15.41215

Cumulative Model Updates: 67,059
Cumulative Timesteps: 1,118,530,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034,322.65843
Policy Entropy: 1.03370
Value Function Loss: 1.16084

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.17349
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.13898

Collected Steps per Second: 4,136.74608
Overall Steps per Second: 3,365.49115

Timestep Collection Time: 12.08776
Timestep Consumption Time: 2.77010
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 14.85786

Cumulative Model Updates: 67,062
Cumulative Timesteps: 1,118,580,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1118580762...
Checkpoint 1118580762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,112,937.50084
Policy Entropy: 1.01266
Value Function Loss: 1.18345

Mean KL Divergence: 0.02677
SB3 Clip Fraction: 0.17095
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.13412

Collected Steps per Second: 3,930.94905
Overall Steps per Second: 3,261.82005

Timestep Collection Time: 12.73128
Timestep Consumption Time: 2.61169
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 15.34297

Cumulative Model Updates: 67,065
Cumulative Timesteps: 1,118,630,808

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730,217.34646
Policy Entropy: 1.01977
Value Function Loss: 1.16476

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.17073
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.12340

Collected Steps per Second: 3,658.97461
Overall Steps per Second: 3,052.20388

Timestep Collection Time: 13.67159
Timestep Consumption Time: 2.71788
PPO Batch Consumption Time: 0.05400
Total Iteration Time: 16.38947

Cumulative Model Updates: 67,068
Cumulative Timesteps: 1,118,680,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1118680832...
Checkpoint 1118680832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,587,044.63495
Policy Entropy: 1.02335
Value Function Loss: 1.15098

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.15285
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.12095

Collected Steps per Second: 3,722.52957
Overall Steps per Second: 3,159.02315

Timestep Collection Time: 13.43925
Timestep Consumption Time: 2.39729
PPO Batch Consumption Time: 0.06116
Total Iteration Time: 15.83654

Cumulative Model Updates: 67,071
Cumulative Timesteps: 1,118,730,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141,095.89676
Policy Entropy: 1.02924
Value Function Loss: 1.15271

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.12459

Collected Steps per Second: 3,738.31667
Overall Steps per Second: 3,181.39389

Timestep Collection Time: 13.37821
Timestep Consumption Time: 2.34194
PPO Batch Consumption Time: 0.05054
Total Iteration Time: 15.72015

Cumulative Model Updates: 67,074
Cumulative Timesteps: 1,118,780,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1118780872...
Checkpoint 1118780872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230,927.15937
Policy Entropy: 1.00131
Value Function Loss: 1.14264

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.12767

Collected Steps per Second: 3,767.72587
Overall Steps per Second: 3,143.15636

Timestep Collection Time: 13.28334
Timestep Consumption Time: 2.63950
PPO Batch Consumption Time: 0.05210
Total Iteration Time: 15.92285

Cumulative Model Updates: 67,077
Cumulative Timesteps: 1,118,830,920

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898,204.00854
Policy Entropy: 1.00043
Value Function Loss: 1.15829

Mean KL Divergence: 0.02493
SB3 Clip Fraction: 0.19832
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.12268

Collected Steps per Second: 4,011.31767
Overall Steps per Second: 3,346.90889

Timestep Collection Time: 12.47221
Timestep Consumption Time: 2.47591
PPO Batch Consumption Time: 0.04769
Total Iteration Time: 14.94812

Cumulative Model Updates: 67,080
Cumulative Timesteps: 1,118,880,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1118880950...
Checkpoint 1118880950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388,637.04903
Policy Entropy: 1.01766
Value Function Loss: 1.12028

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.10845

Collected Steps per Second: 3,824.14795
Overall Steps per Second: 3,185.61945

Timestep Collection Time: 13.07742
Timestep Consumption Time: 2.62125
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 15.69867

Cumulative Model Updates: 67,083
Cumulative Timesteps: 1,118,930,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,901,579.84920
Policy Entropy: 1.02773
Value Function Loss: 1.11677

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.10471

Collected Steps per Second: 3,734.48983
Overall Steps per Second: 3,113.18249

Timestep Collection Time: 13.39032
Timestep Consumption Time: 2.67235
PPO Batch Consumption Time: 0.05177
Total Iteration Time: 16.06266

Cumulative Model Updates: 67,086
Cumulative Timesteps: 1,118,980,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1118980966...
Checkpoint 1118980966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,950,011.08085
Policy Entropy: 1.01254
Value Function Loss: 1.16638

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.09244

Collected Steps per Second: 4,050.64169
Overall Steps per Second: 3,322.89330

Timestep Collection Time: 12.34619
Timestep Consumption Time: 2.70395
PPO Batch Consumption Time: 0.05301
Total Iteration Time: 15.05014

Cumulative Model Updates: 67,089
Cumulative Timesteps: 1,119,030,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258,429.89264
Policy Entropy: 1.00124
Value Function Loss: 1.17992

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.16985
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.09055

Collected Steps per Second: 3,842.26273
Overall Steps per Second: 3,222.02210

Timestep Collection Time: 13.02097
Timestep Consumption Time: 2.50654
PPO Batch Consumption Time: 0.04884
Total Iteration Time: 15.52752

Cumulative Model Updates: 67,092
Cumulative Timesteps: 1,119,081,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1119081006...
Checkpoint 1119081006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679,604.23829
Policy Entropy: 1.01744
Value Function Loss: 1.13983

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.10805

Collected Steps per Second: 3,816.83022
Overall Steps per Second: 3,209.54343

Timestep Collection Time: 13.11140
Timestep Consumption Time: 2.48085
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 15.59225

Cumulative Model Updates: 67,095
Cumulative Timesteps: 1,119,131,050

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,992,944.87089
Policy Entropy: 1.01849
Value Function Loss: 1.12457

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.16916
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 3,803.38802
Overall Steps per Second: 3,179.49528

Timestep Collection Time: 13.14617
Timestep Consumption Time: 2.57959
PPO Batch Consumption Time: 0.04948
Total Iteration Time: 15.72577

Cumulative Model Updates: 67,098
Cumulative Timesteps: 1,119,181,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1119181050...
Checkpoint 1119181050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620,538.13900
Policy Entropy: 0.99768
Value Function Loss: 1.09696

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.15831
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.12507

Collected Steps per Second: 3,851.49572
Overall Steps per Second: 3,249.45141

Timestep Collection Time: 12.98249
Timestep Consumption Time: 2.40534
PPO Batch Consumption Time: 0.05178
Total Iteration Time: 15.38783

Cumulative Model Updates: 67,101
Cumulative Timesteps: 1,119,231,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445,483.04872
Policy Entropy: 1.01523
Value Function Loss: 1.08710

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.17741
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.12063

Collected Steps per Second: 3,853.10565
Overall Steps per Second: 3,252.35807

Timestep Collection Time: 12.98174
Timestep Consumption Time: 2.39787
PPO Batch Consumption Time: 0.05056
Total Iteration Time: 15.37961

Cumulative Model Updates: 67,104
Cumulative Timesteps: 1,119,281,072

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1119281072...
Checkpoint 1119281072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142,405.14937
Policy Entropy: 1.01924
Value Function Loss: 1.07603

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.17245
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.11096

Collected Steps per Second: 3,908.67243
Overall Steps per Second: 3,296.00381

Timestep Collection Time: 12.79207
Timestep Consumption Time: 2.37782
PPO Batch Consumption Time: 0.05370
Total Iteration Time: 15.16989

Cumulative Model Updates: 67,107
Cumulative Timesteps: 1,119,331,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216,252.36634
Policy Entropy: 1.00991
Value Function Loss: 1.15235

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.16891
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.09583

Collected Steps per Second: 3,842.47995
Overall Steps per Second: 3,225.91316

Timestep Collection Time: 13.01920
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 15.50755

Cumulative Model Updates: 67,110
Cumulative Timesteps: 1,119,381,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1119381098...
Checkpoint 1119381098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625,225.16211
Policy Entropy: 1.00033
Value Function Loss: 1.23985

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.18479
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.09367

Collected Steps per Second: 3,761.53598
Overall Steps per Second: 3,153.68997

Timestep Collection Time: 13.29457
Timestep Consumption Time: 2.56241
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 15.85698

Cumulative Model Updates: 67,113
Cumulative Timesteps: 1,119,431,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,099,986.54874
Policy Entropy: 1.01348
Value Function Loss: 1.23171

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.09740

Collected Steps per Second: 4,005.27489
Overall Steps per Second: 3,303.13621

Timestep Collection Time: 12.48853
Timestep Consumption Time: 2.65465
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 15.14318

Cumulative Model Updates: 67,116
Cumulative Timesteps: 1,119,481,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1119481126...
Checkpoint 1119481126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069,814.40940
Policy Entropy: 1.02413
Value Function Loss: 1.22797

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.15655
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.09322

Collected Steps per Second: 3,674.92516
Overall Steps per Second: 3,106.37408

Timestep Collection Time: 13.60681
Timestep Consumption Time: 2.49042
PPO Batch Consumption Time: 0.05339
Total Iteration Time: 16.09722

Cumulative Model Updates: 67,119
Cumulative Timesteps: 1,119,531,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,165,772.72733
Policy Entropy: 1.00817
Value Function Loss: 1.17969

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.15592
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.10406

Collected Steps per Second: 3,939.79508
Overall Steps per Second: 3,281.90430

Timestep Collection Time: 12.69254
Timestep Consumption Time: 2.54435
PPO Batch Consumption Time: 0.05951
Total Iteration Time: 15.23689

Cumulative Model Updates: 67,122
Cumulative Timesteps: 1,119,581,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1119581136...
Checkpoint 1119581136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210,713.01885
Policy Entropy: 1.01931
Value Function Loss: 1.16293

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.15351
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.10346

Collected Steps per Second: 3,706.35751
Overall Steps per Second: 3,124.75512

Timestep Collection Time: 13.49897
Timestep Consumption Time: 2.51253
PPO Batch Consumption Time: 0.06528
Total Iteration Time: 16.01149

Cumulative Model Updates: 67,125
Cumulative Timesteps: 1,119,631,168

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,091,656.18524
Policy Entropy: 1.01726
Value Function Loss: 1.11731

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.07147
Value Function Update Magnitude: 0.09592

Collected Steps per Second: 3,883.08360
Overall Steps per Second: 3,210.49883

Timestep Collection Time: 12.88255
Timestep Consumption Time: 2.69883
PPO Batch Consumption Time: 0.05815
Total Iteration Time: 15.58138

Cumulative Model Updates: 67,128
Cumulative Timesteps: 1,119,681,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1119681192...
Checkpoint 1119681192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488,819.55288
Policy Entropy: 1.01923
Value Function Loss: 1.13285

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.07495
Value Function Update Magnitude: 0.08503

Collected Steps per Second: 3,774.51847
Overall Steps per Second: 3,138.06605

Timestep Collection Time: 13.25043
Timestep Consumption Time: 2.68741
PPO Batch Consumption Time: 0.05803
Total Iteration Time: 15.93784

Cumulative Model Updates: 67,131
Cumulative Timesteps: 1,119,731,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,118,096.09807
Policy Entropy: 1.01300
Value Function Loss: 1.12030

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.08347
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 3,811.49159
Overall Steps per Second: 3,158.30453

Timestep Collection Time: 13.12190
Timestep Consumption Time: 2.71381
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 15.83571

Cumulative Model Updates: 67,134
Cumulative Timesteps: 1,119,781,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1119781220...
Checkpoint 1119781220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342,969.82285
Policy Entropy: 1.00698
Value Function Loss: 1.13509

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.08044
Value Function Update Magnitude: 0.08968

Collected Steps per Second: 3,976.19583
Overall Steps per Second: 3,293.64536

Timestep Collection Time: 12.58087
Timestep Consumption Time: 2.60717
PPO Batch Consumption Time: 0.04920
Total Iteration Time: 15.18803

Cumulative Model Updates: 67,137
Cumulative Timesteps: 1,119,831,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627,115.83208
Policy Entropy: 1.01594
Value Function Loss: 1.15019

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.07395
Value Function Update Magnitude: 0.09655

Collected Steps per Second: 4,053.09847
Overall Steps per Second: 3,372.74697

Timestep Collection Time: 12.34710
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 14.83776

Cumulative Model Updates: 67,140
Cumulative Timesteps: 1,119,881,288

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1119881288...
Checkpoint 1119881288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,037,418.92225
Policy Entropy: 1.01392
Value Function Loss: 1.17076

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.07192
Value Function Update Magnitude: 0.11366

Collected Steps per Second: 4,100.06465
Overall Steps per Second: 3,388.57495

Timestep Collection Time: 12.20371
Timestep Consumption Time: 2.56238
PPO Batch Consumption Time: 0.05805
Total Iteration Time: 14.76609

Cumulative Model Updates: 67,143
Cumulative Timesteps: 1,119,931,324

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030,692.27441
Policy Entropy: 1.02360
Value Function Loss: 1.14887

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.07380
Value Function Update Magnitude: 0.12154

Collected Steps per Second: 3,852.06164
Overall Steps per Second: 3,240.56508

Timestep Collection Time: 12.98370
Timestep Consumption Time: 2.45003
PPO Batch Consumption Time: 0.05220
Total Iteration Time: 15.43373

Cumulative Model Updates: 67,146
Cumulative Timesteps: 1,119,981,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1119981338...
Checkpoint 1119981338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786,830.52429
Policy Entropy: 1.02661
Value Function Loss: 1.12628

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.08116
Value Function Update Magnitude: 0.11691

Collected Steps per Second: 4,104.90278
Overall Steps per Second: 3,349.46144

Timestep Collection Time: 12.19030
Timestep Consumption Time: 2.74941
PPO Batch Consumption Time: 0.05221
Total Iteration Time: 14.93972

Cumulative Model Updates: 67,149
Cumulative Timesteps: 1,120,031,378

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,890,918.15746
Policy Entropy: 1.02731
Value Function Loss: 1.08794

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.08541
Value Function Update Magnitude: 0.10445

Collected Steps per Second: 4,225.11520
Overall Steps per Second: 3,472.57485

Timestep Collection Time: 11.83589
Timestep Consumption Time: 2.56495
PPO Batch Consumption Time: 0.04696
Total Iteration Time: 14.40084

Cumulative Model Updates: 67,152
Cumulative Timesteps: 1,120,081,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1120081386...
Checkpoint 1120081386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644,572.70411
Policy Entropy: 1.03096
Value Function Loss: 1.10607

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.08632
Value Function Update Magnitude: 0.09154

Collected Steps per Second: 4,186.01965
Overall Steps per Second: 3,420.39340

Timestep Collection Time: 11.95408
Timestep Consumption Time: 2.67582
PPO Batch Consumption Time: 0.04676
Total Iteration Time: 14.62990

Cumulative Model Updates: 67,155
Cumulative Timesteps: 1,120,131,426

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265,791.50772
Policy Entropy: 1.02947
Value Function Loss: 1.16621

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.09107
Value Function Update Magnitude: 0.09455

Collected Steps per Second: 4,209.40216
Overall Steps per Second: 3,437.32077

Timestep Collection Time: 11.88340
Timestep Consumption Time: 2.66922
PPO Batch Consumption Time: 0.05044
Total Iteration Time: 14.55261

Cumulative Model Updates: 67,158
Cumulative Timesteps: 1,120,181,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1120181448...
Checkpoint 1120181448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,024,528.26094
Policy Entropy: 1.02737
Value Function Loss: 1.18955

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.08388
Value Function Update Magnitude: 0.09619

Collected Steps per Second: 4,157.69756
Overall Steps per Second: 3,413.84193

Timestep Collection Time: 12.03214
Timestep Consumption Time: 2.62173
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 14.65387

Cumulative Model Updates: 67,161
Cumulative Timesteps: 1,120,231,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,004,616.52162
Policy Entropy: 1.02379
Value Function Loss: 1.18128

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.15953
Policy Update Magnitude: 0.07553
Value Function Update Magnitude: 0.08901

Collected Steps per Second: 3,888.60359
Overall Steps per Second: 3,233.74126

Timestep Collection Time: 12.86580
Timestep Consumption Time: 2.60544
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 15.47124

Cumulative Model Updates: 67,164
Cumulative Timesteps: 1,120,281,504

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1120281504...
Checkpoint 1120281504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349,771.31277
Policy Entropy: 1.04106
Value Function Loss: 1.14885

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.08310

Collected Steps per Second: 4,019.73148
Overall Steps per Second: 3,292.76774

Timestep Collection Time: 12.44312
Timestep Consumption Time: 2.74714
PPO Batch Consumption Time: 0.04786
Total Iteration Time: 15.19026

Cumulative Model Updates: 67,167
Cumulative Timesteps: 1,120,331,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322,765.41740
Policy Entropy: 1.04302
Value Function Loss: 1.16792

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.06282
Value Function Update Magnitude: 0.09166

Collected Steps per Second: 3,806.34842
Overall Steps per Second: 3,213.09136

Timestep Collection Time: 13.14383
Timestep Consumption Time: 2.42684
PPO Batch Consumption Time: 0.04824
Total Iteration Time: 15.57067

Cumulative Model Updates: 67,170
Cumulative Timesteps: 1,120,381,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1120381552...
Checkpoint 1120381552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800,733.61324
Policy Entropy: 1.03331
Value Function Loss: 1.13783

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.16232
Policy Update Magnitude: 0.06182
Value Function Update Magnitude: 0.10153

Collected Steps per Second: 4,026.11343
Overall Steps per Second: 3,315.12883

Timestep Collection Time: 12.42141
Timestep Consumption Time: 2.66398
PPO Batch Consumption Time: 0.05278
Total Iteration Time: 15.08539

Cumulative Model Updates: 67,173
Cumulative Timesteps: 1,120,431,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,821,453.05211
Policy Entropy: 1.03342
Value Function Loss: 1.11878

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.18092
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.10899

Collected Steps per Second: 4,089.32681
Overall Steps per Second: 3,365.91816

Timestep Collection Time: 12.23282
Timestep Consumption Time: 2.62910
PPO Batch Consumption Time: 0.04806
Total Iteration Time: 14.86192

Cumulative Model Updates: 67,176
Cumulative Timesteps: 1,120,481,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1120481586...
Checkpoint 1120481586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715,447.63116
Policy Entropy: 1.05020
Value Function Loss: 1.10770

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.16111
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 4,011.01403
Overall Steps per Second: 3,362.50336

Timestep Collection Time: 12.47565
Timestep Consumption Time: 2.40612
PPO Batch Consumption Time: 0.05091
Total Iteration Time: 14.88177

Cumulative Model Updates: 67,179
Cumulative Timesteps: 1,120,531,626

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880,907.47610
Policy Entropy: 1.04094
Value Function Loss: 1.07757

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.15313
Policy Update Magnitude: 0.06246
Value Function Update Magnitude: 0.08873

Collected Steps per Second: 3,798.44295
Overall Steps per Second: 3,210.77808

Timestep Collection Time: 13.16329
Timestep Consumption Time: 2.40926
PPO Batch Consumption Time: 0.06043
Total Iteration Time: 15.57255

Cumulative Model Updates: 67,182
Cumulative Timesteps: 1,120,581,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1120581626...
Checkpoint 1120581626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836,451.78289
Policy Entropy: 1.01877
Value Function Loss: 1.06342

Mean KL Divergence: 0.03924
SB3 Clip Fraction: 0.21809
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.09157

Collected Steps per Second: 3,668.34208
Overall Steps per Second: 3,131.49436

Timestep Collection Time: 13.63886
Timestep Consumption Time: 2.33818
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 15.97704

Cumulative Model Updates: 67,185
Cumulative Timesteps: 1,120,631,658

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822,815.21745
Policy Entropy: 1.03894
Value Function Loss: 1.04983

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.09458

Collected Steps per Second: 3,891.60324
Overall Steps per Second: 3,278.95138

Timestep Collection Time: 12.85126
Timestep Consumption Time: 2.40118
PPO Batch Consumption Time: 0.05076
Total Iteration Time: 15.25244

Cumulative Model Updates: 67,188
Cumulative Timesteps: 1,120,681,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1120681670...
Checkpoint 1120681670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888,383.84381
Policy Entropy: 1.03522
Value Function Loss: 1.14830

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.06356
Value Function Update Magnitude: 0.08907

Collected Steps per Second: 4,058.69143
Overall Steps per Second: 3,394.84703

Timestep Collection Time: 12.32269
Timestep Consumption Time: 2.40964
PPO Batch Consumption Time: 0.05406
Total Iteration Time: 14.73233

Cumulative Model Updates: 67,191
Cumulative Timesteps: 1,120,731,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585,006.86745
Policy Entropy: 1.03746
Value Function Loss: 1.16825

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.06920
Value Function Update Magnitude: 0.08413

Collected Steps per Second: 4,155.06004
Overall Steps per Second: 3,408.76234

Timestep Collection Time: 12.03641
Timestep Consumption Time: 2.63519
PPO Batch Consumption Time: 0.04854
Total Iteration Time: 14.67160

Cumulative Model Updates: 67,194
Cumulative Timesteps: 1,120,781,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1120781696...
Checkpoint 1120781696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,768,217.20790
Policy Entropy: 1.04654
Value Function Loss: 1.20492

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.07001
Value Function Update Magnitude: 0.09078

Collected Steps per Second: 3,850.86742
Overall Steps per Second: 3,212.61199

Timestep Collection Time: 12.99447
Timestep Consumption Time: 2.58164
PPO Batch Consumption Time: 0.05179
Total Iteration Time: 15.57611

Cumulative Model Updates: 67,197
Cumulative Timesteps: 1,120,831,736

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307,240.34824
Policy Entropy: 1.04615
Value Function Loss: 1.17577

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.17134
Policy Update Magnitude: 0.06491
Value Function Update Magnitude: 0.10109

Collected Steps per Second: 3,730.79942
Overall Steps per Second: 3,132.35658

Timestep Collection Time: 13.41428
Timestep Consumption Time: 2.56283
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 15.97711

Cumulative Model Updates: 67,200
Cumulative Timesteps: 1,120,881,782

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1120881782...
Checkpoint 1120881782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678,422.98899
Policy Entropy: 1.03268
Value Function Loss: 1.15452

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.15352
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.12047

Collected Steps per Second: 3,736.35743
Overall Steps per Second: 3,098.42971

Timestep Collection Time: 13.38630
Timestep Consumption Time: 2.75607
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 16.14237

Cumulative Model Updates: 67,203
Cumulative Timesteps: 1,120,931,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388,085.33684
Policy Entropy: 1.02783
Value Function Loss: 1.13498

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.16092
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 3,660.13717
Overall Steps per Second: 3,034.04199

Timestep Collection Time: 13.67053
Timestep Consumption Time: 2.82101
PPO Batch Consumption Time: 0.06157
Total Iteration Time: 16.49153

Cumulative Model Updates: 67,206
Cumulative Timesteps: 1,120,981,834

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1120981834...
Checkpoint 1120981834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564,245.05591
Policy Entropy: 1.04310
Value Function Loss: 1.15437

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.11844

Collected Steps per Second: 4,064.75290
Overall Steps per Second: 3,341.47653

Timestep Collection Time: 12.30727
Timestep Consumption Time: 2.66396
PPO Batch Consumption Time: 0.05278
Total Iteration Time: 14.97123

Cumulative Model Updates: 67,209
Cumulative Timesteps: 1,121,031,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,602,462.73543
Policy Entropy: 1.04805
Value Function Loss: 1.22831

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.14661

Collected Steps per Second: 4,259.92878
Overall Steps per Second: 3,463.54662

Timestep Collection Time: 11.73963
Timestep Consumption Time: 2.69932
PPO Batch Consumption Time: 0.05260
Total Iteration Time: 14.43896

Cumulative Model Updates: 67,212
Cumulative Timesteps: 1,121,081,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1121081870...
Checkpoint 1121081870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356,193.33848
Policy Entropy: 1.03108
Value Function Loss: 1.22597

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.16378

Collected Steps per Second: 4,186.08942
Overall Steps per Second: 3,480.65860

Timestep Collection Time: 11.94814
Timestep Consumption Time: 2.42155
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 14.36969

Cumulative Model Updates: 67,215
Cumulative Timesteps: 1,121,131,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,834,847.15328
Policy Entropy: 1.02905
Value Function Loss: 1.23704

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.17537
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.15844

Collected Steps per Second: 4,112.85005
Overall Steps per Second: 3,403.27646

Timestep Collection Time: 12.16237
Timestep Consumption Time: 2.53582
PPO Batch Consumption Time: 0.04844
Total Iteration Time: 14.69819

Cumulative Model Updates: 67,218
Cumulative Timesteps: 1,121,181,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1121181908...
Checkpoint 1121181908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479,402.89295
Policy Entropy: 1.04372
Value Function Loss: 1.23164

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.12836

Collected Steps per Second: 4,078.18523
Overall Steps per Second: 3,392.86805

Timestep Collection Time: 12.26967
Timestep Consumption Time: 2.47832
PPO Batch Consumption Time: 0.05142
Total Iteration Time: 14.74799

Cumulative Model Updates: 67,221
Cumulative Timesteps: 1,121,231,946

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739,156.85129
Policy Entropy: 1.05337
Value Function Loss: 1.20589

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.17779
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.11624

Collected Steps per Second: 3,899.02951
Overall Steps per Second: 3,273.62924

Timestep Collection Time: 12.82678
Timestep Consumption Time: 2.45045
PPO Batch Consumption Time: 0.05053
Total Iteration Time: 15.27723

Cumulative Model Updates: 67,224
Cumulative Timesteps: 1,121,281,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1121281958...
Checkpoint 1121281958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698,674.31660
Policy Entropy: 1.02439
Value Function Loss: 1.15878

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.15263
Policy Update Magnitude: 0.06923
Value Function Update Magnitude: 0.11463

Collected Steps per Second: 3,861.13916
Overall Steps per Second: 3,182.77942

Timestep Collection Time: 12.94955
Timestep Consumption Time: 2.75999
PPO Batch Consumption Time: 0.06363
Total Iteration Time: 15.70954

Cumulative Model Updates: 67,227
Cumulative Timesteps: 1,121,331,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932,955.88778
Policy Entropy: 1.04816
Value Function Loss: 1.11642

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.15606
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.10752

Collected Steps per Second: 3,860.13842
Overall Steps per Second: 3,199.07481

Timestep Collection Time: 12.95705
Timestep Consumption Time: 2.67747
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 15.63452

Cumulative Model Updates: 67,230
Cumulative Timesteps: 1,121,381,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1121381974...
Checkpoint 1121381974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545,672.22814
Policy Entropy: 1.04978
Value Function Loss: 1.12654

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.15547
Policy Update Magnitude: 0.06242
Value Function Update Magnitude: 0.12136

Collected Steps per Second: 3,709.19994
Overall Steps per Second: 3,098.41081

Timestep Collection Time: 13.48754
Timestep Consumption Time: 2.65880
PPO Batch Consumption Time: 0.05093
Total Iteration Time: 16.14634

Cumulative Model Updates: 67,233
Cumulative Timesteps: 1,121,432,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212,300.11405
Policy Entropy: 1.04174
Value Function Loss: 1.08238

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.12205

Collected Steps per Second: 3,783.77039
Overall Steps per Second: 3,149.46828

Timestep Collection Time: 13.21433
Timestep Consumption Time: 2.66136
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 15.87570

Cumulative Model Updates: 67,236
Cumulative Timesteps: 1,121,482,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1121482002...
Checkpoint 1121482002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911,672.48206
Policy Entropy: 1.02879
Value Function Loss: 1.12758

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.17299
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.10880

Collected Steps per Second: 3,852.07938
Overall Steps per Second: 3,218.07688

Timestep Collection Time: 12.98104
Timestep Consumption Time: 2.55743
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 15.53847

Cumulative Model Updates: 67,239
Cumulative Timesteps: 1,121,532,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427,357.95657
Policy Entropy: 1.03971
Value Function Loss: 1.15436

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.10486

Collected Steps per Second: 3,719.68131
Overall Steps per Second: 3,125.85084

Timestep Collection Time: 13.45277
Timestep Consumption Time: 2.55568
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 16.00844

Cumulative Model Updates: 67,242
Cumulative Timesteps: 1,121,582,046

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1121582046...
Checkpoint 1121582046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899,416.12662
Policy Entropy: 1.04367
Value Function Loss: 1.15779

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.16875
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.12872

Collected Steps per Second: 3,921.20613
Overall Steps per Second: 3,258.91582

Timestep Collection Time: 12.75781
Timestep Consumption Time: 2.59269
PPO Batch Consumption Time: 0.05260
Total Iteration Time: 15.35050

Cumulative Model Updates: 67,245
Cumulative Timesteps: 1,121,632,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293,705.20873
Policy Entropy: 1.03609
Value Function Loss: 1.09616

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.06745
Value Function Update Magnitude: 0.13602

Collected Steps per Second: 3,785.60897
Overall Steps per Second: 3,163.89752

Timestep Collection Time: 13.21373
Timestep Consumption Time: 2.59652
PPO Batch Consumption Time: 0.06574
Total Iteration Time: 15.81025

Cumulative Model Updates: 67,248
Cumulative Timesteps: 1,121,682,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1121682094...
Checkpoint 1121682094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649,584.56843
Policy Entropy: 1.04232
Value Function Loss: 1.04152

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.06545
Value Function Update Magnitude: 0.13507

Collected Steps per Second: 3,961.39549
Overall Steps per Second: 3,309.52651

Timestep Collection Time: 12.62636
Timestep Consumption Time: 2.48698
PPO Batch Consumption Time: 0.05914
Total Iteration Time: 15.11334

Cumulative Model Updates: 67,251
Cumulative Timesteps: 1,121,732,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018,787.43247
Policy Entropy: 1.05211
Value Function Loss: 0.98611

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.12244

Collected Steps per Second: 3,804.25912
Overall Steps per Second: 3,103.58324

Timestep Collection Time: 13.14684
Timestep Consumption Time: 2.96808
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 16.11492

Cumulative Model Updates: 67,254
Cumulative Timesteps: 1,121,782,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1121782126...
Checkpoint 1121782126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695,271.94072
Policy Entropy: 1.05712
Value Function Loss: 1.05927

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.17425
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.12160

Collected Steps per Second: 3,734.87184
Overall Steps per Second: 3,168.11057

Timestep Collection Time: 13.39591
Timestep Consumption Time: 2.39647
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 15.79238

Cumulative Model Updates: 67,257
Cumulative Timesteps: 1,121,832,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,233,685.36953
Policy Entropy: 1.02006
Value Function Loss: 1.11848

Mean KL Divergence: 0.03926
SB3 Clip Fraction: 0.21436
Policy Update Magnitude: 0.06076
Value Function Update Magnitude: 0.12229

Collected Steps per Second: 3,760.61520
Overall Steps per Second: 3,195.48174

Timestep Collection Time: 13.29889
Timestep Consumption Time: 2.35196
PPO Batch Consumption Time: 0.05134
Total Iteration Time: 15.65085

Cumulative Model Updates: 67,260
Cumulative Timesteps: 1,121,882,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1121882170...
Checkpoint 1121882170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450,161.23938
Policy Entropy: 1.03551
Value Function Loss: 1.21169

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.10459

Collected Steps per Second: 3,964.27984
Overall Steps per Second: 3,303.87155

Timestep Collection Time: 12.62171
Timestep Consumption Time: 2.52294
PPO Batch Consumption Time: 0.06315
Total Iteration Time: 15.14466

Cumulative Model Updates: 67,263
Cumulative Timesteps: 1,121,932,206

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,611,531.52175
Policy Entropy: 1.04568
Value Function Loss: 1.21040

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.09842

Collected Steps per Second: 3,803.07926
Overall Steps per Second: 3,179.05019

Timestep Collection Time: 13.15250
Timestep Consumption Time: 2.58176
PPO Batch Consumption Time: 0.04973
Total Iteration Time: 15.73426

Cumulative Model Updates: 67,266
Cumulative Timesteps: 1,121,982,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1121982226...
Checkpoint 1121982226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617,820.13538
Policy Entropy: 1.03391
Value Function Loss: 1.15796

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.11095

Collected Steps per Second: 3,846.36238
Overall Steps per Second: 3,211.41192

Timestep Collection Time: 13.01229
Timestep Consumption Time: 2.57275
PPO Batch Consumption Time: 0.05856
Total Iteration Time: 15.58505

Cumulative Model Updates: 67,269
Cumulative Timesteps: 1,122,032,276

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553,079.82488
Policy Entropy: 1.02732
Value Function Loss: 1.13132

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.18091
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.11606

Collected Steps per Second: 4,103.02038
Overall Steps per Second: 3,395.45319

Timestep Collection Time: 12.19589
Timestep Consumption Time: 2.54146
PPO Batch Consumption Time: 0.05098
Total Iteration Time: 14.73736

Cumulative Model Updates: 67,272
Cumulative Timesteps: 1,122,082,316

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1122082316...
Checkpoint 1122082316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819,888.69957
Policy Entropy: 1.03606
Value Function Loss: 1.11356

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.11573

Collected Steps per Second: 3,870.92037
Overall Steps per Second: 3,187.90556

Timestep Collection Time: 12.92302
Timestep Consumption Time: 2.76878
PPO Batch Consumption Time: 0.05079
Total Iteration Time: 15.69181

Cumulative Model Updates: 67,275
Cumulative Timesteps: 1,122,132,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,609,501.03981
Policy Entropy: 1.04606
Value Function Loss: 1.15215

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.17300
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.10751

Collected Steps per Second: 3,784.18839
Overall Steps per Second: 3,149.68214

Timestep Collection Time: 13.22186
Timestep Consumption Time: 2.66355
PPO Batch Consumption Time: 0.05782
Total Iteration Time: 15.88541

Cumulative Model Updates: 67,278
Cumulative Timesteps: 1,122,182,374

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1122182374...
Checkpoint 1122182374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762,893.39813
Policy Entropy: 1.02865
Value Function Loss: 1.20277

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.10273

Collected Steps per Second: 3,639.70243
Overall Steps per Second: 3,063.05859

Timestep Collection Time: 13.74618
Timestep Consumption Time: 2.58782
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 16.33400

Cumulative Model Updates: 67,281
Cumulative Timesteps: 1,122,232,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,494,448.85497
Policy Entropy: 1.02609
Value Function Loss: 1.26824

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.15950
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.10325

Collected Steps per Second: 3,788.83112
Overall Steps per Second: 3,184.26963

Timestep Collection Time: 13.19932
Timestep Consumption Time: 2.50601
PPO Batch Consumption Time: 0.05171
Total Iteration Time: 15.70533

Cumulative Model Updates: 67,284
Cumulative Timesteps: 1,122,282,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1122282416...
Checkpoint 1122282416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,191,871.76619
Policy Entropy: 1.03778
Value Function Loss: 1.23551

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.09930

Collected Steps per Second: 4,091.41154
Overall Steps per Second: 3,392.23829

Timestep Collection Time: 12.22805
Timestep Consumption Time: 2.52032
PPO Batch Consumption Time: 0.04553
Total Iteration Time: 14.74837

Cumulative Model Updates: 67,287
Cumulative Timesteps: 1,122,332,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,164,967.38320
Policy Entropy: 1.05396
Value Function Loss: 1.22318

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15881
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.10284

Collected Steps per Second: 4,192.67243
Overall Steps per Second: 3,440.32384

Timestep Collection Time: 11.93702
Timestep Consumption Time: 2.61045
PPO Batch Consumption Time: 0.04698
Total Iteration Time: 14.54747

Cumulative Model Updates: 67,290
Cumulative Timesteps: 1,122,382,494

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1122382494...
Checkpoint 1122382494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792,592.04185
Policy Entropy: 1.03447
Value Function Loss: 1.15544

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.10385

Collected Steps per Second: 5,266.69813
Overall Steps per Second: 4,893.09852

Timestep Collection Time: 9.49551
Timestep Consumption Time: 0.72500
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 10.22052

Cumulative Model Updates: 67,293
Cumulative Timesteps: 1,122,432,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276,744.48098
Policy Entropy: 1.02191
Value Function Loss: 1.22018

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.17599
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.09641

Collected Steps per Second: 10,993.56618
Overall Steps per Second: 9,605.89725

Timestep Collection Time: 4.55030
Timestep Consumption Time: 0.65734
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.20763

Cumulative Model Updates: 67,296
Cumulative Timesteps: 1,122,482,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1122482528...
Checkpoint 1122482528 saved!
