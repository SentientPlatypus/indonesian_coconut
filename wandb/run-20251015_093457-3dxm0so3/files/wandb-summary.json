{"PPO Batch Consumption Time":0.04183554649353027,"_step":10559,"Value Function Update Magnitude":0.06432687491178513,"y_vel":351.2738988390083,"Cumulative Timesteps":252729698,"Policy Entropy":1.2735059261322021,"Collected Steps per Second":7514.067470836671,"Policy Reward":87.16386663582685,"z_vel":8.878204799686781,"SB3 Clip Fraction":0.05831999828418096,"Total Iteration Time":7.586698300001444,"Timestep Collection Time":6.657113499997649,"_timestamp":1.7605355679277012e+09,"Timestep Consumption Time":0.929584800003795,"_runtime":29638,"Overall Steps per Second":6593.381998594893,"Timesteps Collected":50022,"x_vel":2.5762951523551503,"Cumulative Model Updates":15143,"Mean KL Divergence":0.005294840627660354,"_wandb":{"runtime":29638},"Policy Update Magnitude":0.07757531106472015,"Value Function Loss":0.1800288955370585}