{"_timestamp":1.7604805739083436e+09,"Cumulative Timesteps":16905922,"Total Iteration Time":5.812002800000016,"Policy Entropy":1.2334909041722615,"Timestep Collection Time":4.979581300000007,"y_vel":286.025250693096,"Value Function Update Magnitude":0.09906322509050369,"_runtime":3562,"SB3 Clip Fraction":0.19168666005134583,"Timestep Consumption Time":0.8324215000000095,"Cumulative Model Updates":1007,"x_vel":41.9391064504858,"z_vel":10.383345312880772,"Overall Steps per Second":8606.327581259917,"Collected Steps per Second":10045.02125510029,"Policy Update Magnitude":0.1294570416212082,"Policy Reward":168.52912716085865,"_wandb":{"runtime":3562},"Mean KL Divergence":0.021427171304821968,"_step":907,"Value Function Loss":15.883600870768229,"PPO Batch Consumption Time":0.03887502352396647,"Timesteps Collected":50020}