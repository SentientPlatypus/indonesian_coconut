{"_runtime":79991,"Collected Steps per Second":8683.499244347757,"PPO Batch Consumption Time":0.03989497820536295,"Cumulative Timesteps":544575828,"Cumulative Model Updates":32642,"Overall Steps per Second":7432.952186165718,"Timestep Consumption Time":0.969336199999816,"SB3 Clip Fraction":0.12661999464035034,"Value Function Update Magnitude":0.07479080557823181,"Timestep Collection Time":5.761502199999086,"Timesteps Collected":50030,"_timestamp":1.7607505481477306e+09,"Total Iteration Time":6.730838399998902,"Value Function Loss":60.62046432495117,"Policy Entropy":1.097459038098653,"x_vel":27.140222529828954,"z_vel":7.093228344767024,"_step":22729,"Policy Update Magnitude":0.053442686796188354,"y_vel":348.59543232847136,"Mean KL Divergence":0.019704703862468403,"Policy Reward":429278.9772343241,"_wandb":{"runtime":79991}}