{"Policy Reward":1.0348674214615467e+06,"Timesteps Collected":50020,"Value Function Update Magnitude":0.1334991604089737,"x_vel":7.409483280656982,"_step":60184,"Collected Steps per Second":7489.777434570349,"Timestep Consumption Time":0.8280508000000282,"_wandb":{"runtime":219528},"Cumulative Timesteps":1472338014,"Cumulative Model Updates":88272,"Value Function Loss":0.2969803214073181,"z_vel":4.846114864343022,"y_vel":42.29330387646999,"Total Iteration Time":7.506486900000027,"_runtime":219528,"Overall Steps per Second":6663.56987847402,"PPO Batch Consumption Time":0.040631771087646484,"Policy Update Magnitude":0.052673060446977615,"SB3 Clip Fraction":0.20397999385992685,"Mean KL Divergence":0.027647284790873528,"_timestamp":1.7610997234638486e+09,"Timestep Collection Time":6.678436099999999,"Policy Entropy":0.9228387475013733}