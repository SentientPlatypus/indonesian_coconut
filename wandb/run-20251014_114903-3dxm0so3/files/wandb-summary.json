{"Value Function Loss":0.05123701070745786,"Cumulative Model Updates":891,"_step":595,"y_vel":358.75808181927727,"Policy Entropy":1.3641361395517986,"Mean KL Divergence":0.005972114857286215,"Timesteps Collected":50018,"Cumulative Timesteps":14905254,"Overall Steps per Second":6713.161305879415,"Timestep Consumption Time":1.6566523999999845,"Value Function Update Magnitude":0.12512153387069702,"_wandb":{"runtime":2074},"_timestamp":1.7604590171089864e+09,"Policy Reward":0.059910997716953386,"z_vel":12.111549787733967,"Timestep Collection Time":5.794084699999985,"x_vel":-41.00357053812402,"Total Iteration Time":7.450737099999969,"SB3 Clip Fraction":0.06277333324154218,"Policy Update Magnitude":0.10253117233514786,"Collected Steps per Second":8632.597310840163,"PPO Batch Consumption Time":0.1744075616200765,"_runtime":2074}