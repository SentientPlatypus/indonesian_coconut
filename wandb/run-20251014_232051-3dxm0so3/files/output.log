Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.57899
Policy Entropy: 1.18692
Value Function Loss: 9.19462

Mean KL Divergence: -0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.01967
Value Function Update Magnitude: 0.02309

Collected Steps per Second: 8,585.26245
Overall Steps per Second: 6,772.28606

Timestep Collection Time: 5.82603
Timestep Consumption Time: 1.55966
PPO Batch Consumption Time: 0.51679
Total Iteration Time: 7.38569

Cumulative Model Updates: 8,352
Cumulative Timesteps: 139,394,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.58191
Policy Entropy: 1.21639
Value Function Loss: 6.81587

Mean KL Divergence: 0.03198
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.06017

Collected Steps per Second: 8,863.80576
Overall Steps per Second: 7,721.75786

Timestep Collection Time: 5.64317
Timestep Consumption Time: 0.83463
PPO Batch Consumption Time: 0.04144
Total Iteration Time: 6.47780

Cumulative Model Updates: 8,354
Cumulative Timesteps: 139,444,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 139444674...
Checkpoint 139444674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.98967
Policy Entropy: 1.24790
Value Function Loss: 5.12901

Mean KL Divergence: 0.10597
SB3 Clip Fraction: 0.21660
Policy Update Magnitude: 0.06687
Value Function Update Magnitude: 0.07836

Collected Steps per Second: 10,285.30238
Overall Steps per Second: 8,792.88379

Timestep Collection Time: 4.86247
Timestep Consumption Time: 0.82531
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 5.68778

Cumulative Model Updates: 8,356
Cumulative Timesteps: 139,494,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.69292
Policy Entropy: 1.28267
Value Function Loss: 4.73381

Mean KL Divergence: 0.17348
SB3 Clip Fraction: 0.22377
Policy Update Magnitude: 0.11650
Value Function Update Magnitude: 0.09684

Collected Steps per Second: 10,689.03027
Overall Steps per Second: 9,113.25235

Timestep Collection Time: 4.67994
Timestep Consumption Time: 0.80921
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.48915

Cumulative Model Updates: 8,359
Cumulative Timesteps: 139,544,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 139544710...
Checkpoint 139544710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.87401
Policy Entropy: 1.31772
Value Function Loss: 2.94841

Mean KL Divergence: 0.21312
SB3 Clip Fraction: 0.21451
Policy Update Magnitude: 0.11808
Value Function Update Magnitude: 0.16592

Collected Steps per Second: 10,383.70792
Overall Steps per Second: 8,995.48801

Timestep Collection Time: 4.81735
Timestep Consumption Time: 0.74343
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 5.56079

Cumulative Model Updates: 8,362
Cumulative Timesteps: 139,594,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.80877
Policy Entropy: 1.34480
Value Function Loss: 1.91459

Mean KL Divergence: 0.14409
SB3 Clip Fraction: 0.16105
Policy Update Magnitude: 0.11684
Value Function Update Magnitude: 0.18743

Collected Steps per Second: 10,772.92274
Overall Steps per Second: 9,117.91999

Timestep Collection Time: 4.64275
Timestep Consumption Time: 0.84271
PPO Batch Consumption Time: 0.04156
Total Iteration Time: 5.48546

Cumulative Model Updates: 8,365
Cumulative Timesteps: 139,644,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 139644748...
Checkpoint 139644748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.62057
Policy Entropy: 1.36790
Value Function Loss: 1.34947

Mean KL Divergence: 0.07353
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.12647
Value Function Update Magnitude: 0.19179

Collected Steps per Second: 10,104.97783
Overall Steps per Second: 8,647.86732

Timestep Collection Time: 4.94825
Timestep Consumption Time: 0.83375
PPO Batch Consumption Time: 0.04471
Total Iteration Time: 5.78200

Cumulative Model Updates: 8,368
Cumulative Timesteps: 139,694,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.57415
Policy Entropy: 1.38142
Value Function Loss: 1.02322

Mean KL Divergence: 0.03801
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.13127
Value Function Update Magnitude: 0.18398

Collected Steps per Second: 11,285.37762
Overall Steps per Second: 9,578.97826

Timestep Collection Time: 4.43211
Timestep Consumption Time: 0.78954
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.22164

Cumulative Model Updates: 8,371
Cumulative Timesteps: 139,744,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 139744768...
Checkpoint 139744768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.70305
Policy Entropy: 1.38510
Value Function Loss: 0.78769

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.05202
Policy Update Magnitude: 0.12233
Value Function Update Magnitude: 0.17780

Collected Steps per Second: 10,509.11430
Overall Steps per Second: 8,930.56901

Timestep Collection Time: 4.75816
Timestep Consumption Time: 0.84104
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 5.59920

Cumulative Model Updates: 8,374
Cumulative Timesteps: 139,794,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.70648
Policy Entropy: 1.38789
Value Function Loss: 0.62320

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.03455
Policy Update Magnitude: 0.10509
Value Function Update Magnitude: 0.17438

Collected Steps per Second: 10,890.10616
Overall Steps per Second: 9,418.06631

Timestep Collection Time: 4.59316
Timestep Consumption Time: 0.71791
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.31107

Cumulative Model Updates: 8,377
Cumulative Timesteps: 139,844,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 139844792...
Checkpoint 139844792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.38936
Policy Entropy: 1.38958
Value Function Loss: 0.51659

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.09097
Value Function Update Magnitude: 0.15885

Collected Steps per Second: 10,849.15924
Overall Steps per Second: 9,179.58821

Timestep Collection Time: 4.60884
Timestep Consumption Time: 0.83825
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 5.44709

Cumulative Model Updates: 8,380
Cumulative Timesteps: 139,894,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.09008
Policy Entropy: 1.39158
Value Function Loss: 0.45854

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02072
Policy Update Magnitude: 0.07763
Value Function Update Magnitude: 0.14482

Collected Steps per Second: 10,714.60769
Overall Steps per Second: 9,117.98051

Timestep Collection Time: 4.66765
Timestep Consumption Time: 0.81734
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.48499

Cumulative Model Updates: 8,383
Cumulative Timesteps: 139,944,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 139944806...
Checkpoint 139944806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.09192
Policy Entropy: 1.39284
Value Function Loss: 0.45100

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.06736
Value Function Update Magnitude: 0.16380

Collected Steps per Second: 10,527.55986
Overall Steps per Second: 8,960.21037

Timestep Collection Time: 4.75096
Timestep Consumption Time: 0.83105
PPO Batch Consumption Time: 0.04329
Total Iteration Time: 5.58201

Cumulative Model Updates: 8,386
Cumulative Timesteps: 139,994,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.16044
Policy Entropy: 1.39227
Value Function Loss: 0.40546

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.01821
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.13831

Collected Steps per Second: 10,836.02228
Overall Steps per Second: 9,267.83561

Timestep Collection Time: 4.61553
Timestep Consumption Time: 0.78098
PPO Batch Consumption Time: 0.03887
Total Iteration Time: 5.39651

Cumulative Model Updates: 8,389
Cumulative Timesteps: 140,044,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 140044836...
Checkpoint 140044836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.29552
Policy Entropy: 1.38605
Value Function Loss: 0.40487

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.15570

Collected Steps per Second: 10,675.06294
Overall Steps per Second: 9,259.72949

Timestep Collection Time: 4.68512
Timestep Consumption Time: 0.71611
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.40124

Cumulative Model Updates: 8,392
Cumulative Timesteps: 140,094,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.53514
Policy Entropy: 1.38998
Value Function Loss: 0.38893

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01489
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.13208

Collected Steps per Second: 10,912.44610
Overall Steps per Second: 9,277.67252

Timestep Collection Time: 4.58449
Timestep Consumption Time: 0.80781
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.39230

Cumulative Model Updates: 8,395
Cumulative Timesteps: 140,144,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 140144878...
Checkpoint 140144878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.65011
Policy Entropy: 1.39127
Value Function Loss: 0.36455

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01494
Policy Update Magnitude: 0.04208
Value Function Update Magnitude: 0.11482

Collected Steps per Second: 10,957.72689
Overall Steps per Second: 9,262.65993

Timestep Collection Time: 4.56336
Timestep Consumption Time: 0.83509
PPO Batch Consumption Time: 0.04027
Total Iteration Time: 5.39845

Cumulative Model Updates: 8,398
Cumulative Timesteps: 140,194,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.47073
Policy Entropy: 1.39426
Value Function Loss: 0.35552

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01469
Policy Update Magnitude: 0.04118
Value Function Update Magnitude: 0.11475

Collected Steps per Second: 10,159.17365
Overall Steps per Second: 8,666.66918

Timestep Collection Time: 4.92481
Timestep Consumption Time: 0.84811
PPO Batch Consumption Time: 0.04491
Total Iteration Time: 5.77292

Cumulative Model Updates: 8,401
Cumulative Timesteps: 140,244,914

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 140244914...
Checkpoint 140244914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.37606
Policy Entropy: 1.39168
Value Function Loss: 0.41099

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01459
Policy Update Magnitude: 0.04195
Value Function Update Magnitude: 0.13399

Collected Steps per Second: 10,891.49491
Overall Steps per Second: 9,291.95003

Timestep Collection Time: 4.59111
Timestep Consumption Time: 0.79033
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.38143

Cumulative Model Updates: 8,404
Cumulative Timesteps: 140,294,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.04164
Policy Entropy: 1.39265
Value Function Loss: 0.42871

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01478
Policy Update Magnitude: 0.03820
Value Function Update Magnitude: 0.13258

Collected Steps per Second: 10,834.37070
Overall Steps per Second: 9,370.14080

Timestep Collection Time: 4.61531
Timestep Consumption Time: 0.72121
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.33653

Cumulative Model Updates: 8,407
Cumulative Timesteps: 140,344,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 140344922...
Checkpoint 140344922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.27079
Policy Entropy: 1.39339
Value Function Loss: 0.41162

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.01488
Policy Update Magnitude: 0.03648
Value Function Update Magnitude: 0.12525

Collected Steps per Second: 9,197.48935
Overall Steps per Second: 7,903.03928

Timestep Collection Time: 5.43779
Timestep Consumption Time: 0.89066
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.32845

Cumulative Model Updates: 8,410
Cumulative Timesteps: 140,394,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.97709
Policy Entropy: 1.39376
Value Function Loss: 0.37120

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.01339
Policy Update Magnitude: 0.03252
Value Function Update Magnitude: 0.12486

Collected Steps per Second: 8,202.13099
Overall Steps per Second: 7,193.49795

Timestep Collection Time: 6.09866
Timestep Consumption Time: 0.85512
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 6.95378

Cumulative Model Updates: 8,413
Cumulative Timesteps: 140,444,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 140444958...
Checkpoint 140444958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.47086
Policy Entropy: 1.39258
Value Function Loss: 0.36675

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.01576
Policy Update Magnitude: 0.04044
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 8,199.20689
Overall Steps per Second: 7,095.44939

Timestep Collection Time: 6.09913
Timestep Consumption Time: 0.94877
PPO Batch Consumption Time: 0.04585
Total Iteration Time: 7.04790

Cumulative Model Updates: 8,416
Cumulative Timesteps: 140,494,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.04013
Policy Entropy: 1.39402
Value Function Loss: 0.35989

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01373
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.13309

Collected Steps per Second: 9,392.39679
Overall Steps per Second: 8,076.25311

Timestep Collection Time: 5.32388
Timestep Consumption Time: 0.86760
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 6.19148

Cumulative Model Updates: 8,419
Cumulative Timesteps: 140,544,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 140544970...
Checkpoint 140544970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.25579
Policy Entropy: 1.39450
Value Function Loss: 0.38668

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.01750
Policy Update Magnitude: 0.04253
Value Function Update Magnitude: 0.11453

Collected Steps per Second: 9,570.17625
Overall Steps per Second: 8,122.14530

Timestep Collection Time: 5.22791
Timestep Consumption Time: 0.93204
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 6.15995

Cumulative Model Updates: 8,422
Cumulative Timesteps: 140,595,002

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.75161
Policy Entropy: 1.39526
Value Function Loss: 0.35036

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.01665
Policy Update Magnitude: 0.04120
Value Function Update Magnitude: 0.10402

Collected Steps per Second: 5,878.07291
Overall Steps per Second: 5,356.14681

Timestep Collection Time: 8.50653
Timestep Consumption Time: 0.82891
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 9.33544

Cumulative Model Updates: 8,425
Cumulative Timesteps: 140,645,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 140645004...
Checkpoint 140645004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.55006
Policy Entropy: 1.39833
Value Function Loss: 0.35365

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.01879
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.10266

Collected Steps per Second: 10,322.55370
Overall Steps per Second: 8,863.16192

Timestep Collection Time: 4.84667
Timestep Consumption Time: 0.79804
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 5.64471

Cumulative Model Updates: 8,428
Cumulative Timesteps: 140,695,034

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.69299
Policy Entropy: 1.39936
Value Function Loss: 0.31637

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.01993
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.10148

Collected Steps per Second: 10,929.61952
Overall Steps per Second: 9,201.47848

Timestep Collection Time: 4.57747
Timestep Consumption Time: 0.85970
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 5.43717

Cumulative Model Updates: 8,431
Cumulative Timesteps: 140,745,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 140745064...
Checkpoint 140745064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.56041
Policy Entropy: 1.39863
Value Function Loss: 0.36702

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.01862
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.09629

Collected Steps per Second: 10,872.99262
Overall Steps per Second: 9,201.70297

Timestep Collection Time: 4.60039
Timestep Consumption Time: 0.83556
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 5.43595

Cumulative Model Updates: 8,434
Cumulative Timesteps: 140,795,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.59781
Policy Entropy: 1.39805
Value Function Loss: 0.37311

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.11231

Collected Steps per Second: 10,980.47027
Overall Steps per Second: 9,287.64498

Timestep Collection Time: 4.55427
Timestep Consumption Time: 0.83009
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.38436

Cumulative Model Updates: 8,437
Cumulative Timesteps: 140,845,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 140845092...
Checkpoint 140845092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.50682
Policy Entropy: 1.40009
Value Function Loss: 0.38395

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01646
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.10515

Collected Steps per Second: 10,642.38576
Overall Steps per Second: 8,954.38701

Timestep Collection Time: 4.70045
Timestep Consumption Time: 0.88609
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.58654

Cumulative Model Updates: 8,440
Cumulative Timesteps: 140,895,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.25764
Policy Entropy: 1.40250
Value Function Loss: 0.37308

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.00945
Policy Update Magnitude: 0.03919
Value Function Update Magnitude: 0.13672

Collected Steps per Second: 10,598.71687
Overall Steps per Second: 9,170.51592

Timestep Collection Time: 4.71850
Timestep Consumption Time: 0.73485
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.45335

Cumulative Model Updates: 8,443
Cumulative Timesteps: 140,945,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 140945126...
Checkpoint 140945126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.37590
Policy Entropy: 1.40352
Value Function Loss: 0.31141

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01101
Policy Update Magnitude: 0.03815
Value Function Update Magnitude: 0.18176

Collected Steps per Second: 10,508.87135
Overall Steps per Second: 8,897.96617

Timestep Collection Time: 4.76074
Timestep Consumption Time: 0.86189
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 5.62263

Cumulative Model Updates: 8,446
Cumulative Timesteps: 140,995,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.12368
Policy Entropy: 1.40325
Value Function Loss: 0.31384

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00823
Policy Update Magnitude: 0.03588
Value Function Update Magnitude: 0.21835

Collected Steps per Second: 10,669.09595
Overall Steps per Second: 8,993.96226

Timestep Collection Time: 4.68681
Timestep Consumption Time: 0.87292
PPO Batch Consumption Time: 0.04075
Total Iteration Time: 5.55973

Cumulative Model Updates: 8,449
Cumulative Timesteps: 141,045,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 141045160...
Checkpoint 141045160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.09674
Policy Entropy: 1.40120
Value Function Loss: 0.35558

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00751
Policy Update Magnitude: 0.03545
Value Function Update Magnitude: 0.20524

Collected Steps per Second: 10,925.56962
Overall Steps per Second: 9,345.46743

Timestep Collection Time: 4.57697
Timestep Consumption Time: 0.77386
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.35083

Cumulative Model Updates: 8,452
Cumulative Timesteps: 141,095,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.44405
Policy Entropy: 1.39936
Value Function Loss: 0.43507

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01141
Policy Update Magnitude: 0.03737
Value Function Update Magnitude: 0.16581

Collected Steps per Second: 10,896.80866
Overall Steps per Second: 9,246.81460

Timestep Collection Time: 4.59033
Timestep Consumption Time: 0.81910
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.40943

Cumulative Model Updates: 8,455
Cumulative Timesteps: 141,145,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 141145186...
Checkpoint 141145186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.42672
Policy Entropy: 1.39901
Value Function Loss: 0.43154

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01397
Policy Update Magnitude: 0.03493
Value Function Update Magnitude: 0.16875

Collected Steps per Second: 10,892.57002
Overall Steps per Second: 9,330.84923

Timestep Collection Time: 4.59304
Timestep Consumption Time: 0.76875
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 5.36178

Cumulative Model Updates: 8,458
Cumulative Timesteps: 141,195,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.33390
Policy Entropy: 1.40095
Value Function Loss: 0.39378

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01199
Policy Update Magnitude: 0.03657
Value Function Update Magnitude: 0.15156

Collected Steps per Second: 10,347.23607
Overall Steps per Second: 8,759.52158

Timestep Collection Time: 4.83221
Timestep Consumption Time: 0.87587
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 5.70807

Cumulative Model Updates: 8,461
Cumulative Timesteps: 141,245,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 141245216...
Checkpoint 141245216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.12139
Policy Entropy: 1.39992
Value Function Loss: 0.39468

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01590
Policy Update Magnitude: 0.03600
Value Function Update Magnitude: 0.13443

Collected Steps per Second: 10,831.02930
Overall Steps per Second: 9,236.03813

Timestep Collection Time: 4.61932
Timestep Consumption Time: 0.79772
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 5.41704

Cumulative Model Updates: 8,464
Cumulative Timesteps: 141,295,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.08452
Policy Entropy: 1.39641
Value Function Loss: 0.40638

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.03719
Value Function Update Magnitude: 0.15054

Collected Steps per Second: 10,938.84054
Overall Steps per Second: 9,252.77096

Timestep Collection Time: 4.57325
Timestep Consumption Time: 0.83335
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.40660

Cumulative Model Updates: 8,467
Cumulative Timesteps: 141,345,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 141345274...
Checkpoint 141345274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.93600
Policy Entropy: 1.39574
Value Function Loss: 0.45838

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01622
Policy Update Magnitude: 0.03133
Value Function Update Magnitude: 0.15458

Collected Steps per Second: 10,756.95634
Overall Steps per Second: 9,090.61317

Timestep Collection Time: 4.64983
Timestep Consumption Time: 0.85233
PPO Batch Consumption Time: 0.04050
Total Iteration Time: 5.50216

Cumulative Model Updates: 8,470
Cumulative Timesteps: 141,395,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.35085
Policy Entropy: 1.39308
Value Function Loss: 0.45375

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01768
Policy Update Magnitude: 0.03338
Value Function Update Magnitude: 0.12626

Collected Steps per Second: 11,070.79431
Overall Steps per Second: 9,470.82562

Timestep Collection Time: 4.51910
Timestep Consumption Time: 0.76344
PPO Batch Consumption Time: 0.04371
Total Iteration Time: 5.28254

Cumulative Model Updates: 8,473
Cumulative Timesteps: 141,445,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 141445322...
Checkpoint 141445322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.62340
Policy Entropy: 1.39452
Value Function Loss: 0.41991

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01775
Policy Update Magnitude: 0.03206
Value Function Update Magnitude: 0.13614

Collected Steps per Second: 10,974.46967
Overall Steps per Second: 9,344.61241

Timestep Collection Time: 4.55730
Timestep Consumption Time: 0.79487
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.35217

Cumulative Model Updates: 8,476
Cumulative Timesteps: 141,495,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.68600
Policy Entropy: 1.39736
Value Function Loss: 0.37999

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01195
Policy Update Magnitude: 0.03340
Value Function Update Magnitude: 0.11692

Collected Steps per Second: 10,487.16283
Overall Steps per Second: 8,985.02183

Timestep Collection Time: 4.76907
Timestep Consumption Time: 0.79731
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 5.56637

Cumulative Model Updates: 8,479
Cumulative Timesteps: 141,545,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 141545350...
Checkpoint 141545350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.13801
Policy Entropy: 1.39639
Value Function Loss: 0.48353

Mean KL Divergence: 0.00159
SB3 Clip Fraction: 0.01465
Policy Update Magnitude: 0.03573
Value Function Update Magnitude: 0.10633

Collected Steps per Second: 11,030.27157
Overall Steps per Second: 9,399.32816

Timestep Collection Time: 4.53334
Timestep Consumption Time: 0.78661
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 5.31995

Cumulative Model Updates: 8,482
Cumulative Timesteps: 141,595,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.35487
Policy Entropy: 1.39353
Value Function Loss: 0.49956

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01760
Policy Update Magnitude: 0.03348
Value Function Update Magnitude: 0.10193

Collected Steps per Second: 11,404.78468
Overall Steps per Second: 9,586.07035

Timestep Collection Time: 4.38640
Timestep Consumption Time: 0.83221
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 5.21861

Cumulative Model Updates: 8,485
Cumulative Timesteps: 141,645,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 141645380...
Checkpoint 141645380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.20811
Policy Entropy: 1.39268
Value Function Loss: 0.52650

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01544
Policy Update Magnitude: 0.03531
Value Function Update Magnitude: 0.10310

Collected Steps per Second: 11,127.39478
Overall Steps per Second: 9,556.61799

Timestep Collection Time: 4.49359
Timestep Consumption Time: 0.73859
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.23219

Cumulative Model Updates: 8,488
Cumulative Timesteps: 141,695,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.48080
Policy Entropy: 1.39335
Value Function Loss: 0.43264

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01569
Policy Update Magnitude: 0.04052
Value Function Update Magnitude: 0.10445

Collected Steps per Second: 10,817.18863
Overall Steps per Second: 9,178.96153

Timestep Collection Time: 4.62227
Timestep Consumption Time: 0.82497
PPO Batch Consumption Time: 0.03965
Total Iteration Time: 5.44724

Cumulative Model Updates: 8,491
Cumulative Timesteps: 141,745,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 141745382...
Checkpoint 141745382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.37169
Policy Entropy: 1.39751
Value Function Loss: 0.39280

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01541
Policy Update Magnitude: 0.03712
Value Function Update Magnitude: 0.10479

Collected Steps per Second: 10,487.79023
Overall Steps per Second: 8,937.35094

Timestep Collection Time: 4.76936
Timestep Consumption Time: 0.82738
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 5.59674

Cumulative Model Updates: 8,494
Cumulative Timesteps: 141,795,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.49216
Policy Entropy: 1.39636
Value Function Loss: 0.38841

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01419
Policy Update Magnitude: 0.03454
Value Function Update Magnitude: 0.09863

Collected Steps per Second: 10,658.47940
Overall Steps per Second: 9,268.34384

Timestep Collection Time: 4.69373
Timestep Consumption Time: 0.70400
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.39773

Cumulative Model Updates: 8,497
Cumulative Timesteps: 141,845,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 141845430...
Checkpoint 141845430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.42298
Policy Entropy: 1.39686
Value Function Loss: 0.44337

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01669
Policy Update Magnitude: 0.03552
Value Function Update Magnitude: 0.09073

Collected Steps per Second: 10,960.04567
Overall Steps per Second: 9,262.87682

Timestep Collection Time: 4.56476
Timestep Consumption Time: 0.83637
PPO Batch Consumption Time: 0.04488
Total Iteration Time: 5.40113

Cumulative Model Updates: 8,500
Cumulative Timesteps: 141,895,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.59502
Policy Entropy: 1.39647
Value Function Loss: 0.42390

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.01169
Policy Update Magnitude: 0.04017
Value Function Update Magnitude: 0.09140

Collected Steps per Second: 10,895.44513
Overall Steps per Second: 9,422.78249

Timestep Collection Time: 4.58926
Timestep Consumption Time: 0.71724
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 5.30650

Cumulative Model Updates: 8,503
Cumulative Timesteps: 141,945,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 141945462...
Checkpoint 141945462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.75585
Policy Entropy: 1.39909
Value Function Loss: 0.40814

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.01129
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.10008

Collected Steps per Second: 10,888.79039
Overall Steps per Second: 9,256.24771

Timestep Collection Time: 4.59316
Timestep Consumption Time: 0.81011
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 5.40327

Cumulative Model Updates: 8,506
Cumulative Timesteps: 141,995,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.88224
Policy Entropy: 1.39933
Value Function Loss: 0.36830

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01609
Policy Update Magnitude: 0.04159
Value Function Update Magnitude: 0.08925

Collected Steps per Second: 10,788.39274
Overall Steps per Second: 9,233.04366

Timestep Collection Time: 4.63535
Timestep Consumption Time: 0.78085
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.41620

Cumulative Model Updates: 8,509
Cumulative Timesteps: 142,045,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 142045484...
Checkpoint 142045484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.03212
Policy Entropy: 1.39610
Value Function Loss: 0.40846

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.01178
Policy Update Magnitude: 0.04009
Value Function Update Magnitude: 0.09148

Collected Steps per Second: 10,454.62138
Overall Steps per Second: 8,934.75234

Timestep Collection Time: 4.78506
Timestep Consumption Time: 0.81398
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 5.59904

Cumulative Model Updates: 8,512
Cumulative Timesteps: 142,095,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.70005
Policy Entropy: 1.39515
Value Function Loss: 0.46269

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.01147
Policy Update Magnitude: 0.03902
Value Function Update Magnitude: 0.09296

Collected Steps per Second: 10,148.74331
Overall Steps per Second: 8,740.10413

Timestep Collection Time: 4.92711
Timestep Consumption Time: 0.79410
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.72121

Cumulative Model Updates: 8,515
Cumulative Timesteps: 142,145,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 142145514...
Checkpoint 142145514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.85860
Policy Entropy: 1.39302
Value Function Loss: 0.47694

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.02079
Policy Update Magnitude: 0.03776
Value Function Update Magnitude: 0.10001

Collected Steps per Second: 10,600.85155
Overall Steps per Second: 9,209.09797

Timestep Collection Time: 4.71830
Timestep Consumption Time: 0.71307
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.43137

Cumulative Model Updates: 8,518
Cumulative Timesteps: 142,195,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.23151
Policy Entropy: 1.39527
Value Function Loss: 0.46596

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.01390
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.08093

Collected Steps per Second: 10,781.94585
Overall Steps per Second: 9,195.64014

Timestep Collection Time: 4.63942
Timestep Consumption Time: 0.80033
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.43975

Cumulative Model Updates: 8,521
Cumulative Timesteps: 142,245,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 142245554...
Checkpoint 142245554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.66982
Policy Entropy: 1.39520
Value Function Loss: 0.41736

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01768
Policy Update Magnitude: 0.03992
Value Function Update Magnitude: 0.06810

Collected Steps per Second: 10,604.84528
Overall Steps per Second: 9,001.61456

Timestep Collection Time: 4.71690
Timestep Consumption Time: 0.84010
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 5.55700

Cumulative Model Updates: 8,524
Cumulative Timesteps: 142,295,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.48663
Policy Entropy: 1.39722
Value Function Loss: 0.43930

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01661
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.06541

Collected Steps per Second: 10,294.95363
Overall Steps per Second: 8,732.30983

Timestep Collection Time: 4.86025
Timestep Consumption Time: 0.86974
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.72998

Cumulative Model Updates: 8,527
Cumulative Timesteps: 142,345,612

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 142345612...
Checkpoint 142345612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.65218
Policy Entropy: 1.39370
Value Function Loss: 0.48114

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.06581

Collected Steps per Second: 10,813.53026
Overall Steps per Second: 9,145.27852

Timestep Collection Time: 4.62495
Timestep Consumption Time: 0.84367
PPO Batch Consumption Time: 0.04263
Total Iteration Time: 5.46861

Cumulative Model Updates: 8,530
Cumulative Timesteps: 142,395,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.74083
Policy Entropy: 1.39057
Value Function Loss: 0.54350

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.09637

Collected Steps per Second: 10,787.87702
Overall Steps per Second: 9,269.80721

Timestep Collection Time: 4.63539
Timestep Consumption Time: 0.75911
PPO Batch Consumption Time: 0.03824
Total Iteration Time: 5.39450

Cumulative Model Updates: 8,533
Cumulative Timesteps: 142,445,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 142445630...
Checkpoint 142445630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.68773
Policy Entropy: 1.38679
Value Function Loss: 0.61162

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.10439

Collected Steps per Second: 10,766.11781
Overall Steps per Second: 9,140.11306

Timestep Collection Time: 4.64476
Timestep Consumption Time: 0.82629
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 5.47105

Cumulative Model Updates: 8,536
Cumulative Timesteps: 142,495,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.62481
Policy Entropy: 1.38623
Value Function Loss: 0.67950

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.12429

Collected Steps per Second: 10,915.28257
Overall Steps per Second: 9,193.53945

Timestep Collection Time: 4.58165
Timestep Consumption Time: 0.85804
PPO Batch Consumption Time: 0.04035
Total Iteration Time: 5.43969

Cumulative Model Updates: 8,539
Cumulative Timesteps: 142,545,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 142545646...
Checkpoint 142545646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.68310
Policy Entropy: 1.38450
Value Function Loss: 0.72409

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02949
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.12820

Collected Steps per Second: 10,893.15009
Overall Steps per Second: 9,036.17141

Timestep Collection Time: 4.59114
Timestep Consumption Time: 0.94350
PPO Batch Consumption Time: 0.04523
Total Iteration Time: 5.53464

Cumulative Model Updates: 8,542
Cumulative Timesteps: 142,595,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.37520
Policy Entropy: 1.37597
Value Function Loss: 0.84511

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.03763
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 10,307.43196
Overall Steps per Second: 8,836.35027

Timestep Collection Time: 4.85203
Timestep Consumption Time: 0.80777
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.65980

Cumulative Model Updates: 8,545
Cumulative Timesteps: 142,645,670

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 142645670...
Checkpoint 142645670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.27471
Policy Entropy: 1.37352
Value Function Loss: 0.90366

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.03257
Policy Update Magnitude: 0.04119
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 10,622.99445
Overall Steps per Second: 9,200.58944

Timestep Collection Time: 4.70865
Timestep Consumption Time: 0.72795
PPO Batch Consumption Time: 0.03886
Total Iteration Time: 5.43661

Cumulative Model Updates: 8,548
Cumulative Timesteps: 142,695,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.13415
Policy Entropy: 1.36650
Value Function Loss: 0.95693

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03419
Policy Update Magnitude: 0.03938
Value Function Update Magnitude: 0.11943

Collected Steps per Second: 10,918.52775
Overall Steps per Second: 9,211.50572

Timestep Collection Time: 4.57992
Timestep Consumption Time: 0.84872
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.42865

Cumulative Model Updates: 8,551
Cumulative Timesteps: 142,745,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 142745696...
Checkpoint 142745696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.06846
Policy Entropy: 1.36314
Value Function Loss: 1.06409

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.09828

Collected Steps per Second: 10,748.19763
Overall Steps per Second: 9,120.85976

Timestep Collection Time: 4.65399
Timestep Consumption Time: 0.83036
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 5.48435

Cumulative Model Updates: 8,554
Cumulative Timesteps: 142,795,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.69379
Policy Entropy: 1.35438
Value Function Loss: 1.12632

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.09734

Collected Steps per Second: 10,929.48506
Overall Steps per Second: 9,221.58161

Timestep Collection Time: 4.57570
Timestep Consumption Time: 0.84745
PPO Batch Consumption Time: 0.04352
Total Iteration Time: 5.42315

Cumulative Model Updates: 8,557
Cumulative Timesteps: 142,845,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 142845728...
Checkpoint 142845728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.71162
Policy Entropy: 1.35163
Value Function Loss: 1.22529

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.04064
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.08687

Collected Steps per Second: 10,303.94495
Overall Steps per Second: 8,815.28810

Timestep Collection Time: 4.85406
Timestep Consumption Time: 0.81972
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 5.67378

Cumulative Model Updates: 8,560
Cumulative Timesteps: 142,895,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.59685
Policy Entropy: 1.35398
Value Function Loss: 1.17907

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02879
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.08835

Collected Steps per Second: 10,691.25039
Overall Steps per Second: 9,225.16644

Timestep Collection Time: 4.67822
Timestep Consumption Time: 0.74347
PPO Batch Consumption Time: 0.03816
Total Iteration Time: 5.42169

Cumulative Model Updates: 8,563
Cumulative Timesteps: 142,945,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 142945760...
Checkpoint 142945760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.83212
Policy Entropy: 1.35626
Value Function Loss: 1.08638

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 0.06432
Value Function Update Magnitude: 0.10428

Collected Steps per Second: 10,824.13503
Overall Steps per Second: 9,093.05329

Timestep Collection Time: 4.62097
Timestep Consumption Time: 0.87971
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 5.50068

Cumulative Model Updates: 8,566
Cumulative Timesteps: 142,995,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.91967
Policy Entropy: 1.35840
Value Function Loss: 1.07389

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03336
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.10354

Collected Steps per Second: 10,357.41814
Overall Steps per Second: 8,791.67516

Timestep Collection Time: 4.82746
Timestep Consumption Time: 0.85974
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 5.68720

Cumulative Model Updates: 8,569
Cumulative Timesteps: 143,045,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 143045778...
Checkpoint 143045778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.50099
Policy Entropy: 1.35515
Value Function Loss: 0.99890

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.10612

Collected Steps per Second: 10,384.71461
Overall Steps per Second: 8,914.03548

Timestep Collection Time: 4.81708
Timestep Consumption Time: 0.79474
PPO Batch Consumption Time: 0.04437
Total Iteration Time: 5.61182

Cumulative Model Updates: 8,572
Cumulative Timesteps: 143,095,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.37464
Policy Entropy: 1.35633
Value Function Loss: 1.14351

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 10,616.51659
Overall Steps per Second: 8,901.16473

Timestep Collection Time: 4.70983
Timestep Consumption Time: 0.90764
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 5.61747

Cumulative Model Updates: 8,575
Cumulative Timesteps: 143,145,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 143145804...
Checkpoint 143145804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.94751
Policy Entropy: 1.35588
Value Function Loss: 1.14041

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03503
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.10329

Collected Steps per Second: 10,425.77922
Overall Steps per Second: 9,086.44096

Timestep Collection Time: 4.79696
Timestep Consumption Time: 0.70707
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.50403

Cumulative Model Updates: 8,578
Cumulative Timesteps: 143,195,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.24359
Policy Entropy: 1.35247
Value Function Loss: 1.18596

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03153
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.09486

Collected Steps per Second: 10,560.35791
Overall Steps per Second: 9,006.99396

Timestep Collection Time: 4.73488
Timestep Consumption Time: 0.81659
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 5.55146

Cumulative Model Updates: 8,581
Cumulative Timesteps: 143,245,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 143245818...
Checkpoint 143245818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.18768
Policy Entropy: 1.35109
Value Function Loss: 1.07319

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03773
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.08718

Collected Steps per Second: 10,727.50223
Overall Steps per Second: 9,068.90568

Timestep Collection Time: 4.66278
Timestep Consumption Time: 0.85277
PPO Batch Consumption Time: 0.04473
Total Iteration Time: 5.51555

Cumulative Model Updates: 8,584
Cumulative Timesteps: 143,295,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.77658
Policy Entropy: 1.35258
Value Function Loss: 1.05541

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.04597
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.08425

Collected Steps per Second: 10,783.70868
Overall Steps per Second: 9,285.16365

Timestep Collection Time: 4.63699
Timestep Consumption Time: 0.74837
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.38537

Cumulative Model Updates: 8,587
Cumulative Timesteps: 143,345,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 143345842...
Checkpoint 143345842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.68052
Policy Entropy: 1.35347
Value Function Loss: 1.09014

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.04815
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.07028

Collected Steps per Second: 10,616.45794
Overall Steps per Second: 8,989.20812

Timestep Collection Time: 4.71155
Timestep Consumption Time: 0.85290
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.56445

Cumulative Model Updates: 8,590
Cumulative Timesteps: 143,395,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.77839
Policy Entropy: 1.35169
Value Function Loss: 1.18939

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04087
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.07410

Collected Steps per Second: 10,152.02957
Overall Steps per Second: 8,796.77322

Timestep Collection Time: 4.92670
Timestep Consumption Time: 0.75902
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 5.68572

Cumulative Model Updates: 8,593
Cumulative Timesteps: 143,445,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 143445878...
Checkpoint 143445878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.56691
Policy Entropy: 1.35125
Value Function Loss: 1.14589

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.03677
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.09566

Collected Steps per Second: 10,502.58674
Overall Steps per Second: 8,875.95661

Timestep Collection Time: 4.76187
Timestep Consumption Time: 0.87267
PPO Batch Consumption Time: 0.04479
Total Iteration Time: 5.63455

Cumulative Model Updates: 8,596
Cumulative Timesteps: 143,495,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.75201
Policy Entropy: 1.34761
Value Function Loss: 1.15036

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.05075
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.08753

Collected Steps per Second: 10,682.56809
Overall Steps per Second: 9,075.24320

Timestep Collection Time: 4.68258
Timestep Consumption Time: 0.82934
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.51192

Cumulative Model Updates: 8,599
Cumulative Timesteps: 143,545,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 143545912...
Checkpoint 143545912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.02792
Policy Entropy: 1.35032
Value Function Loss: 1.10545

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.04667
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.09168

Collected Steps per Second: 10,870.81255
Overall Steps per Second: 9,107.09850

Timestep Collection Time: 4.60113
Timestep Consumption Time: 0.89107
PPO Batch Consumption Time: 0.04571
Total Iteration Time: 5.49220

Cumulative Model Updates: 8,602
Cumulative Timesteps: 143,595,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.79044
Policy Entropy: 1.35627
Value Function Loss: 1.11387

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.04532
Policy Update Magnitude: 0.04221
Value Function Update Magnitude: 0.09496

Collected Steps per Second: 11,191.80408
Overall Steps per Second: 9,461.95604

Timestep Collection Time: 4.46970
Timestep Consumption Time: 0.81716
PPO Batch Consumption Time: 0.03967
Total Iteration Time: 5.28686

Cumulative Model Updates: 8,605
Cumulative Timesteps: 143,645,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 143645954...
Checkpoint 143645954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.05705
Policy Entropy: 1.35449
Value Function Loss: 1.10116

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05195
Policy Update Magnitude: 0.03091
Value Function Update Magnitude: 0.08801

Collected Steps per Second: 11,295.49988
Overall Steps per Second: 9,512.56882

Timestep Collection Time: 4.42743
Timestep Consumption Time: 0.82983
PPO Batch Consumption Time: 0.03900
Total Iteration Time: 5.25725

Cumulative Model Updates: 8,608
Cumulative Timesteps: 143,695,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.09200
Policy Entropy: 1.35551
Value Function Loss: 1.11752

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 0.03249
Value Function Update Magnitude: 0.08943

Collected Steps per Second: 11,444.24532
Overall Steps per Second: 9,529.84389

Timestep Collection Time: 4.37145
Timestep Consumption Time: 0.87816
PPO Batch Consumption Time: 0.03870
Total Iteration Time: 5.24961

Cumulative Model Updates: 8,611
Cumulative Timesteps: 143,745,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 143745992...
Checkpoint 143745992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.78403
Policy Entropy: 1.35482
Value Function Loss: 1.05780

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02771
Policy Update Magnitude: 0.03805
Value Function Update Magnitude: 0.09386

Collected Steps per Second: 11,170.11436
Overall Steps per Second: 9,455.95000

Timestep Collection Time: 4.47838
Timestep Consumption Time: 0.81184
PPO Batch Consumption Time: 0.03960
Total Iteration Time: 5.29021

Cumulative Model Updates: 8,614
Cumulative Timesteps: 143,796,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.63360
Policy Entropy: 1.36190
Value Function Loss: 1.00153

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03086
Policy Update Magnitude: 0.03734
Value Function Update Magnitude: 0.09188

Collected Steps per Second: 11,439.72996
Overall Steps per Second: 9,601.12919

Timestep Collection Time: 4.37108
Timestep Consumption Time: 0.83706
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 5.20814

Cumulative Model Updates: 8,617
Cumulative Timesteps: 143,846,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 143846020...
Checkpoint 143846020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.73537
Policy Entropy: 1.35548
Value Function Loss: 0.88058

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.04040
Policy Update Magnitude: 0.03586
Value Function Update Magnitude: 0.10830

Collected Steps per Second: 11,240.32724
Overall Steps per Second: 9,362.68978

Timestep Collection Time: 4.44845
Timestep Consumption Time: 0.89211
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.34056

Cumulative Model Updates: 8,620
Cumulative Timesteps: 143,896,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.23194
Policy Entropy: 1.35375
Value Function Loss: 0.91318

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 0.03587
Value Function Update Magnitude: 0.10739

Collected Steps per Second: 10,709.68895
Overall Steps per Second: 9,223.78903

Timestep Collection Time: 4.66998
Timestep Consumption Time: 0.75231
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 5.42228

Cumulative Model Updates: 8,623
Cumulative Timesteps: 143,946,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 143946036...
Checkpoint 143946036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.65139
Policy Entropy: 1.35214
Value Function Loss: 0.91734

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04103
Policy Update Magnitude: 0.03370
Value Function Update Magnitude: 0.10741

Collected Steps per Second: 10,160.07719
Overall Steps per Second: 8,677.62714

Timestep Collection Time: 4.92221
Timestep Consumption Time: 0.84089
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.76310

Cumulative Model Updates: 8,626
Cumulative Timesteps: 143,996,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.32890
Policy Entropy: 1.35280
Value Function Loss: 1.00612

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.03977
Value Function Update Magnitude: 0.09154

Collected Steps per Second: 10,538.19622
Overall Steps per Second: 9,082.90005

Timestep Collection Time: 4.74597
Timestep Consumption Time: 0.76042
PPO Batch Consumption Time: 0.03868
Total Iteration Time: 5.50639

Cumulative Model Updates: 8,629
Cumulative Timesteps: 144,046,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 144046060...
Checkpoint 144046060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.10311
Policy Entropy: 1.35446
Value Function Loss: 0.96491

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02154
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.09385

Collected Steps per Second: 10,979.42919
Overall Steps per Second: 9,260.68220

Timestep Collection Time: 4.55488
Timestep Consumption Time: 0.84537
PPO Batch Consumption Time: 0.04424
Total Iteration Time: 5.40025

Cumulative Model Updates: 8,632
Cumulative Timesteps: 144,096,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.88237
Policy Entropy: 1.35130
Value Function Loss: 1.06107

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03728
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.07945

Collected Steps per Second: 11,007.95130
Overall Steps per Second: 9,352.94570

Timestep Collection Time: 4.54435
Timestep Consumption Time: 0.80412
PPO Batch Consumption Time: 0.04075
Total Iteration Time: 5.34848

Cumulative Model Updates: 8,635
Cumulative Timesteps: 144,146,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 144146094...
Checkpoint 144146094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.08649
Policy Entropy: 1.35120
Value Function Loss: 1.04016

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.05541
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.09851

Collected Steps per Second: 10,921.10170
Overall Steps per Second: 9,312.63119

Timestep Collection Time: 4.58012
Timestep Consumption Time: 0.79108
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.37120

Cumulative Model Updates: 8,638
Cumulative Timesteps: 144,196,114

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.70683
Policy Entropy: 1.35002
Value Function Loss: 1.07672

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03245
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 10,868.44809
Overall Steps per Second: 9,060.92422

Timestep Collection Time: 4.60323
Timestep Consumption Time: 0.91828
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 5.52151

Cumulative Model Updates: 8,641
Cumulative Timesteps: 144,246,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 144246144...
Checkpoint 144246144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.26917
Policy Entropy: 1.35284
Value Function Loss: 1.08333

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.09548

Collected Steps per Second: 10,528.18153
Overall Steps per Second: 9,173.57303

Timestep Collection Time: 4.75049
Timestep Consumption Time: 0.70148
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.45197

Cumulative Model Updates: 8,644
Cumulative Timesteps: 144,296,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.49927
Policy Entropy: 1.35104
Value Function Loss: 1.09883

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03930
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.10656

Collected Steps per Second: 10,595.14712
Overall Steps per Second: 9,015.47665

Timestep Collection Time: 4.72160
Timestep Consumption Time: 0.82731
PPO Batch Consumption Time: 0.03912
Total Iteration Time: 5.54890

Cumulative Model Updates: 8,647
Cumulative Timesteps: 144,346,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 144346184...
Checkpoint 144346184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.19397
Policy Entropy: 1.34932
Value Function Loss: 1.16791

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03283
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.09415

Collected Steps per Second: 10,904.99487
Overall Steps per Second: 9,336.26099

Timestep Collection Time: 4.58634
Timestep Consumption Time: 0.77062
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 5.35696

Cumulative Model Updates: 8,650
Cumulative Timesteps: 144,396,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.67023
Policy Entropy: 1.34962
Value Function Loss: 1.04437

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04783
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.09498

Collected Steps per Second: 10,805.38749
Overall Steps per Second: 9,167.30132

Timestep Collection Time: 4.62806
Timestep Consumption Time: 0.82698
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.45504

Cumulative Model Updates: 8,653
Cumulative Timesteps: 144,446,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 144446206...
Checkpoint 144446206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.05476
Policy Entropy: 1.35511
Value Function Loss: 1.03055

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03286
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.09085

Collected Steps per Second: 10,572.12688
Overall Steps per Second: 8,987.54647

Timestep Collection Time: 4.72961
Timestep Consumption Time: 0.83387
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.56348

Cumulative Model Updates: 8,656
Cumulative Timesteps: 144,496,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.54033
Policy Entropy: 1.35262
Value Function Loss: 1.08577

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 0.04272
Value Function Update Magnitude: 0.09785

Collected Steps per Second: 10,174.59575
Overall Steps per Second: 8,798.75438

Timestep Collection Time: 4.91636
Timestep Consumption Time: 0.76876
PPO Batch Consumption Time: 0.04677
Total Iteration Time: 5.68512

Cumulative Model Updates: 8,659
Cumulative Timesteps: 144,546,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 144546230...
Checkpoint 144546230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.80343
Policy Entropy: 1.35273
Value Function Loss: 1.15430

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02907
Policy Update Magnitude: 0.03963
Value Function Update Magnitude: 0.08494

Collected Steps per Second: 10,756.40824
Overall Steps per Second: 9,120.22106

Timestep Collection Time: 4.64988
Timestep Consumption Time: 0.83420
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.48408

Cumulative Model Updates: 8,662
Cumulative Timesteps: 144,596,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.74852
Policy Entropy: 1.35206
Value Function Loss: 1.26971

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.10588

Collected Steps per Second: 10,833.77373
Overall Steps per Second: 9,235.95967

Timestep Collection Time: 4.61520
Timestep Consumption Time: 0.79843
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.41362

Cumulative Model Updates: 8,665
Cumulative Timesteps: 144,646,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 144646246...
Checkpoint 144646246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.84257
Policy Entropy: 1.34804
Value Function Loss: 1.18292

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04169
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.09617

Collected Steps per Second: 10,839.30546
Overall Steps per Second: 9,157.75790

Timestep Collection Time: 4.61579
Timestep Consumption Time: 0.84755
PPO Batch Consumption Time: 0.03961
Total Iteration Time: 5.46335

Cumulative Model Updates: 8,668
Cumulative Timesteps: 144,696,278

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.59335
Policy Entropy: 1.34921
Value Function Loss: 1.26140

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.09363

Collected Steps per Second: 10,561.87873
Overall Steps per Second: 9,015.67753

Timestep Collection Time: 4.73666
Timestep Consumption Time: 0.81234
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 5.54900

Cumulative Model Updates: 8,671
Cumulative Timesteps: 144,746,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 144746306...
Checkpoint 144746306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.05386
Policy Entropy: 1.35110
Value Function Loss: 1.18919

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 0.05971
Value Function Update Magnitude: 0.11178

Collected Steps per Second: 9,630.09651
Overall Steps per Second: 8,465.47543

Timestep Collection Time: 5.19393
Timestep Consumption Time: 0.71454
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 5.90847

Cumulative Model Updates: 8,674
Cumulative Timesteps: 144,796,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.70468
Policy Entropy: 1.35465
Value Function Loss: 1.20220

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02112
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.13536

Collected Steps per Second: 11,114.90582
Overall Steps per Second: 9,104.12329

Timestep Collection Time: 4.49954
Timestep Consumption Time: 0.99379
PPO Batch Consumption Time: 0.05282
Total Iteration Time: 5.49334

Cumulative Model Updates: 8,677
Cumulative Timesteps: 144,846,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 144846336...
Checkpoint 144846336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.08278
Policy Entropy: 1.35404
Value Function Loss: 1.10927

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.13167

Collected Steps per Second: 10,126.80314
Overall Steps per Second: 8,811.42252

Timestep Collection Time: 4.93798
Timestep Consumption Time: 0.73715
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.67513

Cumulative Model Updates: 8,680
Cumulative Timesteps: 144,896,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.30645
Policy Entropy: 1.34968
Value Function Loss: 1.10155

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.12212

Collected Steps per Second: 10,365.27815
Overall Steps per Second: 8,681.79192

Timestep Collection Time: 4.82631
Timestep Consumption Time: 0.93587
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 5.76217

Cumulative Model Updates: 8,683
Cumulative Timesteps: 144,946,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 144946368...
Checkpoint 144946368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.12518
Policy Entropy: 1.34871
Value Function Loss: 1.15364

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.04827
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.11531

Collected Steps per Second: 10,613.24020
Overall Steps per Second: 9,054.13388

Timestep Collection Time: 4.71317
Timestep Consumption Time: 0.81160
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.52477

Cumulative Model Updates: 8,686
Cumulative Timesteps: 144,996,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.35249
Policy Entropy: 1.34844
Value Function Loss: 1.18625

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.05107
Policy Update Magnitude: 0.04048
Value Function Update Magnitude: 0.11476

Collected Steps per Second: 11,470.20280
Overall Steps per Second: 9,699.40346

Timestep Collection Time: 4.35930
Timestep Consumption Time: 0.79587
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.15516

Cumulative Model Updates: 8,689
Cumulative Timesteps: 145,046,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 145046392...
Checkpoint 145046392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.79975
Policy Entropy: 1.34337
Value Function Loss: 1.20995

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.04840
Policy Update Magnitude: 0.04221
Value Function Update Magnitude: 0.12093

Collected Steps per Second: 11,234.84948
Overall Steps per Second: 9,474.53583

Timestep Collection Time: 4.45240
Timestep Consumption Time: 0.82723
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 5.27963

Cumulative Model Updates: 8,692
Cumulative Timesteps: 145,096,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.59985
Policy Entropy: 1.34320
Value Function Loss: 1.24877

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03977
Policy Update Magnitude: 0.03525
Value Function Update Magnitude: 0.09925

Collected Steps per Second: 11,998.84027
Overall Steps per Second: 10,150.06748

Timestep Collection Time: 4.16890
Timestep Consumption Time: 0.75934
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 4.92824

Cumulative Model Updates: 8,695
Cumulative Timesteps: 145,146,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 145146436...
Checkpoint 145146436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.62135
Policy Entropy: 1.34491
Value Function Loss: 1.23523

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03808
Policy Update Magnitude: 0.03881
Value Function Update Magnitude: 0.09657

Collected Steps per Second: 11,544.25014
Overall Steps per Second: 9,768.51712

Timestep Collection Time: 4.33272
Timestep Consumption Time: 0.78761
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.12033

Cumulative Model Updates: 8,698
Cumulative Timesteps: 145,196,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.20362
Policy Entropy: 1.34748
Value Function Loss: 1.23301

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04362
Policy Update Magnitude: 0.03611
Value Function Update Magnitude: 0.09333

Collected Steps per Second: 12,086.36012
Overall Steps per Second: 10,172.85575

Timestep Collection Time: 4.13739
Timestep Consumption Time: 0.77824
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.91563

Cumulative Model Updates: 8,701
Cumulative Timesteps: 145,246,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 145246460...
Checkpoint 145246460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.65950
Policy Entropy: 1.34445
Value Function Loss: 1.17738

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03208
Policy Update Magnitude: 0.03556
Value Function Update Magnitude: 0.08227

Collected Steps per Second: 11,720.05437
Overall Steps per Second: 9,713.91084

Timestep Collection Time: 4.26722
Timestep Consumption Time: 0.88128
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.14849

Cumulative Model Updates: 8,704
Cumulative Timesteps: 145,296,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.88876
Policy Entropy: 1.34585
Value Function Loss: 1.20537

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03401
Policy Update Magnitude: 0.03683
Value Function Update Magnitude: 0.08583

Collected Steps per Second: 9,485.84598
Overall Steps per Second: 8,107.36898

Timestep Collection Time: 5.27228
Timestep Consumption Time: 0.89643
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.16871

Cumulative Model Updates: 8,707
Cumulative Timesteps: 145,346,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 145346484...
Checkpoint 145346484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.29490
Policy Entropy: 1.34695
Value Function Loss: 1.15781

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 0.03443
Value Function Update Magnitude: 0.07133

Collected Steps per Second: 10,481.94618
Overall Steps per Second: 9,141.86987

Timestep Collection Time: 4.77297
Timestep Consumption Time: 0.69965
PPO Batch Consumption Time: 0.03984
Total Iteration Time: 5.47262

Cumulative Model Updates: 8,710
Cumulative Timesteps: 145,396,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.84711
Policy Entropy: 1.34468
Value Function Loss: 1.17875

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03125
Policy Update Magnitude: 0.03960
Value Function Update Magnitude: 0.07668

Collected Steps per Second: 10,467.51071
Overall Steps per Second: 8,925.49015

Timestep Collection Time: 4.77707
Timestep Consumption Time: 0.82531
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 5.60238

Cumulative Model Updates: 8,713
Cumulative Timesteps: 145,446,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 145446518...
Checkpoint 145446518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.18255
Policy Entropy: 1.34462
Value Function Loss: 1.14148

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02801
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.08309

Collected Steps per Second: 11,410.95896
Overall Steps per Second: 9,644.88737

Timestep Collection Time: 4.38280
Timestep Consumption Time: 0.80253
PPO Batch Consumption Time: 0.03792
Total Iteration Time: 5.18534

Cumulative Model Updates: 8,716
Cumulative Timesteps: 145,496,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.58328
Policy Entropy: 1.34708
Value Function Loss: 1.13869

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03248
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.07066

Collected Steps per Second: 11,428.14016
Overall Steps per Second: 9,651.08118

Timestep Collection Time: 4.37517
Timestep Consumption Time: 0.80560
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 5.18077

Cumulative Model Updates: 8,719
Cumulative Timesteps: 145,546,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 145546530...
Checkpoint 145546530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.73351
Policy Entropy: 1.34548
Value Function Loss: 1.08076

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02995
Policy Update Magnitude: 0.03590
Value Function Update Magnitude: 0.06272

Collected Steps per Second: 11,135.37542
Overall Steps per Second: 9,368.54020

Timestep Collection Time: 4.49091
Timestep Consumption Time: 0.84695
PPO Batch Consumption Time: 0.03775
Total Iteration Time: 5.33786

Cumulative Model Updates: 8,722
Cumulative Timesteps: 145,596,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.97693
Policy Entropy: 1.34203
Value Function Loss: 1.11888

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04594
Policy Update Magnitude: 0.03495
Value Function Update Magnitude: 0.05019

Collected Steps per Second: 9,978.98752
Overall Steps per Second: 8,506.68865

Timestep Collection Time: 5.01374
Timestep Consumption Time: 0.86775
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 5.88149

Cumulative Model Updates: 8,725
Cumulative Timesteps: 145,646,570

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 145646570...
Checkpoint 145646570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.15065
Policy Entropy: 1.34234
Value Function Loss: 1.14376

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02943
Policy Update Magnitude: 0.03711
Value Function Update Magnitude: 0.04567

Collected Steps per Second: 8,640.07530
Overall Steps per Second: 7,559.64410

Timestep Collection Time: 5.78814
Timestep Consumption Time: 0.82725
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 6.61539

Cumulative Model Updates: 8,728
Cumulative Timesteps: 145,696,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.75723
Policy Entropy: 1.34088
Value Function Loss: 1.13436

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02871
Policy Update Magnitude: 0.03688
Value Function Update Magnitude: 0.05107

Collected Steps per Second: 10,260.81925
Overall Steps per Second: 8,188.81106

Timestep Collection Time: 4.87349
Timestep Consumption Time: 1.23314
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 6.10663

Cumulative Model Updates: 8,731
Cumulative Timesteps: 145,746,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 145746586...
Checkpoint 145746586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.48478
Policy Entropy: 1.33265
Value Function Loss: 1.11947

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04719
Policy Update Magnitude: 0.03654
Value Function Update Magnitude: 0.05270

Collected Steps per Second: 9,574.83506
Overall Steps per Second: 8,225.93593

Timestep Collection Time: 5.22390
Timestep Consumption Time: 0.85662
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 6.08052

Cumulative Model Updates: 8,734
Cumulative Timesteps: 145,796,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.61946
Policy Entropy: 1.33976
Value Function Loss: 1.12228

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04492
Policy Update Magnitude: 0.03281
Value Function Update Magnitude: 0.04708

Collected Steps per Second: 11,323.84786
Overall Steps per Second: 9,422.19928

Timestep Collection Time: 4.41793
Timestep Consumption Time: 0.89166
PPO Batch Consumption Time: 0.03977
Total Iteration Time: 5.30959

Cumulative Model Updates: 8,737
Cumulative Timesteps: 145,846,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 145846632...
Checkpoint 145846632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.97333
Policy Entropy: 1.33173
Value Function Loss: 1.15693

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07126
Policy Update Magnitude: 0.02902
Value Function Update Magnitude: 0.05540

Collected Steps per Second: 10,447.14617
Overall Steps per Second: 9,029.68191

Timestep Collection Time: 4.78638
Timestep Consumption Time: 0.75136
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.53774

Cumulative Model Updates: 8,740
Cumulative Timesteps: 145,896,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.89966
Policy Entropy: 1.34160
Value Function Loss: 1.18101

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.03334
Value Function Update Magnitude: 0.04592

Collected Steps per Second: 11,894.38852
Overall Steps per Second: 10,010.36625

Timestep Collection Time: 4.20467
Timestep Consumption Time: 0.79135
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 4.99602

Cumulative Model Updates: 8,743
Cumulative Timesteps: 145,946,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 145946648...
Checkpoint 145946648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.13283
Policy Entropy: 1.34364
Value Function Loss: 1.23672

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.07989
Policy Update Magnitude: 0.03251
Value Function Update Magnitude: 0.04253

Collected Steps per Second: 12,549.70120
Overall Steps per Second: 10,469.36049

Timestep Collection Time: 3.98607
Timestep Consumption Time: 0.79206
PPO Batch Consumption Time: 0.03381
Total Iteration Time: 4.77813

Cumulative Model Updates: 8,746
Cumulative Timesteps: 145,996,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.86215
Policy Entropy: 1.34178
Value Function Loss: 1.22602

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.03064
Value Function Update Magnitude: 0.06996

Collected Steps per Second: 13,090.57831
Overall Steps per Second: 10,829.07069

Timestep Collection Time: 3.82168
Timestep Consumption Time: 0.79811
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.61979

Cumulative Model Updates: 8,749
Cumulative Timesteps: 146,046,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 146046700...
Checkpoint 146046700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.32108
Policy Entropy: 1.34888
Value Function Loss: 1.19097

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.02937
Value Function Update Magnitude: 0.06504

Collected Steps per Second: 12,538.40083
Overall Steps per Second: 10,526.46425

Timestep Collection Time: 3.98823
Timestep Consumption Time: 0.76228
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.75050

Cumulative Model Updates: 8,752
Cumulative Timesteps: 146,096,706

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.44643
Policy Entropy: 1.34467
Value Function Loss: 1.13492

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.02955
Value Function Update Magnitude: 0.06001

Collected Steps per Second: 12,517.09362
Overall Steps per Second: 10,664.22205

Timestep Collection Time: 3.99550
Timestep Consumption Time: 0.69420
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.68970

Cumulative Model Updates: 8,755
Cumulative Timesteps: 146,146,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 146146718...
Checkpoint 146146718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.15533
Policy Entropy: 1.34868
Value Function Loss: 1.17183

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 11,888.93750
Overall Steps per Second: 10,029.31725

Timestep Collection Time: 4.20643
Timestep Consumption Time: 0.77995
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.98638

Cumulative Model Updates: 8,758
Cumulative Timesteps: 146,196,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.28214
Policy Entropy: 1.34259
Value Function Loss: 1.13028

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.08002

Collected Steps per Second: 12,272.69074
Overall Steps per Second: 10,392.03214

Timestep Collection Time: 4.07409
Timestep Consumption Time: 0.73729
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.81138

Cumulative Model Updates: 8,761
Cumulative Timesteps: 146,246,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 146246728...
Checkpoint 146246728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.91511
Policy Entropy: 1.34801
Value Function Loss: 1.13131

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.04646
Value Function Update Magnitude: 0.08439

Collected Steps per Second: 11,532.81422
Overall Steps per Second: 9,748.03447

Timestep Collection Time: 4.33684
Timestep Consumption Time: 0.79404
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 5.13088

Cumulative Model Updates: 8,764
Cumulative Timesteps: 146,296,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.10505
Policy Entropy: 1.34385
Value Function Loss: 1.12613

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06001
Policy Update Magnitude: 0.04108
Value Function Update Magnitude: 0.08128

Collected Steps per Second: 11,976.30572
Overall Steps per Second: 10,042.83415

Timestep Collection Time: 4.17608
Timestep Consumption Time: 0.80399
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 4.98007

Cumulative Model Updates: 8,767
Cumulative Timesteps: 146,346,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 146346758...
Checkpoint 146346758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.80214
Policy Entropy: 1.34602
Value Function Loss: 1.13805

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06632
Policy Update Magnitude: 0.04174
Value Function Update Magnitude: 0.09884

Collected Steps per Second: 11,713.41698
Overall Steps per Second: 10,111.97124

Timestep Collection Time: 4.26998
Timestep Consumption Time: 0.67624
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 4.94622

Cumulative Model Updates: 8,770
Cumulative Timesteps: 146,396,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.17101
Policy Entropy: 1.34545
Value Function Loss: 1.17510

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04973
Policy Update Magnitude: 0.03493
Value Function Update Magnitude: 0.08923

Collected Steps per Second: 9,934.98077
Overall Steps per Second: 8,332.24611

Timestep Collection Time: 5.03333
Timestep Consumption Time: 0.96818
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 6.00150

Cumulative Model Updates: 8,773
Cumulative Timesteps: 146,446,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 146446780...
Checkpoint 146446780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.21421
Policy Entropy: 1.34456
Value Function Loss: 1.15287

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06230
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.08289

Collected Steps per Second: 9,816.13484
Overall Steps per Second: 8,642.81081

Timestep Collection Time: 5.09427
Timestep Consumption Time: 0.69158
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.78585

Cumulative Model Updates: 8,776
Cumulative Timesteps: 146,496,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.42148
Policy Entropy: 1.34809
Value Function Loss: 1.22013

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06140
Policy Update Magnitude: 0.03973
Value Function Update Magnitude: 0.08613

Collected Steps per Second: 11,853.25061
Overall Steps per Second: 9,867.92905

Timestep Collection Time: 4.21960
Timestep Consumption Time: 0.84894
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.06854

Cumulative Model Updates: 8,779
Cumulative Timesteps: 146,546,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 146546802...
Checkpoint 146546802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.90778
Policy Entropy: 1.34800
Value Function Loss: 1.12622

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.04991
Policy Update Magnitude: 0.03588
Value Function Update Magnitude: 0.07180

Collected Steps per Second: 11,338.15693
Overall Steps per Second: 9,682.56620

Timestep Collection Time: 4.41024
Timestep Consumption Time: 0.75409
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.16433

Cumulative Model Updates: 8,782
Cumulative Timesteps: 146,596,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.83813
Policy Entropy: 1.34799
Value Function Loss: 1.16566

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04319
Policy Update Magnitude: 0.03425
Value Function Update Magnitude: 0.07096

Collected Steps per Second: 11,956.15903
Overall Steps per Second: 10,314.90303

Timestep Collection Time: 4.18228
Timestep Consumption Time: 0.66546
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.84774

Cumulative Model Updates: 8,785
Cumulative Timesteps: 146,646,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 146646810...
Checkpoint 146646810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.60532
Policy Entropy: 1.34852
Value Function Loss: 1.05340

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.04545
Policy Update Magnitude: 0.04043
Value Function Update Magnitude: 0.07827

Collected Steps per Second: 12,012.95203
Overall Steps per Second: 10,145.89685

Timestep Collection Time: 4.16451
Timestep Consumption Time: 0.76636
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 4.93086

Cumulative Model Updates: 8,788
Cumulative Timesteps: 146,696,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.29637
Policy Entropy: 1.34659
Value Function Loss: 1.13617

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04635
Policy Update Magnitude: 0.03468
Value Function Update Magnitude: 0.08596

Collected Steps per Second: 11,826.88070
Overall Steps per Second: 10,139.34855

Timestep Collection Time: 4.22969
Timestep Consumption Time: 0.70396
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 4.93365

Cumulative Model Updates: 8,791
Cumulative Timesteps: 146,746,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 146746862...
Checkpoint 146746862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.75451
Policy Entropy: 1.34614
Value Function Loss: 1.17111

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04189
Policy Update Magnitude: 0.03815
Value Function Update Magnitude: 0.08247

Collected Steps per Second: 11,341.38405
Overall Steps per Second: 9,606.55582

Timestep Collection Time: 4.40863
Timestep Consumption Time: 0.79615
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.20478

Cumulative Model Updates: 8,794
Cumulative Timesteps: 146,796,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.09010
Policy Entropy: 1.34510
Value Function Loss: 1.24930

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.04337
Policy Update Magnitude: 0.03814
Value Function Update Magnitude: 0.08893

Collected Steps per Second: 11,048.25164
Overall Steps per Second: 9,461.02070

Timestep Collection Time: 4.52687
Timestep Consumption Time: 0.75945
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 5.28632

Cumulative Model Updates: 8,797
Cumulative Timesteps: 146,846,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 146846876...
Checkpoint 146846876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.34998
Policy Entropy: 1.34185
Value Function Loss: 1.28431

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04202
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.09485

Collected Steps per Second: 12,253.58519
Overall Steps per Second: 10,458.44247

Timestep Collection Time: 4.08289
Timestep Consumption Time: 0.70081
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.78370

Cumulative Model Updates: 8,800
Cumulative Timesteps: 146,896,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.69620
Policy Entropy: 1.34374
Value Function Loss: 1.27356

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.04935
Policy Update Magnitude: 0.03964
Value Function Update Magnitude: 0.08544

Collected Steps per Second: 12,345.48006
Overall Steps per Second: 10,293.59886

Timestep Collection Time: 4.05201
Timestep Consumption Time: 0.80771
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.85972

Cumulative Model Updates: 8,803
Cumulative Timesteps: 146,946,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 146946930...
Checkpoint 146946930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.28239
Policy Entropy: 1.34112
Value Function Loss: 1.32849

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03769
Policy Update Magnitude: 0.04007
Value Function Update Magnitude: 0.07709

Collected Steps per Second: 12,714.69550
Overall Steps per Second: 10,834.89601

Timestep Collection Time: 3.93466
Timestep Consumption Time: 0.68264
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 4.61730

Cumulative Model Updates: 8,806
Cumulative Timesteps: 146,996,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.18940
Policy Entropy: 1.34451
Value Function Loss: 1.21493

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03431
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.07962

Collected Steps per Second: 12,599.40272
Overall Steps per Second: 10,606.84167

Timestep Collection Time: 3.97019
Timestep Consumption Time: 0.74582
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.71601

Cumulative Model Updates: 8,809
Cumulative Timesteps: 147,046,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 147046980...
Checkpoint 147046980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.59664
Policy Entropy: 1.34409
Value Function Loss: 1.18321

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03807
Policy Update Magnitude: 0.04293
Value Function Update Magnitude: 0.07593

Collected Steps per Second: 11,916.77618
Overall Steps per Second: 10,147.91720

Timestep Collection Time: 4.19610
Timestep Consumption Time: 0.73141
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 4.92751

Cumulative Model Updates: 8,812
Cumulative Timesteps: 147,096,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.56142
Policy Entropy: 1.34038
Value Function Loss: 1.14204

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04523
Policy Update Magnitude: 0.03678
Value Function Update Magnitude: 0.06376

Collected Steps per Second: 12,827.54063
Overall Steps per Second: 10,734.48639

Timestep Collection Time: 3.89880
Timestep Consumption Time: 0.76020
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.65900

Cumulative Model Updates: 8,815
Cumulative Timesteps: 147,146,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 147146996...
Checkpoint 147146996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.56348
Policy Entropy: 1.34292
Value Function Loss: 1.15192

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.03923
Policy Update Magnitude: 0.03554
Value Function Update Magnitude: 0.05618

Collected Steps per Second: 11,327.44725
Overall Steps per Second: 9,637.74163

Timestep Collection Time: 4.41635
Timestep Consumption Time: 0.77428
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.19064

Cumulative Model Updates: 8,818
Cumulative Timesteps: 147,197,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.21613
Policy Entropy: 1.33958
Value Function Loss: 1.14172

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05299
Policy Update Magnitude: 0.03348
Value Function Update Magnitude: 0.05713

Collected Steps per Second: 12,225.76874
Overall Steps per Second: 10,525.86895

Timestep Collection Time: 4.09087
Timestep Consumption Time: 0.66066
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.75153

Cumulative Model Updates: 8,821
Cumulative Timesteps: 147,247,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 147247036...
Checkpoint 147247036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.66462
Policy Entropy: 1.34170
Value Function Loss: 1.23683

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.05524

Collected Steps per Second: 12,417.23242
Overall Steps per Second: 10,374.28937

Timestep Collection Time: 4.02795
Timestep Consumption Time: 0.79320
PPO Batch Consumption Time: 0.03373
Total Iteration Time: 4.82115

Cumulative Model Updates: 8,824
Cumulative Timesteps: 147,297,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.81724
Policy Entropy: 1.33801
Value Function Loss: 1.22773

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03551
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.06171

Collected Steps per Second: 12,610.69256
Overall Steps per Second: 10,580.89069

Timestep Collection Time: 3.96489
Timestep Consumption Time: 0.76061
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.72550

Cumulative Model Updates: 8,827
Cumulative Timesteps: 147,347,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 147347052...
Checkpoint 147347052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.35171
Policy Entropy: 1.33803
Value Function Loss: 1.13553

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03646
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.05787

Collected Steps per Second: 12,010.70464
Overall Steps per Second: 10,095.04424

Timestep Collection Time: 4.16395
Timestep Consumption Time: 0.79016
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 4.95411

Cumulative Model Updates: 8,830
Cumulative Timesteps: 147,397,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.56008
Policy Entropy: 1.33459
Value Function Loss: 1.06084

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05399
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.06368

Collected Steps per Second: 12,379.09138
Overall Steps per Second: 10,389.11697

Timestep Collection Time: 4.04149
Timestep Consumption Time: 0.77412
PPO Batch Consumption Time: 0.03417
Total Iteration Time: 4.81562

Cumulative Model Updates: 8,833
Cumulative Timesteps: 147,447,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 147447094...
Checkpoint 147447094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.42854
Policy Entropy: 1.32952
Value Function Loss: 1.02447

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06583
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.06079

Collected Steps per Second: 12,469.99874
Overall Steps per Second: 10,513.88086

Timestep Collection Time: 4.00962
Timestep Consumption Time: 0.74599
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 4.75562

Cumulative Model Updates: 8,836
Cumulative Timesteps: 147,497,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.28884
Policy Entropy: 1.33130
Value Function Loss: 1.01706

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.06008

Collected Steps per Second: 12,721.20770
Overall Steps per Second: 10,642.12787

Timestep Collection Time: 3.93280
Timestep Consumption Time: 0.76832
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 4.70113

Cumulative Model Updates: 8,839
Cumulative Timesteps: 147,547,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 147547124...
Checkpoint 147547124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.23884
Policy Entropy: 1.33163
Value Function Loss: 1.08935

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04957
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.06387

Collected Steps per Second: 11,619.65876
Overall Steps per Second: 9,926.76496

Timestep Collection Time: 4.30495
Timestep Consumption Time: 0.73416
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.03910

Cumulative Model Updates: 8,842
Cumulative Timesteps: 147,597,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.35664
Policy Entropy: 1.33307
Value Function Loss: 1.22041

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06186
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.07123

Collected Steps per Second: 12,536.94494
Overall Steps per Second: 10,420.40446

Timestep Collection Time: 3.98901
Timestep Consumption Time: 0.81023
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.79924

Cumulative Model Updates: 8,845
Cumulative Timesteps: 147,647,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 147647156...
Checkpoint 147647156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.24706
Policy Entropy: 1.33116
Value Function Loss: 1.25349

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06015
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.09480

Collected Steps per Second: 11,609.03387
Overall Steps per Second: 9,899.50396

Timestep Collection Time: 4.30802
Timestep Consumption Time: 0.74395
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.05197

Cumulative Model Updates: 8,848
Cumulative Timesteps: 147,697,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.72331
Policy Entropy: 1.33336
Value Function Loss: 1.11061

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.05273
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.10752

Collected Steps per Second: 12,330.04981
Overall Steps per Second: 10,293.51924

Timestep Collection Time: 4.05643
Timestep Consumption Time: 0.80255
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.85898

Cumulative Model Updates: 8,851
Cumulative Timesteps: 147,747,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 147747184...
Checkpoint 147747184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.75085
Policy Entropy: 1.33696
Value Function Loss: 1.11142

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06475
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.10985

Collected Steps per Second: 11,985.70283
Overall Steps per Second: 10,136.09903

Timestep Collection Time: 4.17397
Timestep Consumption Time: 0.76165
PPO Batch Consumption Time: 0.03323
Total Iteration Time: 4.93563

Cumulative Model Updates: 8,854
Cumulative Timesteps: 147,797,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.85642
Policy Entropy: 1.33599
Value Function Loss: 1.13172

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05404
Policy Update Magnitude: 0.04339
Value Function Update Magnitude: 0.12129

Collected Steps per Second: 12,321.44808
Overall Steps per Second: 10,437.19279

Timestep Collection Time: 4.05894
Timestep Consumption Time: 0.73277
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.79171

Cumulative Model Updates: 8,857
Cumulative Timesteps: 147,847,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 147847224...
Checkpoint 147847224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.83576
Policy Entropy: 1.33685
Value Function Loss: 1.22270

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05751
Policy Update Magnitude: 0.04235
Value Function Update Magnitude: 0.09871

Collected Steps per Second: 12,558.76750
Overall Steps per Second: 10,432.76268

Timestep Collection Time: 3.98128
Timestep Consumption Time: 0.81131
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 4.79259

Cumulative Model Updates: 8,860
Cumulative Timesteps: 147,897,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.32319
Policy Entropy: 1.33304
Value Function Loss: 1.16580

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07013
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.07536

Collected Steps per Second: 12,333.11015
Overall Steps per Second: 10,288.38493

Timestep Collection Time: 4.05607
Timestep Consumption Time: 0.80611
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 4.86218

Cumulative Model Updates: 8,863
Cumulative Timesteps: 147,947,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 147947248...
Checkpoint 147947248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.96475
Policy Entropy: 1.33913
Value Function Loss: 1.22048

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04231
Policy Update Magnitude: 0.04165
Value Function Update Magnitude: 0.06110

Collected Steps per Second: 11,905.32973
Overall Steps per Second: 10,106.33432

Timestep Collection Time: 4.20148
Timestep Consumption Time: 0.74789
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.94937

Cumulative Model Updates: 8,866
Cumulative Timesteps: 147,997,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.03285
Policy Entropy: 1.33364
Value Function Loss: 1.09713

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06245
Policy Update Magnitude: 0.04006
Value Function Update Magnitude: 0.05044

Collected Steps per Second: 12,607.17790
Overall Steps per Second: 10,486.05577

Timestep Collection Time: 3.96822
Timestep Consumption Time: 0.80269
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.77091

Cumulative Model Updates: 8,869
Cumulative Timesteps: 148,047,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 148047296...
Checkpoint 148047296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.35346
Policy Entropy: 1.33631
Value Function Loss: 0.97292

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04329
Policy Update Magnitude: 0.03881
Value Function Update Magnitude: 0.08014

Collected Steps per Second: 12,576.01665
Overall Steps per Second: 10,443.67870

Timestep Collection Time: 3.97821
Timestep Consumption Time: 0.81225
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 4.79046

Cumulative Model Updates: 8,872
Cumulative Timesteps: 148,097,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.29818
Policy Entropy: 1.33544
Value Function Loss: 0.94027

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06741
Policy Update Magnitude: 0.03933
Value Function Update Magnitude: 0.09411

Collected Steps per Second: 12,328.93850
Overall Steps per Second: 10,515.04070

Timestep Collection Time: 4.05809
Timestep Consumption Time: 0.70004
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.75814

Cumulative Model Updates: 8,875
Cumulative Timesteps: 148,147,358

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 148147358...
Checkpoint 148147358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.97438
Policy Entropy: 1.33523
Value Function Loss: 0.93185

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.04410
Value Function Update Magnitude: 0.09614

Collected Steps per Second: 12,467.21833
Overall Steps per Second: 10,481.41661

Timestep Collection Time: 4.01116
Timestep Consumption Time: 0.75995
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 4.77111

Cumulative Model Updates: 8,878
Cumulative Timesteps: 148,197,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.07964
Policy Entropy: 1.33593
Value Function Loss: 1.04651

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.06037
Policy Update Magnitude: 0.03609
Value Function Update Magnitude: 0.10067

Collected Steps per Second: 13,186.79882
Overall Steps per Second: 11,115.12398

Timestep Collection Time: 3.79395
Timestep Consumption Time: 0.70713
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.50107

Cumulative Model Updates: 8,881
Cumulative Timesteps: 148,247,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 148247396...
Checkpoint 148247396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.74532
Policy Entropy: 1.33543
Value Function Loss: 0.98220

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.07193
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.08079

Collected Steps per Second: 13,047.82864
Overall Steps per Second: 10,813.09241

Timestep Collection Time: 3.83405
Timestep Consumption Time: 0.79238
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.62643

Cumulative Model Updates: 8,884
Cumulative Timesteps: 148,297,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.32933
Policy Entropy: 1.33774
Value Function Loss: 1.06922

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.04068
Value Function Update Magnitude: 0.06779

Collected Steps per Second: 12,557.52824
Overall Steps per Second: 10,421.20890

Timestep Collection Time: 3.98215
Timestep Consumption Time: 0.81633
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 4.79848

Cumulative Model Updates: 8,887
Cumulative Timesteps: 148,347,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 148347428...
Checkpoint 148347428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.78590
Policy Entropy: 1.33898
Value Function Loss: 1.06796

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.05808
Policy Update Magnitude: 0.03661
Value Function Update Magnitude: 0.06269

Collected Steps per Second: 13,023.68881
Overall Steps per Second: 10,714.55557

Timestep Collection Time: 3.84131
Timestep Consumption Time: 0.82785
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.66916

Cumulative Model Updates: 8,890
Cumulative Timesteps: 148,397,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.08586
Policy Entropy: 1.33862
Value Function Loss: 1.10304

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.03790
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 13,385.48831
Overall Steps per Second: 10,992.83976

Timestep Collection Time: 3.73763
Timestep Consumption Time: 0.81351
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.55114

Cumulative Model Updates: 8,893
Cumulative Timesteps: 148,447,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 148447486...
Checkpoint 148447486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.20067
Policy Entropy: 1.34003
Value Function Loss: 1.09876

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.06546
Policy Update Magnitude: 0.03399
Value Function Update Magnitude: 0.05653

Collected Steps per Second: 13,220.57675
Overall Steps per Second: 11,134.40347

Timestep Collection Time: 3.78244
Timestep Consumption Time: 0.70869
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 4.49113

Cumulative Model Updates: 8,896
Cumulative Timesteps: 148,497,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.02102
Policy Entropy: 1.33766
Value Function Loss: 1.12663

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.06919
Policy Update Magnitude: 0.03311
Value Function Update Magnitude: 0.07319

Collected Steps per Second: 12,723.25640
Overall Steps per Second: 10,557.29199

Timestep Collection Time: 3.93091
Timestep Consumption Time: 0.80648
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.73739

Cumulative Model Updates: 8,899
Cumulative Timesteps: 148,547,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 148547506...
Checkpoint 148547506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.58841
Policy Entropy: 1.34224
Value Function Loss: 1.04048

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06405
Policy Update Magnitude: 0.03254
Value Function Update Magnitude: 0.08438

Collected Steps per Second: 12,448.05438
Overall Steps per Second: 10,430.98270

Timestep Collection Time: 4.01701
Timestep Consumption Time: 0.77678
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 4.79380

Cumulative Model Updates: 8,902
Cumulative Timesteps: 148,597,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.38795
Policy Entropy: 1.34000
Value Function Loss: 1.04893

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.06230
Policy Update Magnitude: 0.03607
Value Function Update Magnitude: 0.08091

Collected Steps per Second: 12,190.32015
Overall Steps per Second: 10,261.18471

Timestep Collection Time: 4.10162
Timestep Consumption Time: 0.77112
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.87273

Cumulative Model Updates: 8,905
Cumulative Timesteps: 148,647,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 148647510...
Checkpoint 148647510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.41786
Policy Entropy: 1.34070
Value Function Loss: 1.02125

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.03840
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 12,318.10524
Overall Steps per Second: 10,380.31897

Timestep Collection Time: 4.06004
Timestep Consumption Time: 0.75792
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 4.81796

Cumulative Model Updates: 8,908
Cumulative Timesteps: 148,697,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.15588
Policy Entropy: 1.33789
Value Function Loss: 1.12057

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06655
Policy Update Magnitude: 0.03606
Value Function Update Magnitude: 0.06106

Collected Steps per Second: 12,412.75231
Overall Steps per Second: 10,531.48188

Timestep Collection Time: 4.02940
Timestep Consumption Time: 0.71978
PPO Batch Consumption Time: 0.03783
Total Iteration Time: 4.74919

Cumulative Model Updates: 8,911
Cumulative Timesteps: 148,747,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 148747538...
Checkpoint 148747538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.10520
Policy Entropy: 1.33750
Value Function Loss: 1.09759

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.03621
Value Function Update Magnitude: 0.05404

Collected Steps per Second: 12,467.81839
Overall Steps per Second: 10,429.21639

Timestep Collection Time: 4.01161
Timestep Consumption Time: 0.78415
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 4.79576

Cumulative Model Updates: 8,914
Cumulative Timesteps: 148,797,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.03425
Policy Entropy: 1.33467
Value Function Loss: 1.10749

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06247
Policy Update Magnitude: 0.03617
Value Function Update Magnitude: 0.05024

Collected Steps per Second: 12,028.73891
Overall Steps per Second: 10,289.02991

Timestep Collection Time: 4.15788
Timestep Consumption Time: 0.70303
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 4.86091

Cumulative Model Updates: 8,917
Cumulative Timesteps: 148,847,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 148847568...
Checkpoint 148847568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.17293
Policy Entropy: 1.33799
Value Function Loss: 1.03752

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03571
Policy Update Magnitude: 0.03774
Value Function Update Magnitude: 0.04869

Collected Steps per Second: 12,082.22240
Overall Steps per Second: 10,207.85718

Timestep Collection Time: 4.13980
Timestep Consumption Time: 0.76015
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.89995

Cumulative Model Updates: 8,920
Cumulative Timesteps: 148,897,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.68850
Policy Entropy: 1.33627
Value Function Loss: 1.01570

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03894
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.05576

Collected Steps per Second: 11,613.04590
Overall Steps per Second: 9,909.42853

Timestep Collection Time: 4.30585
Timestep Consumption Time: 0.74026
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.04610

Cumulative Model Updates: 8,923
Cumulative Timesteps: 148,947,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 148947590...
Checkpoint 148947590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.62218
Policy Entropy: 1.33922
Value Function Loss: 0.99335

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04287
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.06717

Collected Steps per Second: 12,502.25964
Overall Steps per Second: 10,421.36598

Timestep Collection Time: 4.00008
Timestep Consumption Time: 0.79872
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.79880

Cumulative Model Updates: 8,926
Cumulative Timesteps: 148,997,600

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.17584
Policy Entropy: 1.33261
Value Function Loss: 1.02260

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04266
Policy Update Magnitude: 0.06819
Value Function Update Magnitude: 0.06350

Collected Steps per Second: 12,488.39310
Overall Steps per Second: 10,470.15821

Timestep Collection Time: 4.00516
Timestep Consumption Time: 0.77204
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.77720

Cumulative Model Updates: 8,929
Cumulative Timesteps: 149,047,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 149047618...
Checkpoint 149047618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.53645
Policy Entropy: 1.33927
Value Function Loss: 1.04561

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05247
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.06420

Collected Steps per Second: 12,264.22639
Overall Steps per Second: 10,503.02293

Timestep Collection Time: 4.07755
Timestep Consumption Time: 0.68375
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 4.76130

Cumulative Model Updates: 8,932
Cumulative Timesteps: 149,097,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.41954
Policy Entropy: 1.33092
Value Function Loss: 1.01708

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07082
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.08050

Collected Steps per Second: 12,526.00505
Overall Steps per Second: 10,477.47735

Timestep Collection Time: 3.99249
Timestep Consumption Time: 0.78060
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 4.77310

Cumulative Model Updates: 8,935
Cumulative Timesteps: 149,147,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 149147636...
Checkpoint 149147636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.37978
Policy Entropy: 1.34090
Value Function Loss: 1.04115

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.08667

Collected Steps per Second: 12,185.80065
Overall Steps per Second: 10,453.91077

Timestep Collection Time: 4.10560
Timestep Consumption Time: 0.68017
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 4.78577

Cumulative Model Updates: 8,938
Cumulative Timesteps: 149,197,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.82482
Policy Entropy: 1.33587
Value Function Loss: 1.05954

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06757
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.09200

Collected Steps per Second: 12,153.96310
Overall Steps per Second: 10,049.23486

Timestep Collection Time: 4.11487
Timestep Consumption Time: 0.86183
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.97670

Cumulative Model Updates: 8,941
Cumulative Timesteps: 149,247,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 149247678...
Checkpoint 149247678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.70435
Policy Entropy: 1.33852
Value Function Loss: 1.02664

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05709
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.07496

Collected Steps per Second: 11,788.41950
Overall Steps per Second: 10,043.53443

Timestep Collection Time: 4.24383
Timestep Consumption Time: 0.73729
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.98111

Cumulative Model Updates: 8,944
Cumulative Timesteps: 149,297,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.82389
Policy Entropy: 1.33902
Value Function Loss: 0.99523

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06085
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 10,362.21587
Overall Steps per Second: 8,909.19523

Timestep Collection Time: 4.82792
Timestep Consumption Time: 0.78740
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.61532

Cumulative Model Updates: 8,947
Cumulative Timesteps: 149,347,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 149347734...
Checkpoint 149347734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.78100
Policy Entropy: 1.33569
Value Function Loss: 0.94269

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06213
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.07500

Collected Steps per Second: 12,167.90039
Overall Steps per Second: 10,268.49775

Timestep Collection Time: 4.11098
Timestep Consumption Time: 0.76042
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 4.87140

Cumulative Model Updates: 8,950
Cumulative Timesteps: 149,397,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.58325
Policy Entropy: 1.33964
Value Function Loss: 1.01611

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05327
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.08067

Collected Steps per Second: 12,710.54007
Overall Steps per Second: 10,656.48143

Timestep Collection Time: 3.93610
Timestep Consumption Time: 0.75869
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.69480

Cumulative Model Updates: 8,953
Cumulative Timesteps: 149,447,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 149447786...
Checkpoint 149447786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.68222
Policy Entropy: 1.33652
Value Function Loss: 1.02800

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04680
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.07360

Collected Steps per Second: 12,682.32458
Overall Steps per Second: 10,596.57869

Timestep Collection Time: 3.94328
Timestep Consumption Time: 0.77616
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 4.71945

Cumulative Model Updates: 8,956
Cumulative Timesteps: 149,497,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.66962
Policy Entropy: 1.33818
Value Function Loss: 1.02738

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03691
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.05495

Collected Steps per Second: 13,239.69740
Overall Steps per Second: 10,843.60836

Timestep Collection Time: 3.77713
Timestep Consumption Time: 0.83462
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.61175

Cumulative Model Updates: 8,959
Cumulative Timesteps: 149,547,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 149547804...
Checkpoint 149547804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.31894
Policy Entropy: 1.33810
Value Function Loss: 0.99530

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.06387
Value Function Update Magnitude: 0.04662

Collected Steps per Second: 12,631.76626
Overall Steps per Second: 10,556.63648

Timestep Collection Time: 3.96065
Timestep Consumption Time: 0.77855
PPO Batch Consumption Time: 0.03351
Total Iteration Time: 4.73920

Cumulative Model Updates: 8,962
Cumulative Timesteps: 149,597,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.09316
Policy Entropy: 1.33913
Value Function Loss: 0.94518

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03210
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.06839

Collected Steps per Second: 12,691.10388
Overall Steps per Second: 10,858.21765

Timestep Collection Time: 3.93993
Timestep Consumption Time: 0.66507
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 4.60499

Cumulative Model Updates: 8,965
Cumulative Timesteps: 149,647,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 149647836...
Checkpoint 149647836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.09148
Policy Entropy: 1.33259
Value Function Loss: 1.01995

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05105
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.08605

Collected Steps per Second: 12,650.18842
Overall Steps per Second: 10,521.38172

Timestep Collection Time: 3.95314
Timestep Consumption Time: 0.79985
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.75299

Cumulative Model Updates: 8,968
Cumulative Timesteps: 149,697,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.71946
Policy Entropy: 1.33368
Value Function Loss: 1.04337

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03879
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.07723

Collected Steps per Second: 12,766.63902
Overall Steps per Second: 10,696.81419

Timestep Collection Time: 3.91708
Timestep Consumption Time: 0.75795
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 4.67504

Cumulative Model Updates: 8,971
Cumulative Timesteps: 149,747,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 149747852...
Checkpoint 149747852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.11521
Policy Entropy: 1.32748
Value Function Loss: 1.12258

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.07440
Value Function Update Magnitude: 0.07219

Collected Steps per Second: 12,895.07205
Overall Steps per Second: 10,748.40058

Timestep Collection Time: 3.87931
Timestep Consumption Time: 0.77478
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 4.65409

Cumulative Model Updates: 8,974
Cumulative Timesteps: 149,797,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.47059
Policy Entropy: 1.33330
Value Function Loss: 1.02978

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.08379
Value Function Update Magnitude: 0.06528

Collected Steps per Second: 12,452.61347
Overall Steps per Second: 10,296.58815

Timestep Collection Time: 4.01538
Timestep Consumption Time: 0.84079
PPO Batch Consumption Time: 0.03838
Total Iteration Time: 4.85617

Cumulative Model Updates: 8,977
Cumulative Timesteps: 149,847,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 149847878...
Checkpoint 149847878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.64314
Policy Entropy: 1.33007
Value Function Loss: 1.01375

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04564
Policy Update Magnitude: 0.07267
Value Function Update Magnitude: 0.06253

Collected Steps per Second: 11,815.33872
Overall Steps per Second: 10,203.83541

Timestep Collection Time: 4.23399
Timestep Consumption Time: 0.66868
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.90267

Cumulative Model Updates: 8,980
Cumulative Timesteps: 149,897,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.56157
Policy Entropy: 1.33458
Value Function Loss: 0.93478

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.04993
Policy Update Magnitude: 0.06303
Value Function Update Magnitude: 0.08092

Collected Steps per Second: 12,472.54032
Overall Steps per Second: 10,380.62557

Timestep Collection Time: 4.00929
Timestep Consumption Time: 0.80796
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.81724

Cumulative Model Updates: 8,983
Cumulative Timesteps: 149,947,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 149947910...
Checkpoint 149947910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.08612
Policy Entropy: 1.33327
Value Function Loss: 0.91510

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03953
Policy Update Magnitude: 0.06468
Value Function Update Magnitude: 0.08530

Collected Steps per Second: 12,302.85426
Overall Steps per Second: 10,537.90374

Timestep Collection Time: 4.06572
Timestep Consumption Time: 0.68095
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.74667

Cumulative Model Updates: 8,986
Cumulative Timesteps: 149,997,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.97402
Policy Entropy: 1.33363
Value Function Loss: 0.89156

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05465
Policy Update Magnitude: 0.06925
Value Function Update Magnitude: 0.08434

Collected Steps per Second: 12,852.41680
Overall Steps per Second: 10,650.69778

Timestep Collection Time: 3.89032
Timestep Consumption Time: 0.80421
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.69453

Cumulative Model Updates: 8,989
Cumulative Timesteps: 150,047,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 150047930...
Checkpoint 150047930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.56406
Policy Entropy: 1.32827
Value Function Loss: 0.98306

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05883
Policy Update Magnitude: 0.08277
Value Function Update Magnitude: 0.08759

Collected Steps per Second: 12,633.53844
Overall Steps per Second: 10,618.45124

Timestep Collection Time: 3.95978
Timestep Consumption Time: 0.75146
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.71123

Cumulative Model Updates: 8,992
Cumulative Timesteps: 150,097,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.72111
Policy Entropy: 1.33002
Value Function Loss: 0.97941

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03953
Policy Update Magnitude: 0.06543
Value Function Update Magnitude: 0.08324

Collected Steps per Second: 12,971.15160
Overall Steps per Second: 10,867.83427

Timestep Collection Time: 3.85548
Timestep Consumption Time: 0.74617
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.60165

Cumulative Model Updates: 8,995
Cumulative Timesteps: 150,147,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 150147966...
Checkpoint 150147966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.21776
Policy Entropy: 1.32055
Value Function Loss: 1.05653

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06642
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.08609

Collected Steps per Second: 11,793.90063
Overall Steps per Second: 10,016.64815

Timestep Collection Time: 4.24033
Timestep Consumption Time: 0.75236
PPO Batch Consumption Time: 0.03401
Total Iteration Time: 4.99269

Cumulative Model Updates: 8,998
Cumulative Timesteps: 150,197,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.68071
Policy Entropy: 1.32457
Value Function Loss: 1.00060

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02049
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.08765

Collected Steps per Second: 12,494.34463
Overall Steps per Second: 10,682.01790

Timestep Collection Time: 4.00261
Timestep Consumption Time: 0.67909
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.68170

Cumulative Model Updates: 9,001
Cumulative Timesteps: 150,247,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 150247986...
Checkpoint 150247986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.90254
Policy Entropy: 1.32249
Value Function Loss: 1.09210

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03999
Policy Update Magnitude: 0.08280
Value Function Update Magnitude: 0.07889

Collected Steps per Second: 12,294.61947
Overall Steps per Second: 10,372.91584

Timestep Collection Time: 4.06828
Timestep Consumption Time: 0.75370
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.82198

Cumulative Model Updates: 9,004
Cumulative Timesteps: 150,298,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.27594
Policy Entropy: 1.32625
Value Function Loss: 1.10517

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05704
Policy Update Magnitude: 0.07316
Value Function Update Magnitude: 0.06250

Collected Steps per Second: 12,173.46375
Overall Steps per Second: 10,321.94031

Timestep Collection Time: 4.10812
Timestep Consumption Time: 0.73690
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 4.84502

Cumulative Model Updates: 9,007
Cumulative Timesteps: 150,348,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 150348014...
Checkpoint 150348014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.32715
Policy Entropy: 1.32548
Value Function Loss: 1.08733

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05304
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.04877

Collected Steps per Second: 12,468.63207
Overall Steps per Second: 10,367.68890

Timestep Collection Time: 4.01070
Timestep Consumption Time: 0.81274
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 4.82345

Cumulative Model Updates: 9,010
Cumulative Timesteps: 150,398,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.52702
Policy Entropy: 1.32606
Value Function Loss: 1.06423

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05201
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.06607

Collected Steps per Second: 12,298.77848
Overall Steps per Second: 10,255.65226

Timestep Collection Time: 4.06642
Timestep Consumption Time: 0.81011
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 4.87653

Cumulative Model Updates: 9,013
Cumulative Timesteps: 150,448,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 150448034...
Checkpoint 150448034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.07018
Policy Entropy: 1.32876
Value Function Loss: 1.02731

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04780
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.06247

Collected Steps per Second: 12,276.73695
Overall Steps per Second: 10,402.34810

Timestep Collection Time: 4.07356
Timestep Consumption Time: 0.73401
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.80757

Cumulative Model Updates: 9,016
Cumulative Timesteps: 150,498,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.27930
Policy Entropy: 1.32785
Value Function Loss: 0.98997

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04513
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.05850

Collected Steps per Second: 12,524.55007
Overall Steps per Second: 10,547.22328

Timestep Collection Time: 3.99424
Timestep Consumption Time: 0.74881
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 4.74305

Cumulative Model Updates: 9,019
Cumulative Timesteps: 150,548,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 150548070...
Checkpoint 150548070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.21005
Policy Entropy: 1.32983
Value Function Loss: 0.94967

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04472
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.06986

Collected Steps per Second: 12,310.27344
Overall Steps per Second: 10,222.82872

Timestep Collection Time: 4.06262
Timestep Consumption Time: 0.82957
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.89219

Cumulative Model Updates: 9,022
Cumulative Timesteps: 150,598,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.49311
Policy Entropy: 1.32852
Value Function Loss: 0.97772

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03656
Policy Update Magnitude: 0.06071
Value Function Update Magnitude: 0.08329

Collected Steps per Second: 12,751.52339
Overall Steps per Second: 10,591.35077

Timestep Collection Time: 3.92314
Timestep Consumption Time: 0.80015
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 4.72329

Cumulative Model Updates: 9,025
Cumulative Timesteps: 150,648,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 150648108...
Checkpoint 150648108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.50164
Policy Entropy: 1.33068
Value Function Loss: 1.00001

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04113
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.07893

Collected Steps per Second: 12,513.57478
Overall Steps per Second: 10,379.01109

Timestep Collection Time: 3.99758
Timestep Consumption Time: 0.82215
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 4.81973

Cumulative Model Updates: 9,028
Cumulative Timesteps: 150,698,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.20801
Policy Entropy: 1.33087
Value Function Loss: 0.98429

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03551
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.06538

Collected Steps per Second: 12,765.84372
Overall Steps per Second: 10,816.40897

Timestep Collection Time: 3.91748
Timestep Consumption Time: 0.70605
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 4.62353

Cumulative Model Updates: 9,031
Cumulative Timesteps: 150,748,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 150748142...
Checkpoint 150748142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.56904
Policy Entropy: 1.32998
Value Function Loss: 0.96656

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.04824
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 13,231.10167
Overall Steps per Second: 10,975.79778

Timestep Collection Time: 3.78124
Timestep Consumption Time: 0.77697
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.55821

Cumulative Model Updates: 9,034
Cumulative Timesteps: 150,798,172

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.62508
Policy Entropy: 1.32932
Value Function Loss: 0.98054

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04025
Policy Update Magnitude: 0.06762
Value Function Update Magnitude: 0.05578

Collected Steps per Second: 12,309.55988
Overall Steps per Second: 10,312.19424

Timestep Collection Time: 4.06221
Timestep Consumption Time: 0.78681
PPO Batch Consumption Time: 0.03331
Total Iteration Time: 4.84902

Cumulative Model Updates: 9,037
Cumulative Timesteps: 150,848,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 150848176...
Checkpoint 150848176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.87282
Policy Entropy: 1.33051
Value Function Loss: 0.93718

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05413
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.05455

Collected Steps per Second: 12,711.41981
Overall Steps per Second: 10,489.79498

Timestep Collection Time: 3.93426
Timestep Consumption Time: 0.83323
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 4.76749

Cumulative Model Updates: 9,040
Cumulative Timesteps: 150,898,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.22362
Policy Entropy: 1.32213
Value Function Loss: 0.89186

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07209
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.05034

Collected Steps per Second: 13,264.15799
Overall Steps per Second: 10,938.90728

Timestep Collection Time: 3.77152
Timestep Consumption Time: 0.80170
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 4.57322

Cumulative Model Updates: 9,043
Cumulative Timesteps: 150,948,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 150948212...
Checkpoint 150948212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.88620
Policy Entropy: 1.32357
Value Function Loss: 0.94583

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05012
Policy Update Magnitude: 0.06409
Value Function Update Magnitude: 0.04668

Collected Steps per Second: 12,832.90314
Overall Steps per Second: 10,865.27483

Timestep Collection Time: 3.89686
Timestep Consumption Time: 0.70569
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.60255

Cumulative Model Updates: 9,046
Cumulative Timesteps: 150,998,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.36148
Policy Entropy: 1.32311
Value Function Loss: 0.97303

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06329
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.05555

Collected Steps per Second: 12,944.10705
Overall Steps per Second: 10,785.96806

Timestep Collection Time: 3.86384
Timestep Consumption Time: 0.77311
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.63695

Cumulative Model Updates: 9,049
Cumulative Timesteps: 151,048,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 151048234...
Checkpoint 151048234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.00377
Policy Entropy: 1.32137
Value Function Loss: 1.00982

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.04850
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.05139

Collected Steps per Second: 12,527.86590
Overall Steps per Second: 10,581.59798

Timestep Collection Time: 3.99238
Timestep Consumption Time: 0.73432
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 4.72670

Cumulative Model Updates: 9,052
Cumulative Timesteps: 151,098,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.54544
Policy Entropy: 1.32142
Value Function Loss: 1.02229

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.05823
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.05811

Collected Steps per Second: 11,993.49521
Overall Steps per Second: 10,098.52962

Timestep Collection Time: 4.17009
Timestep Consumption Time: 0.78251
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 4.95260

Cumulative Model Updates: 9,055
Cumulative Timesteps: 151,148,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 151148264...
Checkpoint 151148264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.69440
Policy Entropy: 1.32172
Value Function Loss: 1.05381

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04495
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.06475

Collected Steps per Second: 12,442.18646
Overall Steps per Second: 10,484.39349

Timestep Collection Time: 4.01971
Timestep Consumption Time: 0.75062
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.77033

Cumulative Model Updates: 9,058
Cumulative Timesteps: 151,198,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.48711
Policy Entropy: 1.32104
Value Function Loss: 1.01220

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04513
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.06414

Collected Steps per Second: 12,805.63165
Overall Steps per Second: 10,764.97443

Timestep Collection Time: 3.90547
Timestep Consumption Time: 0.74034
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.64581

Cumulative Model Updates: 9,061
Cumulative Timesteps: 151,248,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 151248290...
Checkpoint 151248290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.45047
Policy Entropy: 1.32338
Value Function Loss: 0.92970

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04001
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.05830

Collected Steps per Second: 12,627.14851
Overall Steps per Second: 10,511.67300

Timestep Collection Time: 3.96226
Timestep Consumption Time: 0.79740
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.75966

Cumulative Model Updates: 9,064
Cumulative Timesteps: 151,298,322

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.17498
Policy Entropy: 1.31933
Value Function Loss: 0.92449

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04859
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.06822

Collected Steps per Second: 12,497.34994
Overall Steps per Second: 10,532.06963

Timestep Collection Time: 4.00085
Timestep Consumption Time: 0.74656
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 4.74741

Cumulative Model Updates: 9,067
Cumulative Timesteps: 151,348,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 151348322...
Checkpoint 151348322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.83536
Policy Entropy: 1.32234
Value Function Loss: 0.98460

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04081
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.05814

Collected Steps per Second: 12,623.82099
Overall Steps per Second: 10,576.14221

Timestep Collection Time: 3.96219
Timestep Consumption Time: 0.76713
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.72932

Cumulative Model Updates: 9,070
Cumulative Timesteps: 151,398,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.37952
Policy Entropy: 1.31607
Value Function Loss: 1.00023

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05646
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.04702

Collected Steps per Second: 12,170.70816
Overall Steps per Second: 10,176.10177

Timestep Collection Time: 4.11003
Timestep Consumption Time: 0.80560
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.91563

Cumulative Model Updates: 9,073
Cumulative Timesteps: 151,448,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 151448362...
Checkpoint 151448362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.31775
Policy Entropy: 1.31597
Value Function Loss: 0.99107

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04307
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.04540

Collected Steps per Second: 12,569.00478
Overall Steps per Second: 10,530.17582

Timestep Collection Time: 3.97804
Timestep Consumption Time: 0.77022
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 4.74826

Cumulative Model Updates: 9,076
Cumulative Timesteps: 151,498,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.02099
Policy Entropy: 1.31297
Value Function Loss: 1.00100

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05020
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.04524

Collected Steps per Second: 12,945.67970
Overall Steps per Second: 10,883.08116

Timestep Collection Time: 3.86368
Timestep Consumption Time: 0.73226
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.59594

Cumulative Model Updates: 9,079
Cumulative Timesteps: 151,548,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 151548380...
Checkpoint 151548380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.91239
Policy Entropy: 1.31419
Value Function Loss: 0.95484

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03394
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.04066

Collected Steps per Second: 12,614.33825
Overall Steps per Second: 10,537.08250

Timestep Collection Time: 3.96406
Timestep Consumption Time: 0.78147
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 4.74553

Cumulative Model Updates: 9,082
Cumulative Timesteps: 151,598,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.37374
Policy Entropy: 1.31283
Value Function Loss: 0.98006

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05665
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.04123

Collected Steps per Second: 12,307.72351
Overall Steps per Second: 10,526.03199

Timestep Collection Time: 4.06346
Timestep Consumption Time: 0.68780
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.75127

Cumulative Model Updates: 9,085
Cumulative Timesteps: 151,648,396

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 151648396...
Checkpoint 151648396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.48619
Policy Entropy: 1.31127
Value Function Loss: 0.95313

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04010
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.03753

Collected Steps per Second: 12,267.55215
Overall Steps per Second: 10,283.83741

Timestep Collection Time: 4.07661
Timestep Consumption Time: 0.78636
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 4.86297

Cumulative Model Updates: 9,088
Cumulative Timesteps: 151,698,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.11764
Policy Entropy: 1.30883
Value Function Loss: 0.97496

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06057
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.03671

Collected Steps per Second: 12,550.03664
Overall Steps per Second: 10,559.21837

Timestep Collection Time: 3.98453
Timestep Consumption Time: 0.75124
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 4.73577

Cumulative Model Updates: 9,091
Cumulative Timesteps: 151,748,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 151748412...
Checkpoint 151748412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.35684
Policy Entropy: 1.30942
Value Function Loss: 0.97020

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03273
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.03316

Collected Steps per Second: 12,348.64126
Overall Steps per Second: 10,402.75446

Timestep Collection Time: 4.05097
Timestep Consumption Time: 0.75775
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.80873

Cumulative Model Updates: 9,094
Cumulative Timesteps: 151,798,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.27763
Policy Entropy: 1.31261
Value Function Loss: 1.01121

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05219
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.03282

Collected Steps per Second: 12,250.79462
Overall Steps per Second: 10,344.20723

Timestep Collection Time: 4.08284
Timestep Consumption Time: 0.75253
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.83536

Cumulative Model Updates: 9,097
Cumulative Timesteps: 151,848,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 151848454...
Checkpoint 151848454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.21584
Policy Entropy: 1.31039
Value Function Loss: 0.99188

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 0.06292
Value Function Update Magnitude: 0.06366

Collected Steps per Second: 12,091.43838
Overall Steps per Second: 10,276.56288

Timestep Collection Time: 4.13714
Timestep Consumption Time: 0.73063
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.86778

Cumulative Model Updates: 9,100
Cumulative Timesteps: 151,898,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.80513
Policy Entropy: 1.31237
Value Function Loss: 1.02477

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05281
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.05249

Collected Steps per Second: 12,543.25571
Overall Steps per Second: 10,490.86411

Timestep Collection Time: 3.98684
Timestep Consumption Time: 0.77997
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.76681

Cumulative Model Updates: 9,103
Cumulative Timesteps: 151,948,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 151948486...
Checkpoint 151948486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.61804
Policy Entropy: 1.30962
Value Function Loss: 1.00060

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03724
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.04186

Collected Steps per Second: 12,322.19966
Overall Steps per Second: 10,445.41070

Timestep Collection Time: 4.05999
Timestep Consumption Time: 0.72948
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 4.78947

Cumulative Model Updates: 9,106
Cumulative Timesteps: 151,998,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.00584
Policy Entropy: 1.31140
Value Function Loss: 1.01008

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04880
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.04278

Collected Steps per Second: 12,822.28772
Overall Steps per Second: 10,617.92214

Timestep Collection Time: 3.90055
Timestep Consumption Time: 0.80979
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 4.71034

Cumulative Model Updates: 9,109
Cumulative Timesteps: 152,048,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 152048528...
Checkpoint 152048528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.50124
Policy Entropy: 1.30759
Value Function Loss: 0.99291

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04553
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.03891

Collected Steps per Second: 11,905.14084
Overall Steps per Second: 10,137.73871

Timestep Collection Time: 4.20037
Timestep Consumption Time: 0.73229
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 4.93266

Cumulative Model Updates: 9,112
Cumulative Timesteps: 152,098,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.89857
Policy Entropy: 1.30956
Value Function Loss: 0.97966

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05073
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.06062

Collected Steps per Second: 12,945.79074
Overall Steps per Second: 10,724.25636

Timestep Collection Time: 3.86303
Timestep Consumption Time: 0.80023
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.66326

Cumulative Model Updates: 9,115
Cumulative Timesteps: 152,148,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 152148544...
Checkpoint 152148544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.92639
Policy Entropy: 1.30574
Value Function Loss: 1.06454

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04988
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.07315

Collected Steps per Second: 10,998.25006
Overall Steps per Second: 9,331.54267

Timestep Collection Time: 4.54781
Timestep Consumption Time: 0.81229
PPO Batch Consumption Time: 0.03400
Total Iteration Time: 5.36010

Cumulative Model Updates: 9,118
Cumulative Timesteps: 152,198,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.92421
Policy Entropy: 1.30986
Value Function Loss: 1.04429

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06092
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.05483

Collected Steps per Second: 10,454.41487
Overall Steps per Second: 9,077.75886

Timestep Collection Time: 4.78458
Timestep Consumption Time: 0.72559
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.51017

Cumulative Model Updates: 9,121
Cumulative Timesteps: 152,248,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 152248582...
Checkpoint 152248582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.72351
Policy Entropy: 1.30857
Value Function Loss: 0.98081

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 0.07162
Value Function Update Magnitude: 0.05155

Collected Steps per Second: 11,362.72686
Overall Steps per Second: 9,604.38576

Timestep Collection Time: 4.40176
Timestep Consumption Time: 0.80586
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.20762

Cumulative Model Updates: 9,124
Cumulative Timesteps: 152,298,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.70504
Policy Entropy: 1.31218
Value Function Loss: 0.87785

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04830
Policy Update Magnitude: 0.07044
Value Function Update Magnitude: 0.04456

Collected Steps per Second: 10,301.66069
Overall Steps per Second: 8,745.12186

Timestep Collection Time: 4.85592
Timestep Consumption Time: 0.86430
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.72022

Cumulative Model Updates: 9,127
Cumulative Timesteps: 152,348,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 152348622...
Checkpoint 152348622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.72748
Policy Entropy: 1.30892
Value Function Loss: 0.87381

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.03813

Collected Steps per Second: 11,404.67462
Overall Steps per Second: 9,415.54169

Timestep Collection Time: 4.38504
Timestep Consumption Time: 0.92639
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 5.31143

Cumulative Model Updates: 9,130
Cumulative Timesteps: 152,398,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.18671
Policy Entropy: 1.30812
Value Function Loss: 0.90465

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07069
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.04871

Collected Steps per Second: 10,470.02170
Overall Steps per Second: 8,898.70746

Timestep Collection Time: 4.77649
Timestep Consumption Time: 0.84342
PPO Batch Consumption Time: 0.03835
Total Iteration Time: 5.61992

Cumulative Model Updates: 9,133
Cumulative Timesteps: 152,448,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 152448642...
Checkpoint 152448642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.92429
Policy Entropy: 1.30877
Value Function Loss: 0.90504

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06888
Policy Update Magnitude: 0.03980
Value Function Update Magnitude: 0.04061

Collected Steps per Second: 11,051.97632
Overall Steps per Second: 9,257.56982

Timestep Collection Time: 4.52426
Timestep Consumption Time: 0.87694
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.40120

Cumulative Model Updates: 9,136
Cumulative Timesteps: 152,498,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.53893
Policy Entropy: 1.31179
Value Function Loss: 0.91198

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06049
Policy Update Magnitude: 0.03829
Value Function Update Magnitude: 0.04994

Collected Steps per Second: 11,255.32039
Overall Steps per Second: 9,453.76523

Timestep Collection Time: 4.44394
Timestep Consumption Time: 0.84686
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 5.29080

Cumulative Model Updates: 9,139
Cumulative Timesteps: 152,548,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 152548662...
Checkpoint 152548662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.53850
Policy Entropy: 1.31046
Value Function Loss: 0.97139

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06293
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.05454

Collected Steps per Second: 11,854.40470
Overall Steps per Second: 9,937.59972

Timestep Collection Time: 4.21919
Timestep Consumption Time: 0.81381
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 5.03301

Cumulative Model Updates: 9,142
Cumulative Timesteps: 152,598,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.68112
Policy Entropy: 1.31194
Value Function Loss: 1.01679

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05235
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.05083

Collected Steps per Second: 11,488.23722
Overall Steps per Second: 9,850.16685

Timestep Collection Time: 4.35454
Timestep Consumption Time: 0.72415
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 5.07870

Cumulative Model Updates: 9,145
Cumulative Timesteps: 152,648,704

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 152648704...
Checkpoint 152648704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.24361
Policy Entropy: 1.31134
Value Function Loss: 0.99080

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05689
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.07456

Collected Steps per Second: 11,895.29514
Overall Steps per Second: 10,017.47148

Timestep Collection Time: 4.20368
Timestep Consumption Time: 0.78800
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 4.99168

Cumulative Model Updates: 9,148
Cumulative Timesteps: 152,698,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.01301
Policy Entropy: 1.31189
Value Function Loss: 0.96610

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05285
Policy Update Magnitude: 0.03935
Value Function Update Magnitude: 0.09426

Collected Steps per Second: 11,578.18926
Overall Steps per Second: 9,732.63464

Timestep Collection Time: 4.32088
Timestep Consumption Time: 0.81935
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.14023

Cumulative Model Updates: 9,151
Cumulative Timesteps: 152,748,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 152748736...
Checkpoint 152748736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.42645
Policy Entropy: 1.31303
Value Function Loss: 1.01970

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04760
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.07977

Collected Steps per Second: 11,309.87497
Overall Steps per Second: 9,630.34086

Timestep Collection Time: 4.42109
Timestep Consumption Time: 0.77104
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.19213

Cumulative Model Updates: 9,154
Cumulative Timesteps: 152,798,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.25891
Policy Entropy: 1.30870
Value Function Loss: 1.08892

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05937
Policy Update Magnitude: 0.03909
Value Function Update Magnitude: 0.07208

Collected Steps per Second: 11,231.28452
Overall Steps per Second: 9,462.66254

Timestep Collection Time: 4.45345
Timestep Consumption Time: 0.83237
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.28583

Cumulative Model Updates: 9,157
Cumulative Timesteps: 152,848,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 152848756...
Checkpoint 152848756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.60428
Policy Entropy: 1.31190
Value Function Loss: 1.06923

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04815
Policy Update Magnitude: 0.03829
Value Function Update Magnitude: 0.06247

Collected Steps per Second: 11,366.88949
Overall Steps per Second: 9,596.28242

Timestep Collection Time: 4.39962
Timestep Consumption Time: 0.81177
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.21139

Cumulative Model Updates: 9,160
Cumulative Timesteps: 152,898,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.40553
Policy Entropy: 1.30591
Value Function Loss: 1.00272

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05131
Policy Update Magnitude: 0.03613
Value Function Update Magnitude: 0.05698

Collected Steps per Second: 10,892.17785
Overall Steps per Second: 9,256.91915

Timestep Collection Time: 4.59247
Timestep Consumption Time: 0.81127
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 5.40374

Cumulative Model Updates: 9,163
Cumulative Timesteps: 152,948,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 152948788...
Checkpoint 152948788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.80396
Policy Entropy: 1.30784
Value Function Loss: 0.93709

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04887
Policy Update Magnitude: 0.04087
Value Function Update Magnitude: 0.08086

Collected Steps per Second: 11,070.10662
Overall Steps per Second: 9,559.00445

Timestep Collection Time: 4.51847
Timestep Consumption Time: 0.71429
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.23276

Cumulative Model Updates: 9,166
Cumulative Timesteps: 152,998,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.28097
Policy Entropy: 1.30560
Value Function Loss: 0.98226

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05287
Policy Update Magnitude: 0.03854
Value Function Update Magnitude: 0.07977

Collected Steps per Second: 11,133.09703
Overall Steps per Second: 9,374.73451

Timestep Collection Time: 4.49399
Timestep Consumption Time: 0.84291
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.33690

Cumulative Model Updates: 9,169
Cumulative Timesteps: 153,048,840

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 153048840...
Checkpoint 153048840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.40118
Policy Entropy: 1.30369
Value Function Loss: 0.95942

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05481
Policy Update Magnitude: 0.03927
Value Function Update Magnitude: 0.06568

Collected Steps per Second: 11,313.06498
Overall Steps per Second: 9,622.27243

Timestep Collection Time: 4.42197
Timestep Consumption Time: 0.77701
PPO Batch Consumption Time: 0.03751
Total Iteration Time: 5.19898

Cumulative Model Updates: 9,172
Cumulative Timesteps: 153,098,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.41310
Policy Entropy: 1.30520
Value Function Loss: 0.98424

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04711
Policy Update Magnitude: 0.03776
Value Function Update Magnitude: 0.06045

Collected Steps per Second: 11,532.30990
Overall Steps per Second: 9,870.39491

Timestep Collection Time: 4.33599
Timestep Consumption Time: 0.73007
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.06606

Cumulative Model Updates: 9,175
Cumulative Timesteps: 153,148,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 153148870...
Checkpoint 153148870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.99226
Policy Entropy: 1.29925
Value Function Loss: 0.98826

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05316
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.05106

Collected Steps per Second: 12,239.03762
Overall Steps per Second: 10,125.83556

Timestep Collection Time: 4.08627
Timestep Consumption Time: 0.85278
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 4.93905

Cumulative Model Updates: 9,178
Cumulative Timesteps: 153,198,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.11621
Policy Entropy: 1.30308
Value Function Loss: 0.97945

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06167
Policy Update Magnitude: 0.04068
Value Function Update Magnitude: 0.06513

Collected Steps per Second: 10,895.38511
Overall Steps per Second: 9,433.92009

Timestep Collection Time: 4.59020
Timestep Consumption Time: 0.71110
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.30130

Cumulative Model Updates: 9,181
Cumulative Timesteps: 153,248,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 153248894...
Checkpoint 153248894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.60085
Policy Entropy: 1.29369
Value Function Loss: 0.95166

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.07723

Collected Steps per Second: 12,331.46328
Overall Steps per Second: 10,242.62565

Timestep Collection Time: 4.05645
Timestep Consumption Time: 0.82726
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.88371

Cumulative Model Updates: 9,184
Cumulative Timesteps: 153,298,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.53738
Policy Entropy: 1.29771
Value Function Loss: 0.91906

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05855
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.11122

Collected Steps per Second: 12,010.88339
Overall Steps per Second: 10,146.09109

Timestep Collection Time: 4.16356
Timestep Consumption Time: 0.76524
PPO Batch Consumption Time: 0.03292
Total Iteration Time: 4.92879

Cumulative Model Updates: 9,187
Cumulative Timesteps: 153,348,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 153348924...
Checkpoint 153348924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.37210
Policy Entropy: 1.28966
Value Function Loss: 0.95049

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.11394

Collected Steps per Second: 11,091.71907
Overall Steps per Second: 8,994.13542

Timestep Collection Time: 4.51021
Timestep Consumption Time: 1.05186
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 5.56207

Cumulative Model Updates: 9,190
Cumulative Timesteps: 153,398,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.77322
Policy Entropy: 1.29116
Value Function Loss: 0.90994

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.10115

Collected Steps per Second: 10,068.51320
Overall Steps per Second: 8,339.04750

Timestep Collection Time: 4.96697
Timestep Consumption Time: 1.03012
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.99709

Cumulative Model Updates: 9,193
Cumulative Timesteps: 153,448,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 153448960...
Checkpoint 153448960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.14937
Policy Entropy: 1.29612
Value Function Loss: 0.84885

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.03958
Value Function Update Magnitude: 0.09157

Collected Steps per Second: 9,945.56746
Overall Steps per Second: 8,478.24202

Timestep Collection Time: 5.02837
Timestep Consumption Time: 0.87026
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.89863

Cumulative Model Updates: 9,196
Cumulative Timesteps: 153,498,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.10319
Policy Entropy: 1.29025
Value Function Loss: 0.84835

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.03610
Value Function Update Magnitude: 0.09928

Collected Steps per Second: 10,367.37456
Overall Steps per Second: 8,865.43538

Timestep Collection Time: 4.82437
Timestep Consumption Time: 0.81732
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.64169

Cumulative Model Updates: 9,199
Cumulative Timesteps: 153,548,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 153548986...
Checkpoint 153548986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.46279
Policy Entropy: 1.29797
Value Function Loss: 0.89599

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.03287
Value Function Update Magnitude: 0.10441

Collected Steps per Second: 9,923.48003
Overall Steps per Second: 8,218.55292

Timestep Collection Time: 5.04138
Timestep Consumption Time: 1.04583
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 6.08720

Cumulative Model Updates: 9,202
Cumulative Timesteps: 153,599,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.33815
Policy Entropy: 1.29678
Value Function Loss: 0.95948

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.03545
Value Function Update Magnitude: 0.10370

Collected Steps per Second: 9,891.68185
Overall Steps per Second: 8,653.17667

Timestep Collection Time: 5.05758
Timestep Consumption Time: 0.72388
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.78146

Cumulative Model Updates: 9,205
Cumulative Timesteps: 153,649,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 153649042...
Checkpoint 153649042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.00488
Policy Entropy: 1.29313
Value Function Loss: 1.04373

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.03626
Value Function Update Magnitude: 0.11328

Collected Steps per Second: 11,309.92093
Overall Steps per Second: 9,563.48744

Timestep Collection Time: 4.42337
Timestep Consumption Time: 0.80777
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 5.23115

Cumulative Model Updates: 9,208
Cumulative Timesteps: 153,699,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.54429
Policy Entropy: 1.29546
Value Function Loss: 1.09442

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.03187
Value Function Update Magnitude: 0.08895

Collected Steps per Second: 11,484.44936
Overall Steps per Second: 9,884.54895

Timestep Collection Time: 4.35441
Timestep Consumption Time: 0.70480
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.05921

Cumulative Model Updates: 9,211
Cumulative Timesteps: 153,749,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 153749078...
Checkpoint 153749078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.87090
Policy Entropy: 1.29151
Value Function Loss: 1.06736

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.03404
Value Function Update Magnitude: 0.06796

Collected Steps per Second: 11,348.24975
Overall Steps per Second: 9,604.60671

Timestep Collection Time: 4.40790
Timestep Consumption Time: 0.80022
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.20813

Cumulative Model Updates: 9,214
Cumulative Timesteps: 153,799,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.88593
Policy Entropy: 1.29405
Value Function Loss: 0.96708

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.03230
Value Function Update Magnitude: 0.05369

Collected Steps per Second: 11,865.91023
Overall Steps per Second: 10,019.89210

Timestep Collection Time: 4.21392
Timestep Consumption Time: 0.77635
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 4.99027

Cumulative Model Updates: 9,217
Cumulative Timesteps: 153,849,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 153849102...
Checkpoint 153849102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.39555
Policy Entropy: 1.29994
Value Function Loss: 0.93044

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.03402
Value Function Update Magnitude: 0.05156

Collected Steps per Second: 11,925.54700
Overall Steps per Second: 9,995.38473

Timestep Collection Time: 4.19268
Timestep Consumption Time: 0.80963
PPO Batch Consumption Time: 0.03341
Total Iteration Time: 5.00231

Cumulative Model Updates: 9,220
Cumulative Timesteps: 153,899,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.59294
Policy Entropy: 1.29465
Value Function Loss: 0.95872

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.03481
Value Function Update Magnitude: 0.05294

Collected Steps per Second: 11,957.45150
Overall Steps per Second: 10,051.54154

Timestep Collection Time: 4.18199
Timestep Consumption Time: 0.79296
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.97496

Cumulative Model Updates: 9,223
Cumulative Timesteps: 153,949,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 153949108...
Checkpoint 153949108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.51739
Policy Entropy: 1.29735
Value Function Loss: 0.96160

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07782
Policy Update Magnitude: 0.03857
Value Function Update Magnitude: 0.04825

Collected Steps per Second: 12,022.67866
Overall Steps per Second: 10,347.77649

Timestep Collection Time: 4.15981
Timestep Consumption Time: 0.67331
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 4.83312

Cumulative Model Updates: 9,226
Cumulative Timesteps: 153,999,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.90086
Policy Entropy: 1.29769
Value Function Loss: 0.98458

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.03809
Value Function Update Magnitude: 0.04372

Collected Steps per Second: 12,236.55400
Overall Steps per Second: 10,289.15695

Timestep Collection Time: 4.08792
Timestep Consumption Time: 0.77371
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.86162

Cumulative Model Updates: 9,229
Cumulative Timesteps: 154,049,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 154049142...
Checkpoint 154049142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.55800
Policy Entropy: 1.29677
Value Function Loss: 0.92707

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.03856
Value Function Update Magnitude: 0.04743

Collected Steps per Second: 11,280.97932
Overall Steps per Second: 9,543.15682

Timestep Collection Time: 4.43242
Timestep Consumption Time: 0.80715
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.23957

Cumulative Model Updates: 9,232
Cumulative Timesteps: 154,099,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.10669
Policy Entropy: 1.30169
Value Function Loss: 0.98379

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.03759
Value Function Update Magnitude: 0.07136

Collected Steps per Second: 11,811.54730
Overall Steps per Second: 10,114.93267

Timestep Collection Time: 4.23416
Timestep Consumption Time: 0.71021
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.94437

Cumulative Model Updates: 9,235
Cumulative Timesteps: 154,149,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 154149156...
Checkpoint 154149156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.77205
Policy Entropy: 1.29985
Value Function Loss: 0.90921

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.03697
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 11,805.30275
Overall Steps per Second: 9,841.83244

Timestep Collection Time: 4.23742
Timestep Consumption Time: 0.84538
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.08279

Cumulative Model Updates: 9,238
Cumulative Timesteps: 154,199,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.26208
Policy Entropy: 1.30190
Value Function Loss: 0.98419

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06825
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.06408

Collected Steps per Second: 11,515.80568
Overall Steps per Second: 9,885.77030

Timestep Collection Time: 4.34325
Timestep Consumption Time: 0.71615
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.05939

Cumulative Model Updates: 9,241
Cumulative Timesteps: 154,249,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 154249196...
Checkpoint 154249196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.13772
Policy Entropy: 1.29850
Value Function Loss: 0.87237

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.04120
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 11,808.32588
Overall Steps per Second: 9,918.34827

Timestep Collection Time: 4.23481
Timestep Consumption Time: 0.80696
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.04177

Cumulative Model Updates: 9,244
Cumulative Timesteps: 154,299,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.54589
Policy Entropy: 1.29683
Value Function Loss: 1.00183

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.03957
Value Function Update Magnitude: 0.06500

Collected Steps per Second: 11,563.69035
Overall Steps per Second: 9,670.69024

Timestep Collection Time: 4.32613
Timestep Consumption Time: 0.84682
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.17295

Cumulative Model Updates: 9,247
Cumulative Timesteps: 154,349,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 154349228...
Checkpoint 154349228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.87681
Policy Entropy: 1.30042
Value Function Loss: 0.98534

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.04090
Value Function Update Magnitude: 0.05384

Collected Steps per Second: 11,458.09298
Overall Steps per Second: 9,878.30774

Timestep Collection Time: 4.36373
Timestep Consumption Time: 0.69787
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.06160

Cumulative Model Updates: 9,250
Cumulative Timesteps: 154,399,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.27856
Policy Entropy: 1.29618
Value Function Loss: 1.02013

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.03770
Value Function Update Magnitude: 0.04287

Collected Steps per Second: 11,928.99156
Overall Steps per Second: 10,050.22702

Timestep Collection Time: 4.19164
Timestep Consumption Time: 0.78357
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.97521

Cumulative Model Updates: 9,253
Cumulative Timesteps: 154,449,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 154449230...
Checkpoint 154449230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.36996
Policy Entropy: 1.30107
Value Function Loss: 0.92234

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07123
Policy Update Magnitude: 0.04173
Value Function Update Magnitude: 0.04830

Collected Steps per Second: 11,772.10219
Overall Steps per Second: 10,079.54433

Timestep Collection Time: 4.24886
Timestep Consumption Time: 0.71347
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 4.96233

Cumulative Model Updates: 9,256
Cumulative Timesteps: 154,499,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.26700
Policy Entropy: 1.29767
Value Function Loss: 0.98340

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.04207

Collected Steps per Second: 11,772.85537
Overall Steps per Second: 9,852.96144

Timestep Collection Time: 4.24740
Timestep Consumption Time: 0.82762
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.07502

Cumulative Model Updates: 9,259
Cumulative Timesteps: 154,549,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 154549252...
Checkpoint 154549252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.37094
Policy Entropy: 1.30081
Value Function Loss: 0.93446

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06491
Policy Update Magnitude: 0.04276
Value Function Update Magnitude: 0.03731

Collected Steps per Second: 11,644.63669
Overall Steps per Second: 9,870.93349

Timestep Collection Time: 4.29434
Timestep Consumption Time: 0.77165
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.06598

Cumulative Model Updates: 9,262
Cumulative Timesteps: 154,599,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.77577
Policy Entropy: 1.29601
Value Function Loss: 0.95615

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 11,809.38190
Overall Steps per Second: 9,933.52394

Timestep Collection Time: 4.23409
Timestep Consumption Time: 0.79957
PPO Batch Consumption Time: 0.03777
Total Iteration Time: 5.03366

Cumulative Model Updates: 9,265
Cumulative Timesteps: 154,649,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 154649260...
Checkpoint 154649260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.39894
Policy Entropy: 1.29790
Value Function Loss: 0.93857

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.06095

Collected Steps per Second: 11,073.93948
Overall Steps per Second: 9,333.94122

Timestep Collection Time: 4.51745
Timestep Consumption Time: 0.84213
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.35958

Cumulative Model Updates: 9,268
Cumulative Timesteps: 154,699,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.22547
Policy Entropy: 1.29449
Value Function Loss: 0.95188

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.04253
Value Function Update Magnitude: 0.05252

Collected Steps per Second: 11,586.24759
Overall Steps per Second: 9,957.28944

Timestep Collection Time: 4.31701
Timestep Consumption Time: 0.70624
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.02325

Cumulative Model Updates: 9,271
Cumulative Timesteps: 154,749,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 154749304...
Checkpoint 154749304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.68646
Policy Entropy: 1.29469
Value Function Loss: 0.98099

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.03778
Value Function Update Magnitude: 0.04684

Collected Steps per Second: 11,573.75833
Overall Steps per Second: 9,794.27749

Timestep Collection Time: 4.32185
Timestep Consumption Time: 0.78522
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.10706

Cumulative Model Updates: 9,274
Cumulative Timesteps: 154,799,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.85637
Policy Entropy: 1.29413
Value Function Loss: 0.90485

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.04038
Value Function Update Magnitude: 0.04483

Collected Steps per Second: 11,757.32942
Overall Steps per Second: 9,962.65161

Timestep Collection Time: 4.25471
Timestep Consumption Time: 0.76645
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.02115

Cumulative Model Updates: 9,277
Cumulative Timesteps: 154,849,348

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 154849348...
Checkpoint 154849348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.12941
Policy Entropy: 1.29848
Value Function Loss: 0.86738

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.04292
Value Function Update Magnitude: 0.04576

Collected Steps per Second: 11,582.48597
Overall Steps per Second: 9,766.37747

Timestep Collection Time: 4.31928
Timestep Consumption Time: 0.80319
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.12247

Cumulative Model Updates: 9,280
Cumulative Timesteps: 154,899,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.78485
Policy Entropy: 1.30036
Value Function Loss: 0.88297

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.04007
Value Function Update Magnitude: 0.04408

Collected Steps per Second: 11,237.78582
Overall Steps per Second: 9,537.27528

Timestep Collection Time: 4.45016
Timestep Consumption Time: 0.79347
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 5.24364

Cumulative Model Updates: 9,283
Cumulative Timesteps: 154,949,386

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 154949386...
Checkpoint 154949386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.54443
Policy Entropy: 1.30150
Value Function Loss: 0.87506

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.04037

Collected Steps per Second: 11,244.14556
Overall Steps per Second: 9,189.17472

Timestep Collection Time: 4.44925
Timestep Consumption Time: 0.99498
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 5.44423

Cumulative Model Updates: 9,286
Cumulative Timesteps: 154,999,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.98675
Policy Entropy: 1.30444
Value Function Loss: 0.91200

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.04423
Value Function Update Magnitude: 0.04219

Collected Steps per Second: 10,643.57677
Overall Steps per Second: 8,359.96486

Timestep Collection Time: 4.69936
Timestep Consumption Time: 1.28368
PPO Batch Consumption Time: 0.04371
Total Iteration Time: 5.98304

Cumulative Model Updates: 9,289
Cumulative Timesteps: 155,049,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 155049432...
Checkpoint 155049432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.75506
Policy Entropy: 1.30192
Value Function Loss: 0.83364

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.03977

Collected Steps per Second: 10,912.44783
Overall Steps per Second: 8,770.80673

Timestep Collection Time: 4.58266
Timestep Consumption Time: 1.11899
PPO Batch Consumption Time: 0.04158
Total Iteration Time: 5.70164

Cumulative Model Updates: 9,292
Cumulative Timesteps: 155,099,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.24733
Policy Entropy: 1.29815
Value Function Loss: 0.93331

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.04019

Collected Steps per Second: 11,431.10909
Overall Steps per Second: 9,691.21252

Timestep Collection Time: 4.37613
Timestep Consumption Time: 0.78566
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.16179

Cumulative Model Updates: 9,295
Cumulative Timesteps: 155,149,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 155149464...
Checkpoint 155149464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.92382
Policy Entropy: 1.29701
Value Function Loss: 0.87522

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.03915

Collected Steps per Second: 11,686.56534
Overall Steps per Second: 9,775.33596

Timestep Collection Time: 4.27927
Timestep Consumption Time: 0.83666
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.11594

Cumulative Model Updates: 9,298
Cumulative Timesteps: 155,199,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.57938
Policy Entropy: 1.29497
Value Function Loss: 0.85900

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.04229
Value Function Update Magnitude: 0.04245

Collected Steps per Second: 11,102.14123
Overall Steps per Second: 9,641.48095

Timestep Collection Time: 4.50508
Timestep Consumption Time: 0.68251
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 5.18758

Cumulative Model Updates: 9,301
Cumulative Timesteps: 155,249,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 155249490...
Checkpoint 155249490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.72225
Policy Entropy: 1.29890
Value Function Loss: 0.82759

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07373
Policy Update Magnitude: 0.04006
Value Function Update Magnitude: 0.04199

Collected Steps per Second: 11,742.32700
Overall Steps per Second: 9,878.64731

Timestep Collection Time: 4.25895
Timestep Consumption Time: 0.80348
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.06243

Cumulative Model Updates: 9,304
Cumulative Timesteps: 155,299,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.68775
Policy Entropy: 1.29994
Value Function Loss: 0.81748

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.04264
Value Function Update Magnitude: 0.05195

Collected Steps per Second: 11,836.23062
Overall Steps per Second: 9,964.76159

Timestep Collection Time: 4.22635
Timestep Consumption Time: 0.79374
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 5.02009

Cumulative Model Updates: 9,307
Cumulative Timesteps: 155,349,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 155349524...
Checkpoint 155349524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.65308
Policy Entropy: 1.29777
Value Function Loss: 0.86353

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.03946
Value Function Update Magnitude: 0.04778

Collected Steps per Second: 11,972.58830
Overall Steps per Second: 10,041.94014

Timestep Collection Time: 4.17721
Timestep Consumption Time: 0.80310
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.98031

Cumulative Model Updates: 9,310
Cumulative Timesteps: 155,399,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.18210
Policy Entropy: 1.30026
Value Function Loss: 0.92701

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.03987
Value Function Update Magnitude: 0.05783

Collected Steps per Second: 12,516.94910
Overall Steps per Second: 10,465.05693

Timestep Collection Time: 3.99490
Timestep Consumption Time: 0.78328
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.77819

Cumulative Model Updates: 9,313
Cumulative Timesteps: 155,449,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 155449540...
Checkpoint 155449540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.34313
Policy Entropy: 1.29498
Value Function Loss: 0.91091

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06997
Policy Update Magnitude: 0.03878
Value Function Update Magnitude: 0.06168

Collected Steps per Second: 12,590.96433
Overall Steps per Second: 10,718.68201

Timestep Collection Time: 3.97142
Timestep Consumption Time: 0.69371
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.66513

Cumulative Model Updates: 9,316
Cumulative Timesteps: 155,499,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.94439
Policy Entropy: 1.29791
Value Function Loss: 0.98301

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07456
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.05670

Collected Steps per Second: 11,696.99529
Overall Steps per Second: 9,756.33397

Timestep Collection Time: 4.27511
Timestep Consumption Time: 0.85038
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.12549

Cumulative Model Updates: 9,319
Cumulative Timesteps: 155,549,550

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 155549550...
Checkpoint 155549550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.90415
Policy Entropy: 1.30134
Value Function Loss: 0.92667

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06806
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.05412

Collected Steps per Second: 12,724.76650
Overall Steps per Second: 10,525.26971

Timestep Collection Time: 3.93107
Timestep Consumption Time: 0.82149
PPO Batch Consumption Time: 0.03876
Total Iteration Time: 4.75256

Cumulative Model Updates: 9,322
Cumulative Timesteps: 155,599,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.62702
Policy Entropy: 1.29726
Value Function Loss: 0.96345

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07223
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.05371

Collected Steps per Second: 12,710.60484
Overall Steps per Second: 10,749.28028

Timestep Collection Time: 3.93530
Timestep Consumption Time: 0.71804
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.65333

Cumulative Model Updates: 9,325
Cumulative Timesteps: 155,649,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 155649592...
Checkpoint 155649592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.92915
Policy Entropy: 1.29859
Value Function Loss: 0.88246

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06960
Policy Update Magnitude: 0.04017
Value Function Update Magnitude: 0.05667

Collected Steps per Second: 12,228.61480
Overall Steps per Second: 10,210.40915

Timestep Collection Time: 4.08959
Timestep Consumption Time: 0.80835
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 4.89794

Cumulative Model Updates: 9,328
Cumulative Timesteps: 155,699,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.89476
Policy Entropy: 1.29375
Value Function Loss: 0.84591

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.05006

Collected Steps per Second: 11,936.19512
Overall Steps per Second: 10,206.15986

Timestep Collection Time: 4.19078
Timestep Consumption Time: 0.71038
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.90116

Cumulative Model Updates: 9,331
Cumulative Timesteps: 155,749,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 155749624...
Checkpoint 155749624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.87910
Policy Entropy: 1.29886
Value Function Loss: 0.83979

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.05390

Collected Steps per Second: 11,344.76357
Overall Steps per Second: 9,603.31207

Timestep Collection Time: 4.40979
Timestep Consumption Time: 0.79966
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 5.20945

Cumulative Model Updates: 9,334
Cumulative Timesteps: 155,799,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.48143
Policy Entropy: 1.29949
Value Function Loss: 0.84255

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.03934
Value Function Update Magnitude: 0.04189

Collected Steps per Second: 11,303.49855
Overall Steps per Second: 9,612.95026

Timestep Collection Time: 4.42465
Timestep Consumption Time: 0.77813
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.20277

Cumulative Model Updates: 9,337
Cumulative Timesteps: 155,849,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 155849666...
Checkpoint 155849666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.35945
Policy Entropy: 1.30050
Value Function Loss: 0.80745

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.03729

Collected Steps per Second: 12,059.40811
Overall Steps per Second: 10,103.82370

Timestep Collection Time: 4.14879
Timestep Consumption Time: 0.80299
PPO Batch Consumption Time: 0.03803
Total Iteration Time: 4.95179

Cumulative Model Updates: 9,340
Cumulative Timesteps: 155,899,698

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.99629
Policy Entropy: 1.29495
Value Function Loss: 0.80523

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.04597

Collected Steps per Second: 11,747.57777
Overall Steps per Second: 9,900.69642

Timestep Collection Time: 4.25637
Timestep Consumption Time: 0.79398
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.05035

Cumulative Model Updates: 9,343
Cumulative Timesteps: 155,949,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 155949700...
Checkpoint 155949700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.09312
Policy Entropy: 1.29733
Value Function Loss: 0.83403

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.05458
Policy Update Magnitude: 0.06564
Value Function Update Magnitude: 0.03938

Collected Steps per Second: 11,653.22717
Overall Steps per Second: 10,041.36694

Timestep Collection Time: 4.29237
Timestep Consumption Time: 0.68902
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 4.98139

Cumulative Model Updates: 9,346
Cumulative Timesteps: 155,999,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.32627
Policy Entropy: 1.29701
Value Function Loss: 0.87366

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.04159
Policy Update Magnitude: 0.07833
Value Function Update Magnitude: 0.05188

Collected Steps per Second: 11,653.88642
Overall Steps per Second: 9,827.15258

Timestep Collection Time: 4.29333
Timestep Consumption Time: 0.79807
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.09140

Cumulative Model Updates: 9,349
Cumulative Timesteps: 156,049,754

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 156049754...
Checkpoint 156049754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.72728
Policy Entropy: 1.29182
Value Function Loss: 0.86238

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06162
Policy Update Magnitude: 0.08609
Value Function Update Magnitude: 0.04358

Collected Steps per Second: 10,568.53643
Overall Steps per Second: 9,029.12421

Timestep Collection Time: 4.73311
Timestep Consumption Time: 0.80697
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.54007

Cumulative Model Updates: 9,352
Cumulative Timesteps: 156,099,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.22120
Policy Entropy: 1.28949
Value Function Loss: 0.82341

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.05462
Policy Update Magnitude: 0.08630
Value Function Update Magnitude: 0.04148

Collected Steps per Second: 10,373.02607
Overall Steps per Second: 8,955.72085

Timestep Collection Time: 4.82289
Timestep Consumption Time: 0.76326
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.58615

Cumulative Model Updates: 9,355
Cumulative Timesteps: 156,149,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 156149804...
Checkpoint 156149804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.68042
Policy Entropy: 1.28908
Value Function Loss: 0.80973

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05877
Policy Update Magnitude: 0.07360
Value Function Update Magnitude: 0.03290

Collected Steps per Second: 11,676.62904
Overall Steps per Second: 9,797.21577

Timestep Collection Time: 4.28360
Timestep Consumption Time: 0.82173
PPO Batch Consumption Time: 0.04087
Total Iteration Time: 5.10533

Cumulative Model Updates: 9,358
Cumulative Timesteps: 156,199,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.39339
Policy Entropy: 1.28427
Value Function Loss: 0.84111

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06350
Policy Update Magnitude: 0.07669
Value Function Update Magnitude: 0.06267

Collected Steps per Second: 11,531.77295
Overall Steps per Second: 9,867.30129

Timestep Collection Time: 4.33827
Timestep Consumption Time: 0.73180
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.07008

Cumulative Model Updates: 9,361
Cumulative Timesteps: 156,249,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 156249850...
Checkpoint 156249850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.14941
Policy Entropy: 1.29515
Value Function Loss: 0.87947

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.05249

Collected Steps per Second: 11,602.78197
Overall Steps per Second: 9,795.53538

Timestep Collection Time: 4.31086
Timestep Consumption Time: 0.79534
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 5.10620

Cumulative Model Updates: 9,364
Cumulative Timesteps: 156,299,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.31254
Policy Entropy: 1.28938
Value Function Loss: 0.88834

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05909
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.05246

Collected Steps per Second: 11,468.82237
Overall Steps per Second: 9,696.50757

Timestep Collection Time: 4.35982
Timestep Consumption Time: 0.79688
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.15670

Cumulative Model Updates: 9,367
Cumulative Timesteps: 156,349,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 156349870...
Checkpoint 156349870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.03135
Policy Entropy: 1.28937
Value Function Loss: 0.84869

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05733
Policy Update Magnitude: 0.06962
Value Function Update Magnitude: 0.05000

Collected Steps per Second: 11,344.06117
Overall Steps per Second: 9,454.80255

Timestep Collection Time: 4.40795
Timestep Consumption Time: 0.88080
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 5.28874

Cumulative Model Updates: 9,370
Cumulative Timesteps: 156,399,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.33339
Policy Entropy: 1.28962
Value Function Loss: 0.76030

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07484
Policy Update Magnitude: 0.07045
Value Function Update Magnitude: 0.04128

Collected Steps per Second: 10,429.42638
Overall Steps per Second: 8,515.92317

Timestep Collection Time: 4.79643
Timestep Consumption Time: 1.07774
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 5.87417

Cumulative Model Updates: 9,373
Cumulative Timesteps: 156,449,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 156449898...
Checkpoint 156449898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.62216
Policy Entropy: 1.28754
Value Function Loss: 0.72029

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.06224
Value Function Update Magnitude: 0.07408

Collected Steps per Second: 9,253.84658
Overall Steps per Second: 8,189.94541

Timestep Collection Time: 5.40381
Timestep Consumption Time: 0.70197
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 6.10578

Cumulative Model Updates: 9,376
Cumulative Timesteps: 156,499,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.18440
Policy Entropy: 1.28727
Value Function Loss: 0.80195

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.06162

Collected Steps per Second: 10,954.62118
Overall Steps per Second: 9,159.29942

Timestep Collection Time: 4.56556
Timestep Consumption Time: 0.89490
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.46046

Cumulative Model Updates: 9,379
Cumulative Timesteps: 156,549,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 156549918...
Checkpoint 156549918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.18740
Policy Entropy: 1.29134
Value Function Loss: 0.82125

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.06643

Collected Steps per Second: 10,903.85119
Overall Steps per Second: 9,343.73521

Timestep Collection Time: 4.58810
Timestep Consumption Time: 0.76607
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.35418

Cumulative Model Updates: 9,382
Cumulative Timesteps: 156,599,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.66706
Policy Entropy: 1.29116
Value Function Loss: 0.83946

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05269
Policy Update Magnitude: 0.06437
Value Function Update Magnitude: 0.06674

Collected Steps per Second: 11,788.78464
Overall Steps per Second: 9,980.47616

Timestep Collection Time: 4.24352
Timestep Consumption Time: 0.76886
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.01239

Cumulative Model Updates: 9,385
Cumulative Timesteps: 156,649,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 156649972...
Checkpoint 156649972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.44115
Policy Entropy: 1.29938
Value Function Loss: 0.77816

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.06117

Collected Steps per Second: 10,846.08388
Overall Steps per Second: 9,229.57039

Timestep Collection Time: 4.61162
Timestep Consumption Time: 0.80770
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.41932

Cumulative Model Updates: 9,388
Cumulative Timesteps: 156,699,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.40320
Policy Entropy: 1.29388
Value Function Loss: 0.78109

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.06104
Policy Update Magnitude: 0.06259
Value Function Update Magnitude: 0.04438

Collected Steps per Second: 11,602.87410
Overall Steps per Second: 9,880.55460

Timestep Collection Time: 4.30945
Timestep Consumption Time: 0.75120
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.06065

Cumulative Model Updates: 9,391
Cumulative Timesteps: 156,749,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 156749992...
Checkpoint 156749992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.81473
Policy Entropy: 1.29864
Value Function Loss: 0.82198

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.05107

Collected Steps per Second: 11,846.42123
Overall Steps per Second: 10,018.45677

Timestep Collection Time: 4.22220
Timestep Consumption Time: 0.77038
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 4.99259

Cumulative Model Updates: 9,394
Cumulative Timesteps: 156,800,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.23626
Policy Entropy: 1.28790
Value Function Loss: 0.84832

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.04193

Collected Steps per Second: 11,716.96257
Overall Steps per Second: 9,934.11553

Timestep Collection Time: 4.26851
Timestep Consumption Time: 0.76606
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.03457

Cumulative Model Updates: 9,397
Cumulative Timesteps: 156,850,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 156850024...
Checkpoint 156850024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.61293
Policy Entropy: 1.29440
Value Function Loss: 0.84841

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.06285

Collected Steps per Second: 11,682.29565
Overall Steps per Second: 9,850.44857

Timestep Collection Time: 4.28152
Timestep Consumption Time: 0.79622
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.07774

Cumulative Model Updates: 9,400
Cumulative Timesteps: 156,900,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.39651
Policy Entropy: 1.29347
Value Function Loss: 0.81442

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07279
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.05569

Collected Steps per Second: 11,577.48434
Overall Steps per Second: 9,846.75010

Timestep Collection Time: 4.31873
Timestep Consumption Time: 0.75909
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.07782

Cumulative Model Updates: 9,403
Cumulative Timesteps: 156,950,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 156950042...
Checkpoint 156950042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.60723
Policy Entropy: 1.29321
Value Function Loss: 0.81316

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.05594

Collected Steps per Second: 10,915.37457
Overall Steps per Second: 9,456.88052

Timestep Collection Time: 4.58106
Timestep Consumption Time: 0.70652
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 5.28758

Cumulative Model Updates: 9,406
Cumulative Timesteps: 157,000,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.59034
Policy Entropy: 1.29475
Value Function Loss: 0.74962

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.05750

Collected Steps per Second: 11,983.85196
Overall Steps per Second: 10,038.23311

Timestep Collection Time: 4.17378
Timestep Consumption Time: 0.80897
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.98275

Cumulative Model Updates: 9,409
Cumulative Timesteps: 157,050,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 157050064...
Checkpoint 157050064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.95141
Policy Entropy: 1.29942
Value Function Loss: 0.74869

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.05593

Collected Steps per Second: 11,829.52270
Overall Steps per Second: 9,976.71906

Timestep Collection Time: 4.22790
Timestep Consumption Time: 0.78517
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 5.01307

Cumulative Model Updates: 9,412
Cumulative Timesteps: 157,100,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.73352
Policy Entropy: 1.30027
Value Function Loss: 0.73509

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.04843

Collected Steps per Second: 12,169.78978
Overall Steps per Second: 10,182.78573

Timestep Collection Time: 4.11051
Timestep Consumption Time: 0.80210
PPO Batch Consumption Time: 0.03911
Total Iteration Time: 4.91260

Cumulative Model Updates: 9,415
Cumulative Timesteps: 157,150,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 157150102...
Checkpoint 157150102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.22288
Policy Entropy: 1.29493
Value Function Loss: 0.75630

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.05260

Collected Steps per Second: 11,730.32359
Overall Steps per Second: 9,956.04036

Timestep Collection Time: 4.26314
Timestep Consumption Time: 0.75974
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.02288

Cumulative Model Updates: 9,418
Cumulative Timesteps: 157,200,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.63038
Policy Entropy: 1.29944
Value Function Loss: 0.78763

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07063
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.05469

Collected Steps per Second: 11,602.51366
Overall Steps per Second: 9,906.39487

Timestep Collection Time: 4.30941
Timestep Consumption Time: 0.73783
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.04724

Cumulative Model Updates: 9,421
Cumulative Timesteps: 157,250,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 157250110...
Checkpoint 157250110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.62454
Policy Entropy: 1.29117
Value Function Loss: 0.77658

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.06925

Collected Steps per Second: 11,071.23875
Overall Steps per Second: 9,431.40316

Timestep Collection Time: 4.51747
Timestep Consumption Time: 0.78545
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.30292

Cumulative Model Updates: 9,424
Cumulative Timesteps: 157,300,124

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.43835
Policy Entropy: 1.29364
Value Function Loss: 0.81318

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05915
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.08149

Collected Steps per Second: 11,746.43327
Overall Steps per Second: 9,973.91335

Timestep Collection Time: 4.25780
Timestep Consumption Time: 0.75668
PPO Batch Consumption Time: 0.03365
Total Iteration Time: 5.01448

Cumulative Model Updates: 9,427
Cumulative Timesteps: 157,350,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 157350138...
Checkpoint 157350138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.20516
Policy Entropy: 1.29149
Value Function Loss: 0.81287

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 0.04366
Value Function Update Magnitude: 0.07001

Collected Steps per Second: 12,199.80447
Overall Steps per Second: 10,241.61081

Timestep Collection Time: 4.09957
Timestep Consumption Time: 0.78384
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 4.88341

Cumulative Model Updates: 9,430
Cumulative Timesteps: 157,400,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.82021
Policy Entropy: 1.29589
Value Function Loss: 0.81288

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04529
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.06268

Collected Steps per Second: 12,122.49596
Overall Steps per Second: 10,205.11722

Timestep Collection Time: 4.12588
Timestep Consumption Time: 0.77519
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.90107

Cumulative Model Updates: 9,433
Cumulative Timesteps: 157,450,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 157450168...
Checkpoint 157450168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.12946
Policy Entropy: 1.28885
Value Function Loss: 0.75369

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07274
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.05978

Collected Steps per Second: 11,750.67845
Overall Steps per Second: 10,024.05870

Timestep Collection Time: 4.25746
Timestep Consumption Time: 0.73334
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 4.99079

Cumulative Model Updates: 9,436
Cumulative Timesteps: 157,500,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.75250
Policy Entropy: 1.29257
Value Function Loss: 0.72730

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06374
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.04927

Collected Steps per Second: 11,768.60252
Overall Steps per Second: 9,951.86958

Timestep Collection Time: 4.25012
Timestep Consumption Time: 0.77587
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.02599

Cumulative Model Updates: 9,439
Cumulative Timesteps: 157,550,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 157550214...
Checkpoint 157550214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.85502
Policy Entropy: 1.29043
Value Function Loss: 0.74951

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 11,207.12844
Overall Steps per Second: 9,560.28700

Timestep Collection Time: 4.46377
Timestep Consumption Time: 0.76892
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.23269

Cumulative Model Updates: 9,442
Cumulative Timesteps: 157,600,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.57441
Policy Entropy: 1.29113
Value Function Loss: 0.76361

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.04735
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.04700

Collected Steps per Second: 12,277.79839
Overall Steps per Second: 10,289.92539

Timestep Collection Time: 4.07435
Timestep Consumption Time: 0.78711
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.86145

Cumulative Model Updates: 9,445
Cumulative Timesteps: 157,650,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 157650264...
Checkpoint 157650264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.90645
Policy Entropy: 1.28902
Value Function Loss: 0.76086

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04081
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.04589

Collected Steps per Second: 11,990.29928
Overall Steps per Second: 10,120.97852

Timestep Collection Time: 4.17037
Timestep Consumption Time: 0.77026
PPO Batch Consumption Time: 0.03380
Total Iteration Time: 4.94063

Cumulative Model Updates: 9,448
Cumulative Timesteps: 157,700,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.60931
Policy Entropy: 1.28103
Value Function Loss: 0.66584

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.07119
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.05847

Collected Steps per Second: 11,571.12851
Overall Steps per Second: 9,907.39582

Timestep Collection Time: 4.32266
Timestep Consumption Time: 0.72590
PPO Batch Consumption Time: 0.03868
Total Iteration Time: 5.04855

Cumulative Model Updates: 9,451
Cumulative Timesteps: 157,750,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 157750286...
Checkpoint 157750286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.60163
Policy Entropy: 1.29013
Value Function Loss: 0.69406

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03669
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.05866

Collected Steps per Second: 12,289.74568
Overall Steps per Second: 10,264.16279

Timestep Collection Time: 4.07087
Timestep Consumption Time: 0.80337
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 4.87424

Cumulative Model Updates: 9,454
Cumulative Timesteps: 157,800,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.95699
Policy Entropy: 1.28603
Value Function Loss: 0.68212

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.05905

Collected Steps per Second: 12,831.39268
Overall Steps per Second: 10,623.53761

Timestep Collection Time: 3.89888
Timestep Consumption Time: 0.81029
PPO Batch Consumption Time: 0.03344
Total Iteration Time: 4.70917

Cumulative Model Updates: 9,457
Cumulative Timesteps: 157,850,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 157850344...
Checkpoint 157850344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.42751
Policy Entropy: 1.29239
Value Function Loss: 0.75476

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.05748

Collected Steps per Second: 11,966.15770
Overall Steps per Second: 9,963.72546

Timestep Collection Time: 4.17845
Timestep Consumption Time: 0.83975
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 5.01820

Cumulative Model Updates: 9,460
Cumulative Timesteps: 157,900,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.07791
Policy Entropy: 1.28710
Value Function Loss: 0.74506

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06138
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.05353

Collected Steps per Second: 12,650.47476
Overall Steps per Second: 10,490.14094

Timestep Collection Time: 3.95416
Timestep Consumption Time: 0.81432
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.76848

Cumulative Model Updates: 9,463
Cumulative Timesteps: 157,950,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 157950366...
Checkpoint 157950366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.17020
Policy Entropy: 1.29269
Value Function Loss: 0.66763

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05510
Policy Update Magnitude: 0.06479
Value Function Update Magnitude: 0.05121

Collected Steps per Second: 12,488.30455
Overall Steps per Second: 10,616.48345

Timestep Collection Time: 4.00391
Timestep Consumption Time: 0.70594
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.70985

Cumulative Model Updates: 9,466
Cumulative Timesteps: 158,000,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.97197
Policy Entropy: 1.28925
Value Function Loss: 0.66282

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05366
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.05139

Collected Steps per Second: 12,522.07094
Overall Steps per Second: 10,394.50327

Timestep Collection Time: 3.99519
Timestep Consumption Time: 0.81774
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 4.81293

Cumulative Model Updates: 9,469
Cumulative Timesteps: 158,050,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 158050396...
Checkpoint 158050396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.09023
Policy Entropy: 1.28579
Value Function Loss: 0.71735

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.06072
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.04059

Collected Steps per Second: 12,241.70000
Overall Steps per Second: 10,277.01331

Timestep Collection Time: 4.08538
Timestep Consumption Time: 0.78101
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.86639

Cumulative Model Updates: 9,472
Cumulative Timesteps: 158,100,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.59360
Policy Entropy: 1.28457
Value Function Loss: 0.74870

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.05767
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.06510

Collected Steps per Second: 12,196.92621
Overall Steps per Second: 10,248.59440

Timestep Collection Time: 4.10005
Timestep Consumption Time: 0.77945
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.87950

Cumulative Model Updates: 9,475
Cumulative Timesteps: 158,150,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 158150416...
Checkpoint 158150416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.41573
Policy Entropy: 1.28171
Value Function Loss: 0.71441

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06372
Policy Update Magnitude: 0.04169
Value Function Update Magnitude: 0.06733

Collected Steps per Second: 11,569.95549
Overall Steps per Second: 9,799.29112

Timestep Collection Time: 4.32154
Timestep Consumption Time: 0.78087
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.10241

Cumulative Model Updates: 9,478
Cumulative Timesteps: 158,200,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.52416
Policy Entropy: 1.28168
Value Function Loss: 0.63542

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04711
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.06368

Collected Steps per Second: 11,971.14976
Overall Steps per Second: 10,239.73082

Timestep Collection Time: 4.17804
Timestep Consumption Time: 0.70646
PPO Batch Consumption Time: 0.03912
Total Iteration Time: 4.88450

Cumulative Model Updates: 9,481
Cumulative Timesteps: 158,250,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 158250432...
Checkpoint 158250432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.82708
Policy Entropy: 1.27672
Value Function Loss: 0.66342

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06521
Policy Update Magnitude: 0.04384
Value Function Update Magnitude: 0.04863

Collected Steps per Second: 12,072.33337
Overall Steps per Second: 10,146.84885

Timestep Collection Time: 4.14170
Timestep Consumption Time: 0.78594
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 4.92764

Cumulative Model Updates: 9,484
Cumulative Timesteps: 158,300,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.76267
Policy Entropy: 1.27347
Value Function Loss: 0.64491

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05626
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 11,754.71361
Overall Steps per Second: 10,082.16165

Timestep Collection Time: 4.25446
Timestep Consumption Time: 0.70578
PPO Batch Consumption Time: 0.03763
Total Iteration Time: 4.96025

Cumulative Model Updates: 9,487
Cumulative Timesteps: 158,350,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 158350442...
Checkpoint 158350442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.75383
Policy Entropy: 1.27751
Value Function Loss: 0.64869

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06037
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.08345

Collected Steps per Second: 11,956.96344
Overall Steps per Second: 10,088.34311

Timestep Collection Time: 4.18217
Timestep Consumption Time: 0.77464
PPO Batch Consumption Time: 0.03303
Total Iteration Time: 4.95681

Cumulative Model Updates: 9,490
Cumulative Timesteps: 158,400,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.64662
Policy Entropy: 1.27654
Value Function Loss: 0.62419

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07331
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.07716

Collected Steps per Second: 12,092.05190
Overall Steps per Second: 10,131.90928

Timestep Collection Time: 4.13644
Timestep Consumption Time: 0.80024
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.93668

Cumulative Model Updates: 9,493
Cumulative Timesteps: 158,450,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 158450466...
Checkpoint 158450466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.59666
Policy Entropy: 1.27441
Value Function Loss: 0.60385

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 11,264.67669
Overall Steps per Second: 9,589.61805

Timestep Collection Time: 4.43865
Timestep Consumption Time: 0.77532
PPO Batch Consumption Time: 0.03324
Total Iteration Time: 5.21397

Cumulative Model Updates: 9,496
Cumulative Timesteps: 158,500,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.69043
Policy Entropy: 1.27744
Value Function Loss: 0.62264

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.06454

Collected Steps per Second: 12,221.99860
Overall Steps per Second: 10,275.19621

Timestep Collection Time: 4.09164
Timestep Consumption Time: 0.77523
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 4.86687

Cumulative Model Updates: 9,499
Cumulative Timesteps: 158,550,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 158550474...
Checkpoint 158550474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.63146
Policy Entropy: 1.26475
Value Function Loss: 0.60415

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.05330

Collected Steps per Second: 12,013.60469
Overall Steps per Second: 10,299.38677

Timestep Collection Time: 4.16395
Timestep Consumption Time: 0.69304
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.85699

Cumulative Model Updates: 9,502
Cumulative Timesteps: 158,600,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.71193
Policy Entropy: 1.27977
Value Function Loss: 0.62094

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 12,070.91634
Overall Steps per Second: 10,168.34095

Timestep Collection Time: 4.14219
Timestep Consumption Time: 0.77504
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 4.91722

Cumulative Model Updates: 9,505
Cumulative Timesteps: 158,650,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 158650498...
Checkpoint 158650498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.62594
Policy Entropy: 1.26266
Value Function Loss: 0.61784

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.05654

Collected Steps per Second: 11,765.34669
Overall Steps per Second: 9,922.33107

Timestep Collection Time: 4.25198
Timestep Consumption Time: 0.78978
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.04176

Cumulative Model Updates: 9,508
Cumulative Timesteps: 158,700,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.36843
Policy Entropy: 1.27160
Value Function Loss: 0.65703

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.07589

Collected Steps per Second: 11,952.26247
Overall Steps per Second: 10,025.63354

Timestep Collection Time: 4.18331
Timestep Consumption Time: 0.80391
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 4.98722

Cumulative Model Updates: 9,511
Cumulative Timesteps: 158,750,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 158750524...
Checkpoint 158750524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.82750
Policy Entropy: 1.27179
Value Function Loss: 0.69027

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.05914

Collected Steps per Second: 11,468.92148
Overall Steps per Second: 9,726.35133

Timestep Collection Time: 4.36118
Timestep Consumption Time: 0.78135
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.14252

Cumulative Model Updates: 9,514
Cumulative Timesteps: 158,800,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.18102
Policy Entropy: 1.26836
Value Function Loss: 0.63250

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.04627

Collected Steps per Second: 12,118.39324
Overall Steps per Second: 10,378.35285

Timestep Collection Time: 4.12629
Timestep Consumption Time: 0.69182
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.81811

Cumulative Model Updates: 9,517
Cumulative Timesteps: 158,850,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 158850546...
Checkpoint 158850546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.36266
Policy Entropy: 1.27382
Value Function Loss: 0.67426

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.04155

Collected Steps per Second: 12,020.18118
Overall Steps per Second: 10,019.85559

Timestep Collection Time: 4.16067
Timestep Consumption Time: 0.83062
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 4.99129

Cumulative Model Updates: 9,520
Cumulative Timesteps: 158,900,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.71983
Policy Entropy: 1.26855
Value Function Loss: 0.66102

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 11,825.80384
Overall Steps per Second: 9,976.64657

Timestep Collection Time: 4.23041
Timestep Consumption Time: 0.78410
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.01451

Cumulative Model Updates: 9,523
Cumulative Timesteps: 158,950,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 158950586...
Checkpoint 158950586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.97301
Policy Entropy: 1.27231
Value Function Loss: 0.71955

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.03943
Value Function Update Magnitude: 0.04414

Collected Steps per Second: 12,253.81542
Overall Steps per Second: 10,287.25478

Timestep Collection Time: 4.08069
Timestep Consumption Time: 0.78008
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.86077

Cumulative Model Updates: 9,526
Cumulative Timesteps: 159,000,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.76182
Policy Entropy: 1.26404
Value Function Loss: 0.61240

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.04228

Collected Steps per Second: 12,202.75867
Overall Steps per Second: 10,283.29584

Timestep Collection Time: 4.10006
Timestep Consumption Time: 0.76531
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.86537

Cumulative Model Updates: 9,529
Cumulative Timesteps: 159,050,622

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 159050622...
Checkpoint 159050622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.90572
Policy Entropy: 1.27165
Value Function Loss: 0.60934

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.05289

Collected Steps per Second: 11,478.64801
Overall Steps per Second: 9,894.76420

Timestep Collection Time: 4.35644
Timestep Consumption Time: 0.69735
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 5.05378

Cumulative Model Updates: 9,532
Cumulative Timesteps: 159,100,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.44735
Policy Entropy: 1.26235
Value Function Loss: 0.57550

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.04723

Collected Steps per Second: 12,362.69725
Overall Steps per Second: 10,313.32705

Timestep Collection Time: 4.04620
Timestep Consumption Time: 0.80402
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.85023

Cumulative Model Updates: 9,535
Cumulative Timesteps: 159,150,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 159150650...
Checkpoint 159150650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.11479
Policy Entropy: 1.26978
Value Function Loss: 0.60317

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 12,310.08680
Overall Steps per Second: 10,271.86643

Timestep Collection Time: 4.06317
Timestep Consumption Time: 0.80624
PPO Batch Consumption Time: 0.03873
Total Iteration Time: 4.86942

Cumulative Model Updates: 9,538
Cumulative Timesteps: 159,200,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.79295
Policy Entropy: 1.26379
Value Function Loss: 0.58583

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.03888

Collected Steps per Second: 12,673.06913
Overall Steps per Second: 10,573.43726

Timestep Collection Time: 3.94537
Timestep Consumption Time: 0.78346
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.72883

Cumulative Model Updates: 9,541
Cumulative Timesteps: 159,250,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 159250668...
Checkpoint 159250668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.83108
Policy Entropy: 1.26991
Value Function Loss: 0.59401

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.04024

Collected Steps per Second: 12,110.85492
Overall Steps per Second: 10,184.97068

Timestep Collection Time: 4.12853
Timestep Consumption Time: 0.78067
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.90919

Cumulative Model Updates: 9,544
Cumulative Timesteps: 159,300,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.11834
Policy Entropy: 1.26087
Value Function Loss: 0.58825

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.04023

Collected Steps per Second: 12,016.50889
Overall Steps per Second: 10,275.05255

Timestep Collection Time: 4.16144
Timestep Consumption Time: 0.70530
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 4.86674

Cumulative Model Updates: 9,547
Cumulative Timesteps: 159,350,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 159350674...
Checkpoint 159350674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.23430
Policy Entropy: 1.26259
Value Function Loss: 0.58872

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06518
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.03832

Collected Steps per Second: 11,382.90458
Overall Steps per Second: 9,647.68681

Timestep Collection Time: 4.39448
Timestep Consumption Time: 0.79039
PPO Batch Consumption Time: 0.03317
Total Iteration Time: 5.18487

Cumulative Model Updates: 9,550
Cumulative Timesteps: 159,400,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.72483
Policy Entropy: 1.26256
Value Function Loss: 0.58026

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.03615

Collected Steps per Second: 11,899.03875
Overall Steps per Second: 10,059.47322

Timestep Collection Time: 4.20202
Timestep Consumption Time: 0.76842
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 4.97044

Cumulative Model Updates: 9,553
Cumulative Timesteps: 159,450,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 159450696...
Checkpoint 159450696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.30802
Policy Entropy: 1.25489
Value Function Loss: 0.59671

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.07267
Value Function Update Magnitude: 0.03627

Collected Steps per Second: 12,309.80452
Overall Steps per Second: 10,290.24007

Timestep Collection Time: 4.06310
Timestep Consumption Time: 0.79743
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.86053

Cumulative Model Updates: 9,556
Cumulative Timesteps: 159,500,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.04725
Policy Entropy: 1.26824
Value Function Loss: 0.55997

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.04229

Collected Steps per Second: 12,053.15308
Overall Steps per Second: 10,118.25905

Timestep Collection Time: 4.15078
Timestep Consumption Time: 0.79375
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 4.94453

Cumulative Model Updates: 9,559
Cumulative Timesteps: 159,550,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 159550742...
Checkpoint 159550742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.94624
Policy Entropy: 1.25630
Value Function Loss: 0.57482

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.03771

Collected Steps per Second: 11,886.46249
Overall Steps per Second: 10,229.57437

Timestep Collection Time: 4.20798
Timestep Consumption Time: 0.68157
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.88955

Cumulative Model Updates: 9,562
Cumulative Timesteps: 159,600,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.75387
Policy Entropy: 1.26068
Value Function Loss: 0.53618

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.06827
Value Function Update Magnitude: 0.03265

Collected Steps per Second: 11,928.64359
Overall Steps per Second: 10,031.06026

Timestep Collection Time: 4.19209
Timestep Consumption Time: 0.79302
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.98512

Cumulative Model Updates: 9,565
Cumulative Timesteps: 159,650,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 159650766...
Checkpoint 159650766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.07217
Policy Entropy: 1.26194
Value Function Loss: 0.57719

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06713
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.04781

Collected Steps per Second: 11,300.10939
Overall Steps per Second: 9,784.22062

Timestep Collection Time: 4.42686
Timestep Consumption Time: 0.68586
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.11272

Cumulative Model Updates: 9,568
Cumulative Timesteps: 159,700,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.29058
Policy Entropy: 1.26358
Value Function Loss: 0.55610

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05869
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.04861

Collected Steps per Second: 11,902.41628
Overall Steps per Second: 10,033.68264

Timestep Collection Time: 4.20133
Timestep Consumption Time: 0.78248
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 4.98381

Cumulative Model Updates: 9,571
Cumulative Timesteps: 159,750,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 159750796...
Checkpoint 159750796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.03408
Policy Entropy: 1.26360
Value Function Loss: 0.55157

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05681
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.06731

Collected Steps per Second: 12,080.35737
Overall Steps per Second: 10,171.67756

Timestep Collection Time: 4.14094
Timestep Consumption Time: 0.77703
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 4.91797

Cumulative Model Updates: 9,574
Cumulative Timesteps: 159,800,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.16090
Policy Entropy: 1.26163
Value Function Loss: 0.56196

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.05628

Collected Steps per Second: 11,912.53425
Overall Steps per Second: 10,177.49828

Timestep Collection Time: 4.19911
Timestep Consumption Time: 0.71585
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 4.91496

Cumulative Model Updates: 9,577
Cumulative Timesteps: 159,850,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 159850842...
Checkpoint 159850842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.56686
Policy Entropy: 1.25747
Value Function Loss: 0.57660

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.06467
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.05501

Collected Steps per Second: 11,934.38503
Overall Steps per Second: 10,028.50118

Timestep Collection Time: 4.19058
Timestep Consumption Time: 0.79641
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 4.98699

Cumulative Model Updates: 9,580
Cumulative Timesteps: 159,900,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.57983
Policy Entropy: 1.26489
Value Function Loss: 0.61028

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.05796

Collected Steps per Second: 11,034.06583
Overall Steps per Second: 9,461.78512

Timestep Collection Time: 4.53360
Timestep Consumption Time: 0.75336
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 5.28695

Cumulative Model Updates: 9,583
Cumulative Timesteps: 159,950,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 159950878...
Checkpoint 159950878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.26978
Policy Entropy: 1.25041
Value Function Loss: 0.57453

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.05447

Collected Steps per Second: 10,257.24420
Overall Steps per Second: 8,478.20120

Timestep Collection Time: 4.87519
Timestep Consumption Time: 1.02300
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.89819

Cumulative Model Updates: 9,586
Cumulative Timesteps: 160,000,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.20664
Policy Entropy: 1.26351
Value Function Loss: 0.56329

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.05375

Collected Steps per Second: 10,812.50460
Overall Steps per Second: 9,191.43893

Timestep Collection Time: 4.62613
Timestep Consumption Time: 0.81590
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.44202

Cumulative Model Updates: 9,589
Cumulative Timesteps: 160,050,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 160050904...
Checkpoint 160050904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.28246
Policy Entropy: 1.25426
Value Function Loss: 0.52581

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.04944

Collected Steps per Second: 10,549.24007
Overall Steps per Second: 8,821.88039

Timestep Collection Time: 4.73968
Timestep Consumption Time: 0.92805
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.66773

Cumulative Model Updates: 9,592
Cumulative Timesteps: 160,100,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.85465
Policy Entropy: 1.25524
Value Function Loss: 0.59969

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04868
Policy Update Magnitude: 0.08146
Value Function Update Magnitude: 0.04925

Collected Steps per Second: 10,364.65545
Overall Steps per Second: 8,762.53659

Timestep Collection Time: 4.82640
Timestep Consumption Time: 0.88245
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 5.70885

Cumulative Model Updates: 9,595
Cumulative Timesteps: 160,150,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 160150928...
Checkpoint 160150928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.56438
Policy Entropy: 1.25170
Value Function Loss: 0.56585

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.08463
Value Function Update Magnitude: 0.04814

Collected Steps per Second: 10,178.93510
Overall Steps per Second: 8,762.20995

Timestep Collection Time: 4.91328
Timestep Consumption Time: 0.79441
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.70769

Cumulative Model Updates: 9,598
Cumulative Timesteps: 160,200,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.06666
Policy Entropy: 1.25193
Value Function Loss: 0.58814

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.07452
Value Function Update Magnitude: 0.05257

Collected Steps per Second: 10,271.27095
Overall Steps per Second: 8,530.09751

Timestep Collection Time: 4.86853
Timestep Consumption Time: 0.99377
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.86230

Cumulative Model Updates: 9,601
Cumulative Timesteps: 160,250,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 160250946...
Checkpoint 160250946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.30709
Policy Entropy: 1.26260
Value Function Loss: 0.57860

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.06500
Value Function Update Magnitude: 0.05237

Collected Steps per Second: 11,402.25380
Overall Steps per Second: 9,539.58940

Timestep Collection Time: 4.38633
Timestep Consumption Time: 0.85646
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.24278

Cumulative Model Updates: 9,604
Cumulative Timesteps: 160,300,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.52548
Policy Entropy: 1.26038
Value Function Loss: 0.57473

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.06803
Value Function Update Magnitude: 0.05931

Collected Steps per Second: 11,259.69987
Overall Steps per Second: 9,559.19585

Timestep Collection Time: 4.44062
Timestep Consumption Time: 0.78995
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 5.23057

Cumulative Model Updates: 9,607
Cumulative Timesteps: 160,350,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 160350960...
Checkpoint 160350960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.68202
Policy Entropy: 1.26172
Value Function Loss: 0.55007

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.06755

Collected Steps per Second: 11,461.93911
Overall Steps per Second: 9,649.58129

Timestep Collection Time: 4.36261
Timestep Consumption Time: 0.81937
PPO Batch Consumption Time: 0.03359
Total Iteration Time: 5.18199

Cumulative Model Updates: 9,610
Cumulative Timesteps: 160,400,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.96594
Policy Entropy: 1.26369
Value Function Loss: 0.52766

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.07226

Collected Steps per Second: 11,209.75621
Overall Steps per Second: 9,688.66119

Timestep Collection Time: 4.46147
Timestep Consumption Time: 0.70044
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.16191

Cumulative Model Updates: 9,613
Cumulative Timesteps: 160,450,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 160450976...
Checkpoint 160450976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.52683
Policy Entropy: 1.27166
Value Function Loss: 0.53350

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.05824

Collected Steps per Second: 11,166.69752
Overall Steps per Second: 9,464.69644

Timestep Collection Time: 4.47903
Timestep Consumption Time: 0.80545
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.28448

Cumulative Model Updates: 9,616
Cumulative Timesteps: 160,500,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.86265
Policy Entropy: 1.26097
Value Function Loss: 0.53980

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.06325
Value Function Update Magnitude: 0.06156

Collected Steps per Second: 10,513.03895
Overall Steps per Second: 9,019.91804

Timestep Collection Time: 4.75771
Timestep Consumption Time: 0.78757
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.54528

Cumulative Model Updates: 9,619
Cumulative Timesteps: 160,551,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 160551010...
Checkpoint 160551010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.78548
Policy Entropy: 1.27190
Value Function Loss: 0.56445

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.05485

Collected Steps per Second: 10,860.22428
Overall Steps per Second: 9,118.09646

Timestep Collection Time: 4.60653
Timestep Consumption Time: 0.88014
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.48667

Cumulative Model Updates: 9,622
Cumulative Timesteps: 160,601,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.87911
Policy Entropy: 1.25773
Value Function Loss: 0.58525

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.06249

Collected Steps per Second: 11,407.83252
Overall Steps per Second: 9,602.35505

Timestep Collection Time: 4.38541
Timestep Consumption Time: 0.82456
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.20997

Cumulative Model Updates: 9,625
Cumulative Timesteps: 160,651,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 160651066...
Checkpoint 160651066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.79279
Policy Entropy: 1.26773
Value Function Loss: 0.57250

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.05851

Collected Steps per Second: 11,459.22245
Overall Steps per Second: 9,846.66368

Timestep Collection Time: 4.36609
Timestep Consumption Time: 0.71502
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.08111

Cumulative Model Updates: 9,628
Cumulative Timesteps: 160,701,098

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.53824
Policy Entropy: 1.25716
Value Function Loss: 0.55764

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.05661

Collected Steps per Second: 11,189.19080
Overall Steps per Second: 9,441.39573

Timestep Collection Time: 4.46985
Timestep Consumption Time: 0.82746
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.29731

Cumulative Model Updates: 9,631
Cumulative Timesteps: 160,751,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 160751112...
Checkpoint 160751112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.62730
Policy Entropy: 1.27181
Value Function Loss: 0.56539

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07857
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.05654

Collected Steps per Second: 11,204.02583
Overall Steps per Second: 9,669.91765

Timestep Collection Time: 4.46500
Timestep Consumption Time: 0.70836
PPO Batch Consumption Time: 0.04357
Total Iteration Time: 5.17336

Cumulative Model Updates: 9,634
Cumulative Timesteps: 160,801,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.98503
Policy Entropy: 1.25749
Value Function Loss: 0.56722

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.05521

Collected Steps per Second: 9,583.74616
Overall Steps per Second: 8,188.51646

Timestep Collection Time: 5.21967
Timestep Consumption Time: 0.88937
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 6.10904

Cumulative Model Updates: 9,637
Cumulative Timesteps: 160,851,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 160851162...
Checkpoint 160851162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.91922
Policy Entropy: 1.26699
Value Function Loss: 0.56351

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.05708

Collected Steps per Second: 10,572.43596
Overall Steps per Second: 9,023.42651

Timestep Collection Time: 4.73098
Timestep Consumption Time: 0.81215
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.54313

Cumulative Model Updates: 9,640
Cumulative Timesteps: 160,901,180

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.72111
Policy Entropy: 1.26944
Value Function Loss: 0.56054

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.05843

Collected Steps per Second: 11,182.71639
Overall Steps per Second: 9,452.31914

Timestep Collection Time: 4.47172
Timestep Consumption Time: 0.81862
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 5.29034

Cumulative Model Updates: 9,643
Cumulative Timesteps: 160,951,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 160951186...
Checkpoint 160951186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.92873
Policy Entropy: 1.27035
Value Function Loss: 0.53037

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.05851

Collected Steps per Second: 11,005.75106
Overall Steps per Second: 9,308.75548

Timestep Collection Time: 4.54453
Timestep Consumption Time: 0.82847
PPO Batch Consumption Time: 0.03343
Total Iteration Time: 5.37301

Cumulative Model Updates: 9,646
Cumulative Timesteps: 161,001,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.54517
Policy Entropy: 1.27286
Value Function Loss: 0.51269

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.06065

Collected Steps per Second: 10,849.80813
Overall Steps per Second: 9,371.18452

Timestep Collection Time: 4.60930
Timestep Consumption Time: 0.72727
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.33657

Cumulative Model Updates: 9,649
Cumulative Timesteps: 161,051,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 161051212...
Checkpoint 161051212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.45940
Policy Entropy: 1.26870
Value Function Loss: 0.48738

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.05466

Collected Steps per Second: 10,766.93688
Overall Steps per Second: 9,188.88837

Timestep Collection Time: 4.64385
Timestep Consumption Time: 0.79751
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.44135

Cumulative Model Updates: 9,652
Cumulative Timesteps: 161,101,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.11941
Policy Entropy: 1.26542
Value Function Loss: 0.52106

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.05361
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.07704

Collected Steps per Second: 11,375.77897
Overall Steps per Second: 9,666.51340

Timestep Collection Time: 4.39671
Timestep Consumption Time: 0.77744
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.17415

Cumulative Model Updates: 9,655
Cumulative Timesteps: 161,151,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 161151228...
Checkpoint 161151228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.09170
Policy Entropy: 1.27099
Value Function Loss: 0.53429

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07067
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.09395

Collected Steps per Second: 11,276.44232
Overall Steps per Second: 9,369.16417

Timestep Collection Time: 4.43580
Timestep Consumption Time: 0.90299
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.33879

Cumulative Model Updates: 9,658
Cumulative Timesteps: 161,201,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.37323
Policy Entropy: 1.26908
Value Function Loss: 0.53471

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05463
Policy Update Magnitude: 0.06779
Value Function Update Magnitude: 0.09414

Collected Steps per Second: 11,363.34121
Overall Steps per Second: 9,501.89716

Timestep Collection Time: 4.40064
Timestep Consumption Time: 0.86210
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.26274

Cumulative Model Updates: 9,661
Cumulative Timesteps: 161,251,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 161251254...
Checkpoint 161251254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.94666
Policy Entropy: 1.26624
Value Function Loss: 0.52571

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05634
Policy Update Magnitude: 0.07162
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 11,695.67017
Overall Steps per Second: 9,969.32138

Timestep Collection Time: 4.27714
Timestep Consumption Time: 0.74066
PPO Batch Consumption Time: 0.03854
Total Iteration Time: 5.01779

Cumulative Model Updates: 9,664
Cumulative Timesteps: 161,301,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.92160
Policy Entropy: 1.26939
Value Function Loss: 0.54238

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06604
Policy Update Magnitude: 0.07079
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 12,193.01501
Overall Steps per Second: 10,175.72623

Timestep Collection Time: 4.10317
Timestep Consumption Time: 0.81343
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 4.91660

Cumulative Model Updates: 9,667
Cumulative Timesteps: 161,351,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 161351308...
Checkpoint 161351308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.90264
Policy Entropy: 1.26739
Value Function Loss: 0.56134

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.07090
Value Function Update Magnitude: 0.06907

Collected Steps per Second: 11,131.21136
Overall Steps per Second: 9,647.81612

Timestep Collection Time: 4.49187
Timestep Consumption Time: 0.69065
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.18252

Cumulative Model Updates: 9,670
Cumulative Timesteps: 161,401,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.83389
Policy Entropy: 1.26940
Value Function Loss: 0.57836

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.06601
Value Function Update Magnitude: 0.06984

Collected Steps per Second: 11,974.67071
Overall Steps per Second: 10,053.90937

Timestep Collection Time: 4.17581
Timestep Consumption Time: 0.79777
PPO Batch Consumption Time: 0.03327
Total Iteration Time: 4.97359

Cumulative Model Updates: 9,673
Cumulative Timesteps: 161,451,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 161451312...
Checkpoint 161451312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.39097
Policy Entropy: 1.27431
Value Function Loss: 0.52552

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10582
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.07792

Collected Steps per Second: 11,846.59014
Overall Steps per Second: 10,053.64436

Timestep Collection Time: 4.22147
Timestep Consumption Time: 0.75285
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 4.97432

Cumulative Model Updates: 9,676
Cumulative Timesteps: 161,501,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.23376
Policy Entropy: 1.27285
Value Function Loss: 0.52248

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.07758

Collected Steps per Second: 11,514.30490
Overall Steps per Second: 9,720.03886

Timestep Collection Time: 4.34399
Timestep Consumption Time: 0.80188
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.14586

Cumulative Model Updates: 9,679
Cumulative Timesteps: 161,551,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 161551340...
Checkpoint 161551340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.75769
Policy Entropy: 1.26856
Value Function Loss: 0.52118

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.07433

Collected Steps per Second: 11,185.76441
Overall Steps per Second: 9,560.80986

Timestep Collection Time: 4.46997
Timestep Consumption Time: 0.75972
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.22968

Cumulative Model Updates: 9,682
Cumulative Timesteps: 161,601,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.16309
Policy Entropy: 1.26644
Value Function Loss: 0.52188

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.06462

Collected Steps per Second: 11,945.68011
Overall Steps per Second: 10,178.75534

Timestep Collection Time: 4.18762
Timestep Consumption Time: 0.72693
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 4.91455

Cumulative Model Updates: 9,685
Cumulative Timesteps: 161,651,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 161651364...
Checkpoint 161651364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.59375
Policy Entropy: 1.26546
Value Function Loss: 0.52428

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.06717
Value Function Update Magnitude: 0.07728

Collected Steps per Second: 11,332.19276
Overall Steps per Second: 9,641.14404

Timestep Collection Time: 4.41291
Timestep Consumption Time: 0.77402
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 5.18694

Cumulative Model Updates: 9,688
Cumulative Timesteps: 161,701,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.81325
Policy Entropy: 1.26127
Value Function Loss: 0.51523

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.07049
Value Function Update Magnitude: 0.06545

Collected Steps per Second: 11,642.99386
Overall Steps per Second: 9,868.80392

Timestep Collection Time: 4.29443
Timestep Consumption Time: 0.77204
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.06647

Cumulative Model Updates: 9,691
Cumulative Timesteps: 161,751,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 161751372...
Checkpoint 161751372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.10679
Policy Entropy: 1.27010
Value Function Loss: 0.51440

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.06995
Value Function Update Magnitude: 0.06166

Collected Steps per Second: 11,896.44989
Overall Steps per Second: 9,989.89507

Timestep Collection Time: 4.20462
Timestep Consumption Time: 0.80244
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 5.00706

Cumulative Model Updates: 9,694
Cumulative Timesteps: 161,801,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.24011
Policy Entropy: 1.26460
Value Function Loss: 0.49352

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07004
Policy Update Magnitude: 0.07462
Value Function Update Magnitude: 0.05804

Collected Steps per Second: 11,740.30068
Overall Steps per Second: 9,889.55276

Timestep Collection Time: 4.26105
Timestep Consumption Time: 0.79742
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.05847

Cumulative Model Updates: 9,697
Cumulative Timesteps: 161,851,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 161851418...
Checkpoint 161851418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.88749
Policy Entropy: 1.26555
Value Function Loss: 0.48058

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.07425
Value Function Update Magnitude: 0.05415

Collected Steps per Second: 11,452.49358
Overall Steps per Second: 9,887.32769

Timestep Collection Time: 4.36621
Timestep Consumption Time: 0.69117
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.05738

Cumulative Model Updates: 9,700
Cumulative Timesteps: 161,901,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.02259
Policy Entropy: 1.26868
Value Function Loss: 0.49087

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05387
Policy Update Magnitude: 0.06838
Value Function Update Magnitude: 0.07576

Collected Steps per Second: 11,684.54195
Overall Steps per Second: 9,768.09725

Timestep Collection Time: 4.27967
Timestep Consumption Time: 0.83965
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 5.11932

Cumulative Model Updates: 9,703
Cumulative Timesteps: 161,951,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 161951428...
Checkpoint 161951428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.68952
Policy Entropy: 1.26913
Value Function Loss: 0.48533

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05689
Policy Update Magnitude: 0.06912
Value Function Update Magnitude: 0.09510

Collected Steps per Second: 11,371.32515
Overall Steps per Second: 9,632.33568

Timestep Collection Time: 4.39808
Timestep Consumption Time: 0.79401
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 5.19209

Cumulative Model Updates: 9,706
Cumulative Timesteps: 162,001,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.91593
Policy Entropy: 1.26558
Value Function Loss: 0.49318

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06160
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.08848

Collected Steps per Second: 12,017.43104
Overall Steps per Second: 10,063.62086

Timestep Collection Time: 4.16262
Timestep Consumption Time: 0.80816
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.97078

Cumulative Model Updates: 9,709
Cumulative Timesteps: 162,051,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 162051464...
Checkpoint 162051464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.86618
Policy Entropy: 1.26822
Value Function Loss: 0.50290

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04945
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.09688

Collected Steps per Second: 11,600.99454
Overall Steps per Second: 9,833.95802

Timestep Collection Time: 4.31118
Timestep Consumption Time: 0.77466
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.08585

Cumulative Model Updates: 9,712
Cumulative Timesteps: 162,101,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.16987
Policy Entropy: 1.26696
Value Function Loss: 0.52323

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05029
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.09013

Collected Steps per Second: 11,739.99116
Overall Steps per Second: 10,062.19745

Timestep Collection Time: 4.26133
Timestep Consumption Time: 0.71054
PPO Batch Consumption Time: 0.03372
Total Iteration Time: 4.97188

Cumulative Model Updates: 9,715
Cumulative Timesteps: 162,151,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 162151506...
Checkpoint 162151506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.02323
Policy Entropy: 1.26559
Value Function Loss: 0.50665

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04987
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.07783

Collected Steps per Second: 11,689.70081
Overall Steps per Second: 9,782.82634

Timestep Collection Time: 4.27984
Timestep Consumption Time: 0.83423
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.11406

Cumulative Model Updates: 9,718
Cumulative Timesteps: 162,201,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.62441
Policy Entropy: 1.27078
Value Function Loss: 0.51816

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05259
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.06552

Collected Steps per Second: 11,747.02816
Overall Steps per Second: 9,613.36227

Timestep Collection Time: 4.25674
Timestep Consumption Time: 0.94477
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.20151

Cumulative Model Updates: 9,721
Cumulative Timesteps: 162,251,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 162251540...
Checkpoint 162251540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.56145
Policy Entropy: 1.27260
Value Function Loss: 0.54315

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05836
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.05589

Collected Steps per Second: 12,040.35302
Overall Steps per Second: 10,050.95175

Timestep Collection Time: 4.15353
Timestep Consumption Time: 0.82212
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 4.97565

Cumulative Model Updates: 9,724
Cumulative Timesteps: 162,301,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.47160
Policy Entropy: 1.26853
Value Function Loss: 0.59117

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06321
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.05434

Collected Steps per Second: 11,827.39300
Overall Steps per Second: 9,897.91016

Timestep Collection Time: 4.22798
Timestep Consumption Time: 0.82420
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.05218

Cumulative Model Updates: 9,727
Cumulative Timesteps: 162,351,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 162351556...
Checkpoint 162351556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.91283
Policy Entropy: 1.26959
Value Function Loss: 0.54114

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05146
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.05728

Collected Steps per Second: 11,822.96497
Overall Steps per Second: 9,996.64553

Timestep Collection Time: 4.22957
Timestep Consumption Time: 0.77271
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 5.00228

Cumulative Model Updates: 9,730
Cumulative Timesteps: 162,401,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.02851
Policy Entropy: 1.26279
Value Function Loss: 0.51966

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05121
Policy Update Magnitude: 0.06565
Value Function Update Magnitude: 0.06312

Collected Steps per Second: 12,064.74693
Overall Steps per Second: 10,101.09229

Timestep Collection Time: 4.14696
Timestep Consumption Time: 0.80617
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 4.95313

Cumulative Model Updates: 9,733
Cumulative Timesteps: 162,451,594

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 162451594...
Checkpoint 162451594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.51112
Policy Entropy: 1.27111
Value Function Loss: 0.47270

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.05676

Collected Steps per Second: 11,436.41354
Overall Steps per Second: 9,684.38003

Timestep Collection Time: 4.37287
Timestep Consumption Time: 0.79111
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.16399

Cumulative Model Updates: 9,736
Cumulative Timesteps: 162,501,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.63772
Policy Entropy: 1.26629
Value Function Loss: 0.44660

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.06739

Collected Steps per Second: 12,552.10383
Overall Steps per Second: 10,429.35289

Timestep Collection Time: 3.98435
Timestep Consumption Time: 0.81096
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 4.79531

Cumulative Model Updates: 9,739
Cumulative Timesteps: 162,551,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 162551616...
Checkpoint 162551616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.20621
Policy Entropy: 1.27255
Value Function Loss: 0.47802

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.07394

Collected Steps per Second: 12,482.47467
Overall Steps per Second: 10,391.34314

Timestep Collection Time: 4.00770
Timestep Consumption Time: 0.80650
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.81420

Cumulative Model Updates: 9,742
Cumulative Timesteps: 162,601,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.28893
Policy Entropy: 1.26576
Value Function Loss: 0.48488

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.07349

Collected Steps per Second: 12,776.52874
Overall Steps per Second: 10,877.13957

Timestep Collection Time: 3.91546
Timestep Consumption Time: 0.68373
PPO Batch Consumption Time: 0.03792
Total Iteration Time: 4.59919

Cumulative Model Updates: 9,745
Cumulative Timesteps: 162,651,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 162651668...
Checkpoint 162651668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.18670
Policy Entropy: 1.27573
Value Function Loss: 0.52748

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.06761

Collected Steps per Second: 12,643.42849
Overall Steps per Second: 10,558.89351

Timestep Collection Time: 3.95510
Timestep Consumption Time: 0.78081
PPO Batch Consumption Time: 0.03372
Total Iteration Time: 4.73591

Cumulative Model Updates: 9,748
Cumulative Timesteps: 162,701,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.95516
Policy Entropy: 1.27161
Value Function Loss: 0.47998

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.09088

Collected Steps per Second: 12,880.16394
Overall Steps per Second: 10,768.52272

Timestep Collection Time: 3.88240
Timestep Consumption Time: 0.76132
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 4.64372

Cumulative Model Updates: 9,751
Cumulative Timesteps: 162,751,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 162751680...
Checkpoint 162751680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.67474
Policy Entropy: 1.28365
Value Function Loss: 0.48339

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.09061

Collected Steps per Second: 12,013.20468
Overall Steps per Second: 9,959.03994

Timestep Collection Time: 4.16458
Timestep Consumption Time: 0.85899
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.02358

Cumulative Model Updates: 9,754
Cumulative Timesteps: 162,801,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.48732
Policy Entropy: 1.27643
Value Function Loss: 0.46670

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06088
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.09250

Collected Steps per Second: 11,832.36817
Overall Steps per Second: 9,904.62760

Timestep Collection Time: 4.22587
Timestep Consumption Time: 0.82248
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.04835

Cumulative Model Updates: 9,757
Cumulative Timesteps: 162,851,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 162851712...
Checkpoint 162851712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.12391
Policy Entropy: 1.28393
Value Function Loss: 0.50706

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06525
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.07442

Collected Steps per Second: 11,232.84821
Overall Steps per Second: 9,638.68795

Timestep Collection Time: 4.45266
Timestep Consumption Time: 0.73643
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.18909

Cumulative Model Updates: 9,760
Cumulative Timesteps: 162,901,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.32137
Policy Entropy: 1.27818
Value Function Loss: 0.51356

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07209
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.06972

Collected Steps per Second: 12,287.59415
Overall Steps per Second: 10,201.46372

Timestep Collection Time: 4.07159
Timestep Consumption Time: 0.83261
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 4.90420

Cumulative Model Updates: 9,763
Cumulative Timesteps: 162,951,758

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 162951758...
Checkpoint 162951758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.28384
Policy Entropy: 1.27956
Value Function Loss: 0.52609

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07116
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.06743

Collected Steps per Second: 12,188.25099
Overall Steps per Second: 10,185.42162

Timestep Collection Time: 4.10494
Timestep Consumption Time: 0.80718
PPO Batch Consumption Time: 0.04277
Total Iteration Time: 4.91212

Cumulative Model Updates: 9,766
Cumulative Timesteps: 163,001,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.98880
Policy Entropy: 1.27933
Value Function Loss: 0.48846

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05599
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.06490

Collected Steps per Second: 12,463.53823
Overall Steps per Second: 10,407.92661

Timestep Collection Time: 4.01170
Timestep Consumption Time: 0.79233
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.80403

Cumulative Model Updates: 9,769
Cumulative Timesteps: 163,051,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 163051790...
Checkpoint 163051790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.23518
Policy Entropy: 1.28286
Value Function Loss: 0.45497

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05064
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 11,929.64543
Overall Steps per Second: 10,128.34153

Timestep Collection Time: 4.19258
Timestep Consumption Time: 0.74564
PPO Batch Consumption Time: 0.03802
Total Iteration Time: 4.93822

Cumulative Model Updates: 9,772
Cumulative Timesteps: 163,101,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.14674
Policy Entropy: 1.27823
Value Function Loss: 0.42444

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05376
Policy Update Magnitude: 0.06789
Value Function Update Magnitude: 0.07218

Collected Steps per Second: 11,807.74749
Overall Steps per Second: 10,157.58863

Timestep Collection Time: 4.23620
Timestep Consumption Time: 0.68820
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 4.92440

Cumulative Model Updates: 9,775
Cumulative Timesteps: 163,151,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 163151826...
Checkpoint 163151826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.84055
Policy Entropy: 1.28538
Value Function Loss: 0.45260

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.06398

Collected Steps per Second: 11,221.33530
Overall Steps per Second: 9,589.59782

Timestep Collection Time: 4.45580
Timestep Consumption Time: 0.75819
PPO Batch Consumption Time: 0.03287
Total Iteration Time: 5.21398

Cumulative Model Updates: 9,778
Cumulative Timesteps: 163,201,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.42211
Policy Entropy: 1.27910
Value Function Loss: 0.46179

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05765
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.06363

Collected Steps per Second: 12,016.46538
Overall Steps per Second: 10,192.13887

Timestep Collection Time: 4.16246
Timestep Consumption Time: 0.74505
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 4.90751

Cumulative Model Updates: 9,781
Cumulative Timesteps: 163,251,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 163251844...
Checkpoint 163251844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.67217
Policy Entropy: 1.28687
Value Function Loss: 0.47570

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.05791
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.08003

Collected Steps per Second: 12,233.82634
Overall Steps per Second: 10,231.53219

Timestep Collection Time: 4.08834
Timestep Consumption Time: 0.80008
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 4.88842

Cumulative Model Updates: 9,784
Cumulative Timesteps: 163,301,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.72253
Policy Entropy: 1.28362
Value Function Loss: 0.46344

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04998
Policy Update Magnitude: 0.04400
Value Function Update Magnitude: 0.07022

Collected Steps per Second: 12,002.43686
Overall Steps per Second: 10,218.91008

Timestep Collection Time: 4.16782
Timestep Consumption Time: 0.72742
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 4.89524

Cumulative Model Updates: 9,787
Cumulative Timesteps: 163,351,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 163351884...
Checkpoint 163351884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.49518
Policy Entropy: 1.28439
Value Function Loss: 0.51268

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04545
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.06018

Collected Steps per Second: 11,764.70478
Overall Steps per Second: 10,052.03370

Timestep Collection Time: 4.25204
Timestep Consumption Time: 0.72447
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 4.97651

Cumulative Model Updates: 9,790
Cumulative Timesteps: 163,401,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.40006
Policy Entropy: 1.28094
Value Function Loss: 0.47557

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05663
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.05563

Collected Steps per Second: 12,105.72901
Overall Steps per Second: 10,201.72706

Timestep Collection Time: 4.13127
Timestep Consumption Time: 0.77104
PPO Batch Consumption Time: 0.03295
Total Iteration Time: 4.90231

Cumulative Model Updates: 9,793
Cumulative Timesteps: 163,451,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 163451920...
Checkpoint 163451920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.04900
Policy Entropy: 1.28228
Value Function Loss: 0.49743

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05665
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.08636

Collected Steps per Second: 11,442.92549
Overall Steps per Second: 9,742.44739

Timestep Collection Time: 4.37021
Timestep Consumption Time: 0.76279
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.13300

Cumulative Model Updates: 9,796
Cumulative Timesteps: 163,501,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.97898
Policy Entropy: 1.28175
Value Function Loss: 0.49326

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06073
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 12,234.67219
Overall Steps per Second: 10,278.99522

Timestep Collection Time: 4.08887
Timestep Consumption Time: 0.77795
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.86682

Cumulative Model Updates: 9,799
Cumulative Timesteps: 163,551,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 163551954...
Checkpoint 163551954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.75723
Policy Entropy: 1.27731
Value Function Loss: 0.50594

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.08227

Collected Steps per Second: 11,846.66567
Overall Steps per Second: 9,941.98264

Timestep Collection Time: 4.22296
Timestep Consumption Time: 0.80903
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 5.03199

Cumulative Model Updates: 9,802
Cumulative Timesteps: 163,601,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.65569
Policy Entropy: 1.28058
Value Function Loss: 0.47406

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05621
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.06862

Collected Steps per Second: 11,985.65393
Overall Steps per Second: 10,156.52135

Timestep Collection Time: 4.17266
Timestep Consumption Time: 0.75147
PPO Batch Consumption Time: 0.03888
Total Iteration Time: 4.92413

Cumulative Model Updates: 9,805
Cumulative Timesteps: 163,651,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 163651994...
Checkpoint 163651994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.22349
Policy Entropy: 1.27726
Value Function Loss: 0.45162

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04691
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.06573

Collected Steps per Second: 12,240.54688
Overall Steps per Second: 10,185.24498

Timestep Collection Time: 4.08691
Timestep Consumption Time: 0.82471
PPO Batch Consumption Time: 0.03961
Total Iteration Time: 4.91161

Cumulative Model Updates: 9,808
Cumulative Timesteps: 163,702,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.12424
Policy Entropy: 1.27205
Value Function Loss: 0.44371

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.06059
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.09328

Collected Steps per Second: 12,090.75052
Overall Steps per Second: 10,254.23673

Timestep Collection Time: 4.13771
Timestep Consumption Time: 0.74106
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 4.87876

Cumulative Model Updates: 9,811
Cumulative Timesteps: 163,752,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 163752048...
Checkpoint 163752048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.93493
Policy Entropy: 1.27148
Value Function Loss: 0.46811

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05649
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.08198

Collected Steps per Second: 11,304.76543
Overall Steps per Second: 9,581.69560

Timestep Collection Time: 4.42362
Timestep Consumption Time: 0.79550
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 5.21912

Cumulative Model Updates: 9,814
Cumulative Timesteps: 163,802,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.75406
Policy Entropy: 1.27881
Value Function Loss: 0.48987

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.06745

Collected Steps per Second: 12,076.22808
Overall Steps per Second: 10,153.79447

Timestep Collection Time: 4.14086
Timestep Consumption Time: 0.78400
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.92486

Cumulative Model Updates: 9,817
Cumulative Timesteps: 163,852,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 163852062...
Checkpoint 163852062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.79524
Policy Entropy: 1.27179
Value Function Loss: 0.47749

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.06675

Collected Steps per Second: 12,174.69171
Overall Steps per Second: 10,249.01585

Timestep Collection Time: 4.10934
Timestep Consumption Time: 0.77210
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.88144

Cumulative Model Updates: 9,820
Cumulative Timesteps: 163,902,092

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.75039
Policy Entropy: 1.27889
Value Function Loss: 0.45369

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06131
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.06211

Collected Steps per Second: 12,205.48091
Overall Steps per Second: 10,268.01018

Timestep Collection Time: 4.09767
Timestep Consumption Time: 0.77319
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.87086

Cumulative Model Updates: 9,823
Cumulative Timesteps: 163,952,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 163952106...
Checkpoint 163952106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.05924
Policy Entropy: 1.27623
Value Function Loss: 0.42752

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.04425
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 11,874.14442
Overall Steps per Second: 10,160.26189

Timestep Collection Time: 4.21235
Timestep Consumption Time: 0.71056
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.92290

Cumulative Model Updates: 9,826
Cumulative Timesteps: 164,002,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.15191
Policy Entropy: 1.28347
Value Function Loss: 0.43327

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05351
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.06627

Collected Steps per Second: 11,966.36252
Overall Steps per Second: 10,040.25898

Timestep Collection Time: 4.18038
Timestep Consumption Time: 0.80196
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.98234

Cumulative Model Updates: 9,829
Cumulative Timesteps: 164,052,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 164052148...
Checkpoint 164052148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.02147
Policy Entropy: 1.27449
Value Function Loss: 0.44510

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.07244

Collected Steps per Second: 11,100.06507
Overall Steps per Second: 9,426.63830

Timestep Collection Time: 4.50448
Timestep Consumption Time: 0.79964
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.30412

Cumulative Model Updates: 9,832
Cumulative Timesteps: 164,102,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.96213
Policy Entropy: 1.28167
Value Function Loss: 0.44333

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.06317

Collected Steps per Second: 12,434.00929
Overall Steps per Second: 10,412.39727

Timestep Collection Time: 4.02155
Timestep Consumption Time: 0.78080
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.80235

Cumulative Model Updates: 9,835
Cumulative Timesteps: 164,152,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 164152152...
Checkpoint 164152152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.35993
Policy Entropy: 1.27184
Value Function Loss: 0.46491

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.05153

Collected Steps per Second: 11,894.28953
Overall Steps per Second: 10,074.02113

Timestep Collection Time: 4.20437
Timestep Consumption Time: 0.75968
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.96406

Cumulative Model Updates: 9,838
Cumulative Timesteps: 164,202,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.48216
Policy Entropy: 1.28374
Value Function Loss: 0.46483

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.05281

Collected Steps per Second: 11,727.31030
Overall Steps per Second: 10,085.16080

Timestep Collection Time: 4.26423
Timestep Consumption Time: 0.69434
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 4.95857

Cumulative Model Updates: 9,841
Cumulative Timesteps: 164,252,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 164252168...
Checkpoint 164252168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.46265
Policy Entropy: 1.27626
Value Function Loss: 0.47748

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.04680

Collected Steps per Second: 11,885.96970
Overall Steps per Second: 9,988.94704

Timestep Collection Time: 4.20748
Timestep Consumption Time: 0.79905
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.00653

Cumulative Model Updates: 9,844
Cumulative Timesteps: 164,302,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.77323
Policy Entropy: 1.27915
Value Function Loss: 0.46394

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.04271

Collected Steps per Second: 12,104.82967
Overall Steps per Second: 10,136.26125

Timestep Collection Time: 4.13273
Timestep Consumption Time: 0.80262
PPO Batch Consumption Time: 0.03390
Total Iteration Time: 4.93535

Cumulative Model Updates: 9,847
Cumulative Timesteps: 164,352,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 164352204...
Checkpoint 164352204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.77600
Policy Entropy: 1.28256
Value Function Loss: 0.49305

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06631
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.06111

Collected Steps per Second: 11,502.41804
Overall Steps per Second: 9,750.01417

Timestep Collection Time: 4.34830
Timestep Consumption Time: 0.78154
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.12984

Cumulative Model Updates: 9,850
Cumulative Timesteps: 164,402,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.18512
Policy Entropy: 1.27584
Value Function Loss: 0.52232

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05837
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.07588

Collected Steps per Second: 12,174.47316
Overall Steps per Second: 10,270.44991

Timestep Collection Time: 4.10843
Timestep Consumption Time: 0.76166
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 4.87009

Cumulative Model Updates: 9,853
Cumulative Timesteps: 164,452,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 164452238...
Checkpoint 164452238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.96409
Policy Entropy: 1.28242
Value Function Loss: 0.51756

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.04027
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.07516

Collected Steps per Second: 11,953.15036
Overall Steps per Second: 10,215.65542

Timestep Collection Time: 4.18501
Timestep Consumption Time: 0.71179
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.89680

Cumulative Model Updates: 9,856
Cumulative Timesteps: 164,502,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.53057
Policy Entropy: 1.27548
Value Function Loss: 0.55762

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.07910

Collected Steps per Second: 11,963.55235
Overall Steps per Second: 10,034.27441

Timestep Collection Time: 4.18103
Timestep Consumption Time: 0.80388
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.98491

Cumulative Model Updates: 9,859
Cumulative Timesteps: 164,552,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 164552282...
Checkpoint 164552282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.69743
Policy Entropy: 1.27754
Value Function Loss: 0.51633

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.06231
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.06715

Collected Steps per Second: 11,783.82583
Overall Steps per Second: 9,999.68965

Timestep Collection Time: 4.24361
Timestep Consumption Time: 0.75714
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.00076

Cumulative Model Updates: 9,862
Cumulative Timesteps: 164,602,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.40728
Policy Entropy: 1.27242
Value Function Loss: 0.54833

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.06626
Value Function Update Magnitude: 0.06388

Collected Steps per Second: 12,102.71294
Overall Steps per Second: 10,169.28602

Timestep Collection Time: 4.13312
Timestep Consumption Time: 0.78581
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 4.91893

Cumulative Model Updates: 9,865
Cumulative Timesteps: 164,652,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 164652310...
Checkpoint 164652310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.62268
Policy Entropy: 1.27417
Value Function Loss: 0.50968

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.06951

Collected Steps per Second: 11,119.23285
Overall Steps per Second: 9,439.35944

Timestep Collection Time: 4.49671
Timestep Consumption Time: 0.80026
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.29697

Cumulative Model Updates: 9,868
Cumulative Timesteps: 164,702,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.50065
Policy Entropy: 1.27010
Value Function Loss: 0.48977

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.06569

Collected Steps per Second: 11,812.72870
Overall Steps per Second: 10,170.40108

Timestep Collection Time: 4.23492
Timestep Consumption Time: 0.68386
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 4.91878

Cumulative Model Updates: 9,871
Cumulative Timesteps: 164,752,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 164752336...
Checkpoint 164752336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.95250
Policy Entropy: 1.27686
Value Function Loss: 0.42348

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06461
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.05769

Collected Steps per Second: 11,929.35566
Overall Steps per Second: 10,032.73706

Timestep Collection Time: 4.19319
Timestep Consumption Time: 0.79269
PPO Batch Consumption Time: 0.03354
Total Iteration Time: 4.98588

Cumulative Model Updates: 9,874
Cumulative Timesteps: 164,802,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.49374
Policy Entropy: 1.27781
Value Function Loss: 0.43983

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05405
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.06759

Collected Steps per Second: 11,785.55772
Overall Steps per Second: 10,095.58581

Timestep Collection Time: 4.24248
Timestep Consumption Time: 0.71018
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 4.95266

Cumulative Model Updates: 9,877
Cumulative Timesteps: 164,852,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 164852358...
Checkpoint 164852358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.67610
Policy Entropy: 1.27943
Value Function Loss: 0.44266

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05574
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.06696

Collected Steps per Second: 12,561.75720
Overall Steps per Second: 10,436.65254

Timestep Collection Time: 3.98209
Timestep Consumption Time: 0.81083
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.79292

Cumulative Model Updates: 9,880
Cumulative Timesteps: 164,902,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.71280
Policy Entropy: 1.27590
Value Function Loss: 0.44813

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05251
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.06091

Collected Steps per Second: 12,410.10866
Overall Steps per Second: 10,396.05468

Timestep Collection Time: 4.03010
Timestep Consumption Time: 0.78076
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.81086

Cumulative Model Updates: 9,883
Cumulative Timesteps: 164,952,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 164952394...
Checkpoint 164952394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.18284
Policy Entropy: 1.27816
Value Function Loss: 0.43538

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04909
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.05698

Collected Steps per Second: 11,808.56583
Overall Steps per Second: 9,999.26778

Timestep Collection Time: 4.23608
Timestep Consumption Time: 0.76649
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.00257

Cumulative Model Updates: 9,886
Cumulative Timesteps: 165,002,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.54103
Policy Entropy: 1.27481
Value Function Loss: 0.49921

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05457
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.05799

Collected Steps per Second: 12,317.07810
Overall Steps per Second: 10,302.27363

Timestep Collection Time: 4.06087
Timestep Consumption Time: 0.79418
PPO Batch Consumption Time: 0.03356
Total Iteration Time: 4.85504

Cumulative Model Updates: 9,889
Cumulative Timesteps: 165,052,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 165052434...
Checkpoint 165052434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.48598
Policy Entropy: 1.27751
Value Function Loss: 0.48388

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05574
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 12,814.39837
Overall Steps per Second: 10,643.38673

Timestep Collection Time: 3.90311
Timestep Consumption Time: 0.79615
PPO Batch Consumption Time: 0.03333
Total Iteration Time: 4.69926

Cumulative Model Updates: 9,892
Cumulative Timesteps: 165,102,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.26825
Policy Entropy: 1.27345
Value Function Loss: 0.46505

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05507
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.05824

Collected Steps per Second: 12,624.35164
Overall Steps per Second: 10,470.12366

Timestep Collection Time: 3.96234
Timestep Consumption Time: 0.81525
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 4.77759

Cumulative Model Updates: 9,895
Cumulative Timesteps: 165,152,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 165152472...
Checkpoint 165152472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.51710
Policy Entropy: 1.27614
Value Function Loss: 0.43849

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05985
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.06163

Collected Steps per Second: 12,011.19668
Overall Steps per Second: 10,113.97908

Timestep Collection Time: 4.16495
Timestep Consumption Time: 0.78128
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.94622

Cumulative Model Updates: 9,898
Cumulative Timesteps: 165,202,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.08971
Policy Entropy: 1.27852
Value Function Loss: 0.49197

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05089
Policy Update Magnitude: 0.06547
Value Function Update Magnitude: 0.06688

Collected Steps per Second: 11,858.92811
Overall Steps per Second: 9,999.52087

Timestep Collection Time: 4.21843
Timestep Consumption Time: 0.78441
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 5.00284

Cumulative Model Updates: 9,901
Cumulative Timesteps: 165,252,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 165252524...
Checkpoint 165252524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.67685
Policy Entropy: 1.27362
Value Function Loss: 0.51145

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04467
Policy Update Magnitude: 0.07451
Value Function Update Magnitude: 0.05125

Collected Steps per Second: 11,310.59029
Overall Steps per Second: 9,561.52205

Timestep Collection Time: 4.42293
Timestep Consumption Time: 0.80908
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.23201

Cumulative Model Updates: 9,904
Cumulative Timesteps: 165,302,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.48698
Policy Entropy: 1.27321
Value Function Loss: 0.45559

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06571
Policy Update Magnitude: 0.07514
Value Function Update Magnitude: 0.04507

Collected Steps per Second: 12,038.69335
Overall Steps per Second: 10,066.13966

Timestep Collection Time: 4.15510
Timestep Consumption Time: 0.81423
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.96933

Cumulative Model Updates: 9,907
Cumulative Timesteps: 165,352,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 165352572...
Checkpoint 165352572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.35359
Policy Entropy: 1.26874
Value Function Loss: 0.44024

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.06258
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 12,169.47685
Overall Steps per Second: 10,161.50463

Timestep Collection Time: 4.11061
Timestep Consumption Time: 0.81228
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 4.92289

Cumulative Model Updates: 9,910
Cumulative Timesteps: 165,402,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.68415
Policy Entropy: 1.27448
Value Function Loss: 0.43403

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.07098

Collected Steps per Second: 11,739.97709
Overall Steps per Second: 9,892.22002

Timestep Collection Time: 4.26014
Timestep Consumption Time: 0.79575
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.05589

Cumulative Model Updates: 9,913
Cumulative Timesteps: 165,452,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 165452610...
Checkpoint 165452610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.38483
Policy Entropy: 1.27416
Value Function Loss: 0.49524

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07518
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.05951

Collected Steps per Second: 11,722.80258
Overall Steps per Second: 9,943.53723

Timestep Collection Time: 4.26570
Timestep Consumption Time: 0.76329
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 5.02900

Cumulative Model Updates: 9,916
Cumulative Timesteps: 165,502,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.17552
Policy Entropy: 1.27359
Value Function Loss: 0.50281

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05151
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.04758

Collected Steps per Second: 11,926.06100
Overall Steps per Second: 10,029.36630

Timestep Collection Time: 4.19434
Timestep Consumption Time: 0.79321
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.98755

Cumulative Model Updates: 9,919
Cumulative Timesteps: 165,552,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 165552638...
Checkpoint 165552638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.15574
Policy Entropy: 1.27233
Value Function Loss: 0.48580

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04854
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.04944

Collected Steps per Second: 11,120.08615
Overall Steps per Second: 9,579.65125

Timestep Collection Time: 4.49853
Timestep Consumption Time: 0.72338
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.22190

Cumulative Model Updates: 9,922
Cumulative Timesteps: 165,602,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.80977
Policy Entropy: 1.27654
Value Function Loss: 0.44593

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06248
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.04161

Collected Steps per Second: 11,478.79995
Overall Steps per Second: 9,709.34583

Timestep Collection Time: 4.35620
Timestep Consumption Time: 0.79389
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.15009

Cumulative Model Updates: 9,925
Cumulative Timesteps: 165,652,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 165652666...
Checkpoint 165652666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.67495
Policy Entropy: 1.27738
Value Function Loss: 0.41955

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04356
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.04177

Collected Steps per Second: 11,554.91552
Overall Steps per Second: 9,837.67192

Timestep Collection Time: 4.32907
Timestep Consumption Time: 0.75567
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.08474

Cumulative Model Updates: 9,928
Cumulative Timesteps: 165,702,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.91562
Policy Entropy: 1.27919
Value Function Loss: 0.42491

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04859
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.03844

Collected Steps per Second: 11,872.15499
Overall Steps per Second: 9,974.98793

Timestep Collection Time: 4.21204
Timestep Consumption Time: 0.80110
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.01314

Cumulative Model Updates: 9,931
Cumulative Timesteps: 165,752,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 165752694...
Checkpoint 165752694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.17026
Policy Entropy: 1.27388
Value Function Loss: 0.42977

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05623
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.04283

Collected Steps per Second: 11,694.76090
Overall Steps per Second: 9,875.55888

Timestep Collection Time: 4.27798
Timestep Consumption Time: 0.78806
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.06604

Cumulative Model Updates: 9,934
Cumulative Timesteps: 165,802,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.96553
Policy Entropy: 1.27974
Value Function Loss: 0.42017

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05390
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.04129

Collected Steps per Second: 11,770.00175
Overall Steps per Second: 10,076.39591

Timestep Collection Time: 4.24860
Timestep Consumption Time: 0.71409
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.96269

Cumulative Model Updates: 9,937
Cumulative Timesteps: 165,852,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 165852730...
Checkpoint 165852730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.45597
Policy Entropy: 1.27585
Value Function Loss: 0.40245

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.05700
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.04692

Collected Steps per Second: 10,644.30729
Overall Steps per Second: 9,082.11229

Timestep Collection Time: 4.69847
Timestep Consumption Time: 0.80817
PPO Batch Consumption Time: 0.03353
Total Iteration Time: 5.50665

Cumulative Model Updates: 9,940
Cumulative Timesteps: 165,902,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.49655
Policy Entropy: 1.28035
Value Function Loss: 0.44709

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05923
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.04257

Collected Steps per Second: 11,870.67260
Overall Steps per Second: 10,162.83388

Timestep Collection Time: 4.21442
Timestep Consumption Time: 0.70822
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.92264

Cumulative Model Updates: 9,943
Cumulative Timesteps: 165,952,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 165952770...
Checkpoint 165952770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.11784
Policy Entropy: 1.27671
Value Function Loss: 0.48641

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06652
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.03893

Collected Steps per Second: 11,988.57361
Overall Steps per Second: 10,067.50542

Timestep Collection Time: 4.17231
Timestep Consumption Time: 0.79615
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 4.96846

Cumulative Model Updates: 9,946
Cumulative Timesteps: 166,002,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.13891
Policy Entropy: 1.28106
Value Function Loss: 0.48410

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.05714

Collected Steps per Second: 11,881.33866
Overall Steps per Second: 10,061.64275

Timestep Collection Time: 4.20929
Timestep Consumption Time: 0.76127
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 4.97056

Cumulative Model Updates: 9,949
Cumulative Timesteps: 166,052,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 166052802...
Checkpoint 166052802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.08423
Policy Entropy: 1.28411
Value Function Loss: 0.47280

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.04285
Value Function Update Magnitude: 0.05295

Collected Steps per Second: 12,112.80950
Overall Steps per Second: 10,279.30327

Timestep Collection Time: 4.12786
Timestep Consumption Time: 0.73628
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.86414

Cumulative Model Updates: 9,952
Cumulative Timesteps: 166,102,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.71627
Policy Entropy: 1.28087
Value Function Loss: 0.42716

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.06359

Collected Steps per Second: 11,200.43938
Overall Steps per Second: 9,555.60313

Timestep Collection Time: 4.46554
Timestep Consumption Time: 0.76867
PPO Batch Consumption Time: 0.03339
Total Iteration Time: 5.23421

Cumulative Model Updates: 9,955
Cumulative Timesteps: 166,152,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 166152818...
Checkpoint 166152818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.15600
Policy Entropy: 1.28292
Value Function Loss: 0.47928

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.04061
Value Function Update Magnitude: 0.06275

Collected Steps per Second: 11,167.33218
Overall Steps per Second: 9,488.61159

Timestep Collection Time: 4.48021
Timestep Consumption Time: 0.79264
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.27285

Cumulative Model Updates: 9,958
Cumulative Timesteps: 166,202,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.53000
Policy Entropy: 1.27749
Value Function Loss: 0.45185

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.04358
Value Function Update Magnitude: 0.04941

Collected Steps per Second: 11,982.10444
Overall Steps per Second: 10,097.48265

Timestep Collection Time: 4.17523
Timestep Consumption Time: 0.77928
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.95450

Cumulative Model Updates: 9,961
Cumulative Timesteps: 166,252,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 166252878...
Checkpoint 166252878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.37972
Policy Entropy: 1.28026
Value Function Loss: 0.51237

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.03953
Value Function Update Magnitude: 0.04628

Collected Steps per Second: 12,418.98373
Overall Steps per Second: 10,289.19813

Timestep Collection Time: 4.02819
Timestep Consumption Time: 0.83380
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 4.86199

Cumulative Model Updates: 9,964
Cumulative Timesteps: 166,302,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.96360
Policy Entropy: 1.28020
Value Function Loss: 0.45366

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07032
Policy Update Magnitude: 0.03817
Value Function Update Magnitude: 0.04498

Collected Steps per Second: 12,309.65115
Overall Steps per Second: 10,280.06149

Timestep Collection Time: 4.06332
Timestep Consumption Time: 0.80222
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.86554

Cumulative Model Updates: 9,967
Cumulative Timesteps: 166,352,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 166352922...
Checkpoint 166352922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.87699
Policy Entropy: 1.28016
Value Function Loss: 0.43920

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.03696
Value Function Update Magnitude: 0.04308

Collected Steps per Second: 12,047.38181
Overall Steps per Second: 10,343.38944

Timestep Collection Time: 4.15094
Timestep Consumption Time: 0.68384
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 4.83478

Cumulative Model Updates: 9,970
Cumulative Timesteps: 166,402,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.67459
Policy Entropy: 1.28111
Value Function Loss: 0.39530

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06799
Policy Update Magnitude: 0.04051
Value Function Update Magnitude: 0.04148

Collected Steps per Second: 12,154.61089
Overall Steps per Second: 10,171.02983

Timestep Collection Time: 4.11432
Timestep Consumption Time: 0.80239
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 4.91671

Cumulative Model Updates: 9,973
Cumulative Timesteps: 166,452,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 166452938...
Checkpoint 166452938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.69557
Policy Entropy: 1.27651
Value Function Loss: 0.45130

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.04126
Value Function Update Magnitude: 0.04254

Collected Steps per Second: 11,226.87901
Overall Steps per Second: 9,546.50258

Timestep Collection Time: 4.45574
Timestep Consumption Time: 0.78430
PPO Batch Consumption Time: 0.03314
Total Iteration Time: 5.24003

Cumulative Model Updates: 9,976
Cumulative Timesteps: 166,502,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.58442
Policy Entropy: 1.27444
Value Function Loss: 0.46283

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.03974
Value Function Update Magnitude: 0.04029

Collected Steps per Second: 12,088.94902
Overall Steps per Second: 10,087.68019

Timestep Collection Time: 4.13667
Timestep Consumption Time: 0.82066
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.95733

Cumulative Model Updates: 9,979
Cumulative Timesteps: 166,552,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 166552970...
Checkpoint 166552970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.06335
Policy Entropy: 1.27459
Value Function Loss: 0.45600

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.03667
Value Function Update Magnitude: 0.04101

Collected Steps per Second: 11,563.72904
Overall Steps per Second: 9,800.18951

Timestep Collection Time: 4.32508
Timestep Consumption Time: 0.77830
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.10337

Cumulative Model Updates: 9,982
Cumulative Timesteps: 166,602,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.79791
Policy Entropy: 1.27779
Value Function Loss: 0.43745

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.03696
Value Function Update Magnitude: 0.06950

Collected Steps per Second: 11,796.07034
Overall Steps per Second: 10,163.28805

Timestep Collection Time: 4.24006
Timestep Consumption Time: 0.68119
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.92124

Cumulative Model Updates: 9,985
Cumulative Timesteps: 166,653,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 166653000...
Checkpoint 166653000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.58068
Policy Entropy: 1.27669
Value Function Loss: 0.43046

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.03330
Value Function Update Magnitude: 0.08633

Collected Steps per Second: 11,815.97177
Overall Steps per Second: 9,942.13806

Timestep Collection Time: 4.23224
Timestep Consumption Time: 0.79767
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.02990

Cumulative Model Updates: 9,988
Cumulative Timesteps: 166,703,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.91646
Policy Entropy: 1.27652
Value Function Loss: 0.40416

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.03758
Value Function Update Magnitude: 0.07883

Collected Steps per Second: 11,774.92092
Overall Steps per Second: 10,138.47471

Timestep Collection Time: 4.24852
Timestep Consumption Time: 0.68575
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.93427

Cumulative Model Updates: 9,991
Cumulative Timesteps: 166,753,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 166753034...
Checkpoint 166753034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.25162
Policy Entropy: 1.27822
Value Function Loss: 0.45304

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.03526
Value Function Update Magnitude: 0.07149

Collected Steps per Second: 11,226.35653
Overall Steps per Second: 9,459.23472

Timestep Collection Time: 4.45398
Timestep Consumption Time: 0.83207
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.28605

Cumulative Model Updates: 9,994
Cumulative Timesteps: 166,803,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.13078
Policy Entropy: 1.27801
Value Function Loss: 0.46450

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.04052
Value Function Update Magnitude: 0.07561

Collected Steps per Second: 11,659.02232
Overall Steps per Second: 9,801.60107

Timestep Collection Time: 4.28955
Timestep Consumption Time: 0.81288
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 5.10243

Cumulative Model Updates: 9,997
Cumulative Timesteps: 166,853,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 166853048...
Checkpoint 166853048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.34358
Policy Entropy: 1.27554
Value Function Loss: 0.56013

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.03792
Value Function Update Magnitude: 0.06213

Collected Steps per Second: 11,970.32788
Overall Steps per Second: 9,995.46137

Timestep Collection Time: 4.17967
Timestep Consumption Time: 0.82580
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 5.00547

Cumulative Model Updates: 10,000
Cumulative Timesteps: 166,903,080

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.63224
Policy Entropy: 1.27195
Value Function Loss: 0.50401

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07568
Policy Update Magnitude: 0.03929
Value Function Update Magnitude: 0.05892

Collected Steps per Second: 11,593.63673
Overall Steps per Second: 9,810.74946

Timestep Collection Time: 4.31478
Timestep Consumption Time: 0.78412
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.09890

Cumulative Model Updates: 10,003
Cumulative Timesteps: 166,953,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 166953104...
Checkpoint 166953104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.55527
Policy Entropy: 1.27489
Value Function Loss: 0.52836

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07436
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.05737

Collected Steps per Second: 11,918.48013
Overall Steps per Second: 10,169.53385

Timestep Collection Time: 4.19567
Timestep Consumption Time: 0.72157
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 4.91724

Cumulative Model Updates: 10,006
Cumulative Timesteps: 167,003,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.78356
Policy Entropy: 1.27761
Value Function Loss: 0.48220

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.04018
Value Function Update Magnitude: 0.05958

Collected Steps per Second: 11,768.29003
Overall Steps per Second: 9,845.48005

Timestep Collection Time: 4.25075
Timestep Consumption Time: 0.83017
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.08091

Cumulative Model Updates: 10,009
Cumulative Timesteps: 167,053,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 167053134...
Checkpoint 167053134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.25135
Policy Entropy: 1.28051
Value Function Loss: 0.50455

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.04475
Value Function Update Magnitude: 0.05485

Collected Steps per Second: 11,009.21889
Overall Steps per Second: 9,357.19448

Timestep Collection Time: 4.54365
Timestep Consumption Time: 0.80219
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.34583

Cumulative Model Updates: 10,012
Cumulative Timesteps: 167,103,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.65235
Policy Entropy: 1.27980
Value Function Loss: 0.49187

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06989
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.05074

Collected Steps per Second: 11,733.44194
Overall Steps per Second: 9,893.57326

Timestep Collection Time: 4.26167
Timestep Consumption Time: 0.79253
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.05419

Cumulative Model Updates: 10,015
Cumulative Timesteps: 167,153,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 167153160...
Checkpoint 167153160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.86432
Policy Entropy: 1.27900
Value Function Loss: 0.49564

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.06609

Collected Steps per Second: 11,741.56544
Overall Steps per Second: 9,848.90223

Timestep Collection Time: 4.25906
Timestep Consumption Time: 0.81846
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 5.07752

Cumulative Model Updates: 10,018
Cumulative Timesteps: 167,203,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.45946
Policy Entropy: 1.27840
Value Function Loss: 0.49432

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07105
Policy Update Magnitude: 0.03847
Value Function Update Magnitude: 0.06789

Collected Steps per Second: 11,658.66143
Overall Steps per Second: 9,999.19075

Timestep Collection Time: 4.29123
Timestep Consumption Time: 0.71217
PPO Batch Consumption Time: 0.03368
Total Iteration Time: 5.00340

Cumulative Model Updates: 10,021
Cumulative Timesteps: 167,253,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 167253198...
Checkpoint 167253198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.19264
Policy Entropy: 1.27657
Value Function Loss: 0.52212

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07401
Policy Update Magnitude: 0.04067
Value Function Update Magnitude: 0.06435

Collected Steps per Second: 12,476.42399
Overall Steps per Second: 10,366.12946

Timestep Collection Time: 4.00900
Timestep Consumption Time: 0.81614
PPO Batch Consumption Time: 0.04004
Total Iteration Time: 4.82514

Cumulative Model Updates: 10,024
Cumulative Timesteps: 167,303,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.84808
Policy Entropy: 1.27485
Value Function Loss: 0.54106

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.03882
Value Function Update Magnitude: 0.05507

Collected Steps per Second: 11,810.84321
Overall Steps per Second: 9,715.47908

Timestep Collection Time: 4.23577
Timestep Consumption Time: 0.91354
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.14931

Cumulative Model Updates: 10,027
Cumulative Timesteps: 167,353,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 167353244...
Checkpoint 167353244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.19300
Policy Entropy: 1.27637
Value Function Loss: 0.55123

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.04268
Value Function Update Magnitude: 0.05464

Collected Steps per Second: 12,307.93397
Overall Steps per Second: 10,249.56803

Timestep Collection Time: 4.06421
Timestep Consumption Time: 0.81619
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.88040

Cumulative Model Updates: 10,030
Cumulative Timesteps: 167,403,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.23013
Policy Entropy: 1.27369
Value Function Loss: 0.52290

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.05371

Collected Steps per Second: 12,529.52387
Overall Steps per Second: 10,535.58887

Timestep Collection Time: 3.99249
Timestep Consumption Time: 0.75561
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 4.74810

Cumulative Model Updates: 10,033
Cumulative Timesteps: 167,453,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 167453290...
Checkpoint 167453290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.37306
Policy Entropy: 1.27401
Value Function Loss: 0.53352

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.06066

Collected Steps per Second: 12,203.99784
Overall Steps per Second: 10,401.82450

Timestep Collection Time: 4.09784
Timestep Consumption Time: 0.70997
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.80781

Cumulative Model Updates: 10,036
Cumulative Timesteps: 167,503,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.62087
Policy Entropy: 1.27586
Value Function Loss: 0.51433

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.04183
Value Function Update Magnitude: 0.05262

Collected Steps per Second: 11,839.78706
Overall Steps per Second: 9,928.69783

Timestep Collection Time: 4.22440
Timestep Consumption Time: 0.81312
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.03752

Cumulative Model Updates: 10,039
Cumulative Timesteps: 167,553,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 167553316...
Checkpoint 167553316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.47503
Policy Entropy: 1.27512
Value Function Loss: 0.53572

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.03837
Value Function Update Magnitude: 0.05661

Collected Steps per Second: 11,906.01746
Overall Steps per Second: 10,064.28950

Timestep Collection Time: 4.20040
Timestep Consumption Time: 0.76866
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.96905

Cumulative Model Updates: 10,042
Cumulative Timesteps: 167,603,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.35252
Policy Entropy: 1.27771
Value Function Loss: 0.50417

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.03796
Value Function Update Magnitude: 0.07322

Collected Steps per Second: 12,729.50992
Overall Steps per Second: 10,543.43207

Timestep Collection Time: 3.93008
Timestep Consumption Time: 0.81486
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 4.74494

Cumulative Model Updates: 10,045
Cumulative Timesteps: 167,653,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 167653354...
Checkpoint 167653354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.94296
Policy Entropy: 1.27058
Value Function Loss: 0.47500

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.04064
Value Function Update Magnitude: 0.07853

Collected Steps per Second: 12,078.70299
Overall Steps per Second: 10,189.31067

Timestep Collection Time: 4.13952
Timestep Consumption Time: 0.76759
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.90710

Cumulative Model Updates: 10,048
Cumulative Timesteps: 167,703,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.64817
Policy Entropy: 1.27563
Value Function Loss: 0.53347

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 0.03510
Value Function Update Magnitude: 0.09327

Collected Steps per Second: 12,102.62554
Overall Steps per Second: 10,346.26011

Timestep Collection Time: 4.13332
Timestep Consumption Time: 0.70167
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.83498

Cumulative Model Updates: 10,051
Cumulative Timesteps: 167,753,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 167753378...
Checkpoint 167753378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.04398
Policy Entropy: 1.26943
Value Function Loss: 0.48076

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.03735
Value Function Update Magnitude: 0.09592

Collected Steps per Second: 12,552.87193
Overall Steps per Second: 10,534.42624

Timestep Collection Time: 3.98411
Timestep Consumption Time: 0.76337
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 4.74748

Cumulative Model Updates: 10,054
Cumulative Timesteps: 167,803,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.84038
Policy Entropy: 1.27704
Value Function Loss: 0.50760

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.03724
Value Function Update Magnitude: 0.10056

Collected Steps per Second: 12,673.74481
Overall Steps per Second: 10,590.83304

Timestep Collection Time: 3.94611
Timestep Consumption Time: 0.77609
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.72220

Cumulative Model Updates: 10,057
Cumulative Timesteps: 167,853,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 167853402...
Checkpoint 167853402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.68874
Policy Entropy: 1.27558
Value Function Loss: 0.43382

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.03828
Value Function Update Magnitude: 0.10568

Collected Steps per Second: 12,591.54477
Overall Steps per Second: 10,554.50893

Timestep Collection Time: 3.97155
Timestep Consumption Time: 0.76652
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 4.73807

Cumulative Model Updates: 10,060
Cumulative Timesteps: 167,903,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.50352
Policy Entropy: 1.28252
Value Function Loss: 0.46614

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.03793
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 12,652.41842
Overall Steps per Second: 10,633.65932

Timestep Collection Time: 3.95276
Timestep Consumption Time: 0.75042
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.70318

Cumulative Model Updates: 10,063
Cumulative Timesteps: 167,953,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 167953422...
Checkpoint 167953422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.72840
Policy Entropy: 1.28077
Value Function Loss: 0.46583

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05618
Policy Update Magnitude: 0.04095
Value Function Update Magnitude: 0.07633

Collected Steps per Second: 11,381.56420
Overall Steps per Second: 9,895.72774

Timestep Collection Time: 4.39325
Timestep Consumption Time: 0.65964
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.05289

Cumulative Model Updates: 10,066
Cumulative Timesteps: 168,003,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.86936
Policy Entropy: 1.27895
Value Function Loss: 0.49118

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04595
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.07124

Collected Steps per Second: 12,174.33110
Overall Steps per Second: 10,288.20746

Timestep Collection Time: 4.10717
Timestep Consumption Time: 0.75296
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.86013

Cumulative Model Updates: 10,069
Cumulative Timesteps: 168,053,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 168053426...
Checkpoint 168053426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.79468
Policy Entropy: 1.27245
Value Function Loss: 0.54338

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05250
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.07532

Collected Steps per Second: 12,435.86962
Overall Steps per Second: 10,626.94583

Timestep Collection Time: 4.02288
Timestep Consumption Time: 0.68478
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.70766

Cumulative Model Updates: 10,072
Cumulative Timesteps: 168,103,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.64029
Policy Entropy: 1.27543
Value Function Loss: 0.52828

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05481
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.07811

Collected Steps per Second: 12,600.02241
Overall Steps per Second: 10,520.12915

Timestep Collection Time: 3.96872
Timestep Consumption Time: 0.78464
PPO Batch Consumption Time: 0.03357
Total Iteration Time: 4.75336

Cumulative Model Updates: 10,075
Cumulative Timesteps: 168,153,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 168153460...
Checkpoint 168153460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.81120
Policy Entropy: 1.27578
Value Function Loss: 0.50160

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05034
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.07213

Collected Steps per Second: 12,468.63462
Overall Steps per Second: 10,492.12038

Timestep Collection Time: 4.01199
Timestep Consumption Time: 0.75578
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 4.76777

Cumulative Model Updates: 10,078
Cumulative Timesteps: 168,203,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.55882
Policy Entropy: 1.27567
Value Function Loss: 0.46585

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06017
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.06363

Collected Steps per Second: 12,622.82324
Overall Steps per Second: 10,554.25136

Timestep Collection Time: 3.96330
Timestep Consumption Time: 0.77678
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 4.74008

Cumulative Model Updates: 10,081
Cumulative Timesteps: 168,253,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 168253512...
Checkpoint 168253512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.25812
Policy Entropy: 1.27808
Value Function Loss: 0.47512

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07149
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.06488

Collected Steps per Second: 11,627.09867
Overall Steps per Second: 9,858.32219

Timestep Collection Time: 4.30271
Timestep Consumption Time: 0.77199
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.07470

Cumulative Model Updates: 10,084
Cumulative Timesteps: 168,303,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.62870
Policy Entropy: 1.28028
Value Function Loss: 0.43855

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04727
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.07280

Collected Steps per Second: 12,201.19420
Overall Steps per Second: 10,436.31924

Timestep Collection Time: 4.09862
Timestep Consumption Time: 0.69311
PPO Batch Consumption Time: 0.03748
Total Iteration Time: 4.79173

Cumulative Model Updates: 10,087
Cumulative Timesteps: 168,353,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 168353548...
Checkpoint 168353548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.39364
Policy Entropy: 1.27679
Value Function Loss: 0.43378

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.06345
Value Function Update Magnitude: 0.06827

Collected Steps per Second: 12,446.23330
Overall Steps per Second: 10,405.58631

Timestep Collection Time: 4.01857
Timestep Consumption Time: 0.78808
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 4.80665

Cumulative Model Updates: 10,090
Cumulative Timesteps: 168,403,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.62808
Policy Entropy: 1.27172
Value Function Loss: 0.46586

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05355
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.05488

Collected Steps per Second: 12,595.55411
Overall Steps per Second: 10,530.43863

Timestep Collection Time: 3.97029
Timestep Consumption Time: 0.77861
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 4.74890

Cumulative Model Updates: 10,093
Cumulative Timesteps: 168,453,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 168453572...
Checkpoint 168453572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.70505
Policy Entropy: 1.27641
Value Function Loss: 0.46937

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05113
Policy Update Magnitude: 0.06931
Value Function Update Magnitude: 0.05623

Collected Steps per Second: 12,514.57311
Overall Steps per Second: 10,529.92771

Timestep Collection Time: 3.99726
Timestep Consumption Time: 0.75339
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.75065

Cumulative Model Updates: 10,096
Cumulative Timesteps: 168,503,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.90892
Policy Entropy: 1.28307
Value Function Loss: 0.45246

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06738
Policy Update Magnitude: 0.06800
Value Function Update Magnitude: 0.05804

Collected Steps per Second: 12,511.63082
Overall Steps per Second: 10,474.21701

Timestep Collection Time: 3.99660
Timestep Consumption Time: 0.77741
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 4.77401

Cumulative Model Updates: 10,099
Cumulative Timesteps: 168,553,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 168553600...
Checkpoint 168553600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.17194
Policy Entropy: 1.26998
Value Function Loss: 0.39253

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.06908

Collected Steps per Second: 11,575.38409
Overall Steps per Second: 9,869.34269

Timestep Collection Time: 4.32124
Timestep Consumption Time: 0.74698
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 5.06822

Cumulative Model Updates: 10,102
Cumulative Timesteps: 168,603,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.99620
Policy Entropy: 1.28252
Value Function Loss: 0.39551

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.09288

Collected Steps per Second: 12,715.71562
Overall Steps per Second: 10,496.91800

Timestep Collection Time: 3.93261
Timestep Consumption Time: 0.83126
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 4.76387

Cumulative Model Updates: 10,105
Cumulative Timesteps: 168,653,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 168653626...
Checkpoint 168653626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.62755
Policy Entropy: 1.27284
Value Function Loss: 0.43767

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07751
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.08732

Collected Steps per Second: 12,378.92630
Overall Steps per Second: 10,383.25274

Timestep Collection Time: 4.04106
Timestep Consumption Time: 0.77670
PPO Batch Consumption Time: 0.03356
Total Iteration Time: 4.81776

Cumulative Model Updates: 10,108
Cumulative Timesteps: 168,703,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.63727
Policy Entropy: 1.28566
Value Function Loss: 0.46523

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.06640
Value Function Update Magnitude: 0.08233

Collected Steps per Second: 12,835.15320
Overall Steps per Second: 10,743.39562

Timestep Collection Time: 3.89571
Timestep Consumption Time: 0.75850
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 4.65421

Cumulative Model Updates: 10,111
Cumulative Timesteps: 168,753,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 168753652...
Checkpoint 168753652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.97265
Policy Entropy: 1.27596
Value Function Loss: 0.48242

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.05149
Policy Update Magnitude: 0.06979
Value Function Update Magnitude: 0.07666

Collected Steps per Second: 12,634.47341
Overall Steps per Second: 10,552.18687

Timestep Collection Time: 3.95790
Timestep Consumption Time: 0.78102
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 4.73892

Cumulative Model Updates: 10,114
Cumulative Timesteps: 168,803,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.17786
Policy Entropy: 1.27902
Value Function Loss: 0.46824

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06704
Policy Update Magnitude: 0.07616
Value Function Update Magnitude: 0.07671

Collected Steps per Second: 12,497.59366
Overall Steps per Second: 10,518.77470

Timestep Collection Time: 4.00141
Timestep Consumption Time: 0.75276
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 4.75417

Cumulative Model Updates: 10,117
Cumulative Timesteps: 168,853,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 168853666...
Checkpoint 168853666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.78141
Policy Entropy: 1.27632
Value Function Loss: 0.45765

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.06751
Value Function Update Magnitude: 0.07670

Collected Steps per Second: 12,437.11006
Overall Steps per Second: 10,265.63216

Timestep Collection Time: 4.02119
Timestep Consumption Time: 0.85060
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 4.87179

Cumulative Model Updates: 10,120
Cumulative Timesteps: 168,903,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.83032
Policy Entropy: 1.27614
Value Function Loss: 0.42420

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.06754
Value Function Update Magnitude: 0.07399

Collected Steps per Second: 12,421.07237
Overall Steps per Second: 10,431.96596

Timestep Collection Time: 4.02606
Timestep Consumption Time: 0.76767
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 4.79373

Cumulative Model Updates: 10,123
Cumulative Timesteps: 168,953,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 168953686...
Checkpoint 168953686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.64139
Policy Entropy: 1.27672
Value Function Loss: 0.42422

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07339
Policy Update Magnitude: 0.07206
Value Function Update Magnitude: 0.07292

Collected Steps per Second: 12,310.93690
Overall Steps per Second: 10,388.03496

Timestep Collection Time: 4.06224
Timestep Consumption Time: 0.75195
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.81419

Cumulative Model Updates: 10,126
Cumulative Timesteps: 169,003,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.41779
Policy Entropy: 1.27477
Value Function Loss: 0.44554

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.06666
Value Function Update Magnitude: 0.08252

Collected Steps per Second: 12,938.54532
Overall Steps per Second: 10,810.66990

Timestep Collection Time: 3.86550
Timestep Consumption Time: 0.76085
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.62636

Cumulative Model Updates: 10,129
Cumulative Timesteps: 169,053,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 169053710...
Checkpoint 169053710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.11671
Policy Entropy: 1.27215
Value Function Loss: 0.42506

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06426
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.08147

Collected Steps per Second: 12,672.36839
Overall Steps per Second: 10,598.57456

Timestep Collection Time: 3.94780
Timestep Consumption Time: 0.77246
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 4.72026

Cumulative Model Updates: 10,132
Cumulative Timesteps: 169,103,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.22698
Policy Entropy: 1.27239
Value Function Loss: 0.40024

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.06105
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.07247

Collected Steps per Second: 12,845.90517
Overall Steps per Second: 10,690.95683

Timestep Collection Time: 3.89447
Timestep Consumption Time: 0.78500
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 4.67947

Cumulative Model Updates: 10,135
Cumulative Timesteps: 169,153,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 169153766...
Checkpoint 169153766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.47137
Policy Entropy: 1.27923
Value Function Loss: 0.38533

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04679
Policy Update Magnitude: 0.06737
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 12,582.09237
Overall Steps per Second: 10,492.38484

Timestep Collection Time: 3.97549
Timestep Consumption Time: 0.79178
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 4.76727

Cumulative Model Updates: 10,138
Cumulative Timesteps: 169,203,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.57197
Policy Entropy: 1.27459
Value Function Loss: 0.41574

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08209
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.09540

Collected Steps per Second: 11,705.35113
Overall Steps per Second: 9,844.83270

Timestep Collection Time: 4.27394
Timestep Consumption Time: 0.80771
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.08165

Cumulative Model Updates: 10,141
Cumulative Timesteps: 169,253,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 169253814...
Checkpoint 169253814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.16635
Policy Entropy: 1.27800
Value Function Loss: 0.41811

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05033
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.11329

Collected Steps per Second: 12,452.14162
Overall Steps per Second: 10,464.87368

Timestep Collection Time: 4.01602
Timestep Consumption Time: 0.76264
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 4.77865

Cumulative Model Updates: 10,144
Cumulative Timesteps: 169,303,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.03667
Policy Entropy: 1.26837
Value Function Loss: 0.46090

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.10608

Collected Steps per Second: 12,705.69029
Overall Steps per Second: 10,891.89993

Timestep Collection Time: 3.93572
Timestep Consumption Time: 0.65540
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 4.59112

Cumulative Model Updates: 10,147
Cumulative Timesteps: 169,353,828

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 169353828...
Checkpoint 169353828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.06233
Policy Entropy: 1.27697
Value Function Loss: 0.43661

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06954
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.09111

Collected Steps per Second: 12,602.87271
Overall Steps per Second: 10,559.05525

Timestep Collection Time: 3.96846
Timestep Consumption Time: 0.76814
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.73660

Cumulative Model Updates: 10,150
Cumulative Timesteps: 169,403,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.01749
Policy Entropy: 1.26855
Value Function Loss: 0.43730

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.07810

Collected Steps per Second: 12,371.08567
Overall Steps per Second: 10,385.96972

Timestep Collection Time: 4.04298
Timestep Consumption Time: 0.77275
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.81573

Cumulative Model Updates: 10,153
Cumulative Timesteps: 169,453,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 169453858...
Checkpoint 169453858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.09331
Policy Entropy: 1.27369
Value Function Loss: 0.40635

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.07943

Collected Steps per Second: 12,457.31197
Overall Steps per Second: 10,440.75342

Timestep Collection Time: 4.01644
Timestep Consumption Time: 0.77575
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.79218

Cumulative Model Updates: 10,156
Cumulative Timesteps: 169,503,892

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.11953
Policy Entropy: 1.26913
Value Function Loss: 0.40156

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.07157

Collected Steps per Second: 11,730.14777
Overall Steps per Second: 9,905.45759

Timestep Collection Time: 4.26286
Timestep Consumption Time: 0.78526
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.04813

Cumulative Model Updates: 10,159
Cumulative Timesteps: 169,553,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 169553896...
Checkpoint 169553896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.10341
Policy Entropy: 1.28010
Value Function Loss: 0.39183

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05069
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 12,120.20942
Overall Steps per Second: 10,333.36797

Timestep Collection Time: 4.12584
Timestep Consumption Time: 0.71344
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 4.83927

Cumulative Model Updates: 10,162
Cumulative Timesteps: 169,603,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.61706
Policy Entropy: 1.27453
Value Function Loss: 0.38175

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07044
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.06914

Collected Steps per Second: 12,517.64393
Overall Steps per Second: 10,395.40843

Timestep Collection Time: 3.99500
Timestep Consumption Time: 0.81558
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 4.81059

Cumulative Model Updates: 10,165
Cumulative Timesteps: 169,653,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 169653910...
Checkpoint 169653910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.51645
Policy Entropy: 1.28109
Value Function Loss: 0.40748

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05937
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.06247

Collected Steps per Second: 12,527.71518
Overall Steps per Second: 10,584.75266

Timestep Collection Time: 3.99163
Timestep Consumption Time: 0.73271
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.72434

Cumulative Model Updates: 10,168
Cumulative Timesteps: 169,703,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.66027
Policy Entropy: 1.27912
Value Function Loss: 0.40054

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.05326

Collected Steps per Second: 12,685.11318
Overall Steps per Second: 10,578.38412

Timestep Collection Time: 3.94305
Timestep Consumption Time: 0.78527
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 4.72832

Cumulative Model Updates: 10,171
Cumulative Timesteps: 169,753,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 169753934...
Checkpoint 169753934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.11202
Policy Entropy: 1.27500
Value Function Loss: 0.37215

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06666
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.04531

Collected Steps per Second: 13,131.04049
Overall Steps per Second: 10,922.66174

Timestep Collection Time: 3.80823
Timestep Consumption Time: 0.76996
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.57819

Cumulative Model Updates: 10,174
Cumulative Timesteps: 169,803,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.80944
Policy Entropy: 1.27498
Value Function Loss: 0.39523

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.05595
Policy Update Magnitude: 0.07130
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 12,826.36597
Overall Steps per Second: 10,695.42293

Timestep Collection Time: 3.89994
Timestep Consumption Time: 0.77702
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.67695

Cumulative Model Updates: 10,177
Cumulative Timesteps: 169,853,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 169853962...
Checkpoint 169853962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.00817
Policy Entropy: 1.28726
Value Function Loss: 0.44101

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07769
Policy Update Magnitude: 0.06682
Value Function Update Magnitude: 0.07512

Collected Steps per Second: 13,077.13873
Overall Steps per Second: 10,926.95876

Timestep Collection Time: 3.82561
Timestep Consumption Time: 0.75279
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.57840

Cumulative Model Updates: 10,180
Cumulative Timesteps: 169,903,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.01036
Policy Entropy: 1.27883
Value Function Loss: 0.46226

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.06071
Value Function Update Magnitude: 0.07063

Collected Steps per Second: 12,871.47409
Overall Steps per Second: 10,923.04824

Timestep Collection Time: 3.88596
Timestep Consumption Time: 0.69317
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 4.57912

Cumulative Model Updates: 10,183
Cumulative Timesteps: 169,954,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 169954008...
Checkpoint 169954008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.02476
Policy Entropy: 1.28242
Value Function Loss: 0.42488

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04148
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.06854

Collected Steps per Second: 12,804.91833
Overall Steps per Second: 10,657.23653

Timestep Collection Time: 3.90506
Timestep Consumption Time: 0.78696
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 4.69202

Cumulative Model Updates: 10,186
Cumulative Timesteps: 170,004,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.59511
Policy Entropy: 1.28082
Value Function Loss: 0.38605

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04123
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.06143

Collected Steps per Second: 13,182.88345
Overall Steps per Second: 10,967.60145

Timestep Collection Time: 3.79356
Timestep Consumption Time: 0.76624
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.55979

Cumulative Model Updates: 10,189
Cumulative Timesteps: 170,054,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 170054022...
Checkpoint 170054022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.95078
Policy Entropy: 1.27795
Value Function Loss: 0.39300

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04170
Policy Update Magnitude: 0.06958
Value Function Update Magnitude: 0.06320

Collected Steps per Second: 12,792.14594
Overall Steps per Second: 10,624.09078

Timestep Collection Time: 3.91021
Timestep Consumption Time: 0.79796
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 4.70817

Cumulative Model Updates: 10,192
Cumulative Timesteps: 170,104,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.20523
Policy Entropy: 1.27348
Value Function Loss: 0.43745

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06496
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.06287

Collected Steps per Second: 12,618.93104
Overall Steps per Second: 10,545.11035

Timestep Collection Time: 3.96341
Timestep Consumption Time: 0.77945
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.74286

Cumulative Model Updates: 10,195
Cumulative Timesteps: 170,154,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 170154056...
Checkpoint 170154056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.90359
Policy Entropy: 1.27448
Value Function Loss: 0.45470

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06418
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.06499

Collected Steps per Second: 11,604.28066
Overall Steps per Second: 9,990.22814

Timestep Collection Time: 4.30910
Timestep Consumption Time: 0.69619
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.00529

Cumulative Model Updates: 10,198
Cumulative Timesteps: 170,204,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.88154
Policy Entropy: 1.27078
Value Function Loss: 0.45939

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06752
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.07039

Collected Steps per Second: 12,346.13342
Overall Steps per Second: 10,352.26880

Timestep Collection Time: 4.05082
Timestep Consumption Time: 0.78020
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.83102

Cumulative Model Updates: 10,201
Cumulative Timesteps: 170,254,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 170254072...
Checkpoint 170254072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.76493
Policy Entropy: 1.27233
Value Function Loss: 0.43553

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05707
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 12,457.91314
Overall Steps per Second: 10,391.37854

Timestep Collection Time: 4.01512
Timestep Consumption Time: 0.79849
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 4.81361

Cumulative Model Updates: 10,204
Cumulative Timesteps: 170,304,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.21008
Policy Entropy: 1.27313
Value Function Loss: 0.39537

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05531
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.06555

Collected Steps per Second: 11,951.34872
Overall Steps per Second: 10,089.55041

Timestep Collection Time: 4.18497
Timestep Consumption Time: 0.77224
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 4.95721

Cumulative Model Updates: 10,207
Cumulative Timesteps: 170,354,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 170354108...
Checkpoint 170354108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.31586
Policy Entropy: 1.27591
Value Function Loss: 0.37428

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05992
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.07166

Collected Steps per Second: 12,623.45087
Overall Steps per Second: 10,689.54467

Timestep Collection Time: 3.96199
Timestep Consumption Time: 0.71679
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.67878

Cumulative Model Updates: 10,210
Cumulative Timesteps: 170,404,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.51073
Policy Entropy: 1.27714
Value Function Loss: 0.36820

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05447
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.06987

Collected Steps per Second: 12,296.41603
Overall Steps per Second: 10,544.99653

Timestep Collection Time: 4.06867
Timestep Consumption Time: 0.67576
PPO Batch Consumption Time: 0.03851
Total Iteration Time: 4.74443

Cumulative Model Updates: 10,213
Cumulative Timesteps: 170,454,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 170454152...
Checkpoint 170454152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.99948
Policy Entropy: 1.27913
Value Function Loss: 0.37600

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05236
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.07054

Collected Steps per Second: 11,470.71350
Overall Steps per Second: 9,756.33813

Timestep Collection Time: 4.35997
Timestep Consumption Time: 0.76613
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.12610

Cumulative Model Updates: 10,216
Cumulative Timesteps: 170,504,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.15868
Policy Entropy: 1.27617
Value Function Loss: 0.38326

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05489
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.07426

Collected Steps per Second: 12,450.83893
Overall Steps per Second: 10,395.60289

Timestep Collection Time: 4.01804
Timestep Consumption Time: 0.79438
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.81242

Cumulative Model Updates: 10,219
Cumulative Timesteps: 170,554,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 170554192...
Checkpoint 170554192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.62944
Policy Entropy: 1.27852
Value Function Loss: 0.38016

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04950
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.07382

Collected Steps per Second: 12,830.68629
Overall Steps per Second: 10,757.20657

Timestep Collection Time: 3.89878
Timestep Consumption Time: 0.75150
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 4.65028

Cumulative Model Updates: 10,222
Cumulative Timesteps: 170,604,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.55545
Policy Entropy: 1.27147
Value Function Loss: 0.39005

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04313
Policy Update Magnitude: 0.04472
Value Function Update Magnitude: 0.07431

Collected Steps per Second: 12,754.74243
Overall Steps per Second: 10,802.22403

Timestep Collection Time: 3.92293
Timestep Consumption Time: 0.70908
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.63201

Cumulative Model Updates: 10,225
Cumulative Timesteps: 170,654,252

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 170654252...
Checkpoint 170654252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.03844
Policy Entropy: 1.27484
Value Function Loss: 0.39992

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04584
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.06070

Collected Steps per Second: 12,402.92903
Overall Steps per Second: 10,567.27773

Timestep Collection Time: 4.03340
Timestep Consumption Time: 0.70065
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.73405

Cumulative Model Updates: 10,228
Cumulative Timesteps: 170,704,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.61823
Policy Entropy: 1.27227
Value Function Loss: 0.39645

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04507
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.04453

Collected Steps per Second: 12,466.67783
Overall Steps per Second: 10,377.47048

Timestep Collection Time: 4.01246
Timestep Consumption Time: 0.80779
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.82025

Cumulative Model Updates: 10,231
Cumulative Timesteps: 170,754,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 170754300...
Checkpoint 170754300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.29519
Policy Entropy: 1.27656
Value Function Loss: 0.41536

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05854
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.04509

Collected Steps per Second: 11,611.91507
Overall Steps per Second: 9,855.05436

Timestep Collection Time: 4.30661
Timestep Consumption Time: 0.76774
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.07435

Cumulative Model Updates: 10,234
Cumulative Timesteps: 170,804,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.14052
Policy Entropy: 1.27435
Value Function Loss: 0.39551

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05577
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.05212

Collected Steps per Second: 12,647.17419
Overall Steps per Second: 10,632.29612

Timestep Collection Time: 3.95424
Timestep Consumption Time: 0.74935
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 4.70359

Cumulative Model Updates: 10,237
Cumulative Timesteps: 170,854,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 170854318...
Checkpoint 170854318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.99775
Policy Entropy: 1.28355
Value Function Loss: 0.39390

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06597
Policy Update Magnitude: 0.04727
Value Function Update Magnitude: 0.05700

Collected Steps per Second: 12,307.34909
Overall Steps per Second: 10,325.19661

Timestep Collection Time: 4.06294
Timestep Consumption Time: 0.77997
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 4.84291

Cumulative Model Updates: 10,240
Cumulative Timesteps: 170,904,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.62271
Policy Entropy: 1.28469
Value Function Loss: 0.37339

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03463
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.06112

Collected Steps per Second: 12,326.22748
Overall Steps per Second: 10,486.76197

Timestep Collection Time: 4.05655
Timestep Consumption Time: 0.71155
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 4.76811

Cumulative Model Updates: 10,243
Cumulative Timesteps: 170,954,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 170954324...
Checkpoint 170954324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.49426
Policy Entropy: 1.28196
Value Function Loss: 0.34788

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03909
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.05642

Collected Steps per Second: 12,421.36377
Overall Steps per Second: 10,419.00043

Timestep Collection Time: 4.02661
Timestep Consumption Time: 0.77385
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.80046

Cumulative Model Updates: 10,246
Cumulative Timesteps: 171,004,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.07196
Policy Entropy: 1.28123
Value Function Loss: 0.36142

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06365
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.05576

Collected Steps per Second: 12,478.36800
Overall Steps per Second: 10,687.63925

Timestep Collection Time: 4.00934
Timestep Consumption Time: 0.67177
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.68111

Cumulative Model Updates: 10,249
Cumulative Timesteps: 171,054,370

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 171054370...
Checkpoint 171054370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.90477
Policy Entropy: 1.27345
Value Function Loss: 0.38550

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.05934

Collected Steps per Second: 12,572.17574
Overall Steps per Second: 10,329.46801

Timestep Collection Time: 3.97751
Timestep Consumption Time: 0.86359
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.84110

Cumulative Model Updates: 10,252
Cumulative Timesteps: 171,104,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.79176
Policy Entropy: 1.28122
Value Function Loss: 0.42501

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06581
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.06711

Collected Steps per Second: 12,759.37421
Overall Steps per Second: 10,781.65629

Timestep Collection Time: 3.92073
Timestep Consumption Time: 0.71919
PPO Batch Consumption Time: 0.03339
Total Iteration Time: 4.63992

Cumulative Model Updates: 10,255
Cumulative Timesteps: 171,154,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 171154402...
Checkpoint 171154402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.72134
Policy Entropy: 1.27470
Value Function Loss: 0.41722

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.08116

Collected Steps per Second: 12,782.70546
Overall Steps per Second: 10,692.94935

Timestep Collection Time: 3.91200
Timestep Consumption Time: 0.76454
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.67654

Cumulative Model Updates: 10,258
Cumulative Timesteps: 171,204,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.43401
Policy Entropy: 1.27668
Value Function Loss: 0.41890

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05699
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.07137

Collected Steps per Second: 12,787.70547
Overall Steps per Second: 10,680.78662

Timestep Collection Time: 3.91047
Timestep Consumption Time: 0.77139
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.68186

Cumulative Model Updates: 10,261
Cumulative Timesteps: 171,254,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 171254414...
Checkpoint 171254414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.74167
Policy Entropy: 1.27447
Value Function Loss: 0.39144

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05413
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 12,890.47079
Overall Steps per Second: 10,859.51031

Timestep Collection Time: 3.87977
Timestep Consumption Time: 0.72560
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.60536

Cumulative Model Updates: 10,264
Cumulative Timesteps: 171,304,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.50436
Policy Entropy: 1.27365
Value Function Loss: 0.39887

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05617
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.07612

Collected Steps per Second: 12,551.72336
Overall Steps per Second: 10,570.69766

Timestep Collection Time: 3.98575
Timestep Consumption Time: 0.74696
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 4.73271

Cumulative Model Updates: 10,267
Cumulative Timesteps: 171,354,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 171354454...
Checkpoint 171354454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.34390
Policy Entropy: 1.27254
Value Function Loss: 0.36872

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05384
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.06862

Collected Steps per Second: 12,728.06313
Overall Steps per Second: 10,619.42204

Timestep Collection Time: 3.92848
Timestep Consumption Time: 0.78006
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.70854

Cumulative Model Updates: 10,270
Cumulative Timesteps: 171,404,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.32630
Policy Entropy: 1.26933
Value Function Loss: 0.37224

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05291
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 11,646.47345
Overall Steps per Second: 9,849.96650

Timestep Collection Time: 4.29538
Timestep Consumption Time: 0.78342
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.07880

Cumulative Model Updates: 10,273
Cumulative Timesteps: 171,454,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 171454482...
Checkpoint 171454482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.73650
Policy Entropy: 1.27324
Value Function Loss: 0.37929

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05579
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.06641

Collected Steps per Second: 12,805.91109
Overall Steps per Second: 10,628.19316

Timestep Collection Time: 3.90523
Timestep Consumption Time: 0.80018
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.70541

Cumulative Model Updates: 10,276
Cumulative Timesteps: 171,504,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.12819
Policy Entropy: 1.27035
Value Function Loss: 0.39310

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04842
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.05930

Collected Steps per Second: 12,535.52834
Overall Steps per Second: 10,461.60772

Timestep Collection Time: 3.98882
Timestep Consumption Time: 0.79075
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 4.77957

Cumulative Model Updates: 10,279
Cumulative Timesteps: 171,554,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 171554494...
Checkpoint 171554494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.24262
Policy Entropy: 1.27695
Value Function Loss: 0.39977

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06412
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.07345

Collected Steps per Second: 12,775.52152
Overall Steps per Second: 10,916.46551

Timestep Collection Time: 3.91420
Timestep Consumption Time: 0.66658
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 4.58079

Cumulative Model Updates: 10,282
Cumulative Timesteps: 171,604,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.38546
Policy Entropy: 1.27430
Value Function Loss: 0.36920

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.06117

Collected Steps per Second: 12,523.05484
Overall Steps per Second: 10,565.08840

Timestep Collection Time: 3.99455
Timestep Consumption Time: 0.74029
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 4.73484

Cumulative Model Updates: 10,285
Cumulative Timesteps: 171,654,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 171654524...
Checkpoint 171654524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.52955
Policy Entropy: 1.27210
Value Function Loss: 0.35792

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.05521

Collected Steps per Second: 12,320.44952
Overall Steps per Second: 10,414.09086

Timestep Collection Time: 4.05992
Timestep Consumption Time: 0.74319
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.80311

Cumulative Model Updates: 10,288
Cumulative Timesteps: 171,704,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.94094
Policy Entropy: 1.27030
Value Function Loss: 0.41489

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.04547
Value Function Update Magnitude: 0.04660

Collected Steps per Second: 11,757.88296
Overall Steps per Second: 9,998.02574

Timestep Collection Time: 4.25366
Timestep Consumption Time: 0.74873
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.00239

Cumulative Model Updates: 10,291
Cumulative Timesteps: 171,754,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 171754558...
Checkpoint 171754558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.79093
Policy Entropy: 1.26837
Value Function Loss: 0.42129

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.04136

Collected Steps per Second: 11,976.89591
Overall Steps per Second: 10,115.34703

Timestep Collection Time: 4.17604
Timestep Consumption Time: 0.76853
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 4.94457

Cumulative Model Updates: 10,294
Cumulative Timesteps: 171,804,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.84841
Policy Entropy: 1.26914
Value Function Loss: 0.46032

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.04560

Collected Steps per Second: 12,353.83392
Overall Steps per Second: 10,602.20184

Timestep Collection Time: 4.04846
Timestep Consumption Time: 0.66886
PPO Batch Consumption Time: 0.03399
Total Iteration Time: 4.71732

Cumulative Model Updates: 10,297
Cumulative Timesteps: 171,854,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 171854588...
Checkpoint 171854588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.75661
Policy Entropy: 1.27284
Value Function Loss: 0.42666

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.05073

Collected Steps per Second: 12,475.27833
Overall Steps per Second: 10,481.98810

Timestep Collection Time: 4.00969
Timestep Consumption Time: 0.76250
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.77219

Cumulative Model Updates: 10,300
Cumulative Timesteps: 171,904,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.04950
Policy Entropy: 1.26724
Value Function Loss: 0.42760

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.03844
Value Function Update Magnitude: 0.04633

Collected Steps per Second: 12,403.42225
Overall Steps per Second: 10,462.12058

Timestep Collection Time: 4.03179
Timestep Consumption Time: 0.74812
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 4.77991

Cumulative Model Updates: 10,303
Cumulative Timesteps: 171,954,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 171954618...
Checkpoint 171954618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.22581
Policy Entropy: 1.27282
Value Function Loss: 0.38492

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.04060
Value Function Update Magnitude: 0.04342

Collected Steps per Second: 12,643.50879
Overall Steps per Second: 10,495.22012

Timestep Collection Time: 3.95586
Timestep Consumption Time: 0.80973
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 4.76560

Cumulative Model Updates: 10,306
Cumulative Timesteps: 172,004,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.38553
Policy Entropy: 1.27470
Value Function Loss: 0.40505

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.04897

Collected Steps per Second: 12,098.89738
Overall Steps per Second: 9,874.27109

Timestep Collection Time: 4.13294
Timestep Consumption Time: 0.93113
PPO Batch Consumption Time: 0.03374
Total Iteration Time: 5.06407

Cumulative Model Updates: 10,309
Cumulative Timesteps: 172,054,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 172054638...
Checkpoint 172054638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.23862
Policy Entropy: 1.27479
Value Function Loss: 0.42866

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.04086
Value Function Update Magnitude: 0.05606

Collected Steps per Second: 12,477.69613
Overall Steps per Second: 10,609.64080

Timestep Collection Time: 4.00939
Timestep Consumption Time: 0.70594
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 4.71533

Cumulative Model Updates: 10,312
Cumulative Timesteps: 172,104,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.82651
Policy Entropy: 1.27230
Value Function Loss: 0.44594

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.04093
Value Function Update Magnitude: 0.06149

Collected Steps per Second: 12,523.05595
Overall Steps per Second: 10,447.62979

Timestep Collection Time: 3.99327
Timestep Consumption Time: 0.79327
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.78654

Cumulative Model Updates: 10,315
Cumulative Timesteps: 172,154,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 172154674...
Checkpoint 172154674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.45255
Policy Entropy: 1.27080
Value Function Loss: 0.43148

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.03980
Value Function Update Magnitude: 0.05490

Collected Steps per Second: 12,194.91672
Overall Steps per Second: 10,250.01425

Timestep Collection Time: 4.10007
Timestep Consumption Time: 0.77797
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 4.87804

Cumulative Model Updates: 10,318
Cumulative Timesteps: 172,204,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.74960
Policy Entropy: 1.27252
Value Function Loss: 0.43165

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.03889
Value Function Update Magnitude: 0.05493

Collected Steps per Second: 12,652.97625
Overall Steps per Second: 10,561.99712

Timestep Collection Time: 3.95275
Timestep Consumption Time: 0.78253
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.73528

Cumulative Model Updates: 10,321
Cumulative Timesteps: 172,254,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 172254688...
Checkpoint 172254688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.73434
Policy Entropy: 1.27374
Value Function Loss: 0.40834

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.05577

Collected Steps per Second: 13,049.73237
Overall Steps per Second: 10,887.74616

Timestep Collection Time: 3.83303
Timestep Consumption Time: 0.76113
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 4.59416

Cumulative Model Updates: 10,324
Cumulative Timesteps: 172,304,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.76499
Policy Entropy: 1.27262
Value Function Loss: 0.38801

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.04002
Value Function Update Magnitude: 0.05936

Collected Steps per Second: 13,077.49707
Overall Steps per Second: 10,974.55824

Timestep Collection Time: 3.82474
Timestep Consumption Time: 0.73289
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.55763

Cumulative Model Updates: 10,327
Cumulative Timesteps: 172,354,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 172354726...
Checkpoint 172354726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.61551
Policy Entropy: 1.27201
Value Function Loss: 0.37163

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.04190
Value Function Update Magnitude: 0.06866

Collected Steps per Second: 12,398.56416
Overall Steps per Second: 10,385.78188

Timestep Collection Time: 4.03402
Timestep Consumption Time: 0.78180
PPO Batch Consumption Time: 0.03360
Total Iteration Time: 4.81581

Cumulative Model Updates: 10,330
Cumulative Timesteps: 172,404,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.10366
Policy Entropy: 1.26620
Value Function Loss: 0.36349

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.03968
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 12,835.30844
Overall Steps per Second: 10,808.03833

Timestep Collection Time: 3.89582
Timestep Consumption Time: 0.73074
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.62656

Cumulative Model Updates: 10,333
Cumulative Timesteps: 172,454,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 172454746...
Checkpoint 172454746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.14571
Policy Entropy: 1.26965
Value Function Loss: 0.38904

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.03706
Value Function Update Magnitude: 0.07591

Collected Steps per Second: 13,549.61853
Overall Steps per Second: 11,108.60126

Timestep Collection Time: 3.69044
Timestep Consumption Time: 0.81094
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 4.50138

Cumulative Model Updates: 10,336
Cumulative Timesteps: 172,504,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.11204
Policy Entropy: 1.26293
Value Function Loss: 0.39261

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.03772
Value Function Update Magnitude: 0.07174

Collected Steps per Second: 13,088.62491
Overall Steps per Second: 10,866.21701

Timestep Collection Time: 3.82011
Timestep Consumption Time: 0.78131
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 4.60142

Cumulative Model Updates: 10,339
Cumulative Timesteps: 172,554,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 172554750...
Checkpoint 172554750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.75383
Policy Entropy: 1.27356
Value Function Loss: 0.41696

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.03848
Value Function Update Magnitude: 0.05923

Collected Steps per Second: 12,510.83973
Overall Steps per Second: 10,680.90913

Timestep Collection Time: 3.99733
Timestep Consumption Time: 0.68485
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.68219

Cumulative Model Updates: 10,342
Cumulative Timesteps: 172,604,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.68952
Policy Entropy: 1.26989
Value Function Loss: 0.37971

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.04125
Value Function Update Magnitude: 0.05195

Collected Steps per Second: 12,587.71073
Overall Steps per Second: 10,492.02396

Timestep Collection Time: 3.97467
Timestep Consumption Time: 0.79390
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 4.76857

Cumulative Model Updates: 10,345
Cumulative Timesteps: 172,654,792

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 172654792...
Checkpoint 172654792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.69475
Policy Entropy: 1.27669
Value Function Loss: 0.38512

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.04925

Collected Steps per Second: 11,582.46110
Overall Steps per Second: 9,864.18780

Timestep Collection Time: 4.31704
Timestep Consumption Time: 0.75200
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.06904

Cumulative Model Updates: 10,348
Cumulative Timesteps: 172,704,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.37826
Policy Entropy: 1.27272
Value Function Loss: 0.41028

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.03776
Value Function Update Magnitude: 0.04297

Collected Steps per Second: 12,619.46444
Overall Steps per Second: 10,522.94165

Timestep Collection Time: 3.96404
Timestep Consumption Time: 0.78977
PPO Batch Consumption Time: 0.03803
Total Iteration Time: 4.75380

Cumulative Model Updates: 10,351
Cumulative Timesteps: 172,754,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 172754818...
Checkpoint 172754818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.57219
Policy Entropy: 1.27501
Value Function Loss: 0.44432

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.04477
Value Function Update Magnitude: 0.05368

Collected Steps per Second: 12,302.09649
Overall Steps per Second: 10,367.32460

Timestep Collection Time: 4.06744
Timestep Consumption Time: 0.75907
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 4.82651

Cumulative Model Updates: 10,354
Cumulative Timesteps: 172,804,856

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.31390
Policy Entropy: 1.27174
Value Function Loss: 0.45531

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.05857
Value Function Update Magnitude: 0.06341

Collected Steps per Second: 12,743.59047
Overall Steps per Second: 10,858.43602

Timestep Collection Time: 3.92495
Timestep Consumption Time: 0.68142
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 4.60637

Cumulative Model Updates: 10,357
Cumulative Timesteps: 172,854,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 172854874...
Checkpoint 172854874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.42374
Policy Entropy: 1.27053
Value Function Loss: 0.42421

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07117
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.07181

Collected Steps per Second: 12,383.12043
Overall Steps per Second: 10,402.01984

Timestep Collection Time: 4.03808
Timestep Consumption Time: 0.76907
PPO Batch Consumption Time: 0.03316
Total Iteration Time: 4.80714

Cumulative Model Updates: 10,360
Cumulative Timesteps: 172,904,878

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.59620
Policy Entropy: 1.26862
Value Function Loss: 0.42150

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05655
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.07708

Collected Steps per Second: 12,576.33400
Overall Steps per Second: 10,554.05074

Timestep Collection Time: 3.97747
Timestep Consumption Time: 0.76213
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.73960

Cumulative Model Updates: 10,363
Cumulative Timesteps: 172,954,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 172954900...
Checkpoint 172954900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.30201
Policy Entropy: 1.26961
Value Function Loss: 0.39583

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04070
Policy Update Magnitude: 0.06902
Value Function Update Magnitude: 0.06404

Collected Steps per Second: 11,609.82726
Overall Steps per Second: 9,882.44908

Timestep Collection Time: 4.30825
Timestep Consumption Time: 0.75305
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.06130

Cumulative Model Updates: 10,366
Cumulative Timesteps: 173,004,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.09698
Policy Entropy: 1.26300
Value Function Loss: 0.37262

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04742
Policy Update Magnitude: 0.06771
Value Function Update Magnitude: 0.06355

Collected Steps per Second: 12,489.40016
Overall Steps per Second: 10,462.59509

Timestep Collection Time: 4.00596
Timestep Consumption Time: 0.77603
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 4.78199

Cumulative Model Updates: 10,369
Cumulative Timesteps: 173,054,950

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 173054950...
Checkpoint 173054950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.08542
Policy Entropy: 1.26508
Value Function Loss: 0.36331

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05553
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.06507

Collected Steps per Second: 12,424.89339
Overall Steps per Second: 10,669.59439

Timestep Collection Time: 4.02466
Timestep Consumption Time: 0.66211
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.68678

Cumulative Model Updates: 10,372
Cumulative Timesteps: 173,104,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.52165
Policy Entropy: 1.26561
Value Function Loss: 0.37496

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06815
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 12,304.07146
Overall Steps per Second: 10,312.16166

Timestep Collection Time: 4.06467
Timestep Consumption Time: 0.78514
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.84981

Cumulative Model Updates: 10,375
Cumulative Timesteps: 173,154,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 173154968...
Checkpoint 173154968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.80406
Policy Entropy: 1.26347
Value Function Loss: 0.36346

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05708
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.05440

Collected Steps per Second: 12,404.89129
Overall Steps per Second: 10,679.90696

Timestep Collection Time: 4.03228
Timestep Consumption Time: 0.65128
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 4.68356

Cumulative Model Updates: 10,378
Cumulative Timesteps: 173,204,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.95921
Policy Entropy: 1.26526
Value Function Loss: 0.36899

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.05143

Collected Steps per Second: 12,393.85008
Overall Steps per Second: 10,395.53666

Timestep Collection Time: 4.03426
Timestep Consumption Time: 0.77550
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 4.80976

Cumulative Model Updates: 10,381
Cumulative Timesteps: 173,254,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 173254988...
Checkpoint 173254988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.22625
Policy Entropy: 1.26269
Value Function Loss: 0.35967

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07205
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.05206

Collected Steps per Second: 12,245.07375
Overall Steps per Second: 10,228.79264

Timestep Collection Time: 4.08425
Timestep Consumption Time: 0.80508
PPO Batch Consumption Time: 0.03350
Total Iteration Time: 4.88934

Cumulative Model Updates: 10,384
Cumulative Timesteps: 173,305,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.23755
Policy Entropy: 1.26452
Value Function Loss: 0.37877

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07148
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.06575

Collected Steps per Second: 12,508.08929
Overall Steps per Second: 10,501.99406

Timestep Collection Time: 3.99741
Timestep Consumption Time: 0.76359
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 4.76100

Cumulative Model Updates: 10,387
Cumulative Timesteps: 173,355,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 173355000...
Checkpoint 173355000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.55493
Policy Entropy: 1.27350
Value Function Loss: 0.37624

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06333
Policy Update Magnitude: 0.06140
Value Function Update Magnitude: 0.06100

Collected Steps per Second: 12,312.32420
Overall Steps per Second: 10,388.59851

Timestep Collection Time: 4.06227
Timestep Consumption Time: 0.75224
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.81451

Cumulative Model Updates: 10,390
Cumulative Timesteps: 173,405,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.25025
Policy Entropy: 1.27510
Value Function Loss: 0.39757

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.06131
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.06607

Collected Steps per Second: 12,493.16394
Overall Steps per Second: 10,640.90843

Timestep Collection Time: 4.00267
Timestep Consumption Time: 0.69674
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 4.69941

Cumulative Model Updates: 10,393
Cumulative Timesteps: 173,455,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 173455022...
Checkpoint 173455022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.93188
Policy Entropy: 1.26985
Value Function Loss: 0.39107

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05041
Policy Update Magnitude: 0.07142
Value Function Update Magnitude: 0.06143

Collected Steps per Second: 12,491.03410
Overall Steps per Second: 10,446.36573

Timestep Collection Time: 4.00559
Timestep Consumption Time: 0.78402
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 4.78961

Cumulative Model Updates: 10,396
Cumulative Timesteps: 173,505,056

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.40478
Policy Entropy: 1.27186
Value Function Loss: 0.40310

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05849
Policy Update Magnitude: 0.07674
Value Function Update Magnitude: 0.05765

Collected Steps per Second: 12,552.08229
Overall Steps per Second: 10,559.49732

Timestep Collection Time: 3.98420
Timestep Consumption Time: 0.75182
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.73602

Cumulative Model Updates: 10,399
Cumulative Timesteps: 173,555,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 173555066...
Checkpoint 173555066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.69092
Policy Entropy: 1.27576
Value Function Loss: 0.39424

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05093
Policy Update Magnitude: 0.07437
Value Function Update Magnitude: 0.06569

Collected Steps per Second: 12,884.72209
Overall Steps per Second: 10,798.16964

Timestep Collection Time: 3.88072
Timestep Consumption Time: 0.74988
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 4.63060

Cumulative Model Updates: 10,402
Cumulative Timesteps: 173,605,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.80851
Policy Entropy: 1.26860
Value Function Loss: 0.41023

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.06648
Value Function Update Magnitude: 0.06990

Collected Steps per Second: 11,613.31754
Overall Steps per Second: 9,886.80140

Timestep Collection Time: 4.30592
Timestep Consumption Time: 0.75194
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 5.05785

Cumulative Model Updates: 10,405
Cumulative Timesteps: 173,655,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 173655074...
Checkpoint 173655074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.54089
Policy Entropy: 1.27739
Value Function Loss: 0.37910

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07160
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.08653

Collected Steps per Second: 12,463.37880
Overall Steps per Second: 10,687.23300

Timestep Collection Time: 4.01400
Timestep Consumption Time: 0.66710
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.68110

Cumulative Model Updates: 10,408
Cumulative Timesteps: 173,705,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.03067
Policy Entropy: 1.27692
Value Function Loss: 0.37105

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.08089

Collected Steps per Second: 12,801.21398
Overall Steps per Second: 10,684.21971

Timestep Collection Time: 3.90650
Timestep Consumption Time: 0.77404
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.68055

Cumulative Model Updates: 10,411
Cumulative Timesteps: 173,755,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 173755110...
Checkpoint 173755110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.92185
Policy Entropy: 1.27406
Value Function Loss: 0.37393

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06336
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 12,515.65615
Overall Steps per Second: 10,725.56583

Timestep Collection Time: 3.99564
Timestep Consumption Time: 0.66687
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 4.66250

Cumulative Model Updates: 10,414
Cumulative Timesteps: 173,805,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.47122
Policy Entropy: 1.27311
Value Function Loss: 0.36135

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05415
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.05335

Collected Steps per Second: 12,578.21401
Overall Steps per Second: 10,488.54278

Timestep Collection Time: 3.97672
Timestep Consumption Time: 0.79230
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.76901

Cumulative Model Updates: 10,417
Cumulative Timesteps: 173,855,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 173855138...
Checkpoint 173855138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.60073
Policy Entropy: 1.27150
Value Function Loss: 0.35475

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05583
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.04730

Collected Steps per Second: 12,407.98242
Overall Steps per Second: 10,430.28328

Timestep Collection Time: 4.03079
Timestep Consumption Time: 0.76428
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 4.79508

Cumulative Model Updates: 10,420
Cumulative Timesteps: 173,905,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.51074
Policy Entropy: 1.27058
Value Function Loss: 0.33067

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04949
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.04048

Collected Steps per Second: 11,875.56130
Overall Steps per Second: 10,152.09020

Timestep Collection Time: 4.21285
Timestep Consumption Time: 0.71520
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 4.92805

Cumulative Model Updates: 10,423
Cumulative Timesteps: 173,955,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 173955182...
Checkpoint 173955182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.75005
Policy Entropy: 1.27416
Value Function Loss: 0.33470

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06097
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.04080

Collected Steps per Second: 12,125.66542
Overall Steps per Second: 10,195.79482

Timestep Collection Time: 4.12414
Timestep Consumption Time: 0.78062
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 4.90477

Cumulative Model Updates: 10,426
Cumulative Timesteps: 174,005,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.76840
Policy Entropy: 1.27505
Value Function Loss: 0.34532

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04425
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.04034

Collected Steps per Second: 12,443.87566
Overall Steps per Second: 10,612.06670

Timestep Collection Time: 4.01884
Timestep Consumption Time: 0.69372
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.71256

Cumulative Model Updates: 10,429
Cumulative Timesteps: 174,055,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 174055200...
Checkpoint 174055200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.18416
Policy Entropy: 1.26763
Value Function Loss: 0.37257

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06685
Policy Update Magnitude: 0.06291
Value Function Update Magnitude: 0.04110

Collected Steps per Second: 12,497.03349
Overall Steps per Second: 10,426.26734

Timestep Collection Time: 4.00175
Timestep Consumption Time: 0.79479
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.79654

Cumulative Model Updates: 10,432
Cumulative Timesteps: 174,105,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.99355
Policy Entropy: 1.27771
Value Function Loss: 0.40162

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05767
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.04572

Collected Steps per Second: 12,249.58170
Overall Steps per Second: 10,267.48928

Timestep Collection Time: 4.08308
Timestep Consumption Time: 0.78822
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.87130

Cumulative Model Updates: 10,435
Cumulative Timesteps: 174,155,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 174155226...
Checkpoint 174155226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.40136
Policy Entropy: 1.27120
Value Function Loss: 0.39477

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.04418

Collected Steps per Second: 12,280.10447
Overall Steps per Second: 10,627.87938

Timestep Collection Time: 4.07163
Timestep Consumption Time: 0.63298
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.70461

Cumulative Model Updates: 10,438
Cumulative Timesteps: 174,205,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.28149
Policy Entropy: 1.27697
Value Function Loss: 0.39827

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04757
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.04836

Collected Steps per Second: 11,907.15307
Overall Steps per Second: 10,093.07289

Timestep Collection Time: 4.19949
Timestep Consumption Time: 0.75480
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.95429

Cumulative Model Updates: 10,441
Cumulative Timesteps: 174,255,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 174255230...
Checkpoint 174255230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.23886
Policy Entropy: 1.27422
Value Function Loss: 0.36390

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05406
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.04303

Collected Steps per Second: 12,318.12011
Overall Steps per Second: 10,559.17867

Timestep Collection Time: 4.06133
Timestep Consumption Time: 0.67653
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.73787

Cumulative Model Updates: 10,444
Cumulative Timesteps: 174,305,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.48182
Policy Entropy: 1.27154
Value Function Loss: 0.36788

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05341
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.05743

Collected Steps per Second: 12,631.68638
Overall Steps per Second: 10,562.40553

Timestep Collection Time: 3.95846
Timestep Consumption Time: 0.77550
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 4.73396

Cumulative Model Updates: 10,447
Cumulative Timesteps: 174,355,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 174355260...
Checkpoint 174355260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.29552
Policy Entropy: 1.27288
Value Function Loss: 0.36154

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05687
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.05242

Collected Steps per Second: 12,234.00082
Overall Steps per Second: 10,332.31964

Timestep Collection Time: 4.08746
Timestep Consumption Time: 0.75230
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.83977

Cumulative Model Updates: 10,450
Cumulative Timesteps: 174,405,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.42226
Policy Entropy: 1.27105
Value Function Loss: 0.35881

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05528
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.06051

Collected Steps per Second: 12,745.99899
Overall Steps per Second: 10,583.17997

Timestep Collection Time: 3.92515
Timestep Consumption Time: 0.80216
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.72731

Cumulative Model Updates: 10,453
Cumulative Timesteps: 174,455,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 174455296...
Checkpoint 174455296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.71550
Policy Entropy: 1.27443
Value Function Loss: 0.39352

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.05843

Collected Steps per Second: 12,322.71530
Overall Steps per Second: 10,278.13516

Timestep Collection Time: 4.05901
Timestep Consumption Time: 0.80744
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 4.86645

Cumulative Model Updates: 10,456
Cumulative Timesteps: 174,505,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.00493
Policy Entropy: 1.27173
Value Function Loss: 0.39039

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05528
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 12,414.22084
Overall Steps per Second: 10,425.73923

Timestep Collection Time: 4.02764
Timestep Consumption Time: 0.76818
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.79582

Cumulative Model Updates: 10,459
Cumulative Timesteps: 174,555,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 174555314...
Checkpoint 174555314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.75389
Policy Entropy: 1.27003
Value Function Loss: 0.41326

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06387
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.05287

Collected Steps per Second: 12,296.52138
Overall Steps per Second: 10,281.30099

Timestep Collection Time: 4.06814
Timestep Consumption Time: 0.79739
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.86553

Cumulative Model Updates: 10,462
Cumulative Timesteps: 174,605,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.77204
Policy Entropy: 1.26684
Value Function Loss: 0.37531

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05606
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.05606

Collected Steps per Second: 12,311.65181
Overall Steps per Second: 10,466.92899

Timestep Collection Time: 4.06298
Timestep Consumption Time: 0.71607
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 4.77905

Cumulative Model Updates: 10,465
Cumulative Timesteps: 174,655,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 174655360...
Checkpoint 174655360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.02739
Policy Entropy: 1.27145
Value Function Loss: 0.35996

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05207
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.07218

Collected Steps per Second: 12,428.80572
Overall Steps per Second: 10,450.64598

Timestep Collection Time: 4.02517
Timestep Consumption Time: 0.76191
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 4.78707

Cumulative Model Updates: 10,468
Cumulative Timesteps: 174,705,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.23466
Policy Entropy: 1.27066
Value Function Loss: 0.36260

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06379
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.06407

Collected Steps per Second: 12,078.69967
Overall Steps per Second: 10,121.23439

Timestep Collection Time: 4.13985
Timestep Consumption Time: 0.80065
PPO Batch Consumption Time: 0.03837
Total Iteration Time: 4.94050

Cumulative Model Updates: 10,471
Cumulative Timesteps: 174,755,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 174755392...
Checkpoint 174755392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.05451
Policy Entropy: 1.27124
Value Function Loss: 0.36969

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.05890

Collected Steps per Second: 10,975.70939
Overall Steps per Second: 9,550.85317

Timestep Collection Time: 4.55551
Timestep Consumption Time: 0.67962
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.23513

Cumulative Model Updates: 10,474
Cumulative Timesteps: 174,805,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.87013
Policy Entropy: 1.26546
Value Function Loss: 0.36345

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06915
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.05804

Collected Steps per Second: 11,837.61397
Overall Steps per Second: 9,691.86327

Timestep Collection Time: 4.22551
Timestep Consumption Time: 0.93552
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 5.16103

Cumulative Model Updates: 10,477
Cumulative Timesteps: 174,855,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 174855412...
Checkpoint 174855412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.54070
Policy Entropy: 1.26391
Value Function Loss: 0.34667

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06764
Policy Update Magnitude: 0.06151
Value Function Update Magnitude: 0.05326

Collected Steps per Second: 11,206.68390
Overall Steps per Second: 9,589.05538

Timestep Collection Time: 4.46376
Timestep Consumption Time: 0.75302
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.21678

Cumulative Model Updates: 10,480
Cumulative Timesteps: 174,905,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.07079
Policy Entropy: 1.26998
Value Function Loss: 0.34508

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04188
Policy Update Magnitude: 0.06292
Value Function Update Magnitude: 0.07182

Collected Steps per Second: 11,777.16352
Overall Steps per Second: 9,743.50234

Timestep Collection Time: 4.24686
Timestep Consumption Time: 0.88640
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.13327

Cumulative Model Updates: 10,483
Cumulative Timesteps: 174,955,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 174955452...
Checkpoint 174955452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.25221
Policy Entropy: 1.27037
Value Function Loss: 0.36259

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06141
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 12,387.19372
Overall Steps per Second: 10,363.62619

Timestep Collection Time: 4.03772
Timestep Consumption Time: 0.78839
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.82611

Cumulative Model Updates: 10,486
Cumulative Timesteps: 175,005,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.42311
Policy Entropy: 1.26845
Value Function Loss: 0.37428

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05645
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 12,886.24826
Overall Steps per Second: 10,932.95210

Timestep Collection Time: 3.88057
Timestep Consumption Time: 0.69331
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.57388

Cumulative Model Updates: 10,489
Cumulative Timesteps: 175,055,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 175055474...
Checkpoint 175055474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.35071
Policy Entropy: 1.26683
Value Function Loss: 0.37759

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06341
Policy Update Magnitude: 0.05926
Value Function Update Magnitude: 0.08180

Collected Steps per Second: 12,238.70540
Overall Steps per Second: 10,249.18917

Timestep Collection Time: 4.08720
Timestep Consumption Time: 0.79338
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.88058

Cumulative Model Updates: 10,492
Cumulative Timesteps: 175,105,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.33533
Policy Entropy: 1.27060
Value Function Loss: 0.33504

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05357
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.06924

Collected Steps per Second: 12,291.27138
Overall Steps per Second: 10,392.97669

Timestep Collection Time: 4.06955
Timestep Consumption Time: 0.74331
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 4.81287

Cumulative Model Updates: 10,495
Cumulative Timesteps: 175,155,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 175155516...
Checkpoint 175155516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.48930
Policy Entropy: 1.27052
Value Function Loss: 0.32190

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06652
Policy Update Magnitude: 0.06395
Value Function Update Magnitude: 0.07320

Collected Steps per Second: 11,973.22915
Overall Steps per Second: 10,137.53902

Timestep Collection Time: 4.17732
Timestep Consumption Time: 0.75642
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 4.93374

Cumulative Model Updates: 10,498
Cumulative Timesteps: 175,205,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.60845
Policy Entropy: 1.27305
Value Function Loss: 0.30359

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.06978

Collected Steps per Second: 12,378.68827
Overall Steps per Second: 10,429.15499

Timestep Collection Time: 4.04065
Timestep Consumption Time: 0.75532
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.79598

Cumulative Model Updates: 10,501
Cumulative Timesteps: 175,255,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 175255550...
Checkpoint 175255550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.81342
Policy Entropy: 1.27076
Value Function Loss: 0.31441

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.05625
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.07842

Collected Steps per Second: 12,638.91308
Overall Steps per Second: 10,613.53894

Timestep Collection Time: 3.95762
Timestep Consumption Time: 0.75523
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 4.71285

Cumulative Model Updates: 10,504
Cumulative Timesteps: 175,305,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.88684
Policy Entropy: 1.26680
Value Function Loss: 0.31098

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06539
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.07208

Collected Steps per Second: 12,268.10397
Overall Steps per Second: 10,322.27759

Timestep Collection Time: 4.07822
Timestep Consumption Time: 0.76877
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 4.84699

Cumulative Model Updates: 10,507
Cumulative Timesteps: 175,355,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 175355602...
Checkpoint 175355602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.33348
Policy Entropy: 1.27345
Value Function Loss: 0.33947

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.08656

Collected Steps per Second: 12,237.45677
Overall Steps per Second: 10,389.78823

Timestep Collection Time: 4.08696
Timestep Consumption Time: 0.72680
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 4.81377

Cumulative Model Updates: 10,510
Cumulative Timesteps: 175,405,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.67013
Policy Entropy: 1.26981
Value Function Loss: 0.38339

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06142
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.07954

Collected Steps per Second: 12,073.60072
Overall Steps per Second: 10,174.36898

Timestep Collection Time: 4.14176
Timestep Consumption Time: 0.77314
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 4.91490

Cumulative Model Updates: 10,513
Cumulative Timesteps: 175,455,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 175455622...
Checkpoint 175455622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.30387
Policy Entropy: 1.27506
Value Function Loss: 0.39440

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05265
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.06764

Collected Steps per Second: 11,535.55735
Overall Steps per Second: 9,825.88893

Timestep Collection Time: 4.33512
Timestep Consumption Time: 0.75429
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.08941

Cumulative Model Updates: 10,516
Cumulative Timesteps: 175,505,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.55241
Policy Entropy: 1.26900
Value Function Loss: 0.36455

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04803
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.06541

Collected Steps per Second: 11,976.06339
Overall Steps per Second: 10,154.16830

Timestep Collection Time: 4.17499
Timestep Consumption Time: 0.74909
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 4.92409

Cumulative Model Updates: 10,519
Cumulative Timesteps: 175,555,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 175555630...
Checkpoint 175555630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.52798
Policy Entropy: 1.26770
Value Function Loss: 0.37029

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03862
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.05596

Collected Steps per Second: 12,212.59646
Overall Steps per Second: 10,343.63938

Timestep Collection Time: 4.09544
Timestep Consumption Time: 0.73999
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.83544

Cumulative Model Updates: 10,522
Cumulative Timesteps: 175,605,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.03249
Policy Entropy: 1.27298
Value Function Loss: 0.37123

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06474
Policy Update Magnitude: 0.06516
Value Function Update Magnitude: 0.07152

Collected Steps per Second: 12,588.53611
Overall Steps per Second: 10,672.43830

Timestep Collection Time: 3.97314
Timestep Consumption Time: 0.71333
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.68646

Cumulative Model Updates: 10,525
Cumulative Timesteps: 175,655,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 175655662...
Checkpoint 175655662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.37247
Policy Entropy: 1.26689
Value Function Loss: 0.37073

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.05902

Collected Steps per Second: 12,615.37935
Overall Steps per Second: 10,531.99567

Timestep Collection Time: 3.96564
Timestep Consumption Time: 0.78446
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.75010

Cumulative Model Updates: 10,528
Cumulative Timesteps: 175,705,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.10555
Policy Entropy: 1.27114
Value Function Loss: 0.35455

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06843
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.05018

Collected Steps per Second: 12,329.88731
Overall Steps per Second: 10,443.79315

Timestep Collection Time: 4.05730
Timestep Consumption Time: 0.73273
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.79002

Cumulative Model Updates: 10,531
Cumulative Timesteps: 175,755,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 175755716...
Checkpoint 175755716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.39951
Policy Entropy: 1.26861
Value Function Loss: 0.34692

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06734
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.05236

Collected Steps per Second: 11,262.29716
Overall Steps per Second: 9,531.55656

Timestep Collection Time: 4.44190
Timestep Consumption Time: 0.80656
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.24846

Cumulative Model Updates: 10,534
Cumulative Timesteps: 175,805,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.03870
Policy Entropy: 1.28151
Value Function Loss: 0.35705

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05070
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.06177

Collected Steps per Second: 11,813.34546
Overall Steps per Second: 9,989.85231

Timestep Collection Time: 4.23250
Timestep Consumption Time: 0.77258
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.00508

Cumulative Model Updates: 10,537
Cumulative Timesteps: 175,855,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 175855742...
Checkpoint 175855742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.76503
Policy Entropy: 1.27186
Value Function Loss: 0.37977

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.06839

Collected Steps per Second: 12,118.05702
Overall Steps per Second: 10,335.33037

Timestep Collection Time: 4.12723
Timestep Consumption Time: 0.71190
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.83913

Cumulative Model Updates: 10,540
Cumulative Timesteps: 175,905,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.25815
Policy Entropy: 1.27661
Value Function Loss: 0.36664

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04149
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.06736

Collected Steps per Second: 12,447.80041
Overall Steps per Second: 10,426.80663

Timestep Collection Time: 4.01742
Timestep Consumption Time: 0.77868
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.79610

Cumulative Model Updates: 10,543
Cumulative Timesteps: 175,955,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 175955764...
Checkpoint 175955764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.59586
Policy Entropy: 1.27344
Value Function Loss: 0.36607

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04843
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.06565

Collected Steps per Second: 12,320.27361
Overall Steps per Second: 10,393.25815

Timestep Collection Time: 4.05916
Timestep Consumption Time: 0.75261
PPO Batch Consumption Time: 0.03347
Total Iteration Time: 4.81177

Cumulative Model Updates: 10,546
Cumulative Timesteps: 176,005,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.49902
Policy Entropy: 1.26550
Value Function Loss: 0.36789

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.07326

Collected Steps per Second: 12,440.26455
Overall Steps per Second: 10,414.45650

Timestep Collection Time: 4.01937
Timestep Consumption Time: 0.78184
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 4.80121

Cumulative Model Updates: 10,549
Cumulative Timesteps: 176,055,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 176055776...
Checkpoint 176055776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.31999
Policy Entropy: 1.26906
Value Function Loss: 0.36510

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05149
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.06422

Collected Steps per Second: 11,260.96887
Overall Steps per Second: 9,561.49825

Timestep Collection Time: 4.44065
Timestep Consumption Time: 0.78929
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.22993

Cumulative Model Updates: 10,552
Cumulative Timesteps: 176,105,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.22921
Policy Entropy: 1.27038
Value Function Loss: 0.33145

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07637
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.06094

Collected Steps per Second: 11,859.93699
Overall Steps per Second: 10,105.12340

Timestep Collection Time: 4.21587
Timestep Consumption Time: 0.73211
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 4.94799

Cumulative Model Updates: 10,555
Cumulative Timesteps: 176,155,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 176155782...
Checkpoint 176155782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.42859
Policy Entropy: 1.26532
Value Function Loss: 0.29548

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.07666

Collected Steps per Second: 11,778.25700
Overall Steps per Second: 9,996.91880

Timestep Collection Time: 4.24545
Timestep Consumption Time: 0.75649
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.00194

Cumulative Model Updates: 10,558
Cumulative Timesteps: 176,205,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.18677
Policy Entropy: 1.27191
Value Function Loss: 0.28656

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.08373

Collected Steps per Second: 12,456.96074
Overall Steps per Second: 10,546.89362

Timestep Collection Time: 4.01398
Timestep Consumption Time: 0.72694
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.74092

Cumulative Model Updates: 10,561
Cumulative Timesteps: 176,255,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 176255788...
Checkpoint 176255788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.69423
Policy Entropy: 1.26493
Value Function Loss: 0.31061

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.08274

Collected Steps per Second: 12,208.35389
Overall Steps per Second: 10,169.83734

Timestep Collection Time: 4.09670
Timestep Consumption Time: 0.82117
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.91788

Cumulative Model Updates: 10,564
Cumulative Timesteps: 176,305,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.54270
Policy Entropy: 1.27572
Value Function Loss: 0.33207

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.08269

Collected Steps per Second: 12,220.56204
Overall Steps per Second: 10,331.55465

Timestep Collection Time: 4.09245
Timestep Consumption Time: 0.74826
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.84070

Cumulative Model Updates: 10,567
Cumulative Timesteps: 176,355,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 176355814...
Checkpoint 176355814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.43490
Policy Entropy: 1.27131
Value Function Loss: 0.36778

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06170
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.07997

Collected Steps per Second: 11,538.23621
Overall Steps per Second: 9,766.77205

Timestep Collection Time: 4.33550
Timestep Consumption Time: 0.78636
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.12186

Cumulative Model Updates: 10,570
Cumulative Timesteps: 176,405,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.47784
Policy Entropy: 1.27307
Value Function Loss: 0.37507

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06529
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.07575

Collected Steps per Second: 12,580.68172
Overall Steps per Second: 10,521.11879

Timestep Collection Time: 3.97451
Timestep Consumption Time: 0.77803
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 4.75254

Cumulative Model Updates: 10,573
Cumulative Timesteps: 176,455,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 176455840...
Checkpoint 176455840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.79194
Policy Entropy: 1.27082
Value Function Loss: 0.36650

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06539
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.10175

Collected Steps per Second: 12,356.65202
Overall Steps per Second: 10,600.35020

Timestep Collection Time: 4.04640
Timestep Consumption Time: 0.67042
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.71683

Cumulative Model Updates: 10,576
Cumulative Timesteps: 176,505,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.62993
Policy Entropy: 1.27369
Value Function Loss: 0.35022

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05980
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.09535

Collected Steps per Second: 12,468.62406
Overall Steps per Second: 10,406.79488

Timestep Collection Time: 4.01215
Timestep Consumption Time: 0.79490
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.80705

Cumulative Model Updates: 10,579
Cumulative Timesteps: 176,555,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 176555866...
Checkpoint 176555866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.00049
Policy Entropy: 1.27106
Value Function Loss: 0.34744

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06287
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.08569

Collected Steps per Second: 12,223.33616
Overall Steps per Second: 10,315.25415

Timestep Collection Time: 4.09070
Timestep Consumption Time: 0.75668
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.84738

Cumulative Model Updates: 10,582
Cumulative Timesteps: 176,605,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.59372
Policy Entropy: 1.27353
Value Function Loss: 0.33912

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05636
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.07954

Collected Steps per Second: 12,765.10687
Overall Steps per Second: 10,683.47148

Timestep Collection Time: 3.91724
Timestep Consumption Time: 0.76326
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.68050

Cumulative Model Updates: 10,585
Cumulative Timesteps: 176,655,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 176655872...
Checkpoint 176655872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.60248
Policy Entropy: 1.26744
Value Function Loss: 0.33771

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05832
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.06641

Collected Steps per Second: 11,949.38847
Overall Steps per Second: 10,110.76562

Timestep Collection Time: 4.18582
Timestep Consumption Time: 0.76118
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.94700

Cumulative Model Updates: 10,588
Cumulative Timesteps: 176,705,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.60602
Policy Entropy: 1.27213
Value Function Loss: 0.31373

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06251
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.05407

Collected Steps per Second: 12,470.75212
Overall Steps per Second: 10,679.34783

Timestep Collection Time: 4.01179
Timestep Consumption Time: 0.67296
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.68474

Cumulative Model Updates: 10,591
Cumulative Timesteps: 176,755,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 176755920...
Checkpoint 176755920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.56932
Policy Entropy: 1.27507
Value Function Loss: 0.33606

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.05278

Collected Steps per Second: 12,368.71534
Overall Steps per Second: 10,292.83581

Timestep Collection Time: 4.04327
Timestep Consumption Time: 0.81545
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 4.85872

Cumulative Model Updates: 10,594
Cumulative Timesteps: 176,805,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.60439
Policy Entropy: 1.26395
Value Function Loss: 0.34954

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 12,443.83348
Overall Steps per Second: 10,423.33066

Timestep Collection Time: 4.02014
Timestep Consumption Time: 0.77928
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 4.79943

Cumulative Model Updates: 10,597
Cumulative Timesteps: 176,855,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 176855956...
Checkpoint 176855956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.70369
Policy Entropy: 1.27842
Value Function Loss: 0.37664

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.05259

Collected Steps per Second: 12,630.27768
Overall Steps per Second: 10,559.66120

Timestep Collection Time: 3.95922
Timestep Consumption Time: 0.77635
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 4.73557

Cumulative Model Updates: 10,600
Cumulative Timesteps: 176,905,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.30150
Policy Entropy: 1.27298
Value Function Loss: 0.34913

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.05995
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.05297

Collected Steps per Second: 12,245.32445
Overall Steps per Second: 10,323.15100

Timestep Collection Time: 4.08368
Timestep Consumption Time: 0.76038
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.84406

Cumulative Model Updates: 10,603
Cumulative Timesteps: 176,955,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 176955968...
Checkpoint 176955968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.10464
Policy Entropy: 1.27805
Value Function Loss: 0.34736

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05229
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.05938

Collected Steps per Second: 12,314.79810
Overall Steps per Second: 10,326.56150

Timestep Collection Time: 4.06048
Timestep Consumption Time: 0.78179
PPO Batch Consumption Time: 0.03417
Total Iteration Time: 4.84227

Cumulative Model Updates: 10,606
Cumulative Timesteps: 177,005,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.32995
Policy Entropy: 1.27065
Value Function Loss: 0.32242

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05717
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.06511

Collected Steps per Second: 12,255.65947
Overall Steps per Second: 10,267.99584

Timestep Collection Time: 4.08171
Timestep Consumption Time: 0.79013
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 4.87184

Cumulative Model Updates: 10,609
Cumulative Timesteps: 177,055,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 177055996...
Checkpoint 177055996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.15203
Policy Entropy: 1.27525
Value Function Loss: 0.35551

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06790
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.06167

Collected Steps per Second: 12,298.26373
Overall Steps per Second: 10,336.02410

Timestep Collection Time: 4.06724
Timestep Consumption Time: 0.77214
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.83938

Cumulative Model Updates: 10,612
Cumulative Timesteps: 177,106,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.00948
Policy Entropy: 1.26433
Value Function Loss: 0.34261

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.07363

Collected Steps per Second: 12,799.39748
Overall Steps per Second: 10,600.91199

Timestep Collection Time: 3.90784
Timestep Consumption Time: 0.81043
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 4.71827

Cumulative Model Updates: 10,615
Cumulative Timesteps: 177,156,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 177156034...
Checkpoint 177156034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.07020
Policy Entropy: 1.27106
Value Function Loss: 0.34570

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.08140

Collected Steps per Second: 12,259.39671
Overall Steps per Second: 10,238.25210

Timestep Collection Time: 4.07883
Timestep Consumption Time: 0.80521
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.88404

Cumulative Model Updates: 10,618
Cumulative Timesteps: 177,206,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.14274
Policy Entropy: 1.26476
Value Function Loss: 0.33336

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.10819

Collected Steps per Second: 13,128.25918
Overall Steps per Second: 11,016.46290

Timestep Collection Time: 3.80904
Timestep Consumption Time: 0.73017
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.53921

Cumulative Model Updates: 10,621
Cumulative Timesteps: 177,256,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 177256044...
Checkpoint 177256044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.05464
Policy Entropy: 1.27164
Value Function Loss: 0.33879

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04466
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.10201

Collected Steps per Second: 13,011.55205
Overall Steps per Second: 10,739.82465

Timestep Collection Time: 3.84412
Timestep Consumption Time: 0.81312
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.65725

Cumulative Model Updates: 10,624
Cumulative Timesteps: 177,306,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.39862
Policy Entropy: 1.27097
Value Function Loss: 0.34069

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05131
Policy Update Magnitude: 0.06589
Value Function Update Magnitude: 0.09203

Collected Steps per Second: 12,094.16332
Overall Steps per Second: 10,288.11284

Timestep Collection Time: 4.13439
Timestep Consumption Time: 0.72578
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.86017

Cumulative Model Updates: 10,627
Cumulative Timesteps: 177,356,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 177356064...
Checkpoint 177356064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.62680
Policy Entropy: 1.27062
Value Function Loss: 0.34095

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.08610

Collected Steps per Second: 13,400.47489
Overall Steps per Second: 11,148.99189

Timestep Collection Time: 3.73136
Timestep Consumption Time: 0.75353
PPO Batch Consumption Time: 0.03361
Total Iteration Time: 4.48489

Cumulative Model Updates: 10,630
Cumulative Timesteps: 177,406,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.80129
Policy Entropy: 1.27260
Value Function Loss: 0.34187

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04961
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.08793

Collected Steps per Second: 13,079.18183
Overall Steps per Second: 10,952.65817

Timestep Collection Time: 3.82501
Timestep Consumption Time: 0.74265
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.56766

Cumulative Model Updates: 10,633
Cumulative Timesteps: 177,456,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 177456094...
Checkpoint 177456094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.35858
Policy Entropy: 1.27058
Value Function Loss: 0.33108

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06962
Policy Update Magnitude: 0.06617
Value Function Update Magnitude: 0.08543

Collected Steps per Second: 13,086.31109
Overall Steps per Second: 11,028.00525

Timestep Collection Time: 3.82155
Timestep Consumption Time: 0.71327
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.53482

Cumulative Model Updates: 10,636
Cumulative Timesteps: 177,506,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.59163
Policy Entropy: 1.26696
Value Function Loss: 0.33947

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.08912

Collected Steps per Second: 12,646.46280
Overall Steps per Second: 10,514.83890

Timestep Collection Time: 3.95367
Timestep Consumption Time: 0.80151
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.75518

Cumulative Model Updates: 10,639
Cumulative Timesteps: 177,556,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 177556104...
Checkpoint 177556104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.89254
Policy Entropy: 1.26722
Value Function Loss: 0.33503

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.07696

Collected Steps per Second: 12,541.69345
Overall Steps per Second: 10,539.85765

Timestep Collection Time: 3.98846
Timestep Consumption Time: 0.75753
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 4.74598

Cumulative Model Updates: 10,642
Cumulative Timesteps: 177,606,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.23035
Policy Entropy: 1.26779
Value Function Loss: 0.32571

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06668
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.06609

Collected Steps per Second: 11,913.33298
Overall Steps per Second: 10,027.69449

Timestep Collection Time: 4.19698
Timestep Consumption Time: 0.78921
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 4.98619

Cumulative Model Updates: 10,645
Cumulative Timesteps: 177,656,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 177656126...
Checkpoint 177656126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.22448
Policy Entropy: 1.26475
Value Function Loss: 0.30713

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07062
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.05777

Collected Steps per Second: 12,596.06685
Overall Steps per Second: 10,526.21302

Timestep Collection Time: 3.97156
Timestep Consumption Time: 0.78096
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 4.75252

Cumulative Model Updates: 10,648
Cumulative Timesteps: 177,706,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.17691
Policy Entropy: 1.26980
Value Function Loss: 0.32219

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05426
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.05361

Collected Steps per Second: 12,628.31632
Overall Steps per Second: 10,696.59935

Timestep Collection Time: 3.95936
Timestep Consumption Time: 0.71503
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.67438

Cumulative Model Updates: 10,651
Cumulative Timesteps: 177,756,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 177756152...
Checkpoint 177756152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.81207
Policy Entropy: 1.26646
Value Function Loss: 0.31775

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07278
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.05256

Collected Steps per Second: 12,160.20756
Overall Steps per Second: 10,201.94287

Timestep Collection Time: 4.11358
Timestep Consumption Time: 0.78960
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.90318

Cumulative Model Updates: 10,654
Cumulative Timesteps: 177,806,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.28901
Policy Entropy: 1.27456
Value Function Loss: 0.31543

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.07333

Collected Steps per Second: 11,891.43710
Overall Steps per Second: 10,098.60487

Timestep Collection Time: 4.20555
Timestep Consumption Time: 0.74662
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 4.95217

Cumulative Model Updates: 10,657
Cumulative Timesteps: 177,856,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 177856184...
Checkpoint 177856184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.03343
Policy Entropy: 1.27295
Value Function Loss: 0.29897

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.06188

Collected Steps per Second: 12,545.08767
Overall Steps per Second: 10,464.37790

Timestep Collection Time: 3.98754
Timestep Consumption Time: 0.79287
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.78041

Cumulative Model Updates: 10,660
Cumulative Timesteps: 177,906,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.83596
Policy Entropy: 1.26752
Value Function Loss: 0.31254

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.06247

Collected Steps per Second: 11,912.51197
Overall Steps per Second: 9,930.28074

Timestep Collection Time: 4.19827
Timestep Consumption Time: 0.83804
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.03631

Cumulative Model Updates: 10,663
Cumulative Timesteps: 177,956,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 177956220...
Checkpoint 177956220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.55537
Policy Entropy: 1.26666
Value Function Loss: 0.32099

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05981
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.06247

Collected Steps per Second: 12,259.84056
Overall Steps per Second: 10,448.14436

Timestep Collection Time: 4.07852
Timestep Consumption Time: 0.70721
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.78573

Cumulative Model Updates: 10,666
Cumulative Timesteps: 178,006,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.42811
Policy Entropy: 1.26931
Value Function Loss: 0.34360

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05383
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.06149

Collected Steps per Second: 12,037.24037
Overall Steps per Second: 10,159.14525

Timestep Collection Time: 4.15577
Timestep Consumption Time: 0.76827
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.92404

Cumulative Model Updates: 10,669
Cumulative Timesteps: 178,056,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 178056246...
Checkpoint 178056246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.85001
Policy Entropy: 1.26763
Value Function Loss: 0.34796

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05245
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.06601

Collected Steps per Second: 12,190.17304
Overall Steps per Second: 10,415.57091

Timestep Collection Time: 4.10265
Timestep Consumption Time: 0.69901
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 4.80166

Cumulative Model Updates: 10,672
Cumulative Timesteps: 178,106,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.90915
Policy Entropy: 1.27127
Value Function Loss: 0.33657

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06738
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.06131

Collected Steps per Second: 12,267.78993
Overall Steps per Second: 10,297.28584

Timestep Collection Time: 4.07604
Timestep Consumption Time: 0.78000
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 4.85604

Cumulative Model Updates: 10,675
Cumulative Timesteps: 178,156,262

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 178156262...
Checkpoint 178156262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.97176
Policy Entropy: 1.27299
Value Function Loss: 0.30511

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06821
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.06496

Collected Steps per Second: 12,277.28910
Overall Steps per Second: 10,380.65228

Timestep Collection Time: 4.07354
Timestep Consumption Time: 0.74427
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 4.81781

Cumulative Model Updates: 10,678
Cumulative Timesteps: 178,206,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.59078
Policy Entropy: 1.27105
Value Function Loss: 0.30657

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.06122

Collected Steps per Second: 12,503.98983
Overall Steps per Second: 10,381.55612

Timestep Collection Time: 4.00048
Timestep Consumption Time: 0.81787
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.81835

Cumulative Model Updates: 10,681
Cumulative Timesteps: 178,256,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 178256296...
Checkpoint 178256296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.11137
Policy Entropy: 1.27335
Value Function Loss: 0.29781

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06936
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.06245

Collected Steps per Second: 12,249.05167
Overall Steps per Second: 10,292.79158

Timestep Collection Time: 4.08309
Timestep Consumption Time: 0.77604
PPO Batch Consumption Time: 0.03945
Total Iteration Time: 4.85913

Cumulative Model Updates: 10,684
Cumulative Timesteps: 178,306,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.09743
Policy Entropy: 1.28040
Value Function Loss: 0.31453

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.05662

Collected Steps per Second: 12,531.07941
Overall Steps per Second: 10,693.00793

Timestep Collection Time: 3.99231
Timestep Consumption Time: 0.68626
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 4.67857

Cumulative Model Updates: 10,687
Cumulative Timesteps: 178,356,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 178356338...
Checkpoint 178356338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.94764
Policy Entropy: 1.27464
Value Function Loss: 0.30778

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05842
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.06151

Collected Steps per Second: 12,291.42831
Overall Steps per Second: 10,308.25865

Timestep Collection Time: 4.06901
Timestep Consumption Time: 0.78282
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 4.85184

Cumulative Model Updates: 10,690
Cumulative Timesteps: 178,406,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.59862
Policy Entropy: 1.28548
Value Function Loss: 0.30543

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05339
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 12,266.56507
Overall Steps per Second: 10,388.15993

Timestep Collection Time: 4.07824
Timestep Consumption Time: 0.73743
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 4.81567

Cumulative Model Updates: 10,693
Cumulative Timesteps: 178,456,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 178456378...
Checkpoint 178456378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.23381
Policy Entropy: 1.27810
Value Function Loss: 0.27633

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03579
Policy Update Magnitude: 0.07087
Value Function Update Magnitude: 0.07164

Collected Steps per Second: 12,709.14907
Overall Steps per Second: 10,628.61772

Timestep Collection Time: 3.93465
Timestep Consumption Time: 0.77020
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.70485

Cumulative Model Updates: 10,696
Cumulative Timesteps: 178,506,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.49589
Policy Entropy: 1.27924
Value Function Loss: 0.26753

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07259
Policy Update Magnitude: 0.07319
Value Function Update Magnitude: 0.06201

Collected Steps per Second: 12,347.53572
Overall Steps per Second: 10,427.40559

Timestep Collection Time: 4.04939
Timestep Consumption Time: 0.74567
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 4.79506

Cumulative Model Updates: 10,699
Cumulative Timesteps: 178,556,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 178556384...
Checkpoint 178556384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.19645
Policy Entropy: 1.27746
Value Function Loss: 0.30154

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05268
Policy Update Magnitude: 0.07329
Value Function Update Magnitude: 0.06999

Collected Steps per Second: 11,772.44386
Overall Steps per Second: 10,107.01399

Timestep Collection Time: 4.24857
Timestep Consumption Time: 0.70008
PPO Batch Consumption Time: 0.03355
Total Iteration Time: 4.94864

Cumulative Model Updates: 10,702
Cumulative Timesteps: 178,606,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.96950
Policy Entropy: 1.27312
Value Function Loss: 0.33912

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05571
Policy Update Magnitude: 0.07820
Value Function Update Magnitude: 0.06344

Collected Steps per Second: 12,460.41399
Overall Steps per Second: 10,444.59439

Timestep Collection Time: 4.01528
Timestep Consumption Time: 0.77495
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.79023

Cumulative Model Updates: 10,705
Cumulative Timesteps: 178,656,432

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 178656432...
Checkpoint 178656432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.79584
Policy Entropy: 1.27657
Value Function Loss: 0.34047

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05368
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.07650

Collected Steps per Second: 12,610.70430
Overall Steps per Second: 10,585.50610

Timestep Collection Time: 3.96520
Timestep Consumption Time: 0.75861
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 4.72382

Cumulative Model Updates: 10,708
Cumulative Timesteps: 178,706,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.36388
Policy Entropy: 1.27707
Value Function Loss: 0.35386

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05778
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.06778

Collected Steps per Second: 12,707.55177
Overall Steps per Second: 10,550.17979

Timestep Collection Time: 3.93483
Timestep Consumption Time: 0.80462
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 4.73945

Cumulative Model Updates: 10,711
Cumulative Timesteps: 178,756,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 178756438...
Checkpoint 178756438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.91503
Policy Entropy: 1.27410
Value Function Loss: 0.36188

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.06047
Policy Update Magnitude: 0.06766
Value Function Update Magnitude: 0.06239

Collected Steps per Second: 12,622.26956
Overall Steps per Second: 10,612.80516

Timestep Collection Time: 3.96300
Timestep Consumption Time: 0.75037
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.71336

Cumulative Model Updates: 10,714
Cumulative Timesteps: 178,806,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.82064
Policy Entropy: 1.26949
Value Function Loss: 0.37029

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05143
Policy Update Magnitude: 0.07632
Value Function Update Magnitude: 0.05330

Collected Steps per Second: 12,677.31503
Overall Steps per Second: 10,747.17611

Timestep Collection Time: 3.94453
Timestep Consumption Time: 0.70842
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 4.65294

Cumulative Model Updates: 10,717
Cumulative Timesteps: 178,856,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 178856466...
Checkpoint 178856466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.13072
Policy Entropy: 1.27040
Value Function Loss: 0.37833

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 0.07440
Value Function Update Magnitude: 0.05534

Collected Steps per Second: 11,758.84532
Overall Steps per Second: 9,940.32032

Timestep Collection Time: 4.25416
Timestep Consumption Time: 0.77827
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 5.03243

Cumulative Model Updates: 10,720
Cumulative Timesteps: 178,906,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.75061
Policy Entropy: 1.27623
Value Function Loss: 0.38255

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.06923
Value Function Update Magnitude: 0.05861

Collected Steps per Second: 12,512.83044
Overall Steps per Second: 10,482.45134

Timestep Collection Time: 3.99782
Timestep Consumption Time: 0.77435
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 4.77217

Cumulative Model Updates: 10,723
Cumulative Timesteps: 178,956,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 178956514...
Checkpoint 178956514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.58324
Policy Entropy: 1.27275
Value Function Loss: 0.36926

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.07202
Value Function Update Magnitude: 0.05388

Collected Steps per Second: 12,425.62881
Overall Steps per Second: 10,448.49573

Timestep Collection Time: 4.02555
Timestep Consumption Time: 0.76174
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 4.78729

Cumulative Model Updates: 10,726
Cumulative Timesteps: 179,006,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.81398
Policy Entropy: 1.27763
Value Function Loss: 0.33603

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.07377
Value Function Update Magnitude: 0.04482

Collected Steps per Second: 12,347.44243
Overall Steps per Second: 10,394.93520

Timestep Collection Time: 4.05007
Timestep Consumption Time: 0.76073
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.81080

Cumulative Model Updates: 10,729
Cumulative Timesteps: 179,056,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 179056542...
Checkpoint 179056542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.36636
Policy Entropy: 1.27761
Value Function Loss: 0.33800

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.06919
Value Function Update Magnitude: 0.04180

Collected Steps per Second: 12,338.78179
Overall Steps per Second: 10,531.38238

Timestep Collection Time: 4.05226
Timestep Consumption Time: 0.69545
PPO Batch Consumption Time: 0.03737
Total Iteration Time: 4.74771

Cumulative Model Updates: 10,732
Cumulative Timesteps: 179,106,542

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.48197
Policy Entropy: 1.28264
Value Function Loss: 0.36417

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.06079
Policy Update Magnitude: 0.06463
Value Function Update Magnitude: 0.04001

Collected Steps per Second: 12,542.17099
Overall Steps per Second: 10,492.32636

Timestep Collection Time: 3.98846
Timestep Consumption Time: 0.77921
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.76767

Cumulative Model Updates: 10,735
Cumulative Timesteps: 179,156,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 179156566...
Checkpoint 179156566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.40478
Policy Entropy: 1.28346
Value Function Loss: 0.36169

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05414
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.03913

Collected Steps per Second: 11,851.28483
Overall Steps per Second: 9,991.18856

Timestep Collection Time: 4.22115
Timestep Consumption Time: 0.78587
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.00701

Cumulative Model Updates: 10,738
Cumulative Timesteps: 179,206,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.98403
Policy Entropy: 1.28533
Value Function Loss: 0.37541

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03355
Policy Update Magnitude: 0.07023
Value Function Update Magnitude: 0.04208

Collected Steps per Second: 12,418.72324
Overall Steps per Second: 10,415.02073

Timestep Collection Time: 4.02795
Timestep Consumption Time: 0.77492
PPO Batch Consumption Time: 0.03826
Total Iteration Time: 4.80287

Cumulative Model Updates: 10,741
Cumulative Timesteps: 179,256,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 179256614...
Checkpoint 179256614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.15054
Policy Entropy: 1.28292
Value Function Loss: 0.34400

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04367
Policy Update Magnitude: 0.07595
Value Function Update Magnitude: 0.03830

Collected Steps per Second: 12,483.55218
Overall Steps per Second: 10,482.94089

Timestep Collection Time: 4.00767
Timestep Consumption Time: 0.76484
PPO Batch Consumption Time: 0.03899
Total Iteration Time: 4.77252

Cumulative Model Updates: 10,744
Cumulative Timesteps: 179,306,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.15872
Policy Entropy: 1.28198
Value Function Loss: 0.37951

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04259
Policy Update Magnitude: 0.07662
Value Function Update Magnitude: 0.03809

Collected Steps per Second: 12,572.35456
Overall Steps per Second: 10,679.48262

Timestep Collection Time: 3.97921
Timestep Consumption Time: 0.70529
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.68450

Cumulative Model Updates: 10,747
Cumulative Timesteps: 179,356,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 179356672...
Checkpoint 179356672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.57738
Policy Entropy: 1.28436
Value Function Loss: 0.36354

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.04927
Policy Update Magnitude: 0.07587
Value Function Update Magnitude: 0.04687

Collected Steps per Second: 12,606.97253
Overall Steps per Second: 10,517.28868

Timestep Collection Time: 3.96812
Timestep Consumption Time: 0.78843
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.75655

Cumulative Model Updates: 10,750
Cumulative Timesteps: 179,406,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.65493
Policy Entropy: 1.28458
Value Function Loss: 0.38255

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05247
Policy Update Magnitude: 0.07493
Value Function Update Magnitude: 0.04581

Collected Steps per Second: 12,580.96322
Overall Steps per Second: 10,544.63415

Timestep Collection Time: 3.97426
Timestep Consumption Time: 0.76749
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.74175

Cumulative Model Updates: 10,753
Cumulative Timesteps: 179,456,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 179456698...
Checkpoint 179456698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.15269
Policy Entropy: 1.28492
Value Function Loss: 0.34951

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.06937
Value Function Update Magnitude: 0.04448

Collected Steps per Second: 12,432.28967
Overall Steps per Second: 10,240.65540

Timestep Collection Time: 4.02355
Timestep Consumption Time: 0.86109
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.88465

Cumulative Model Updates: 10,756
Cumulative Timesteps: 179,506,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.04771
Policy Entropy: 1.28166
Value Function Loss: 0.33483

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04699
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.05812

Collected Steps per Second: 12,251.21485
Overall Steps per Second: 10,297.07231

Timestep Collection Time: 4.08319
Timestep Consumption Time: 0.77489
PPO Batch Consumption Time: 0.03824
Total Iteration Time: 4.85808

Cumulative Model Updates: 10,759
Cumulative Timesteps: 179,556,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 179556744...
Checkpoint 179556744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.44004
Policy Entropy: 1.28207
Value Function Loss: 0.32843

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05039
Policy Update Magnitude: 0.06547
Value Function Update Magnitude: 0.04974

Collected Steps per Second: 12,329.62239
Overall Steps per Second: 10,519.30307

Timestep Collection Time: 4.05771
Timestep Consumption Time: 0.69831
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.75602

Cumulative Model Updates: 10,762
Cumulative Timesteps: 179,606,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.13243
Policy Entropy: 1.28514
Value Function Loss: 0.30068

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03857
Policy Update Magnitude: 0.06876
Value Function Update Magnitude: 0.05880

Collected Steps per Second: 12,031.06622
Overall Steps per Second: 10,140.32223

Timestep Collection Time: 4.15757
Timestep Consumption Time: 0.77521
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 4.93278

Cumulative Model Updates: 10,765
Cumulative Timesteps: 179,656,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 179656794...
Checkpoint 179656794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.58081
Policy Entropy: 1.28510
Value Function Loss: 0.30193

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.07261
Value Function Update Magnitude: 0.05999

Collected Steps per Second: 12,027.98253
Overall Steps per Second: 10,223.29553

Timestep Collection Time: 4.15947
Timestep Consumption Time: 0.73426
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 4.89373

Cumulative Model Updates: 10,768
Cumulative Timesteps: 179,706,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.01316
Policy Entropy: 1.28208
Value Function Loss: 0.30064

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03906
Policy Update Magnitude: 0.07470
Value Function Update Magnitude: 0.04868

Collected Steps per Second: 12,983.55388
Overall Steps per Second: 10,789.01800

Timestep Collection Time: 3.85318
Timestep Consumption Time: 0.78375
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 4.63694

Cumulative Model Updates: 10,771
Cumulative Timesteps: 179,756,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 179756852...
Checkpoint 179756852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.49866
Policy Entropy: 1.27930
Value Function Loss: 0.32898

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03397
Policy Update Magnitude: 0.07473
Value Function Update Magnitude: 0.04629

Collected Steps per Second: 13,237.83092
Overall Steps per Second: 10,998.23021

Timestep Collection Time: 3.77902
Timestep Consumption Time: 0.76953
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.54855

Cumulative Model Updates: 10,774
Cumulative Timesteps: 179,806,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.37029
Policy Entropy: 1.28207
Value Function Loss: 0.34555

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05843
Policy Update Magnitude: 0.07392
Value Function Update Magnitude: 0.04170

Collected Steps per Second: 12,559.88666
Overall Steps per Second: 10,433.10960

Timestep Collection Time: 3.98332
Timestep Consumption Time: 0.81199
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 4.79531

Cumulative Model Updates: 10,777
Cumulative Timesteps: 179,856,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 179856908...
Checkpoint 179856908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.79538
Policy Entropy: 1.28341
Value Function Loss: 0.35832

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06042
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.04086

Collected Steps per Second: 13,263.57217
Overall Steps per Second: 11,084.84248

Timestep Collection Time: 3.77138
Timestep Consumption Time: 0.74127
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 4.51265

Cumulative Model Updates: 10,780
Cumulative Timesteps: 179,906,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.48862
Policy Entropy: 1.28404
Value Function Loss: 0.33214

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.06134
Value Function Update Magnitude: 0.04382

Collected Steps per Second: 12,806.73368
Overall Steps per Second: 10,840.96980

Timestep Collection Time: 3.90529
Timestep Consumption Time: 0.70814
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 4.61342

Cumulative Model Updates: 10,783
Cumulative Timesteps: 179,956,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 179956944...
Checkpoint 179956944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.95825
Policy Entropy: 1.28729
Value Function Loss: 0.31406

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.04262

Collected Steps per Second: 13,124.20136
Overall Steps per Second: 10,876.40660

Timestep Collection Time: 3.81021
Timestep Consumption Time: 0.78745
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.59766

Cumulative Model Updates: 10,786
Cumulative Timesteps: 180,006,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.09259
Policy Entropy: 1.28574
Value Function Loss: 0.31013

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06841
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.04097

Collected Steps per Second: 12,689.37797
Overall Steps per Second: 10,834.04776

Timestep Collection Time: 3.94204
Timestep Consumption Time: 0.67507
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 4.61711

Cumulative Model Updates: 10,789
Cumulative Timesteps: 180,056,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 180056972...
Checkpoint 180056972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.39011
Policy Entropy: 1.28166
Value Function Loss: 0.31616

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06093
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.03972

Collected Steps per Second: 12,403.42925
Overall Steps per Second: 10,408.87007

Timestep Collection Time: 4.03276
Timestep Consumption Time: 0.77276
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 4.80552

Cumulative Model Updates: 10,792
Cumulative Timesteps: 180,106,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.34420
Policy Entropy: 1.28622
Value Function Loss: 0.31021

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07145
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.04231

Collected Steps per Second: 11,671.56020
Overall Steps per Second: 9,907.66692

Timestep Collection Time: 4.28477
Timestep Consumption Time: 0.76283
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.04761

Cumulative Model Updates: 10,795
Cumulative Timesteps: 180,157,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 180157002...
Checkpoint 180157002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.90450
Policy Entropy: 1.28762
Value Function Loss: 0.29744

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06568
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.05330

Collected Steps per Second: 12,295.77988
Overall Steps per Second: 10,496.85969

Timestep Collection Time: 4.06660
Timestep Consumption Time: 0.69692
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.76352

Cumulative Model Updates: 10,798
Cumulative Timesteps: 180,207,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.40952
Policy Entropy: 1.29138
Value Function Loss: 0.31424

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04353
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.06472

Collected Steps per Second: 12,495.42986
Overall Steps per Second: 10,379.37779

Timestep Collection Time: 4.00370
Timestep Consumption Time: 0.81624
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.81994

Cumulative Model Updates: 10,801
Cumulative Timesteps: 180,257,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 180257032...
Checkpoint 180257032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.78859
Policy Entropy: 1.28499
Value Function Loss: 0.35237

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05985
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.06507

Collected Steps per Second: 12,220.05779
Overall Steps per Second: 10,372.20466

Timestep Collection Time: 4.09294
Timestep Consumption Time: 0.72918
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 4.82212

Cumulative Model Updates: 10,804
Cumulative Timesteps: 180,307,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.38474
Policy Entropy: 1.28790
Value Function Loss: 0.36837

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04182
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.06479

Collected Steps per Second: 12,328.19686
Overall Steps per Second: 10,337.73404

Timestep Collection Time: 4.05655
Timestep Consumption Time: 0.78106
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 4.83762

Cumulative Model Updates: 10,807
Cumulative Timesteps: 180,357,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 180357058...
Checkpoint 180357058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.41807
Policy Entropy: 1.28628
Value Function Loss: 0.37716

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04727
Policy Update Magnitude: 0.06904
Value Function Update Magnitude: 0.07556

Collected Steps per Second: 12,286.47096
Overall Steps per Second: 10,395.11651

Timestep Collection Time: 4.06952
Timestep Consumption Time: 0.74043
PPO Batch Consumption Time: 0.03293
Total Iteration Time: 4.80995

Cumulative Model Updates: 10,810
Cumulative Timesteps: 180,407,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.38149
Policy Entropy: 1.28823
Value Function Loss: 0.34726

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05563
Policy Update Magnitude: 0.06972
Value Function Update Magnitude: 0.10075

Collected Steps per Second: 12,379.14055
Overall Steps per Second: 10,303.18894

Timestep Collection Time: 4.03954
Timestep Consumption Time: 0.81391
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.85345

Cumulative Model Updates: 10,813
Cumulative Timesteps: 180,457,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 180457064...
Checkpoint 180457064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.45910
Policy Entropy: 1.28590
Value Function Loss: 0.32932

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.09845

Collected Steps per Second: 12,324.35576
Overall Steps per Second: 10,386.49297

Timestep Collection Time: 4.05944
Timestep Consumption Time: 0.75739
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 4.81683

Cumulative Model Updates: 10,816
Cumulative Timesteps: 180,507,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.13408
Policy Entropy: 1.27997
Value Function Loss: 0.31715

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.08442

Collected Steps per Second: 12,493.88567
Overall Steps per Second: 10,693.59663

Timestep Collection Time: 4.00228
Timestep Consumption Time: 0.67379
PPO Batch Consumption Time: 0.03263
Total Iteration Time: 4.67607

Cumulative Model Updates: 10,819
Cumulative Timesteps: 180,557,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 180557098...
Checkpoint 180557098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.81014
Policy Entropy: 1.28329
Value Function Loss: 0.31130

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04627
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.08490

Collected Steps per Second: 12,052.05441
Overall Steps per Second: 10,203.32546

Timestep Collection Time: 4.15050
Timestep Consumption Time: 0.75202
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 4.90252

Cumulative Model Updates: 10,822
Cumulative Timesteps: 180,607,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.15940
Policy Entropy: 1.28189
Value Function Loss: 0.31782

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05254
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.09344

Collected Steps per Second: 12,401.51635
Overall Steps per Second: 10,473.51574

Timestep Collection Time: 4.03306
Timestep Consumption Time: 0.74242
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.77547

Cumulative Model Updates: 10,825
Cumulative Timesteps: 180,657,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 180657136...
Checkpoint 180657136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.43212
Policy Entropy: 1.28292
Value Function Loss: 0.30779

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04983
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.08640

Collected Steps per Second: 12,546.04808
Overall Steps per Second: 10,588.50323

Timestep Collection Time: 3.98659
Timestep Consumption Time: 0.73702
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 4.72361

Cumulative Model Updates: 10,828
Cumulative Timesteps: 180,707,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.08181
Policy Entropy: 1.28243
Value Function Loss: 0.30391

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04907
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.09606

Collected Steps per Second: 12,449.22389
Overall Steps per Second: 10,554.94561

Timestep Collection Time: 4.01776
Timestep Consumption Time: 0.72106
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.73882

Cumulative Model Updates: 10,831
Cumulative Timesteps: 180,757,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 180757170...
Checkpoint 180757170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.03318
Policy Entropy: 1.28394
Value Function Loss: 0.29704

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05500
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.11320

Collected Steps per Second: 11,876.75223
Overall Steps per Second: 10,115.23500

Timestep Collection Time: 4.21075
Timestep Consumption Time: 0.73328
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 4.94403

Cumulative Model Updates: 10,834
Cumulative Timesteps: 180,807,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.46781
Policy Entropy: 1.28697
Value Function Loss: 0.29891

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05850
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.11899

Collected Steps per Second: 12,388.26502
Overall Steps per Second: 10,363.81917

Timestep Collection Time: 4.03688
Timestep Consumption Time: 0.78856
PPO Batch Consumption Time: 0.03835
Total Iteration Time: 4.82544

Cumulative Model Updates: 10,837
Cumulative Timesteps: 180,857,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 180857190...
Checkpoint 180857190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.87627
Policy Entropy: 1.28411
Value Function Loss: 0.30364

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05511
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.10711

Collected Steps per Second: 12,431.03515
Overall Steps per Second: 10,439.07679

Timestep Collection Time: 4.02332
Timestep Consumption Time: 0.76772
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 4.79104

Cumulative Model Updates: 10,840
Cumulative Timesteps: 180,907,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.15145
Policy Entropy: 1.28008
Value Function Loss: 0.29353

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06105
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.11587

Collected Steps per Second: 12,467.18763
Overall Steps per Second: 10,480.51912

Timestep Collection Time: 4.01133
Timestep Consumption Time: 0.76038
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.77171

Cumulative Model Updates: 10,843
Cumulative Timesteps: 180,957,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 180957214...
Checkpoint 180957214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.92403
Policy Entropy: 1.27933
Value Function Loss: 0.29083

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05924
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.11789

Collected Steps per Second: 12,401.66748
Overall Steps per Second: 10,491.57667

Timestep Collection Time: 4.03430
Timestep Consumption Time: 0.73448
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 4.76878

Cumulative Model Updates: 10,846
Cumulative Timesteps: 181,007,246

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.86833
Policy Entropy: 1.27996
Value Function Loss: 0.28545

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06249
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.11746

Collected Steps per Second: 12,473.63205
Overall Steps per Second: 10,659.82874

Timestep Collection Time: 4.01022
Timestep Consumption Time: 0.68235
PPO Batch Consumption Time: 0.03399
Total Iteration Time: 4.69257

Cumulative Model Updates: 10,849
Cumulative Timesteps: 181,057,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 181057268...
Checkpoint 181057268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.53815
Policy Entropy: 1.28245
Value Function Loss: 0.27608

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06485
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.12545

Collected Steps per Second: 11,736.32542
Overall Steps per Second: 9,979.88902

Timestep Collection Time: 4.26283
Timestep Consumption Time: 0.75025
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.01308

Cumulative Model Updates: 10,852
Cumulative Timesteps: 181,107,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.37823
Policy Entropy: 1.27528
Value Function Loss: 0.27272

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05635
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.11202

Collected Steps per Second: 11,821.15049
Overall Steps per Second: 10,026.03003

Timestep Collection Time: 4.23038
Timestep Consumption Time: 0.75743
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.98782

Cumulative Model Updates: 10,855
Cumulative Timesteps: 181,157,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 181157306...
Checkpoint 181157306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.78668
Policy Entropy: 1.27576
Value Function Loss: 0.26466

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.10252

Collected Steps per Second: 12,602.76940
Overall Steps per Second: 10,447.03062

Timestep Collection Time: 3.96945
Timestep Consumption Time: 0.81909
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.78854

Cumulative Model Updates: 10,858
Cumulative Timesteps: 181,207,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.78485
Policy Entropy: 1.26702
Value Function Loss: 0.29897

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.09022

Collected Steps per Second: 12,643.87360
Overall Steps per Second: 10,630.61396

Timestep Collection Time: 3.95622
Timestep Consumption Time: 0.74924
PPO Batch Consumption Time: 0.03275
Total Iteration Time: 4.70547

Cumulative Model Updates: 10,861
Cumulative Timesteps: 181,257,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 181257354...
Checkpoint 181257354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.29775
Policy Entropy: 1.28187
Value Function Loss: 0.30555

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.07741

Collected Steps per Second: 12,452.70141
Overall Steps per Second: 10,543.08547

Timestep Collection Time: 4.01648
Timestep Consumption Time: 0.72748
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 4.74396

Cumulative Model Updates: 10,864
Cumulative Timesteps: 181,307,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.68957
Policy Entropy: 1.28306
Value Function Loss: 0.31424

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.06452

Collected Steps per Second: 12,608.54755
Overall Steps per Second: 10,485.18706

Timestep Collection Time: 3.96683
Timestep Consumption Time: 0.80333
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 4.77016

Cumulative Model Updates: 10,867
Cumulative Timesteps: 181,357,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 181357386...
Checkpoint 181357386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.41079
Policy Entropy: 1.28163
Value Function Loss: 0.28798

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.07419

Collected Steps per Second: 11,756.41663
Overall Steps per Second: 10,134.81410

Timestep Collection Time: 4.25555
Timestep Consumption Time: 0.68090
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 4.93645

Cumulative Model Updates: 10,870
Cumulative Timesteps: 181,407,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.91966
Policy Entropy: 1.28674
Value Function Loss: 0.30405

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.07657

Collected Steps per Second: 12,195.18500
Overall Steps per Second: 10,238.51263

Timestep Collection Time: 4.10063
Timestep Consumption Time: 0.78367
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.88430

Cumulative Model Updates: 10,873
Cumulative Timesteps: 181,457,424

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 181457424...
Checkpoint 181457424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.14243
Policy Entropy: 1.27757
Value Function Loss: 0.32681

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07823
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.06496

Collected Steps per Second: 12,370.45882
Overall Steps per Second: 10,449.14249

Timestep Collection Time: 4.04431
Timestep Consumption Time: 0.74364
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.78795

Cumulative Model Updates: 10,876
Cumulative Timesteps: 181,507,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.92097
Policy Entropy: 1.28688
Value Function Loss: 0.32689

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05289
Policy Update Magnitude: 0.06467
Value Function Update Magnitude: 0.05811

Collected Steps per Second: 12,294.36600
Overall Steps per Second: 10,470.52311

Timestep Collection Time: 4.06820
Timestep Consumption Time: 0.70863
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 4.77684

Cumulative Model Updates: 10,879
Cumulative Timesteps: 181,557,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 181557470...
Checkpoint 181557470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.57539
Policy Entropy: 1.27132
Value Function Loss: 0.28647

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.07214

Collected Steps per Second: 12,099.21589
Overall Steps per Second: 10,254.82044

Timestep Collection Time: 4.13316
Timestep Consumption Time: 0.74338
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 4.87654

Cumulative Model Updates: 10,882
Cumulative Timesteps: 181,607,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.29040
Policy Entropy: 1.28783
Value Function Loss: 0.28034

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05653
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.09231

Collected Steps per Second: 12,410.26016
Overall Steps per Second: 10,580.88684

Timestep Collection Time: 4.03118
Timestep Consumption Time: 0.69697
PPO Batch Consumption Time: 0.03352
Total Iteration Time: 4.72815

Cumulative Model Updates: 10,885
Cumulative Timesteps: 181,657,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 181657506...
Checkpoint 181657506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.97546
Policy Entropy: 1.27509
Value Function Loss: 0.27349

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.09297

Collected Steps per Second: 11,569.56070
Overall Steps per Second: 9,798.80182

Timestep Collection Time: 4.32203
Timestep Consumption Time: 0.78104
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.10307

Cumulative Model Updates: 10,888
Cumulative Timesteps: 181,707,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.22404
Policy Entropy: 1.28107
Value Function Loss: 0.30794

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06203
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.07729

Collected Steps per Second: 12,329.62820
Overall Steps per Second: 10,462.89164

Timestep Collection Time: 4.05641
Timestep Consumption Time: 0.72372
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 4.78013

Cumulative Model Updates: 10,891
Cumulative Timesteps: 181,757,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 181757524...
Checkpoint 181757524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.05750
Policy Entropy: 1.27598
Value Function Loss: 0.33334

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04172
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.07163

Collected Steps per Second: 12,601.73697
Overall Steps per Second: 10,562.11803

Timestep Collection Time: 3.96771
Timestep Consumption Time: 0.76619
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 4.73390

Cumulative Model Updates: 10,894
Cumulative Timesteps: 181,807,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.51380
Policy Entropy: 1.27340
Value Function Loss: 0.34037

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05687
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.06819

Collected Steps per Second: 12,536.42990
Overall Steps per Second: 10,483.24451

Timestep Collection Time: 3.99061
Timestep Consumption Time: 0.78158
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.77219

Cumulative Model Updates: 10,897
Cumulative Timesteps: 181,857,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 181857552...
Checkpoint 181857552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.73622
Policy Entropy: 1.26849
Value Function Loss: 0.32621

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.06335
Value Function Update Magnitude: 0.07052

Collected Steps per Second: 12,506.37681
Overall Steps per Second: 10,624.82830

Timestep Collection Time: 4.00004
Timestep Consumption Time: 0.70837
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.70841

Cumulative Model Updates: 10,900
Cumulative Timesteps: 181,907,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.71836
Policy Entropy: 1.27753
Value Function Loss: 0.28132

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03598
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.07996

Collected Steps per Second: 12,214.03411
Overall Steps per Second: 10,222.00225

Timestep Collection Time: 4.09480
Timestep Consumption Time: 0.79798
PPO Batch Consumption Time: 0.03343
Total Iteration Time: 4.89278

Cumulative Model Updates: 10,903
Cumulative Timesteps: 181,957,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 181957592...
Checkpoint 181957592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.66291
Policy Entropy: 1.27177
Value Function Loss: 0.28832

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05425
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.07713

Collected Steps per Second: 11,938.87702
Overall Steps per Second: 9,926.34380

Timestep Collection Time: 4.18984
Timestep Consumption Time: 0.84948
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.03932

Cumulative Model Updates: 10,906
Cumulative Timesteps: 182,007,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.32269
Policy Entropy: 1.27183
Value Function Loss: 0.29390

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.05113
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.07340

Collected Steps per Second: 12,019.54830
Overall Steps per Second: 10,260.01294

Timestep Collection Time: 4.15989
Timestep Consumption Time: 0.71340
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 4.87329

Cumulative Model Updates: 10,909
Cumulative Timesteps: 182,057,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 182057614...
Checkpoint 182057614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.35349
Policy Entropy: 1.27250
Value Function Loss: 0.32083

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05472
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.07321

Collected Steps per Second: 12,357.28151
Overall Steps per Second: 10,296.30943

Timestep Collection Time: 4.04798
Timestep Consumption Time: 0.81027
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 4.85825

Cumulative Model Updates: 10,912
Cumulative Timesteps: 182,107,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.45857
Policy Entropy: 1.27626
Value Function Loss: 0.31748

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06469
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 12,298.56108
Overall Steps per Second: 10,457.53591

Timestep Collection Time: 4.06665
Timestep Consumption Time: 0.71593
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.78258

Cumulative Model Updates: 10,915
Cumulative Timesteps: 182,157,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 182157650...
Checkpoint 182157650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.95884
Policy Entropy: 1.27184
Value Function Loss: 0.30495

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05832
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.07321

Collected Steps per Second: 12,181.86307
Overall Steps per Second: 10,254.17531

Timestep Collection Time: 4.10512
Timestep Consumption Time: 0.77172
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 4.87684

Cumulative Model Updates: 10,918
Cumulative Timesteps: 182,207,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.68958
Policy Entropy: 1.27334
Value Function Loss: 0.29348

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.07000

Collected Steps per Second: 12,579.02376
Overall Steps per Second: 10,608.64553

Timestep Collection Time: 3.97662
Timestep Consumption Time: 0.73859
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 4.71521

Cumulative Model Updates: 10,921
Cumulative Timesteps: 182,257,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 182257680...
Checkpoint 182257680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.31304
Policy Entropy: 1.27624
Value Function Loss: 0.27404

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05471
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.06717

Collected Steps per Second: 13,105.88994
Overall Steps per Second: 10,840.00784

Timestep Collection Time: 3.81599
Timestep Consumption Time: 0.79766
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.61365

Cumulative Model Updates: 10,924
Cumulative Timesteps: 182,307,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.22745
Policy Entropy: 1.27371
Value Function Loss: 0.27458

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05373
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.08392

Collected Steps per Second: 12,426.66912
Overall Steps per Second: 10,374.97671

Timestep Collection Time: 4.02377
Timestep Consumption Time: 0.79572
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 4.81948

Cumulative Model Updates: 10,927
Cumulative Timesteps: 182,357,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 182357694...
Checkpoint 182357694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.85077
Policy Entropy: 1.27421
Value Function Loss: 0.25897

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.04339
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.07902

Collected Steps per Second: 13,054.13875
Overall Steps per Second: 11,089.62767

Timestep Collection Time: 3.83036
Timestep Consumption Time: 0.67854
PPO Batch Consumption Time: 0.03401
Total Iteration Time: 4.50890

Cumulative Model Updates: 10,930
Cumulative Timesteps: 182,407,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.78454
Policy Entropy: 1.27277
Value Function Loss: 0.27413

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05752
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.07848

Collected Steps per Second: 12,982.38254
Overall Steps per Second: 10,818.60574

Timestep Collection Time: 3.85338
Timestep Consumption Time: 0.77070
PPO Batch Consumption Time: 0.03374
Total Iteration Time: 4.62407

Cumulative Model Updates: 10,933
Cumulative Timesteps: 182,457,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 182457722...
Checkpoint 182457722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.28621
Policy Entropy: 1.26864
Value Function Loss: 0.27911

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06365
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.06913

Collected Steps per Second: 12,607.08865
Overall Steps per Second: 10,623.28047

Timestep Collection Time: 3.96634
Timestep Consumption Time: 0.74068
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.70702

Cumulative Model Updates: 10,936
Cumulative Timesteps: 182,507,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.23152
Policy Entropy: 1.26955
Value Function Loss: 0.30515

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06526
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.05824

Collected Steps per Second: 12,301.11112
Overall Steps per Second: 10,443.68893

Timestep Collection Time: 4.06679
Timestep Consumption Time: 0.72328
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 4.79007

Cumulative Model Updates: 10,939
Cumulative Timesteps: 182,557,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 182557752...
Checkpoint 182557752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.77706
Policy Entropy: 1.27141
Value Function Loss: 0.31184

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04822
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.05582

Collected Steps per Second: 12,483.39417
Overall Steps per Second: 10,443.82956

Timestep Collection Time: 4.00740
Timestep Consumption Time: 0.78260
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 4.79001

Cumulative Model Updates: 10,942
Cumulative Timesteps: 182,607,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.20354
Policy Entropy: 1.27215
Value Function Loss: 0.29182

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05267
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.06241

Collected Steps per Second: 11,717.44429
Overall Steps per Second: 10,120.72817

Timestep Collection Time: 4.26851
Timestep Consumption Time: 0.67343
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.94194

Cumulative Model Updates: 10,945
Cumulative Timesteps: 182,657,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 182657794...
Checkpoint 182657794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.27919
Policy Entropy: 1.27587
Value Function Loss: 0.27688

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.06038

Collected Steps per Second: 12,217.23829
Overall Steps per Second: 10,275.38479

Timestep Collection Time: 4.09536
Timestep Consumption Time: 0.77395
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.86931

Cumulative Model Updates: 10,948
Cumulative Timesteps: 182,707,828

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.47754
Policy Entropy: 1.27418
Value Function Loss: 0.28416

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04939
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.05651

Collected Steps per Second: 12,502.64763
Overall Steps per Second: 10,526.92862

Timestep Collection Time: 4.00027
Timestep Consumption Time: 0.75078
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.75105

Cumulative Model Updates: 10,951
Cumulative Timesteps: 182,757,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 182757842...
Checkpoint 182757842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.86278
Policy Entropy: 1.27662
Value Function Loss: 0.29211

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03781
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.05438

Collected Steps per Second: 12,587.17791
Overall Steps per Second: 10,532.10813

Timestep Collection Time: 3.97389
Timestep Consumption Time: 0.77540
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.74929

Cumulative Model Updates: 10,954
Cumulative Timesteps: 182,807,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.20751
Policy Entropy: 1.27542
Value Function Loss: 0.28256

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04643
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.05923

Collected Steps per Second: 12,539.29024
Overall Steps per Second: 10,588.24192

Timestep Collection Time: 3.98986
Timestep Consumption Time: 0.73519
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 4.72505

Cumulative Model Updates: 10,957
Cumulative Timesteps: 182,857,892

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 182857892...
Checkpoint 182857892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.45128
Policy Entropy: 1.27406
Value Function Loss: 0.31263

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04007
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.05481

Collected Steps per Second: 12,311.64499
Overall Steps per Second: 10,570.47138

Timestep Collection Time: 4.06315
Timestep Consumption Time: 0.66928
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.73243

Cumulative Model Updates: 10,960
Cumulative Timesteps: 182,907,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.94363
Policy Entropy: 1.27170
Value Function Loss: 0.31847

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04786
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.05696

Collected Steps per Second: 11,727.44264
Overall Steps per Second: 9,888.47573

Timestep Collection Time: 4.26555
Timestep Consumption Time: 0.79327
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.05882

Cumulative Model Updates: 10,963
Cumulative Timesteps: 182,957,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 182957940...
Checkpoint 182957940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.43605
Policy Entropy: 1.27430
Value Function Loss: 0.33152

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04741
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.05477

Collected Steps per Second: 12,578.33171
Overall Steps per Second: 10,520.21392

Timestep Collection Time: 3.97716
Timestep Consumption Time: 0.77807
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.75523

Cumulative Model Updates: 10,966
Cumulative Timesteps: 183,007,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.07133
Policy Entropy: 1.27675
Value Function Loss: 0.28831

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05266
Policy Update Magnitude: 0.06027
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 12,746.42173
Overall Steps per Second: 10,639.83697

Timestep Collection Time: 3.92455
Timestep Consumption Time: 0.77702
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 4.70158

Cumulative Model Updates: 10,969
Cumulative Timesteps: 183,057,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 183057990...
Checkpoint 183057990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.71064
Policy Entropy: 1.28042
Value Function Loss: 0.28907

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05747
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 12,363.83091
Overall Steps per Second: 10,411.53158

Timestep Collection Time: 4.04454
Timestep Consumption Time: 0.75840
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 4.80294

Cumulative Model Updates: 10,972
Cumulative Timesteps: 183,107,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.03365
Policy Entropy: 1.27620
Value Function Loss: 0.32533

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05329
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.06526

Collected Steps per Second: 12,391.01746
Overall Steps per Second: 10,449.15467

Timestep Collection Time: 4.03647
Timestep Consumption Time: 0.75013
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 4.78661

Cumulative Model Updates: 10,975
Cumulative Timesteps: 183,158,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 183158012...
Checkpoint 183158012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.49850
Policy Entropy: 1.27787
Value Function Loss: 0.34831

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05567
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.06627

Collected Steps per Second: 12,201.91254
Overall Steps per Second: 10,321.44044

Timestep Collection Time: 4.09821
Timestep Consumption Time: 0.74666
PPO Batch Consumption Time: 0.03874
Total Iteration Time: 4.84487

Cumulative Model Updates: 10,978
Cumulative Timesteps: 183,208,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.46686
Policy Entropy: 1.27821
Value Function Loss: 0.34329

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05178
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.06919

Collected Steps per Second: 12,221.71398
Overall Steps per Second: 10,280.09149

Timestep Collection Time: 4.09255
Timestep Consumption Time: 0.77297
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 4.86552

Cumulative Model Updates: 10,981
Cumulative Timesteps: 183,258,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 183258036...
Checkpoint 183258036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.93980
Policy Entropy: 1.28176
Value Function Loss: 0.30183

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05417
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.06220

Collected Steps per Second: 12,354.33160
Overall Steps per Second: 10,382.27363

Timestep Collection Time: 4.04846
Timestep Consumption Time: 0.76898
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.81744

Cumulative Model Updates: 10,984
Cumulative Timesteps: 183,308,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.56190
Policy Entropy: 1.27666
Value Function Loss: 0.27879

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04840
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.05921

Collected Steps per Second: 12,602.73263
Overall Steps per Second: 10,623.84132

Timestep Collection Time: 3.96882
Timestep Consumption Time: 0.73927
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 4.70809

Cumulative Model Updates: 10,987
Cumulative Timesteps: 183,358,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 183358070...
Checkpoint 183358070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.82564
Policy Entropy: 1.28004
Value Function Loss: 0.27236

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05914
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.05910

Collected Steps per Second: 12,500.22149
Overall Steps per Second: 10,487.00082

Timestep Collection Time: 4.00137
Timestep Consumption Time: 0.76815
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.76952

Cumulative Model Updates: 10,990
Cumulative Timesteps: 183,408,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.85862
Policy Entropy: 1.28146
Value Function Loss: 0.28680

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05462
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.06651

Collected Steps per Second: 12,148.97142
Overall Steps per Second: 10,183.03508

Timestep Collection Time: 4.11739
Timestep Consumption Time: 0.79490
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 4.91229

Cumulative Model Updates: 10,993
Cumulative Timesteps: 183,458,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 183458110...
Checkpoint 183458110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.87507
Policy Entropy: 1.28542
Value Function Loss: 0.31402

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06321
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.08177

Collected Steps per Second: 12,358.29179
Overall Steps per Second: 10,544.55409

Timestep Collection Time: 4.04587
Timestep Consumption Time: 0.69592
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 4.74178

Cumulative Model Updates: 10,996
Cumulative Timesteps: 183,508,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.03163
Policy Entropy: 1.28093
Value Function Loss: 0.32104

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05688
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.10383

Collected Steps per Second: 12,549.23882
Overall Steps per Second: 10,540.83129

Timestep Collection Time: 3.98431
Timestep Consumption Time: 0.75915
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.74346

Cumulative Model Updates: 10,999
Cumulative Timesteps: 183,558,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 183558110...
Checkpoint 183558110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.25806
Policy Entropy: 1.28088
Value Function Loss: 0.30816

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04868
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.10348

Collected Steps per Second: 11,889.96567
Overall Steps per Second: 10,259.00648

Timestep Collection Time: 4.20691
Timestep Consumption Time: 0.66881
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.87572

Cumulative Model Updates: 11,002
Cumulative Timesteps: 183,608,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.99647
Policy Entropy: 1.27973
Value Function Loss: 0.28955

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05203
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.11183

Collected Steps per Second: 12,520.54966
Overall Steps per Second: 10,469.31593

Timestep Collection Time: 3.99471
Timestep Consumption Time: 0.78268
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.77739

Cumulative Model Updates: 11,005
Cumulative Timesteps: 183,658,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 183658146...
Checkpoint 183658146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.30124
Policy Entropy: 1.28474
Value Function Loss: 0.29155

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.10173

Collected Steps per Second: 12,278.79906
Overall Steps per Second: 10,446.94971

Timestep Collection Time: 4.07271
Timestep Consumption Time: 0.71414
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 4.78685

Cumulative Model Updates: 11,008
Cumulative Timesteps: 183,708,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.86829
Policy Entropy: 1.27845
Value Function Loss: 0.29821

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06815
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.08288

Collected Steps per Second: 12,564.28278
Overall Steps per Second: 10,543.19108

Timestep Collection Time: 3.98001
Timestep Consumption Time: 0.76295
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.74297

Cumulative Model Updates: 11,011
Cumulative Timesteps: 183,758,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 183758160...
Checkpoint 183758160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.45573
Policy Entropy: 1.27924
Value Function Loss: 0.32321

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06185
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.07195

Collected Steps per Second: 12,582.67985
Overall Steps per Second: 10,479.52175

Timestep Collection Time: 3.97372
Timestep Consumption Time: 0.79749
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.77121

Cumulative Model Updates: 11,014
Cumulative Timesteps: 183,808,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.43542
Policy Entropy: 1.27904
Value Function Loss: 0.32123

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05132
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.06839

Collected Steps per Second: 12,995.94133
Overall Steps per Second: 10,871.10170

Timestep Collection Time: 3.84766
Timestep Consumption Time: 0.75205
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.59972

Cumulative Model Updates: 11,017
Cumulative Timesteps: 183,858,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 183858164...
Checkpoint 183858164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.36829
Policy Entropy: 1.28370
Value Function Loss: 0.33640

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05650
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.07119

Collected Steps per Second: 11,463.36032
Overall Steps per Second: 9,659.70322

Timestep Collection Time: 4.36225
Timestep Consumption Time: 0.81452
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 5.17676

Cumulative Model Updates: 11,020
Cumulative Timesteps: 183,908,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.14824
Policy Entropy: 1.28401
Value Function Loss: 0.32562

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05321
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.06620

Collected Steps per Second: 12,423.04559
Overall Steps per Second: 10,619.72820

Timestep Collection Time: 4.02574
Timestep Consumption Time: 0.68360
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.70935

Cumulative Model Updates: 11,023
Cumulative Timesteps: 183,958,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 183958182...
Checkpoint 183958182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.83248
Policy Entropy: 1.28660
Value Function Loss: 0.34578

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06073
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.07122

Collected Steps per Second: 12,467.79384
Overall Steps per Second: 10,426.07993

Timestep Collection Time: 4.01162
Timestep Consumption Time: 0.78559
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.79720

Cumulative Model Updates: 11,026
Cumulative Timesteps: 184,008,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.86390
Policy Entropy: 1.28205
Value Function Loss: 0.35984

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05621
Policy Update Magnitude: 0.06524
Value Function Update Magnitude: 0.06800

Collected Steps per Second: 11,974.42471
Overall Steps per Second: 10,026.35733

Timestep Collection Time: 4.17674
Timestep Consumption Time: 0.81152
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.98825

Cumulative Model Updates: 11,029
Cumulative Timesteps: 184,058,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 184058212...
Checkpoint 184058212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.31782
Policy Entropy: 1.28612
Value Function Loss: 0.37663

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.07123

Collected Steps per Second: 12,292.46603
Overall Steps per Second: 10,357.11808

Timestep Collection Time: 4.06932
Timestep Consumption Time: 0.76040
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 4.82972

Cumulative Model Updates: 11,032
Cumulative Timesteps: 184,108,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.68749
Policy Entropy: 1.27406
Value Function Loss: 0.36611

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.06428

Collected Steps per Second: 12,344.03136
Overall Steps per Second: 10,350.86429

Timestep Collection Time: 4.05216
Timestep Consumption Time: 0.78029
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 4.83245

Cumulative Model Updates: 11,035
Cumulative Timesteps: 184,158,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 184158254...
Checkpoint 184158254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.25086
Policy Entropy: 1.28600
Value Function Loss: 0.35748

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05440
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.06698

Collected Steps per Second: 10,992.12731
Overall Steps per Second: 9,552.63537

Timestep Collection Time: 4.54926
Timestep Consumption Time: 0.68553
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.23479

Cumulative Model Updates: 11,038
Cumulative Timesteps: 184,208,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.22661
Policy Entropy: 1.27782
Value Function Loss: 0.33742

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.06827

Collected Steps per Second: 12,313.66593
Overall Steps per Second: 10,296.66014

Timestep Collection Time: 4.06134
Timestep Consumption Time: 0.79557
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 4.85691

Cumulative Model Updates: 11,041
Cumulative Timesteps: 184,258,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 184258270...
Checkpoint 184258270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.16482
Policy Entropy: 1.28091
Value Function Loss: 0.32546

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04306
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.06196

Collected Steps per Second: 12,454.88615
Overall Steps per Second: 10,530.44989

Timestep Collection Time: 4.01626
Timestep Consumption Time: 0.73397
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 4.75022

Cumulative Model Updates: 11,044
Cumulative Timesteps: 184,308,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.70610
Policy Entropy: 1.28513
Value Function Loss: 0.31112

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.05865

Collected Steps per Second: 12,957.95214
Overall Steps per Second: 10,698.07357

Timestep Collection Time: 3.86064
Timestep Consumption Time: 0.81553
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.67617

Cumulative Model Updates: 11,047
Cumulative Timesteps: 184,358,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 184358318...
Checkpoint 184358318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.04836
Policy Entropy: 1.27294
Value Function Loss: 0.32005

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.07634

Collected Steps per Second: 12,365.96034
Overall Steps per Second: 10,363.96706

Timestep Collection Time: 4.04514
Timestep Consumption Time: 0.78139
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.82653

Cumulative Model Updates: 11,050
Cumulative Timesteps: 184,408,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.44931
Policy Entropy: 1.28134
Value Function Loss: 0.34826

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06289
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.07974

Collected Steps per Second: 12,365.34818
Overall Steps per Second: 10,507.37864

Timestep Collection Time: 4.04550
Timestep Consumption Time: 0.71535
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 4.76084

Cumulative Model Updates: 11,053
Cumulative Timesteps: 184,458,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 184458364...
Checkpoint 184458364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.34092
Policy Entropy: 1.27302
Value Function Loss: 0.34304

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.07473
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 11,872.21735
Overall Steps per Second: 10,030.83856

Timestep Collection Time: 4.21404
Timestep Consumption Time: 0.77358
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.98762

Cumulative Model Updates: 11,056
Cumulative Timesteps: 184,508,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.05222
Policy Entropy: 1.27783
Value Function Loss: 0.34433

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.06546

Collected Steps per Second: 12,359.83663
Overall Steps per Second: 10,541.95103

Timestep Collection Time: 4.04746
Timestep Consumption Time: 0.69796
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 4.74542

Cumulative Model Updates: 11,059
Cumulative Timesteps: 184,558,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 184558420...
Checkpoint 184558420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.77429
Policy Entropy: 1.28183
Value Function Loss: 0.32942

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06361
Policy Update Magnitude: 0.07074
Value Function Update Magnitude: 0.05626

Collected Steps per Second: 12,313.51632
Overall Steps per Second: 10,301.62612

Timestep Collection Time: 4.06107
Timestep Consumption Time: 0.79312
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.85419

Cumulative Model Updates: 11,062
Cumulative Timesteps: 184,608,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.34461
Policy Entropy: 1.28383
Value Function Loss: 0.31980

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06454
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.04935

Collected Steps per Second: 12,291.56299
Overall Steps per Second: 10,379.83272

Timestep Collection Time: 4.06881
Timestep Consumption Time: 0.74938
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 4.81819

Cumulative Model Updates: 11,065
Cumulative Timesteps: 184,658,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 184658438...
Checkpoint 184658438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.46173
Policy Entropy: 1.27353
Value Function Loss: 0.33026

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07731
Policy Update Magnitude: 0.06736
Value Function Update Magnitude: 0.04616

Collected Steps per Second: 12,627.35914
Overall Steps per Second: 10,574.78673

Timestep Collection Time: 3.95997
Timestep Consumption Time: 0.76863
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.72861

Cumulative Model Updates: 11,068
Cumulative Timesteps: 184,708,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.73664
Policy Entropy: 1.28431
Value Function Loss: 0.32881

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.05572

Collected Steps per Second: 13,161.58434
Overall Steps per Second: 10,902.81415

Timestep Collection Time: 3.79909
Timestep Consumption Time: 0.78707
PPO Batch Consumption Time: 0.03354
Total Iteration Time: 4.58616

Cumulative Model Updates: 11,071
Cumulative Timesteps: 184,758,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 184758444...
Checkpoint 184758444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.16859
Policy Entropy: 1.27181
Value Function Loss: 0.31259

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.07768

Collected Steps per Second: 12,897.02165
Overall Steps per Second: 10,686.98562

Timestep Collection Time: 3.87919
Timestep Consumption Time: 0.80220
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 4.68139

Cumulative Model Updates: 11,074
Cumulative Timesteps: 184,808,474

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.04989
Policy Entropy: 1.28381
Value Function Loss: 0.30257

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.08961

Collected Steps per Second: 12,834.03851
Overall Steps per Second: 10,583.53386

Timestep Collection Time: 3.89667
Timestep Consumption Time: 0.82860
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.72526

Cumulative Model Updates: 11,077
Cumulative Timesteps: 184,858,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 184858484...
Checkpoint 184858484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.31981
Policy Entropy: 1.28503
Value Function Loss: 0.29353

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06505
Policy Update Magnitude: 0.06965
Value Function Update Magnitude: 0.07369

Collected Steps per Second: 13,138.30780
Overall Steps per Second: 10,916.17393

Timestep Collection Time: 3.80658
Timestep Consumption Time: 0.77488
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 4.58146

Cumulative Model Updates: 11,080
Cumulative Timesteps: 184,908,496

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.32655
Policy Entropy: 1.29473
Value Function Loss: 0.31731

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04118
Policy Update Magnitude: 0.07125
Value Function Update Magnitude: 0.05938

Collected Steps per Second: 13,386.96650
Overall Steps per Second: 11,086.80432

Timestep Collection Time: 3.73587
Timestep Consumption Time: 0.77508
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 4.51095

Cumulative Model Updates: 11,083
Cumulative Timesteps: 184,958,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 184958508...
Checkpoint 184958508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.82918
Policy Entropy: 1.28205
Value Function Loss: 0.29155

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.05307

Collected Steps per Second: 12,832.87778
Overall Steps per Second: 10,658.85239

Timestep Collection Time: 3.89780
Timestep Consumption Time: 0.79501
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.69281

Cumulative Model Updates: 11,086
Cumulative Timesteps: 185,008,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.47374
Policy Entropy: 1.28815
Value Function Loss: 0.28965

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04513
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.05094

Collected Steps per Second: 12,589.34651
Overall Steps per Second: 10,771.33610

Timestep Collection Time: 3.97352
Timestep Consumption Time: 0.67066
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 4.64418

Cumulative Model Updates: 11,089
Cumulative Timesteps: 185,058,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 185058552...
Checkpoint 185058552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.24529
Policy Entropy: 1.28279
Value Function Loss: 0.28010

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04047
Policy Update Magnitude: 0.06477
Value Function Update Magnitude: 0.04622

Collected Steps per Second: 12,420.50018
Overall Steps per Second: 10,358.98454

Timestep Collection Time: 4.02576
Timestep Consumption Time: 0.80116
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 4.82692

Cumulative Model Updates: 11,092
Cumulative Timesteps: 185,108,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.24120
Policy Entropy: 1.28434
Value Function Loss: 0.30124

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04324
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.04649

Collected Steps per Second: 11,788.80304
Overall Steps per Second: 9,984.66458

Timestep Collection Time: 4.24165
Timestep Consumption Time: 0.76643
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.00808

Cumulative Model Updates: 11,095
Cumulative Timesteps: 185,158,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 185158558...
Checkpoint 185158558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.38245
Policy Entropy: 1.27918
Value Function Loss: 0.31084

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05481
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.05063

Collected Steps per Second: 12,691.57999
Overall Steps per Second: 10,586.64908

Timestep Collection Time: 3.94183
Timestep Consumption Time: 0.78375
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.72557

Cumulative Model Updates: 11,098
Cumulative Timesteps: 185,208,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.73929
Policy Entropy: 1.28498
Value Function Loss: 0.32538

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06950
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.04921

Collected Steps per Second: 12,712.96123
Overall Steps per Second: 10,596.04029

Timestep Collection Time: 3.93472
Timestep Consumption Time: 0.78610
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 4.72082

Cumulative Model Updates: 11,101
Cumulative Timesteps: 185,258,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 185258608...
Checkpoint 185258608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.85326
Policy Entropy: 1.27839
Value Function Loss: 0.32598

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.05651

Collected Steps per Second: 12,529.21776
Overall Steps per Second: 10,578.70192

Timestep Collection Time: 3.99115
Timestep Consumption Time: 0.73589
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 4.72704

Cumulative Model Updates: 11,104
Cumulative Timesteps: 185,308,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.55173
Policy Entropy: 1.27843
Value Function Loss: 0.38273

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.05868

Collected Steps per Second: 12,357.79742
Overall Steps per Second: 10,336.83400

Timestep Collection Time: 4.04700
Timestep Consumption Time: 0.79123
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.83823

Cumulative Model Updates: 11,107
Cumulative Timesteps: 185,358,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 185358626...
Checkpoint 185358626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.02406
Policy Entropy: 1.27389
Value Function Loss: 0.35919

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.05937

Collected Steps per Second: 12,137.83689
Overall Steps per Second: 10,435.23209

Timestep Collection Time: 4.12083
Timestep Consumption Time: 0.67235
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.79319

Cumulative Model Updates: 11,110
Cumulative Timesteps: 185,408,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.04348
Policy Entropy: 1.28487
Value Function Loss: 0.37128

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.10705
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.05871

Collected Steps per Second: 11,572.71037
Overall Steps per Second: 9,830.79199

Timestep Collection Time: 4.32085
Timestep Consumption Time: 0.76561
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.08647

Cumulative Model Updates: 11,113
Cumulative Timesteps: 185,458,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 185458648...
Checkpoint 185458648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.21893
Policy Entropy: 1.28555
Value Function Loss: 0.30587

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.07154

Collected Steps per Second: 12,193.31331
Overall Steps per Second: 10,308.72488

Timestep Collection Time: 4.10225
Timestep Consumption Time: 0.74995
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.85220

Cumulative Model Updates: 11,116
Cumulative Timesteps: 185,508,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.58067
Policy Entropy: 1.29294
Value Function Loss: 0.30337

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.08792

Collected Steps per Second: 12,822.77189
Overall Steps per Second: 10,717.07079

Timestep Collection Time: 3.90165
Timestep Consumption Time: 0.76660
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.66825

Cumulative Model Updates: 11,119
Cumulative Timesteps: 185,558,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 185558698...
Checkpoint 185558698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.10600
Policy Entropy: 1.29340
Value Function Loss: 0.28266

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.05319
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.08882

Collected Steps per Second: 12,252.14218
Overall Steps per Second: 10,303.61738

Timestep Collection Time: 4.08174
Timestep Consumption Time: 0.77190
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.85364

Cumulative Model Updates: 11,122
Cumulative Timesteps: 185,608,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.06251
Policy Entropy: 1.29366
Value Function Loss: 0.32833

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05905
Policy Update Magnitude: 0.06184
Value Function Update Magnitude: 0.07570

Collected Steps per Second: 12,483.16962
Overall Steps per Second: 10,507.26544

Timestep Collection Time: 4.00555
Timestep Consumption Time: 0.75325
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 4.75880

Cumulative Model Updates: 11,125
Cumulative Timesteps: 185,658,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 185658710...
Checkpoint 185658710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.77047
Policy Entropy: 1.29611
Value Function Loss: 0.34365

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06467
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.06927

Collected Steps per Second: 12,436.34003
Overall Steps per Second: 10,440.77877

Timestep Collection Time: 4.02160
Timestep Consumption Time: 0.76865
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 4.79026

Cumulative Model Updates: 11,128
Cumulative Timesteps: 185,708,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.55764
Policy Entropy: 1.29362
Value Function Loss: 0.33103

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04939
Policy Update Magnitude: 0.05900
Value Function Update Magnitude: 0.07593

Collected Steps per Second: 12,246.48272
Overall Steps per Second: 10,228.16278

Timestep Collection Time: 4.08509
Timestep Consumption Time: 0.80611
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.89120

Cumulative Model Updates: 11,131
Cumulative Timesteps: 185,758,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 185758752...
Checkpoint 185758752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.52622
Policy Entropy: 1.29628
Value Function Loss: 0.30156

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04462
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.07392

Collected Steps per Second: 12,250.53068
Overall Steps per Second: 10,218.46929

Timestep Collection Time: 4.08162
Timestep Consumption Time: 0.81168
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.89330

Cumulative Model Updates: 11,134
Cumulative Timesteps: 185,808,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.14320
Policy Entropy: 1.29246
Value Function Loss: 0.28556

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05027
Policy Update Magnitude: 0.06599
Value Function Update Magnitude: 0.08352

Collected Steps per Second: 12,784.95057
Overall Steps per Second: 10,612.89028

Timestep Collection Time: 3.91257
Timestep Consumption Time: 0.80076
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.71332

Cumulative Model Updates: 11,137
Cumulative Timesteps: 185,858,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 185858776...
Checkpoint 185858776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.86846
Policy Entropy: 1.28833
Value Function Loss: 0.27777

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05465
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.09460

Collected Steps per Second: 12,513.15827
Overall Steps per Second: 10,542.07310

Timestep Collection Time: 3.99739
Timestep Consumption Time: 0.74741
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.74480

Cumulative Model Updates: 11,140
Cumulative Timesteps: 185,908,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.65061
Policy Entropy: 1.29128
Value Function Loss: 0.27239

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.06175
Value Function Update Magnitude: 0.10394

Collected Steps per Second: 12,312.46139
Overall Steps per Second: 10,393.77148

Timestep Collection Time: 4.06206
Timestep Consumption Time: 0.74986
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 4.81192

Cumulative Model Updates: 11,143
Cumulative Timesteps: 185,958,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 185958810...
Checkpoint 185958810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.74663
Policy Entropy: 1.29079
Value Function Loss: 0.28714

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06997
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.09730

Collected Steps per Second: 10,188.34654
Overall Steps per Second: 8,753.61002

Timestep Collection Time: 4.91032
Timestep Consumption Time: 0.80481
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.71513

Cumulative Model Updates: 11,146
Cumulative Timesteps: 186,008,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.01438
Policy Entropy: 1.28235
Value Function Loss: 0.30734

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.08108

Collected Steps per Second: 12,396.06563
Overall Steps per Second: 10,213.57049

Timestep Collection Time: 4.03370
Timestep Consumption Time: 0.86194
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.89564

Cumulative Model Updates: 11,149
Cumulative Timesteps: 186,058,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 186058840...
Checkpoint 186058840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.24422
Policy Entropy: 1.28520
Value Function Loss: 0.31319

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.04529
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.07104

Collected Steps per Second: 12,491.26625
Overall Steps per Second: 10,390.63903

Timestep Collection Time: 4.00344
Timestep Consumption Time: 0.80936
PPO Batch Consumption Time: 0.03769
Total Iteration Time: 4.81279

Cumulative Model Updates: 11,152
Cumulative Timesteps: 186,108,848

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.03275
Policy Entropy: 1.28305
Value Function Loss: 0.30218

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05382
Policy Update Magnitude: 0.06318
Value Function Update Magnitude: 0.07179

Collected Steps per Second: 12,383.01580
Overall Steps per Second: 10,637.99107

Timestep Collection Time: 4.03924
Timestep Consumption Time: 0.66259
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.70183

Cumulative Model Updates: 11,155
Cumulative Timesteps: 186,158,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 186158866...
Checkpoint 186158866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.04143
Policy Entropy: 1.28176
Value Function Loss: 0.30071

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05645
Policy Update Magnitude: 0.06807
Value Function Update Magnitude: 0.08689

Collected Steps per Second: 11,855.83858
Overall Steps per Second: 10,013.56502

Timestep Collection Time: 4.21919
Timestep Consumption Time: 0.77624
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.99542

Cumulative Model Updates: 11,158
Cumulative Timesteps: 186,208,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.99221
Policy Entropy: 1.27982
Value Function Loss: 0.30695

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04643
Policy Update Magnitude: 0.06943
Value Function Update Magnitude: 0.08212

Collected Steps per Second: 12,660.91976
Overall Steps per Second: 10,656.42831

Timestep Collection Time: 3.94995
Timestep Consumption Time: 0.74299
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.69294

Cumulative Model Updates: 11,161
Cumulative Timesteps: 186,258,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 186258898...
Checkpoint 186258898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.24443
Policy Entropy: 1.28215
Value Function Loss: 0.32947

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.05365
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.07861

Collected Steps per Second: 12,833.67392
Overall Steps per Second: 10,730.18145

Timestep Collection Time: 3.89834
Timestep Consumption Time: 0.76421
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 4.66255

Cumulative Model Updates: 11,164
Cumulative Timesteps: 186,308,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.41365
Policy Entropy: 1.27722
Value Function Loss: 0.32535

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07235
Policy Update Magnitude: 0.06725
Value Function Update Magnitude: 0.08255

Collected Steps per Second: 12,406.14696
Overall Steps per Second: 10,416.15717

Timestep Collection Time: 4.03219
Timestep Consumption Time: 0.77034
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 4.80254

Cumulative Model Updates: 11,167
Cumulative Timesteps: 186,358,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 186358952...
Checkpoint 186358952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.93023
Policy Entropy: 1.27803
Value Function Loss: 0.33340

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05731
Policy Update Magnitude: 0.06080
Value Function Update Magnitude: 0.08530

Collected Steps per Second: 11,962.00312
Overall Steps per Second: 10,109.69008

Timestep Collection Time: 4.18141
Timestep Consumption Time: 0.76612
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 4.94753

Cumulative Model Updates: 11,170
Cumulative Timesteps: 186,408,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.38380
Policy Entropy: 1.27927
Value Function Loss: 0.30980

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06855
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.07889

Collected Steps per Second: 12,819.03453
Overall Steps per Second: 10,609.23469

Timestep Collection Time: 3.90263
Timestep Consumption Time: 0.81288
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 4.71551

Cumulative Model Updates: 11,173
Cumulative Timesteps: 186,458,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 186458998...
Checkpoint 186458998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.55481
Policy Entropy: 1.27859
Value Function Loss: 0.28790

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05925
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.07674

Collected Steps per Second: 12,596.87497
Overall Steps per Second: 10,382.68069

Timestep Collection Time: 3.97035
Timestep Consumption Time: 0.84671
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 4.81706

Cumulative Model Updates: 11,176
Cumulative Timesteps: 186,509,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.28634
Policy Entropy: 1.27625
Value Function Loss: 0.27631

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06383
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.06957

Collected Steps per Second: 12,504.07060
Overall Steps per Second: 10,536.35772

Timestep Collection Time: 4.00126
Timestep Consumption Time: 0.74725
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.74851

Cumulative Model Updates: 11,179
Cumulative Timesteps: 186,559,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 186559044...
Checkpoint 186559044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.14693
Policy Entropy: 1.27587
Value Function Loss: 0.27525

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04980
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.06338

Collected Steps per Second: 12,290.05654
Overall Steps per Second: 10,306.13689

Timestep Collection Time: 4.07012
Timestep Consumption Time: 0.78349
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.85361

Cumulative Model Updates: 11,182
Cumulative Timesteps: 186,609,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.39719
Policy Entropy: 1.27830
Value Function Loss: 0.29677

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07109
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.06228

Collected Steps per Second: 12,508.65898
Overall Steps per Second: 10,735.56203

Timestep Collection Time: 3.99787
Timestep Consumption Time: 0.66029
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.65816

Cumulative Model Updates: 11,185
Cumulative Timesteps: 186,659,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 186659074...
Checkpoint 186659074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.65697
Policy Entropy: 1.28090
Value Function Loss: 0.29260

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.06282

Collected Steps per Second: 11,822.78472
Overall Steps per Second: 10,044.28102

Timestep Collection Time: 4.23098
Timestep Consumption Time: 0.74916
PPO Batch Consumption Time: 0.03804
Total Iteration Time: 4.98015

Cumulative Model Updates: 11,188
Cumulative Timesteps: 186,709,096

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.33560
Policy Entropy: 1.27858
Value Function Loss: 0.30711

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06806
Policy Update Magnitude: 0.03978
Value Function Update Magnitude: 0.08494

Collected Steps per Second: 12,476.85842
Overall Steps per Second: 10,395.35212

Timestep Collection Time: 4.00950
Timestep Consumption Time: 0.80284
PPO Batch Consumption Time: 0.03822
Total Iteration Time: 4.81234

Cumulative Model Updates: 11,191
Cumulative Timesteps: 186,759,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 186759122...
Checkpoint 186759122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.93866
Policy Entropy: 1.27798
Value Function Loss: 0.31533

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.03801
Value Function Update Magnitude: 0.07378

Collected Steps per Second: 12,621.01817
Overall Steps per Second: 10,603.07956

Timestep Collection Time: 3.96402
Timestep Consumption Time: 0.75442
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 4.71844

Cumulative Model Updates: 11,194
Cumulative Timesteps: 186,809,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.19184
Policy Entropy: 1.28155
Value Function Loss: 0.31405

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.03709
Value Function Update Magnitude: 0.05841

Collected Steps per Second: 12,376.81549
Overall Steps per Second: 10,454.29339

Timestep Collection Time: 4.04143
Timestep Consumption Time: 0.74321
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.78464

Cumulative Model Updates: 11,197
Cumulative Timesteps: 186,859,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 186859172...
Checkpoint 186859172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.11480
Policy Entropy: 1.28342
Value Function Loss: 0.32610

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.03619
Value Function Update Magnitude: 0.05643

Collected Steps per Second: 12,290.36149
Overall Steps per Second: 10,429.52929

Timestep Collection Time: 4.07051
Timestep Consumption Time: 0.72626
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 4.79676

Cumulative Model Updates: 11,200
Cumulative Timesteps: 186,909,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.12931
Policy Entropy: 1.27568
Value Function Loss: 0.30710

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.03740
Value Function Update Magnitude: 0.06469

Collected Steps per Second: 12,651.51631
Overall Steps per Second: 10,470.85280

Timestep Collection Time: 3.95352
Timestep Consumption Time: 0.82336
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 4.77688

Cumulative Model Updates: 11,203
Cumulative Timesteps: 186,959,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 186959218...
Checkpoint 186959218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.38159
Policy Entropy: 1.27876
Value Function Loss: 0.33853

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.03590
Value Function Update Magnitude: 0.06571

Collected Steps per Second: 11,976.82708
Overall Steps per Second: 10,080.68803

Timestep Collection Time: 4.17606
Timestep Consumption Time: 0.78550
PPO Batch Consumption Time: 0.03320
Total Iteration Time: 4.96157

Cumulative Model Updates: 11,206
Cumulative Timesteps: 187,009,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.59777
Policy Entropy: 1.27433
Value Function Loss: 0.34355

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.03739
Value Function Update Magnitude: 0.06202

Collected Steps per Second: 12,409.76003
Overall Steps per Second: 10,549.18096

Timestep Collection Time: 4.03118
Timestep Consumption Time: 0.71099
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.74217

Cumulative Model Updates: 11,209
Cumulative Timesteps: 187,059,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 187059260...
Checkpoint 187059260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.76788
Policy Entropy: 1.27866
Value Function Loss: 0.35805

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.03591
Value Function Update Magnitude: 0.07421

Collected Steps per Second: 12,417.40417
Overall Steps per Second: 10,437.18867

Timestep Collection Time: 4.02693
Timestep Consumption Time: 0.76402
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.79095

Cumulative Model Updates: 11,212
Cumulative Timesteps: 187,109,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.93968
Policy Entropy: 1.27868
Value Function Loss: 0.33448

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.03711
Value Function Update Magnitude: 0.08501

Collected Steps per Second: 12,543.74761
Overall Steps per Second: 10,639.95783

Timestep Collection Time: 3.98685
Timestep Consumption Time: 0.71336
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.70021

Cumulative Model Updates: 11,215
Cumulative Timesteps: 187,159,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 187159274...
Checkpoint 187159274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.00577
Policy Entropy: 1.28118
Value Function Loss: 0.32264

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.03642
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 12,454.90600
Overall Steps per Second: 10,411.29031

Timestep Collection Time: 4.01545
Timestep Consumption Time: 0.78819
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.80363

Cumulative Model Updates: 11,218
Cumulative Timesteps: 187,209,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.64414
Policy Entropy: 1.27950
Value Function Loss: 0.32468

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.04160
Value Function Update Magnitude: 0.06547

Collected Steps per Second: 12,962.64523
Overall Steps per Second: 10,876.39678

Timestep Collection Time: 3.85724
Timestep Consumption Time: 0.73987
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 4.59711

Cumulative Model Updates: 11,221
Cumulative Timesteps: 187,259,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 187259286...
Checkpoint 187259286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.58453
Policy Entropy: 1.27962
Value Function Loss: 0.31012

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.04218
Value Function Update Magnitude: 0.06083

Collected Steps per Second: 13,048.49332
Overall Steps per Second: 10,596.72587

Timestep Collection Time: 3.83324
Timestep Consumption Time: 0.88690
PPO Batch Consumption Time: 0.03362
Total Iteration Time: 4.72014

Cumulative Model Updates: 11,224
Cumulative Timesteps: 187,309,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.90893
Policy Entropy: 1.28051
Value Function Loss: 0.29947

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.04056
Value Function Update Magnitude: 0.05569

Collected Steps per Second: 12,564.66200
Overall Steps per Second: 10,479.46200

Timestep Collection Time: 3.97973
Timestep Consumption Time: 0.79189
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 4.77162

Cumulative Model Updates: 11,227
Cumulative Timesteps: 187,359,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 187359308...
Checkpoint 187359308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.92144
Policy Entropy: 1.28142
Value Function Loss: 0.27337

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.03816
Value Function Update Magnitude: 0.04911

Collected Steps per Second: 12,833.05298
Overall Steps per Second: 10,868.78444

Timestep Collection Time: 3.89681
Timestep Consumption Time: 0.70425
PPO Batch Consumption Time: 0.03317
Total Iteration Time: 4.60107

Cumulative Model Updates: 11,230
Cumulative Timesteps: 187,409,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.93045
Policy Entropy: 1.27808
Value Function Loss: 0.28560

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.03754
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 13,128.20788
Overall Steps per Second: 10,726.18245

Timestep Collection Time: 3.80981
Timestep Consumption Time: 0.85317
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.66298

Cumulative Model Updates: 11,233
Cumulative Timesteps: 187,459,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 187459332...
Checkpoint 187459332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.24278
Policy Entropy: 1.27886
Value Function Loss: 0.29082

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.03562
Value Function Update Magnitude: 0.05579

Collected Steps per Second: 13,048.48795
Overall Steps per Second: 10,875.13652

Timestep Collection Time: 3.83370
Timestep Consumption Time: 0.76615
PPO Batch Consumption Time: 0.03819
Total Iteration Time: 4.59985

Cumulative Model Updates: 11,236
Cumulative Timesteps: 187,509,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.20337
Policy Entropy: 1.28299
Value Function Loss: 0.31834

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.03750
Value Function Update Magnitude: 0.05757

Collected Steps per Second: 12,474.58616
Overall Steps per Second: 10,397.92632

Timestep Collection Time: 4.00879
Timestep Consumption Time: 0.80063
PPO Batch Consumption Time: 0.03865
Total Iteration Time: 4.80942

Cumulative Model Updates: 11,239
Cumulative Timesteps: 187,559,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 187559364...
Checkpoint 187559364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.37719
Policy Entropy: 1.28286
Value Function Loss: 0.34377

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.03886
Value Function Update Magnitude: 0.06175

Collected Steps per Second: 12,353.09738
Overall Steps per Second: 10,326.84998

Timestep Collection Time: 4.04967
Timestep Consumption Time: 0.79459
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 4.84427

Cumulative Model Updates: 11,242
Cumulative Timesteps: 187,609,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.63283
Policy Entropy: 1.28151
Value Function Loss: 0.35063

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.03834
Value Function Update Magnitude: 0.06395

Collected Steps per Second: 11,869.27062
Overall Steps per Second: 10,197.55303

Timestep Collection Time: 4.21492
Timestep Consumption Time: 0.69097
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.90588

Cumulative Model Updates: 11,245
Cumulative Timesteps: 187,659,418

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 187659418...
Checkpoint 187659418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.15361
Policy Entropy: 1.28136
Value Function Loss: 0.33359

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.03683
Value Function Update Magnitude: 0.06987

Collected Steps per Second: 12,427.99998
Overall Steps per Second: 10,334.92163

Timestep Collection Time: 4.02446
Timestep Consumption Time: 0.81505
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.83951

Cumulative Model Updates: 11,248
Cumulative Timesteps: 187,709,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.25873
Policy Entropy: 1.27950
Value Function Loss: 0.32424

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.03736
Value Function Update Magnitude: 0.07810

Collected Steps per Second: 12,760.94338
Overall Steps per Second: 10,700.59243

Timestep Collection Time: 3.91868
Timestep Consumption Time: 0.75452
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 4.67320

Cumulative Model Updates: 11,251
Cumulative Timesteps: 187,759,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 187759440...
Checkpoint 187759440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.78317
Policy Entropy: 1.28669
Value Function Loss: 0.32462

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.03634
Value Function Update Magnitude: 0.08440

Collected Steps per Second: 12,548.89379
Overall Steps per Second: 10,544.46458

Timestep Collection Time: 3.98473
Timestep Consumption Time: 0.75747
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 4.74220

Cumulative Model Updates: 11,254
Cumulative Timesteps: 187,809,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.58537
Policy Entropy: 1.28482
Value Function Loss: 0.32495

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07904
Policy Update Magnitude: 0.03743
Value Function Update Magnitude: 0.08269

Collected Steps per Second: 12,448.37590
Overall Steps per Second: 10,541.07663

Timestep Collection Time: 4.01755
Timestep Consumption Time: 0.72693
PPO Batch Consumption Time: 0.03329
Total Iteration Time: 4.74449

Cumulative Model Updates: 11,257
Cumulative Timesteps: 187,859,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 187859456...
Checkpoint 187859456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.40862
Policy Entropy: 1.29022
Value Function Loss: 0.33990

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06889
Policy Update Magnitude: 0.03951
Value Function Update Magnitude: 0.09097

Collected Steps per Second: 12,446.86525
Overall Steps per Second: 10,649.37810

Timestep Collection Time: 4.01900
Timestep Consumption Time: 0.67836
PPO Batch Consumption Time: 0.03299
Total Iteration Time: 4.69736

Cumulative Model Updates: 11,260
Cumulative Timesteps: 187,909,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.81250
Policy Entropy: 1.28850
Value Function Loss: 0.30702

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.06831
Policy Update Magnitude: 0.03972
Value Function Update Magnitude: 0.10382

Collected Steps per Second: 11,889.50204
Overall Steps per Second: 9,985.80915

Timestep Collection Time: 4.20657
Timestep Consumption Time: 0.80194
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.00851

Cumulative Model Updates: 11,263
Cumulative Timesteps: 187,959,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 187959494...
Checkpoint 187959494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.99559
Policy Entropy: 1.28809
Value Function Loss: 0.33626

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06500
Policy Update Magnitude: 0.04005
Value Function Update Magnitude: 0.10039

Collected Steps per Second: 12,631.72563
Overall Steps per Second: 10,639.51435

Timestep Collection Time: 3.95845
Timestep Consumption Time: 0.74120
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 4.69965

Cumulative Model Updates: 11,266
Cumulative Timesteps: 188,009,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.55084
Policy Entropy: 1.28857
Value Function Loss: 0.32853

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.09316

Collected Steps per Second: 12,855.19128
Overall Steps per Second: 10,723.74519

Timestep Collection Time: 3.89150
Timestep Consumption Time: 0.77347
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 4.66497

Cumulative Model Updates: 11,269
Cumulative Timesteps: 188,059,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 188059522...
Checkpoint 188059522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.35657
Policy Entropy: 1.28882
Value Function Loss: 0.36955

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.04051
Value Function Update Magnitude: 0.08694

Collected Steps per Second: 12,389.54331
Overall Steps per Second: 10,387.40614

Timestep Collection Time: 4.03711
Timestep Consumption Time: 0.77814
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 4.81525

Cumulative Model Updates: 11,272
Cumulative Timesteps: 188,109,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.30002
Policy Entropy: 1.28927
Value Function Loss: 0.35392

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06628
Policy Update Magnitude: 0.04174
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 12,289.08371
Overall Steps per Second: 10,525.70247

Timestep Collection Time: 4.07044
Timestep Consumption Time: 0.68193
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 4.75237

Cumulative Model Updates: 11,275
Cumulative Timesteps: 188,159,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 188159562...
Checkpoint 188159562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.33705
Policy Entropy: 1.28493
Value Function Loss: 0.36551

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.08684

Collected Steps per Second: 12,439.98734
Overall Steps per Second: 10,460.59706

Timestep Collection Time: 4.02155
Timestep Consumption Time: 0.76097
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 4.78252

Cumulative Model Updates: 11,278
Cumulative Timesteps: 188,209,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.02158
Policy Entropy: 1.28620
Value Function Loss: 0.33307

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07325
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.08419

Collected Steps per Second: 11,965.55047
Overall Steps per Second: 10,109.93493

Timestep Collection Time: 4.18100
Timestep Consumption Time: 0.76740
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.94840

Cumulative Model Updates: 11,281
Cumulative Timesteps: 188,259,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 188259618...
Checkpoint 188259618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.85925
Policy Entropy: 1.28652
Value Function Loss: 0.36655

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07639
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.07161

Collected Steps per Second: 12,536.96241
Overall Steps per Second: 10,500.30707

Timestep Collection Time: 3.98932
Timestep Consumption Time: 0.77378
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.76310

Cumulative Model Updates: 11,284
Cumulative Timesteps: 188,309,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.09615
Policy Entropy: 1.28889
Value Function Loss: 0.36198

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.07192

Collected Steps per Second: 12,250.99488
Overall Steps per Second: 10,298.42364

Timestep Collection Time: 4.08195
Timestep Consumption Time: 0.77393
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.85589

Cumulative Model Updates: 11,287
Cumulative Timesteps: 188,359,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 188359640...
Checkpoint 188359640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.18051
Policy Entropy: 1.28632
Value Function Loss: 0.41463

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.03946
Value Function Update Magnitude: 0.09130

Collected Steps per Second: 12,446.29465
Overall Steps per Second: 10,670.46964

Timestep Collection Time: 4.01838
Timestep Consumption Time: 0.66876
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.68714

Cumulative Model Updates: 11,290
Cumulative Timesteps: 188,409,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.43520
Policy Entropy: 1.28905
Value Function Loss: 0.40055

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06451
Policy Update Magnitude: 0.04266
Value Function Update Magnitude: 0.09756

Collected Steps per Second: 12,775.57729
Overall Steps per Second: 10,599.27966

Timestep Collection Time: 3.91575
Timestep Consumption Time: 0.80400
PPO Batch Consumption Time: 0.03342
Total Iteration Time: 4.71975

Cumulative Model Updates: 11,293
Cumulative Timesteps: 188,459,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 188459680...
Checkpoint 188459680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.93568
Policy Entropy: 1.28525
Value Function Loss: 0.38641

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.09413

Collected Steps per Second: 12,585.07080
Overall Steps per Second: 10,670.12279

Timestep Collection Time: 3.97503
Timestep Consumption Time: 0.71339
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.68842

Cumulative Model Updates: 11,296
Cumulative Timesteps: 188,509,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.18239
Policy Entropy: 1.28915
Value Function Loss: 0.34636

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.07964

Collected Steps per Second: 11,123.32163
Overall Steps per Second: 9,282.77302

Timestep Collection Time: 4.49740
Timestep Consumption Time: 0.89172
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.38912

Cumulative Model Updates: 11,299
Cumulative Timesteps: 188,559,732

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 188559732...
Checkpoint 188559732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.16801
Policy Entropy: 1.28442
Value Function Loss: 0.35024

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.04261
Value Function Update Magnitude: 0.07444

Collected Steps per Second: 11,908.68358
Overall Steps per Second: 10,109.34767

Timestep Collection Time: 4.19979
Timestep Consumption Time: 0.74751
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 4.94730

Cumulative Model Updates: 11,302
Cumulative Timesteps: 188,609,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.63655
Policy Entropy: 1.28932
Value Function Loss: 0.38684

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.06679

Collected Steps per Second: 11,898.89490
Overall Steps per Second: 10,059.16965

Timestep Collection Time: 4.20207
Timestep Consumption Time: 0.76852
PPO Batch Consumption Time: 0.03347
Total Iteration Time: 4.97059

Cumulative Model Updates: 11,305
Cumulative Timesteps: 188,659,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 188659746...
Checkpoint 188659746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.14967
Policy Entropy: 1.28791
Value Function Loss: 0.39198

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07195
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.06483

Collected Steps per Second: 11,672.74719
Overall Steps per Second: 9,925.17719

Timestep Collection Time: 4.28485
Timestep Consumption Time: 0.75445
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.03931

Cumulative Model Updates: 11,308
Cumulative Timesteps: 188,709,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.61013
Policy Entropy: 1.29195
Value Function Loss: 0.38698

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06614
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.07064

Collected Steps per Second: 11,777.62653
Overall Steps per Second: 10,077.19233

Timestep Collection Time: 4.24738
Timestep Consumption Time: 0.71671
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 4.96408

Cumulative Model Updates: 11,311
Cumulative Timesteps: 188,759,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 188759786...
Checkpoint 188759786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.65857
Policy Entropy: 1.29123
Value Function Loss: 0.39328

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06749
Policy Update Magnitude: 0.04144
Value Function Update Magnitude: 0.06639

Collected Steps per Second: 11,360.37169
Overall Steps per Second: 9,659.22210

Timestep Collection Time: 4.40320
Timestep Consumption Time: 0.77548
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.17868

Cumulative Model Updates: 11,314
Cumulative Timesteps: 188,809,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.49055
Policy Entropy: 1.29269
Value Function Loss: 0.38396

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.07235

Collected Steps per Second: 11,174.76893
Overall Steps per Second: 9,586.23723

Timestep Collection Time: 4.47472
Timestep Consumption Time: 0.74150
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.21623

Cumulative Model Updates: 11,317
Cumulative Timesteps: 188,859,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 188859812...
Checkpoint 188859812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.40668
Policy Entropy: 1.29078
Value Function Loss: 0.36463

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.08986

Collected Steps per Second: 11,359.23796
Overall Steps per Second: 9,682.81211

Timestep Collection Time: 4.40294
Timestep Consumption Time: 0.76230
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.16524

Cumulative Model Updates: 11,320
Cumulative Timesteps: 188,909,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.83878
Policy Entropy: 1.29375
Value Function Loss: 0.32774

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06529
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.08816

Collected Steps per Second: 11,666.01278
Overall Steps per Second: 9,956.58855

Timestep Collection Time: 4.28818
Timestep Consumption Time: 0.73623
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.02441

Cumulative Model Updates: 11,323
Cumulative Timesteps: 188,959,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 188959852...
Checkpoint 188959852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.82797
Policy Entropy: 1.29127
Value Function Loss: 0.32934

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.07801

Collected Steps per Second: 11,718.90102
Overall Steps per Second: 9,816.34932

Timestep Collection Time: 4.26798
Timestep Consumption Time: 0.82720
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 5.09517

Cumulative Model Updates: 11,326
Cumulative Timesteps: 189,009,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.31497
Policy Entropy: 1.29256
Value Function Loss: 0.32889

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.03800
Value Function Update Magnitude: 0.07566

Collected Steps per Second: 11,308.72619
Overall Steps per Second: 9,585.50252

Timestep Collection Time: 4.42313
Timestep Consumption Time: 0.79516
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 5.21830

Cumulative Model Updates: 11,329
Cumulative Timesteps: 189,059,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 189059888...
Checkpoint 189059888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.58342
Policy Entropy: 1.29223
Value Function Loss: 0.32113

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06615
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.06709

Collected Steps per Second: 10,630.56766
Overall Steps per Second: 9,229.03694

Timestep Collection Time: 4.70398
Timestep Consumption Time: 0.71435
PPO Batch Consumption Time: 0.03889
Total Iteration Time: 5.41833

Cumulative Model Updates: 11,332
Cumulative Timesteps: 189,109,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.14126
Policy Entropy: 1.28896
Value Function Loss: 0.34351

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06724
Policy Update Magnitude: 0.04057
Value Function Update Magnitude: 0.06335

Collected Steps per Second: 10,971.86921
Overall Steps per Second: 9,420.00542

Timestep Collection Time: 4.55875
Timestep Consumption Time: 0.75101
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 5.30976

Cumulative Model Updates: 11,335
Cumulative Timesteps: 189,159,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 189159912...
Checkpoint 189159912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.28325
Policy Entropy: 1.28857
Value Function Loss: 0.32550

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06961
Policy Update Magnitude: 0.03946
Value Function Update Magnitude: 0.05214

Collected Steps per Second: 12,438.85723
Overall Steps per Second: 10,518.28456

Timestep Collection Time: 4.02159
Timestep Consumption Time: 0.73432
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 4.75591

Cumulative Model Updates: 11,338
Cumulative Timesteps: 189,209,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.86628
Policy Entropy: 1.28909
Value Function Loss: 0.33951

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.04196
Value Function Update Magnitude: 0.04994

Collected Steps per Second: 12,731.78302
Overall Steps per Second: 10,722.27571

Timestep Collection Time: 3.92734
Timestep Consumption Time: 0.73604
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.66338

Cumulative Model Updates: 11,341
Cumulative Timesteps: 189,259,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 189259938...
Checkpoint 189259938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.30410
Policy Entropy: 1.28720
Value Function Loss: 0.30231

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.04022
Value Function Update Magnitude: 0.05531

Collected Steps per Second: 12,463.19748
Overall Steps per Second: 10,566.10363

Timestep Collection Time: 4.01229
Timestep Consumption Time: 0.72039
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.73268

Cumulative Model Updates: 11,344
Cumulative Timesteps: 189,309,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.36627
Policy Entropy: 1.29066
Value Function Loss: 0.33179

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.03609
Value Function Update Magnitude: 0.06179

Collected Steps per Second: 12,222.11173
Overall Steps per Second: 10,392.44077

Timestep Collection Time: 4.09193
Timestep Consumption Time: 0.72042
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.81234

Cumulative Model Updates: 11,347
Cumulative Timesteps: 189,359,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 189359956...
Checkpoint 189359956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.83885
Policy Entropy: 1.28693
Value Function Loss: 0.30450

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.04177
Value Function Update Magnitude: 0.05665

Collected Steps per Second: 12,286.73738
Overall Steps per Second: 10,254.41378

Timestep Collection Time: 4.07057
Timestep Consumption Time: 0.80675
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 4.87731

Cumulative Model Updates: 11,350
Cumulative Timesteps: 189,409,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.44555
Policy Entropy: 1.28840
Value Function Loss: 0.31602

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.03961
Value Function Update Magnitude: 0.06375

Collected Steps per Second: 11,923.56305
Overall Steps per Second: 9,932.14602

Timestep Collection Time: 4.19522
Timestep Consumption Time: 0.84115
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.03637

Cumulative Model Updates: 11,353
Cumulative Timesteps: 189,459,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 189459992...
Checkpoint 189459992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.18774
Policy Entropy: 1.29002
Value Function Loss: 0.31291

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.03706
Value Function Update Magnitude: 0.05547

Collected Steps per Second: 12,743.97258
Overall Steps per Second: 10,603.73619

Timestep Collection Time: 3.92562
Timestep Consumption Time: 0.79234
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 4.71796

Cumulative Model Updates: 11,356
Cumulative Timesteps: 189,510,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.62230
Policy Entropy: 1.28858
Value Function Loss: 0.32672

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07116
Policy Update Magnitude: 0.03944
Value Function Update Magnitude: 0.05341

Collected Steps per Second: 12,550.35390
Overall Steps per Second: 10,519.63837

Timestep Collection Time: 3.98395
Timestep Consumption Time: 0.76906
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 4.75302

Cumulative Model Updates: 11,359
Cumulative Timesteps: 189,560,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 189560020...
Checkpoint 189560020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.33825
Policy Entropy: 1.28567
Value Function Loss: 0.33219

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.03816
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 12,500.67675
Overall Steps per Second: 10,575.26820

Timestep Collection Time: 4.00074
Timestep Consumption Time: 0.72840
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 4.72915

Cumulative Model Updates: 11,362
Cumulative Timesteps: 189,610,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.92562
Policy Entropy: 1.28673
Value Function Loss: 0.32009

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.06687
Policy Update Magnitude: 0.03803
Value Function Update Magnitude: 0.05469

Collected Steps per Second: 12,422.51263
Overall Steps per Second: 10,434.36648

Timestep Collection Time: 4.02720
Timestep Consumption Time: 0.76734
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.79454

Cumulative Model Updates: 11,365
Cumulative Timesteps: 189,660,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 189660060...
Checkpoint 189660060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.20561
Policy Entropy: 1.28692
Value Function Loss: 0.33344

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.03817
Value Function Update Magnitude: 0.05726

Collected Steps per Second: 12,932.46952
Overall Steps per Second: 10,813.89029

Timestep Collection Time: 3.86840
Timestep Consumption Time: 0.75787
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.62627

Cumulative Model Updates: 11,368
Cumulative Timesteps: 189,710,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.36108
Policy Entropy: 1.28587
Value Function Loss: 0.34658

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06208
Policy Update Magnitude: 0.04002
Value Function Update Magnitude: 0.06798

Collected Steps per Second: 13,142.72615
Overall Steps per Second: 10,889.02271

Timestep Collection Time: 3.80652
Timestep Consumption Time: 0.78784
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.59435

Cumulative Model Updates: 11,371
Cumulative Timesteps: 189,760,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 189760116...
Checkpoint 189760116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.15885
Policy Entropy: 1.28636
Value Function Loss: 0.34804

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07116
Policy Update Magnitude: 0.04048
Value Function Update Magnitude: 0.08896

Collected Steps per Second: 12,316.07295
Overall Steps per Second: 10,383.83854

Timestep Collection Time: 4.06152
Timestep Consumption Time: 0.75577
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 4.81729

Cumulative Model Updates: 11,374
Cumulative Timesteps: 189,810,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.65335
Policy Entropy: 1.28181
Value Function Loss: 0.33670

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.09097

Collected Steps per Second: 13,198.48842
Overall Steps per Second: 11,046.64632

Timestep Collection Time: 3.78831
Timestep Consumption Time: 0.73795
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 4.52626

Cumulative Model Updates: 11,377
Cumulative Timesteps: 189,860,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 189860138...
Checkpoint 189860138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.01035
Policy Entropy: 1.28828
Value Function Loss: 0.31762

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 13,281.09888
Overall Steps per Second: 10,928.60719

Timestep Collection Time: 3.76656
Timestep Consumption Time: 0.81079
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 4.57734

Cumulative Model Updates: 11,380
Cumulative Timesteps: 189,910,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.94063
Policy Entropy: 1.28550
Value Function Loss: 0.30864

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.06325

Collected Steps per Second: 13,131.22386
Overall Steps per Second: 10,879.98466

Timestep Collection Time: 3.80955
Timestep Consumption Time: 0.78825
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.59780

Cumulative Model Updates: 11,383
Cumulative Timesteps: 189,960,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 189960186...
Checkpoint 189960186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.88097
Policy Entropy: 1.29045
Value Function Loss: 0.30375

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07007
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.06359

Collected Steps per Second: 12,592.96170
Overall Steps per Second: 10,500.58703

Timestep Collection Time: 3.97254
Timestep Consumption Time: 0.79158
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.76411

Cumulative Model Updates: 11,386
Cumulative Timesteps: 190,010,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.36998
Policy Entropy: 1.28333
Value Function Loss: 0.31798

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 12,471.89330
Overall Steps per Second: 10,459.07075

Timestep Collection Time: 4.01110
Timestep Consumption Time: 0.77193
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.78303

Cumulative Model Updates: 11,389
Cumulative Timesteps: 190,060,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 190060238...
Checkpoint 190060238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.92651
Policy Entropy: 1.28474
Value Function Loss: 0.31935

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07403
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.06915

Collected Steps per Second: 11,721.61680
Overall Steps per Second: 9,933.78937

Timestep Collection Time: 4.26733
Timestep Consumption Time: 0.76801
PPO Batch Consumption Time: 0.03803
Total Iteration Time: 5.03534

Cumulative Model Updates: 11,392
Cumulative Timesteps: 190,110,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.70764
Policy Entropy: 1.28375
Value Function Loss: 0.29519

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.06162

Collected Steps per Second: 12,823.10115
Overall Steps per Second: 10,697.33802

Timestep Collection Time: 3.90015
Timestep Consumption Time: 0.77503
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 4.67518

Cumulative Model Updates: 11,395
Cumulative Timesteps: 190,160,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 190160270...
Checkpoint 190160270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.51923
Policy Entropy: 1.28513
Value Function Loss: 0.30472

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 12,607.87355
Overall Steps per Second: 10,466.63942

Timestep Collection Time: 3.96673
Timestep Consumption Time: 0.81150
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 4.77823

Cumulative Model Updates: 11,398
Cumulative Timesteps: 190,210,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.18920
Policy Entropy: 1.28141
Value Function Loss: 0.32563

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07407
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.06948

Collected Steps per Second: 12,520.88609
Overall Steps per Second: 10,675.99050

Timestep Collection Time: 3.99381
Timestep Consumption Time: 0.69016
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.68397

Cumulative Model Updates: 11,401
Cumulative Timesteps: 190,260,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 190260288...
Checkpoint 190260288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.79446
Policy Entropy: 1.28604
Value Function Loss: 0.35445

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.07142

Collected Steps per Second: 12,557.12755
Overall Steps per Second: 10,553.82760

Timestep Collection Time: 3.98324
Timestep Consumption Time: 0.75609
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 4.73932

Cumulative Model Updates: 11,404
Cumulative Timesteps: 190,310,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.87435
Policy Entropy: 1.28008
Value Function Loss: 0.35443

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.06135

Collected Steps per Second: 12,478.41519
Overall Steps per Second: 10,707.92655

Timestep Collection Time: 4.00820
Timestep Consumption Time: 0.66273
PPO Batch Consumption Time: 0.03360
Total Iteration Time: 4.67093

Cumulative Model Updates: 11,407
Cumulative Timesteps: 190,360,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 190360322...
Checkpoint 190360322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.57118
Policy Entropy: 1.28524
Value Function Loss: 0.37116

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.04184
Value Function Update Magnitude: 0.06657

Collected Steps per Second: 11,846.72590
Overall Steps per Second: 9,946.39631

Timestep Collection Time: 4.22125
Timestep Consumption Time: 0.80650
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 5.02775

Cumulative Model Updates: 11,410
Cumulative Timesteps: 190,410,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.67272
Policy Entropy: 1.27861
Value Function Loss: 0.35396

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.08468

Collected Steps per Second: 12,239.61425
Overall Steps per Second: 10,266.08069

Timestep Collection Time: 4.08657
Timestep Consumption Time: 0.78559
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.87216

Cumulative Model Updates: 11,413
Cumulative Timesteps: 190,460,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 190460348...
Checkpoint 190460348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.05914
Policy Entropy: 1.28315
Value Function Loss: 0.35289

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.07933

Collected Steps per Second: 12,376.15370
Overall Steps per Second: 10,473.83988

Timestep Collection Time: 4.04067
Timestep Consumption Time: 0.73389
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 4.77456

Cumulative Model Updates: 11,416
Cumulative Timesteps: 190,510,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.08355
Policy Entropy: 1.28024
Value Function Loss: 0.33409

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.06976

Collected Steps per Second: 12,357.57912
Overall Steps per Second: 10,400.33493

Timestep Collection Time: 4.04820
Timestep Consumption Time: 0.76183
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.81004

Cumulative Model Updates: 11,419
Cumulative Timesteps: 190,560,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 190560382...
Checkpoint 190560382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.64669
Policy Entropy: 1.28577
Value Function Loss: 0.36697

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.06853

Collected Steps per Second: 12,578.15548
Overall Steps per Second: 10,497.27002

Timestep Collection Time: 3.97658
Timestep Consumption Time: 0.78828
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 4.76486

Cumulative Model Updates: 11,422
Cumulative Timesteps: 190,610,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.49410
Policy Entropy: 1.28401
Value Function Loss: 0.34318

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.07725

Collected Steps per Second: 12,376.08665
Overall Steps per Second: 10,478.12939

Timestep Collection Time: 4.04134
Timestep Consumption Time: 0.73203
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 4.77337

Cumulative Model Updates: 11,425
Cumulative Timesteps: 190,660,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 190660416...
Checkpoint 190660416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.49038
Policy Entropy: 1.28549
Value Function Loss: 0.38105

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07658
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.07067

Collected Steps per Second: 12,478.42569
Overall Steps per Second: 10,306.01317

Timestep Collection Time: 4.00772
Timestep Consumption Time: 0.84479
PPO Batch Consumption Time: 0.03373
Total Iteration Time: 4.85251

Cumulative Model Updates: 11,428
Cumulative Timesteps: 190,710,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.60406
Policy Entropy: 1.28558
Value Function Loss: 0.35016

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.06599

Collected Steps per Second: 12,104.11758
Overall Steps per Second: 10,225.29051

Timestep Collection Time: 4.13132
Timestep Consumption Time: 0.75910
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 4.89042

Cumulative Model Updates: 11,431
Cumulative Timesteps: 190,760,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 190760432...
Checkpoint 190760432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.51147
Policy Entropy: 1.28105
Value Function Loss: 0.37137

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.06268

Collected Steps per Second: 12,583.16750
Overall Steps per Second: 10,684.67231

Timestep Collection Time: 3.97356
Timestep Consumption Time: 0.70604
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.67960

Cumulative Model Updates: 11,434
Cumulative Timesteps: 190,810,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.50285
Policy Entropy: 1.28194
Value Function Loss: 0.32781

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06025
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 12,420.26517
Overall Steps per Second: 10,393.17213

Timestep Collection Time: 4.02777
Timestep Consumption Time: 0.78558
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 4.81335

Cumulative Model Updates: 11,437
Cumulative Timesteps: 190,860,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 190860458...
Checkpoint 190860458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.79144
Policy Entropy: 1.28785
Value Function Loss: 0.30874

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06686
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.06584

Collected Steps per Second: 12,404.29224
Overall Steps per Second: 10,361.70401

Timestep Collection Time: 4.03231
Timestep Consumption Time: 0.79488
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.82720

Cumulative Model Updates: 11,440
Cumulative Timesteps: 190,910,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.50171
Policy Entropy: 1.28458
Value Function Loss: 0.27869

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.07278

Collected Steps per Second: 13,144.28769
Overall Steps per Second: 10,932.28110

Timestep Collection Time: 3.80530
Timestep Consumption Time: 0.76995
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.57526

Cumulative Model Updates: 11,443
Cumulative Timesteps: 190,960,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 190960494...
Checkpoint 190960494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.23267
Policy Entropy: 1.28917
Value Function Loss: 0.27677

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06971
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.06966

Collected Steps per Second: 12,141.95569
Overall Steps per Second: 10,261.45732

Timestep Collection Time: 4.12009
Timestep Consumption Time: 0.75504
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 4.87514

Cumulative Model Updates: 11,446
Cumulative Timesteps: 191,010,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.34990
Policy Entropy: 1.28405
Value Function Loss: 0.33192

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 11,943.48429
Overall Steps per Second: 10,224.33047

Timestep Collection Time: 4.18689
Timestep Consumption Time: 0.70400
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.89088

Cumulative Model Updates: 11,449
Cumulative Timesteps: 191,060,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 191060526...
Checkpoint 191060526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.04014
Policy Entropy: 1.28575
Value Function Loss: 0.34469

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07076
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.07772

Collected Steps per Second: 12,664.71928
Overall Steps per Second: 10,575.67453

Timestep Collection Time: 3.94892
Timestep Consumption Time: 0.78004
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 4.72897

Cumulative Model Updates: 11,452
Cumulative Timesteps: 191,110,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.38002
Policy Entropy: 1.28449
Value Function Loss: 0.36014

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07682
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.08176

Collected Steps per Second: 12,694.45106
Overall Steps per Second: 10,649.67149

Timestep Collection Time: 3.93873
Timestep Consumption Time: 0.75625
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.69498

Cumulative Model Updates: 11,455
Cumulative Timesteps: 191,160,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 191160538...
Checkpoint 191160538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.07553
Policy Entropy: 1.28653
Value Function Loss: 0.34999

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06713
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.07303

Collected Steps per Second: 12,665.95098
Overall Steps per Second: 10,606.41473

Timestep Collection Time: 3.94901
Timestep Consumption Time: 0.76681
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.71583

Cumulative Model Updates: 11,458
Cumulative Timesteps: 191,210,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.59578
Policy Entropy: 1.28374
Value Function Loss: 0.34304

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06915
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.06432

Collected Steps per Second: 12,391.38308
Overall Steps per Second: 10,419.38515

Timestep Collection Time: 4.03619
Timestep Consumption Time: 0.76390
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 4.80009

Cumulative Model Updates: 11,461
Cumulative Timesteps: 191,260,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 191260570...
Checkpoint 191260570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.01361
Policy Entropy: 1.28203
Value Function Loss: 0.32317

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.05693

Collected Steps per Second: 12,407.30213
Overall Steps per Second: 10,444.39242

Timestep Collection Time: 4.03134
Timestep Consumption Time: 0.75765
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 4.78898

Cumulative Model Updates: 11,464
Cumulative Timesteps: 191,310,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.31943
Policy Entropy: 1.27965
Value Function Loss: 0.32476

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06534
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.05509

Collected Steps per Second: 12,074.15033
Overall Steps per Second: 10,156.60365

Timestep Collection Time: 4.14207
Timestep Consumption Time: 0.78202
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.92409

Cumulative Model Updates: 11,467
Cumulative Timesteps: 191,360,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 191360600...
Checkpoint 191360600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.54972
Policy Entropy: 1.28198
Value Function Loss: 0.33620

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.05877

Collected Steps per Second: 12,814.95213
Overall Steps per Second: 10,662.22103

Timestep Collection Time: 3.90216
Timestep Consumption Time: 0.78786
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 4.69002

Cumulative Model Updates: 11,470
Cumulative Timesteps: 191,410,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.19303
Policy Entropy: 1.28129
Value Function Loss: 0.35130

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07769
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.05594

Collected Steps per Second: 12,640.05020
Overall Steps per Second: 10,720.00224

Timestep Collection Time: 3.95631
Timestep Consumption Time: 0.70861
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.66492

Cumulative Model Updates: 11,473
Cumulative Timesteps: 191,460,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 191460614...
Checkpoint 191460614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.05222
Policy Entropy: 1.28084
Value Function Loss: 0.36858

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.06570

Collected Steps per Second: 12,559.71054
Overall Steps per Second: 10,561.25996

Timestep Collection Time: 3.98274
Timestep Consumption Time: 0.75363
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.73637

Cumulative Model Updates: 11,476
Cumulative Timesteps: 191,510,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.62629
Policy Entropy: 1.28005
Value Function Loss: 0.37589

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.07707

Collected Steps per Second: 12,568.02224
Overall Steps per Second: 10,759.01335

Timestep Collection Time: 3.97978
Timestep Consumption Time: 0.66916
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 4.64894

Cumulative Model Updates: 11,479
Cumulative Timesteps: 191,560,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 191560654...
Checkpoint 191560654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.13673
Policy Entropy: 1.27933
Value Function Loss: 0.37000

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05996
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.07309

Collected Steps per Second: 12,256.05090
Overall Steps per Second: 10,364.95282

Timestep Collection Time: 4.08092
Timestep Consumption Time: 0.74457
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.82549

Cumulative Model Updates: 11,482
Cumulative Timesteps: 191,610,670

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.47329
Policy Entropy: 1.28027
Value Function Loss: 0.33388

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05267
Policy Update Magnitude: 0.05217
Value Function Update Magnitude: 0.07213

Collected Steps per Second: 11,471.90062
Overall Steps per Second: 9,799.49392

Timestep Collection Time: 4.36074
Timestep Consumption Time: 0.74422
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.10496

Cumulative Model Updates: 11,485
Cumulative Timesteps: 191,660,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 191660696...
Checkpoint 191660696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.33300
Policy Entropy: 1.28045
Value Function Loss: 0.32518

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04632
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.06542

Collected Steps per Second: 12,499.51055
Overall Steps per Second: 10,437.83180

Timestep Collection Time: 4.00192
Timestep Consumption Time: 0.79046
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 4.79237

Cumulative Model Updates: 11,488
Cumulative Timesteps: 191,710,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.72445
Policy Entropy: 1.27965
Value Function Loss: 0.31341

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05206
Policy Update Magnitude: 0.06772
Value Function Update Magnitude: 0.05502

Collected Steps per Second: 12,204.91291
Overall Steps per Second: 10,274.00285

Timestep Collection Time: 4.09786
Timestep Consumption Time: 0.77016
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 4.86802

Cumulative Model Updates: 11,491
Cumulative Timesteps: 191,760,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 191760732...
Checkpoint 191760732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.85998
Policy Entropy: 1.27808
Value Function Loss: 0.32171

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06457
Policy Update Magnitude: 0.07094
Value Function Update Magnitude: 0.05210

Collected Steps per Second: 12,645.03649
Overall Steps per Second: 10,775.53247

Timestep Collection Time: 3.95618
Timestep Consumption Time: 0.68638
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.64255

Cumulative Model Updates: 11,494
Cumulative Timesteps: 191,810,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.17749
Policy Entropy: 1.28227
Value Function Loss: 0.31141

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.05908
Policy Update Magnitude: 0.07067
Value Function Update Magnitude: 0.06046

Collected Steps per Second: 12,446.79696
Overall Steps per Second: 10,397.49063

Timestep Collection Time: 4.01854
Timestep Consumption Time: 0.79204
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.81058

Cumulative Model Updates: 11,497
Cumulative Timesteps: 191,860,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 191860776...
Checkpoint 191860776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.24768
Policy Entropy: 1.28113
Value Function Loss: 0.31409

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06404
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.05997

Collected Steps per Second: 12,303.10833
Overall Steps per Second: 10,457.56695

Timestep Collection Time: 4.06580
Timestep Consumption Time: 0.71753
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 4.78333

Cumulative Model Updates: 11,500
Cumulative Timesteps: 191,910,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.74719
Policy Entropy: 1.26805
Value Function Loss: 0.28089

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.06788
Value Function Update Magnitude: 0.05940

Collected Steps per Second: 12,283.96622
Overall Steps per Second: 10,113.24730

Timestep Collection Time: 4.07165
Timestep Consumption Time: 0.87394
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.94559

Cumulative Model Updates: 11,503
Cumulative Timesteps: 191,960,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 191960814...
Checkpoint 191960814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.13243
Policy Entropy: 1.28193
Value Function Loss: 0.29137

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.06577
Value Function Update Magnitude: 0.05893

Collected Steps per Second: 12,110.95900
Overall Steps per Second: 10,190.57064

Timestep Collection Time: 4.12882
Timestep Consumption Time: 0.77807
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 4.90689

Cumulative Model Updates: 11,506
Cumulative Timesteps: 192,010,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.11225
Policy Entropy: 1.26596
Value Function Loss: 0.30984

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.05543

Collected Steps per Second: 12,463.29457
Overall Steps per Second: 10,676.32998

Timestep Collection Time: 4.01194
Timestep Consumption Time: 0.67150
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.68344

Cumulative Model Updates: 11,509
Cumulative Timesteps: 192,060,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 192060820...
Checkpoint 192060820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.30796
Policy Entropy: 1.28086
Value Function Loss: 0.33964

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.06841

Collected Steps per Second: 12,393.03369
Overall Steps per Second: 10,390.56157

Timestep Collection Time: 4.03501
Timestep Consumption Time: 0.77763
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.81264

Cumulative Model Updates: 11,512
Cumulative Timesteps: 192,110,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.85481
Policy Entropy: 1.27257
Value Function Loss: 0.32500

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07399
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.05405

Collected Steps per Second: 12,428.82286
Overall Steps per Second: 10,575.18929

Timestep Collection Time: 4.02468
Timestep Consumption Time: 0.70545
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 4.73013

Cumulative Model Updates: 11,515
Cumulative Timesteps: 192,160,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 192160848...
Checkpoint 192160848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.19146
Policy Entropy: 1.27780
Value Function Loss: 0.31528

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05723
Policy Update Magnitude: 0.06863
Value Function Update Magnitude: 0.04761

Collected Steps per Second: 13,113.83127
Overall Steps per Second: 10,815.86050

Timestep Collection Time: 3.81292
Timestep Consumption Time: 0.81010
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.62303

Cumulative Model Updates: 11,518
Cumulative Timesteps: 192,210,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.72648
Policy Entropy: 1.27771
Value Function Loss: 0.32551

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06223
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.06206

Collected Steps per Second: 12,794.36939
Overall Steps per Second: 10,659.92963

Timestep Collection Time: 3.90813
Timestep Consumption Time: 0.78252
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.69065

Cumulative Model Updates: 11,521
Cumulative Timesteps: 192,260,852

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 192260852...
Checkpoint 192260852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.18773
Policy Entropy: 1.27584
Value Function Loss: 0.33126

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05718
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.06576

Collected Steps per Second: 11,976.64862
Overall Steps per Second: 10,182.92190

Timestep Collection Time: 4.17663
Timestep Consumption Time: 0.73572
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.91234

Cumulative Model Updates: 11,524
Cumulative Timesteps: 192,310,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.12988
Policy Entropy: 1.27696
Value Function Loss: 0.32748

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04460
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.06066

Collected Steps per Second: 13,108.60874
Overall Steps per Second: 10,866.31833

Timestep Collection Time: 3.81597
Timestep Consumption Time: 0.78743
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.60340

Cumulative Model Updates: 11,527
Cumulative Timesteps: 192,360,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 192360896...
Checkpoint 192360896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.23181
Policy Entropy: 1.27158
Value Function Loss: 0.31301

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04820
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.05791

Collected Steps per Second: 13,579.69208
Overall Steps per Second: 11,255.04863

Timestep Collection Time: 3.68344
Timestep Consumption Time: 0.76079
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.44423

Cumulative Model Updates: 11,530
Cumulative Timesteps: 192,410,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.80473
Policy Entropy: 1.27215
Value Function Loss: 0.32268

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04615
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.06102

Collected Steps per Second: 13,025.33389
Overall Steps per Second: 10,725.25731

Timestep Collection Time: 3.84067
Timestep Consumption Time: 0.82365
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.66432

Cumulative Model Updates: 11,533
Cumulative Timesteps: 192,460,942

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 192460942...
Checkpoint 192460942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.13300
Policy Entropy: 1.27277
Value Function Loss: 0.31587

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05642
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.07470

Collected Steps per Second: 12,640.64915
Overall Steps per Second: 10,672.12767

Timestep Collection Time: 3.95660
Timestep Consumption Time: 0.72981
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.68641

Cumulative Model Updates: 11,536
Cumulative Timesteps: 192,510,956

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.64846
Policy Entropy: 1.27778
Value Function Loss: 0.28555

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04700
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 12,281.83835
Overall Steps per Second: 10,463.51488

Timestep Collection Time: 4.07187
Timestep Consumption Time: 0.70760
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.77946

Cumulative Model Updates: 11,539
Cumulative Timesteps: 192,560,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 192560966...
Checkpoint 192560966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.22917
Policy Entropy: 1.27895
Value Function Loss: 0.29312

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06651
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.06694

Collected Steps per Second: 11,820.04881
Overall Steps per Second: 10,023.97802

Timestep Collection Time: 4.23112
Timestep Consumption Time: 0.75812
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 4.98924

Cumulative Model Updates: 11,542
Cumulative Timesteps: 192,610,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.81845
Policy Entropy: 1.27344
Value Function Loss: 0.28740

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04456
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.08008

Collected Steps per Second: 12,664.68406
Overall Steps per Second: 10,725.00144

Timestep Collection Time: 3.94988
Timestep Consumption Time: 0.71436
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.66424

Cumulative Model Updates: 11,545
Cumulative Timesteps: 192,661,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 192661002...
Checkpoint 192661002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.45127
Policy Entropy: 1.27598
Value Function Loss: 0.33496

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06918
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.07573

Collected Steps per Second: 12,394.67408
Overall Steps per Second: 10,350.65460

Timestep Collection Time: 4.03560
Timestep Consumption Time: 0.79694
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 4.83254

Cumulative Model Updates: 11,548
Cumulative Timesteps: 192,711,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.11895
Policy Entropy: 1.27503
Value Function Loss: 0.31329

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.06295

Collected Steps per Second: 11,956.45847
Overall Steps per Second: 10,159.18267

Timestep Collection Time: 4.18318
Timestep Consumption Time: 0.74005
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 4.92323

Cumulative Model Updates: 11,551
Cumulative Timesteps: 192,761,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 192761038...
Checkpoint 192761038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.55506
Policy Entropy: 1.27282
Value Function Loss: 0.31245

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06265
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 12,586.52924
Overall Steps per Second: 10,514.07838

Timestep Collection Time: 3.97282
Timestep Consumption Time: 0.78309
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.75591

Cumulative Model Updates: 11,554
Cumulative Timesteps: 192,811,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.99527
Policy Entropy: 1.28049
Value Function Loss: 0.29730

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06509
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.09947

Collected Steps per Second: 12,382.35298
Overall Steps per Second: 10,393.16932

Timestep Collection Time: 4.04010
Timestep Consumption Time: 0.77325
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 4.81335

Cumulative Model Updates: 11,557
Cumulative Timesteps: 192,861,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 192861068...
Checkpoint 192861068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.40477
Policy Entropy: 1.28298
Value Function Loss: 0.28556

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.09632

Collected Steps per Second: 11,535.81465
Overall Steps per Second: 9,772.96058

Timestep Collection Time: 4.33571
Timestep Consumption Time: 0.78208
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.11779

Cumulative Model Updates: 11,560
Cumulative Timesteps: 192,911,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.21806
Policy Entropy: 1.28262
Value Function Loss: 0.31063

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.08456

Collected Steps per Second: 11,209.22055
Overall Steps per Second: 9,591.73220

Timestep Collection Time: 4.46240
Timestep Consumption Time: 0.75251
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.21491

Cumulative Model Updates: 11,563
Cumulative Timesteps: 192,961,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 192961104...
Checkpoint 192961104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.72077
Policy Entropy: 1.27720
Value Function Loss: 0.31263

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06047
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.07270

Collected Steps per Second: 11,357.06735
Overall Steps per Second: 9,685.53598

Timestep Collection Time: 4.40307
Timestep Consumption Time: 0.75988
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 5.16296

Cumulative Model Updates: 11,566
Cumulative Timesteps: 193,011,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.24998
Policy Entropy: 1.28055
Value Function Loss: 0.31668

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.06982

Collected Steps per Second: 11,185.48166
Overall Steps per Second: 9,705.53486

Timestep Collection Time: 4.47062
Timestep Consumption Time: 0.68170
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.15232

Cumulative Model Updates: 11,569
Cumulative Timesteps: 193,061,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 193061116...
Checkpoint 193061116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.49203
Policy Entropy: 1.26772
Value Function Loss: 0.29979

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.07178

Collected Steps per Second: 11,264.20112
Overall Steps per Second: 9,550.26284

Timestep Collection Time: 4.43884
Timestep Consumption Time: 0.79662
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.23546

Cumulative Model Updates: 11,572
Cumulative Timesteps: 193,111,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.95202
Policy Entropy: 1.28306
Value Function Loss: 0.29069

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07613
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.06241

Collected Steps per Second: 11,203.80899
Overall Steps per Second: 9,603.00383

Timestep Collection Time: 4.46313
Timestep Consumption Time: 0.74400
PPO Batch Consumption Time: 0.04046
Total Iteration Time: 5.20712

Cumulative Model Updates: 11,575
Cumulative Timesteps: 193,161,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 193161120...
Checkpoint 193161120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.21243
Policy Entropy: 1.26905
Value Function Loss: 0.29586

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.05594

Collected Steps per Second: 10,535.91507
Overall Steps per Second: 9,017.24079

Timestep Collection Time: 4.74871
Timestep Consumption Time: 0.79977
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.54848

Cumulative Model Updates: 11,578
Cumulative Timesteps: 193,211,152

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.14042
Policy Entropy: 1.27913
Value Function Loss: 0.31091

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.05788

Collected Steps per Second: 11,155.40909
Overall Steps per Second: 9,464.05923

Timestep Collection Time: 4.48285
Timestep Consumption Time: 0.80114
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.28399

Cumulative Model Updates: 11,581
Cumulative Timesteps: 193,261,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 193261160...
Checkpoint 193261160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.36183
Policy Entropy: 1.27466
Value Function Loss: 0.31174

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.05542

Collected Steps per Second: 11,347.31465
Overall Steps per Second: 9,825.86682

Timestep Collection Time: 4.40880
Timestep Consumption Time: 0.68266
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.09146

Cumulative Model Updates: 11,584
Cumulative Timesteps: 193,311,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.72838
Policy Entropy: 1.27542
Value Function Loss: 0.29652

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06200
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.07527

Collected Steps per Second: 10,982.52262
Overall Steps per Second: 9,364.59462

Timestep Collection Time: 4.55524
Timestep Consumption Time: 0.78701
PPO Batch Consumption Time: 0.04182
Total Iteration Time: 5.34225

Cumulative Model Updates: 11,587
Cumulative Timesteps: 193,361,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 193361216...
Checkpoint 193361216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.24190
Policy Entropy: 1.27637
Value Function Loss: 0.26086

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.06951
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 11,689.15952
Overall Steps per Second: 10,013.03793

Timestep Collection Time: 4.27781
Timestep Consumption Time: 0.71608
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.99389

Cumulative Model Updates: 11,590
Cumulative Timesteps: 193,411,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.22593
Policy Entropy: 1.28156
Value Function Loss: 0.25703

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04865
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 11,627.44835
Overall Steps per Second: 9,847.59087

Timestep Collection Time: 4.30258
Timestep Consumption Time: 0.77765
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.08023

Cumulative Model Updates: 11,593
Cumulative Timesteps: 193,461,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 193461248...
Checkpoint 193461248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.11793
Policy Entropy: 1.28423
Value Function Loss: 0.26582

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03503
Policy Update Magnitude: 0.06572
Value Function Update Magnitude: 0.07354

Collected Steps per Second: 10,991.41094
Overall Steps per Second: 9,335.02145

Timestep Collection Time: 4.55137
Timestep Consumption Time: 0.80759
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.35896

Cumulative Model Updates: 11,596
Cumulative Timesteps: 193,511,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.98398
Policy Entropy: 1.28136
Value Function Loss: 0.27565

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03406
Policy Update Magnitude: 0.06692
Value Function Update Magnitude: 0.06836

Collected Steps per Second: 12,616.26450
Overall Steps per Second: 10,623.01239

Timestep Collection Time: 3.96552
Timestep Consumption Time: 0.74407
PPO Batch Consumption Time: 0.03856
Total Iteration Time: 4.70959

Cumulative Model Updates: 11,599
Cumulative Timesteps: 193,561,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 193561304...
Checkpoint 193561304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.87401
Policy Entropy: 1.27886
Value Function Loss: 0.26023

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.06675
Value Function Update Magnitude: 0.06613

Collected Steps per Second: 12,383.39580
Overall Steps per Second: 10,445.04210

Timestep Collection Time: 4.03783
Timestep Consumption Time: 0.74933
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.78715

Cumulative Model Updates: 11,602
Cumulative Timesteps: 193,611,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.71010
Policy Entropy: 1.27814
Value Function Loss: 0.26508

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03721
Policy Update Magnitude: 0.06758
Value Function Update Magnitude: 0.07060

Collected Steps per Second: 12,607.26382
Overall Steps per Second: 10,787.90972

Timestep Collection Time: 3.96755
Timestep Consumption Time: 0.66912
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 4.63667

Cumulative Model Updates: 11,605
Cumulative Timesteps: 193,661,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 193661326...
Checkpoint 193661326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.80846
Policy Entropy: 1.27648
Value Function Loss: 0.27895

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03966
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 12,496.83208
Overall Steps per Second: 10,465.97303

Timestep Collection Time: 4.00341
Timestep Consumption Time: 0.77684
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.78025

Cumulative Model Updates: 11,608
Cumulative Timesteps: 193,711,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.09944
Policy Entropy: 1.28017
Value Function Loss: 0.29702

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05668
Policy Update Magnitude: 0.06741
Value Function Update Magnitude: 0.08045

Collected Steps per Second: 12,287.73157
Overall Steps per Second: 10,365.37061

Timestep Collection Time: 4.07138
Timestep Consumption Time: 0.75508
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.82646

Cumulative Model Updates: 11,611
Cumulative Timesteps: 193,761,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 193761384...
Checkpoint 193761384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.30845
Policy Entropy: 1.28011
Value Function Loss: 0.28586

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06255
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.08146

Collected Steps per Second: 12,124.65109
Overall Steps per Second: 10,218.22381

Timestep Collection Time: 4.12597
Timestep Consumption Time: 0.76979
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 4.89576

Cumulative Model Updates: 11,614
Cumulative Timesteps: 193,811,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.80930
Policy Entropy: 1.28638
Value Function Loss: 0.28398

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05634
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.07570

Collected Steps per Second: 12,564.23210
Overall Steps per Second: 10,526.86217

Timestep Collection Time: 3.98051
Timestep Consumption Time: 0.77039
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 4.75089

Cumulative Model Updates: 11,617
Cumulative Timesteps: 193,861,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 193861422...
Checkpoint 193861422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.90939
Policy Entropy: 1.28846
Value Function Loss: 0.28554

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05540
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.07576

Collected Steps per Second: 12,392.81481
Overall Steps per Second: 10,620.37051

Timestep Collection Time: 4.03573
Timestep Consumption Time: 0.67353
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 4.70925

Cumulative Model Updates: 11,620
Cumulative Timesteps: 193,911,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.81937
Policy Entropy: 1.28508
Value Function Loss: 0.27577

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05051
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.07792

Collected Steps per Second: 12,384.68305
Overall Steps per Second: 10,351.19637

Timestep Collection Time: 4.03918
Timestep Consumption Time: 0.79350
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 4.83268

Cumulative Model Updates: 11,623
Cumulative Timesteps: 193,961,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 193961460...
Checkpoint 193961460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.52079
Policy Entropy: 1.28916
Value Function Loss: 0.25363

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05807
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.09196

Collected Steps per Second: 12,504.69013
Overall Steps per Second: 10,415.97173

Timestep Collection Time: 4.00042
Timestep Consumption Time: 0.80221
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 4.80262

Cumulative Model Updates: 11,626
Cumulative Timesteps: 194,011,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.01359
Policy Entropy: 1.28421
Value Function Loss: 0.27653

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07067
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.08238

Collected Steps per Second: 12,840.75084
Overall Steps per Second: 10,744.32973

Timestep Collection Time: 3.89588
Timestep Consumption Time: 0.76016
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.65604

Cumulative Model Updates: 11,629
Cumulative Timesteps: 194,061,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 194061510...
Checkpoint 194061510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.29860
Policy Entropy: 1.28715
Value Function Loss: 0.28370

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.07466

Collected Steps per Second: 11,555.78420
Overall Steps per Second: 9,784.21579

Timestep Collection Time: 4.32857
Timestep Consumption Time: 0.78375
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.11232

Cumulative Model Updates: 11,632
Cumulative Timesteps: 194,111,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.69478
Policy Entropy: 1.28935
Value Function Loss: 0.30119

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.07182

Collected Steps per Second: 12,337.68148
Overall Steps per Second: 10,560.90454

Timestep Collection Time: 4.05295
Timestep Consumption Time: 0.68187
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.73482

Cumulative Model Updates: 11,635
Cumulative Timesteps: 194,161,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 194161534...
Checkpoint 194161534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.78526
Policy Entropy: 1.28647
Value Function Loss: 0.26594

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05081
Policy Update Magnitude: 0.06260
Value Function Update Magnitude: 0.07902

Collected Steps per Second: 12,183.56836
Overall Steps per Second: 10,184.26285

Timestep Collection Time: 4.10389
Timestep Consumption Time: 0.80565
PPO Batch Consumption Time: 0.03326
Total Iteration Time: 4.90954

Cumulative Model Updates: 11,638
Cumulative Timesteps: 194,211,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.11591
Policy Entropy: 1.29061
Value Function Loss: 0.27550

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06251
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.08734

Collected Steps per Second: 12,274.35116
Overall Steps per Second: 10,428.93875

Timestep Collection Time: 4.07402
Timestep Consumption Time: 0.72090
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 4.79493

Cumulative Model Updates: 11,641
Cumulative Timesteps: 194,261,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 194261540...
Checkpoint 194261540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.61508
Policy Entropy: 1.28611
Value Function Loss: 0.27757

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.07373

Collected Steps per Second: 12,705.95833
Overall Steps per Second: 10,609.88533

Timestep Collection Time: 3.93626
Timestep Consumption Time: 0.77764
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.71391

Cumulative Model Updates: 11,644
Cumulative Timesteps: 194,311,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.91398
Policy Entropy: 1.28832
Value Function Loss: 0.29558

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07025
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.06638

Collected Steps per Second: 12,203.28411
Overall Steps per Second: 10,322.34634

Timestep Collection Time: 4.09922
Timestep Consumption Time: 0.74696
PPO Batch Consumption Time: 0.03300
Total Iteration Time: 4.84619

Cumulative Model Updates: 11,647
Cumulative Timesteps: 194,361,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 194361578...
Checkpoint 194361578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.93904
Policy Entropy: 1.28763
Value Function Loss: 0.29834

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06156
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.06670

Collected Steps per Second: 12,011.48016
Overall Steps per Second: 10,151.29579

Timestep Collection Time: 4.16468
Timestep Consumption Time: 0.76316
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 4.92784

Cumulative Model Updates: 11,650
Cumulative Timesteps: 194,411,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.98669
Policy Entropy: 1.28837
Value Function Loss: 0.30879

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05171
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.06292

Collected Steps per Second: 12,299.60859
Overall Steps per Second: 10,286.28826

Timestep Collection Time: 4.06728
Timestep Consumption Time: 0.79608
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.86337

Cumulative Model Updates: 11,653
Cumulative Timesteps: 194,461,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 194461628...
Checkpoint 194461628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.70782
Policy Entropy: 1.28839
Value Function Loss: 0.30293

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.04193
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.06319

Collected Steps per Second: 12,304.91622
Overall Steps per Second: 10,378.85777

Timestep Collection Time: 4.06504
Timestep Consumption Time: 0.75437
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 4.81941

Cumulative Model Updates: 11,656
Cumulative Timesteps: 194,511,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.68100
Policy Entropy: 1.28731
Value Function Loss: 0.29242

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04821
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.08302

Collected Steps per Second: 12,665.97384
Overall Steps per Second: 10,530.59296

Timestep Collection Time: 3.95027
Timestep Consumption Time: 0.80103
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 4.75130

Cumulative Model Updates: 11,659
Cumulative Timesteps: 194,561,682

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 194561682...
Checkpoint 194561682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.57447
Policy Entropy: 1.28528
Value Function Loss: 0.27248

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05787
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.06933

Collected Steps per Second: 12,224.09425
Overall Steps per Second: 10,154.33872

Timestep Collection Time: 4.09176
Timestep Consumption Time: 0.83402
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 4.92578

Cumulative Model Updates: 11,662
Cumulative Timesteps: 194,611,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.31945
Policy Entropy: 1.28785
Value Function Loss: 0.28361

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06539
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.07066

Collected Steps per Second: 13,025.86364
Overall Steps per Second: 11,028.66660

Timestep Collection Time: 3.83975
Timestep Consumption Time: 0.69534
PPO Batch Consumption Time: 0.03280
Total Iteration Time: 4.53509

Cumulative Model Updates: 11,665
Cumulative Timesteps: 194,661,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 194661716...
Checkpoint 194661716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.02055
Policy Entropy: 1.28407
Value Function Loss: 0.28438

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07067
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.05619

Collected Steps per Second: 12,879.78509
Overall Steps per Second: 10,589.96933

Timestep Collection Time: 3.88423
Timestep Consumption Time: 0.83987
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 4.72409

Cumulative Model Updates: 11,668
Cumulative Timesteps: 194,711,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.97911
Policy Entropy: 1.28986
Value Function Loss: 0.27503

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06445
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.05577

Collected Steps per Second: 12,080.89840
Overall Steps per Second: 10,155.61137

Timestep Collection Time: 4.14059
Timestep Consumption Time: 0.78497
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 4.92555

Cumulative Model Updates: 11,671
Cumulative Timesteps: 194,761,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 194761766...
Checkpoint 194761766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.05085
Policy Entropy: 1.28939
Value Function Loss: 0.26320

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.06438
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.05521

Collected Steps per Second: 13,655.50317
Overall Steps per Second: 11,231.43674

Timestep Collection Time: 3.66255
Timestep Consumption Time: 0.79048
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.45304

Cumulative Model Updates: 11,674
Cumulative Timesteps: 194,811,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.19940
Policy Entropy: 1.29028
Value Function Loss: 0.28039

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05711
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.06000

Collected Steps per Second: 12,826.07743
Overall Steps per Second: 10,657.62915

Timestep Collection Time: 3.90034
Timestep Consumption Time: 0.79358
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.69391

Cumulative Model Updates: 11,677
Cumulative Timesteps: 194,861,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 194861806...
Checkpoint 194861806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.41694
Policy Entropy: 1.29073
Value Function Loss: 0.27716

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06297
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 12,924.60865
Overall Steps per Second: 10,904.98944

Timestep Collection Time: 3.87076
Timestep Consumption Time: 0.71687
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.58762

Cumulative Model Updates: 11,680
Cumulative Timesteps: 194,911,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.99138
Policy Entropy: 1.28878
Value Function Loss: 0.28200

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.06371
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.05273

Collected Steps per Second: 12,389.10018
Overall Steps per Second: 10,382.22867

Timestep Collection Time: 4.03726
Timestep Consumption Time: 0.78040
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 4.81766

Cumulative Model Updates: 11,683
Cumulative Timesteps: 194,961,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 194961852...
Checkpoint 194961852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.07852
Policy Entropy: 1.29445
Value Function Loss: 0.27192

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06405
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.06704

Collected Steps per Second: 12,481.77629
Overall Steps per Second: 10,481.59469

Timestep Collection Time: 4.00584
Timestep Consumption Time: 0.76443
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 4.77027

Cumulative Model Updates: 11,686
Cumulative Timesteps: 195,011,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.82046
Policy Entropy: 1.29252
Value Function Loss: 0.26718

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06464
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.08225

Collected Steps per Second: 12,221.95355
Overall Steps per Second: 10,230.33406

Timestep Collection Time: 4.09296
Timestep Consumption Time: 0.79681
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.88977

Cumulative Model Updates: 11,689
Cumulative Timesteps: 195,061,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 195061876...
Checkpoint 195061876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.50467
Policy Entropy: 1.29532
Value Function Loss: 0.28793

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06149
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.07003

Collected Steps per Second: 12,669.50592
Overall Steps per Second: 10,651.31367

Timestep Collection Time: 3.94885
Timestep Consumption Time: 0.74822
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.69707

Cumulative Model Updates: 11,692
Cumulative Timesteps: 195,111,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.32550
Policy Entropy: 1.29565
Value Function Loss: 0.27059

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06172
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.06078

Collected Steps per Second: 12,413.55466
Overall Steps per Second: 10,553.46713

Timestep Collection Time: 4.02963
Timestep Consumption Time: 0.71024
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.73986

Cumulative Model Updates: 11,695
Cumulative Timesteps: 195,161,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 195161928...
Checkpoint 195161928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.14833
Policy Entropy: 1.29434
Value Function Loss: 0.30833

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05395
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.05400

Collected Steps per Second: 12,414.72141
Overall Steps per Second: 10,382.67176

Timestep Collection Time: 4.02780
Timestep Consumption Time: 0.78830
PPO Batch Consumption Time: 0.03974
Total Iteration Time: 4.81610

Cumulative Model Updates: 11,698
Cumulative Timesteps: 195,211,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.91305
Policy Entropy: 1.29069
Value Function Loss: 0.28525

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05570
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.06044

Collected Steps per Second: 12,210.68755
Overall Steps per Second: 10,382.36861

Timestep Collection Time: 4.09690
Timestep Consumption Time: 0.72146
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.81836

Cumulative Model Updates: 11,701
Cumulative Timesteps: 195,261,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 195261958...
Checkpoint 195261958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.83726
Policy Entropy: 1.29794
Value Function Loss: 0.29121

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05793
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.06148

Collected Steps per Second: 12,701.32832
Overall Steps per Second: 10,635.23030

Timestep Collection Time: 3.93675
Timestep Consumption Time: 0.76479
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.70154

Cumulative Model Updates: 11,704
Cumulative Timesteps: 195,311,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.88928
Policy Entropy: 1.29611
Value Function Loss: 0.26762

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04633
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.06769

Collected Steps per Second: 11,870.40903
Overall Steps per Second: 10,027.11853

Timestep Collection Time: 4.21300
Timestep Consumption Time: 0.77448
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.98747

Cumulative Model Updates: 11,707
Cumulative Timesteps: 195,361,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 195361970...
Checkpoint 195361970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.55931
Policy Entropy: 1.29998
Value Function Loss: 0.26236

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04764
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.07157

Collected Steps per Second: 12,187.71270
Overall Steps per Second: 10,439.62037

Timestep Collection Time: 4.10463
Timestep Consumption Time: 0.68731
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 4.79194

Cumulative Model Updates: 11,710
Cumulative Timesteps: 195,411,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.63818
Policy Entropy: 1.29491
Value Function Loss: 0.25703

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03736
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.06119

Collected Steps per Second: 12,612.52699
Overall Steps per Second: 10,572.83641

Timestep Collection Time: 3.96447
Timestep Consumption Time: 0.76482
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 4.72929

Cumulative Model Updates: 11,713
Cumulative Timesteps: 195,461,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 195461998...
Checkpoint 195461998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.06822
Policy Entropy: 1.29687
Value Function Loss: 0.25854

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 12,469.97901
Overall Steps per Second: 10,522.95682

Timestep Collection Time: 4.01011
Timestep Consumption Time: 0.74198
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.75209

Cumulative Model Updates: 11,716
Cumulative Timesteps: 195,512,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.19859
Policy Entropy: 1.29933
Value Function Loss: 0.26116

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02513
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.05736

Collected Steps per Second: 12,782.65461
Overall Steps per Second: 10,537.09893

Timestep Collection Time: 3.91186
Timestep Consumption Time: 0.83366
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.74552

Cumulative Model Updates: 11,719
Cumulative Timesteps: 195,562,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 195562008...
Checkpoint 195562008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.36616
Policy Entropy: 1.30223
Value Function Loss: 0.27848

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03206
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.05893

Collected Steps per Second: 12,293.60565
Overall Steps per Second: 10,255.36616

Timestep Collection Time: 4.06862
Timestep Consumption Time: 0.80863
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.87725

Cumulative Model Updates: 11,722
Cumulative Timesteps: 195,612,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.50838
Policy Entropy: 1.29810
Value Function Loss: 0.27173

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.05884

Collected Steps per Second: 12,239.22855
Overall Steps per Second: 10,358.29101

Timestep Collection Time: 4.08522
Timestep Consumption Time: 0.74183
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.82705

Cumulative Model Updates: 11,725
Cumulative Timesteps: 195,662,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 195662026...
Checkpoint 195662026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.62417
Policy Entropy: 1.29901
Value Function Loss: 0.26355

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04069
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.05521

Collected Steps per Second: 12,086.97157
Overall Steps per Second: 10,181.64274

Timestep Collection Time: 4.13718
Timestep Consumption Time: 0.77421
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.91139

Cumulative Model Updates: 11,728
Cumulative Timesteps: 195,712,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.26393
Policy Entropy: 1.29301
Value Function Loss: 0.26768

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04826
Policy Update Magnitude: 0.06762
Value Function Update Magnitude: 0.06132

Collected Steps per Second: 12,401.47611
Overall Steps per Second: 10,650.92454

Timestep Collection Time: 4.03355
Timestep Consumption Time: 0.66294
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 4.69649

Cumulative Model Updates: 11,731
Cumulative Timesteps: 195,762,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 195762054...
Checkpoint 195762054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.33228
Policy Entropy: 1.29361
Value Function Loss: 0.27642

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05196
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.05596

Collected Steps per Second: 12,328.84424
Overall Steps per Second: 10,336.73516

Timestep Collection Time: 4.05715
Timestep Consumption Time: 0.78190
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 4.83905

Cumulative Model Updates: 11,734
Cumulative Timesteps: 195,812,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.53925
Policy Entropy: 1.29102
Value Function Loss: 0.27167

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04462
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.05931

Collected Steps per Second: 12,256.26424
Overall Steps per Second: 10,409.87585

Timestep Collection Time: 4.08053
Timestep Consumption Time: 0.72376
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 4.80428

Cumulative Model Updates: 11,737
Cumulative Timesteps: 195,862,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 195862086...
Checkpoint 195862086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.38082
Policy Entropy: 1.29567
Value Function Loss: 0.25154

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04460
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.06409

Collected Steps per Second: 13,113.56320
Overall Steps per Second: 10,955.32637

Timestep Collection Time: 3.81361
Timestep Consumption Time: 0.75129
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 4.56490

Cumulative Model Updates: 11,740
Cumulative Timesteps: 195,912,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.98325
Policy Entropy: 1.29536
Value Function Loss: 0.26113

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05577
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.05913

Collected Steps per Second: 12,402.45264
Overall Steps per Second: 10,473.08860

Timestep Collection Time: 4.03211
Timestep Consumption Time: 0.74280
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 4.77490

Cumulative Model Updates: 11,743
Cumulative Timesteps: 195,962,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 195962104...
Checkpoint 195962104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.01325
Policy Entropy: 1.29604
Value Function Loss: 0.24885

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05224
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.04694

Collected Steps per Second: 11,812.32342
Overall Steps per Second: 10,056.33000

Timestep Collection Time: 4.23507
Timestep Consumption Time: 0.73951
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 4.97458

Cumulative Model Updates: 11,746
Cumulative Timesteps: 196,012,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.40449
Policy Entropy: 1.29427
Value Function Loss: 0.27137

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03814
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.04632

Collected Steps per Second: 11,630.76685
Overall Steps per Second: 9,762.44210

Timestep Collection Time: 4.30049
Timestep Consumption Time: 0.82302
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.12351

Cumulative Model Updates: 11,749
Cumulative Timesteps: 196,062,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 196062148...
Checkpoint 196062148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.59261
Policy Entropy: 1.29718
Value Function Loss: 0.28260

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.05219
Policy Update Magnitude: 0.05788
Value Function Update Magnitude: 0.05153

Collected Steps per Second: 11,439.37887
Overall Steps per Second: 9,779.15308

Timestep Collection Time: 4.37296
Timestep Consumption Time: 0.74241
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 5.11537

Cumulative Model Updates: 11,752
Cumulative Timesteps: 196,112,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.61511
Policy Entropy: 1.29107
Value Function Loss: 0.29203

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.04804

Collected Steps per Second: 11,594.71612
Overall Steps per Second: 9,778.38573

Timestep Collection Time: 4.31265
Timestep Consumption Time: 0.80107
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.11373

Cumulative Model Updates: 11,755
Cumulative Timesteps: 196,162,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 196162176...
Checkpoint 196162176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.19902
Policy Entropy: 1.29543
Value Function Loss: 0.28954

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06375
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.05345

Collected Steps per Second: 11,521.93009
Overall Steps per Second: 9,697.46233

Timestep Collection Time: 4.33972
Timestep Consumption Time: 0.81647
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.15619

Cumulative Model Updates: 11,758
Cumulative Timesteps: 196,212,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.42021
Policy Entropy: 1.29410
Value Function Loss: 0.28800

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06500
Policy Update Magnitude: 0.04324
Value Function Update Magnitude: 0.05613

Collected Steps per Second: 11,764.58277
Overall Steps per Second: 10,076.02740

Timestep Collection Time: 4.25242
Timestep Consumption Time: 0.71263
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 4.96505

Cumulative Model Updates: 11,761
Cumulative Timesteps: 196,262,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 196262206...
Checkpoint 196262206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.61529
Policy Entropy: 1.29744
Value Function Loss: 0.29082

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05316
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.05936

Collected Steps per Second: 10,788.05138
Overall Steps per Second: 8,955.48911

Timestep Collection Time: 4.63494
Timestep Consumption Time: 0.94845
PPO Batch Consumption Time: 0.03737
Total Iteration Time: 5.58339

Cumulative Model Updates: 11,764
Cumulative Timesteps: 196,312,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.07103
Policy Entropy: 1.29666
Value Function Loss: 0.27411

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04447
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.07659

Collected Steps per Second: 11,573.26545
Overall Steps per Second: 9,788.49951

Timestep Collection Time: 4.32117
Timestep Consumption Time: 0.78789
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.10906

Cumulative Model Updates: 11,767
Cumulative Timesteps: 196,362,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 196362218...
Checkpoint 196362218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.32694
Policy Entropy: 1.29269
Value Function Loss: 0.25689

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05775
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.08298

Collected Steps per Second: 11,961.55262
Overall Steps per Second: 9,887.17178

Timestep Collection Time: 4.18273
Timestep Consumption Time: 0.87756
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 5.06029

Cumulative Model Updates: 11,770
Cumulative Timesteps: 196,412,250

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.43855
Policy Entropy: 1.28850
Value Function Loss: 0.26345

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.05149
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.09172

Collected Steps per Second: 11,022.77959
Overall Steps per Second: 9,324.35561

Timestep Collection Time: 4.53715
Timestep Consumption Time: 0.82644
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.36359

Cumulative Model Updates: 11,773
Cumulative Timesteps: 196,462,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 196462262...
Checkpoint 196462262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.31843
Policy Entropy: 1.28582
Value Function Loss: 0.25676

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.05922
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.10295

Collected Steps per Second: 11,383.93608
Overall Steps per Second: 9,481.46504

Timestep Collection Time: 4.39426
Timestep Consumption Time: 0.88172
PPO Batch Consumption Time: 0.04671
Total Iteration Time: 5.27598

Cumulative Model Updates: 11,776
Cumulative Timesteps: 196,512,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.85840
Policy Entropy: 1.28780
Value Function Loss: 0.25070

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04640
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.08707

Collected Steps per Second: 10,832.12003
Overall Steps per Second: 9,156.89499

Timestep Collection Time: 4.61701
Timestep Consumption Time: 0.84467
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.46168

Cumulative Model Updates: 11,779
Cumulative Timesteps: 196,562,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 196562298...
Checkpoint 196562298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.18480
Policy Entropy: 1.28717
Value Function Loss: 0.25413

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05779
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.07871

Collected Steps per Second: 10,953.15152
Overall Steps per Second: 9,298.58095

Timestep Collection Time: 4.56581
Timestep Consumption Time: 0.81243
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.37824

Cumulative Model Updates: 11,782
Cumulative Timesteps: 196,612,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.06950
Policy Entropy: 1.28881
Value Function Loss: 0.26320

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04996
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.07253

Collected Steps per Second: 11,160.37118
Overall Steps per Second: 9,608.42213

Timestep Collection Time: 4.48247
Timestep Consumption Time: 0.72401
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 5.20647

Cumulative Model Updates: 11,785
Cumulative Timesteps: 196,662,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 196662334...
Checkpoint 196662334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.61496
Policy Entropy: 1.28760
Value Function Loss: 0.26176

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05301
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.06316

Collected Steps per Second: 11,596.29546
Overall Steps per Second: 9,797.48758

Timestep Collection Time: 4.31396
Timestep Consumption Time: 0.79204
PPO Batch Consumption Time: 0.03864
Total Iteration Time: 5.10600

Cumulative Model Updates: 11,788
Cumulative Timesteps: 196,712,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.85520
Policy Entropy: 1.28731
Value Function Loss: 0.25961

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05910
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.06141

Collected Steps per Second: 11,081.26476
Overall Steps per Second: 9,461.23907

Timestep Collection Time: 4.51483
Timestep Consumption Time: 0.77306
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 5.28789

Cumulative Model Updates: 11,791
Cumulative Timesteps: 196,762,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 196762390...
Checkpoint 196762390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.29104
Policy Entropy: 1.28309
Value Function Loss: 0.24640

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05271
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.05842

Collected Steps per Second: 11,323.29327
Overall Steps per Second: 9,514.46596

Timestep Collection Time: 4.41568
Timestep Consumption Time: 0.83948
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.25516

Cumulative Model Updates: 11,794
Cumulative Timesteps: 196,812,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.65837
Policy Entropy: 1.28553
Value Function Loss: 0.24077

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03687
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.05753

Collected Steps per Second: 10,551.56940
Overall Steps per Second: 9,073.94013

Timestep Collection Time: 4.73996
Timestep Consumption Time: 0.77187
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 5.51183

Cumulative Model Updates: 11,797
Cumulative Timesteps: 196,862,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 196862404...
Checkpoint 196862404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.25079
Policy Entropy: 1.28612
Value Function Loss: 0.22490

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05293
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.05754

Collected Steps per Second: 11,622.09771
Overall Steps per Second: 9,746.85990

Timestep Collection Time: 4.30387
Timestep Consumption Time: 0.82804
PPO Batch Consumption Time: 0.03717
Total Iteration Time: 5.13191

Cumulative Model Updates: 11,800
Cumulative Timesteps: 196,912,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.91057
Policy Entropy: 1.28880
Value Function Loss: 0.25272

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.06580

Collected Steps per Second: 11,377.76626
Overall Steps per Second: 9,586.87730

Timestep Collection Time: 4.39454
Timestep Consumption Time: 0.82093
PPO Batch Consumption Time: 0.03803
Total Iteration Time: 5.21546

Cumulative Model Updates: 11,803
Cumulative Timesteps: 196,962,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 196962424...
Checkpoint 196962424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.57472
Policy Entropy: 1.28474
Value Function Loss: 0.27835

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.06315

Collected Steps per Second: 10,764.97367
Overall Steps per Second: 9,301.31634

Timestep Collection Time: 4.64618
Timestep Consumption Time: 0.73112
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.37730

Cumulative Model Updates: 11,806
Cumulative Timesteps: 197,012,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.76259
Policy Entropy: 1.28633
Value Function Loss: 0.28929

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04836
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.08169

Collected Steps per Second: 12,227.52310
Overall Steps per Second: 10,186.37231

Timestep Collection Time: 4.08914
Timestep Consumption Time: 0.81938
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 4.90852

Cumulative Model Updates: 11,809
Cumulative Timesteps: 197,062,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 197062440...
Checkpoint 197062440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.19622
Policy Entropy: 1.28392
Value Function Loss: 0.26950

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05377
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.09278

Collected Steps per Second: 12,109.24068
Overall Steps per Second: 10,096.23419

Timestep Collection Time: 4.13023
Timestep Consumption Time: 0.82349
PPO Batch Consumption Time: 0.04392
Total Iteration Time: 4.95373

Cumulative Model Updates: 11,812
Cumulative Timesteps: 197,112,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.42715
Policy Entropy: 1.28683
Value Function Loss: 0.26970

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05102
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.08770

Collected Steps per Second: 11,644.36940
Overall Steps per Second: 9,731.23389

Timestep Collection Time: 4.29633
Timestep Consumption Time: 0.84465
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 5.14097

Cumulative Model Updates: 11,815
Cumulative Timesteps: 197,162,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 197162482...
Checkpoint 197162482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.72523
Policy Entropy: 1.28586
Value Function Loss: 0.24854

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04859
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.07734

Collected Steps per Second: 12,369.67028
Overall Steps per Second: 10,332.79115

Timestep Collection Time: 4.04360
Timestep Consumption Time: 0.79711
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.84071

Cumulative Model Updates: 11,818
Cumulative Timesteps: 197,212,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.90138
Policy Entropy: 1.28769
Value Function Loss: 0.25201

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05066
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.08042

Collected Steps per Second: 12,127.21228
Overall Steps per Second: 10,344.11254

Timestep Collection Time: 4.12494
Timestep Consumption Time: 0.71105
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.83599

Cumulative Model Updates: 11,821
Cumulative Timesteps: 197,262,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 197262524...
Checkpoint 197262524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.79307
Policy Entropy: 1.28765
Value Function Loss: 0.24156

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04049
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.08454

Collected Steps per Second: 12,255.72366
Overall Steps per Second: 10,196.93446

Timestep Collection Time: 4.08201
Timestep Consumption Time: 0.82417
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 4.90618

Cumulative Model Updates: 11,824
Cumulative Timesteps: 197,312,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.34700
Policy Entropy: 1.28768
Value Function Loss: 0.27265

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.08725

Collected Steps per Second: 11,372.09977
Overall Steps per Second: 9,690.85119

Timestep Collection Time: 4.39848
Timestep Consumption Time: 0.76309
PPO Batch Consumption Time: 0.03960
Total Iteration Time: 5.16157

Cumulative Model Updates: 11,827
Cumulative Timesteps: 197,362,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 197362572...
Checkpoint 197362572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.73621
Policy Entropy: 1.28987
Value Function Loss: 0.27197

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03245
Policy Update Magnitude: 0.06294
Value Function Update Magnitude: 0.09600

Collected Steps per Second: 11,700.55032
Overall Steps per Second: 9,884.79180

Timestep Collection Time: 4.27450
Timestep Consumption Time: 0.78519
PPO Batch Consumption Time: 0.03952
Total Iteration Time: 5.05969

Cumulative Model Updates: 11,830
Cumulative Timesteps: 197,412,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.87709
Policy Entropy: 1.28652
Value Function Loss: 0.29197

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.04046
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.08970

Collected Steps per Second: 10,889.93598
Overall Steps per Second: 9,362.99710

Timestep Collection Time: 4.59397
Timestep Consumption Time: 0.74919
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.34316

Cumulative Model Updates: 11,833
Cumulative Timesteps: 197,462,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 197462614...
Checkpoint 197462614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.50287
Policy Entropy: 1.28817
Value Function Loss: 0.28710

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 0.06323
Value Function Update Magnitude: 0.08566

Collected Steps per Second: 11,380.25856
Overall Steps per Second: 9,786.10770

Timestep Collection Time: 4.39568
Timestep Consumption Time: 0.71605
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.11174

Cumulative Model Updates: 11,836
Cumulative Timesteps: 197,512,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.47462
Policy Entropy: 1.28641
Value Function Loss: 0.27534

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.09264

Collected Steps per Second: 11,288.46295
Overall Steps per Second: 9,521.54847

Timestep Collection Time: 4.43107
Timestep Consumption Time: 0.82227
PPO Batch Consumption Time: 0.03792
Total Iteration Time: 5.25335

Cumulative Model Updates: 11,839
Cumulative Timesteps: 197,562,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 197562658...
Checkpoint 197562658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.33360
Policy Entropy: 1.29225
Value Function Loss: 0.26276

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03727
Policy Update Magnitude: 0.06752
Value Function Update Magnitude: 0.09125

Collected Steps per Second: 11,462.78453
Overall Steps per Second: 9,775.71814

Timestep Collection Time: 4.36421
Timestep Consumption Time: 0.75316
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.11737

Cumulative Model Updates: 11,842
Cumulative Timesteps: 197,612,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.18877
Policy Entropy: 1.28769
Value Function Loss: 0.25627

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03984
Policy Update Magnitude: 0.06606
Value Function Update Magnitude: 0.08730

Collected Steps per Second: 11,618.77673
Overall Steps per Second: 9,885.74900

Timestep Collection Time: 4.30476
Timestep Consumption Time: 0.75465
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.05940

Cumulative Model Updates: 11,845
Cumulative Timesteps: 197,662,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 197662700...
Checkpoint 197662700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.61787
Policy Entropy: 1.28881
Value Function Loss: 0.25944

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04815
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.08874

Collected Steps per Second: 10,840.89811
Overall Steps per Second: 9,134.72104

Timestep Collection Time: 4.61216
Timestep Consumption Time: 0.86146
PPO Batch Consumption Time: 0.03981
Total Iteration Time: 5.47362

Cumulative Model Updates: 11,848
Cumulative Timesteps: 197,712,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.21694
Policy Entropy: 1.28839
Value Function Loss: 0.25283

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03697
Policy Update Magnitude: 0.06634
Value Function Update Magnitude: 0.08850

Collected Steps per Second: 10,870.05768
Overall Steps per Second: 9,474.54873

Timestep Collection Time: 4.60200
Timestep Consumption Time: 0.67783
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 5.27983

Cumulative Model Updates: 11,851
Cumulative Timesteps: 197,762,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 197762724...
Checkpoint 197762724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.39469
Policy Entropy: 1.28432
Value Function Loss: 0.27313

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05327
Policy Update Magnitude: 0.07449
Value Function Update Magnitude: 0.09230

Collected Steps per Second: 11,216.30241
Overall Steps per Second: 9,557.67832

Timestep Collection Time: 4.45976
Timestep Consumption Time: 0.77394
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.23370

Cumulative Model Updates: 11,854
Cumulative Timesteps: 197,812,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.69554
Policy Entropy: 1.27898
Value Function Loss: 0.28922

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.08566

Collected Steps per Second: 11,343.32987
Overall Steps per Second: 9,665.71729

Timestep Collection Time: 4.40964
Timestep Consumption Time: 0.76535
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.17499

Cumulative Model Updates: 11,857
Cumulative Timesteps: 197,862,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 197862766...
Checkpoint 197862766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.50804
Policy Entropy: 1.28563
Value Function Loss: 0.28702

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04907
Policy Update Magnitude: 0.07039
Value Function Update Magnitude: 0.08643

Collected Steps per Second: 11,416.49162
Overall Steps per Second: 9,680.19557

Timestep Collection Time: 4.38191
Timestep Consumption Time: 0.78596
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 5.16787

Cumulative Model Updates: 11,860
Cumulative Timesteps: 197,912,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.79752
Policy Entropy: 1.27991
Value Function Loss: 0.26991

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.07464

Collected Steps per Second: 11,157.10714
Overall Steps per Second: 9,543.60309

Timestep Collection Time: 4.48360
Timestep Consumption Time: 0.75803
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.24163

Cumulative Model Updates: 11,863
Cumulative Timesteps: 197,962,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 197962816...
Checkpoint 197962816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.60974
Policy Entropy: 1.29010
Value Function Loss: 0.26045

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.06318
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 10,532.53008
Overall Steps per Second: 9,160.42841

Timestep Collection Time: 4.74967
Timestep Consumption Time: 0.71143
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.46110

Cumulative Model Updates: 11,866
Cumulative Timesteps: 198,012,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.38760
Policy Entropy: 1.27980
Value Function Loss: 0.26088

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07149
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.05960

Collected Steps per Second: 11,059.64041
Overall Steps per Second: 9,375.43952

Timestep Collection Time: 4.52167
Timestep Consumption Time: 0.81227
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 5.33394

Cumulative Model Updates: 11,869
Cumulative Timesteps: 198,062,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 198062850...
Checkpoint 198062850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.94238
Policy Entropy: 1.28827
Value Function Loss: 0.27214

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.06028

Collected Steps per Second: 11,087.80754
Overall Steps per Second: 9,478.85007

Timestep Collection Time: 4.51180
Timestep Consumption Time: 0.76584
PPO Batch Consumption Time: 0.03995
Total Iteration Time: 5.27764

Cumulative Model Updates: 11,872
Cumulative Timesteps: 198,112,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.40739
Policy Entropy: 1.27834
Value Function Loss: 0.25854

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.05271

Collected Steps per Second: 11,134.14218
Overall Steps per Second: 9,483.79514

Timestep Collection Time: 4.49321
Timestep Consumption Time: 0.78190
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.27510

Cumulative Model Updates: 11,875
Cumulative Timesteps: 198,162,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 198162904...
Checkpoint 198162904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.26083
Policy Entropy: 1.28861
Value Function Loss: 0.26271

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04812
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.05558

Collected Steps per Second: 11,676.99414
Overall Steps per Second: 9,855.93517

Timestep Collection Time: 4.28398
Timestep Consumption Time: 0.79154
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.07552

Cumulative Model Updates: 11,878
Cumulative Timesteps: 198,212,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.45186
Policy Entropy: 1.28120
Value Function Loss: 0.25055

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.06060
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.06156

Collected Steps per Second: 10,627.02259
Overall Steps per Second: 9,262.70673

Timestep Collection Time: 4.70706
Timestep Consumption Time: 0.69331
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.40037

Cumulative Model Updates: 11,881
Cumulative Timesteps: 198,262,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 198262950...
Checkpoint 198262950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.44633
Policy Entropy: 1.28949
Value Function Loss: 0.26709

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04465
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.06092

Collected Steps per Second: 11,098.65378
Overall Steps per Second: 9,371.68403

Timestep Collection Time: 4.50667
Timestep Consumption Time: 0.83047
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 5.33714

Cumulative Model Updates: 11,884
Cumulative Timesteps: 198,312,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.11809
Policy Entropy: 1.28341
Value Function Loss: 0.27427

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05596
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.06398

Collected Steps per Second: 11,325.89137
Overall Steps per Second: 9,662.88249

Timestep Collection Time: 4.41555
Timestep Consumption Time: 0.75993
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.17547

Cumulative Model Updates: 11,887
Cumulative Timesteps: 198,362,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 198362978...
Checkpoint 198362978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.43205
Policy Entropy: 1.29118
Value Function Loss: 0.25730

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05581
Policy Update Magnitude: 0.04341
Value Function Update Magnitude: 0.05958

Collected Steps per Second: 11,841.66627
Overall Steps per Second: 10,051.78155

Timestep Collection Time: 4.22407
Timestep Consumption Time: 0.75216
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 4.97623

Cumulative Model Updates: 11,890
Cumulative Timesteps: 198,412,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.74614
Policy Entropy: 1.28451
Value Function Loss: 0.25345

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04824
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.06864

Collected Steps per Second: 11,706.91980
Overall Steps per Second: 9,936.22474

Timestep Collection Time: 4.27200
Timestep Consumption Time: 0.76130
PPO Batch Consumption Time: 0.03825
Total Iteration Time: 5.03330

Cumulative Model Updates: 11,893
Cumulative Timesteps: 198,463,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 198463010...
Checkpoint 198463010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.45670
Policy Entropy: 1.28684
Value Function Loss: 0.23980

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03622
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.06024

Collected Steps per Second: 11,550.14712
Overall Steps per Second: 10,038.41357

Timestep Collection Time: 4.33137
Timestep Consumption Time: 0.65228
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.98366

Cumulative Model Updates: 11,896
Cumulative Timesteps: 198,513,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.61854
Policy Entropy: 1.27805
Value Function Loss: 0.27080

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05461
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.06670

Collected Steps per Second: 11,737.22582
Overall Steps per Second: 9,895.38872

Timestep Collection Time: 4.26114
Timestep Consumption Time: 0.79313
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.05427

Cumulative Model Updates: 11,899
Cumulative Timesteps: 198,563,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 198563052...
Checkpoint 198563052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.29569
Policy Entropy: 1.28271
Value Function Loss: 0.25831

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03622
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.06122

Collected Steps per Second: 10,656.27359
Overall Steps per Second: 9,123.71118

Timestep Collection Time: 4.69451
Timestep Consumption Time: 0.78856
PPO Batch Consumption Time: 0.03974
Total Iteration Time: 5.48308

Cumulative Model Updates: 11,902
Cumulative Timesteps: 198,613,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.48127
Policy Entropy: 1.27824
Value Function Loss: 0.25889

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.06175
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 11,896.59078
Overall Steps per Second: 9,993.03030

Timestep Collection Time: 4.20339
Timestep Consumption Time: 0.80070
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 5.00409

Cumulative Model Updates: 11,905
Cumulative Timesteps: 198,663,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 198663084...
Checkpoint 198663084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.92420
Policy Entropy: 1.28537
Value Function Loss: 0.23378

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05995
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.06296

Collected Steps per Second: 11,601.28861
Overall Steps per Second: 9,828.00655

Timestep Collection Time: 4.31176
Timestep Consumption Time: 0.77798
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.08974

Cumulative Model Updates: 11,908
Cumulative Timesteps: 198,713,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.94282
Policy Entropy: 1.28262
Value Function Loss: 0.23181

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03925
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.07166

Collected Steps per Second: 11,615.83996
Overall Steps per Second: 10,014.47284

Timestep Collection Time: 4.30705
Timestep Consumption Time: 0.68872
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 4.99577

Cumulative Model Updates: 11,911
Cumulative Timesteps: 198,763,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 198763136...
Checkpoint 198763136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.42875
Policy Entropy: 1.29681
Value Function Loss: 0.24301

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.07838

Collected Steps per Second: 11,494.16938
Overall Steps per Second: 9,800.58810

Timestep Collection Time: 4.35038
Timestep Consumption Time: 0.75176
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.10214

Cumulative Model Updates: 11,914
Cumulative Timesteps: 198,813,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.38145
Policy Entropy: 1.28735
Value Function Loss: 0.25491

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.08549

Collected Steps per Second: 11,409.09875
Overall Steps per Second: 9,652.77645

Timestep Collection Time: 4.38334
Timestep Consumption Time: 0.79755
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.18089

Cumulative Model Updates: 11,917
Cumulative Timesteps: 198,863,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 198863150...
Checkpoint 198863150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.09604
Policy Entropy: 1.29289
Value Function Loss: 0.26640

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06051
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.08126

Collected Steps per Second: 11,112.72991
Overall Steps per Second: 9,387.06363

Timestep Collection Time: 4.50060
Timestep Consumption Time: 0.82737
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.32797

Cumulative Model Updates: 11,920
Cumulative Timesteps: 198,913,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.53913
Policy Entropy: 1.28842
Value Function Loss: 0.25732

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06501
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.07542

Collected Steps per Second: 11,326.25383
Overall Steps per Second: 9,679.83248

Timestep Collection Time: 4.41629
Timestep Consumption Time: 0.75116
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.16744

Cumulative Model Updates: 11,923
Cumulative Timesteps: 198,963,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 198963184...
Checkpoint 198963184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.19928
Policy Entropy: 1.29029
Value Function Loss: 0.24876

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04149
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.06965

Collected Steps per Second: 11,449.36176
Overall Steps per Second: 9,871.83162

Timestep Collection Time: 4.36758
Timestep Consumption Time: 0.69794
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.06552

Cumulative Model Updates: 11,926
Cumulative Timesteps: 199,013,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.93724
Policy Entropy: 1.28640
Value Function Loss: 0.23198

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05783
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.06483

Collected Steps per Second: 11,201.01853
Overall Steps per Second: 9,413.05520

Timestep Collection Time: 4.46495
Timestep Consumption Time: 0.84810
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.31305

Cumulative Model Updates: 11,929
Cumulative Timesteps: 199,063,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 199063202...
Checkpoint 199063202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.20334
Policy Entropy: 1.29424
Value Function Loss: 0.22756

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05871
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.05884

Collected Steps per Second: 11,122.06261
Overall Steps per Second: 9,463.03126

Timestep Collection Time: 4.49629
Timestep Consumption Time: 0.78828
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.28456

Cumulative Model Updates: 11,932
Cumulative Timesteps: 199,113,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.98741
Policy Entropy: 1.28840
Value Function Loss: 0.26067

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05029
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.05653

Collected Steps per Second: 10,909.10946
Overall Steps per Second: 9,178.05145

Timestep Collection Time: 4.58589
Timestep Consumption Time: 0.86494
PPO Batch Consumption Time: 0.03895
Total Iteration Time: 5.45083

Cumulative Model Updates: 11,935
Cumulative Timesteps: 199,163,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 199163238...
Checkpoint 199163238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.43790
Policy Entropy: 1.29289
Value Function Loss: 0.28905

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04659
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.05969

Collected Steps per Second: 10,956.39152
Overall Steps per Second: 9,343.43426

Timestep Collection Time: 4.56355
Timestep Consumption Time: 0.78781
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.35135

Cumulative Model Updates: 11,938
Cumulative Timesteps: 199,213,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.44475
Policy Entropy: 1.28802
Value Function Loss: 0.29319

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04361
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.06338

Collected Steps per Second: 11,241.52203
Overall Steps per Second: 9,653.74910

Timestep Collection Time: 4.44940
Timestep Consumption Time: 0.73180
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 5.18120

Cumulative Model Updates: 11,941
Cumulative Timesteps: 199,263,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 199263256...
Checkpoint 199263256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.74050
Policy Entropy: 1.29192
Value Function Loss: 0.27094

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04185
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.07200

Collected Steps per Second: 11,379.02402
Overall Steps per Second: 9,633.61322

Timestep Collection Time: 4.39616
Timestep Consumption Time: 0.79649
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.19265

Cumulative Model Updates: 11,944
Cumulative Timesteps: 199,313,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.72819
Policy Entropy: 1.28893
Value Function Loss: 0.26016

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04216
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 12,007.43252
Overall Steps per Second: 9,976.74380

Timestep Collection Time: 4.16559
Timestep Consumption Time: 0.84787
PPO Batch Consumption Time: 0.04049
Total Iteration Time: 5.01346

Cumulative Model Updates: 11,947
Cumulative Timesteps: 199,363,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 199363298...
Checkpoint 199363298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.03822
Policy Entropy: 1.28792
Value Function Loss: 0.27677

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05507
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.06574

Collected Steps per Second: 12,415.54184
Overall Steps per Second: 10,298.56535

Timestep Collection Time: 4.02947
Timestep Consumption Time: 0.82830
PPO Batch Consumption Time: 0.04344
Total Iteration Time: 4.85776

Cumulative Model Updates: 11,950
Cumulative Timesteps: 199,413,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.19768
Policy Entropy: 1.29253
Value Function Loss: 0.26236

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03693
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.06415

Collected Steps per Second: 11,731.34204
Overall Steps per Second: 9,856.57948

Timestep Collection Time: 4.26379
Timestep Consumption Time: 0.81099
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 5.07478

Cumulative Model Updates: 11,953
Cumulative Timesteps: 199,463,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 199463346...
Checkpoint 199463346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.08806
Policy Entropy: 1.29472
Value Function Loss: 0.27534

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06014
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.05856

Collected Steps per Second: 11,422.81427
Overall Steps per Second: 9,787.52111

Timestep Collection Time: 4.37756
Timestep Consumption Time: 0.73140
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.10895

Cumulative Model Updates: 11,956
Cumulative Timesteps: 199,513,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.04685
Policy Entropy: 1.28970
Value Function Loss: 0.27457

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.05645

Collected Steps per Second: 12,134.41797
Overall Steps per Second: 10,194.01271

Timestep Collection Time: 4.12232
Timestep Consumption Time: 0.78467
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 4.90700

Cumulative Model Updates: 11,959
Cumulative Timesteps: 199,563,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 199563372...
Checkpoint 199563372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.99227
Policy Entropy: 1.28873
Value Function Loss: 0.28289

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.05519

Collected Steps per Second: 12,224.40946
Overall Steps per Second: 10,305.25390

Timestep Collection Time: 4.09181
Timestep Consumption Time: 0.76202
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.85383

Cumulative Model Updates: 11,962
Cumulative Timesteps: 199,613,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.89984
Policy Entropy: 1.28863
Value Function Loss: 0.26605

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07007
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.06260

Collected Steps per Second: 11,820.52683
Overall Steps per Second: 10,017.19537

Timestep Collection Time: 4.23061
Timestep Consumption Time: 0.76161
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 4.99222

Cumulative Model Updates: 11,965
Cumulative Timesteps: 199,663,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 199663400...
Checkpoint 199663400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.09936
Policy Entropy: 1.28928
Value Function Loss: 0.26472

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04973
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.07141

Collected Steps per Second: 11,271.66774
Overall Steps per Second: 9,616.83224

Timestep Collection Time: 4.43785
Timestep Consumption Time: 0.76365
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 5.20150

Cumulative Model Updates: 11,968
Cumulative Timesteps: 199,713,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.77829
Policy Entropy: 1.29447
Value Function Loss: 0.29444

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.07297

Collected Steps per Second: 10,884.03270
Overall Steps per Second: 9,432.75096

Timestep Collection Time: 4.59389
Timestep Consumption Time: 0.70680
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 5.30068

Cumulative Model Updates: 11,971
Cumulative Timesteps: 199,763,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 199763422...
Checkpoint 199763422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.94800
Policy Entropy: 1.28800
Value Function Loss: 0.29273

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07150
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.06829

Collected Steps per Second: 11,358.99866
Overall Steps per Second: 9,669.88530

Timestep Collection Time: 4.40338
Timestep Consumption Time: 0.76917
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.17255

Cumulative Model Updates: 11,974
Cumulative Timesteps: 199,813,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.42842
Policy Entropy: 1.29258
Value Function Loss: 0.27179

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06300
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.07144

Collected Steps per Second: 11,573.09906
Overall Steps per Second: 9,813.99767

Timestep Collection Time: 4.32209
Timestep Consumption Time: 0.77471
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.09680

Cumulative Model Updates: 11,977
Cumulative Timesteps: 199,863,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 199863460...
Checkpoint 199863460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.31640
Policy Entropy: 1.29225
Value Function Loss: 0.24909

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04822
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.06811

Collected Steps per Second: 11,850.45845
Overall Steps per Second: 10,020.31031

Timestep Collection Time: 4.22009
Timestep Consumption Time: 0.77077
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 4.99086

Cumulative Model Updates: 11,980
Cumulative Timesteps: 199,913,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.65337
Policy Entropy: 1.29188
Value Function Loss: 0.25149

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04835
Policy Update Magnitude: 0.06298
Value Function Update Magnitude: 0.05532

Collected Steps per Second: 11,494.81477
Overall Steps per Second: 9,795.81367

Timestep Collection Time: 4.35101
Timestep Consumption Time: 0.75465
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.10565

Cumulative Model Updates: 11,983
Cumulative Timesteps: 199,963,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 199963484...
Checkpoint 199963484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.53792
Policy Entropy: 1.29594
Value Function Loss: 0.26645

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06306
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.04855

Collected Steps per Second: 10,982.72415
Overall Steps per Second: 9,538.27136

Timestep Collection Time: 4.55461
Timestep Consumption Time: 0.68974
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.24435

Cumulative Model Updates: 11,986
Cumulative Timesteps: 200,013,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.77868
Policy Entropy: 1.29432
Value Function Loss: 0.27226

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05511
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.05788

Collected Steps per Second: 10,921.96038
Overall Steps per Second: 9,342.97974

Timestep Collection Time: 4.58068
Timestep Consumption Time: 0.77414
PPO Batch Consumption Time: 0.03800
Total Iteration Time: 5.35482

Cumulative Model Updates: 11,989
Cumulative Timesteps: 200,063,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 200063536...
Checkpoint 200063536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.03075
Policy Entropy: 1.29610
Value Function Loss: 0.26864

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06535
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.06022

Collected Steps per Second: 11,145.44347
Overall Steps per Second: 9,501.92415

Timestep Collection Time: 4.48721
Timestep Consumption Time: 0.77614
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.26335

Cumulative Model Updates: 11,992
Cumulative Timesteps: 200,113,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.96421
Policy Entropy: 1.29740
Value Function Loss: 0.27848

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07169
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.05500

Collected Steps per Second: 11,772.71431
Overall Steps per Second: 9,984.60148

Timestep Collection Time: 4.24847
Timestep Consumption Time: 0.76085
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.00931

Cumulative Model Updates: 11,995
Cumulative Timesteps: 200,163,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 200163564...
Checkpoint 200163564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.67946
Policy Entropy: 1.29214
Value Function Loss: 0.27272

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.05133

Collected Steps per Second: 11,647.70414
Overall Steps per Second: 9,868.66420

Timestep Collection Time: 4.29372
Timestep Consumption Time: 0.77404
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 5.06776

Cumulative Model Updates: 11,998
Cumulative Timesteps: 200,213,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.75350
Policy Entropy: 1.29086
Value Function Loss: 0.26934

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.04418

Collected Steps per Second: 11,135.45476
Overall Steps per Second: 9,680.13492

Timestep Collection Time: 4.49088
Timestep Consumption Time: 0.67516
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.16604

Cumulative Model Updates: 12,001
Cumulative Timesteps: 200,263,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 200263584...
Checkpoint 200263584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.84252
Policy Entropy: 1.29445
Value Function Loss: 0.25703

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.04889

Collected Steps per Second: 11,237.25220
Overall Steps per Second: 9,516.53267

Timestep Collection Time: 4.45144
Timestep Consumption Time: 0.80488
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.25633

Cumulative Model Updates: 12,004
Cumulative Timesteps: 200,313,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.02793
Policy Entropy: 1.29248
Value Function Loss: 0.28327

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.04413

Collected Steps per Second: 10,826.90732
Overall Steps per Second: 9,325.82855

Timestep Collection Time: 4.61997
Timestep Consumption Time: 0.74363
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 5.36360

Cumulative Model Updates: 12,007
Cumulative Timesteps: 200,363,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 200363626...
Checkpoint 200363626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.90649
Policy Entropy: 1.29338
Value Function Loss: 0.30903

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.04473

Collected Steps per Second: 11,655.46532
Overall Steps per Second: 9,827.28670

Timestep Collection Time: 4.29035
Timestep Consumption Time: 0.79814
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.08848

Cumulative Model Updates: 12,010
Cumulative Timesteps: 200,413,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.94774
Policy Entropy: 1.29354
Value Function Loss: 0.31669

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06346
Policy Update Magnitude: 0.04115
Value Function Update Magnitude: 0.05200

Collected Steps per Second: 11,010.19848
Overall Steps per Second: 9,361.53483

Timestep Collection Time: 4.54197
Timestep Consumption Time: 0.79989
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.34186

Cumulative Model Updates: 12,013
Cumulative Timesteps: 200,463,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 200463640...
Checkpoint 200463640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.63616
Policy Entropy: 1.29010
Value Function Loss: 0.29120

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07237
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.06423

Collected Steps per Second: 11,274.01611
Overall Steps per Second: 9,786.82126

Timestep Collection Time: 4.43711
Timestep Consumption Time: 0.67426
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.11136

Cumulative Model Updates: 12,016
Cumulative Timesteps: 200,513,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.65380
Policy Entropy: 1.29238
Value Function Loss: 0.26588

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04333
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.09020

Collected Steps per Second: 11,656.23933
Overall Steps per Second: 9,877.49247

Timestep Collection Time: 4.29109
Timestep Consumption Time: 0.77274
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 5.06384

Cumulative Model Updates: 12,019
Cumulative Timesteps: 200,563,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 200563682...
Checkpoint 200563682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.37871
Policy Entropy: 1.28695
Value Function Loss: 0.26551

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.07394

Collected Steps per Second: 11,162.96120
Overall Steps per Second: 9,425.61688

Timestep Collection Time: 4.48035
Timestep Consumption Time: 0.82583
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 5.30618

Cumulative Model Updates: 12,022
Cumulative Timesteps: 200,613,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.80082
Policy Entropy: 1.29040
Value Function Loss: 0.27483

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04646
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.06858

Collected Steps per Second: 11,822.35868
Overall Steps per Second: 9,985.20903

Timestep Collection Time: 4.23097
Timestep Consumption Time: 0.77844
PPO Batch Consumption Time: 0.03979
Total Iteration Time: 5.00941

Cumulative Model Updates: 12,025
Cumulative Timesteps: 200,663,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 200663716...
Checkpoint 200663716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.01273
Policy Entropy: 1.29222
Value Function Loss: 0.27789

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05063
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.05943

Collected Steps per Second: 11,454.47792
Overall Steps per Second: 9,743.80630

Timestep Collection Time: 4.36511
Timestep Consumption Time: 0.76636
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 5.13146

Cumulative Model Updates: 12,028
Cumulative Timesteps: 200,713,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.12665
Policy Entropy: 1.28364
Value Function Loss: 0.26352

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07317
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 11,886.22659
Overall Steps per Second: 10,230.17819

Timestep Collection Time: 4.20857
Timestep Consumption Time: 0.68128
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 4.88985

Cumulative Model Updates: 12,031
Cumulative Timesteps: 200,763,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 200763740...
Checkpoint 200763740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.51946
Policy Entropy: 1.28770
Value Function Loss: 0.25083

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.10132

Collected Steps per Second: 11,749.34235
Overall Steps per Second: 9,921.09942

Timestep Collection Time: 4.25607
Timestep Consumption Time: 0.78430
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 5.04037

Cumulative Model Updates: 12,034
Cumulative Timesteps: 200,813,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.16936
Policy Entropy: 1.28553
Value Function Loss: 0.25769

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.10001

Collected Steps per Second: 11,827.37257
Overall Steps per Second: 9,942.54669

Timestep Collection Time: 4.22883
Timestep Consumption Time: 0.80167
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.03050

Cumulative Model Updates: 12,037
Cumulative Timesteps: 200,863,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 200863762...
Checkpoint 200863762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.12127
Policy Entropy: 1.29104
Value Function Loss: 0.27966

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07215
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.08929

Collected Steps per Second: 11,111.15579
Overall Steps per Second: 9,445.61289

Timestep Collection Time: 4.50160
Timestep Consumption Time: 0.79377
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.29537

Cumulative Model Updates: 12,040
Cumulative Timesteps: 200,913,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.06413
Policy Entropy: 1.29134
Value Function Loss: 0.28491

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05621
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.07677

Collected Steps per Second: 11,407.21265
Overall Steps per Second: 9,550.42874

Timestep Collection Time: 4.38372
Timestep Consumption Time: 0.85228
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 5.23600

Cumulative Model Updates: 12,043
Cumulative Timesteps: 200,963,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 200963786...
Checkpoint 200963786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.82232
Policy Entropy: 1.29390
Value Function Loss: 0.30115

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04737
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.07373

Collected Steps per Second: 11,434.02661
Overall Steps per Second: 9,798.24212

Timestep Collection Time: 4.37519
Timestep Consumption Time: 0.73042
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 5.10561

Cumulative Model Updates: 12,046
Cumulative Timesteps: 201,013,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.14001
Policy Entropy: 1.29398
Value Function Loss: 0.27330

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04583
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.06814

Collected Steps per Second: 11,961.25428
Overall Steps per Second: 9,931.86949

Timestep Collection Time: 4.18217
Timestep Consumption Time: 0.85455
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 5.03672

Cumulative Model Updates: 12,049
Cumulative Timesteps: 201,063,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 201063836...
Checkpoint 201063836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.27303
Policy Entropy: 1.29425
Value Function Loss: 0.27535

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05805
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.06818

Collected Steps per Second: 11,488.93554
Overall Steps per Second: 9,733.61167

Timestep Collection Time: 4.35271
Timestep Consumption Time: 0.78495
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.13766

Cumulative Model Updates: 12,052
Cumulative Timesteps: 201,113,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.75364
Policy Entropy: 1.29182
Value Function Loss: 0.25281

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06407
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.06309

Collected Steps per Second: 11,261.91815
Overall Steps per Second: 9,735.75062

Timestep Collection Time: 4.44010
Timestep Consumption Time: 0.69603
PPO Batch Consumption Time: 0.03995
Total Iteration Time: 5.13612

Cumulative Model Updates: 12,055
Cumulative Timesteps: 201,163,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 201163848...
Checkpoint 201163848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.42134
Policy Entropy: 1.28526
Value Function Loss: 0.26560

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.06205

Collected Steps per Second: 11,050.92747
Overall Steps per Second: 9,320.96451

Timestep Collection Time: 4.52469
Timestep Consumption Time: 0.83978
PPO Batch Consumption Time: 0.03851
Total Iteration Time: 5.36447

Cumulative Model Updates: 12,058
Cumulative Timesteps: 201,213,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.63218
Policy Entropy: 1.28671
Value Function Loss: 0.26321

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.06015
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.07119

Collected Steps per Second: 11,505.74616
Overall Steps per Second: 9,670.49259

Timestep Collection Time: 4.34757
Timestep Consumption Time: 0.82508
PPO Batch Consumption Time: 0.04016
Total Iteration Time: 5.17264

Cumulative Model Updates: 12,061
Cumulative Timesteps: 201,263,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 201263872...
Checkpoint 201263872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.58190
Policy Entropy: 1.28578
Value Function Loss: 0.27115

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.06559

Collected Steps per Second: 11,718.20233
Overall Steps per Second: 9,753.90496

Timestep Collection Time: 4.26738
Timestep Consumption Time: 0.85939
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 5.12677

Cumulative Model Updates: 12,064
Cumulative Timesteps: 201,313,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.18416
Policy Entropy: 1.29123
Value Function Loss: 0.28319

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05243
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 11,462.35275
Overall Steps per Second: 9,739.23073

Timestep Collection Time: 4.36211
Timestep Consumption Time: 0.77177
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.13388

Cumulative Model Updates: 12,067
Cumulative Timesteps: 201,363,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 201363878...
Checkpoint 201363878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.82971
Policy Entropy: 1.28709
Value Function Loss: 0.29305

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05107
Policy Update Magnitude: 0.06364
Value Function Update Magnitude: 0.08169

Collected Steps per Second: 11,279.98598
Overall Steps per Second: 9,728.16478

Timestep Collection Time: 4.43529
Timestep Consumption Time: 0.70751
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 5.14280

Cumulative Model Updates: 12,070
Cumulative Timesteps: 201,413,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.05379
Policy Entropy: 1.28588
Value Function Loss: 0.29755

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04453
Policy Update Magnitude: 0.07155
Value Function Update Magnitude: 0.07294

Collected Steps per Second: 11,247.26990
Overall Steps per Second: 9,518.57856

Timestep Collection Time: 4.44837
Timestep Consumption Time: 0.80788
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.25625

Cumulative Model Updates: 12,073
Cumulative Timesteps: 201,463,940

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 201463940...
Checkpoint 201463940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.62842
Policy Entropy: 1.28918
Value Function Loss: 0.27640

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05104
Policy Update Magnitude: 0.07279
Value Function Update Magnitude: 0.06988

Collected Steps per Second: 10,790.86063
Overall Steps per Second: 9,139.02353

Timestep Collection Time: 4.63392
Timestep Consumption Time: 0.83756
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 5.47148

Cumulative Model Updates: 12,076
Cumulative Timesteps: 201,513,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.16610
Policy Entropy: 1.28957
Value Function Loss: 0.27306

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.04723
Policy Update Magnitude: 0.07281
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 11,237.99595
Overall Steps per Second: 9,646.05730

Timestep Collection Time: 4.45168
Timestep Consumption Time: 0.73468
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.18637

Cumulative Model Updates: 12,079
Cumulative Timesteps: 201,563,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 201563972...
Checkpoint 201563972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.10352
Policy Entropy: 1.28820
Value Function Loss: 0.26181

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04638
Policy Update Magnitude: 0.07259
Value Function Update Magnitude: 0.06743

Collected Steps per Second: 11,052.75332
Overall Steps per Second: 9,358.36780

Timestep Collection Time: 4.52485
Timestep Consumption Time: 0.81925
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.34409

Cumulative Model Updates: 12,082
Cumulative Timesteps: 201,613,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.53449
Policy Entropy: 1.28811
Value Function Loss: 0.27930

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04013
Policy Update Magnitude: 0.06806
Value Function Update Magnitude: 0.05715

Collected Steps per Second: 11,158.28606
Overall Steps per Second: 9,623.76347

Timestep Collection Time: 4.48133
Timestep Consumption Time: 0.71455
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 5.19589

Cumulative Model Updates: 12,085
Cumulative Timesteps: 201,663,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 201663988...
Checkpoint 201663988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.45193
Policy Entropy: 1.28926
Value Function Loss: 0.25624

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04215
Policy Update Magnitude: 0.06833
Value Function Update Magnitude: 0.06926

Collected Steps per Second: 12,285.07322
Overall Steps per Second: 10,358.93900

Timestep Collection Time: 4.07242
Timestep Consumption Time: 0.75722
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 4.82965

Cumulative Model Updates: 12,088
Cumulative Timesteps: 201,714,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.77630
Policy Entropy: 1.28837
Value Function Loss: 0.27018

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03967
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.07614

Collected Steps per Second: 12,211.38573
Overall Steps per Second: 10,284.57353

Timestep Collection Time: 4.09454
Timestep Consumption Time: 0.76711
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 4.86165

Cumulative Model Updates: 12,091
Cumulative Timesteps: 201,764,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 201764018...
Checkpoint 201764018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.85060
Policy Entropy: 1.28971
Value Function Loss: 0.26808

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04740
Policy Update Magnitude: 0.06805
Value Function Update Magnitude: 0.06092

Collected Steps per Second: 11,752.44183
Overall Steps per Second: 9,814.30919

Timestep Collection Time: 4.25529
Timestep Consumption Time: 0.84034
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.09562

Cumulative Model Updates: 12,094
Cumulative Timesteps: 201,814,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.79911
Policy Entropy: 1.28800
Value Function Loss: 0.30329

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.06144
Value Function Update Magnitude: 0.06829

Collected Steps per Second: 11,937.33702
Overall Steps per Second: 10,086.92568

Timestep Collection Time: 4.19072
Timestep Consumption Time: 0.76877
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 4.95949

Cumulative Model Updates: 12,097
Cumulative Timesteps: 201,864,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 201864054...
Checkpoint 201864054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.42049
Policy Entropy: 1.29096
Value Function Loss: 0.28905

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06881
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.06801

Collected Steps per Second: 12,071.34206
Overall Steps per Second: 10,343.60221

Timestep Collection Time: 4.14403
Timestep Consumption Time: 0.69220
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.83623

Cumulative Model Updates: 12,100
Cumulative Timesteps: 201,914,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.41305
Policy Entropy: 1.29092
Value Function Loss: 0.28531

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.05656
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.05822

Collected Steps per Second: 12,267.25129
Overall Steps per Second: 10,278.05225

Timestep Collection Time: 4.07818
Timestep Consumption Time: 0.78928
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 4.86746

Cumulative Model Updates: 12,103
Cumulative Timesteps: 201,964,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 201964106...
Checkpoint 201964106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.05831
Policy Entropy: 1.29010
Value Function Loss: 0.25067

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06081
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.05249

Collected Steps per Second: 11,516.45795
Overall Steps per Second: 9,770.46078

Timestep Collection Time: 4.34352
Timestep Consumption Time: 0.77619
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.11972

Cumulative Model Updates: 12,106
Cumulative Timesteps: 202,014,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.51224
Policy Entropy: 1.29319
Value Function Loss: 0.23930

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05016
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.05595

Collected Steps per Second: 11,558.74963
Overall Steps per Second: 9,724.64247

Timestep Collection Time: 4.32573
Timestep Consumption Time: 0.81585
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 5.14158

Cumulative Model Updates: 12,109
Cumulative Timesteps: 202,064,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 202064128...
Checkpoint 202064128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.35225
Policy Entropy: 1.29251
Value Function Loss: 0.23456

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06353
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.06297

Collected Steps per Second: 10,854.52805
Overall Steps per Second: 9,275.89801

Timestep Collection Time: 4.60656
Timestep Consumption Time: 0.78397
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.39053

Cumulative Model Updates: 12,112
Cumulative Timesteps: 202,114,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.38907
Policy Entropy: 1.29532
Value Function Loss: 0.29221

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07569
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.05760

Collected Steps per Second: 11,291.27391
Overall Steps per Second: 9,571.84564

Timestep Collection Time: 4.42944
Timestep Consumption Time: 0.79568
PPO Batch Consumption Time: 0.03992
Total Iteration Time: 5.22512

Cumulative Model Updates: 12,115
Cumulative Timesteps: 202,164,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 202164144...
Checkpoint 202164144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.50872
Policy Entropy: 1.29053
Value Function Loss: 0.29488

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.05399

Collected Steps per Second: 11,520.10892
Overall Steps per Second: 9,756.96682

Timestep Collection Time: 4.34128
Timestep Consumption Time: 0.78449
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.12577

Cumulative Model Updates: 12,118
Cumulative Timesteps: 202,214,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.48425
Policy Entropy: 1.28979
Value Function Loss: 0.31417

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05627
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.04770

Collected Steps per Second: 11,041.90625
Overall Steps per Second: 9,418.53455

Timestep Collection Time: 4.53056
Timestep Consumption Time: 0.78088
PPO Batch Consumption Time: 0.03949
Total Iteration Time: 5.31144

Cumulative Model Updates: 12,121
Cumulative Timesteps: 202,264,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 202264182...
Checkpoint 202264182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.63578
Policy Entropy: 1.29170
Value Function Loss: 0.27179

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05867
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.04744

Collected Steps per Second: 11,575.23945
Overall Steps per Second: 9,863.09629

Timestep Collection Time: 4.32026
Timestep Consumption Time: 0.74996
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.07021

Cumulative Model Updates: 12,124
Cumulative Timesteps: 202,314,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.93890
Policy Entropy: 1.29670
Value Function Loss: 0.30180

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04490
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.04539

Collected Steps per Second: 10,854.04607
Overall Steps per Second: 9,288.68138

Timestep Collection Time: 4.60805
Timestep Consumption Time: 0.77657
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.38462

Cumulative Model Updates: 12,127
Cumulative Timesteps: 202,364,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 202364206...
Checkpoint 202364206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.20419
Policy Entropy: 1.28973
Value Function Loss: 0.30209

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.05050

Collected Steps per Second: 11,068.01230
Overall Steps per Second: 9,523.32414

Timestep Collection Time: 4.51951
Timestep Consumption Time: 0.73307
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.25258

Cumulative Model Updates: 12,130
Cumulative Timesteps: 202,414,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.77575
Policy Entropy: 1.29142
Value Function Loss: 0.33622

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.04979

Collected Steps per Second: 11,396.05008
Overall Steps per Second: 9,661.70942

Timestep Collection Time: 4.38977
Timestep Consumption Time: 0.78799
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 5.17776

Cumulative Model Updates: 12,133
Cumulative Timesteps: 202,464,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 202464254...
Checkpoint 202464254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.79636
Policy Entropy: 1.29130
Value Function Loss: 0.32735

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.04039
Value Function Update Magnitude: 0.04537

Collected Steps per Second: 11,462.34579
Overall Steps per Second: 9,811.17470

Timestep Collection Time: 4.36490
Timestep Consumption Time: 0.73459
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.09949

Cumulative Model Updates: 12,136
Cumulative Timesteps: 202,514,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.76157
Policy Entropy: 1.28982
Value Function Loss: 0.31997

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.04473

Collected Steps per Second: 11,622.19869
Overall Steps per Second: 9,807.86985

Timestep Collection Time: 4.30280
Timestep Consumption Time: 0.79596
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.09876

Cumulative Model Updates: 12,139
Cumulative Timesteps: 202,564,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 202564294...
Checkpoint 202564294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.31094
Policy Entropy: 1.29107
Value Function Loss: 0.29371

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.04019
Value Function Update Magnitude: 0.04658

Collected Steps per Second: 11,267.43021
Overall Steps per Second: 9,629.65754

Timestep Collection Time: 4.43846
Timestep Consumption Time: 0.75487
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.19333

Cumulative Model Updates: 12,142
Cumulative Timesteps: 202,614,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.91062
Policy Entropy: 1.29166
Value Function Loss: 0.29457

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07752
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.04895

Collected Steps per Second: 10,821.60274
Overall Steps per Second: 9,379.51635

Timestep Collection Time: 4.62298
Timestep Consumption Time: 0.71078
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.33375

Cumulative Model Updates: 12,145
Cumulative Timesteps: 202,664,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 202664332...
Checkpoint 202664332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.68814
Policy Entropy: 1.28957
Value Function Loss: 0.30380

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.05158

Collected Steps per Second: 11,036.77893
Overall Steps per Second: 9,322.39959

Timestep Collection Time: 4.53049
Timestep Consumption Time: 0.83315
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.36364

Cumulative Model Updates: 12,148
Cumulative Timesteps: 202,714,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.86444
Policy Entropy: 1.28737
Value Function Loss: 0.29360

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05150
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.05341

Collected Steps per Second: 11,028.20152
Overall Steps per Second: 9,475.04780

Timestep Collection Time: 4.53510
Timestep Consumption Time: 0.74340
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.27850

Cumulative Model Updates: 12,151
Cumulative Timesteps: 202,764,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 202764348...
Checkpoint 202764348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.50322
Policy Entropy: 1.28277
Value Function Loss: 0.29702

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06500
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.05017

Collected Steps per Second: 11,540.24090
Overall Steps per Second: 9,746.06952

Timestep Collection Time: 4.33301
Timestep Consumption Time: 0.79767
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.13068

Cumulative Model Updates: 12,154
Cumulative Timesteps: 202,814,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.72764
Policy Entropy: 1.28285
Value Function Loss: 0.29659

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03640
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.05242

Collected Steps per Second: 11,691.00223
Overall Steps per Second: 9,941.97110

Timestep Collection Time: 4.27679
Timestep Consumption Time: 0.75239
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 5.02918

Cumulative Model Updates: 12,157
Cumulative Timesteps: 202,864,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 202864352...
Checkpoint 202864352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.43179
Policy Entropy: 1.28206
Value Function Loss: 0.31040

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.04105
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.05346

Collected Steps per Second: 11,645.21019
Overall Steps per Second: 10,061.06302

Timestep Collection Time: 4.29602
Timestep Consumption Time: 0.67642
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.97244

Cumulative Model Updates: 12,160
Cumulative Timesteps: 202,914,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.43241
Policy Entropy: 1.28350
Value Function Loss: 0.29332

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04205
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.05643

Collected Steps per Second: 10,965.96070
Overall Steps per Second: 9,270.53287

Timestep Collection Time: 4.55993
Timestep Consumption Time: 0.83394
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 5.39386

Cumulative Model Updates: 12,163
Cumulative Timesteps: 202,964,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 202964384...
Checkpoint 202964384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.84265
Policy Entropy: 1.28394
Value Function Loss: 0.27288

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04984
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.06432

Collected Steps per Second: 10,592.01266
Overall Steps per Second: 7,652.48731

Timestep Collection Time: 4.72262
Timestep Consumption Time: 1.81408
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 6.53670

Cumulative Model Updates: 12,166
Cumulative Timesteps: 203,014,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.80072
Policy Entropy: 1.28445
Value Function Loss: 0.26476

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04871
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.06172

Collected Steps per Second: 7,867.98284
Overall Steps per Second: 6,912.49480

Timestep Collection Time: 6.35817
Timestep Consumption Time: 0.87887
PPO Batch Consumption Time: 0.04022
Total Iteration Time: 7.23704

Cumulative Model Updates: 12,169
Cumulative Timesteps: 203,064,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 203064432...
Checkpoint 203064432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.61581
Policy Entropy: 1.28507
Value Function Loss: 0.28201

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04643
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.07510

Collected Steps per Second: 9,812.83045
Overall Steps per Second: 8,415.95879

Timestep Collection Time: 5.09802
Timestep Consumption Time: 0.84616
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 5.94418

Cumulative Model Updates: 12,172
Cumulative Timesteps: 203,114,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.97506
Policy Entropy: 1.28481
Value Function Loss: 0.30102

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.07636

Collected Steps per Second: 10,842.26935
Overall Steps per Second: 9,360.62930

Timestep Collection Time: 4.61306
Timestep Consumption Time: 0.73017
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.34323

Cumulative Model Updates: 12,175
Cumulative Timesteps: 203,164,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 203164474...
Checkpoint 203164474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.50971
Policy Entropy: 1.28827
Value Function Loss: 0.29153

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04981
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.07533

Collected Steps per Second: 10,294.12906
Overall Steps per Second: 8,803.72396

Timestep Collection Time: 4.85947
Timestep Consumption Time: 0.82267
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.68214

Cumulative Model Updates: 12,178
Cumulative Timesteps: 203,214,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.14357
Policy Entropy: 1.28507
Value Function Loss: 0.26905

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05670
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.07400

Collected Steps per Second: 11,157.88745
Overall Steps per Second: 9,421.83281

Timestep Collection Time: 4.48113
Timestep Consumption Time: 0.82569
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.30682

Cumulative Model Updates: 12,181
Cumulative Timesteps: 203,264,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 203264498...
Checkpoint 203264498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.45726
Policy Entropy: 1.28464
Value Function Loss: 0.23975

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04251
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.08192

Collected Steps per Second: 11,518.54756
Overall Steps per Second: 9,635.40991

Timestep Collection Time: 4.34204
Timestep Consumption Time: 0.84861
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 5.19065

Cumulative Model Updates: 12,184
Cumulative Timesteps: 203,314,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.95615
Policy Entropy: 1.28013
Value Function Loss: 0.24743

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06877
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.07989

Collected Steps per Second: 11,486.07536
Overall Steps per Second: 9,787.25469

Timestep Collection Time: 4.35466
Timestep Consumption Time: 0.75586
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.11052

Cumulative Model Updates: 12,187
Cumulative Timesteps: 203,364,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 203364530...
Checkpoint 203364530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.88387
Policy Entropy: 1.28795
Value Function Loss: 0.23883

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04901
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.06634

Collected Steps per Second: 11,295.73683
Overall Steps per Second: 9,702.69304

Timestep Collection Time: 4.42787
Timestep Consumption Time: 0.72699
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.15486

Cumulative Model Updates: 12,190
Cumulative Timesteps: 203,414,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.49814
Policy Entropy: 1.28565
Value Function Loss: 0.24794

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05196
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.05441

Collected Steps per Second: 10,684.71561
Overall Steps per Second: 9,067.21867

Timestep Collection Time: 4.68220
Timestep Consumption Time: 0.83526
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 5.51746

Cumulative Model Updates: 12,193
Cumulative Timesteps: 203,464,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 203464574...
Checkpoint 203464574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.72269
Policy Entropy: 1.28885
Value Function Loss: 0.24359

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06160
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.04755

Collected Steps per Second: 11,079.75692
Overall Steps per Second: 9,479.40217

Timestep Collection Time: 4.51310
Timestep Consumption Time: 0.76192
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.27502

Cumulative Model Updates: 12,196
Cumulative Timesteps: 203,514,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.42305
Policy Entropy: 1.28238
Value Function Loss: 0.26003

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06056
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.06316

Collected Steps per Second: 11,279.70863
Overall Steps per Second: 9,609.86407

Timestep Collection Time: 4.43433
Timestep Consumption Time: 0.77053
PPO Batch Consumption Time: 0.04355
Total Iteration Time: 5.20486

Cumulative Model Updates: 12,199
Cumulative Timesteps: 203,564,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 203564596...
Checkpoint 203564596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.60170
Policy Entropy: 1.28522
Value Function Loss: 0.28666

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05816
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.05854

Collected Steps per Second: 11,343.94544
Overall Steps per Second: 9,545.25398

Timestep Collection Time: 4.40887
Timestep Consumption Time: 0.83080
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.23967

Cumulative Model Updates: 12,202
Cumulative Timesteps: 203,614,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.98838
Policy Entropy: 1.28395
Value Function Loss: 0.32318

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04721
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.04905

Collected Steps per Second: 11,060.18284
Overall Steps per Second: 9,589.46027

Timestep Collection Time: 4.52307
Timestep Consumption Time: 0.69370
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.21677

Cumulative Model Updates: 12,205
Cumulative Timesteps: 203,664,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 203664636...
Checkpoint 203664636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.49490
Policy Entropy: 1.28710
Value Function Loss: 0.31857

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04973
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.04804

Collected Steps per Second: 11,357.79634
Overall Steps per Second: 9,580.22836

Timestep Collection Time: 4.40261
Timestep Consumption Time: 0.81689
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.21950

Cumulative Model Updates: 12,208
Cumulative Timesteps: 203,714,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.64651
Policy Entropy: 1.28314
Value Function Loss: 0.28369

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04485
Policy Update Magnitude: 0.06244
Value Function Update Magnitude: 0.04527

Collected Steps per Second: 10,825.15368
Overall Steps per Second: 9,262.01628

Timestep Collection Time: 4.61998
Timestep Consumption Time: 0.77971
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.39969

Cumulative Model Updates: 12,211
Cumulative Timesteps: 203,764,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 203764652...
Checkpoint 203764652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.51000
Policy Entropy: 1.28720
Value Function Loss: 0.25112

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03883
Policy Update Magnitude: 0.06303
Value Function Update Magnitude: 0.04465

Collected Steps per Second: 10,941.12724
Overall Steps per Second: 9,454.49885

Timestep Collection Time: 4.57174
Timestep Consumption Time: 0.71886
PPO Batch Consumption Time: 0.03804
Total Iteration Time: 5.29060

Cumulative Model Updates: 12,214
Cumulative Timesteps: 203,814,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.12276
Policy Entropy: 1.28857
Value Function Loss: 0.24150

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06105
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.05051

Collected Steps per Second: 10,902.09102
Overall Steps per Second: 9,297.52012

Timestep Collection Time: 4.58646
Timestep Consumption Time: 0.79153
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 5.37799

Cumulative Model Updates: 12,217
Cumulative Timesteps: 203,864,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 203864674...
Checkpoint 203864674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.98933
Policy Entropy: 1.28406
Value Function Loss: 0.24904

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05546
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.04647

Collected Steps per Second: 10,924.67573
Overall Steps per Second: 9,411.61821

Timestep Collection Time: 4.57734
Timestep Consumption Time: 0.73588
PPO Batch Consumption Time: 0.03959
Total Iteration Time: 5.31322

Cumulative Model Updates: 12,220
Cumulative Timesteps: 203,914,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.94804
Policy Entropy: 1.28277
Value Function Loss: 0.24751

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05605
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.04555

Collected Steps per Second: 12,343.89357
Overall Steps per Second: 10,296.17058

Timestep Collection Time: 4.05059
Timestep Consumption Time: 0.80559
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 4.85617

Cumulative Model Updates: 12,223
Cumulative Timesteps: 203,964,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 203964680...
Checkpoint 203964680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.66652
Policy Entropy: 1.27933
Value Function Loss: 0.26769

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.06512

Collected Steps per Second: 12,506.94514
Overall Steps per Second: 10,488.12267

Timestep Collection Time: 3.99794
Timestep Consumption Time: 0.76955
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 4.76749

Cumulative Model Updates: 12,226
Cumulative Timesteps: 204,014,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.98469
Policy Entropy: 1.28315
Value Function Loss: 0.29264

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.05017
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.05984

Collected Steps per Second: 11,845.74793
Overall Steps per Second: 9,922.78944

Timestep Collection Time: 4.22160
Timestep Consumption Time: 0.81811
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.03971

Cumulative Model Updates: 12,229
Cumulative Timesteps: 204,064,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 204064690...
Checkpoint 204064690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.62041
Policy Entropy: 1.28461
Value Function Loss: 0.28042

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04575
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.04839

Collected Steps per Second: 11,764.00807
Overall Steps per Second: 9,798.66851

Timestep Collection Time: 4.25195
Timestep Consumption Time: 0.85282
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.10478

Cumulative Model Updates: 12,232
Cumulative Timesteps: 204,114,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.00399
Policy Entropy: 1.28212
Value Function Loss: 0.28233

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05177
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.04071

Collected Steps per Second: 11,979.11681
Overall Steps per Second: 10,006.26127

Timestep Collection Time: 4.17477
Timestep Consumption Time: 0.82311
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 4.99787

Cumulative Model Updates: 12,235
Cumulative Timesteps: 204,164,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 204164720...
Checkpoint 204164720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.71170
Policy Entropy: 1.28217
Value Function Loss: 0.27680

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05398
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.03645

Collected Steps per Second: 12,088.19511
Overall Steps per Second: 10,145.40263

Timestep Collection Time: 4.13858
Timestep Consumption Time: 0.79252
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 4.93110

Cumulative Model Updates: 12,238
Cumulative Timesteps: 204,214,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.65432
Policy Entropy: 1.28336
Value Function Loss: 0.26230

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05090
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.04153

Collected Steps per Second: 11,593.64994
Overall Steps per Second: 9,733.13699

Timestep Collection Time: 4.31512
Timestep Consumption Time: 0.82485
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.13997

Cumulative Model Updates: 12,241
Cumulative Timesteps: 204,264,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 204264776...
Checkpoint 204264776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.41755
Policy Entropy: 1.28085
Value Function Loss: 0.26238

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05690
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.04367

Collected Steps per Second: 11,514.29039
Overall Steps per Second: 9,587.10671

Timestep Collection Time: 4.34243
Timestep Consumption Time: 0.87291
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.21534

Cumulative Model Updates: 12,244
Cumulative Timesteps: 204,314,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.24946
Policy Entropy: 1.27938
Value Function Loss: 0.23876

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05494
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.04859

Collected Steps per Second: 10,865.81576
Overall Steps per Second: 9,292.41956

Timestep Collection Time: 4.60269
Timestep Consumption Time: 0.77933
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.38202

Cumulative Model Updates: 12,247
Cumulative Timesteps: 204,364,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 204364788...
Checkpoint 204364788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.90336
Policy Entropy: 1.27788
Value Function Loss: 0.27131

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05837
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.05006

Collected Steps per Second: 10,937.78241
Overall Steps per Second: 9,458.47873

Timestep Collection Time: 4.57222
Timestep Consumption Time: 0.71509
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 5.28732

Cumulative Model Updates: 12,250
Cumulative Timesteps: 204,414,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.05673
Policy Entropy: 1.28224
Value Function Loss: 0.26366

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05238
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.05847

Collected Steps per Second: 11,494.80024
Overall Steps per Second: 9,693.97666

Timestep Collection Time: 4.35101
Timestep Consumption Time: 0.80828
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.15929

Cumulative Model Updates: 12,253
Cumulative Timesteps: 204,464,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 204464812...
Checkpoint 204464812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.59287
Policy Entropy: 1.28309
Value Function Loss: 0.28783

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05779
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.06261

Collected Steps per Second: 11,272.59717
Overall Steps per Second: 9,622.15971

Timestep Collection Time: 4.43749
Timestep Consumption Time: 0.76114
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 5.19863

Cumulative Model Updates: 12,256
Cumulative Timesteps: 204,514,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.71172
Policy Entropy: 1.28372
Value Function Loss: 0.28817

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04585
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 11,639.89998
Overall Steps per Second: 9,793.64997

Timestep Collection Time: 4.29815
Timestep Consumption Time: 0.81027
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 5.10841

Cumulative Model Updates: 12,259
Cumulative Timesteps: 204,564,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 204564864...
Checkpoint 204564864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.55928
Policy Entropy: 1.27949
Value Function Loss: 0.28778

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04609
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.05986

Collected Steps per Second: 11,317.67446
Overall Steps per Second: 9,414.04832

Timestep Collection Time: 4.41999
Timestep Consumption Time: 0.89377
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.31376

Cumulative Model Updates: 12,262
Cumulative Timesteps: 204,614,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.46011
Policy Entropy: 1.28594
Value Function Loss: 0.26078

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05371
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.04771

Collected Steps per Second: 11,571.19184
Overall Steps per Second: 9,975.29133

Timestep Collection Time: 4.32246
Timestep Consumption Time: 0.69153
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.01399

Cumulative Model Updates: 12,265
Cumulative Timesteps: 204,664,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 204664904...
Checkpoint 204664904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.85475
Policy Entropy: 1.28187
Value Function Loss: 0.25505

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06535
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.04062

Collected Steps per Second: 10,940.53744
Overall Steps per Second: 9,344.82760

Timestep Collection Time: 4.57016
Timestep Consumption Time: 0.78039
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.35055

Cumulative Model Updates: 12,268
Cumulative Timesteps: 204,714,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.43182
Policy Entropy: 1.28420
Value Function Loss: 0.26938

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03791
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.05474

Collected Steps per Second: 10,886.72892
Overall Steps per Second: 9,359.94539

Timestep Collection Time: 4.59514
Timestep Consumption Time: 0.74955
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.34469

Cumulative Model Updates: 12,271
Cumulative Timesteps: 204,764,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 204764930...
Checkpoint 204764930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.02583
Policy Entropy: 1.27966
Value Function Loss: 0.26544

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03896
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.06176

Collected Steps per Second: 11,675.88700
Overall Steps per Second: 9,919.64906

Timestep Collection Time: 4.28233
Timestep Consumption Time: 0.75817
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 5.04050

Cumulative Model Updates: 12,274
Cumulative Timesteps: 204,814,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.43585
Policy Entropy: 1.28424
Value Function Loss: 0.26441

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04712
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.06282

Collected Steps per Second: 10,903.47517
Overall Steps per Second: 9,256.44779

Timestep Collection Time: 4.58808
Timestep Consumption Time: 0.81637
PPO Batch Consumption Time: 0.03761
Total Iteration Time: 5.40445

Cumulative Model Updates: 12,277
Cumulative Timesteps: 204,864,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 204864956...
Checkpoint 204864956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.86849
Policy Entropy: 1.27566
Value Function Loss: 0.24292

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.06514

Collected Steps per Second: 10,705.85830
Overall Steps per Second: 9,341.56392

Timestep Collection Time: 4.67221
Timestep Consumption Time: 0.68236
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.35456

Cumulative Model Updates: 12,280
Cumulative Timesteps: 204,914,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.48597
Policy Entropy: 1.27947
Value Function Loss: 0.24112

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06151
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.06808

Collected Steps per Second: 10,714.30041
Overall Steps per Second: 9,149.30508

Timestep Collection Time: 4.66759
Timestep Consumption Time: 0.79840
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.46599

Cumulative Model Updates: 12,283
Cumulative Timesteps: 204,964,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 204964986...
Checkpoint 204964986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.01404
Policy Entropy: 1.27723
Value Function Loss: 0.23411

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04898
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.06441

Collected Steps per Second: 10,950.28631
Overall Steps per Second: 9,355.10821

Timestep Collection Time: 4.56627
Timestep Consumption Time: 0.77861
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.34489

Cumulative Model Updates: 12,286
Cumulative Timesteps: 205,014,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.82736
Policy Entropy: 1.27749
Value Function Loss: 0.23526

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05088
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.07608

Collected Steps per Second: 10,812.35483
Overall Steps per Second: 9,241.49095

Timestep Collection Time: 4.62674
Timestep Consumption Time: 0.78645
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 5.41320

Cumulative Model Updates: 12,289
Cumulative Timesteps: 205,065,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 205065014...
Checkpoint 205065014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.93818
Policy Entropy: 1.28005
Value Function Loss: 0.23452

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05027
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.06823

Collected Steps per Second: 11,560.32251
Overall Steps per Second: 9,759.43894

Timestep Collection Time: 4.32670
Timestep Consumption Time: 0.79839
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 5.12509

Cumulative Model Updates: 12,292
Cumulative Timesteps: 205,115,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.62532
Policy Entropy: 1.27615
Value Function Loss: 0.22748

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06175
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.07505

Collected Steps per Second: 11,287.38136
Overall Steps per Second: 9,770.28711

Timestep Collection Time: 4.43150
Timestep Consumption Time: 0.68811
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.11960

Cumulative Model Updates: 12,295
Cumulative Timesteps: 205,165,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 205165052...
Checkpoint 205165052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.41362
Policy Entropy: 1.28137
Value Function Loss: 0.25643

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05392
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.08830

Collected Steps per Second: 10,935.28317
Overall Steps per Second: 9,368.12606

Timestep Collection Time: 4.57254
Timestep Consumption Time: 0.76492
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 5.33746

Cumulative Model Updates: 12,298
Cumulative Timesteps: 205,215,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.79627
Policy Entropy: 1.27772
Value Function Loss: 0.27330

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05677
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.08750

Collected Steps per Second: 11,115.80374
Overall Steps per Second: 9,367.80271

Timestep Collection Time: 4.50044
Timestep Consumption Time: 0.83977
PPO Batch Consumption Time: 0.04504
Total Iteration Time: 5.34021

Cumulative Model Updates: 12,301
Cumulative Timesteps: 205,265,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 205265080...
Checkpoint 205265080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.64841
Policy Entropy: 1.27689
Value Function Loss: 0.29026

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04776
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.08666

Collected Steps per Second: 11,776.27110
Overall Steps per Second: 9,950.61231

Timestep Collection Time: 4.24600
Timestep Consumption Time: 0.77902
PPO Batch Consumption Time: 0.03887
Total Iteration Time: 5.02502

Cumulative Model Updates: 12,304
Cumulative Timesteps: 205,315,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.69859
Policy Entropy: 1.27836
Value Function Loss: 0.27680

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05208
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.07452

Collected Steps per Second: 11,486.73977
Overall Steps per Second: 9,655.17311

Timestep Collection Time: 4.35546
Timestep Consumption Time: 0.82622
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.18168

Cumulative Model Updates: 12,307
Cumulative Timesteps: 205,365,112

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 205365112...
Checkpoint 205365112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.67944
Policy Entropy: 1.27925
Value Function Loss: 0.27121

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05060
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.07035

Collected Steps per Second: 11,350.20009
Overall Steps per Second: 9,755.29017

Timestep Collection Time: 4.40556
Timestep Consumption Time: 0.72027
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 5.12583

Cumulative Model Updates: 12,310
Cumulative Timesteps: 205,415,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.34891
Policy Entropy: 1.27493
Value Function Loss: 0.26526

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04777
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.06629

Collected Steps per Second: 11,493.93712
Overall Steps per Second: 9,518.33240

Timestep Collection Time: 4.35012
Timestep Consumption Time: 0.90290
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.25302

Cumulative Model Updates: 12,313
Cumulative Timesteps: 205,465,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 205465116...
Checkpoint 205465116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.00472
Policy Entropy: 1.27782
Value Function Loss: 0.27307

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05181
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 10,992.77738
Overall Steps per Second: 9,333.78587

Timestep Collection Time: 4.55008
Timestep Consumption Time: 0.80873
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.35881

Cumulative Model Updates: 12,316
Cumulative Timesteps: 205,515,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.96745
Policy Entropy: 1.27370
Value Function Loss: 0.25056

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04111
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.08487

Collected Steps per Second: 11,543.82205
Overall Steps per Second: 9,806.15641

Timestep Collection Time: 4.33132
Timestep Consumption Time: 0.76752
PPO Batch Consumption Time: 0.03838
Total Iteration Time: 5.09884

Cumulative Model Updates: 12,319
Cumulative Timesteps: 205,565,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 205565134...
Checkpoint 205565134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.22642
Policy Entropy: 1.27707
Value Function Loss: 0.23161

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04454
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.09639

Collected Steps per Second: 11,622.47383
Overall Steps per Second: 9,763.62967

Timestep Collection Time: 4.30390
Timestep Consumption Time: 0.81940
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.12330

Cumulative Model Updates: 12,322
Cumulative Timesteps: 205,615,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.18186
Policy Entropy: 1.27995
Value Function Loss: 0.22317

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04736
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.08962

Collected Steps per Second: 11,658.60415
Overall Steps per Second: 9,957.77868

Timestep Collection Time: 4.29022
Timestep Consumption Time: 0.73279
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.02301

Cumulative Model Updates: 12,325
Cumulative Timesteps: 205,665,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 205665174...
Checkpoint 205665174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.61088
Policy Entropy: 1.27989
Value Function Loss: 0.24915

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05187
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.08310

Collected Steps per Second: 11,426.84318
Overall Steps per Second: 9,606.72757

Timestep Collection Time: 4.37636
Timestep Consumption Time: 0.82916
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 5.20552

Cumulative Model Updates: 12,328
Cumulative Timesteps: 205,715,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.13655
Policy Entropy: 1.27943
Value Function Loss: 0.25562

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.08132

Collected Steps per Second: 10,733.43869
Overall Steps per Second: 9,075.78614

Timestep Collection Time: 4.65908
Timestep Consumption Time: 0.85096
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.51005

Cumulative Model Updates: 12,331
Cumulative Timesteps: 205,765,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 205765190...
Checkpoint 205765190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.17226
Policy Entropy: 1.28107
Value Function Loss: 0.24787

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05073
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.07367

Collected Steps per Second: 11,534.83611
Overall Steps per Second: 9,787.52377

Timestep Collection Time: 4.33626
Timestep Consumption Time: 0.77413
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.11038

Cumulative Model Updates: 12,334
Cumulative Timesteps: 205,815,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.18307
Policy Entropy: 1.28311
Value Function Loss: 0.23012

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03599
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.06987

Collected Steps per Second: 11,197.49092
Overall Steps per Second: 9,408.20623

Timestep Collection Time: 4.46761
Timestep Consumption Time: 0.84966
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 5.31727

Cumulative Model Updates: 12,337
Cumulative Timesteps: 205,865,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 205865234...
Checkpoint 205865234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.76724
Policy Entropy: 1.27926
Value Function Loss: 0.23150

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05562
Policy Update Magnitude: 0.06329
Value Function Update Magnitude: 0.06755

Collected Steps per Second: 11,015.22416
Overall Steps per Second: 9,497.42616

Timestep Collection Time: 4.54171
Timestep Consumption Time: 0.72582
PPO Batch Consumption Time: 0.03989
Total Iteration Time: 5.26753

Cumulative Model Updates: 12,340
Cumulative Timesteps: 205,915,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.74567
Policy Entropy: 1.28292
Value Function Loss: 0.24244

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04897
Policy Update Magnitude: 0.05948
Value Function Update Magnitude: 0.07722

Collected Steps per Second: 11,291.70168
Overall Steps per Second: 9,490.78073

Timestep Collection Time: 4.42927
Timestep Consumption Time: 0.84048
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 5.26975

Cumulative Model Updates: 12,343
Cumulative Timesteps: 205,965,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 205965276...
Checkpoint 205965276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.34930
Policy Entropy: 1.27736
Value Function Loss: 0.23816

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04928
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.07032

Collected Steps per Second: 11,169.67340
Overall Steps per Second: 9,436.74690

Timestep Collection Time: 4.47856
Timestep Consumption Time: 0.82242
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 5.30098

Cumulative Model Updates: 12,346
Cumulative Timesteps: 206,015,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.87496
Policy Entropy: 1.28239
Value Function Loss: 0.24913

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07323
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.06567

Collected Steps per Second: 10,542.68237
Overall Steps per Second: 9,120.10911

Timestep Collection Time: 4.74471
Timestep Consumption Time: 0.74009
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.48480

Cumulative Model Updates: 12,349
Cumulative Timesteps: 206,065,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 206065322...
Checkpoint 206065322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.35916
Policy Entropy: 1.28205
Value Function Loss: 0.23526

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.06400

Collected Steps per Second: 11,035.51115
Overall Steps per Second: 9,325.64746

Timestep Collection Time: 4.53336
Timestep Consumption Time: 0.83120
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.36456

Cumulative Model Updates: 12,352
Cumulative Timesteps: 206,115,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.72813
Policy Entropy: 1.28679
Value Function Loss: 0.24121

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.06227

Collected Steps per Second: 11,095.50148
Overall Steps per Second: 9,465.62080

Timestep Collection Time: 4.50669
Timestep Consumption Time: 0.77600
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.28270

Cumulative Model Updates: 12,355
Cumulative Timesteps: 206,165,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 206165354...
Checkpoint 206165354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.95732
Policy Entropy: 1.28330
Value Function Loss: 0.23056

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05132
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.06934

Collected Steps per Second: 11,135.07258
Overall Steps per Second: 9,416.64667

Timestep Collection Time: 4.49193
Timestep Consumption Time: 0.81972
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 5.31166

Cumulative Model Updates: 12,358
Cumulative Timesteps: 206,215,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.47002
Policy Entropy: 1.28075
Value Function Loss: 0.24439

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05353
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.06805

Collected Steps per Second: 12,170.78025
Overall Steps per Second: 10,164.37748

Timestep Collection Time: 4.10968
Timestep Consumption Time: 0.81123
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.92091

Cumulative Model Updates: 12,361
Cumulative Timesteps: 206,265,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 206265390...
Checkpoint 206265390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.60626
Policy Entropy: 1.28217
Value Function Loss: 0.24865

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05684
Policy Update Magnitude: 0.06657
Value Function Update Magnitude: 0.06190

Collected Steps per Second: 11,872.51492
Overall Steps per Second: 9,930.97042

Timestep Collection Time: 4.21309
Timestep Consumption Time: 0.82368
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.03677

Cumulative Model Updates: 12,364
Cumulative Timesteps: 206,315,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.17173
Policy Entropy: 1.28288
Value Function Loss: 0.25252

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.06027
Policy Update Magnitude: 0.06401
Value Function Update Magnitude: 0.06038

Collected Steps per Second: 11,509.51109
Overall Steps per Second: 9,722.44473

Timestep Collection Time: 4.34528
Timestep Consumption Time: 0.79870
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.14397

Cumulative Model Updates: 12,367
Cumulative Timesteps: 206,365,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 206365422...
Checkpoint 206365422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.70133
Policy Entropy: 1.27888
Value Function Loss: 0.25200

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06502
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 11,983.06241
Overall Steps per Second: 9,901.83224

Timestep Collection Time: 4.17356
Timestep Consumption Time: 0.87722
PPO Batch Consumption Time: 0.03884
Total Iteration Time: 5.05078

Cumulative Model Updates: 12,370
Cumulative Timesteps: 206,415,434

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.44053
Policy Entropy: 1.28584
Value Function Loss: 0.23147

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.06970

Collected Steps per Second: 12,264.62916
Overall Steps per Second: 10,113.18180

Timestep Collection Time: 4.07905
Timestep Consumption Time: 0.86776
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 4.94681

Cumulative Model Updates: 12,373
Cumulative Timesteps: 206,465,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 206465462...
Checkpoint 206465462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.24226
Policy Entropy: 1.28030
Value Function Loss: 0.24666

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06330
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.06368

Collected Steps per Second: 12,250.10742
Overall Steps per Second: 10,267.52949

Timestep Collection Time: 4.08323
Timestep Consumption Time: 0.78844
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.87167

Cumulative Model Updates: 12,376
Cumulative Timesteps: 206,515,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.51297
Policy Entropy: 1.28704
Value Function Loss: 0.22976

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06483
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 11,377.34663
Overall Steps per Second: 9,617.97363

Timestep Collection Time: 4.39733
Timestep Consumption Time: 0.80438
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 5.20172

Cumulative Model Updates: 12,379
Cumulative Timesteps: 206,565,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 206565512...
Checkpoint 206565512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.63439
Policy Entropy: 1.27807
Value Function Loss: 0.25165

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.06031

Collected Steps per Second: 11,157.91110
Overall Steps per Second: 9,284.34553

Timestep Collection Time: 4.48310
Timestep Consumption Time: 0.90468
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 5.38778

Cumulative Model Updates: 12,382
Cumulative Timesteps: 206,615,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.61647
Policy Entropy: 1.28963
Value Function Loss: 0.23567

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07018
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.04999

Collected Steps per Second: 11,200.17705
Overall Steps per Second: 9,656.16210

Timestep Collection Time: 4.46618
Timestep Consumption Time: 0.71414
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.18032

Cumulative Model Updates: 12,385
Cumulative Timesteps: 206,665,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 206665556...
Checkpoint 206665556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.84987
Policy Entropy: 1.28293
Value Function Loss: 0.24314

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05819
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.04618

Collected Steps per Second: 11,405.63867
Overall Steps per Second: 9,665.94088

Timestep Collection Time: 4.38415
Timestep Consumption Time: 0.78907
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.17322

Cumulative Model Updates: 12,388
Cumulative Timesteps: 206,715,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.25076
Policy Entropy: 1.28953
Value Function Loss: 0.26089

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05573
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.05304

Collected Steps per Second: 11,357.42555
Overall Steps per Second: 9,675.80071

Timestep Collection Time: 4.40434
Timestep Consumption Time: 0.76546
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.16980

Cumulative Model Updates: 12,391
Cumulative Timesteps: 206,765,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 206765582...
Checkpoint 206765582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.65589
Policy Entropy: 1.28049
Value Function Loss: 0.25533

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.04653

Collected Steps per Second: 11,445.76701
Overall Steps per Second: 9,700.46649

Timestep Collection Time: 4.37122
Timestep Consumption Time: 0.78647
PPO Batch Consumption Time: 0.04024
Total Iteration Time: 5.15769

Cumulative Model Updates: 12,394
Cumulative Timesteps: 206,815,614

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.91973
Policy Entropy: 1.28369
Value Function Loss: 0.24049

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.05856
Policy Update Magnitude: 0.06677
Value Function Update Magnitude: 0.04280

Collected Steps per Second: 11,385.35881
Overall Steps per Second: 9,705.11618

Timestep Collection Time: 4.39266
Timestep Consumption Time: 0.76050
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.15316

Cumulative Model Updates: 12,397
Cumulative Timesteps: 206,865,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 206865626...
Checkpoint 206865626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.12872
Policy Entropy: 1.28466
Value Function Loss: 0.22617

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05301
Policy Update Magnitude: 0.06741
Value Function Update Magnitude: 0.04957

Collected Steps per Second: 10,257.32240
Overall Steps per Second: 8,889.56057

Timestep Collection Time: 4.87554
Timestep Consumption Time: 0.75016
PPO Batch Consumption Time: 0.04582
Total Iteration Time: 5.62570

Cumulative Model Updates: 12,400
Cumulative Timesteps: 206,915,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.47403
Policy Entropy: 1.28676
Value Function Loss: 0.23673

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05042
Policy Update Magnitude: 0.06662
Value Function Update Magnitude: 0.06424

Collected Steps per Second: 11,100.67376
Overall Steps per Second: 9,440.59929

Timestep Collection Time: 4.50657
Timestep Consumption Time: 0.79245
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.29903

Cumulative Model Updates: 12,403
Cumulative Timesteps: 206,965,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 206965662...
Checkpoint 206965662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.47226
Policy Entropy: 1.28314
Value Function Loss: 0.24761

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04185
Policy Update Magnitude: 0.07039
Value Function Update Magnitude: 0.06814

Collected Steps per Second: 11,036.97318
Overall Steps per Second: 9,493.44183

Timestep Collection Time: 4.53113
Timestep Consumption Time: 0.73671
PPO Batch Consumption Time: 0.03335
Total Iteration Time: 5.26785

Cumulative Model Updates: 12,406
Cumulative Timesteps: 207,015,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.42883
Policy Entropy: 1.29084
Value Function Loss: 0.24296

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 0.07525
Value Function Update Magnitude: 0.07770

Collected Steps per Second: 11,460.93123
Overall Steps per Second: 9,783.63057

Timestep Collection Time: 4.36439
Timestep Consumption Time: 0.74823
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.11262

Cumulative Model Updates: 12,409
Cumulative Timesteps: 207,065,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 207065692...
Checkpoint 207065692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.26244
Policy Entropy: 1.28430
Value Function Loss: 0.23353

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04817
Policy Update Magnitude: 0.06742
Value Function Update Magnitude: 0.07484

Collected Steps per Second: 10,978.22279
Overall Steps per Second: 9,406.14608

Timestep Collection Time: 4.55484
Timestep Consumption Time: 0.76126
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.31610

Cumulative Model Updates: 12,412
Cumulative Timesteps: 207,115,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.12191
Policy Entropy: 1.28747
Value Function Loss: 0.23279

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04245
Policy Update Magnitude: 0.06756
Value Function Update Magnitude: 0.07347

Collected Steps per Second: 11,254.76400
Overall Steps per Second: 9,719.36419

Timestep Collection Time: 4.44487
Timestep Consumption Time: 0.70217
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.14704

Cumulative Model Updates: 12,415
Cumulative Timesteps: 207,165,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 207165722...
Checkpoint 207165722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.24169
Policy Entropy: 1.28487
Value Function Loss: 0.22251

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04979
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.06325

Collected Steps per Second: 10,478.19666
Overall Steps per Second: 8,977.35409

Timestep Collection Time: 4.77372
Timestep Consumption Time: 0.79808
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.57180

Cumulative Model Updates: 12,418
Cumulative Timesteps: 207,215,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.17707
Policy Entropy: 1.28747
Value Function Loss: 0.21498

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03785
Policy Update Magnitude: 0.06652
Value Function Update Magnitude: 0.06026

Collected Steps per Second: 10,857.88728
Overall Steps per Second: 9,373.81488

Timestep Collection Time: 4.60642
Timestep Consumption Time: 0.72929
PPO Batch Consumption Time: 0.03364
Total Iteration Time: 5.33571

Cumulative Model Updates: 12,421
Cumulative Timesteps: 207,265,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 207265758...
Checkpoint 207265758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.89840
Policy Entropy: 1.28253
Value Function Loss: 0.22047

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05796
Policy Update Magnitude: 0.07162
Value Function Update Magnitude: 0.06781

Collected Steps per Second: 11,398.59924
Overall Steps per Second: 9,642.75186

Timestep Collection Time: 4.38650
Timestep Consumption Time: 0.79874
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 5.18524

Cumulative Model Updates: 12,424
Cumulative Timesteps: 207,315,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.60048
Policy Entropy: 1.28567
Value Function Loss: 0.24423

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.07175
Value Function Update Magnitude: 0.06963

Collected Steps per Second: 11,383.59441
Overall Steps per Second: 9,640.85772

Timestep Collection Time: 4.39422
Timestep Consumption Time: 0.79432
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 5.18854

Cumulative Model Updates: 12,427
Cumulative Timesteps: 207,365,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 207365780...
Checkpoint 207365780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.85735
Policy Entropy: 1.28380
Value Function Loss: 0.26490

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.06520
Value Function Update Magnitude: 0.07270

Collected Steps per Second: 11,663.31750
Overall Steps per Second: 10,091.70434

Timestep Collection Time: 4.28883
Timestep Consumption Time: 0.66791
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 4.95674

Cumulative Model Updates: 12,430
Cumulative Timesteps: 207,415,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.02767
Policy Entropy: 1.28997
Value Function Loss: 0.25817

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.07674

Collected Steps per Second: 11,252.07002
Overall Steps per Second: 9,581.73239

Timestep Collection Time: 4.44398
Timestep Consumption Time: 0.77470
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.21868

Cumulative Model Updates: 12,433
Cumulative Timesteps: 207,465,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 207465806...
Checkpoint 207465806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.09093
Policy Entropy: 1.28709
Value Function Loss: 0.24558

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.05669
Policy Update Magnitude: 0.05922
Value Function Update Magnitude: 0.07675

Collected Steps per Second: 10,844.05418
Overall Steps per Second: 9,364.14395

Timestep Collection Time: 4.61156
Timestep Consumption Time: 0.72881
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.34037

Cumulative Model Updates: 12,436
Cumulative Timesteps: 207,515,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.58254
Policy Entropy: 1.29599
Value Function Loss: 0.25287

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06880
Policy Update Magnitude: 0.05943
Value Function Update Magnitude: 0.09880

Collected Steps per Second: 11,734.72026
Overall Steps per Second: 9,923.69227

Timestep Collection Time: 4.26291
Timestep Consumption Time: 0.77796
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.04087

Cumulative Model Updates: 12,439
Cumulative Timesteps: 207,565,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 207565838...
Checkpoint 207565838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.20110
Policy Entropy: 1.29082
Value Function Loss: 0.25554

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06465
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.10394

Collected Steps per Second: 11,397.67044
Overall Steps per Second: 9,657.95135

Timestep Collection Time: 4.38862
Timestep Consumption Time: 0.79054
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 5.17915

Cumulative Model Updates: 12,442
Cumulative Timesteps: 207,615,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.03703
Policy Entropy: 1.28772
Value Function Loss: 0.26328

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04976
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.11064

Collected Steps per Second: 11,644.71104
Overall Steps per Second: 10,077.22522

Timestep Collection Time: 4.29637
Timestep Consumption Time: 0.66829
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 4.96466

Cumulative Model Updates: 12,445
Cumulative Timesteps: 207,665,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 207665888...
Checkpoint 207665888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.03398
Policy Entropy: 1.28506
Value Function Loss: 0.23944

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06767
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.10952

Collected Steps per Second: 11,340.92163
Overall Steps per Second: 9,565.39767

Timestep Collection Time: 4.41163
Timestep Consumption Time: 0.81889
PPO Batch Consumption Time: 0.04085
Total Iteration Time: 5.23052

Cumulative Model Updates: 12,448
Cumulative Timesteps: 207,715,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.54423
Policy Entropy: 1.28719
Value Function Loss: 0.23267

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.10130

Collected Steps per Second: 11,348.40385
Overall Steps per Second: 9,447.13466

Timestep Collection Time: 4.40714
Timestep Consumption Time: 0.88695
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.29409

Cumulative Model Updates: 12,451
Cumulative Timesteps: 207,765,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 207765934...
Checkpoint 207765934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.87855
Policy Entropy: 1.28655
Value Function Loss: 0.22929

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05631
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.09385

Collected Steps per Second: 11,626.31290
Overall Steps per Second: 9,810.00479

Timestep Collection Time: 4.30300
Timestep Consumption Time: 0.79669
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.09969

Cumulative Model Updates: 12,454
Cumulative Timesteps: 207,815,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.48020
Policy Entropy: 1.28441
Value Function Loss: 0.22068

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.06461
Value Function Update Magnitude: 0.11899

Collected Steps per Second: 11,654.29724
Overall Steps per Second: 9,835.49774

Timestep Collection Time: 4.29061
Timestep Consumption Time: 0.79343
PPO Batch Consumption Time: 0.04022
Total Iteration Time: 5.08403

Cumulative Model Updates: 12,457
Cumulative Timesteps: 207,865,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 207865966...
Checkpoint 207865966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.66462
Policy Entropy: 1.28740
Value Function Loss: 0.20839

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.11348

Collected Steps per Second: 11,228.95567
Overall Steps per Second: 9,686.49117

Timestep Collection Time: 4.45384
Timestep Consumption Time: 0.70922
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.16307

Cumulative Model Updates: 12,460
Cumulative Timesteps: 207,915,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.17487
Policy Entropy: 1.28591
Value Function Loss: 0.20876

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.05610
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.09178

Collected Steps per Second: 11,580.09565
Overall Steps per Second: 9,817.24619

Timestep Collection Time: 4.31896
Timestep Consumption Time: 0.77554
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.09450

Cumulative Model Updates: 12,463
Cumulative Timesteps: 207,965,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 207965992...
Checkpoint 207965992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.37370
Policy Entropy: 1.28614
Value Function Loss: 0.23938

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06539
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 11,455.06120
Overall Steps per Second: 9,772.97615

Timestep Collection Time: 4.36611
Timestep Consumption Time: 0.75148
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.11758

Cumulative Model Updates: 12,466
Cumulative Timesteps: 208,016,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.60348
Policy Entropy: 1.28880
Value Function Loss: 0.26459

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05965
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.05974

Collected Steps per Second: 10,848.49163
Overall Steps per Second: 9,231.60942

Timestep Collection Time: 4.61096
Timestep Consumption Time: 0.80759
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 5.41856

Cumulative Model Updates: 12,469
Cumulative Timesteps: 208,066,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 208066028...
Checkpoint 208066028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.83389
Policy Entropy: 1.28618
Value Function Loss: 0.26574

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04735
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.05150

Collected Steps per Second: 10,938.95815
Overall Steps per Second: 9,200.31836

Timestep Collection Time: 4.57246
Timestep Consumption Time: 0.86409
PPO Batch Consumption Time: 0.03850
Total Iteration Time: 5.43655

Cumulative Model Updates: 12,472
Cumulative Timesteps: 208,116,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.34894
Policy Entropy: 1.28544
Value Function Loss: 0.28516

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.06544

Collected Steps per Second: 11,181.22734
Overall Steps per Second: 9,703.98520

Timestep Collection Time: 4.47429
Timestep Consumption Time: 0.68112
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.15541

Cumulative Model Updates: 12,475
Cumulative Timesteps: 208,166,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 208166074...
Checkpoint 208166074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.41091
Policy Entropy: 1.28117
Value Function Loss: 0.28906

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06746
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.05615

Collected Steps per Second: 10,969.78778
Overall Steps per Second: 9,359.49022

Timestep Collection Time: 4.56071
Timestep Consumption Time: 0.78467
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 5.34538

Cumulative Model Updates: 12,478
Cumulative Timesteps: 208,216,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.31738
Policy Entropy: 1.27934
Value Function Loss: 0.31343

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05643
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 11,048.01888
Overall Steps per Second: 9,390.83863

Timestep Collection Time: 4.52715
Timestep Consumption Time: 0.79890
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.32604

Cumulative Model Updates: 12,481
Cumulative Timesteps: 208,266,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 208266120...
Checkpoint 208266120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.43421
Policy Entropy: 1.27387
Value Function Loss: 0.29320

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.06782

Collected Steps per Second: 11,199.16095
Overall Steps per Second: 9,449.21311

Timestep Collection Time: 4.46676
Timestep Consumption Time: 0.82722
PPO Batch Consumption Time: 0.03868
Total Iteration Time: 5.29399

Cumulative Model Updates: 12,484
Cumulative Timesteps: 208,316,144

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.42290
Policy Entropy: 1.27892
Value Function Loss: 0.28045

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05569
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.06134

Collected Steps per Second: 10,309.97369
Overall Steps per Second: 8,842.99195

Timestep Collection Time: 4.84967
Timestep Consumption Time: 0.80452
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.65419

Cumulative Model Updates: 12,487
Cumulative Timesteps: 208,366,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 208366144...
Checkpoint 208366144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.17279
Policy Entropy: 1.27865
Value Function Loss: 0.25159

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04980
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.05830

Collected Steps per Second: 10,952.35722
Overall Steps per Second: 9,455.37895

Timestep Collection Time: 4.56559
Timestep Consumption Time: 0.72283
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.28842

Cumulative Model Updates: 12,490
Cumulative Timesteps: 208,416,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.27044
Policy Entropy: 1.27487
Value Function Loss: 0.24971

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07531
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.06826

Collected Steps per Second: 10,992.16638
Overall Steps per Second: 9,349.51432

Timestep Collection Time: 4.55142
Timestep Consumption Time: 0.79966
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 5.35108

Cumulative Model Updates: 12,493
Cumulative Timesteps: 208,466,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 208466178...
Checkpoint 208466178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.42602
Policy Entropy: 1.27693
Value Function Loss: 0.23844

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04609
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.06097

Collected Steps per Second: 11,011.98800
Overall Steps per Second: 9,382.47136

Timestep Collection Time: 4.54123
Timestep Consumption Time: 0.78871
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.32994

Cumulative Model Updates: 12,496
Cumulative Timesteps: 208,516,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.97214
Policy Entropy: 1.27443
Value Function Loss: 0.25964

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06573
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.05817

Collected Steps per Second: 12,768.74287
Overall Steps per Second: 10,539.37476

Timestep Collection Time: 3.91644
Timestep Consumption Time: 0.82843
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 4.74487

Cumulative Model Updates: 12,499
Cumulative Timesteps: 208,566,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 208566194...
Checkpoint 208566194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.82165
Policy Entropy: 1.28289
Value Function Loss: 0.25783

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.05420

Collected Steps per Second: 12,110.80752
Overall Steps per Second: 10,161.37611

Timestep Collection Time: 4.12871
Timestep Consumption Time: 0.79208
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.92079

Cumulative Model Updates: 12,502
Cumulative Timesteps: 208,616,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.60602
Policy Entropy: 1.27834
Value Function Loss: 0.26195

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06090
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.06023

Collected Steps per Second: 11,414.11302
Overall Steps per Second: 9,816.68963

Timestep Collection Time: 4.38159
Timestep Consumption Time: 0.71300
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.09459

Cumulative Model Updates: 12,505
Cumulative Timesteps: 208,666,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 208666208...
Checkpoint 208666208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.20331
Policy Entropy: 1.28277
Value Function Loss: 0.25625

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05343
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.06515

Collected Steps per Second: 11,739.37140
Overall Steps per Second: 9,828.14196

Timestep Collection Time: 4.25934
Timestep Consumption Time: 0.82829
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.08764

Cumulative Model Updates: 12,508
Cumulative Timesteps: 208,716,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.64752
Policy Entropy: 1.27668
Value Function Loss: 0.25050

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05427
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.06601

Collected Steps per Second: 11,968.31566
Overall Steps per Second: 10,086.56936

Timestep Collection Time: 4.17987
Timestep Consumption Time: 0.77979
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 4.95966

Cumulative Model Updates: 12,511
Cumulative Timesteps: 208,766,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 208766236...
Checkpoint 208766236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.65590
Policy Entropy: 1.28092
Value Function Loss: 0.24758

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06376
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.06424

Collected Steps per Second: 12,336.07698
Overall Steps per Second: 10,331.16850

Timestep Collection Time: 4.05315
Timestep Consumption Time: 0.78657
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.83972

Cumulative Model Updates: 12,514
Cumulative Timesteps: 208,816,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.47848
Policy Entropy: 1.27519
Value Function Loss: 0.23886

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04647
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.07225

Collected Steps per Second: 11,277.47701
Overall Steps per Second: 9,562.15612

Timestep Collection Time: 4.43450
Timestep Consumption Time: 0.79549
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.22999

Cumulative Model Updates: 12,517
Cumulative Timesteps: 208,866,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 208866246...
Checkpoint 208866246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.33261
Policy Entropy: 1.28327
Value Function Loss: 0.23931

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06439
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.07617

Collected Steps per Second: 11,430.86875
Overall Steps per Second: 9,616.29887

Timestep Collection Time: 4.37430
Timestep Consumption Time: 0.82542
PPO Batch Consumption Time: 0.04420
Total Iteration Time: 5.19971

Cumulative Model Updates: 12,520
Cumulative Timesteps: 208,916,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.06176
Policy Entropy: 1.28211
Value Function Loss: 0.24979

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06119
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 11,115.78040
Overall Steps per Second: 9,456.88234

Timestep Collection Time: 4.50081
Timestep Consumption Time: 0.78952
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.29033

Cumulative Model Updates: 12,523
Cumulative Timesteps: 208,966,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 208966278...
Checkpoint 208966278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.04880
Policy Entropy: 1.28536
Value Function Loss: 0.24983

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05353
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.05964

Collected Steps per Second: 11,239.57156
Overall Steps per Second: 9,608.27412

Timestep Collection Time: 4.45088
Timestep Consumption Time: 0.75567
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.20655

Cumulative Model Updates: 12,526
Cumulative Timesteps: 209,016,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.93601
Policy Entropy: 1.28013
Value Function Loss: 0.23522

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06121
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.04709

Collected Steps per Second: 11,398.32578
Overall Steps per Second: 9,654.74978

Timestep Collection Time: 4.38924
Timestep Consumption Time: 0.79266
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.18191

Cumulative Model Updates: 12,529
Cumulative Timesteps: 209,066,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 209066334...
Checkpoint 209066334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.46340
Policy Entropy: 1.28109
Value Function Loss: 0.24088

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05325
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.05651

Collected Steps per Second: 11,400.27714
Overall Steps per Second: 9,689.11703

Timestep Collection Time: 4.38744
Timestep Consumption Time: 0.77485
PPO Batch Consumption Time: 0.03831
Total Iteration Time: 5.16229

Cumulative Model Updates: 12,532
Cumulative Timesteps: 209,116,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.39171
Policy Entropy: 1.28934
Value Function Loss: 0.24481

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07045
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.06357

Collected Steps per Second: 11,209.94233
Overall Steps per Second: 9,649.58469

Timestep Collection Time: 4.46104
Timestep Consumption Time: 0.72136
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.18240

Cumulative Model Updates: 12,535
Cumulative Timesteps: 209,166,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 209166360...
Checkpoint 209166360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.62464
Policy Entropy: 1.27972
Value Function Loss: 0.27353

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.06818

Collected Steps per Second: 10,264.12741
Overall Steps per Second: 8,843.56409

Timestep Collection Time: 4.87426
Timestep Consumption Time: 0.78296
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.65722

Cumulative Model Updates: 12,538
Cumulative Timesteps: 209,216,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.11150
Policy Entropy: 1.29034
Value Function Loss: 0.28694

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06379
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 10,994.16596
Overall Steps per Second: 9,413.76876

Timestep Collection Time: 4.54805
Timestep Consumption Time: 0.76353
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.31158

Cumulative Model Updates: 12,541
Cumulative Timesteps: 209,266,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 209266392...
Checkpoint 209266392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.76014
Policy Entropy: 1.28023
Value Function Loss: 0.26864

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07243
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.07995

Collected Steps per Second: 11,022.69933
Overall Steps per Second: 9,546.12493

Timestep Collection Time: 4.53827
Timestep Consumption Time: 0.70197
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.24024

Cumulative Model Updates: 12,544
Cumulative Timesteps: 209,316,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.47892
Policy Entropy: 1.28606
Value Function Loss: 0.25722

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04605
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.07370

Collected Steps per Second: 11,206.25866
Overall Steps per Second: 9,560.49051

Timestep Collection Time: 4.46447
Timestep Consumption Time: 0.76853
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.23300

Cumulative Model Updates: 12,547
Cumulative Timesteps: 209,366,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 209366446...
Checkpoint 209366446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.59123
Policy Entropy: 1.28285
Value Function Loss: 0.22676

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05891
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.07293

Collected Steps per Second: 10,948.61254
Overall Steps per Second: 9,499.30599

Timestep Collection Time: 4.56935
Timestep Consumption Time: 0.69714
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.26649

Cumulative Model Updates: 12,550
Cumulative Timesteps: 209,416,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.07265
Policy Entropy: 1.28666
Value Function Loss: 0.23210

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05819
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.06740

Collected Steps per Second: 10,858.65630
Overall Steps per Second: 9,241.12226

Timestep Collection Time: 4.60573
Timestep Consumption Time: 0.80617
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.41190

Cumulative Model Updates: 12,553
Cumulative Timesteps: 209,466,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 209466486...
Checkpoint 209466486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.40386
Policy Entropy: 1.28093
Value Function Loss: 0.23916

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.06316
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 10,292.19472
Overall Steps per Second: 8,899.44006

Timestep Collection Time: 4.86038
Timestep Consumption Time: 0.76065
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 5.62103

Cumulative Model Updates: 12,556
Cumulative Timesteps: 209,516,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.57372
Policy Entropy: 1.28423
Value Function Loss: 0.26210

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05627
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 11,258.98032
Overall Steps per Second: 9,619.48720

Timestep Collection Time: 4.44143
Timestep Consumption Time: 0.75697
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.19841

Cumulative Model Updates: 12,559
Cumulative Timesteps: 209,566,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 209566516...
Checkpoint 209566516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.13777
Policy Entropy: 1.27855
Value Function Loss: 0.26528

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06794
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.06167

Collected Steps per Second: 10,695.97872
Overall Steps per Second: 9,229.33213

Timestep Collection Time: 4.67503
Timestep Consumption Time: 0.74292
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.41794

Cumulative Model Updates: 12,562
Cumulative Timesteps: 209,616,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.62185
Policy Entropy: 1.28171
Value Function Loss: 0.27838

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05556
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.05799

Collected Steps per Second: 11,107.30556
Overall Steps per Second: 9,629.43524

Timestep Collection Time: 4.50190
Timestep Consumption Time: 0.69093
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.19283

Cumulative Model Updates: 12,565
Cumulative Timesteps: 209,666,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 209666524...
Checkpoint 209666524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.17352
Policy Entropy: 1.27822
Value Function Loss: 0.25108

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06309
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.05789

Collected Steps per Second: 11,600.59218
Overall Steps per Second: 9,781.07734

Timestep Collection Time: 4.31030
Timestep Consumption Time: 0.80182
PPO Batch Consumption Time: 0.03785
Total Iteration Time: 5.11212

Cumulative Model Updates: 12,568
Cumulative Timesteps: 209,716,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.46435
Policy Entropy: 1.27609
Value Function Loss: 0.25718

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04711
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.06413

Collected Steps per Second: 11,560.84681
Overall Steps per Second: 9,619.03097

Timestep Collection Time: 4.32494
Timestep Consumption Time: 0.87309
PPO Batch Consumption Time: 0.04079
Total Iteration Time: 5.19803

Cumulative Model Updates: 12,571
Cumulative Timesteps: 209,766,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 209766526...
Checkpoint 209766526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.23878
Policy Entropy: 1.28055
Value Function Loss: 0.25348

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03782
Policy Update Magnitude: 0.06329
Value Function Update Magnitude: 0.06844

Collected Steps per Second: 11,526.06162
Overall Steps per Second: 9,797.20914

Timestep Collection Time: 4.33800
Timestep Consumption Time: 0.76550
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.10349

Cumulative Model Updates: 12,574
Cumulative Timesteps: 209,816,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.69991
Policy Entropy: 1.28288
Value Function Loss: 0.25389

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04343
Policy Update Magnitude: 0.06938
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 11,466.23159
Overall Steps per Second: 9,777.22369

Timestep Collection Time: 4.36290
Timestep Consumption Time: 0.75369
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.11659

Cumulative Model Updates: 12,577
Cumulative Timesteps: 209,866,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 209866552...
Checkpoint 209866552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.01631
Policy Entropy: 1.28223
Value Function Loss: 0.25551

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04342
Policy Update Magnitude: 0.07450
Value Function Update Magnitude: 0.06506

Collected Steps per Second: 11,643.31857
Overall Steps per Second: 9,965.86696

Timestep Collection Time: 4.29517
Timestep Consumption Time: 0.72296
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.01813

Cumulative Model Updates: 12,580
Cumulative Timesteps: 209,916,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.76093
Policy Entropy: 1.28163
Value Function Loss: 0.22749

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05627
Policy Update Magnitude: 0.07053
Value Function Update Magnitude: 0.05576

Collected Steps per Second: 11,397.77163
Overall Steps per Second: 9,513.79971

Timestep Collection Time: 4.38752
Timestep Consumption Time: 0.86884
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.25636

Cumulative Model Updates: 12,583
Cumulative Timesteps: 209,966,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 209966570...
Checkpoint 209966570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.96182
Policy Entropy: 1.28304
Value Function Loss: 0.21692

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04172
Policy Update Magnitude: 0.06908
Value Function Update Magnitude: 0.05988

Collected Steps per Second: 11,407.90349
Overall Steps per Second: 9,635.19447

Timestep Collection Time: 4.38521
Timestep Consumption Time: 0.80680
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.19201

Cumulative Model Updates: 12,586
Cumulative Timesteps: 210,016,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.30995
Policy Entropy: 1.27598
Value Function Loss: 0.20723

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.05741
Policy Update Magnitude: 0.07150
Value Function Update Magnitude: 0.05880

Collected Steps per Second: 11,263.44458
Overall Steps per Second: 9,447.78508

Timestep Collection Time: 4.44091
Timestep Consumption Time: 0.85345
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.29436

Cumulative Model Updates: 12,589
Cumulative Timesteps: 210,066,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 210066616...
Checkpoint 210066616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.37076
Policy Entropy: 1.28070
Value Function Loss: 0.22669

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04545
Policy Update Magnitude: 0.07142
Value Function Update Magnitude: 0.06665

Collected Steps per Second: 11,573.50806
Overall Steps per Second: 9,769.70656

Timestep Collection Time: 4.32280
Timestep Consumption Time: 0.79813
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.12093

Cumulative Model Updates: 12,592
Cumulative Timesteps: 210,116,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.12898
Policy Entropy: 1.28186
Value Function Loss: 0.25667

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06613
Policy Update Magnitude: 0.07326
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 11,462.64989
Overall Steps per Second: 9,867.72549

Timestep Collection Time: 4.36391
Timestep Consumption Time: 0.70534
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.06925

Cumulative Model Updates: 12,595
Cumulative Timesteps: 210,166,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 210166668...
Checkpoint 210166668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.04471
Policy Entropy: 1.28472
Value Function Loss: 0.25118

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03693
Policy Update Magnitude: 0.07849
Value Function Update Magnitude: 0.09690

Collected Steps per Second: 11,504.59195
Overall Steps per Second: 9,594.68674

Timestep Collection Time: 4.34731
Timestep Consumption Time: 0.86537
PPO Batch Consumption Time: 0.04450
Total Iteration Time: 5.21268

Cumulative Model Updates: 12,598
Cumulative Timesteps: 210,216,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.75119
Policy Entropy: 1.27975
Value Function Loss: 0.24186

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04616
Policy Update Magnitude: 0.07768
Value Function Update Magnitude: 0.11017

Collected Steps per Second: 11,857.72344
Overall Steps per Second: 10,099.14476

Timestep Collection Time: 4.21767
Timestep Consumption Time: 0.73443
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 4.95210

Cumulative Model Updates: 12,601
Cumulative Timesteps: 210,266,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 210266694...
Checkpoint 210266694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.51336
Policy Entropy: 1.28259
Value Function Loss: 0.22651

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.05013
Policy Update Magnitude: 0.07537
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 11,083.92919
Overall Steps per Second: 9,478.00736

Timestep Collection Time: 4.51158
Timestep Consumption Time: 0.76443
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.27600

Cumulative Model Updates: 12,604
Cumulative Timesteps: 210,316,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.45217
Policy Entropy: 1.28276
Value Function Loss: 0.23099

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03899
Policy Update Magnitude: 0.07341
Value Function Update Magnitude: 0.10606

Collected Steps per Second: 10,803.23854
Overall Steps per Second: 9,317.56633

Timestep Collection Time: 4.62898
Timestep Consumption Time: 0.73808
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.36707

Cumulative Model Updates: 12,607
Cumulative Timesteps: 210,366,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 210366708...
Checkpoint 210366708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.01948
Policy Entropy: 1.28820
Value Function Loss: 0.22098

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03187
Policy Update Magnitude: 0.07131
Value Function Update Magnitude: 0.08808

Collected Steps per Second: 11,264.95781
Overall Steps per Second: 9,740.33936

Timestep Collection Time: 4.43925
Timestep Consumption Time: 0.69486
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.13411

Cumulative Model Updates: 12,610
Cumulative Timesteps: 210,416,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.44408
Policy Entropy: 1.28402
Value Function Loss: 0.21069

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 0.07088
Value Function Update Magnitude: 0.09074

Collected Steps per Second: 11,310.39042
Overall Steps per Second: 9,651.99732

Timestep Collection Time: 4.42142
Timestep Consumption Time: 0.75968
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.18110

Cumulative Model Updates: 12,613
Cumulative Timesteps: 210,466,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 210466724...
Checkpoint 210466724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.10883
Policy Entropy: 1.28370
Value Function Loss: 0.19072

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04372
Policy Update Magnitude: 0.07359
Value Function Update Magnitude: 0.09477

Collected Steps per Second: 11,239.23616
Overall Steps per Second: 9,541.09599

Timestep Collection Time: 4.44870
Timestep Consumption Time: 0.79179
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.24049

Cumulative Model Updates: 12,616
Cumulative Timesteps: 210,516,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.35661
Policy Entropy: 1.28374
Value Function Loss: 0.21424

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04476
Policy Update Magnitude: 0.07218
Value Function Update Magnitude: 0.08425

Collected Steps per Second: 11,118.20910
Overall Steps per Second: 9,360.91278

Timestep Collection Time: 4.49893
Timestep Consumption Time: 0.84457
PPO Batch Consumption Time: 0.03863
Total Iteration Time: 5.34350

Cumulative Model Updates: 12,619
Cumulative Timesteps: 210,566,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 210566744...
Checkpoint 210566744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.22790
Policy Entropy: 1.28350
Value Function Loss: 0.23356

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04117
Policy Update Magnitude: 0.07297
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 10,903.61830
Overall Steps per Second: 9,266.96781

Timestep Collection Time: 4.58820
Timestep Consumption Time: 0.81033
PPO Batch Consumption Time: 0.03717
Total Iteration Time: 5.39853

Cumulative Model Updates: 12,622
Cumulative Timesteps: 210,616,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.70857
Policy Entropy: 1.27862
Value Function Loss: 0.25749

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05663
Policy Update Magnitude: 0.07070
Value Function Update Magnitude: 0.07020

Collected Steps per Second: 10,448.66351
Overall Steps per Second: 9,062.20723

Timestep Collection Time: 4.78683
Timestep Consumption Time: 0.73235
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 5.51919

Cumulative Model Updates: 12,625
Cumulative Timesteps: 210,666,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 210666788...
Checkpoint 210666788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.12827
Policy Entropy: 1.28530
Value Function Loss: 0.23880

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06030
Policy Update Magnitude: 0.06836
Value Function Update Magnitude: 0.07525

Collected Steps per Second: 11,033.65218
Overall Steps per Second: 9,302.23005

Timestep Collection Time: 4.53159
Timestep Consumption Time: 0.84346
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 5.37506

Cumulative Model Updates: 12,628
Cumulative Timesteps: 210,716,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.07592
Policy Entropy: 1.28286
Value Function Loss: 0.22701

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 11,304.17821
Overall Steps per Second: 9,591.54631

Timestep Collection Time: 4.42527
Timestep Consumption Time: 0.79016
PPO Batch Consumption Time: 0.04019
Total Iteration Time: 5.21543

Cumulative Model Updates: 12,631
Cumulative Timesteps: 210,766,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 210766812...
Checkpoint 210766812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.05057
Policy Entropy: 1.28117
Value Function Loss: 0.22215

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07353
Policy Update Magnitude: 0.05910
Value Function Update Magnitude: 0.06320

Collected Steps per Second: 11,431.78293
Overall Steps per Second: 9,577.93204

Timestep Collection Time: 4.37570
Timestep Consumption Time: 0.84694
PPO Batch Consumption Time: 0.04447
Total Iteration Time: 5.22263

Cumulative Model Updates: 12,634
Cumulative Timesteps: 210,816,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.76317
Policy Entropy: 1.28116
Value Function Loss: 0.22463

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.07378

Collected Steps per Second: 12,027.45646
Overall Steps per Second: 10,060.67136

Timestep Collection Time: 4.15882
Timestep Consumption Time: 0.81302
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 4.97184

Cumulative Model Updates: 12,637
Cumulative Timesteps: 210,866,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 210866854...
Checkpoint 210866854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.37744
Policy Entropy: 1.28561
Value Function Loss: 0.22183

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03123
Policy Update Magnitude: 0.06616
Value Function Update Magnitude: 0.07982

Collected Steps per Second: 12,028.22543
Overall Steps per Second: 9,953.00963

Timestep Collection Time: 4.15872
Timestep Consumption Time: 0.86710
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 5.02582

Cumulative Model Updates: 12,640
Cumulative Timesteps: 210,916,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.39396
Policy Entropy: 1.28218
Value Function Loss: 0.21525

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04369
Policy Update Magnitude: 0.06866
Value Function Update Magnitude: 0.06729

Collected Steps per Second: 11,692.49742
Overall Steps per Second: 9,724.26667

Timestep Collection Time: 4.27625
Timestep Consumption Time: 0.86553
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.14178

Cumulative Model Updates: 12,643
Cumulative Timesteps: 210,966,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 210966876...
Checkpoint 210966876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.21919
Policy Entropy: 1.27895
Value Function Loss: 0.21891

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06015
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 11,522.50592
Overall Steps per Second: 9,779.06689

Timestep Collection Time: 4.33968
Timestep Consumption Time: 0.77369
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.11337

Cumulative Model Updates: 12,646
Cumulative Timesteps: 211,016,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.36047
Policy Entropy: 1.28301
Value Function Loss: 0.22635

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05690
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.05657

Collected Steps per Second: 12,303.25411
Overall Steps per Second: 10,219.50236

Timestep Collection Time: 4.06624
Timestep Consumption Time: 0.82910
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.89535

Cumulative Model Updates: 12,649
Cumulative Timesteps: 211,066,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 211066908...
Checkpoint 211066908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.44625
Policy Entropy: 1.27940
Value Function Loss: 0.23282

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06703
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.06942

Collected Steps per Second: 11,433.32422
Overall Steps per Second: 9,625.87281

Timestep Collection Time: 4.37493
Timestep Consumption Time: 0.82148
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.19641

Cumulative Model Updates: 12,652
Cumulative Timesteps: 211,116,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.81822
Policy Entropy: 1.28364
Value Function Loss: 0.23577

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05124
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.06479

Collected Steps per Second: 11,379.33667
Overall Steps per Second: 9,827.78268

Timestep Collection Time: 4.39446
Timestep Consumption Time: 0.69377
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.08823

Cumulative Model Updates: 12,655
Cumulative Timesteps: 211,166,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 211166934...
Checkpoint 211166934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.27299
Policy Entropy: 1.27243
Value Function Loss: 0.24822

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05720
Policy Update Magnitude: 0.05922
Value Function Update Magnitude: 0.06119

Collected Steps per Second: 10,749.03928
Overall Steps per Second: 9,091.91152

Timestep Collection Time: 4.65158
Timestep Consumption Time: 0.84782
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.49939

Cumulative Model Updates: 12,658
Cumulative Timesteps: 211,216,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.65673
Policy Entropy: 1.27902
Value Function Loss: 0.25044

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04852
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.06705

Collected Steps per Second: 11,542.69984
Overall Steps per Second: 9,831.95749

Timestep Collection Time: 4.33174
Timestep Consumption Time: 0.75372
PPO Batch Consumption Time: 0.03304
Total Iteration Time: 5.08546

Cumulative Model Updates: 12,661
Cumulative Timesteps: 211,266,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 211266934...
Checkpoint 211266934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.90183
Policy Entropy: 1.27367
Value Function Loss: 0.25210

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.06983

Collected Steps per Second: 11,307.78777
Overall Steps per Second: 9,583.13699

Timestep Collection Time: 4.42332
Timestep Consumption Time: 0.79605
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.21938

Cumulative Model Updates: 12,664
Cumulative Timesteps: 211,316,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.84400
Policy Entropy: 1.27978
Value Function Loss: 0.25695

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05363
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.06305

Collected Steps per Second: 11,337.35387
Overall Steps per Second: 9,610.35017

Timestep Collection Time: 4.41302
Timestep Consumption Time: 0.79303
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.20605

Cumulative Model Updates: 12,667
Cumulative Timesteps: 211,366,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 211366984...
Checkpoint 211366984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.71571
Policy Entropy: 1.27653
Value Function Loss: 0.28175

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05980
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.05611

Collected Steps per Second: 11,253.96044
Overall Steps per Second: 9,712.50266

Timestep Collection Time: 4.44430
Timestep Consumption Time: 0.70535
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.14965

Cumulative Model Updates: 12,670
Cumulative Timesteps: 211,417,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.64218
Policy Entropy: 1.27879
Value Function Loss: 0.27376

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05335
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.05110

Collected Steps per Second: 10,915.17509
Overall Steps per Second: 9,329.99476

Timestep Collection Time: 4.58279
Timestep Consumption Time: 0.77862
PPO Batch Consumption Time: 0.03375
Total Iteration Time: 5.36142

Cumulative Model Updates: 12,673
Cumulative Timesteps: 211,467,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 211467022...
Checkpoint 211467022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.76288
Policy Entropy: 1.27788
Value Function Loss: 0.27257

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04824
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.05241

Collected Steps per Second: 10,687.68093
Overall Steps per Second: 9,215.23217

Timestep Collection Time: 4.67903
Timestep Consumption Time: 0.74764
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 5.42667

Cumulative Model Updates: 12,676
Cumulative Timesteps: 211,517,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.77409
Policy Entropy: 1.27372
Value Function Loss: 0.24124

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04998
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.06939

Collected Steps per Second: 11,549.77250
Overall Steps per Second: 9,744.67414

Timestep Collection Time: 4.32909
Timestep Consumption Time: 0.80192
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.13101

Cumulative Model Updates: 12,679
Cumulative Timesteps: 211,567,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 211567030...
Checkpoint 211567030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.56290
Policy Entropy: 1.27681
Value Function Loss: 0.23272

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03283
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.07952

Collected Steps per Second: 11,457.83679
Overall Steps per Second: 9,774.54108

Timestep Collection Time: 4.36557
Timestep Consumption Time: 0.75180
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.11738

Cumulative Model Updates: 12,682
Cumulative Timesteps: 211,617,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.32572
Policy Entropy: 1.28008
Value Function Loss: 0.22324

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03662
Policy Update Magnitude: 0.07293
Value Function Update Magnitude: 0.07840

Collected Steps per Second: 11,303.86819
Overall Steps per Second: 9,766.05742

Timestep Collection Time: 4.42326
Timestep Consumption Time: 0.69651
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.11977

Cumulative Model Updates: 12,685
Cumulative Timesteps: 211,667,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 211667050...
Checkpoint 211667050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.87495
Policy Entropy: 1.28173
Value Function Loss: 0.24699

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05151
Policy Update Magnitude: 0.07050
Value Function Update Magnitude: 0.07408

Collected Steps per Second: 11,192.69753
Overall Steps per Second: 9,543.31646

Timestep Collection Time: 4.46952
Timestep Consumption Time: 0.77247
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.24199

Cumulative Model Updates: 12,688
Cumulative Timesteps: 211,717,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.86297
Policy Entropy: 1.28353
Value Function Loss: 0.23964

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03681
Policy Update Magnitude: 0.06795
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 11,005.34822
Overall Steps per Second: 9,389.99049

Timestep Collection Time: 4.54379
Timestep Consumption Time: 0.78167
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.32546

Cumulative Model Updates: 12,691
Cumulative Timesteps: 211,767,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 211767082...
Checkpoint 211767082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.25352
Policy Entropy: 1.27696
Value Function Loss: 0.23168

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04896
Policy Update Magnitude: 0.06612
Value Function Update Magnitude: 0.07907

Collected Steps per Second: 10,712.57286
Overall Steps per Second: 9,149.27979

Timestep Collection Time: 4.66891
Timestep Consumption Time: 0.79775
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.46666

Cumulative Model Updates: 12,694
Cumulative Timesteps: 211,817,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.71363
Policy Entropy: 1.27560
Value Function Loss: 0.21078

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06509
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.06616

Collected Steps per Second: 11,243.16418
Overall Steps per Second: 9,546.28206

Timestep Collection Time: 4.44786
Timestep Consumption Time: 0.79062
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 5.23848

Cumulative Model Updates: 12,697
Cumulative Timesteps: 211,867,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 211867106...
Checkpoint 211867106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.85828
Policy Entropy: 1.28133
Value Function Loss: 0.21008

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.06435

Collected Steps per Second: 11,101.88888
Overall Steps per Second: 9,581.69434

Timestep Collection Time: 4.50626
Timestep Consumption Time: 0.71495
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.22121

Cumulative Model Updates: 12,700
Cumulative Timesteps: 211,917,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.96316
Policy Entropy: 1.27974
Value Function Loss: 0.24234

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06417
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.06036

Collected Steps per Second: 11,601.03812
Overall Steps per Second: 9,829.61368

Timestep Collection Time: 4.31151
Timestep Consumption Time: 0.77699
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 5.08850

Cumulative Model Updates: 12,703
Cumulative Timesteps: 211,967,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 211967152...
Checkpoint 211967152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.35117
Policy Entropy: 1.28337
Value Function Loss: 0.26209

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.06703

Collected Steps per Second: 11,649.00736
Overall Steps per Second: 9,910.82969

Timestep Collection Time: 4.29238
Timestep Consumption Time: 0.75281
PPO Batch Consumption Time: 0.03975
Total Iteration Time: 5.04519

Cumulative Model Updates: 12,706
Cumulative Timesteps: 212,017,154

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.89993
Policy Entropy: 1.28320
Value Function Loss: 0.26940

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07077
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.06071

Collected Steps per Second: 12,152.62383
Overall Steps per Second: 10,055.33854

Timestep Collection Time: 4.11516
Timestep Consumption Time: 0.85832
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 4.97348

Cumulative Model Updates: 12,709
Cumulative Timesteps: 212,067,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 212067164...
Checkpoint 212067164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.12430
Policy Entropy: 1.28595
Value Function Loss: 0.26450

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05347
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 11,649.24536
Overall Steps per Second: 9,822.94214

Timestep Collection Time: 4.29350
Timestep Consumption Time: 0.79826
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.09175

Cumulative Model Updates: 12,712
Cumulative Timesteps: 212,117,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.85643
Policy Entropy: 1.28584
Value Function Loss: 0.24863

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06307
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.09760

Collected Steps per Second: 11,995.72445
Overall Steps per Second: 10,150.88901

Timestep Collection Time: 4.17032
Timestep Consumption Time: 0.75792
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 4.92824

Cumulative Model Updates: 12,715
Cumulative Timesteps: 212,167,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 212167206...
Checkpoint 212167206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.00380
Policy Entropy: 1.28318
Value Function Loss: 0.24056

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05655
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.08484

Collected Steps per Second: 11,937.81383
Overall Steps per Second: 10,091.82202

Timestep Collection Time: 4.18854
Timestep Consumption Time: 0.76617
PPO Batch Consumption Time: 0.03313
Total Iteration Time: 4.95470

Cumulative Model Updates: 12,718
Cumulative Timesteps: 212,217,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.05595
Policy Entropy: 1.28334
Value Function Loss: 0.21083

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.07100

Collected Steps per Second: 11,913.13217
Overall Steps per Second: 9,969.13507

Timestep Collection Time: 4.19839
Timestep Consumption Time: 0.81869
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.01709

Cumulative Model Updates: 12,721
Cumulative Timesteps: 212,267,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 212267224...
Checkpoint 212267224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.08334
Policy Entropy: 1.28205
Value Function Loss: 0.20036

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05876
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.07037

Collected Steps per Second: 11,658.55127
Overall Steps per Second: 10,046.08923

Timestep Collection Time: 4.29076
Timestep Consumption Time: 0.68869
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 4.97945

Cumulative Model Updates: 12,724
Cumulative Timesteps: 212,317,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.77636
Policy Entropy: 1.28539
Value Function Loss: 0.21252

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05361
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.07367

Collected Steps per Second: 11,373.57691
Overall Steps per Second: 9,441.54234

Timestep Collection Time: 4.39774
Timestep Consumption Time: 0.89991
PPO Batch Consumption Time: 0.03945
Total Iteration Time: 5.29765

Cumulative Model Updates: 12,727
Cumulative Timesteps: 212,367,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 212367266...
Checkpoint 212367266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.13449
Policy Entropy: 1.28150
Value Function Loss: 0.22225

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06383
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.06824

Collected Steps per Second: 11,378.20550
Overall Steps per Second: 9,843.41448

Timestep Collection Time: 4.39542
Timestep Consumption Time: 0.68534
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.08076

Cumulative Model Updates: 12,730
Cumulative Timesteps: 212,417,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.79629
Policy Entropy: 1.28634
Value Function Loss: 0.22416

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05544
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.06538

Collected Steps per Second: 11,876.78189
Overall Steps per Second: 10,006.74027

Timestep Collection Time: 4.21006
Timestep Consumption Time: 0.78677
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 4.99683

Cumulative Model Updates: 12,733
Cumulative Timesteps: 212,467,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 212467280...
Checkpoint 212467280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.99474
Policy Entropy: 1.28186
Value Function Loss: 0.21377

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.06904

Collected Steps per Second: 11,706.55034
Overall Steps per Second: 9,845.41944

Timestep Collection Time: 4.27282
Timestep Consumption Time: 0.80771
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.08054

Cumulative Model Updates: 12,736
Cumulative Timesteps: 212,517,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.81923
Policy Entropy: 1.28366
Value Function Loss: 0.21522

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04570
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.06330

Collected Steps per Second: 11,614.46228
Overall Steps per Second: 9,942.89081

Timestep Collection Time: 4.30567
Timestep Consumption Time: 0.72386
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.02952

Cumulative Model Updates: 12,739
Cumulative Timesteps: 212,567,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 212567308...
Checkpoint 212567308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.49551
Policy Entropy: 1.28202
Value Function Loss: 0.22094

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04737
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.07309

Collected Steps per Second: 11,479.17485
Overall Steps per Second: 9,707.53512

Timestep Collection Time: 4.35589
Timestep Consumption Time: 0.79496
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.15084

Cumulative Model Updates: 12,742
Cumulative Timesteps: 212,617,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.72785
Policy Entropy: 1.28263
Value Function Loss: 0.23563

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04229
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.09584

Collected Steps per Second: 11,575.76247
Overall Steps per Second: 9,834.79240

Timestep Collection Time: 4.31937
Timestep Consumption Time: 0.76462
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 5.08399

Cumulative Model Updates: 12,745
Cumulative Timesteps: 212,667,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 212667310...
Checkpoint 212667310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.00022
Policy Entropy: 1.28138
Value Function Loss: 0.23303

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.06872
Value Function Update Magnitude: 0.09873

Collected Steps per Second: 11,418.25165
Overall Steps per Second: 9,538.88067

Timestep Collection Time: 4.37983
Timestep Consumption Time: 0.86292
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.24275

Cumulative Model Updates: 12,748
Cumulative Timesteps: 212,717,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.87383
Policy Entropy: 1.28238
Value Function Loss: 0.23287

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04143
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.09589

Collected Steps per Second: 11,915.16038
Overall Steps per Second: 10,082.57682

Timestep Collection Time: 4.19785
Timestep Consumption Time: 0.76299
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 4.96083

Cumulative Model Updates: 12,751
Cumulative Timesteps: 212,767,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 212767338...
Checkpoint 212767338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.69634
Policy Entropy: 1.28209
Value Function Loss: 0.21858

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04601
Policy Update Magnitude: 0.06722
Value Function Update Magnitude: 0.09291

Collected Steps per Second: 11,716.26232
Overall Steps per Second: 9,984.04478

Timestep Collection Time: 4.26791
Timestep Consumption Time: 0.74048
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.00839

Cumulative Model Updates: 12,754
Cumulative Timesteps: 212,817,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.31996
Policy Entropy: 1.28094
Value Function Loss: 0.23371

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04137
Policy Update Magnitude: 0.07074
Value Function Update Magnitude: 0.09916

Collected Steps per Second: 11,308.13297
Overall Steps per Second: 9,596.44606

Timestep Collection Time: 4.42354
Timestep Consumption Time: 0.78901
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 5.21255

Cumulative Model Updates: 12,757
Cumulative Timesteps: 212,867,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 212867364...
Checkpoint 212867364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.29076
Policy Entropy: 1.27945
Value Function Loss: 0.23079

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03732
Policy Update Magnitude: 0.07693
Value Function Update Magnitude: 0.09217

Collected Steps per Second: 11,485.95864
Overall Steps per Second: 9,944.07131

Timestep Collection Time: 4.35436
Timestep Consumption Time: 0.67517
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.02953

Cumulative Model Updates: 12,760
Cumulative Timesteps: 212,917,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.20327
Policy Entropy: 1.28353
Value Function Loss: 0.23503

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05010
Policy Update Magnitude: 0.07862
Value Function Update Magnitude: 0.08797

Collected Steps per Second: 10,940.24310
Overall Steps per Second: 9,282.49358

Timestep Collection Time: 4.57101
Timestep Consumption Time: 0.81633
PPO Batch Consumption Time: 0.03807
Total Iteration Time: 5.38735

Cumulative Model Updates: 12,763
Cumulative Timesteps: 212,967,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 212967386...
Checkpoint 212967386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.45763
Policy Entropy: 1.28437
Value Function Loss: 0.20471

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08459
Policy Update Magnitude: 0.07061
Value Function Update Magnitude: 0.07871

Collected Steps per Second: 11,624.96981
Overall Steps per Second: 9,778.09940

Timestep Collection Time: 4.30212
Timestep Consumption Time: 0.81258
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.11470

Cumulative Model Updates: 12,766
Cumulative Timesteps: 213,017,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.65508
Policy Entropy: 1.28438
Value Function Loss: 0.20294

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06459
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.08836

Collected Steps per Second: 11,791.54619
Overall Steps per Second: 9,943.75083

Timestep Collection Time: 4.24151
Timestep Consumption Time: 0.78818
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 5.02969

Cumulative Model Updates: 12,769
Cumulative Timesteps: 213,067,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 213067412...
Checkpoint 213067412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.21047
Policy Entropy: 1.28481
Value Function Loss: 0.21278

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07034
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.10609

Collected Steps per Second: 11,562.08908
Overall Steps per Second: 9,831.11972

Timestep Collection Time: 4.32707
Timestep Consumption Time: 0.76187
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.08894

Cumulative Model Updates: 12,772
Cumulative Timesteps: 213,117,442

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.26548
Policy Entropy: 1.27860
Value Function Loss: 0.23107

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06316
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.10594

Collected Steps per Second: 11,897.68957
Overall Steps per Second: 10,204.58238

Timestep Collection Time: 4.20519
Timestep Consumption Time: 0.69771
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.90290

Cumulative Model Updates: 12,775
Cumulative Timesteps: 213,167,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 213167474...
Checkpoint 213167474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.96977
Policy Entropy: 1.28325
Value Function Loss: 0.24461

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.06628
Value Function Update Magnitude: 0.12698

Collected Steps per Second: 12,257.64130
Overall Steps per Second: 10,234.43634

Timestep Collection Time: 4.07909
Timestep Consumption Time: 0.80638
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.88547

Cumulative Model Updates: 12,778
Cumulative Timesteps: 213,217,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.15558
Policy Entropy: 1.27564
Value Function Loss: 0.24666

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.06420
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 11,740.02173
Overall Steps per Second: 9,897.21356

Timestep Collection Time: 4.26013
Timestep Consumption Time: 0.79321
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.05334

Cumulative Model Updates: 12,781
Cumulative Timesteps: 213,267,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 213267488...
Checkpoint 213267488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.29189
Policy Entropy: 1.28286
Value Function Loss: 0.24421

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05194
Policy Update Magnitude: 0.07043
Value Function Update Magnitude: 0.10318

Collected Steps per Second: 12,597.30017
Overall Steps per Second: 10,471.78181

Timestep Collection Time: 3.96926
Timestep Consumption Time: 0.80566
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 4.77493

Cumulative Model Updates: 12,784
Cumulative Timesteps: 213,317,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.69580
Policy Entropy: 1.27813
Value Function Loss: 0.25582

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.06648
Value Function Update Magnitude: 0.10608

Collected Steps per Second: 12,523.18550
Overall Steps per Second: 10,496.23946

Timestep Collection Time: 3.99355
Timestep Consumption Time: 0.77120
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.76475

Cumulative Model Updates: 12,787
Cumulative Timesteps: 213,367,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 213367502...
Checkpoint 213367502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.35142
Policy Entropy: 1.28178
Value Function Loss: 0.22466

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06038
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.11680

Collected Steps per Second: 11,976.40367
Overall Steps per Second: 10,149.20685

Timestep Collection Time: 4.17755
Timestep Consumption Time: 0.75210
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 4.92965

Cumulative Model Updates: 12,790
Cumulative Timesteps: 213,417,534

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.06059
Policy Entropy: 1.27303
Value Function Loss: 0.24010

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.06298
Value Function Update Magnitude: 0.11275

Collected Steps per Second: 11,697.09433
Overall Steps per Second: 9,871.65467

Timestep Collection Time: 4.27508
Timestep Consumption Time: 0.79054
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.06561

Cumulative Model Updates: 12,793
Cumulative Timesteps: 213,467,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 213467540...
Checkpoint 213467540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.66070
Policy Entropy: 1.27921
Value Function Loss: 0.23068

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06251
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.10820

Collected Steps per Second: 11,828.53062
Overall Steps per Second: 10,046.39141

Timestep Collection Time: 4.22927
Timestep Consumption Time: 0.75023
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.97950

Cumulative Model Updates: 12,796
Cumulative Timesteps: 213,517,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.75956
Policy Entropy: 1.27484
Value Function Loss: 0.24274

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.10658

Collected Steps per Second: 11,362.30663
Overall Steps per Second: 9,619.97392

Timestep Collection Time: 4.40280
Timestep Consumption Time: 0.79742
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.20022

Cumulative Model Updates: 12,799
Cumulative Timesteps: 213,567,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 213567592...
Checkpoint 213567592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.63283
Policy Entropy: 1.28387
Value Function Loss: 0.23607

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07233
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.10598

Collected Steps per Second: 12,041.18355
Overall Steps per Second: 10,026.97629

Timestep Collection Time: 4.15391
Timestep Consumption Time: 0.83443
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.98834

Cumulative Model Updates: 12,802
Cumulative Timesteps: 213,617,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.47924
Policy Entropy: 1.27697
Value Function Loss: 0.23228

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.10270

Collected Steps per Second: 11,728.13046
Overall Steps per Second: 9,938.70338

Timestep Collection Time: 4.26564
Timestep Consumption Time: 0.76801
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 5.03365

Cumulative Model Updates: 12,805
Cumulative Timesteps: 213,667,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 213667638...
Checkpoint 213667638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.71639
Policy Entropy: 1.28115
Value Function Loss: 0.24211

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06133
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.10052

Collected Steps per Second: 12,230.23959
Overall Steps per Second: 10,177.76211

Timestep Collection Time: 4.09019
Timestep Consumption Time: 0.82484
PPO Batch Consumption Time: 0.04444
Total Iteration Time: 4.91503

Cumulative Model Updates: 12,808
Cumulative Timesteps: 213,717,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.03129
Policy Entropy: 1.27560
Value Function Loss: 0.24777

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 11,802.37730
Overall Steps per Second: 10,010.35270

Timestep Collection Time: 4.23898
Timestep Consumption Time: 0.75885
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.99783

Cumulative Model Updates: 12,811
Cumulative Timesteps: 213,767,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 213767692...
Checkpoint 213767692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.31653
Policy Entropy: 1.28885
Value Function Loss: 0.26083

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 11,650.57536
Overall Steps per Second: 9,865.04977

Timestep Collection Time: 4.29284
Timestep Consumption Time: 0.77698
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 5.06982

Cumulative Model Updates: 12,814
Cumulative Timesteps: 213,817,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.08351
Policy Entropy: 1.28505
Value Function Loss: 0.27268

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.07824

Collected Steps per Second: 11,057.21365
Overall Steps per Second: 9,481.62462

Timestep Collection Time: 4.52411
Timestep Consumption Time: 0.75178
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.27589

Cumulative Model Updates: 12,817
Cumulative Timesteps: 213,867,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 213867730...
Checkpoint 213867730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.67078
Policy Entropy: 1.28511
Value Function Loss: 0.26402

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06348
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 11,068.53464
Overall Steps per Second: 9,633.47169

Timestep Collection Time: 4.51966
Timestep Consumption Time: 0.67328
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.19294

Cumulative Model Updates: 12,820
Cumulative Timesteps: 213,917,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.09850
Policy Entropy: 1.28171
Value Function Loss: 0.24623

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06141
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.07149

Collected Steps per Second: 11,801.62456
Overall Steps per Second: 9,974.53067

Timestep Collection Time: 4.23857
Timestep Consumption Time: 0.77640
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.01497

Cumulative Model Updates: 12,823
Cumulative Timesteps: 213,967,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 213967778...
Checkpoint 213967778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.55855
Policy Entropy: 1.28654
Value Function Loss: 0.22382

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05155
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.07616

Collected Steps per Second: 11,425.15407
Overall Steps per Second: 9,822.85194

Timestep Collection Time: 4.37631
Timestep Consumption Time: 0.71386
PPO Batch Consumption Time: 0.03371
Total Iteration Time: 5.09017

Cumulative Model Updates: 12,826
Cumulative Timesteps: 214,017,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.08686
Policy Entropy: 1.28141
Value Function Loss: 0.25589

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05945
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.07314

Collected Steps per Second: 11,516.89141
Overall Steps per Second: 9,760.56987

Timestep Collection Time: 4.34388
Timestep Consumption Time: 0.78164
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.12552

Cumulative Model Updates: 12,829
Cumulative Timesteps: 214,067,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 214067806...
Checkpoint 214067806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.43435
Policy Entropy: 1.27884
Value Function Loss: 0.27365

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05401
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.08952

Collected Steps per Second: 11,256.14288
Overall Steps per Second: 9,450.01341

Timestep Collection Time: 4.44433
Timestep Consumption Time: 0.84942
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.29375

Cumulative Model Updates: 12,832
Cumulative Timesteps: 214,117,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.14188
Policy Entropy: 1.27800
Value Function Loss: 0.27572

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05706
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.09792

Collected Steps per Second: 10,848.82785
Overall Steps per Second: 9,360.35030

Timestep Collection Time: 4.61119
Timestep Consumption Time: 0.73327
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.34446

Cumulative Model Updates: 12,835
Cumulative Timesteps: 214,167,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 214167858...
Checkpoint 214167858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.20011
Policy Entropy: 1.27755
Value Function Loss: 0.24933

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05356
Policy Update Magnitude: 0.06376
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 11,338.98464
Overall Steps per Second: 9,668.52431

Timestep Collection Time: 4.40957
Timestep Consumption Time: 0.76185
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.17142

Cumulative Model Updates: 12,838
Cumulative Timesteps: 214,217,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.69557
Policy Entropy: 1.27797
Value Function Loss: 0.24557

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.08148

Collected Steps per Second: 11,282.71290
Overall Steps per Second: 9,636.85609

Timestep Collection Time: 4.43156
Timestep Consumption Time: 0.75686
PPO Batch Consumption Time: 0.03781
Total Iteration Time: 5.18841

Cumulative Model Updates: 12,841
Cumulative Timesteps: 214,267,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 214267858...
Checkpoint 214267858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.06146
Policy Entropy: 1.27538
Value Function Loss: 0.24235

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05479
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 11,404.63968
Overall Steps per Second: 9,613.54739

Timestep Collection Time: 4.38523
Timestep Consumption Time: 0.81701
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.20224

Cumulative Model Updates: 12,844
Cumulative Timesteps: 214,317,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.36274
Policy Entropy: 1.27758
Value Function Loss: 0.22519

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04638
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.06424

Collected Steps per Second: 11,812.34932
Overall Steps per Second: 9,990.84878

Timestep Collection Time: 4.23489
Timestep Consumption Time: 0.77209
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.00698

Cumulative Model Updates: 12,847
Cumulative Timesteps: 214,367,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 214367894...
Checkpoint 214367894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.97625
Policy Entropy: 1.28033
Value Function Loss: 0.22726

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05161
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.06037

Collected Steps per Second: 11,765.37140
Overall Steps per Second: 10,140.38555

Timestep Collection Time: 4.25146
Timestep Consumption Time: 0.68129
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.93275

Cumulative Model Updates: 12,850
Cumulative Timesteps: 214,417,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.83691
Policy Entropy: 1.28537
Value Function Loss: 0.23015

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06207
Policy Update Magnitude: 0.06608
Value Function Update Magnitude: 0.06865

Collected Steps per Second: 11,567.04506
Overall Steps per Second: 9,791.49227

Timestep Collection Time: 4.32401
Timestep Consumption Time: 0.78410
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.10811

Cumulative Model Updates: 12,853
Cumulative Timesteps: 214,467,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 214467930...
Checkpoint 214467930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.02519
Policy Entropy: 1.28007
Value Function Loss: 0.26441

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04703
Policy Update Magnitude: 0.06997
Value Function Update Magnitude: 0.07172

Collected Steps per Second: 11,803.79037
Overall Steps per Second: 9,902.87020

Timestep Collection Time: 4.23830
Timestep Consumption Time: 0.81357
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.05187

Cumulative Model Updates: 12,856
Cumulative Timesteps: 214,517,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.52346
Policy Entropy: 1.27904
Value Function Loss: 0.26747

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03936
Policy Update Magnitude: 0.07110
Value Function Update Magnitude: 0.06757

Collected Steps per Second: 12,182.78463
Overall Steps per Second: 10,165.33285

Timestep Collection Time: 4.10661
Timestep Consumption Time: 0.81501
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 4.92163

Cumulative Model Updates: 12,859
Cumulative Timesteps: 214,567,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 214567988...
Checkpoint 214567988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.78204
Policy Entropy: 1.27689
Value Function Loss: 0.25518

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04888
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.06107

Collected Steps per Second: 11,695.26451
Overall Steps per Second: 9,899.43793

Timestep Collection Time: 4.27626
Timestep Consumption Time: 0.77574
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 5.05200

Cumulative Model Updates: 12,862
Cumulative Timesteps: 214,618,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.78407
Policy Entropy: 1.28071
Value Function Loss: 0.23037

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 0.07092
Value Function Update Magnitude: 0.05625

Collected Steps per Second: 11,523.78917
Overall Steps per Second: 9,823.70626

Timestep Collection Time: 4.33937
Timestep Consumption Time: 0.75097
PPO Batch Consumption Time: 0.03816
Total Iteration Time: 5.09034

Cumulative Model Updates: 12,865
Cumulative Timesteps: 214,668,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 214668006...
Checkpoint 214668006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.40406
Policy Entropy: 1.28057
Value Function Loss: 0.20617

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 0.07355
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 11,891.02918
Overall Steps per Second: 9,927.13010

Timestep Collection Time: 4.20485
Timestep Consumption Time: 0.83185
PPO Batch Consumption Time: 0.03777
Total Iteration Time: 5.03670

Cumulative Model Updates: 12,868
Cumulative Timesteps: 214,718,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.94626
Policy Entropy: 1.28104
Value Function Loss: 0.21339

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04029
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.06641

Collected Steps per Second: 11,113.91665
Overall Steps per Second: 9,480.50323

Timestep Collection Time: 4.49904
Timestep Consumption Time: 0.77515
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 5.27419

Cumulative Model Updates: 12,871
Cumulative Timesteps: 214,768,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 214768008...
Checkpoint 214768008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.17421
Policy Entropy: 1.28567
Value Function Loss: 0.23423

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05507
Policy Update Magnitude: 0.07871
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 11,861.94277
Overall Steps per Second: 9,998.30210

Timestep Collection Time: 4.21718
Timestep Consumption Time: 0.78607
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 5.00325

Cumulative Model Updates: 12,874
Cumulative Timesteps: 214,818,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.26228
Policy Entropy: 1.28240
Value Function Loss: 0.25010

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.06914

Collected Steps per Second: 11,696.11619
Overall Steps per Second: 9,840.39719

Timestep Collection Time: 4.27680
Timestep Consumption Time: 0.80653
PPO Batch Consumption Time: 0.03349
Total Iteration Time: 5.08333

Cumulative Model Updates: 12,877
Cumulative Timesteps: 214,868,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 214868054...
Checkpoint 214868054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.03688
Policy Entropy: 1.28470
Value Function Loss: 0.25503

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05793
Policy Update Magnitude: 0.06527
Value Function Update Magnitude: 0.10180

Collected Steps per Second: 11,834.09242
Overall Steps per Second: 10,155.90178

Timestep Collection Time: 4.22610
Timestep Consumption Time: 0.69833
PPO Batch Consumption Time: 0.04084
Total Iteration Time: 4.92443

Cumulative Model Updates: 12,880
Cumulative Timesteps: 214,918,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.04261
Policy Entropy: 1.28201
Value Function Loss: 0.25216

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06471
Policy Update Magnitude: 0.06559
Value Function Update Magnitude: 0.10447

Collected Steps per Second: 11,789.44479
Overall Steps per Second: 9,936.20070

Timestep Collection Time: 4.24295
Timestep Consumption Time: 0.79137
PPO Batch Consumption Time: 0.03312
Total Iteration Time: 5.03432

Cumulative Model Updates: 12,883
Cumulative Timesteps: 214,968,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 214968088...
Checkpoint 214968088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.51776
Policy Entropy: 1.28141
Value Function Loss: 0.24638

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05530
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.09508

Collected Steps per Second: 11,609.38876
Overall Steps per Second: 9,779.35540

Timestep Collection Time: 4.30927
Timestep Consumption Time: 0.80640
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.11567

Cumulative Model Updates: 12,886
Cumulative Timesteps: 215,018,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.61830
Policy Entropy: 1.28119
Value Function Loss: 0.24372

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05006
Policy Update Magnitude: 0.05989
Value Function Update Magnitude: 0.09185

Collected Steps per Second: 11,040.12114
Overall Steps per Second: 9,355.26580

Timestep Collection Time: 4.52984
Timestep Consumption Time: 0.81581
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.34565

Cumulative Model Updates: 12,889
Cumulative Timesteps: 215,068,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 215068126...
Checkpoint 215068126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.35235
Policy Entropy: 1.28029
Value Function Loss: 0.24524

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04550
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.08643

Collected Steps per Second: 11,702.98451
Overall Steps per Second: 9,797.13668

Timestep Collection Time: 4.27429
Timestep Consumption Time: 0.83148
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.10578

Cumulative Model Updates: 12,892
Cumulative Timesteps: 215,118,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.19128
Policy Entropy: 1.28026
Value Function Loss: 0.23425

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04761
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.08550

Collected Steps per Second: 11,484.49630
Overall Steps per Second: 9,687.13078

Timestep Collection Time: 4.35474
Timestep Consumption Time: 0.80799
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 5.16273

Cumulative Model Updates: 12,895
Cumulative Timesteps: 215,168,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 215168160...
Checkpoint 215168160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.90634
Policy Entropy: 1.27780
Value Function Loss: 0.23988

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04850
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.07945

Collected Steps per Second: 11,875.12402
Overall Steps per Second: 9,918.02742

Timestep Collection Time: 4.21099
Timestep Consumption Time: 0.83094
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.04193

Cumulative Model Updates: 12,898
Cumulative Timesteps: 215,218,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.77632
Policy Entropy: 1.27945
Value Function Loss: 0.22764

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05684
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.07545

Collected Steps per Second: 11,283.08014
Overall Steps per Second: 9,595.91051

Timestep Collection Time: 4.43248
Timestep Consumption Time: 0.77933
PPO Batch Consumption Time: 0.03839
Total Iteration Time: 5.21180

Cumulative Model Updates: 12,901
Cumulative Timesteps: 215,268,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 215268178...
Checkpoint 215268178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.00562
Policy Entropy: 1.28082
Value Function Loss: 0.23195

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05279
Policy Update Magnitude: 0.05830
Value Function Update Magnitude: 0.07676

Collected Steps per Second: 11,014.41847
Overall Steps per Second: 9,313.13905

Timestep Collection Time: 4.54132
Timestep Consumption Time: 0.82959
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.37091

Cumulative Model Updates: 12,904
Cumulative Timesteps: 215,318,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.19468
Policy Entropy: 1.28499
Value Function Loss: 0.22658

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05366
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.07917

Collected Steps per Second: 11,028.96048
Overall Steps per Second: 9,317.07210

Timestep Collection Time: 4.53606
Timestep Consumption Time: 0.83344
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.36950

Cumulative Model Updates: 12,907
Cumulative Timesteps: 215,368,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 215368226...
Checkpoint 215368226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.47469
Policy Entropy: 1.27955
Value Function Loss: 0.22323

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05389
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.09458

Collected Steps per Second: 11,286.21733
Overall Steps per Second: 9,564.88258

Timestep Collection Time: 4.43071
Timestep Consumption Time: 0.79737
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.22808

Cumulative Model Updates: 12,910
Cumulative Timesteps: 215,418,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.77187
Policy Entropy: 1.27895
Value Function Loss: 0.22355

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04439
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.08817

Collected Steps per Second: 11,865.14806
Overall Steps per Second: 9,851.46755

Timestep Collection Time: 4.21672
Timestep Consumption Time: 0.86191
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 5.07863

Cumulative Model Updates: 12,913
Cumulative Timesteps: 215,468,264

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 215468264...
Checkpoint 215468264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.66846
Policy Entropy: 1.27464
Value Function Loss: 0.21839

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05218
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.08009

Collected Steps per Second: 11,955.94967
Overall Steps per Second: 9,981.26652

Timestep Collection Time: 4.18352
Timestep Consumption Time: 0.82766
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 5.01119

Cumulative Model Updates: 12,916
Cumulative Timesteps: 215,518,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.38151
Policy Entropy: 1.27409
Value Function Loss: 0.22170

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05785
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.06719

Collected Steps per Second: 12,701.30352
Overall Steps per Second: 10,805.40445

Timestep Collection Time: 3.93802
Timestep Consumption Time: 0.69096
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 4.62898

Cumulative Model Updates: 12,919
Cumulative Timesteps: 215,568,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 215568300...
Checkpoint 215568300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.21806
Policy Entropy: 1.28576
Value Function Loss: 0.22564

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04329
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.07298

Collected Steps per Second: 11,813.36695
Overall Steps per Second: 9,912.28292

Timestep Collection Time: 4.23283
Timestep Consumption Time: 0.81182
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.04465

Cumulative Model Updates: 12,922
Cumulative Timesteps: 215,618,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.46757
Policy Entropy: 1.27882
Value Function Loss: 0.24136

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.07140
Value Function Update Magnitude: 0.06981

Collected Steps per Second: 11,841.05373
Overall Steps per Second: 9,911.25096

Timestep Collection Time: 4.22378
Timestep Consumption Time: 0.82240
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 5.04618

Cumulative Model Updates: 12,925
Cumulative Timesteps: 215,668,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 215668318...
Checkpoint 215668318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.09260
Policy Entropy: 1.28000
Value Function Loss: 0.23151

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06518
Policy Update Magnitude: 0.07201
Value Function Update Magnitude: 0.07307

Collected Steps per Second: 12,564.35399
Overall Steps per Second: 10,663.38519

Timestep Collection Time: 3.97951
Timestep Consumption Time: 0.70943
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 4.68894

Cumulative Model Updates: 12,928
Cumulative Timesteps: 215,718,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.65672
Policy Entropy: 1.28114
Value Function Loss: 0.23189

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05575
Policy Update Magnitude: 0.07295
Value Function Update Magnitude: 0.07257

Collected Steps per Second: 12,392.87321
Overall Steps per Second: 10,232.07568

Timestep Collection Time: 4.03651
Timestep Consumption Time: 0.85243
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.88894

Cumulative Model Updates: 12,931
Cumulative Timesteps: 215,768,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 215768342...
Checkpoint 215768342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.40434
Policy Entropy: 1.28029
Value Function Loss: 0.21692

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06445
Policy Update Magnitude: 0.07098
Value Function Update Magnitude: 0.06623

Collected Steps per Second: 12,148.93989
Overall Steps per Second: 10,204.69447

Timestep Collection Time: 4.11608
Timestep Consumption Time: 0.78421
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.90029

Cumulative Model Updates: 12,934
Cumulative Timesteps: 215,818,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.28287
Policy Entropy: 1.27843
Value Function Loss: 0.22011

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.06069
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.07429

Collected Steps per Second: 11,619.24643
Overall Steps per Second: 9,832.19601

Timestep Collection Time: 4.30407
Timestep Consumption Time: 0.78229
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.08635

Cumulative Model Updates: 12,937
Cumulative Timesteps: 215,868,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 215868358...
Checkpoint 215868358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.58744
Policy Entropy: 1.29086
Value Function Loss: 0.23098

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06388
Policy Update Magnitude: 0.06963
Value Function Update Magnitude: 0.06798

Collected Steps per Second: 11,338.51701
Overall Steps per Second: 9,607.06837

Timestep Collection Time: 4.41081
Timestep Consumption Time: 0.79494
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.20575

Cumulative Model Updates: 12,940
Cumulative Timesteps: 215,918,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.95091
Policy Entropy: 1.28451
Value Function Loss: 0.23856

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.06164

Collected Steps per Second: 11,665.10176
Overall Steps per Second: 10,072.07665

Timestep Collection Time: 4.28886
Timestep Consumption Time: 0.67834
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.96720

Cumulative Model Updates: 12,943
Cumulative Timesteps: 215,968,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 215968400...
Checkpoint 215968400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.02876
Policy Entropy: 1.28757
Value Function Loss: 0.25653

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.04846

Collected Steps per Second: 11,633.82430
Overall Steps per Second: 9,867.26868

Timestep Collection Time: 4.29936
Timestep Consumption Time: 0.76972
PPO Batch Consumption Time: 0.03942
Total Iteration Time: 5.06908

Cumulative Model Updates: 12,946
Cumulative Timesteps: 216,018,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.38373
Policy Entropy: 1.28341
Value Function Loss: 0.22707

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06370
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.04226

Collected Steps per Second: 11,708.47056
Overall Steps per Second: 9,952.55053

Timestep Collection Time: 4.27058
Timestep Consumption Time: 0.75346
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 5.02404

Cumulative Model Updates: 12,949
Cumulative Timesteps: 216,068,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 216068420...
Checkpoint 216068420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.30722
Policy Entropy: 1.28301
Value Function Loss: 0.23576

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.03913

Collected Steps per Second: 11,743.36418
Overall Steps per Second: 9,956.52782

Timestep Collection Time: 4.25960
Timestep Consumption Time: 0.76444
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.02404

Cumulative Model Updates: 12,952
Cumulative Timesteps: 216,118,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.94992
Policy Entropy: 1.28530
Value Function Loss: 0.22356

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.03700

Collected Steps per Second: 11,577.01777
Overall Steps per Second: 9,855.52171

Timestep Collection Time: 4.32028
Timestep Consumption Time: 0.75464
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.07492

Cumulative Model Updates: 12,955
Cumulative Timesteps: 216,168,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 216168458...
Checkpoint 216168458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.47896
Policy Entropy: 1.28300
Value Function Loss: 0.24173

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05755
Policy Update Magnitude: 0.06295
Value Function Update Magnitude: 0.04997

Collected Steps per Second: 10,849.68264
Overall Steps per Second: 9,387.39283

Timestep Collection Time: 4.60880
Timestep Consumption Time: 0.71792
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.32672

Cumulative Model Updates: 12,958
Cumulative Timesteps: 216,218,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.96925
Policy Entropy: 1.28000
Value Function Loss: 0.24174

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05265
Policy Update Magnitude: 0.06908
Value Function Update Magnitude: 0.05660

Collected Steps per Second: 11,552.59762
Overall Steps per Second: 9,825.35174

Timestep Collection Time: 4.33011
Timestep Consumption Time: 0.76121
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.09132

Cumulative Model Updates: 12,961
Cumulative Timesteps: 216,268,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 216268486...
Checkpoint 216268486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.75254
Policy Entropy: 1.27949
Value Function Loss: 0.23700

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04625
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.04716

Collected Steps per Second: 11,534.87146
Overall Steps per Second: 9,760.57297

Timestep Collection Time: 4.33503
Timestep Consumption Time: 0.78803
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 5.12306

Cumulative Model Updates: 12,964
Cumulative Timesteps: 216,318,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.14070
Policy Entropy: 1.28322
Value Function Loss: 0.24086

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03631
Policy Update Magnitude: 0.07432
Value Function Update Magnitude: 0.04417

Collected Steps per Second: 11,658.84134
Overall Steps per Second: 10,002.08150

Timestep Collection Time: 4.28928
Timestep Consumption Time: 0.71048
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 4.99976

Cumulative Model Updates: 12,967
Cumulative Timesteps: 216,368,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 216368498...
Checkpoint 216368498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.61151
Policy Entropy: 1.28205
Value Function Loss: 0.25041

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07093
Policy Update Magnitude: 0.07214
Value Function Update Magnitude: 0.04397

Collected Steps per Second: 11,443.99218
Overall Steps per Second: 9,678.50766

Timestep Collection Time: 4.36910
Timestep Consumption Time: 0.79698
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.16609

Cumulative Model Updates: 12,970
Cumulative Timesteps: 216,418,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.64152
Policy Entropy: 1.28493
Value Function Loss: 0.23066

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.03941

Collected Steps per Second: 11,171.16594
Overall Steps per Second: 9,530.17357

Timestep Collection Time: 4.47832
Timestep Consumption Time: 0.77112
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.24943

Cumulative Model Updates: 12,973
Cumulative Timesteps: 216,468,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 216468526...
Checkpoint 216468526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.01628
Policy Entropy: 1.28043
Value Function Loss: 0.23026

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.06372
Value Function Update Magnitude: 0.05182

Collected Steps per Second: 11,191.05768
Overall Steps per Second: 9,507.22409

Timestep Collection Time: 4.46982
Timestep Consumption Time: 0.79165
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.26147

Cumulative Model Updates: 12,976
Cumulative Timesteps: 216,518,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.09504
Policy Entropy: 1.27564
Value Function Loss: 0.22853

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07645
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.05109

Collected Steps per Second: 11,736.46010
Overall Steps per Second: 9,818.17703

Timestep Collection Time: 4.26125
Timestep Consumption Time: 0.83257
PPO Batch Consumption Time: 0.03737
Total Iteration Time: 5.09382

Cumulative Model Updates: 12,979
Cumulative Timesteps: 216,568,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 216568560...
Checkpoint 216568560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.49079
Policy Entropy: 1.27563
Value Function Loss: 0.24642

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06772
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.05905

Collected Steps per Second: 11,786.92515
Overall Steps per Second: 10,058.03354

Timestep Collection Time: 4.24216
Timestep Consumption Time: 0.72919
PPO Batch Consumption Time: 0.04580
Total Iteration Time: 4.97135

Cumulative Model Updates: 12,982
Cumulative Timesteps: 216,618,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.28978
Policy Entropy: 1.27775
Value Function Loss: 0.23118

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06731
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.06584

Collected Steps per Second: 11,386.30714
Overall Steps per Second: 9,577.52219

Timestep Collection Time: 4.39247
Timestep Consumption Time: 0.82955
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.22202

Cumulative Model Updates: 12,985
Cumulative Timesteps: 216,668,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 216668576...
Checkpoint 216668576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.97746
Policy Entropy: 1.27911
Value Function Loss: 0.20787

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06407
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 11,767.45710
Overall Steps per Second: 10,015.66213

Timestep Collection Time: 4.25139
Timestep Consumption Time: 0.74359
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 4.99498

Cumulative Model Updates: 12,988
Cumulative Timesteps: 216,718,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.48901
Policy Entropy: 1.27786
Value Function Loss: 0.19606

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05277
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.06310

Collected Steps per Second: 11,749.00546
Overall Steps per Second: 9,941.06217

Timestep Collection Time: 4.25721
Timestep Consumption Time: 0.77424
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.03145

Cumulative Model Updates: 12,991
Cumulative Timesteps: 216,768,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 216768622...
Checkpoint 216768622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.04897
Policy Entropy: 1.27572
Value Function Loss: 0.20436

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06677
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.05855

Collected Steps per Second: 11,353.60952
Overall Steps per Second: 9,618.84010

Timestep Collection Time: 4.40635
Timestep Consumption Time: 0.79469
PPO Batch Consumption Time: 0.03856
Total Iteration Time: 5.20104

Cumulative Model Updates: 12,994
Cumulative Timesteps: 216,818,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.97149
Policy Entropy: 1.28067
Value Function Loss: 0.20154

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.06366

Collected Steps per Second: 11,482.62015
Overall Steps per Second: 9,921.40952

Timestep Collection Time: 4.35563
Timestep Consumption Time: 0.68539
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.04102

Cumulative Model Updates: 12,997
Cumulative Timesteps: 216,868,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 216868664...
Checkpoint 216868664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.44263
Policy Entropy: 1.27772
Value Function Loss: 0.21704

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05549
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.06087

Collected Steps per Second: 11,597.80179
Overall Steps per Second: 9,781.26326

Timestep Collection Time: 4.31340
Timestep Consumption Time: 0.80107
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.11447

Cumulative Model Updates: 13,000
Cumulative Timesteps: 216,918,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.77542
Policy Entropy: 1.28227
Value Function Loss: 0.20764

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.06420
Value Function Update Magnitude: 0.05732

Collected Steps per Second: 11,811.16730
Overall Steps per Second: 10,017.97361

Timestep Collection Time: 4.23362
Timestep Consumption Time: 0.75781
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.99143

Cumulative Model Updates: 13,003
Cumulative Timesteps: 216,968,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 216968694...
Checkpoint 216968694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.16065
Policy Entropy: 1.27715
Value Function Loss: 0.21786

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.05041

Collected Steps per Second: 11,710.20561
Overall Steps per Second: 9,972.69692

Timestep Collection Time: 4.27080
Timestep Consumption Time: 0.74409
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 5.01489

Cumulative Model Updates: 13,006
Cumulative Timesteps: 217,018,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.49966
Policy Entropy: 1.28449
Value Function Loss: 0.23606

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.04494

Collected Steps per Second: 11,672.57703
Overall Steps per Second: 9,899.64220

Timestep Collection Time: 4.28423
Timestep Consumption Time: 0.76727
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.05150

Cumulative Model Updates: 13,009
Cumulative Timesteps: 217,068,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 217068714...
Checkpoint 217068714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.44054
Policy Entropy: 1.27741
Value Function Loss: 0.25016

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05947
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.05639

Collected Steps per Second: 11,137.19881
Overall Steps per Second: 9,605.38522

Timestep Collection Time: 4.49054
Timestep Consumption Time: 0.71613
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.20666

Cumulative Model Updates: 13,012
Cumulative Timesteps: 217,118,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.10810
Policy Entropy: 1.28123
Value Function Loss: 0.24806

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06263
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.05697

Collected Steps per Second: 11,431.90640
Overall Steps per Second: 9,674.43798

Timestep Collection Time: 4.37442
Timestep Consumption Time: 0.79466
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.16909

Cumulative Model Updates: 13,015
Cumulative Timesteps: 217,168,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 217168734...
Checkpoint 217168734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.07068
Policy Entropy: 1.27250
Value Function Loss: 0.22684

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.06069

Collected Steps per Second: 11,771.59990
Overall Steps per Second: 10,007.75487

Timestep Collection Time: 4.24989
Timestep Consumption Time: 0.74903
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 4.99892

Cumulative Model Updates: 13,018
Cumulative Timesteps: 217,218,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.76058
Policy Entropy: 1.27993
Value Function Loss: 0.22606

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.05760

Collected Steps per Second: 12,242.81655
Overall Steps per Second: 10,240.52879

Timestep Collection Time: 4.08631
Timestep Consumption Time: 0.79898
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.88529

Cumulative Model Updates: 13,021
Cumulative Timesteps: 217,268,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 217268790...
Checkpoint 217268790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.30537
Policy Entropy: 1.27538
Value Function Loss: 0.21824

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07382
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 11,454.45989
Overall Steps per Second: 9,773.38095

Timestep Collection Time: 4.36616
Timestep Consumption Time: 0.75101
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.11716

Cumulative Model Updates: 13,024
Cumulative Timesteps: 217,318,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.61094
Policy Entropy: 1.27800
Value Function Loss: 0.21827

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06610
Policy Update Magnitude: 0.06448
Value Function Update Magnitude: 0.07586

Collected Steps per Second: 11,663.74863
Overall Steps per Second: 10,001.11448

Timestep Collection Time: 4.28850
Timestep Consumption Time: 0.71294
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 5.00144

Cumulative Model Updates: 13,027
Cumulative Timesteps: 217,368,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 217368822...
Checkpoint 217368822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.01773
Policy Entropy: 1.27997
Value Function Loss: 0.20467

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.06773

Collected Steps per Second: 10,819.62954
Overall Steps per Second: 9,237.73968

Timestep Collection Time: 4.62382
Timestep Consumption Time: 0.79179
PPO Batch Consumption Time: 0.03877
Total Iteration Time: 5.41561

Cumulative Model Updates: 13,030
Cumulative Timesteps: 217,418,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.68604
Policy Entropy: 1.28212
Value Function Loss: 0.20575

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05039
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.08288

Collected Steps per Second: 11,287.06648
Overall Steps per Second: 9,599.41073

Timestep Collection Time: 4.43233
Timestep Consumption Time: 0.77924
PPO Batch Consumption Time: 0.03771
Total Iteration Time: 5.21157

Cumulative Model Updates: 13,033
Cumulative Timesteps: 217,468,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 217468878...
Checkpoint 217468878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.04200
Policy Entropy: 1.27741
Value Function Loss: 0.20519

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04970
Policy Update Magnitude: 0.06094
Value Function Update Magnitude: 0.09953

Collected Steps per Second: 11,601.51516
Overall Steps per Second: 9,786.06410

Timestep Collection Time: 4.31168
Timestep Consumption Time: 0.79988
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.11155

Cumulative Model Updates: 13,036
Cumulative Timesteps: 217,518,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.87010
Policy Entropy: 1.27717
Value Function Loss: 0.20901

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04026
Policy Update Magnitude: 0.06257
Value Function Update Magnitude: 0.08587

Collected Steps per Second: 11,426.69372
Overall Steps per Second: 9,716.35592

Timestep Collection Time: 4.37677
Timestep Consumption Time: 0.77043
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.14720

Cumulative Model Updates: 13,039
Cumulative Timesteps: 217,568,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 217568912...
Checkpoint 217568912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.17898
Policy Entropy: 1.27414
Value Function Loss: 0.20238

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04971
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.08231

Collected Steps per Second: 10,941.76227
Overall Steps per Second: 9,381.63141

Timestep Collection Time: 4.57239
Timestep Consumption Time: 0.76037
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.33276

Cumulative Model Updates: 13,042
Cumulative Timesteps: 217,618,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.28293
Policy Entropy: 1.27656
Value Function Loss: 0.20758

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05397
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.07604

Collected Steps per Second: 11,219.65159
Overall Steps per Second: 9,446.71627

Timestep Collection Time: 4.45807
Timestep Consumption Time: 0.83668
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.29475

Cumulative Model Updates: 13,045
Cumulative Timesteps: 217,668,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 217668960...
Checkpoint 217668960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.31816
Policy Entropy: 1.27687
Value Function Loss: 0.20169

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06267
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.07826

Collected Steps per Second: 11,334.91982
Overall Steps per Second: 9,662.39598

Timestep Collection Time: 4.41185
Timestep Consumption Time: 0.76367
PPO Batch Consumption Time: 0.03937
Total Iteration Time: 5.17553

Cumulative Model Updates: 13,048
Cumulative Timesteps: 217,718,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.47101
Policy Entropy: 1.27679
Value Function Loss: 0.21218

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04697
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.08151

Collected Steps per Second: 11,639.93560
Overall Steps per Second: 9,697.57934

Timestep Collection Time: 4.29624
Timestep Consumption Time: 0.86051
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.15675

Cumulative Model Updates: 13,051
Cumulative Timesteps: 217,768,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 217768976...
Checkpoint 217768976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.60115
Policy Entropy: 1.27855
Value Function Loss: 0.22092

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05485
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.08206

Collected Steps per Second: 11,405.84876
Overall Steps per Second: 9,541.28064

Timestep Collection Time: 4.38389
Timestep Consumption Time: 0.85671
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 5.24060

Cumulative Model Updates: 13,054
Cumulative Timesteps: 217,818,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.25924
Policy Entropy: 1.27697
Value Function Loss: 0.24096

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.08804

Collected Steps per Second: 12,101.51658
Overall Steps per Second: 10,293.75985

Timestep Collection Time: 4.13353
Timestep Consumption Time: 0.72592
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 4.85945

Cumulative Model Updates: 13,057
Cumulative Timesteps: 217,869,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 217869000...
Checkpoint 217869000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.31180
Policy Entropy: 1.27863
Value Function Loss: 0.25188

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.08916

Collected Steps per Second: 12,478.25100
Overall Steps per Second: 10,412.97588

Timestep Collection Time: 4.00857
Timestep Consumption Time: 0.79505
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.80362

Cumulative Model Updates: 13,060
Cumulative Timesteps: 217,919,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.91644
Policy Entropy: 1.28436
Value Function Loss: 0.23838

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.06524
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.09320

Collected Steps per Second: 11,434.52004
Overall Steps per Second: 9,671.45922

Timestep Collection Time: 4.37500
Timestep Consumption Time: 0.79754
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.17254

Cumulative Model Updates: 13,063
Cumulative Timesteps: 217,969,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 217969046...
Checkpoint 217969046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.92398
Policy Entropy: 1.28336
Value Function Loss: 0.23656

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 12,934.89517
Overall Steps per Second: 10,639.35837

Timestep Collection Time: 3.86567
Timestep Consumption Time: 0.83405
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 4.69972

Cumulative Model Updates: 13,066
Cumulative Timesteps: 218,019,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.67937
Policy Entropy: 1.28457
Value Function Loss: 0.23126

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05705
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.07908

Collected Steps per Second: 12,591.53791
Overall Steps per Second: 10,492.15398

Timestep Collection Time: 3.97171
Timestep Consumption Time: 0.79470
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.76642

Cumulative Model Updates: 13,069
Cumulative Timesteps: 218,069,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 218069058...
Checkpoint 218069058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.91236
Policy Entropy: 1.28843
Value Function Loss: 0.23718

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.07678

Collected Steps per Second: 12,402.68337
Overall Steps per Second: 10,505.20261

Timestep Collection Time: 4.03380
Timestep Consumption Time: 0.72860
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 4.76240

Cumulative Model Updates: 13,072
Cumulative Timesteps: 218,119,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.28186
Policy Entropy: 1.28719
Value Function Loss: 0.26988

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.09742

Collected Steps per Second: 12,352.27944
Overall Steps per Second: 10,308.80225

Timestep Collection Time: 4.04800
Timestep Consumption Time: 0.80242
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 4.85042

Cumulative Model Updates: 13,075
Cumulative Timesteps: 218,169,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 218169090...
Checkpoint 218169090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.84216
Policy Entropy: 1.28655
Value Function Loss: 0.26196

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06683
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 11,417.40734
Overall Steps per Second: 9,625.97053

Timestep Collection Time: 4.38191
Timestep Consumption Time: 0.81549
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 5.19740

Cumulative Model Updates: 13,078
Cumulative Timesteps: 218,219,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.32422
Policy Entropy: 1.28515
Value Function Loss: 0.24922

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.05813
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.10427

Collected Steps per Second: 11,379.39602
Overall Steps per Second: 9,634.14717

Timestep Collection Time: 4.39637
Timestep Consumption Time: 0.79641
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.19278

Cumulative Model Updates: 13,081
Cumulative Timesteps: 218,269,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 218269148...
Checkpoint 218269148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.30627
Policy Entropy: 1.28750
Value Function Loss: 0.21831

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05821
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.08808

Collected Steps per Second: 11,543.60339
Overall Steps per Second: 9,721.88813

Timestep Collection Time: 4.33158
Timestep Consumption Time: 0.81166
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.14324

Cumulative Model Updates: 13,084
Cumulative Timesteps: 218,319,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.11846
Policy Entropy: 1.28453
Value Function Loss: 0.23867

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.05395
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.07613

Collected Steps per Second: 11,808.03813
Overall Steps per Second: 10,146.74779

Timestep Collection Time: 4.23491
Timestep Consumption Time: 0.69337
PPO Batch Consumption Time: 0.03890
Total Iteration Time: 4.92828

Cumulative Model Updates: 13,087
Cumulative Timesteps: 218,369,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 218369156...
Checkpoint 218369156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.41300
Policy Entropy: 1.28280
Value Function Loss: 0.25254

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04579
Policy Update Magnitude: 0.06901
Value Function Update Magnitude: 0.06662

Collected Steps per Second: 11,701.30062
Overall Steps per Second: 9,855.08055

Timestep Collection Time: 4.27491
Timestep Consumption Time: 0.80085
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 5.07576

Cumulative Model Updates: 13,090
Cumulative Timesteps: 218,419,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.50923
Policy Entropy: 1.27976
Value Function Loss: 0.24710

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07043
Policy Update Magnitude: 0.06291
Value Function Update Magnitude: 0.06537

Collected Steps per Second: 11,653.33719
Overall Steps per Second: 9,902.03318

Timestep Collection Time: 4.29250
Timestep Consumption Time: 0.75919
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.05169

Cumulative Model Updates: 13,093
Cumulative Timesteps: 218,469,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 218469200...
Checkpoint 218469200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.19755
Policy Entropy: 1.28258
Value Function Loss: 0.22208

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07233
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.05915

Collected Steps per Second: 11,900.15039
Overall Steps per Second: 10,057.65807

Timestep Collection Time: 4.20247
Timestep Consumption Time: 0.76986
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 4.97233

Cumulative Model Updates: 13,096
Cumulative Timesteps: 218,519,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.54585
Policy Entropy: 1.27927
Value Function Loss: 0.21148

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03847
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.06438

Collected Steps per Second: 11,148.11049
Overall Steps per Second: 9,438.43946

Timestep Collection Time: 4.48614
Timestep Consumption Time: 0.81262
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.29876

Cumulative Model Updates: 13,099
Cumulative Timesteps: 218,569,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 218569222...
Checkpoint 218569222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.32373
Policy Entropy: 1.28241
Value Function Loss: 0.19688

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03801
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.08451

Collected Steps per Second: 11,780.98736
Overall Steps per Second: 10,128.49113

Timestep Collection Time: 4.24531
Timestep Consumption Time: 0.69264
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 4.93795

Cumulative Model Updates: 13,102
Cumulative Timesteps: 218,619,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.31046
Policy Entropy: 1.28038
Value Function Loss: 0.20659

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04867
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.07885

Collected Steps per Second: 11,742.39764
Overall Steps per Second: 9,945.84494

Timestep Collection Time: 4.25910
Timestep Consumption Time: 0.76934
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 5.02843

Cumulative Model Updates: 13,105
Cumulative Timesteps: 218,669,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 218669248...
Checkpoint 218669248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.18032
Policy Entropy: 1.28246
Value Function Loss: 0.21033

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06316
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.06632

Collected Steps per Second: 11,711.24258
Overall Steps per Second: 9,985.78367

Timestep Collection Time: 4.27145
Timestep Consumption Time: 0.73807
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 5.00952

Cumulative Model Updates: 13,108
Cumulative Timesteps: 218,719,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.37001
Policy Entropy: 1.28205
Value Function Loss: 0.23859

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03690
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.07093

Collected Steps per Second: 11,418.27582
Overall Steps per Second: 9,593.09853

Timestep Collection Time: 4.37912
Timestep Consumption Time: 0.83317
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.21229

Cumulative Model Updates: 13,111
Cumulative Timesteps: 218,769,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 218769274...
Checkpoint 218769274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.19963
Policy Entropy: 1.28274
Value Function Loss: 0.22732

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03858
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.07589

Collected Steps per Second: 10,970.85509
Overall Steps per Second: 9,348.10901

Timestep Collection Time: 4.55899
Timestep Consumption Time: 0.79140
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.35039

Cumulative Model Updates: 13,114
Cumulative Timesteps: 218,819,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.96759
Policy Entropy: 1.28242
Value Function Loss: 0.23257

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04459
Policy Update Magnitude: 0.06841
Value Function Update Magnitude: 0.07204

Collected Steps per Second: 10,995.11892
Overall Steps per Second: 9,544.27053

Timestep Collection Time: 4.55020
Timestep Consumption Time: 0.69169
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.24189

Cumulative Model Updates: 13,117
Cumulative Timesteps: 218,869,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 218869320...
Checkpoint 218869320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.08749
Policy Entropy: 1.28290
Value Function Loss: 0.20036

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04073
Policy Update Magnitude: 0.06793
Value Function Update Magnitude: 0.07145

Collected Steps per Second: 11,411.13453
Overall Steps per Second: 9,690.95435

Timestep Collection Time: 4.38309
Timestep Consumption Time: 0.77801
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.16110

Cumulative Model Updates: 13,120
Cumulative Timesteps: 218,919,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.83132
Policy Entropy: 1.28256
Value Function Loss: 0.18995

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05430
Policy Update Magnitude: 0.06811
Value Function Update Magnitude: 0.08406

Collected Steps per Second: 11,232.37673
Overall Steps per Second: 9,560.78409

Timestep Collection Time: 4.45284
Timestep Consumption Time: 0.77853
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 5.23137

Cumulative Model Updates: 13,123
Cumulative Timesteps: 218,969,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 218969352...
Checkpoint 218969352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.49474
Policy Entropy: 1.28271
Value Function Loss: 0.19157

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05421
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.09121

Collected Steps per Second: 11,096.64015
Overall Steps per Second: 9,592.64436

Timestep Collection Time: 4.50803
Timestep Consumption Time: 0.70680
PPO Batch Consumption Time: 0.03868
Total Iteration Time: 5.21483

Cumulative Model Updates: 13,126
Cumulative Timesteps: 219,019,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.93079
Policy Entropy: 1.28298
Value Function Loss: 0.21762

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07303
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.09305

Collected Steps per Second: 11,957.31191
Overall Steps per Second: 10,101.65319

Timestep Collection Time: 4.18388
Timestep Consumption Time: 0.76857
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 4.95246

Cumulative Model Updates: 13,129
Cumulative Timesteps: 219,069,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 219069404...
Checkpoint 219069404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.31452
Policy Entropy: 1.28428
Value Function Loss: 0.22810

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04683
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.09012

Collected Steps per Second: 11,788.79994
Overall Steps per Second: 10,190.98492

Timestep Collection Time: 4.24386
Timestep Consumption Time: 0.66538
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.90924

Cumulative Model Updates: 13,132
Cumulative Timesteps: 219,119,434

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.32116
Policy Entropy: 1.28745
Value Function Loss: 0.22491

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03951
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.08434

Collected Steps per Second: 11,401.53692
Overall Steps per Second: 9,717.27816

Timestep Collection Time: 4.38555
Timestep Consumption Time: 0.76013
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.14568

Cumulative Model Updates: 13,135
Cumulative Timesteps: 219,169,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 219169436...
Checkpoint 219169436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.39298
Policy Entropy: 1.28522
Value Function Loss: 0.23074

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05482
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.07914

Collected Steps per Second: 11,692.43945
Overall Steps per Second: 9,996.86918

Timestep Collection Time: 4.27627
Timestep Consumption Time: 0.72530
PPO Batch Consumption Time: 0.03975
Total Iteration Time: 5.00157

Cumulative Model Updates: 13,138
Cumulative Timesteps: 219,219,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.59186
Policy Entropy: 1.28136
Value Function Loss: 0.22974

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04359
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 11,847.47485
Overall Steps per Second: 9,930.18277

Timestep Collection Time: 4.22166
Timestep Consumption Time: 0.81511
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.03677

Cumulative Model Updates: 13,141
Cumulative Timesteps: 219,269,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 219269452...
Checkpoint 219269452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.65222
Policy Entropy: 1.28202
Value Function Loss: 0.23092

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04035
Policy Update Magnitude: 0.06923
Value Function Update Magnitude: 0.07463

Collected Steps per Second: 11,762.10795
Overall Steps per Second: 9,929.91181

Timestep Collection Time: 4.25315
Timestep Consumption Time: 0.78476
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 5.03791

Cumulative Model Updates: 13,144
Cumulative Timesteps: 219,319,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.21722
Policy Entropy: 1.28544
Value Function Loss: 0.20644

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04847
Policy Update Magnitude: 0.07216
Value Function Update Magnitude: 0.07914

Collected Steps per Second: 12,024.41720
Overall Steps per Second: 10,166.02550

Timestep Collection Time: 4.15887
Timestep Consumption Time: 0.76026
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 4.91913

Cumulative Model Updates: 13,147
Cumulative Timesteps: 219,369,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 219369486...
Checkpoint 219369486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.57354
Policy Entropy: 1.28610
Value Function Loss: 0.21487

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04105
Policy Update Magnitude: 0.06952
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 11,616.18607
Overall Steps per Second: 9,842.20110

Timestep Collection Time: 4.30606
Timestep Consumption Time: 0.77614
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.08220

Cumulative Model Updates: 13,150
Cumulative Timesteps: 219,419,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.69172
Policy Entropy: 1.28745
Value Function Loss: 0.20895

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04412
Policy Update Magnitude: 0.06480
Value Function Update Magnitude: 0.07981

Collected Steps per Second: 11,002.05776
Overall Steps per Second: 9,519.98886

Timestep Collection Time: 4.54679
Timestep Consumption Time: 0.70784
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.25463

Cumulative Model Updates: 13,153
Cumulative Timesteps: 219,469,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 219469530...
Checkpoint 219469530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.50078
Policy Entropy: 1.28615
Value Function Loss: 0.23146

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04844
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.07663

Collected Steps per Second: 11,638.79712
Overall Steps per Second: 9,702.50174

Timestep Collection Time: 4.29821
Timestep Consumption Time: 0.85778
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.15599

Cumulative Model Updates: 13,156
Cumulative Timesteps: 219,519,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.77418
Policy Entropy: 1.28703
Value Function Loss: 0.23000

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05703
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.06973

Collected Steps per Second: 11,813.12897
Overall Steps per Second: 10,119.00747

Timestep Collection Time: 4.23444
Timestep Consumption Time: 0.70893
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.94337

Cumulative Model Updates: 13,159
Cumulative Timesteps: 219,569,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 219569578...
Checkpoint 219569578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.28426
Policy Entropy: 1.28421
Value Function Loss: 0.24432

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.05762
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.06493

Collected Steps per Second: 10,928.73892
Overall Steps per Second: 9,352.68831

Timestep Collection Time: 4.57601
Timestep Consumption Time: 0.77112
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.34713

Cumulative Model Updates: 13,162
Cumulative Timesteps: 219,619,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.57482
Policy Entropy: 1.28717
Value Function Loss: 0.21584

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05363
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.07508

Collected Steps per Second: 11,764.09034
Overall Steps per Second: 9,988.90415

Timestep Collection Time: 4.25260
Timestep Consumption Time: 0.75575
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.00836

Cumulative Model Updates: 13,165
Cumulative Timesteps: 219,669,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 219669616...
Checkpoint 219669616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.18434
Policy Entropy: 1.28516
Value Function Loss: 0.21174

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05952
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.07181

Collected Steps per Second: 11,899.68916
Overall Steps per Second: 10,033.44777

Timestep Collection Time: 4.20196
Timestep Consumption Time: 0.78157
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 4.98353

Cumulative Model Updates: 13,168
Cumulative Timesteps: 219,719,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.41231
Policy Entropy: 1.28594
Value Function Loss: 0.21323

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05259
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.06378

Collected Steps per Second: 11,192.86597
Overall Steps per Second: 9,609.72476

Timestep Collection Time: 4.46749
Timestep Consumption Time: 0.73599
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.20348

Cumulative Model Updates: 13,171
Cumulative Timesteps: 219,769,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 219769622...
Checkpoint 219769622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.26523
Policy Entropy: 1.28328
Value Function Loss: 0.22314

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06476
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.05885

Collected Steps per Second: 10,994.13831
Overall Steps per Second: 9,527.32867

Timestep Collection Time: 4.54879
Timestep Consumption Time: 0.70032
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.24911

Cumulative Model Updates: 13,174
Cumulative Timesteps: 219,819,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.96317
Policy Entropy: 1.28208
Value Function Loss: 0.22190

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05369
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.05808

Collected Steps per Second: 11,363.70709
Overall Steps per Second: 9,659.62209

Timestep Collection Time: 4.40244
Timestep Consumption Time: 0.77665
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.17908

Cumulative Model Updates: 13,177
Cumulative Timesteps: 219,869,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 219869660...
Checkpoint 219869660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.51853
Policy Entropy: 1.27895
Value Function Loss: 0.22086

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05461
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.05741

Collected Steps per Second: 11,447.14827
Overall Steps per Second: 9,825.39835

Timestep Collection Time: 4.37017
Timestep Consumption Time: 0.72133
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.09150

Cumulative Model Updates: 13,180
Cumulative Timesteps: 219,919,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.49462
Policy Entropy: 1.28133
Value Function Loss: 0.23323

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05697
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.05869

Collected Steps per Second: 11,277.62175
Overall Steps per Second: 9,555.94597

Timestep Collection Time: 4.43533
Timestep Consumption Time: 0.79911
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.23444

Cumulative Model Updates: 13,183
Cumulative Timesteps: 219,969,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 219969706...
Checkpoint 219969706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.53835
Policy Entropy: 1.27919
Value Function Loss: 0.22038

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04819
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.06476

Collected Steps per Second: 11,308.06161
Overall Steps per Second: 9,458.39651

Timestep Collection Time: 4.42162
Timestep Consumption Time: 0.86468
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 5.28631

Cumulative Model Updates: 13,186
Cumulative Timesteps: 220,019,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.11826
Policy Entropy: 1.28460
Value Function Loss: 0.22213

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.06198

Collected Steps per Second: 11,342.61318
Overall Steps per Second: 9,773.47913

Timestep Collection Time: 4.40974
Timestep Consumption Time: 0.70798
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 5.11773

Cumulative Model Updates: 13,189
Cumulative Timesteps: 220,069,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 220069724...
Checkpoint 220069724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.64886
Policy Entropy: 1.28022
Value Function Loss: 0.22130

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07134
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.06542

Collected Steps per Second: 11,571.73467
Overall Steps per Second: 9,750.31919

Timestep Collection Time: 4.32208
Timestep Consumption Time: 0.80739
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 5.12947

Cumulative Model Updates: 13,192
Cumulative Timesteps: 220,119,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.06801
Policy Entropy: 1.28467
Value Function Loss: 0.23725

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03817
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.06782

Collected Steps per Second: 11,266.17742
Overall Steps per Second: 9,636.83484

Timestep Collection Time: 4.43931
Timestep Consumption Time: 0.75057
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.18988

Cumulative Model Updates: 13,195
Cumulative Timesteps: 220,169,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 220169752...
Checkpoint 220169752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.52764
Policy Entropy: 1.27877
Value Function Loss: 0.21996

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06409
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 11,915.95323
Overall Steps per Second: 10,059.93613

Timestep Collection Time: 4.19841
Timestep Consumption Time: 0.77459
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 4.97299

Cumulative Model Updates: 13,198
Cumulative Timesteps: 220,219,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.40267
Policy Entropy: 1.28331
Value Function Loss: 0.19275

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04648
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.07072

Collected Steps per Second: 12,373.47672
Overall Steps per Second: 10,279.07290

Timestep Collection Time: 4.04203
Timestep Consumption Time: 0.82358
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 4.86561

Cumulative Model Updates: 13,201
Cumulative Timesteps: 220,269,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 220269794...
Checkpoint 220269794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.58727
Policy Entropy: 1.27962
Value Function Loss: 0.19620

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07425
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.06498

Collected Steps per Second: 12,459.54292
Overall Steps per Second: 10,279.36587

Timestep Collection Time: 4.01379
Timestep Consumption Time: 0.85130
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 4.86509

Cumulative Model Updates: 13,204
Cumulative Timesteps: 220,319,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.19258
Policy Entropy: 1.28257
Value Function Loss: 0.24037

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.05866

Collected Steps per Second: 12,587.13756
Overall Steps per Second: 10,429.42279

Timestep Collection Time: 3.97263
Timestep Consumption Time: 0.82189
PPO Batch Consumption Time: 0.04094
Total Iteration Time: 4.79451

Cumulative Model Updates: 13,207
Cumulative Timesteps: 220,369,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 220369808...
Checkpoint 220369808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.08210
Policy Entropy: 1.27121
Value Function Loss: 0.27717

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 12,610.16561
Overall Steps per Second: 10,317.57698

Timestep Collection Time: 3.96632
Timestep Consumption Time: 0.88133
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 4.84765

Cumulative Model Updates: 13,210
Cumulative Timesteps: 220,419,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.11906
Policy Entropy: 1.27943
Value Function Loss: 0.27079

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.06631

Collected Steps per Second: 12,563.13431
Overall Steps per Second: 10,369.67205

Timestep Collection Time: 3.98181
Timestep Consumption Time: 0.84226
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 4.82407

Cumulative Model Updates: 13,213
Cumulative Timesteps: 220,469,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 220469848...
Checkpoint 220469848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.27020
Policy Entropy: 1.27553
Value Function Loss: 0.25762

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05547
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.07186

Collected Steps per Second: 12,559.92965
Overall Steps per Second: 10,369.27796

Timestep Collection Time: 3.98171
Timestep Consumption Time: 0.84119
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 4.82290

Cumulative Model Updates: 13,216
Cumulative Timesteps: 220,519,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.91762
Policy Entropy: 1.27410
Value Function Loss: 0.22579

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06441
Policy Update Magnitude: 0.06160
Value Function Update Magnitude: 0.06657

Collected Steps per Second: 12,179.90261
Overall Steps per Second: 10,169.83974

Timestep Collection Time: 4.10726
Timestep Consumption Time: 0.81180
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 4.91905

Cumulative Model Updates: 13,219
Cumulative Timesteps: 220,569,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 220569884...
Checkpoint 220569884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.40293
Policy Entropy: 1.28028
Value Function Loss: 0.22667

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.06697

Collected Steps per Second: 11,893.51996
Overall Steps per Second: 9,934.54760

Timestep Collection Time: 4.20481
Timestep Consumption Time: 0.82914
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 5.03395

Cumulative Model Updates: 13,222
Cumulative Timesteps: 220,619,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.22181
Policy Entropy: 1.27758
Value Function Loss: 0.21070

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.06230

Collected Steps per Second: 11,487.72755
Overall Steps per Second: 9,616.92579

Timestep Collection Time: 4.35439
Timestep Consumption Time: 0.84707
PPO Batch Consumption Time: 0.03993
Total Iteration Time: 5.20145

Cumulative Model Updates: 13,225
Cumulative Timesteps: 220,669,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 220669916...
Checkpoint 220669916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.28807
Policy Entropy: 1.28583
Value Function Loss: 0.22984

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07597
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.05752

Collected Steps per Second: 11,772.62195
Overall Steps per Second: 10,151.19466

Timestep Collection Time: 4.24765
Timestep Consumption Time: 0.67847
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.92612

Cumulative Model Updates: 13,228
Cumulative Timesteps: 220,719,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.55292
Policy Entropy: 1.28434
Value Function Loss: 0.24469

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06845
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.05681

Collected Steps per Second: 11,788.89615
Overall Steps per Second: 9,832.56501

Timestep Collection Time: 4.24162
Timestep Consumption Time: 0.84393
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.08555

Cumulative Model Updates: 13,231
Cumulative Timesteps: 220,769,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 220769926...
Checkpoint 220769926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.11853
Policy Entropy: 1.28525
Value Function Loss: 0.26510

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05716
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.05605

Collected Steps per Second: 11,738.63029
Overall Steps per Second: 10,053.53792

Timestep Collection Time: 4.26046
Timestep Consumption Time: 0.71410
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 4.97457

Cumulative Model Updates: 13,234
Cumulative Timesteps: 220,819,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.89190
Policy Entropy: 1.28267
Value Function Loss: 0.23916

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06614
Policy Update Magnitude: 0.06503
Value Function Update Magnitude: 0.07206

Collected Steps per Second: 11,906.02346
Overall Steps per Second: 10,080.32756

Timestep Collection Time: 4.20023
Timestep Consumption Time: 0.76072
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.96095

Cumulative Model Updates: 13,237
Cumulative Timesteps: 220,869,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 220869946...
Checkpoint 220869946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.24566
Policy Entropy: 1.28733
Value Function Loss: 0.22653

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03929
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.07014

Collected Steps per Second: 11,439.97553
Overall Steps per Second: 9,650.17694

Timestep Collection Time: 4.37186
Timestep Consumption Time: 0.81084
PPO Batch Consumption Time: 0.03941
Total Iteration Time: 5.18270

Cumulative Model Updates: 13,240
Cumulative Timesteps: 220,919,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.42164
Policy Entropy: 1.28443
Value Function Loss: 0.20819

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05929
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.06174

Collected Steps per Second: 11,670.14163
Overall Steps per Second: 9,893.69451

Timestep Collection Time: 4.28632
Timestep Consumption Time: 0.76962
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.05595

Cumulative Model Updates: 13,243
Cumulative Timesteps: 220,969,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 220969982...
Checkpoint 220969982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.61763
Policy Entropy: 1.28369
Value Function Loss: 0.21886

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.06973

Collected Steps per Second: 11,576.51647
Overall Steps per Second: 9,745.39137

Timestep Collection Time: 4.32133
Timestep Consumption Time: 0.81196
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.13330

Cumulative Model Updates: 13,246
Cumulative Timesteps: 221,020,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.31244
Policy Entropy: 1.28247
Value Function Loss: 0.21576

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 11,612.87140
Overall Steps per Second: 10,041.45585

Timestep Collection Time: 4.30591
Timestep Consumption Time: 0.67384
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 4.97976

Cumulative Model Updates: 13,249
Cumulative Timesteps: 221,070,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 221070012...
Checkpoint 221070012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.48487
Policy Entropy: 1.28481
Value Function Loss: 0.22760

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 11,516.02629
Overall Steps per Second: 9,668.56611

Timestep Collection Time: 4.34195
Timestep Consumption Time: 0.82966
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.17160

Cumulative Model Updates: 13,252
Cumulative Timesteps: 221,120,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.49838
Policy Entropy: 1.28195
Value Function Loss: 0.23074

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.08513

Collected Steps per Second: 11,343.96496
Overall Steps per Second: 9,691.76693

Timestep Collection Time: 4.40851
Timestep Consumption Time: 0.75154
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 5.16005

Cumulative Model Updates: 13,255
Cumulative Timesteps: 221,170,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 221170024...
Checkpoint 221170024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.30910
Policy Entropy: 1.28588
Value Function Loss: 0.24351

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.08079

Collected Steps per Second: 11,062.58155
Overall Steps per Second: 9,351.28153

Timestep Collection Time: 4.52137
Timestep Consumption Time: 0.82742
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 5.34879

Cumulative Model Updates: 13,258
Cumulative Timesteps: 221,220,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.38651
Policy Entropy: 1.28397
Value Function Loss: 0.24190

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.07340

Collected Steps per Second: 11,335.17523
Overall Steps per Second: 9,622.01420

Timestep Collection Time: 4.41264
Timestep Consumption Time: 0.78565
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.19829

Cumulative Model Updates: 13,261
Cumulative Timesteps: 221,270,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 221270060...
Checkpoint 221270060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.90282
Policy Entropy: 1.28201
Value Function Loss: 0.25102

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.06591

Collected Steps per Second: 11,496.47666
Overall Steps per Second: 9,858.14107

Timestep Collection Time: 4.35107
Timestep Consumption Time: 0.72311
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.07418

Cumulative Model Updates: 13,264
Cumulative Timesteps: 221,320,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.32349
Policy Entropy: 1.28213
Value Function Loss: 0.24952

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.06833

Collected Steps per Second: 11,299.27572
Overall Steps per Second: 9,558.25240

Timestep Collection Time: 4.42595
Timestep Consumption Time: 0.80618
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 5.23213

Cumulative Model Updates: 13,267
Cumulative Timesteps: 221,370,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 221370092...
Checkpoint 221370092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.42659
Policy Entropy: 1.28120
Value Function Loss: 0.25512

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 11,567.61783
Overall Steps per Second: 9,875.49597

Timestep Collection Time: 4.32362
Timestep Consumption Time: 0.74083
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.06445

Cumulative Model Updates: 13,270
Cumulative Timesteps: 221,420,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.91441
Policy Entropy: 1.27906
Value Function Loss: 0.25938

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 12,151.91669
Overall Steps per Second: 10,179.52106

Timestep Collection Time: 4.11606
Timestep Consumption Time: 0.79753
PPO Batch Consumption Time: 0.04330
Total Iteration Time: 4.91359

Cumulative Model Updates: 13,273
Cumulative Timesteps: 221,470,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 221470124...
Checkpoint 221470124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.02132
Policy Entropy: 1.28141
Value Function Loss: 0.24341

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06580
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.06273

Collected Steps per Second: 11,418.68041
Overall Steps per Second: 9,666.52480

Timestep Collection Time: 4.38054
Timestep Consumption Time: 0.79402
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.17456

Cumulative Model Updates: 13,276
Cumulative Timesteps: 221,520,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.32295
Policy Entropy: 1.28041
Value Function Loss: 0.24723

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04512
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.06280

Collected Steps per Second: 11,874.91387
Overall Steps per Second: 10,056.19544

Timestep Collection Time: 4.21241
Timestep Consumption Time: 0.76184
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 4.97425

Cumulative Model Updates: 13,279
Cumulative Timesteps: 221,570,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 221570166...
Checkpoint 221570166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.96745
Policy Entropy: 1.27831
Value Function Loss: 0.21856

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06401
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.06177

Collected Steps per Second: 11,820.50393
Overall Steps per Second: 9,816.22474

Timestep Collection Time: 4.23028
Timestep Consumption Time: 0.86374
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 5.09402

Cumulative Model Updates: 13,282
Cumulative Timesteps: 221,620,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.02546
Policy Entropy: 1.27927
Value Function Loss: 0.23700

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05255
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.07238

Collected Steps per Second: 12,187.84165
Overall Steps per Second: 10,204.63768

Timestep Collection Time: 4.10245
Timestep Consumption Time: 0.79728
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 4.89973

Cumulative Model Updates: 13,285
Cumulative Timesteps: 221,670,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 221670170...
Checkpoint 221670170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.17410
Policy Entropy: 1.27541
Value Function Loss: 0.23093

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.07606

Collected Steps per Second: 11,919.08119
Overall Steps per Second: 9,932.77902

Timestep Collection Time: 4.19730
Timestep Consumption Time: 0.83935
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.03666

Cumulative Model Updates: 13,288
Cumulative Timesteps: 221,720,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.64308
Policy Entropy: 1.27897
Value Function Loss: 0.23699

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04335
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.06905

Collected Steps per Second: 11,662.92496
Overall Steps per Second: 9,766.07997

Timestep Collection Time: 4.28846
Timestep Consumption Time: 0.83294
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.12140

Cumulative Model Updates: 13,291
Cumulative Timesteps: 221,770,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 221770214...
Checkpoint 221770214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.03051
Policy Entropy: 1.27900
Value Function Loss: 0.20906

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03017
Policy Update Magnitude: 0.06345
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 10,836.61080
Overall Steps per Second: 9,231.73149

Timestep Collection Time: 4.61454
Timestep Consumption Time: 0.80221
PPO Batch Consumption Time: 0.03870
Total Iteration Time: 5.41675

Cumulative Model Updates: 13,294
Cumulative Timesteps: 221,820,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.48264
Policy Entropy: 1.27828
Value Function Loss: 0.21729

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04548
Policy Update Magnitude: 0.06703
Value Function Update Magnitude: 0.06426

Collected Steps per Second: 11,990.31395
Overall Steps per Second: 10,080.35579

Timestep Collection Time: 4.17053
Timestep Consumption Time: 0.79020
PPO Batch Consumption Time: 0.03819
Total Iteration Time: 4.96074

Cumulative Model Updates: 13,297
Cumulative Timesteps: 221,870,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 221870226...
Checkpoint 221870226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.47328
Policy Entropy: 1.28003
Value Function Loss: 0.22870

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04257
Policy Update Magnitude: 0.07190
Value Function Update Magnitude: 0.06108

Collected Steps per Second: 11,876.64983
Overall Steps per Second: 9,986.52915

Timestep Collection Time: 4.21112
Timestep Consumption Time: 0.79703
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 5.00815

Cumulative Model Updates: 13,300
Cumulative Timesteps: 221,920,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.13759
Policy Entropy: 1.27604
Value Function Loss: 0.22795

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05687
Policy Update Magnitude: 0.07261
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 11,868.08775
Overall Steps per Second: 10,183.79792

Timestep Collection Time: 4.21365
Timestep Consumption Time: 0.69689
PPO Batch Consumption Time: 0.03789
Total Iteration Time: 4.91055

Cumulative Model Updates: 13,303
Cumulative Timesteps: 221,970,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 221970248...
Checkpoint 221970248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.14570
Policy Entropy: 1.27778
Value Function Loss: 0.22095

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06356
Policy Update Magnitude: 0.06346
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 11,664.64650
Overall Steps per Second: 9,837.89540

Timestep Collection Time: 4.28817
Timestep Consumption Time: 0.79625
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 5.08442

Cumulative Model Updates: 13,306
Cumulative Timesteps: 222,020,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.89578
Policy Entropy: 1.28056
Value Function Loss: 0.22088

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04685
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.05729

Collected Steps per Second: 11,496.50212
Overall Steps per Second: 9,773.45799

Timestep Collection Time: 4.35037
Timestep Consumption Time: 0.76696
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.11733

Cumulative Model Updates: 13,309
Cumulative Timesteps: 222,070,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 222070282...
Checkpoint 222070282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.64120
Policy Entropy: 1.27996
Value Function Loss: 0.23580

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04613
Policy Update Magnitude: 0.06927
Value Function Update Magnitude: 0.05272

Collected Steps per Second: 11,410.78611
Overall Steps per Second: 9,722.19167

Timestep Collection Time: 4.38410
Timestep Consumption Time: 0.76145
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.14555

Cumulative Model Updates: 13,312
Cumulative Timesteps: 222,120,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.06963
Policy Entropy: 1.27719
Value Function Loss: 0.23284

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06055
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.05645

Collected Steps per Second: 11,399.61955
Overall Steps per Second: 9,670.24155

Timestep Collection Time: 4.38734
Timestep Consumption Time: 0.78461
PPO Batch Consumption Time: 0.03966
Total Iteration Time: 5.17195

Cumulative Model Updates: 13,315
Cumulative Timesteps: 222,170,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 222170322...
Checkpoint 222170322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.44430
Policy Entropy: 1.27059
Value Function Loss: 0.22189

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05669
Policy Update Magnitude: 0.06577
Value Function Update Magnitude: 0.05374

Collected Steps per Second: 11,674.19585
Overall Steps per Second: 9,948.91230

Timestep Collection Time: 4.28346
Timestep Consumption Time: 0.74281
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.02628

Cumulative Model Updates: 13,318
Cumulative Timesteps: 222,220,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.87930
Policy Entropy: 1.28025
Value Function Loss: 0.22397

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06429
Policy Update Magnitude: 0.06694
Value Function Update Magnitude: 0.04980

Collected Steps per Second: 11,641.46468
Overall Steps per Second: 9,898.60884

Timestep Collection Time: 4.29516
Timestep Consumption Time: 0.75625
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.05142

Cumulative Model Updates: 13,321
Cumulative Timesteps: 222,270,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 222270330...
Checkpoint 222270330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.42250
Policy Entropy: 1.28001
Value Function Loss: 0.23504

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06358
Policy Update Magnitude: 0.07352
Value Function Update Magnitude: 0.05567

Collected Steps per Second: 11,291.37835
Overall Steps per Second: 9,615.69303

Timestep Collection Time: 4.42851
Timestep Consumption Time: 0.77174
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.20025

Cumulative Model Updates: 13,324
Cumulative Timesteps: 222,320,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.65916
Policy Entropy: 1.27977
Value Function Loss: 0.25691

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.06463

Collected Steps per Second: 11,581.37804
Overall Steps per Second: 9,693.87790

Timestep Collection Time: 4.31779
Timestep Consumption Time: 0.84072
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 5.15851

Cumulative Model Updates: 13,327
Cumulative Timesteps: 222,370,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 222370340...
Checkpoint 222370340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.55274
Policy Entropy: 1.27626
Value Function Loss: 0.27882

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06587
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.06545

Collected Steps per Second: 11,091.31557
Overall Steps per Second: 9,337.60911

Timestep Collection Time: 4.51056
Timestep Consumption Time: 0.84713
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.35769

Cumulative Model Updates: 13,330
Cumulative Timesteps: 222,420,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.50804
Policy Entropy: 1.27801
Value Function Loss: 0.26900

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03183
Policy Update Magnitude: 0.06953
Value Function Update Magnitude: 0.05897

Collected Steps per Second: 11,720.99073
Overall Steps per Second: 10,103.61570

Timestep Collection Time: 4.26636
Timestep Consumption Time: 0.68295
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.94932

Cumulative Model Updates: 13,333
Cumulative Timesteps: 222,470,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 222470374...
Checkpoint 222470374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.26147
Policy Entropy: 1.27805
Value Function Loss: 0.25814

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04217
Policy Update Magnitude: 0.08031
Value Function Update Magnitude: 0.07357

Collected Steps per Second: 11,326.91042
Overall Steps per Second: 9,479.32469

Timestep Collection Time: 4.41603
Timestep Consumption Time: 0.86072
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 5.27675

Cumulative Model Updates: 13,336
Cumulative Timesteps: 222,520,394

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.34403
Policy Entropy: 1.28099
Value Function Loss: 0.21884

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03657
Policy Update Magnitude: 0.08294
Value Function Update Magnitude: 0.06734

Collected Steps per Second: 11,624.55126
Overall Steps per Second: 9,838.13796

Timestep Collection Time: 4.30193
Timestep Consumption Time: 0.78115
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.08308

Cumulative Model Updates: 13,339
Cumulative Timesteps: 222,570,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 222570402...
Checkpoint 222570402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.39856
Policy Entropy: 1.28434
Value Function Loss: 0.19654

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04288
Policy Update Magnitude: 0.07928
Value Function Update Magnitude: 0.07275

Collected Steps per Second: 12,257.13502
Overall Steps per Second: 10,424.55721

Timestep Collection Time: 4.08138
Timestep Consumption Time: 0.71748
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.79886

Cumulative Model Updates: 13,342
Cumulative Timesteps: 222,620,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.35115
Policy Entropy: 1.28448
Value Function Loss: 0.19689

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.04839
Policy Update Magnitude: 0.07914
Value Function Update Magnitude: 0.07454

Collected Steps per Second: 12,478.48946
Overall Steps per Second: 10,365.09895

Timestep Collection Time: 4.00914
Timestep Consumption Time: 0.81744
PPO Batch Consumption Time: 0.03991
Total Iteration Time: 4.82658

Cumulative Model Updates: 13,345
Cumulative Timesteps: 222,670,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 222670456...
Checkpoint 222670456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.51262
Policy Entropy: 1.28523
Value Function Loss: 0.19592

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03419
Policy Update Magnitude: 0.07847
Value Function Update Magnitude: 0.06331

Collected Steps per Second: 11,919.83468
Overall Steps per Second: 10,211.16958

Timestep Collection Time: 4.19670
Timestep Consumption Time: 0.70225
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 4.89895

Cumulative Model Updates: 13,348
Cumulative Timesteps: 222,720,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.17088
Policy Entropy: 1.28515
Value Function Loss: 0.20391

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04110
Policy Update Magnitude: 0.07335
Value Function Update Magnitude: 0.05804

Collected Steps per Second: 11,998.69977
Overall Steps per Second: 10,045.47493

Timestep Collection Time: 4.16912
Timestep Consumption Time: 0.81064
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 4.97975

Cumulative Model Updates: 13,351
Cumulative Timesteps: 222,770,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 222770504...
Checkpoint 222770504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.96552
Policy Entropy: 1.28633
Value Function Loss: 0.20453

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04527
Policy Update Magnitude: 0.07330
Value Function Update Magnitude: 0.05719

Collected Steps per Second: 12,136.30337
Overall Steps per Second: 10,293.47771

Timestep Collection Time: 4.12135
Timestep Consumption Time: 0.73784
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.85919

Cumulative Model Updates: 13,354
Cumulative Timesteps: 222,820,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.99835
Policy Entropy: 1.28763
Value Function Loss: 0.23361

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05251
Policy Update Magnitude: 0.07089
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 12,351.09568
Overall Steps per Second: 10,417.78454

Timestep Collection Time: 4.04855
Timestep Consumption Time: 0.75132
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 4.79987

Cumulative Model Updates: 13,357
Cumulative Timesteps: 222,870,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 222870526...
Checkpoint 222870526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.03324
Policy Entropy: 1.28643
Value Function Loss: 0.23330

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06359
Policy Update Magnitude: 0.06828
Value Function Update Magnitude: 0.09682

Collected Steps per Second: 11,932.05813
Overall Steps per Second: 9,974.66841

Timestep Collection Time: 4.19123
Timestep Consumption Time: 0.82247
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 5.01370

Cumulative Model Updates: 13,360
Cumulative Timesteps: 222,920,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.02573
Policy Entropy: 1.28294
Value Function Loss: 0.22016

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04914
Policy Update Magnitude: 0.06765
Value Function Update Magnitude: 0.09256

Collected Steps per Second: 11,753.85330
Overall Steps per Second: 10,033.17623

Timestep Collection Time: 4.25597
Timestep Consumption Time: 0.72989
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 4.98586

Cumulative Model Updates: 13,363
Cumulative Timesteps: 222,970,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 222970560...
Checkpoint 222970560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.26498
Policy Entropy: 1.28049
Value Function Loss: 0.20563

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06389
Policy Update Magnitude: 0.06988
Value Function Update Magnitude: 0.07987

Collected Steps per Second: 11,233.32343
Overall Steps per Second: 9,455.70512

Timestep Collection Time: 4.45318
Timestep Consumption Time: 0.83717
PPO Batch Consumption Time: 0.03717
Total Iteration Time: 5.29035

Cumulative Model Updates: 13,366
Cumulative Timesteps: 223,020,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.63035
Policy Entropy: 1.28194
Value Function Loss: 0.21482

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04578
Policy Update Magnitude: 0.06686
Value Function Update Magnitude: 0.06792

Collected Steps per Second: 11,811.43701
Overall Steps per Second: 10,023.81136

Timestep Collection Time: 4.23522
Timestep Consumption Time: 0.75530
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 4.99052

Cumulative Model Updates: 13,369
Cumulative Timesteps: 223,070,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 223070608...
Checkpoint 223070608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.87615
Policy Entropy: 1.29282
Value Function Loss: 0.22964

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 11,979.59389
Overall Steps per Second: 10,084.31067

Timestep Collection Time: 4.17610
Timestep Consumption Time: 0.78487
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 4.96097

Cumulative Model Updates: 13,372
Cumulative Timesteps: 223,120,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.92451
Policy Entropy: 1.28895
Value Function Loss: 0.22172

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.06893

Collected Steps per Second: 11,894.20650
Overall Steps per Second: 10,104.10816

Timestep Collection Time: 4.20390
Timestep Consumption Time: 0.74478
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 4.94868

Cumulative Model Updates: 13,375
Cumulative Timesteps: 223,170,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 223170638...
Checkpoint 223170638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.25089
Policy Entropy: 1.28868
Value Function Loss: 0.21908

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05130
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.07663

Collected Steps per Second: 11,578.36830
Overall Steps per Second: 9,908.71704

Timestep Collection Time: 4.31943
Timestep Consumption Time: 0.72784
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.04727

Cumulative Model Updates: 13,378
Cumulative Timesteps: 223,220,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.36286
Policy Entropy: 1.28474
Value Function Loss: 0.21881

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05216
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.06516

Collected Steps per Second: 11,614.07705
Overall Steps per Second: 9,904.34940

Timestep Collection Time: 4.30529
Timestep Consumption Time: 0.74320
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.04849

Cumulative Model Updates: 13,381
Cumulative Timesteps: 223,270,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 223270652...
Checkpoint 223270652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.60660
Policy Entropy: 1.28372
Value Function Loss: 0.21489

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.06773

Collected Steps per Second: 11,070.77615
Overall Steps per Second: 9,449.70049

Timestep Collection Time: 4.51874
Timestep Consumption Time: 0.77518
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.29392

Cumulative Model Updates: 13,384
Cumulative Timesteps: 223,320,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.64455
Policy Entropy: 1.28610
Value Function Loss: 0.22221

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03587
Policy Update Magnitude: 0.06599
Value Function Update Magnitude: 0.08450

Collected Steps per Second: 11,742.43364
Overall Steps per Second: 9,856.47583

Timestep Collection Time: 4.26028
Timestep Consumption Time: 0.81517
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.07544

Cumulative Model Updates: 13,387
Cumulative Timesteps: 223,370,704

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 223370704...
Checkpoint 223370704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.07364
Policy Entropy: 1.28389
Value Function Loss: 0.21705

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.06478
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 11,666.77566
Overall Steps per Second: 9,986.57054

Timestep Collection Time: 4.28602
Timestep Consumption Time: 0.72111
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 5.00712

Cumulative Model Updates: 13,390
Cumulative Timesteps: 223,420,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.70475
Policy Entropy: 1.28654
Value Function Loss: 0.23744

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06097
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 11,543.42737
Overall Steps per Second: 9,953.95297

Timestep Collection Time: 4.33268
Timestep Consumption Time: 0.69185
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.02454

Cumulative Model Updates: 13,393
Cumulative Timesteps: 223,470,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 223470722...
Checkpoint 223470722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.03235
Policy Entropy: 1.27787
Value Function Loss: 0.23197

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.05460

Collected Steps per Second: 11,267.19296
Overall Steps per Second: 9,613.82398

Timestep Collection Time: 4.43962
Timestep Consumption Time: 0.76352
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.20313

Cumulative Model Updates: 13,396
Cumulative Timesteps: 223,520,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.60799
Policy Entropy: 1.28484
Value Function Loss: 0.23988

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.04872

Collected Steps per Second: 11,405.76511
Overall Steps per Second: 9,520.47397

Timestep Collection Time: 4.38620
Timestep Consumption Time: 0.86858
PPO Batch Consumption Time: 0.03924
Total Iteration Time: 5.25478

Cumulative Model Updates: 13,399
Cumulative Timesteps: 223,570,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 223570772...
Checkpoint 223570772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.82714
Policy Entropy: 1.28370
Value Function Loss: 0.22570

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06822
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.05248

Collected Steps per Second: 11,688.49142
Overall Steps per Second: 9,815.09136

Timestep Collection Time: 4.27977
Timestep Consumption Time: 0.81688
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.09664

Cumulative Model Updates: 13,402
Cumulative Timesteps: 223,620,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.37247
Policy Entropy: 1.28768
Value Function Loss: 0.24177

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06143
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.06989

Collected Steps per Second: 11,596.56141
Overall Steps per Second: 9,839.23674

Timestep Collection Time: 4.31369
Timestep Consumption Time: 0.77044
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.08413

Cumulative Model Updates: 13,405
Cumulative Timesteps: 223,670,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 223670820...
Checkpoint 223670820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.85541
Policy Entropy: 1.28403
Value Function Loss: 0.24286

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05616
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.07886

Collected Steps per Second: 11,330.10462
Overall Steps per Second: 9,750.76660

Timestep Collection Time: 4.41373
Timestep Consumption Time: 0.71489
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.12862

Cumulative Model Updates: 13,408
Cumulative Timesteps: 223,720,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.07979
Policy Entropy: 1.28930
Value Function Loss: 0.23287

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04109
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.07151

Collected Steps per Second: 11,430.50968
Overall Steps per Second: 9,705.76226

Timestep Collection Time: 4.37566
Timestep Consumption Time: 0.77757
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 5.15323

Cumulative Model Updates: 13,411
Cumulative Timesteps: 223,770,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 223770844...
Checkpoint 223770844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.30828
Policy Entropy: 1.29058
Value Function Loss: 0.22446

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05880
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.06843

Collected Steps per Second: 12,047.39290
Overall Steps per Second: 10,216.72211

Timestep Collection Time: 4.15127
Timestep Consumption Time: 0.74384
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.89511

Cumulative Model Updates: 13,414
Cumulative Timesteps: 223,820,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.61314
Policy Entropy: 1.28266
Value Function Loss: 0.23010

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07175
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.07335

Collected Steps per Second: 12,189.22129
Overall Steps per Second: 10,110.58010

Timestep Collection Time: 4.10248
Timestep Consumption Time: 0.84343
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.94591

Cumulative Model Updates: 13,417
Cumulative Timesteps: 223,870,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 223870862...
Checkpoint 223870862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.52512
Policy Entropy: 1.28654
Value Function Loss: 0.23031

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.07739

Collected Steps per Second: 11,942.79681
Overall Steps per Second: 10,174.31487

Timestep Collection Time: 4.18863
Timestep Consumption Time: 0.72806
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 4.91669

Cumulative Model Updates: 13,420
Cumulative Timesteps: 223,920,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.90214
Policy Entropy: 1.27904
Value Function Loss: 0.23594

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.07826

Collected Steps per Second: 11,940.43589
Overall Steps per Second: 10,291.93569

Timestep Collection Time: 4.18929
Timestep Consumption Time: 0.67102
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 4.86031

Cumulative Model Updates: 13,423
Cumulative Timesteps: 223,970,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 223970908...
Checkpoint 223970908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.85400
Policy Entropy: 1.28527
Value Function Loss: 0.23212

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06021
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.06961

Collected Steps per Second: 11,745.64829
Overall Steps per Second: 9,846.50600

Timestep Collection Time: 4.25707
Timestep Consumption Time: 0.82108
PPO Batch Consumption Time: 0.03869
Total Iteration Time: 5.07815

Cumulative Model Updates: 13,426
Cumulative Timesteps: 224,020,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.63601
Policy Entropy: 1.28409
Value Function Loss: 0.23425

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06181
Policy Update Magnitude: 0.06576
Value Function Update Magnitude: 0.06448

Collected Steps per Second: 12,069.56377
Overall Steps per Second: 10,060.06220

Timestep Collection Time: 4.14282
Timestep Consumption Time: 0.82753
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 4.97035

Cumulative Model Updates: 13,429
Cumulative Timesteps: 224,070,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 224070912...
Checkpoint 224070912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.50504
Policy Entropy: 1.29055
Value Function Loss: 0.23942

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05030
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.06546

Collected Steps per Second: 12,132.30087
Overall Steps per Second: 10,169.57471

Timestep Collection Time: 4.12288
Timestep Consumption Time: 0.79571
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.91859

Cumulative Model Updates: 13,432
Cumulative Timesteps: 224,120,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.69177
Policy Entropy: 1.29011
Value Function Loss: 0.22949

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05007
Policy Update Magnitude: 0.06637
Value Function Update Magnitude: 0.07860

Collected Steps per Second: 11,747.39438
Overall Steps per Second: 9,568.11980

Timestep Collection Time: 4.25763
Timestep Consumption Time: 0.96973
PPO Batch Consumption Time: 0.04746
Total Iteration Time: 5.22736

Cumulative Model Updates: 13,435
Cumulative Timesteps: 224,170,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 224170948...
Checkpoint 224170948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.46958
Policy Entropy: 1.28817
Value Function Loss: 0.22743

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05381
Policy Update Magnitude: 0.06783
Value Function Update Magnitude: 0.07267

Collected Steps per Second: 11,629.94094
Overall Steps per Second: 10,020.53169

Timestep Collection Time: 4.30080
Timestep Consumption Time: 0.69076
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 4.99155

Cumulative Model Updates: 13,438
Cumulative Timesteps: 224,220,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.42260
Policy Entropy: 1.28729
Value Function Loss: 0.19683

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05558
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.07028

Collected Steps per Second: 11,847.23801
Overall Steps per Second: 9,884.94352

Timestep Collection Time: 4.22073
Timestep Consumption Time: 0.83787
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 5.05860

Cumulative Model Updates: 13,441
Cumulative Timesteps: 224,270,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 224270970...
Checkpoint 224270970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.72855
Policy Entropy: 1.28384
Value Function Loss: 0.19639

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.06403
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.06809

Collected Steps per Second: 11,888.35574
Overall Steps per Second: 10,064.76886

Timestep Collection Time: 4.20748
Timestep Consumption Time: 0.76233
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.96981

Cumulative Model Updates: 13,444
Cumulative Timesteps: 224,320,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.93168
Policy Entropy: 1.28179
Value Function Loss: 0.18926

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.06263
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.06445

Collected Steps per Second: 12,117.69293
Overall Steps per Second: 10,159.16430

Timestep Collection Time: 4.12801
Timestep Consumption Time: 0.79582
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 4.92383

Cumulative Model Updates: 13,447
Cumulative Timesteps: 224,371,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 224371012...
Checkpoint 224371012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.90472
Policy Entropy: 1.27983
Value Function Loss: 0.20698

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04352
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.07036

Collected Steps per Second: 11,613.33877
Overall Steps per Second: 9,926.34233

Timestep Collection Time: 4.30781
Timestep Consumption Time: 0.73212
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.03992

Cumulative Model Updates: 13,450
Cumulative Timesteps: 224,421,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.80303
Policy Entropy: 1.28236
Value Function Loss: 0.21502

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06802
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.06924

Collected Steps per Second: 11,387.42830
Overall Steps per Second: 9,801.00480

Timestep Collection Time: 4.39239
Timestep Consumption Time: 0.71097
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.10335

Cumulative Model Updates: 13,453
Cumulative Timesteps: 224,471,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 224471058...
Checkpoint 224471058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.96357
Policy Entropy: 1.28245
Value Function Loss: 0.22133

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 11,485.47876
Overall Steps per Second: 9,565.86160

Timestep Collection Time: 4.35332
Timestep Consumption Time: 0.87360
PPO Batch Consumption Time: 0.04606
Total Iteration Time: 5.22692

Cumulative Model Updates: 13,456
Cumulative Timesteps: 224,521,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.11657
Policy Entropy: 1.27872
Value Function Loss: 0.22445

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05792
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.09007

Collected Steps per Second: 11,293.44137
Overall Steps per Second: 9,662.41218

Timestep Collection Time: 4.42841
Timestep Consumption Time: 0.74752
PPO Batch Consumption Time: 0.03839
Total Iteration Time: 5.17593

Cumulative Model Updates: 13,459
Cumulative Timesteps: 224,571,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 224571070...
Checkpoint 224571070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.12804
Policy Entropy: 1.27073
Value Function Loss: 0.21849

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.09589

Collected Steps per Second: 12,066.03462
Overall Steps per Second: 9,973.71709

Timestep Collection Time: 4.14519
Timestep Consumption Time: 0.86959
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 5.01478

Cumulative Model Updates: 13,462
Cumulative Timesteps: 224,621,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.59541
Policy Entropy: 1.28139
Value Function Loss: 0.22782

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.08797

Collected Steps per Second: 11,370.88835
Overall Steps per Second: 9,673.56084

Timestep Collection Time: 4.39895
Timestep Consumption Time: 0.77184
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.17079

Cumulative Model Updates: 13,465
Cumulative Timesteps: 224,671,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 224671106...
Checkpoint 224671106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.14824
Policy Entropy: 1.27709
Value Function Loss: 0.19772

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 11,439.35767
Overall Steps per Second: 9,898.73831

Timestep Collection Time: 4.37245
Timestep Consumption Time: 0.68052
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.05297

Cumulative Model Updates: 13,468
Cumulative Timesteps: 224,721,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.25354
Policy Entropy: 1.27740
Value Function Loss: 0.19942

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.06821

Collected Steps per Second: 10,776.50776
Overall Steps per Second: 9,171.76972

Timestep Collection Time: 4.64121
Timestep Consumption Time: 0.81205
PPO Batch Consumption Time: 0.03771
Total Iteration Time: 5.45326

Cumulative Model Updates: 13,471
Cumulative Timesteps: 224,771,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 224771140...
Checkpoint 224771140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.93180
Policy Entropy: 1.27666
Value Function Loss: 0.18939

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.07969

Collected Steps per Second: 11,548.87257
Overall Steps per Second: 9,814.68030

Timestep Collection Time: 4.33047
Timestep Consumption Time: 0.76517
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.09563

Cumulative Model Updates: 13,474
Cumulative Timesteps: 224,821,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.98528
Policy Entropy: 1.27986
Value Function Loss: 0.21583

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06691
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.07565

Collected Steps per Second: 11,131.67745
Overall Steps per Second: 9,459.61912

Timestep Collection Time: 4.49402
Timestep Consumption Time: 0.79435
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.28837

Cumulative Model Updates: 13,477
Cumulative Timesteps: 224,871,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 224871178...
Checkpoint 224871178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.70872
Policy Entropy: 1.27714
Value Function Loss: 0.26248

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.06490

Collected Steps per Second: 11,697.18228
Overall Steps per Second: 9,895.85705

Timestep Collection Time: 4.27556
Timestep Consumption Time: 0.77827
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.05383

Cumulative Model Updates: 13,480
Cumulative Timesteps: 224,921,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.79100
Policy Entropy: 1.28081
Value Function Loss: 0.28306

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06213
Policy Update Magnitude: 0.06065
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 12,508.02293
Overall Steps per Second: 10,611.80353

Timestep Collection Time: 3.99807
Timestep Consumption Time: 0.71441
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.71249

Cumulative Model Updates: 13,483
Cumulative Timesteps: 224,971,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 224971198...
Checkpoint 224971198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.44209
Policy Entropy: 1.27897
Value Function Loss: 0.27564

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06213
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.07565

Collected Steps per Second: 12,487.55669
Overall Steps per Second: 10,402.25209

Timestep Collection Time: 4.00607
Timestep Consumption Time: 0.80308
PPO Batch Consumption Time: 0.04662
Total Iteration Time: 4.80915

Cumulative Model Updates: 13,486
Cumulative Timesteps: 225,021,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.59628
Policy Entropy: 1.28082
Value Function Loss: 0.24630

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.07292

Collected Steps per Second: 11,755.87081
Overall Steps per Second: 9,949.50701

Timestep Collection Time: 4.25524
Timestep Consumption Time: 0.77255
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.02779

Cumulative Model Updates: 13,489
Cumulative Timesteps: 225,071,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 225071248...
Checkpoint 225071248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.29564
Policy Entropy: 1.27620
Value Function Loss: 0.22270

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.06023
Value Function Update Magnitude: 0.08098

Collected Steps per Second: 12,813.31958
Overall Steps per Second: 10,560.26647

Timestep Collection Time: 3.90235
Timestep Consumption Time: 0.83257
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 4.73492

Cumulative Model Updates: 13,492
Cumulative Timesteps: 225,121,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.76778
Policy Entropy: 1.27179
Value Function Loss: 0.22048

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.06947
Value Function Update Magnitude: 0.08405

Collected Steps per Second: 12,399.06357
Overall Steps per Second: 10,309.04412

Timestep Collection Time: 4.03272
Timestep Consumption Time: 0.81758
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.85030

Cumulative Model Updates: 13,495
Cumulative Timesteps: 225,171,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 225171252...
Checkpoint 225171252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.35686
Policy Entropy: 1.27715
Value Function Loss: 0.21002

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.08709

Collected Steps per Second: 12,427.16251
Overall Steps per Second: 10,375.06785

Timestep Collection Time: 4.02554
Timestep Consumption Time: 0.79621
PPO Batch Consumption Time: 0.03713
Total Iteration Time: 4.82175

Cumulative Model Updates: 13,498
Cumulative Timesteps: 225,221,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.12245
Policy Entropy: 1.27815
Value Function Loss: 0.20093

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 11,974.53631
Overall Steps per Second: 10,136.48943

Timestep Collection Time: 4.17770
Timestep Consumption Time: 0.75754
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 4.93524

Cumulative Model Updates: 13,501
Cumulative Timesteps: 225,271,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 225271304...
Checkpoint 225271304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.51312
Policy Entropy: 1.27577
Value Function Loss: 0.20725

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.08348

Collected Steps per Second: 11,909.42239
Overall Steps per Second: 10,145.82761

Timestep Collection Time: 4.19970
Timestep Consumption Time: 0.73001
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 4.92971

Cumulative Model Updates: 13,504
Cumulative Timesteps: 225,321,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.93824
Policy Entropy: 1.28179
Value Function Loss: 0.21101

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.06885

Collected Steps per Second: 10,922.38578
Overall Steps per Second: 9,288.40478

Timestep Collection Time: 4.57885
Timestep Consumption Time: 0.80549
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.38435

Cumulative Model Updates: 13,507
Cumulative Timesteps: 225,371,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 225371332...
Checkpoint 225371332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.37161
Policy Entropy: 1.28141
Value Function Loss: 0.22305

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.05635

Collected Steps per Second: 11,819.21175
Overall Steps per Second: 10,022.02703

Timestep Collection Time: 4.23294
Timestep Consumption Time: 0.75907
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 4.99200

Cumulative Model Updates: 13,510
Cumulative Timesteps: 225,421,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.22347
Policy Entropy: 1.27513
Value Function Loss: 0.22149

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.05123

Collected Steps per Second: 11,935.74768
Overall Steps per Second: 10,193.08834

Timestep Collection Time: 4.19094
Timestep Consumption Time: 0.71650
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 4.90744

Cumulative Model Updates: 13,513
Cumulative Timesteps: 225,471,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 225471384...
Checkpoint 225471384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.92041
Policy Entropy: 1.28482
Value Function Loss: 0.20631

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05953
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.04918

Collected Steps per Second: 11,822.66848
Overall Steps per Second: 9,980.00229

Timestep Collection Time: 4.23102
Timestep Consumption Time: 0.78120
PPO Batch Consumption Time: 0.03374
Total Iteration Time: 5.01222

Cumulative Model Updates: 13,516
Cumulative Timesteps: 225,521,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.67115
Policy Entropy: 1.28113
Value Function Loss: 0.19466

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07011
Policy Update Magnitude: 0.07371
Value Function Update Magnitude: 0.05862

Collected Steps per Second: 11,704.29078
Overall Steps per Second: 9,827.46095

Timestep Collection Time: 4.27279
Timestep Consumption Time: 0.81601
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.08880

Cumulative Model Updates: 13,519
Cumulative Timesteps: 225,571,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 225571416...
Checkpoint 225571416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.75322
Policy Entropy: 1.28520
Value Function Loss: 0.17663

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.06745
Value Function Update Magnitude: 0.08325

Collected Steps per Second: 11,802.08395
Overall Steps per Second: 10,010.83690

Timestep Collection Time: 4.23671
Timestep Consumption Time: 0.75808
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.99479

Cumulative Model Updates: 13,522
Cumulative Timesteps: 225,621,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.99582
Policy Entropy: 1.28570
Value Function Loss: 0.17615

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05713
Policy Update Magnitude: 0.06742
Value Function Update Magnitude: 0.09160

Collected Steps per Second: 11,384.05204
Overall Steps per Second: 9,737.56336

Timestep Collection Time: 4.39351
Timestep Consumption Time: 0.74288
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.13640

Cumulative Model Updates: 13,525
Cumulative Timesteps: 225,671,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 225671434...
Checkpoint 225671434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.97049
Policy Entropy: 1.28455
Value Function Loss: 0.20139

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04527
Policy Update Magnitude: 0.07034
Value Function Update Magnitude: 0.09667

Collected Steps per Second: 11,119.58183
Overall Steps per Second: 9,689.00529

Timestep Collection Time: 4.49693
Timestep Consumption Time: 0.66397
PPO Batch Consumption Time: 0.03883
Total Iteration Time: 5.16090

Cumulative Model Updates: 13,528
Cumulative Timesteps: 225,721,438

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.47452
Policy Entropy: 1.28541
Value Function Loss: 0.20039

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03458
Policy Update Magnitude: 0.07140
Value Function Update Magnitude: 0.08535

Collected Steps per Second: 11,698.40689
Overall Steps per Second: 9,922.24112

Timestep Collection Time: 4.27477
Timestep Consumption Time: 0.76522
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.03999

Cumulative Model Updates: 13,531
Cumulative Timesteps: 225,771,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 225771446...
Checkpoint 225771446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.79212
Policy Entropy: 1.28652
Value Function Loss: 0.19802

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04418
Policy Update Magnitude: 0.07201
Value Function Update Magnitude: 0.08264

Collected Steps per Second: 11,774.66103
Overall Steps per Second: 9,984.27141

Timestep Collection Time: 4.24658
Timestep Consumption Time: 0.76150
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.00808

Cumulative Model Updates: 13,534
Cumulative Timesteps: 225,821,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.70038
Policy Entropy: 1.28966
Value Function Loss: 0.19401

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.04841
Policy Update Magnitude: 0.07107
Value Function Update Magnitude: 0.08786

Collected Steps per Second: 11,706.48145
Overall Steps per Second: 9,941.73201

Timestep Collection Time: 4.27268
Timestep Consumption Time: 0.75844
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.03112

Cumulative Model Updates: 13,537
Cumulative Timesteps: 225,871,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 225871466...
Checkpoint 225871466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.74051
Policy Entropy: 1.28278
Value Function Loss: 0.21414

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05147
Policy Update Magnitude: 0.07068
Value Function Update Magnitude: 0.10399

Collected Steps per Second: 11,544.39429
Overall Steps per Second: 9,838.08867

Timestep Collection Time: 4.33111
Timestep Consumption Time: 0.75118
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.08229

Cumulative Model Updates: 13,540
Cumulative Timesteps: 225,921,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.40523
Policy Entropy: 1.28676
Value Function Loss: 0.22246

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.04666
Policy Update Magnitude: 0.07198
Value Function Update Magnitude: 0.11302

Collected Steps per Second: 10,805.70655
Overall Steps per Second: 9,363.49209

Timestep Collection Time: 4.62718
Timestep Consumption Time: 0.71270
PPO Batch Consumption Time: 0.03919
Total Iteration Time: 5.33989

Cumulative Model Updates: 13,543
Cumulative Timesteps: 225,971,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 225971466...
Checkpoint 225971466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.60132
Policy Entropy: 1.28659
Value Function Loss: 0.21866

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04716
Policy Update Magnitude: 0.06930
Value Function Update Magnitude: 0.09178

Collected Steps per Second: 11,476.15023
Overall Steps per Second: 9,708.75841

Timestep Collection Time: 4.35791
Timestep Consumption Time: 0.79332
PPO Batch Consumption Time: 0.03917
Total Iteration Time: 5.15123

Cumulative Model Updates: 13,546
Cumulative Timesteps: 226,021,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.01126
Policy Entropy: 1.28624
Value Function Loss: 0.20445

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.08868

Collected Steps per Second: 11,100.06861
Overall Steps per Second: 9,400.99604

Timestep Collection Time: 4.50502
Timestep Consumption Time: 0.81421
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.31922

Cumulative Model Updates: 13,549
Cumulative Timesteps: 226,071,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 226071484...
Checkpoint 226071484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.73554
Policy Entropy: 1.29129
Value Function Loss: 0.22114

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06324
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.09216

Collected Steps per Second: 11,779.15183
Overall Steps per Second: 9,971.28134

Timestep Collection Time: 4.24683
Timestep Consumption Time: 0.76998
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.01681

Cumulative Model Updates: 13,552
Cumulative Timesteps: 226,121,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.34793
Policy Entropy: 1.28793
Value Function Loss: 0.22980

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.09564

Collected Steps per Second: 12,125.94867
Overall Steps per Second: 10,259.18842

Timestep Collection Time: 4.12421
Timestep Consumption Time: 0.75044
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.87465

Cumulative Model Updates: 13,555
Cumulative Timesteps: 226,171,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 226171518...
Checkpoint 226171518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.99430
Policy Entropy: 1.29156
Value Function Loss: 0.22460

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05314
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.09795

Collected Steps per Second: 11,902.61816
Overall Steps per Second: 10,248.49160

Timestep Collection Time: 4.20160
Timestep Consumption Time: 0.67815
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 4.87974

Cumulative Model Updates: 13,558
Cumulative Timesteps: 226,221,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.39868
Policy Entropy: 1.28687
Value Function Loss: 0.19771

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.10873

Collected Steps per Second: 11,231.92852
Overall Steps per Second: 9,589.25893

Timestep Collection Time: 4.45249
Timestep Consumption Time: 0.76272
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.21521

Cumulative Model Updates: 13,561
Cumulative Timesteps: 226,271,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 226271538...
Checkpoint 226271538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.84032
Policy Entropy: 1.28746
Value Function Loss: 0.19117

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05024
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.10771

Collected Steps per Second: 11,970.17732
Overall Steps per Second: 10,226.97848

Timestep Collection Time: 4.17855
Timestep Consumption Time: 0.71224
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 4.89079

Cumulative Model Updates: 13,564
Cumulative Timesteps: 226,321,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.12050
Policy Entropy: 1.28531
Value Function Loss: 0.19721

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04150
Policy Update Magnitude: 0.06332
Value Function Update Magnitude: 0.09355

Collected Steps per Second: 12,221.27755
Overall Steps per Second: 10,229.05048

Timestep Collection Time: 4.09253
Timestep Consumption Time: 0.79707
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.88960

Cumulative Model Updates: 13,567
Cumulative Timesteps: 226,371,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 226371572...
Checkpoint 226371572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.65687
Policy Entropy: 1.28715
Value Function Loss: 0.20179

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04263
Policy Update Magnitude: 0.06535
Value Function Update Magnitude: 0.08102

Collected Steps per Second: 11,827.15440
Overall Steps per Second: 10,036.34840

Timestep Collection Time: 4.22841
Timestep Consumption Time: 0.75448
PPO Batch Consumption Time: 0.03856
Total Iteration Time: 4.98289

Cumulative Model Updates: 13,570
Cumulative Timesteps: 226,421,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.59039
Policy Entropy: 1.28676
Value Function Loss: 0.20864

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05538
Policy Update Magnitude: 0.06260
Value Function Update Magnitude: 0.06360

Collected Steps per Second: 11,939.18365
Overall Steps per Second: 10,135.25447

Timestep Collection Time: 4.18873
Timestep Consumption Time: 0.74553
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.93426

Cumulative Model Updates: 13,573
Cumulative Timesteps: 226,471,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 226471592...
Checkpoint 226471592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.82500
Policy Entropy: 1.28645
Value Function Loss: 0.20657

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05251
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.05463

Collected Steps per Second: 11,944.04508
Overall Steps per Second: 10,056.72575

Timestep Collection Time: 4.18803
Timestep Consumption Time: 0.78596
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.97398

Cumulative Model Updates: 13,576
Cumulative Timesteps: 226,521,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.21556
Policy Entropy: 1.28861
Value Function Loss: 0.24190

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06011
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.05329

Collected Steps per Second: 10,971.77422
Overall Steps per Second: 9,372.01469

Timestep Collection Time: 4.55970
Timestep Consumption Time: 0.77832
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.33802

Cumulative Model Updates: 13,579
Cumulative Timesteps: 226,571,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 226571642...
Checkpoint 226571642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.75378
Policy Entropy: 1.27603
Value Function Loss: 0.22218

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09275
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.05145

Collected Steps per Second: 11,775.60862
Overall Steps per Second: 9,906.12098

Timestep Collection Time: 4.24793
Timestep Consumption Time: 0.80167
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.04961

Cumulative Model Updates: 13,582
Cumulative Timesteps: 226,621,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.19723
Policy Entropy: 1.28434
Value Function Loss: 0.22778

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06374
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.05653

Collected Steps per Second: 11,627.44131
Overall Steps per Second: 10,046.51408

Timestep Collection Time: 4.30241
Timestep Consumption Time: 0.67703
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.97944

Cumulative Model Updates: 13,585
Cumulative Timesteps: 226,671,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 226671690...
Checkpoint 226671690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.61053
Policy Entropy: 1.27648
Value Function Loss: 0.21016

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.07879

Collected Steps per Second: 11,957.40421
Overall Steps per Second: 10,056.02219

Timestep Collection Time: 4.18218
Timestep Consumption Time: 0.79076
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 4.97294

Cumulative Model Updates: 13,588
Cumulative Timesteps: 226,721,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.89094
Policy Entropy: 1.28548
Value Function Loss: 0.21779

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04965
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.09715

Collected Steps per Second: 11,525.12910
Overall Steps per Second: 9,948.20516

Timestep Collection Time: 4.33939
Timestep Consumption Time: 0.68785
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.02724

Cumulative Model Updates: 13,591
Cumulative Timesteps: 226,771,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 226771710...
Checkpoint 226771710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.44433
Policy Entropy: 1.27776
Value Function Loss: 0.21629

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06326
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.11008

Collected Steps per Second: 11,683.14483
Overall Steps per Second: 9,950.78185

Timestep Collection Time: 4.28121
Timestep Consumption Time: 0.74533
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.02654

Cumulative Model Updates: 13,594
Cumulative Timesteps: 226,821,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.64449
Policy Entropy: 1.28311
Value Function Loss: 0.23791

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.11962

Collected Steps per Second: 11,330.77200
Overall Steps per Second: 9,588.14872

Timestep Collection Time: 4.41294
Timestep Consumption Time: 0.80204
PPO Batch Consumption Time: 0.04211
Total Iteration Time: 5.21498

Cumulative Model Updates: 13,597
Cumulative Timesteps: 226,871,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 226871730...
Checkpoint 226871730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.18160
Policy Entropy: 1.27973
Value Function Loss: 0.23509

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05725
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.12701

Collected Steps per Second: 11,749.83425
Overall Steps per Second: 9,987.03618

Timestep Collection Time: 4.25674
Timestep Consumption Time: 0.75135
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.00809

Cumulative Model Updates: 13,600
Cumulative Timesteps: 226,921,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.11863
Policy Entropy: 1.28165
Value Function Loss: 0.24124

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07529
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.11411

Collected Steps per Second: 11,752.42394
Overall Steps per Second: 9,942.45670

Timestep Collection Time: 4.25512
Timestep Consumption Time: 0.77462
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.02974

Cumulative Model Updates: 13,603
Cumulative Timesteps: 226,971,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 226971754...
Checkpoint 226971754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.93265
Policy Entropy: 1.28115
Value Function Loss: 0.25753

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.10451

Collected Steps per Second: 11,797.40675
Overall Steps per Second: 9,941.36791

Timestep Collection Time: 4.24025
Timestep Consumption Time: 0.79165
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 5.03190

Cumulative Model Updates: 13,606
Cumulative Timesteps: 227,021,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.75086
Policy Entropy: 1.28166
Value Function Loss: 0.24267

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06338
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.09938

Collected Steps per Second: 11,587.97911
Overall Steps per Second: 9,812.07887

Timestep Collection Time: 4.31482
Timestep Consumption Time: 0.78094
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.09576

Cumulative Model Updates: 13,609
Cumulative Timesteps: 227,071,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 227071778...
Checkpoint 227071778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.01208
Policy Entropy: 1.27962
Value Function Loss: 0.27861

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.08542

Collected Steps per Second: 11,227.59323
Overall Steps per Second: 9,639.46080

Timestep Collection Time: 4.45349
Timestep Consumption Time: 0.73373
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 5.18722

Cumulative Model Updates: 13,612
Cumulative Timesteps: 227,121,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.21368
Policy Entropy: 1.28111
Value Function Loss: 0.26159

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04915
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 10,860.81075
Overall Steps per Second: 9,196.22596

Timestep Collection Time: 4.60647
Timestep Consumption Time: 0.83381
PPO Batch Consumption Time: 0.03980
Total Iteration Time: 5.44028

Cumulative Model Updates: 13,615
Cumulative Timesteps: 227,171,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 227171810...
Checkpoint 227171810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.88296
Policy Entropy: 1.28373
Value Function Loss: 0.26893

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04226
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.07512

Collected Steps per Second: 11,292.73725
Overall Steps per Second: 9,698.68857

Timestep Collection Time: 4.42798
Timestep Consumption Time: 0.72777
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 5.15575

Cumulative Model Updates: 13,618
Cumulative Timesteps: 227,221,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.65313
Policy Entropy: 1.28387
Value Function Loss: 0.22411

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05337
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.09091

Collected Steps per Second: 11,493.13369
Overall Steps per Second: 9,686.28211

Timestep Collection Time: 4.35251
Timestep Consumption Time: 0.81191
PPO Batch Consumption Time: 0.03910
Total Iteration Time: 5.16442

Cumulative Model Updates: 13,621
Cumulative Timesteps: 227,271,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 227271838...
Checkpoint 227271838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.18299
Policy Entropy: 1.28923
Value Function Loss: 0.19800

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05013
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 12,053.06326
Overall Steps per Second: 10,133.63775

Timestep Collection Time: 4.14965
Timestep Consumption Time: 0.78599
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.93564

Cumulative Model Updates: 13,624
Cumulative Timesteps: 227,321,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.25183
Policy Entropy: 1.28175
Value Function Loss: 0.19140

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 12,883.29682
Overall Steps per Second: 10,705.27502

Timestep Collection Time: 3.88146
Timestep Consumption Time: 0.78970
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 4.67116

Cumulative Model Updates: 13,627
Cumulative Timesteps: 227,371,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 227371860...
Checkpoint 227371860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.67959
Policy Entropy: 1.28539
Value Function Loss: 0.19481

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.06502

Collected Steps per Second: 11,619.70921
Overall Steps per Second: 9,519.52387

Timestep Collection Time: 4.30407
Timestep Consumption Time: 0.94956
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.25362

Cumulative Model Updates: 13,630
Cumulative Timesteps: 227,421,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.65305
Policy Entropy: 1.28154
Value Function Loss: 0.20217

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04521
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.06287

Collected Steps per Second: 12,043.83702
Overall Steps per Second: 10,161.37521

Timestep Collection Time: 4.15349
Timestep Consumption Time: 0.76946
PPO Batch Consumption Time: 0.03858
Total Iteration Time: 4.92296

Cumulative Model Updates: 13,633
Cumulative Timesteps: 227,471,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 227471896...
Checkpoint 227471896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.11829
Policy Entropy: 1.28487
Value Function Loss: 0.19364

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05135
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.06304

Collected Steps per Second: 12,568.76819
Overall Steps per Second: 10,407.77654

Timestep Collection Time: 3.98018
Timestep Consumption Time: 0.82641
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 4.80660

Cumulative Model Updates: 13,636
Cumulative Timesteps: 227,521,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.84090
Policy Entropy: 1.28331
Value Function Loss: 0.19399

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04801
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 12,911.23592
Overall Steps per Second: 10,803.89007

Timestep Collection Time: 3.87445
Timestep Consumption Time: 0.75573
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 4.63018

Cumulative Model Updates: 13,639
Cumulative Timesteps: 227,571,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 227571946...
Checkpoint 227571946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.45536
Policy Entropy: 1.28686
Value Function Loss: 0.18697

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03817
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.05987

Collected Steps per Second: 12,449.00476
Overall Steps per Second: 10,551.37627

Timestep Collection Time: 4.01863
Timestep Consumption Time: 0.72274
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 4.74137

Cumulative Model Updates: 13,642
Cumulative Timesteps: 227,621,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.42454
Policy Entropy: 1.28535
Value Function Loss: 0.20584

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04675
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.05935

Collected Steps per Second: 11,838.75715
Overall Steps per Second: 10,009.09676

Timestep Collection Time: 4.22477
Timestep Consumption Time: 0.77229
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 4.99705

Cumulative Model Updates: 13,645
Cumulative Timesteps: 227,671,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 227671990...
Checkpoint 227671990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.77214
Policy Entropy: 1.28598
Value Function Loss: 0.21637

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04746
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.06182

Collected Steps per Second: 11,666.54029
Overall Steps per Second: 9,806.38191

Timestep Collection Time: 4.28628
Timestep Consumption Time: 0.81306
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.09933

Cumulative Model Updates: 13,648
Cumulative Timesteps: 227,721,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.51596
Policy Entropy: 1.28316
Value Function Loss: 0.24382

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06279
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.06032

Collected Steps per Second: 11,041.58422
Overall Steps per Second: 9,413.50198

Timestep Collection Time: 4.53051
Timestep Consumption Time: 0.78356
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.31407

Cumulative Model Updates: 13,651
Cumulative Timesteps: 227,772,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 227772020...
Checkpoint 227772020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.75434
Policy Entropy: 1.28175
Value Function Loss: 0.22679

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.07924

Collected Steps per Second: 11,781.56801
Overall Steps per Second: 9,908.97467

Timestep Collection Time: 4.24460
Timestep Consumption Time: 0.80214
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 5.04674

Cumulative Model Updates: 13,654
Cumulative Timesteps: 227,822,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.15604
Policy Entropy: 1.28170
Value Function Loss: 0.21321

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.07845

Collected Steps per Second: 11,757.87246
Overall Steps per Second: 10,143.48871

Timestep Collection Time: 4.25383
Timestep Consumption Time: 0.67702
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 4.93085

Cumulative Model Updates: 13,657
Cumulative Timesteps: 227,872,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 227872044...
Checkpoint 227872044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.07325
Policy Entropy: 1.28248
Value Function Loss: 0.21324

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.07743

Collected Steps per Second: 11,911.79525
Overall Steps per Second: 10,097.20682

Timestep Collection Time: 4.19752
Timestep Consumption Time: 0.75434
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.95186

Cumulative Model Updates: 13,660
Cumulative Timesteps: 227,922,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.68815
Policy Entropy: 1.27943
Value Function Loss: 0.21302

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.07666

Collected Steps per Second: 11,797.83789
Overall Steps per Second: 10,029.60196

Timestep Collection Time: 4.23976
Timestep Consumption Time: 0.74748
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 4.98724

Cumulative Model Updates: 13,663
Cumulative Timesteps: 227,972,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 227972064...
Checkpoint 227972064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.57540
Policy Entropy: 1.28345
Value Function Loss: 0.21899

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.04444
Value Function Update Magnitude: 0.07934

Collected Steps per Second: 11,713.53314
Overall Steps per Second: 10,029.15060

Timestep Collection Time: 4.26891
Timestep Consumption Time: 0.71696
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 4.98587

Cumulative Model Updates: 13,666
Cumulative Timesteps: 228,022,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.71447
Policy Entropy: 1.28225
Value Function Loss: 0.20479

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.08355

Collected Steps per Second: 10,620.57039
Overall Steps per Second: 9,140.23648

Timestep Collection Time: 4.70954
Timestep Consumption Time: 0.76275
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.47229

Cumulative Model Updates: 13,669
Cumulative Timesteps: 228,072,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 228072086...
Checkpoint 228072086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.39175
Policy Entropy: 1.27956
Value Function Loss: 0.22874

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.09396

Collected Steps per Second: 11,917.12133
Overall Steps per Second: 10,300.88650

Timestep Collection Time: 4.19749
Timestep Consumption Time: 0.65860
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.85609

Cumulative Model Updates: 13,672
Cumulative Timesteps: 228,122,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.16060
Policy Entropy: 1.28086
Value Function Loss: 0.22520

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06648
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.09119

Collected Steps per Second: 11,837.30906
Overall Steps per Second: 10,009.09226

Timestep Collection Time: 4.22579
Timestep Consumption Time: 0.77186
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 4.99766

Cumulative Model Updates: 13,675
Cumulative Timesteps: 228,172,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 228172130...
Checkpoint 228172130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.28357
Policy Entropy: 1.28275
Value Function Loss: 0.21978

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.07990

Collected Steps per Second: 11,455.14763
Overall Steps per Second: 9,813.09393

Timestep Collection Time: 4.36485
Timestep Consumption Time: 0.73038
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.09523

Cumulative Model Updates: 13,678
Cumulative Timesteps: 228,222,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.12965
Policy Entropy: 1.28666
Value Function Loss: 0.20216

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06501
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.07067

Collected Steps per Second: 11,798.46821
Overall Steps per Second: 9,928.24369

Timestep Collection Time: 4.23835
Timestep Consumption Time: 0.79839
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.03674

Cumulative Model Updates: 13,681
Cumulative Timesteps: 228,272,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 228272136...
Checkpoint 228272136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.76656
Policy Entropy: 1.28610
Value Function Loss: 0.22120

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05069
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.05876

Collected Steps per Second: 11,686.21801
Overall Steps per Second: 9,685.55062

Timestep Collection Time: 4.27906
Timestep Consumption Time: 0.88389
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 5.16295

Cumulative Model Updates: 13,684
Cumulative Timesteps: 228,322,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.83031
Policy Entropy: 1.29333
Value Function Loss: 0.24130

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06883
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.06448

Collected Steps per Second: 11,211.48961
Overall Steps per Second: 9,696.05244

Timestep Collection Time: 4.46256
Timestep Consumption Time: 0.69747
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.16004

Cumulative Model Updates: 13,687
Cumulative Timesteps: 228,372,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 228372174...
Checkpoint 228372174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.65643
Policy Entropy: 1.28822
Value Function Loss: 0.23540

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06171
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.06378

Collected Steps per Second: 11,357.07357
Overall Steps per Second: 9,603.23098

Timestep Collection Time: 4.40448
Timestep Consumption Time: 0.80439
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.20887

Cumulative Model Updates: 13,690
Cumulative Timesteps: 228,422,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.44192
Policy Entropy: 1.28961
Value Function Loss: 0.22314

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06184
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.06278

Collected Steps per Second: 11,643.38904
Overall Steps per Second: 9,883.11240

Timestep Collection Time: 4.29634
Timestep Consumption Time: 0.76522
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.06156

Cumulative Model Updates: 13,693
Cumulative Timesteps: 228,472,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 228472220...
Checkpoint 228472220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.32717
Policy Entropy: 1.28857
Value Function Loss: 0.21829

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05389
Policy Update Magnitude: 0.06128
Value Function Update Magnitude: 0.06344

Collected Steps per Second: 11,522.15706
Overall Steps per Second: 9,789.01159

Timestep Collection Time: 4.34137
Timestep Consumption Time: 0.76864
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 5.11002

Cumulative Model Updates: 13,696
Cumulative Timesteps: 228,522,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.53403
Policy Entropy: 1.28692
Value Function Loss: 0.23566

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.05161
Policy Update Magnitude: 0.06432
Value Function Update Magnitude: 0.06352

Collected Steps per Second: 11,834.06645
Overall Steps per Second: 10,039.62285

Timestep Collection Time: 4.22729
Timestep Consumption Time: 0.75557
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 4.98286

Cumulative Model Updates: 13,699
Cumulative Timesteps: 228,572,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 228572268...
Checkpoint 228572268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.39853
Policy Entropy: 1.28863
Value Function Loss: 0.23274

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05831
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.06258

Collected Steps per Second: 11,369.76967
Overall Steps per Second: 9,733.06750

Timestep Collection Time: 4.39886
Timestep Consumption Time: 0.73971
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 5.13857

Cumulative Model Updates: 13,702
Cumulative Timesteps: 228,622,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.16358
Policy Entropy: 1.28688
Value Function Loss: 0.22618

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05689
Policy Update Magnitude: 0.06196
Value Function Update Magnitude: 0.06371

Collected Steps per Second: 11,524.60110
Overall Steps per Second: 9,696.52283

Timestep Collection Time: 4.34080
Timestep Consumption Time: 0.81837
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.15917

Cumulative Model Updates: 13,705
Cumulative Timesteps: 228,672,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 228672308...
Checkpoint 228672308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.21159
Policy Entropy: 1.28841
Value Function Loss: 0.22535

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06941
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.06305

Collected Steps per Second: 12,075.23798
Overall Steps per Second: 9,963.72438

Timestep Collection Time: 4.14104
Timestep Consumption Time: 0.87757
PPO Batch Consumption Time: 0.03926
Total Iteration Time: 5.01861

Cumulative Model Updates: 13,708
Cumulative Timesteps: 228,722,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.59654
Policy Entropy: 1.28844
Value Function Loss: 0.23376

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04804
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.06105

Collected Steps per Second: 12,352.10413
Overall Steps per Second: 10,254.37044

Timestep Collection Time: 4.04854
Timestep Consumption Time: 0.82821
PPO Batch Consumption Time: 0.03906
Total Iteration Time: 4.87675

Cumulative Model Updates: 13,711
Cumulative Timesteps: 228,772,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 228772320...
Checkpoint 228772320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.89840
Policy Entropy: 1.28745
Value Function Loss: 0.22786

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05361
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 12,055.81751
Overall Steps per Second: 10,211.32802

Timestep Collection Time: 4.14804
Timestep Consumption Time: 0.74927
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 4.89731

Cumulative Model Updates: 13,714
Cumulative Timesteps: 228,822,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.57763
Policy Entropy: 1.29064
Value Function Loss: 0.22127

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.06773

Collected Steps per Second: 11,845.71061
Overall Steps per Second: 10,160.52339

Timestep Collection Time: 4.22161
Timestep Consumption Time: 0.70018
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.92179

Cumulative Model Updates: 13,717
Cumulative Timesteps: 228,872,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 228872336...
Checkpoint 228872336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.13543
Policy Entropy: 1.28931
Value Function Loss: 0.20907

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03721
Policy Update Magnitude: 0.06608
Value Function Update Magnitude: 0.07354

Collected Steps per Second: 11,362.08827
Overall Steps per Second: 9,602.79939

Timestep Collection Time: 4.40130
Timestep Consumption Time: 0.80634
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.20765

Cumulative Model Updates: 13,720
Cumulative Timesteps: 228,922,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.58270
Policy Entropy: 1.29110
Value Function Loss: 0.21064

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03163
Policy Update Magnitude: 0.06780
Value Function Update Magnitude: 0.07065

Collected Steps per Second: 11,588.97825
Overall Steps per Second: 9,818.52088

Timestep Collection Time: 4.31600
Timestep Consumption Time: 0.77825
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.09425

Cumulative Model Updates: 13,723
Cumulative Timesteps: 228,972,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 228972362...
Checkpoint 228972362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.34507
Policy Entropy: 1.28676
Value Function Loss: 0.22088

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02906
Policy Update Magnitude: 0.07008
Value Function Update Magnitude: 0.06575

Collected Steps per Second: 11,920.90722
Overall Steps per Second: 10,048.43673

Timestep Collection Time: 4.19582
Timestep Consumption Time: 0.78187
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.97769

Cumulative Model Updates: 13,726
Cumulative Timesteps: 229,022,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.63163
Policy Entropy: 1.28335
Value Function Loss: 0.23538

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03799
Policy Update Magnitude: 0.07145
Value Function Update Magnitude: 0.06696

Collected Steps per Second: 12,148.72238
Overall Steps per Second: 10,274.94191

Timestep Collection Time: 4.11681
Timestep Consumption Time: 0.75076
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.86757

Cumulative Model Updates: 13,729
Cumulative Timesteps: 229,072,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 229072394...
Checkpoint 229072394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.19389
Policy Entropy: 1.28490
Value Function Loss: 0.22791

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04689
Policy Update Magnitude: 0.06776
Value Function Update Magnitude: 0.06936

Collected Steps per Second: 11,300.06222
Overall Steps per Second: 9,664.80590

Timestep Collection Time: 4.42652
Timestep Consumption Time: 0.74895
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 5.17548

Cumulative Model Updates: 13,732
Cumulative Timesteps: 229,122,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.45504
Policy Entropy: 1.29276
Value Function Loss: 0.21257

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04037
Policy Update Magnitude: 0.06550
Value Function Update Magnitude: 0.07085

Collected Steps per Second: 11,632.95528
Overall Steps per Second: 9,845.77880

Timestep Collection Time: 4.29848
Timestep Consumption Time: 0.78025
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.07872

Cumulative Model Updates: 13,735
Cumulative Timesteps: 229,172,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 229172418...
Checkpoint 229172418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.14861
Policy Entropy: 1.29006
Value Function Loss: 0.19846

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04017
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 11,005.87465
Overall Steps per Second: 9,443.93845

Timestep Collection Time: 4.54303
Timestep Consumption Time: 0.75137
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.29440

Cumulative Model Updates: 13,738
Cumulative Timesteps: 229,222,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.96365
Policy Entropy: 1.28703
Value Function Loss: 0.21376

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04877
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 11,916.20199
Overall Steps per Second: 10,024.15316

Timestep Collection Time: 4.19765
Timestep Consumption Time: 0.79230
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 4.98995

Cumulative Model Updates: 13,741
Cumulative Timesteps: 229,272,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 229272438...
Checkpoint 229272438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.80026
Policy Entropy: 1.29159
Value Function Loss: 0.21874

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04582
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.06101

Collected Steps per Second: 11,670.08477
Overall Steps per Second: 9,967.80377

Timestep Collection Time: 4.28703
Timestep Consumption Time: 0.73213
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.01916

Cumulative Model Updates: 13,744
Cumulative Timesteps: 229,322,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.06766
Policy Entropy: 1.28849
Value Function Loss: 0.21685

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04383
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.06243

Collected Steps per Second: 11,777.92737
Overall Steps per Second: 10,158.41519

Timestep Collection Time: 4.24710
Timestep Consumption Time: 0.67710
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 4.92419

Cumulative Model Updates: 13,747
Cumulative Timesteps: 229,372,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 229372490...
Checkpoint 229372490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.82199
Policy Entropy: 1.28453
Value Function Loss: 0.19115

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04829
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.05952

Collected Steps per Second: 11,418.86837
Overall Steps per Second: 9,642.68578

Timestep Collection Time: 4.37977
Timestep Consumption Time: 0.80675
PPO Batch Consumption Time: 0.04378
Total Iteration Time: 5.18652

Cumulative Model Updates: 13,750
Cumulative Timesteps: 229,422,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.19008
Policy Entropy: 1.28718
Value Function Loss: 0.17743

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04134
Policy Update Magnitude: 0.06693
Value Function Update Magnitude: 0.05980

Collected Steps per Second: 11,183.03709
Overall Steps per Second: 9,497.44176

Timestep Collection Time: 4.47302
Timestep Consumption Time: 0.79387
PPO Batch Consumption Time: 0.03881
Total Iteration Time: 5.26689

Cumulative Model Updates: 13,753
Cumulative Timesteps: 229,472,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 229472524...
Checkpoint 229472524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.34334
Policy Entropy: 1.28919
Value Function Loss: 0.16314

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04325
Policy Update Magnitude: 0.06557
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 11,244.34040
Overall Steps per Second: 9,557.95052

Timestep Collection Time: 4.44810
Timestep Consumption Time: 0.78482
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.23292

Cumulative Model Updates: 13,756
Cumulative Timesteps: 229,522,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.35400
Policy Entropy: 1.29076
Value Function Loss: 0.17667

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.06755
Value Function Update Magnitude: 0.08280

Collected Steps per Second: 11,125.04058
Overall Steps per Second: 9,467.61162

Timestep Collection Time: 4.49598
Timestep Consumption Time: 0.78708
PPO Batch Consumption Time: 0.03865
Total Iteration Time: 5.28306

Cumulative Model Updates: 13,759
Cumulative Timesteps: 229,572,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 229572558...
Checkpoint 229572558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.45005
Policy Entropy: 1.28966
Value Function Loss: 0.19464

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04589
Policy Update Magnitude: 0.06808
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 11,283.57529
Overall Steps per Second: 9,795.15759

Timestep Collection Time: 4.43122
Timestep Consumption Time: 0.67334
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.10456

Cumulative Model Updates: 13,762
Cumulative Timesteps: 229,622,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.76316
Policy Entropy: 1.29060
Value Function Loss: 0.20498

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.06069
Policy Update Magnitude: 0.07042
Value Function Update Magnitude: 0.07923

Collected Steps per Second: 11,498.71983
Overall Steps per Second: 9,704.74831

Timestep Collection Time: 4.34866
Timestep Consumption Time: 0.80387
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.15253

Cumulative Model Updates: 13,765
Cumulative Timesteps: 229,672,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 229672562...
Checkpoint 229672562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.09884
Policy Entropy: 1.28981
Value Function Loss: 0.20269

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.05282
Policy Update Magnitude: 0.07245
Value Function Update Magnitude: 0.07607

Collected Steps per Second: 12,276.70127
Overall Steps per Second: 10,372.57131

Timestep Collection Time: 4.07455
Timestep Consumption Time: 0.74798
PPO Batch Consumption Time: 0.03802
Total Iteration Time: 4.82253

Cumulative Model Updates: 13,768
Cumulative Timesteps: 229,722,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.21449
Policy Entropy: 1.29309
Value Function Loss: 0.20108

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06168
Policy Update Magnitude: 0.07375
Value Function Update Magnitude: 0.06341

Collected Steps per Second: 13,148.38230
Overall Steps per Second: 10,732.41591

Timestep Collection Time: 3.80305
Timestep Consumption Time: 0.85610
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 4.65916

Cumulative Model Updates: 13,771
Cumulative Timesteps: 229,772,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 229772588...
Checkpoint 229772588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.10872
Policy Entropy: 1.29366
Value Function Loss: 0.20811

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04948
Policy Update Magnitude: 0.07488
Value Function Update Magnitude: 0.06422

Collected Steps per Second: 11,972.65431
Overall Steps per Second: 9,976.26206

Timestep Collection Time: 4.17836
Timestep Consumption Time: 0.83615
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.01450

Cumulative Model Updates: 13,774
Cumulative Timesteps: 229,822,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.59310
Policy Entropy: 1.29403
Value Function Loss: 0.21499

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06923
Policy Update Magnitude: 0.07381
Value Function Update Magnitude: 0.07331

Collected Steps per Second: 12,533.01200
Overall Steps per Second: 10,612.64174

Timestep Collection Time: 3.99010
Timestep Consumption Time: 0.72201
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 4.71212

Cumulative Model Updates: 13,777
Cumulative Timesteps: 229,872,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 229872622...
Checkpoint 229872622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.43979
Policy Entropy: 1.29450
Value Function Loss: 0.21286

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04725
Policy Update Magnitude: 0.07178
Value Function Update Magnitude: 0.07368

Collected Steps per Second: 12,569.96836
Overall Steps per Second: 10,449.16469

Timestep Collection Time: 3.97853
Timestep Consumption Time: 0.80750
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 4.78603

Cumulative Model Updates: 13,780
Cumulative Timesteps: 229,922,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.29437
Policy Entropy: 1.29016
Value Function Loss: 0.20927

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06889
Policy Update Magnitude: 0.06776
Value Function Update Magnitude: 0.06308

Collected Steps per Second: 12,450.79456
Overall Steps per Second: 10,453.92886

Timestep Collection Time: 4.01597
Timestep Consumption Time: 0.76711
PPO Batch Consumption Time: 0.03809
Total Iteration Time: 4.78308

Cumulative Model Updates: 13,783
Cumulative Timesteps: 229,972,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 229972634...
Checkpoint 229972634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.57203
Policy Entropy: 1.29106
Value Function Loss: 0.20668

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05157
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.05866

Collected Steps per Second: 12,311.11565
Overall Steps per Second: 10,233.30386

Timestep Collection Time: 4.06153
Timestep Consumption Time: 0.82467
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 4.88620

Cumulative Model Updates: 13,786
Cumulative Timesteps: 230,022,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.15145
Policy Entropy: 1.28856
Value Function Loss: 0.21240

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.05167

Collected Steps per Second: 11,800.57960
Overall Steps per Second: 9,992.40328

Timestep Collection Time: 4.23725
Timestep Consumption Time: 0.76675
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.00400

Cumulative Model Updates: 13,789
Cumulative Timesteps: 230,072,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 230072638...
Checkpoint 230072638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.32136
Policy Entropy: 1.29046
Value Function Loss: 0.23258

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03905
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.05108

Collected Steps per Second: 11,293.71976
Overall Steps per Second: 9,749.54677

Timestep Collection Time: 4.42901
Timestep Consumption Time: 0.70148
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.13049

Cumulative Model Updates: 13,792
Cumulative Timesteps: 230,122,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.17067
Policy Entropy: 1.28715
Value Function Loss: 0.23051

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04371
Policy Update Magnitude: 0.07343
Value Function Update Magnitude: 0.05981

Collected Steps per Second: 11,471.97588
Overall Steps per Second: 9,677.32770

Timestep Collection Time: 4.35845
Timestep Consumption Time: 0.80827
PPO Batch Consumption Time: 0.03884
Total Iteration Time: 5.16672

Cumulative Model Updates: 13,795
Cumulative Timesteps: 230,172,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 230172658...
Checkpoint 230172658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.19146
Policy Entropy: 1.28700
Value Function Loss: 0.22673

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04610
Policy Update Magnitude: 0.07845
Value Function Update Magnitude: 0.07106

Collected Steps per Second: 11,757.86333
Overall Steps per Second: 9,918.60919

Timestep Collection Time: 4.25434
Timestep Consumption Time: 0.78890
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.04325

Cumulative Model Updates: 13,798
Cumulative Timesteps: 230,222,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.03401
Policy Entropy: 1.28514
Value Function Loss: 0.22172

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03679
Policy Update Magnitude: 0.07859
Value Function Update Magnitude: 0.06473

Collected Steps per Second: 11,991.20332
Overall Steps per Second: 10,028.73346

Timestep Collection Time: 4.17139
Timestep Consumption Time: 0.81628
PPO Batch Consumption Time: 0.03819
Total Iteration Time: 4.98767

Cumulative Model Updates: 13,801
Cumulative Timesteps: 230,272,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 230272700...
Checkpoint 230272700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.68063
Policy Entropy: 1.28701
Value Function Loss: 0.22215

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04013
Policy Update Magnitude: 0.08115
Value Function Update Magnitude: 0.08252

Collected Steps per Second: 11,556.79989
Overall Steps per Second: 9,915.24128

Timestep Collection Time: 4.32767
Timestep Consumption Time: 0.71648
PPO Batch Consumption Time: 0.03319
Total Iteration Time: 5.04415

Cumulative Model Updates: 13,804
Cumulative Timesteps: 230,322,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.98952
Policy Entropy: 1.28758
Value Function Loss: 0.20444

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05085
Policy Update Magnitude: 0.07975
Value Function Update Magnitude: 0.09893

Collected Steps per Second: 11,892.00535
Overall Steps per Second: 10,183.87843

Timestep Collection Time: 4.20484
Timestep Consumption Time: 0.70527
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 4.91011

Cumulative Model Updates: 13,807
Cumulative Timesteps: 230,372,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 230372718...
Checkpoint 230372718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.05724
Policy Entropy: 1.28142
Value Function Loss: 0.18585

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.05875
Policy Update Magnitude: 0.06926
Value Function Update Magnitude: 0.09170

Collected Steps per Second: 11,329.35543
Overall Steps per Second: 9,617.58763

Timestep Collection Time: 4.41473
Timestep Consumption Time: 0.78575
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.20047

Cumulative Model Updates: 13,810
Cumulative Timesteps: 230,422,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.44264
Policy Entropy: 1.28381
Value Function Loss: 0.19401

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04267
Policy Update Magnitude: 0.07724
Value Function Update Magnitude: 0.07435

Collected Steps per Second: 11,656.19432
Overall Steps per Second: 9,971.55279

Timestep Collection Time: 4.29180
Timestep Consumption Time: 0.72508
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.01687

Cumulative Model Updates: 13,813
Cumulative Timesteps: 230,472,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 230472760...
Checkpoint 230472760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.86905
Policy Entropy: 1.28462
Value Function Loss: 0.22811

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05175
Policy Update Magnitude: 0.08410
Value Function Update Magnitude: 0.06900

Collected Steps per Second: 11,687.76876
Overall Steps per Second: 9,914.37136

Timestep Collection Time: 4.27986
Timestep Consumption Time: 0.76554
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.04540

Cumulative Model Updates: 13,816
Cumulative Timesteps: 230,522,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.44809
Policy Entropy: 1.28153
Value Function Loss: 0.24300

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.07841
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 11,705.28396
Overall Steps per Second: 9,870.84455

Timestep Collection Time: 4.27363
Timestep Consumption Time: 0.79423
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.06785

Cumulative Model Updates: 13,819
Cumulative Timesteps: 230,572,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 230572806...
Checkpoint 230572806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.68671
Policy Entropy: 1.28538
Value Function Loss: 0.23057

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.07285

Collected Steps per Second: 11,569.36233
Overall Steps per Second: 9,931.87636

Timestep Collection Time: 4.32332
Timestep Consumption Time: 0.71279
PPO Batch Consumption Time: 0.04326
Total Iteration Time: 5.03611

Cumulative Model Updates: 13,822
Cumulative Timesteps: 230,622,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.94848
Policy Entropy: 1.28459
Value Function Loss: 0.20858

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 11,704.05517
Overall Steps per Second: 9,896.43759

Timestep Collection Time: 4.27390
Timestep Consumption Time: 0.78064
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.05455

Cumulative Model Updates: 13,825
Cumulative Timesteps: 230,672,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 230672846...
Checkpoint 230672846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.08158
Policy Entropy: 1.28708
Value Function Loss: 0.19300

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.07118

Collected Steps per Second: 11,059.02796
Overall Steps per Second: 9,457.03075

Timestep Collection Time: 4.52264
Timestep Consumption Time: 0.76612
PPO Batch Consumption Time: 0.03713
Total Iteration Time: 5.28876

Cumulative Model Updates: 13,828
Cumulative Timesteps: 230,722,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.17264
Policy Entropy: 1.28427
Value Function Loss: 0.20799

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.06960

Collected Steps per Second: 11,126.22973
Overall Steps per Second: 9,595.75687

Timestep Collection Time: 4.49460
Timestep Consumption Time: 0.71687
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.21147

Cumulative Model Updates: 13,831
Cumulative Timesteps: 230,772,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 230772870...
Checkpoint 230772870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.79159
Policy Entropy: 1.28714
Value Function Loss: 0.21823

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05379
Policy Update Magnitude: 0.06259
Value Function Update Magnitude: 0.06668

Collected Steps per Second: 11,691.69906
Overall Steps per Second: 9,708.59109

Timestep Collection Time: 4.27876
Timestep Consumption Time: 0.87399
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 5.15276

Cumulative Model Updates: 13,834
Cumulative Timesteps: 230,822,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.95894
Policy Entropy: 1.28355
Value Function Loss: 0.23987

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.06903
Value Function Update Magnitude: 0.07115

Collected Steps per Second: 11,707.44542
Overall Steps per Second: 9,945.81330

Timestep Collection Time: 4.27181
Timestep Consumption Time: 0.75664
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.02845

Cumulative Model Updates: 13,837
Cumulative Timesteps: 230,872,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 230872908...
Checkpoint 230872908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.00737
Policy Entropy: 1.28359
Value Function Loss: 0.23411

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07327
Policy Update Magnitude: 0.06734
Value Function Update Magnitude: 0.07734

Collected Steps per Second: 12,083.07241
Overall Steps per Second: 9,993.59954

Timestep Collection Time: 4.14050
Timestep Consumption Time: 0.86570
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 5.00620

Cumulative Model Updates: 13,840
Cumulative Timesteps: 230,922,938

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.49270
Policy Entropy: 1.28716
Value Function Loss: 0.21523

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.06337
Value Function Update Magnitude: 0.09564

Collected Steps per Second: 11,942.62089
Overall Steps per Second: 10,110.01335

Timestep Collection Time: 4.18819
Timestep Consumption Time: 0.75918
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 4.94737

Cumulative Model Updates: 13,843
Cumulative Timesteps: 230,972,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 230972956...
Checkpoint 230972956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.29985
Policy Entropy: 1.28436
Value Function Loss: 0.20434

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.06329
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.10222

Collected Steps per Second: 11,334.94756
Overall Steps per Second: 9,633.68282

Timestep Collection Time: 4.41378
Timestep Consumption Time: 0.77945
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.19324

Cumulative Model Updates: 13,846
Cumulative Timesteps: 231,022,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.99185
Policy Entropy: 1.28955
Value Function Loss: 0.20262

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05087
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.08925

Collected Steps per Second: 12,060.03025
Overall Steps per Second: 10,221.11758

Timestep Collection Time: 4.14825
Timestep Consumption Time: 0.74632
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 4.89457

Cumulative Model Updates: 13,849
Cumulative Timesteps: 231,073,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 231073014...
Checkpoint 231073014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.61914
Policy Entropy: 1.28044
Value Function Loss: 0.19843

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.07349

Collected Steps per Second: 11,996.40031
Overall Steps per Second: 10,235.87868

Timestep Collection Time: 4.16958
Timestep Consumption Time: 0.71715
PPO Batch Consumption Time: 0.03356
Total Iteration Time: 4.88673

Cumulative Model Updates: 13,852
Cumulative Timesteps: 231,123,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.81789
Policy Entropy: 1.28580
Value Function Loss: 0.22227

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05720
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.07256

Collected Steps per Second: 12,132.45263
Overall Steps per Second: 10,214.57199

Timestep Collection Time: 4.12167
Timestep Consumption Time: 0.77388
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 4.89556

Cumulative Model Updates: 13,855
Cumulative Timesteps: 231,173,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 231173040...
Checkpoint 231173040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.68533
Policy Entropy: 1.27966
Value Function Loss: 0.22734

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05165
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.06778

Collected Steps per Second: 11,828.62809
Overall Steps per Second: 10,102.59987

Timestep Collection Time: 4.22788
Timestep Consumption Time: 0.72233
PPO Batch Consumption Time: 0.04578
Total Iteration Time: 4.95021

Cumulative Model Updates: 13,858
Cumulative Timesteps: 231,223,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.15789
Policy Entropy: 1.28685
Value Function Loss: 0.26045

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05762
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.06969

Collected Steps per Second: 11,910.02254
Overall Steps per Second: 10,009.02489

Timestep Collection Time: 4.19966
Timestep Consumption Time: 0.79763
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.99729

Cumulative Model Updates: 13,861
Cumulative Timesteps: 231,273,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 231273068...
Checkpoint 231273068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.97890
Policy Entropy: 1.28190
Value Function Loss: 0.24295

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.10537

Collected Steps per Second: 11,346.46031
Overall Steps per Second: 9,649.77779

Timestep Collection Time: 4.40737
Timestep Consumption Time: 0.77493
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 5.18230

Cumulative Model Updates: 13,864
Cumulative Timesteps: 231,323,076

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.12582
Policy Entropy: 1.28480
Value Function Loss: 0.23648

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.11035

Collected Steps per Second: 11,614.44367
Overall Steps per Second: 9,813.14541

Timestep Collection Time: 4.30567
Timestep Consumption Time: 0.79035
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.09602

Cumulative Model Updates: 13,867
Cumulative Timesteps: 231,373,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 231373084...
Checkpoint 231373084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.03417
Policy Entropy: 1.27613
Value Function Loss: 0.20460

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06973
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.10011

Collected Steps per Second: 11,906.37627
Overall Steps per Second: 10,040.51756

Timestep Collection Time: 4.20111
Timestep Consumption Time: 0.78070
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 4.98181

Cumulative Model Updates: 13,870
Cumulative Timesteps: 231,423,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.38132
Policy Entropy: 1.28314
Value Function Loss: 0.21519

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.10125

Collected Steps per Second: 11,670.85546
Overall Steps per Second: 10,066.04876

Timestep Collection Time: 4.28572
Timestep Consumption Time: 0.68326
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.96898

Cumulative Model Updates: 13,873
Cumulative Timesteps: 231,473,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 231473122...
Checkpoint 231473122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.34802
Policy Entropy: 1.28294
Value Function Loss: 0.20333

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04766
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.08764

Collected Steps per Second: 11,462.27362
Overall Steps per Second: 9,696.29528

Timestep Collection Time: 4.36231
Timestep Consumption Time: 0.79450
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 5.15681

Cumulative Model Updates: 13,876
Cumulative Timesteps: 231,523,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.32851
Policy Entropy: 1.29068
Value Function Loss: 0.22046

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03865
Policy Update Magnitude: 0.06496
Value Function Update Magnitude: 0.07915

Collected Steps per Second: 11,503.28824
Overall Steps per Second: 9,785.91171

Timestep Collection Time: 4.34919
Timestep Consumption Time: 0.76326
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.11245

Cumulative Model Updates: 13,879
Cumulative Timesteps: 231,573,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 231573154...
Checkpoint 231573154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.96830
Policy Entropy: 1.28727
Value Function Loss: 0.20972

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04217
Policy Update Magnitude: 0.06553
Value Function Update Magnitude: 0.07121

Collected Steps per Second: 11,254.20669
Overall Steps per Second: 9,620.50082

Timestep Collection Time: 4.44492
Timestep Consumption Time: 0.75481
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.19973

Cumulative Model Updates: 13,882
Cumulative Timesteps: 231,623,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.91013
Policy Entropy: 1.28164
Value Function Loss: 0.20888

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03860
Policy Update Magnitude: 0.06870
Value Function Update Magnitude: 0.07781

Collected Steps per Second: 11,129.89309
Overall Steps per Second: 9,538.01824

Timestep Collection Time: 4.49402
Timestep Consumption Time: 0.75004
PPO Batch Consumption Time: 0.03941
Total Iteration Time: 5.24407

Cumulative Model Updates: 13,885
Cumulative Timesteps: 231,673,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 231673196...
Checkpoint 231673196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.53400
Policy Entropy: 1.28125
Value Function Loss: 0.19652

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04318
Policy Update Magnitude: 0.07224
Value Function Update Magnitude: 0.08594

Collected Steps per Second: 11,460.07436
Overall Steps per Second: 9,959.32519

Timestep Collection Time: 4.36542
Timestep Consumption Time: 0.65782
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.02323

Cumulative Model Updates: 13,888
Cumulative Timesteps: 231,723,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.98763
Policy Entropy: 1.28523
Value Function Loss: 0.19902

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.07440
Value Function Update Magnitude: 0.07448

Collected Steps per Second: 11,730.80009
Overall Steps per Second: 9,916.53995

Timestep Collection Time: 4.26365
Timestep Consumption Time: 0.78005
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.04369

Cumulative Model Updates: 13,891
Cumulative Timesteps: 231,773,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 231773240...
Checkpoint 231773240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.33363
Policy Entropy: 1.28379
Value Function Loss: 0.21385

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04037
Policy Update Magnitude: 0.07651
Value Function Update Magnitude: 0.06549

Collected Steps per Second: 11,088.67732
Overall Steps per Second: 9,459.04281

Timestep Collection Time: 4.51145
Timestep Consumption Time: 0.77725
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.28870

Cumulative Model Updates: 13,894
Cumulative Timesteps: 231,823,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.59713
Policy Entropy: 1.28470
Value Function Loss: 0.20876

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05032
Policy Update Magnitude: 0.07756
Value Function Update Magnitude: 0.07819

Collected Steps per Second: 11,714.49531
Overall Steps per Second: 9,742.95620

Timestep Collection Time: 4.26992
Timestep Consumption Time: 0.86404
PPO Batch Consumption Time: 0.04027
Total Iteration Time: 5.13397

Cumulative Model Updates: 13,897
Cumulative Timesteps: 231,873,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 231873286...
Checkpoint 231873286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.53313
Policy Entropy: 1.28518
Value Function Loss: 0.19149

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04535
Policy Update Magnitude: 0.07221
Value Function Update Magnitude: 0.10111

Collected Steps per Second: 11,233.96313
Overall Steps per Second: 9,531.53233

Timestep Collection Time: 4.45168
Timestep Consumption Time: 0.79512
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 5.24680

Cumulative Model Updates: 13,900
Cumulative Timesteps: 231,923,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.51648
Policy Entropy: 1.28015
Value Function Loss: 0.18854

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05445
Policy Update Magnitude: 0.06936
Value Function Update Magnitude: 0.09527

Collected Steps per Second: 11,175.56207
Overall Steps per Second: 9,622.44953

Timestep Collection Time: 4.47405
Timestep Consumption Time: 0.72213
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.19618

Cumulative Model Updates: 13,903
Cumulative Timesteps: 231,973,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 231973296...
Checkpoint 231973296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.97794
Policy Entropy: 1.28175
Value Function Loss: 0.19604

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04873
Policy Update Magnitude: 0.07083
Value Function Update Magnitude: 0.07392

Collected Steps per Second: 11,408.64159
Overall Steps per Second: 9,658.70845

Timestep Collection Time: 4.38510
Timestep Consumption Time: 0.79448
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.17957

Cumulative Model Updates: 13,906
Cumulative Timesteps: 232,023,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.41251
Policy Entropy: 1.28282
Value Function Loss: 0.21043

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.06334

Collected Steps per Second: 12,074.46886
Overall Steps per Second: 10,147.40348

Timestep Collection Time: 4.14312
Timestep Consumption Time: 0.78681
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.92993

Cumulative Model Updates: 13,909
Cumulative Timesteps: 232,073,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 232073350...
Checkpoint 232073350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.86230
Policy Entropy: 1.28066
Value Function Loss: 0.21460

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07046
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.05980

Collected Steps per Second: 12,918.84440
Overall Steps per Second: 10,729.90447

Timestep Collection Time: 3.87140
Timestep Consumption Time: 0.78978
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 4.66118

Cumulative Model Updates: 13,912
Cumulative Timesteps: 232,123,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.07445
Policy Entropy: 1.28437
Value Function Loss: 0.20899

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05088
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.05825

Collected Steps per Second: 12,847.34334
Overall Steps per Second: 10,366.23880

Timestep Collection Time: 3.89186
Timestep Consumption Time: 0.93150
PPO Batch Consumption Time: 0.03926
Total Iteration Time: 4.82335

Cumulative Model Updates: 13,915
Cumulative Timesteps: 232,173,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 232173364...
Checkpoint 232173364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.22036
Policy Entropy: 1.28087
Value Function Loss: 0.20227

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04222
Policy Update Magnitude: 0.06791
Value Function Update Magnitude: 0.06256

Collected Steps per Second: 12,353.90265
Overall Steps per Second: 10,497.86229

Timestep Collection Time: 4.04795
Timestep Consumption Time: 0.71568
PPO Batch Consumption Time: 0.03812
Total Iteration Time: 4.76364

Cumulative Model Updates: 13,918
Cumulative Timesteps: 232,223,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.56861
Policy Entropy: 1.27805
Value Function Loss: 0.18392

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06623
Policy Update Magnitude: 0.06835
Value Function Update Magnitude: 0.06900

Collected Steps per Second: 12,517.14675
Overall Steps per Second: 10,328.33109

Timestep Collection Time: 3.99500
Timestep Consumption Time: 0.84663
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 4.84163

Cumulative Model Updates: 13,921
Cumulative Timesteps: 232,273,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 232273378...
Checkpoint 232273378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.88470
Policy Entropy: 1.28530
Value Function Loss: 0.18622

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04239
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.05998

Collected Steps per Second: 12,547.89928
Overall Steps per Second: 10,475.77561

Timestep Collection Time: 3.98680
Timestep Consumption Time: 0.78860
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.77540

Cumulative Model Updates: 13,924
Cumulative Timesteps: 232,323,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.60293
Policy Entropy: 1.28129
Value Function Loss: 0.18437

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.05056
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.06128

Collected Steps per Second: 12,735.04619
Overall Steps per Second: 10,558.27970

Timestep Collection Time: 3.92774
Timestep Consumption Time: 0.80977
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.73751

Cumulative Model Updates: 13,927
Cumulative Timesteps: 232,373,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 232373424...
Checkpoint 232373424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.52815
Policy Entropy: 1.28059
Value Function Loss: 0.21182

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04605
Policy Update Magnitude: 0.07038
Value Function Update Magnitude: 0.06753

Collected Steps per Second: 11,689.07892
Overall Steps per Second: 9,929.97921

Timestep Collection Time: 4.27801
Timestep Consumption Time: 0.75785
PPO Batch Consumption Time: 0.03847
Total Iteration Time: 5.03586

Cumulative Model Updates: 13,930
Cumulative Timesteps: 232,423,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.22068
Policy Entropy: 1.27991
Value Function Loss: 0.20421

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05964
Policy Update Magnitude: 0.07551
Value Function Update Magnitude: 0.07682

Collected Steps per Second: 11,956.70080
Overall Steps per Second: 10,243.51949

Timestep Collection Time: 4.18376
Timestep Consumption Time: 0.69971
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 4.88348

Cumulative Model Updates: 13,933
Cumulative Timesteps: 232,473,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 232473454...
Checkpoint 232473454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.09947
Policy Entropy: 1.28125
Value Function Loss: 0.22441

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03527
Policy Update Magnitude: 0.07565
Value Function Update Magnitude: 0.07020

Collected Steps per Second: 10,941.77943
Overall Steps per Second: 9,311.41890

Timestep Collection Time: 4.57147
Timestep Consumption Time: 0.80043
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.37190

Cumulative Model Updates: 13,936
Cumulative Timesteps: 232,523,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.29146
Policy Entropy: 1.27967
Value Function Loss: 0.21200

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06603
Policy Update Magnitude: 0.07820
Value Function Update Magnitude: 0.06677

Collected Steps per Second: 11,367.84617
Overall Steps per Second: 9,655.62281

Timestep Collection Time: 4.39855
Timestep Consumption Time: 0.77999
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 5.17854

Cumulative Model Updates: 13,939
Cumulative Timesteps: 232,573,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 232573476...
Checkpoint 232573476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.95309
Policy Entropy: 1.28073
Value Function Loss: 0.21496

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06010
Policy Update Magnitude: 0.07867
Value Function Update Magnitude: 0.06166

Collected Steps per Second: 11,836.21121
Overall Steps per Second: 9,970.59627

Timestep Collection Time: 4.22466
Timestep Consumption Time: 0.79048
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 5.01515

Cumulative Model Updates: 13,942
Cumulative Timesteps: 232,623,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.06618
Policy Entropy: 1.28624
Value Function Loss: 0.21212

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03963
Policy Update Magnitude: 0.07780
Value Function Update Magnitude: 0.05894

Collected Steps per Second: 11,744.22301
Overall Steps per Second: 10,011.52815

Timestep Collection Time: 4.25946
Timestep Consumption Time: 0.73718
PPO Batch Consumption Time: 0.03386
Total Iteration Time: 4.99664

Cumulative Model Updates: 13,945
Cumulative Timesteps: 232,673,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 232673504...
Checkpoint 232673504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.45597
Policy Entropy: 1.28030
Value Function Loss: 0.21519

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06132
Policy Update Magnitude: 0.07907
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 11,687.81092
Overall Steps per Second: 10,009.20068

Timestep Collection Time: 4.28019
Timestep Consumption Time: 0.71782
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 4.99800

Cumulative Model Updates: 13,948
Cumulative Timesteps: 232,723,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.41807
Policy Entropy: 1.28059
Value Function Loss: 0.21933

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.07673
Value Function Update Magnitude: 0.08351

Collected Steps per Second: 11,493.58915
Overall Steps per Second: 9,470.22841

Timestep Collection Time: 4.35025
Timestep Consumption Time: 0.92945
PPO Batch Consumption Time: 0.04660
Total Iteration Time: 5.27970

Cumulative Model Updates: 13,951
Cumulative Timesteps: 232,773,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 232773530...
Checkpoint 232773530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.52437
Policy Entropy: 1.28056
Value Function Loss: 0.20068

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04180
Policy Update Magnitude: 0.07245
Value Function Update Magnitude: 0.09449

Collected Steps per Second: 11,583.37742
Overall Steps per Second: 9,796.73288

Timestep Collection Time: 4.31757
Timestep Consumption Time: 0.78740
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 5.10497

Cumulative Model Updates: 13,954
Cumulative Timesteps: 232,823,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.80929
Policy Entropy: 1.27754
Value Function Loss: 0.20350

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06892
Policy Update Magnitude: 0.07208
Value Function Update Magnitude: 0.07985

Collected Steps per Second: 11,546.94211
Overall Steps per Second: 9,695.10994

Timestep Collection Time: 4.33171
Timestep Consumption Time: 0.82739
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.15910

Cumulative Model Updates: 13,957
Cumulative Timesteps: 232,873,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 232873560...
Checkpoint 232873560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.33320
Policy Entropy: 1.27536
Value Function Loss: 0.19541

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06505
Policy Update Magnitude: 0.07443
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 11,464.31918
Overall Steps per Second: 9,705.96023

Timestep Collection Time: 4.36397
Timestep Consumption Time: 0.79059
PPO Batch Consumption Time: 0.03778
Total Iteration Time: 5.15456

Cumulative Model Updates: 13,960
Cumulative Timesteps: 232,923,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.83275
Policy Entropy: 1.27944
Value Function Loss: 0.20137

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05592
Policy Update Magnitude: 0.07666
Value Function Update Magnitude: 0.09702

Collected Steps per Second: 11,567.62459
Overall Steps per Second: 9,954.80855

Timestep Collection Time: 4.32241
Timestep Consumption Time: 0.70029
PPO Batch Consumption Time: 0.03399
Total Iteration Time: 5.02270

Cumulative Model Updates: 13,963
Cumulative Timesteps: 232,973,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 232973590...
Checkpoint 232973590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.18803
Policy Entropy: 1.28234
Value Function Loss: 0.18347

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06325
Policy Update Magnitude: 0.07096
Value Function Update Magnitude: 0.10247

Collected Steps per Second: 11,618.90350
Overall Steps per Second: 9,807.81229

Timestep Collection Time: 4.30557
Timestep Consumption Time: 0.79506
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.10063

Cumulative Model Updates: 13,966
Cumulative Timesteps: 233,023,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.47172
Policy Entropy: 1.28133
Value Function Loss: 0.17894

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05383
Policy Update Magnitude: 0.07001
Value Function Update Magnitude: 0.09227

Collected Steps per Second: 11,090.13853
Overall Steps per Second: 9,418.71380

Timestep Collection Time: 4.50869
Timestep Consumption Time: 0.80010
PPO Batch Consumption Time: 0.04054
Total Iteration Time: 5.30879

Cumulative Model Updates: 13,969
Cumulative Timesteps: 233,073,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 233073618...
Checkpoint 233073618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.05143
Policy Entropy: 1.28942
Value Function Loss: 0.16594

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.05303
Policy Update Magnitude: 0.07266
Value Function Update Magnitude: 0.07647

Collected Steps per Second: 11,138.19654
Overall Steps per Second: 9,423.80267

Timestep Collection Time: 4.49085
Timestep Consumption Time: 0.81698
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.30784

Cumulative Model Updates: 13,972
Cumulative Timesteps: 233,123,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.25638
Policy Entropy: 1.28798
Value Function Loss: 0.17062

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04329
Policy Update Magnitude: 0.07105
Value Function Update Magnitude: 0.08052

Collected Steps per Second: 11,283.66248
Overall Steps per Second: 9,512.17221

Timestep Collection Time: 4.43207
Timestep Consumption Time: 0.82540
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.25747

Cumulative Model Updates: 13,975
Cumulative Timesteps: 233,173,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 233173648...
Checkpoint 233173648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.37054
Policy Entropy: 1.28935
Value Function Loss: 0.19148

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06568
Policy Update Magnitude: 0.06887
Value Function Update Magnitude: 0.08484

Collected Steps per Second: 11,447.99142
Overall Steps per Second: 9,792.22781

Timestep Collection Time: 4.36775
Timestep Consumption Time: 0.73854
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 5.10629

Cumulative Model Updates: 13,978
Cumulative Timesteps: 233,223,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.29875
Policy Entropy: 1.29234
Value Function Loss: 0.19708

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04943
Policy Update Magnitude: 0.06839
Value Function Update Magnitude: 0.06964

Collected Steps per Second: 11,876.55900
Overall Steps per Second: 9,917.86821

Timestep Collection Time: 4.21216
Timestep Consumption Time: 0.83186
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.04403

Cumulative Model Updates: 13,981
Cumulative Timesteps: 233,273,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 233273676...
Checkpoint 233273676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.32163
Policy Entropy: 1.29049
Value Function Loss: 0.19065

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.06779
Value Function Update Magnitude: 0.06345

Collected Steps per Second: 12,099.86181
Overall Steps per Second: 10,085.07344

Timestep Collection Time: 4.13228
Timestep Consumption Time: 0.82554
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 4.95782

Cumulative Model Updates: 13,984
Cumulative Timesteps: 233,323,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.04435
Policy Entropy: 1.29037
Value Function Loss: 0.18050

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06057
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.05662

Collected Steps per Second: 11,623.42331
Overall Steps per Second: 9,859.22194

Timestep Collection Time: 4.30166
Timestep Consumption Time: 0.76974
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.07139

Cumulative Model Updates: 13,987
Cumulative Timesteps: 233,373,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 233373676...
Checkpoint 233373676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.35689
Policy Entropy: 1.28455
Value Function Loss: 0.17184

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05911
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.05860

Collected Steps per Second: 11,987.36590
Overall Steps per Second: 10,119.93483

Timestep Collection Time: 4.17173
Timestep Consumption Time: 0.76981
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.94153

Cumulative Model Updates: 13,990
Cumulative Timesteps: 233,423,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.85028
Policy Entropy: 1.28764
Value Function Loss: 0.18748

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05863
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.06559

Collected Steps per Second: 10,858.84329
Overall Steps per Second: 9,325.06799

Timestep Collection Time: 4.60454
Timestep Consumption Time: 0.75735
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 5.36189

Cumulative Model Updates: 13,993
Cumulative Timesteps: 233,473,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 233473684...
Checkpoint 233473684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.05921
Policy Entropy: 1.28694
Value Function Loss: 0.19239

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 12,148.17235
Overall Steps per Second: 10,111.03851

Timestep Collection Time: 4.11799
Timestep Consumption Time: 0.82968
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 4.94766

Cumulative Model Updates: 13,996
Cumulative Timesteps: 233,523,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.62398
Policy Entropy: 1.28897
Value Function Loss: 0.19862

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06543
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.07163

Collected Steps per Second: 11,816.74785
Overall Steps per Second: 10,014.95155

Timestep Collection Time: 4.23314
Timestep Consumption Time: 0.76159
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.99473

Cumulative Model Updates: 13,999
Cumulative Timesteps: 233,573,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 233573732...
Checkpoint 233573732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.44838
Policy Entropy: 1.28294
Value Function Loss: 0.19117

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06543
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.06994

Collected Steps per Second: 11,560.06123
Overall Steps per Second: 9,885.33388

Timestep Collection Time: 4.32697
Timestep Consumption Time: 0.73305
PPO Batch Consumption Time: 0.03788
Total Iteration Time: 5.06002

Cumulative Model Updates: 14,002
Cumulative Timesteps: 233,623,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.66765
Policy Entropy: 1.28516
Value Function Loss: 0.18959

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04955
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.06943

Collected Steps per Second: 11,063.11193
Overall Steps per Second: 9,408.16400

Timestep Collection Time: 4.52151
Timestep Consumption Time: 0.79536
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.31687

Cumulative Model Updates: 14,005
Cumulative Timesteps: 233,673,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 233673774...
Checkpoint 233673774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.72453
Policy Entropy: 1.28570
Value Function Loss: 0.20499

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05917
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.07017

Collected Steps per Second: 11,798.94839
Overall Steps per Second: 10,184.06778

Timestep Collection Time: 4.24038
Timestep Consumption Time: 0.67239
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 4.91277

Cumulative Model Updates: 14,008
Cumulative Timesteps: 233,723,806

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.96805
Policy Entropy: 1.28474
Value Function Loss: 0.20682

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06657
Policy Update Magnitude: 0.06713
Value Function Update Magnitude: 0.06660

Collected Steps per Second: 11,384.72667
Overall Steps per Second: 9,660.11572

Timestep Collection Time: 4.39361
Timestep Consumption Time: 0.78439
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.17799

Cumulative Model Updates: 14,011
Cumulative Timesteps: 233,773,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 233773826...
Checkpoint 233773826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.30674
Policy Entropy: 1.28827
Value Function Loss: 0.20084

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06037
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.06601

Collected Steps per Second: 11,687.81447
Overall Steps per Second: 9,921.50831

Timestep Collection Time: 4.28018
Timestep Consumption Time: 0.76199
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.04218

Cumulative Model Updates: 14,014
Cumulative Timesteps: 233,823,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.73866
Policy Entropy: 1.28412
Value Function Loss: 0.19054

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06936
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 11,746.99904
Overall Steps per Second: 10,090.76565

Timestep Collection Time: 4.25811
Timestep Consumption Time: 0.69890
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 4.95701

Cumulative Model Updates: 14,017
Cumulative Timesteps: 233,873,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 233873872...
Checkpoint 233873872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.12510
Policy Entropy: 1.28754
Value Function Loss: 0.21232

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04078
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.06587

Collected Steps per Second: 11,605.13665
Overall Steps per Second: 9,772.80523

Timestep Collection Time: 4.31033
Timestep Consumption Time: 0.80816
PPO Batch Consumption Time: 0.03360
Total Iteration Time: 5.11849

Cumulative Model Updates: 14,020
Cumulative Timesteps: 233,923,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.45624
Policy Entropy: 1.28396
Value Function Loss: 0.21213

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05421
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 11,128.85661
Overall Steps per Second: 9,695.11587

Timestep Collection Time: 4.49516
Timestep Consumption Time: 0.66476
PPO Batch Consumption Time: 0.03417
Total Iteration Time: 5.15992

Cumulative Model Updates: 14,023
Cumulative Timesteps: 233,973,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 233973920...
Checkpoint 233973920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.02212
Policy Entropy: 1.28448
Value Function Loss: 0.20800

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05703
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 11,476.14430
Overall Steps per Second: 9,736.78193

Timestep Collection Time: 4.35756
Timestep Consumption Time: 0.77843
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.13599

Cumulative Model Updates: 14,026
Cumulative Timesteps: 234,023,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.74185
Policy Entropy: 1.28256
Value Function Loss: 0.18764

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.06749

Collected Steps per Second: 11,502.82170
Overall Steps per Second: 9,843.40680

Timestep Collection Time: 4.34937
Timestep Consumption Time: 0.73322
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.08259

Cumulative Model Updates: 14,029
Cumulative Timesteps: 234,073,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 234073958...
Checkpoint 234073958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.78218
Policy Entropy: 1.28494
Value Function Loss: 0.19407

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04601
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.05690

Collected Steps per Second: 11,839.78547
Overall Steps per Second: 10,020.15472

Timestep Collection Time: 4.22389
Timestep Consumption Time: 0.76705
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.99094

Cumulative Model Updates: 14,032
Cumulative Timesteps: 234,123,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.17379
Policy Entropy: 1.28045
Value Function Loss: 0.22008

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 11,386.01119
Overall Steps per Second: 9,649.56863

Timestep Collection Time: 4.39170
Timestep Consumption Time: 0.79029
PPO Batch Consumption Time: 0.03863
Total Iteration Time: 5.18199

Cumulative Model Updates: 14,035
Cumulative Timesteps: 234,173,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 234173972...
Checkpoint 234173972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.32093
Policy Entropy: 1.28118
Value Function Loss: 0.22221

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.05831

Collected Steps per Second: 11,622.26275
Overall Steps per Second: 9,921.80523

Timestep Collection Time: 4.30364
Timestep Consumption Time: 0.73758
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.04122

Cumulative Model Updates: 14,038
Cumulative Timesteps: 234,223,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.17965
Policy Entropy: 1.27561
Value Function Loss: 0.24757

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.06178

Collected Steps per Second: 10,865.98144
Overall Steps per Second: 9,284.28963

Timestep Collection Time: 4.60317
Timestep Consumption Time: 0.78421
PPO Batch Consumption Time: 0.03907
Total Iteration Time: 5.38738

Cumulative Model Updates: 14,041
Cumulative Timesteps: 234,274,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 234274008...
Checkpoint 234274008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.18857
Policy Entropy: 1.28058
Value Function Loss: 0.24025

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07435
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 11,169.18105
Overall Steps per Second: 9,454.53081

Timestep Collection Time: 4.47786
Timestep Consumption Time: 0.81209
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 5.28995

Cumulative Model Updates: 14,044
Cumulative Timesteps: 234,324,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.66421
Policy Entropy: 1.28155
Value Function Loss: 0.23763

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.06276

Collected Steps per Second: 11,668.61552
Overall Steps per Second: 9,872.04289

Timestep Collection Time: 4.28534
Timestep Consumption Time: 0.77987
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.06521

Cumulative Model Updates: 14,047
Cumulative Timesteps: 234,374,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 234374026...
Checkpoint 234374026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.66283
Policy Entropy: 1.28216
Value Function Loss: 0.20305

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.08263

Collected Steps per Second: 11,666.05208
Overall Steps per Second: 9,932.04824

Timestep Collection Time: 4.28611
Timestep Consumption Time: 0.74830
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.03441

Cumulative Model Updates: 14,050
Cumulative Timesteps: 234,424,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.75937
Policy Entropy: 1.28151
Value Function Loss: 0.19469

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.08633

Collected Steps per Second: 12,307.20248
Overall Steps per Second: 10,446.62366

Timestep Collection Time: 4.06299
Timestep Consumption Time: 0.72363
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 4.78662

Cumulative Model Updates: 14,053
Cumulative Timesteps: 234,474,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 234474032...
Checkpoint 234474032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.65560
Policy Entropy: 1.27923
Value Function Loss: 0.21364

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.07811

Collected Steps per Second: 12,637.48993
Overall Steps per Second: 10,410.94117

Timestep Collection Time: 3.95759
Timestep Consumption Time: 0.84639
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.80398

Cumulative Model Updates: 14,056
Cumulative Timesteps: 234,524,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.49962
Policy Entropy: 1.28882
Value Function Loss: 0.23519

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09196
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.07577

Collected Steps per Second: 11,679.49979
Overall Steps per Second: 9,771.56525

Timestep Collection Time: 4.28375
Timestep Consumption Time: 0.83642
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.12016

Cumulative Model Updates: 14,059
Cumulative Timesteps: 234,574,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 234574078...
Checkpoint 234574078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.59674
Policy Entropy: 1.28618
Value Function Loss: 0.23025

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.04066
Value Function Update Magnitude: 0.07274

Collected Steps per Second: 12,773.68124
Overall Steps per Second: 10,669.85114

Timestep Collection Time: 3.91539
Timestep Consumption Time: 0.77202
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 4.68741

Cumulative Model Updates: 14,062
Cumulative Timesteps: 234,624,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.92666
Policy Entropy: 1.28963
Value Function Loss: 0.21497

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 0.04247
Value Function Update Magnitude: 0.08575

Collected Steps per Second: 12,333.02116
Overall Steps per Second: 10,370.67890

Timestep Collection Time: 4.05594
Timestep Consumption Time: 0.76747
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.82341

Cumulative Model Updates: 14,065
Cumulative Timesteps: 234,674,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 234674114...
Checkpoint 234674114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.46294
Policy Entropy: 1.29132
Value Function Loss: 0.20085

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.04369
Value Function Update Magnitude: 0.08892

Collected Steps per Second: 12,528.49429
Overall Steps per Second: 10,650.57844

Timestep Collection Time: 3.99282
Timestep Consumption Time: 0.70402
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 4.69683

Cumulative Model Updates: 14,068
Cumulative Timesteps: 234,724,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.30083
Policy Entropy: 1.28814
Value Function Loss: 0.18847

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.04053
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 11,459.18836
Overall Steps per Second: 9,616.90329

Timestep Collection Time: 4.36453
Timestep Consumption Time: 0.83610
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.20063

Cumulative Model Updates: 14,071
Cumulative Timesteps: 234,774,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 234774152...
Checkpoint 234774152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.63123
Policy Entropy: 1.29276
Value Function Loss: 0.18520

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.08850

Collected Steps per Second: 11,786.10323
Overall Steps per Second: 10,035.57160

Timestep Collection Time: 4.24313
Timestep Consumption Time: 0.74014
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.98327

Cumulative Model Updates: 14,074
Cumulative Timesteps: 234,824,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.43006
Policy Entropy: 1.29183
Value Function Loss: 0.20775

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.09314

Collected Steps per Second: 11,410.86542
Overall Steps per Second: 9,703.74693

Timestep Collection Time: 4.38179
Timestep Consumption Time: 0.77086
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.15265

Cumulative Model Updates: 14,077
Cumulative Timesteps: 234,874,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 234874162...
Checkpoint 234874162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.03532
Policy Entropy: 1.29560
Value Function Loss: 0.22697

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.09080

Collected Steps per Second: 11,773.83117
Overall Steps per Second: 9,964.95990

Timestep Collection Time: 4.24908
Timestep Consumption Time: 0.77131
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 5.02039

Cumulative Model Updates: 14,080
Cumulative Timesteps: 234,924,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.89878
Policy Entropy: 1.29435
Value Function Loss: 0.23053

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 11,472.55717
Overall Steps per Second: 9,851.58160

Timestep Collection Time: 4.35962
Timestep Consumption Time: 0.71733
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.07695

Cumulative Model Updates: 14,083
Cumulative Timesteps: 234,974,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 234974206...
Checkpoint 234974206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.51156
Policy Entropy: 1.29197
Value Function Loss: 0.20638

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07494
Policy Update Magnitude: 0.04242
Value Function Update Magnitude: 0.08537

Collected Steps per Second: 11,710.53069
Overall Steps per Second: 9,928.28638

Timestep Collection Time: 4.27000
Timestep Consumption Time: 0.76652
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.03652

Cumulative Model Updates: 14,086
Cumulative Timesteps: 235,024,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.08681
Policy Entropy: 1.29150
Value Function Loss: 0.20566

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.10015

Collected Steps per Second: 11,659.23069
Overall Steps per Second: 9,836.63727

Timestep Collection Time: 4.28931
Timestep Consumption Time: 0.79475
PPO Batch Consumption Time: 0.03980
Total Iteration Time: 5.08405

Cumulative Model Updates: 14,089
Cumulative Timesteps: 235,074,220

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 235074220...
Checkpoint 235074220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.49658
Policy Entropy: 1.29170
Value Function Loss: 0.20624

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.04236
Value Function Update Magnitude: 0.11107

Collected Steps per Second: 11,741.53704
Overall Steps per Second: 9,913.61626

Timestep Collection Time: 4.25907
Timestep Consumption Time: 0.78531
PPO Batch Consumption Time: 0.03916
Total Iteration Time: 5.04438

Cumulative Model Updates: 14,092
Cumulative Timesteps: 235,124,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.59483
Policy Entropy: 1.28946
Value Function Loss: 0.23583

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.10360

Collected Steps per Second: 11,156.17508
Overall Steps per Second: 9,444.70102

Timestep Collection Time: 4.48326
Timestep Consumption Time: 0.81241
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.29567

Cumulative Model Updates: 14,095
Cumulative Timesteps: 235,174,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 235174244...
Checkpoint 235174244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.97270
Policy Entropy: 1.29128
Value Function Loss: 0.22834

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.09028

Collected Steps per Second: 11,356.08741
Overall Steps per Second: 9,690.90073

Timestep Collection Time: 4.40398
Timestep Consumption Time: 0.75674
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 5.16072

Cumulative Model Updates: 14,098
Cumulative Timesteps: 235,224,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.40558
Policy Entropy: 1.28966
Value Function Loss: 0.24482

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.08094

Collected Steps per Second: 11,747.23576
Overall Steps per Second: 9,917.60835

Timestep Collection Time: 4.25836
Timestep Consumption Time: 0.78559
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.04396

Cumulative Model Updates: 14,101
Cumulative Timesteps: 235,274,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 235274280...
Checkpoint 235274280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.51614
Policy Entropy: 1.29369
Value Function Loss: 0.23249

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.08588

Collected Steps per Second: 11,483.86701
Overall Steps per Second: 9,744.40825

Timestep Collection Time: 4.35428
Timestep Consumption Time: 0.77728
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.13156

Cumulative Model Updates: 14,104
Cumulative Timesteps: 235,324,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.12244
Policy Entropy: 1.28901
Value Function Loss: 0.26110

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 11,846.06996
Overall Steps per Second: 10,003.16226

Timestep Collection Time: 4.22233
Timestep Consumption Time: 0.77789
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 5.00022

Cumulative Model Updates: 14,107
Cumulative Timesteps: 235,374,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 235374302...
Checkpoint 235374302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.30867
Policy Entropy: 1.29267
Value Function Loss: 0.24629

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.07556

Collected Steps per Second: 11,736.05096
Overall Steps per Second: 9,718.71889

Timestep Collection Time: 4.26191
Timestep Consumption Time: 0.88465
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 5.14656

Cumulative Model Updates: 14,110
Cumulative Timesteps: 235,424,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.68794
Policy Entropy: 1.29468
Value Function Loss: 0.24889

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.04341
Value Function Update Magnitude: 0.08529

Collected Steps per Second: 11,237.10611
Overall Steps per Second: 9,699.03059

Timestep Collection Time: 4.45026
Timestep Consumption Time: 0.70572
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.15598

Cumulative Model Updates: 14,113
Cumulative Timesteps: 235,474,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 235474328...
Checkpoint 235474328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.49120
Policy Entropy: 1.29504
Value Function Loss: 0.23619

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06737
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.08623

Collected Steps per Second: 11,677.80513
Overall Steps per Second: 9,860.98111

Timestep Collection Time: 4.28265
Timestep Consumption Time: 0.78905
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 5.07171

Cumulative Model Updates: 14,116
Cumulative Timesteps: 235,524,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.06438
Policy Entropy: 1.29323
Value Function Loss: 0.26439

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.06895
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.08131

Collected Steps per Second: 11,047.58885
Overall Steps per Second: 9,411.58748

Timestep Collection Time: 4.52877
Timestep Consumption Time: 0.78723
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.31600

Cumulative Model Updates: 14,119
Cumulative Timesteps: 235,574,372

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 235574372...
Checkpoint 235574372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.36946
Policy Entropy: 1.29020
Value Function Loss: 0.27910

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.08375

Collected Steps per Second: 11,929.27750
Overall Steps per Second: 10,268.99566

Timestep Collection Time: 4.19237
Timestep Consumption Time: 0.67782
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.87019

Cumulative Model Updates: 14,122
Cumulative Timesteps: 235,624,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.87496
Policy Entropy: 1.28964
Value Function Loss: 0.27419

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06960
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 12,081.83015
Overall Steps per Second: 10,020.25734

Timestep Collection Time: 4.13861
Timestep Consumption Time: 0.85148
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 4.99009

Cumulative Model Updates: 14,125
Cumulative Timesteps: 235,674,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 235674386...
Checkpoint 235674386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.65644
Policy Entropy: 1.29070
Value Function Loss: 0.26886

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07122
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.07432

Collected Steps per Second: 11,471.00809
Overall Steps per Second: 9,767.66160

Timestep Collection Time: 4.36108
Timestep Consumption Time: 0.76051
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.12159

Cumulative Model Updates: 14,128
Cumulative Timesteps: 235,724,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.44765
Policy Entropy: 1.28734
Value Function Loss: 0.24956

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.07318

Collected Steps per Second: 11,826.50040
Overall Steps per Second: 9,919.18389

Timestep Collection Time: 4.22965
Timestep Consumption Time: 0.81330
PPO Batch Consumption Time: 0.04413
Total Iteration Time: 5.04296

Cumulative Model Updates: 14,131
Cumulative Timesteps: 235,774,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 235774434...
Checkpoint 235774434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.84944
Policy Entropy: 1.28589
Value Function Loss: 0.25217

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 12,061.73109
Overall Steps per Second: 10,343.19334

Timestep Collection Time: 4.14584
Timestep Consumption Time: 0.68884
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 4.83468

Cumulative Model Updates: 14,134
Cumulative Timesteps: 235,824,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.64776
Policy Entropy: 1.28384
Value Function Loss: 0.24152

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.07563

Collected Steps per Second: 12,192.29587
Overall Steps per Second: 10,071.40937

Timestep Collection Time: 4.10161
Timestep Consumption Time: 0.86374
PPO Batch Consumption Time: 0.03822
Total Iteration Time: 4.96534

Cumulative Model Updates: 14,137
Cumulative Timesteps: 235,874,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 235874448...
Checkpoint 235874448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.92321
Policy Entropy: 1.28725
Value Function Loss: 0.25296

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.08244

Collected Steps per Second: 11,724.98064
Overall Steps per Second: 9,985.18072

Timestep Collection Time: 4.26628
Timestep Consumption Time: 0.74335
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.00962

Cumulative Model Updates: 14,140
Cumulative Timesteps: 235,924,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.56357
Policy Entropy: 1.28963
Value Function Loss: 0.25588

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06905
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.09264

Collected Steps per Second: 11,933.70407
Overall Steps per Second: 10,256.67568

Timestep Collection Time: 4.19132
Timestep Consumption Time: 0.68531
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 4.87663

Cumulative Model Updates: 14,143
Cumulative Timesteps: 235,974,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 235974488...
Checkpoint 235974488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.62650
Policy Entropy: 1.29115
Value Function Loss: 0.26333

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07176
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.09307

Collected Steps per Second: 11,386.85082
Overall Steps per Second: 9,614.41654

Timestep Collection Time: 4.39279
Timestep Consumption Time: 0.80982
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.20260

Cumulative Model Updates: 14,146
Cumulative Timesteps: 236,024,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.85337
Policy Entropy: 1.28916
Value Function Loss: 0.27252

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07151
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.08176

Collected Steps per Second: 11,653.52434
Overall Steps per Second: 10,081.53961

Timestep Collection Time: 4.29192
Timestep Consumption Time: 0.66923
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 4.96115

Cumulative Model Updates: 14,149
Cumulative Timesteps: 236,074,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 236074524...
Checkpoint 236074524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.60594
Policy Entropy: 1.28919
Value Function Loss: 0.27188

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06333
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.08253

Collected Steps per Second: 11,687.01900
Overall Steps per Second: 9,867.90142

Timestep Collection Time: 4.28030
Timestep Consumption Time: 0.78906
PPO Batch Consumption Time: 0.03908
Total Iteration Time: 5.06937

Cumulative Model Updates: 14,152
Cumulative Timesteps: 236,124,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.93437
Policy Entropy: 1.28489
Value Function Loss: 0.26827

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.07635

Collected Steps per Second: 11,434.48191
Overall Steps per Second: 9,725.36217

Timestep Collection Time: 4.37344
Timestep Consumption Time: 0.76858
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 5.14202

Cumulative Model Updates: 14,155
Cumulative Timesteps: 236,174,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 236174556...
Checkpoint 236174556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.32516
Policy Entropy: 1.28340
Value Function Loss: 0.27064

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06868
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.06288

Collected Steps per Second: 11,934.44675
Overall Steps per Second: 10,089.67470

Timestep Collection Time: 4.18989
Timestep Consumption Time: 0.76607
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 4.95596

Cumulative Model Updates: 14,158
Cumulative Timesteps: 236,224,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.06529
Policy Entropy: 1.28485
Value Function Loss: 0.26672

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06808
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.08467

Collected Steps per Second: 11,612.27943
Overall Steps per Second: 9,854.41418

Timestep Collection Time: 4.30665
Timestep Consumption Time: 0.76824
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.07488

Cumulative Model Updates: 14,161
Cumulative Timesteps: 236,274,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 236274570...
Checkpoint 236274570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.43118
Policy Entropy: 1.28508
Value Function Loss: 0.26640

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07331
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.09785

Collected Steps per Second: 11,416.76845
Overall Steps per Second: 9,742.54620

Timestep Collection Time: 4.37952
Timestep Consumption Time: 0.75261
PPO Batch Consumption Time: 0.03784
Total Iteration Time: 5.13213

Cumulative Model Updates: 14,164
Cumulative Timesteps: 236,324,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.97113
Policy Entropy: 1.28706
Value Function Loss: 0.25052

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07283
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.08679

Collected Steps per Second: 11,362.40699
Overall Steps per Second: 9,610.82242

Timestep Collection Time: 4.40171
Timestep Consumption Time: 0.80222
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.20393

Cumulative Model Updates: 14,167
Cumulative Timesteps: 236,374,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 236374584...
Checkpoint 236374584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.00816
Policy Entropy: 1.28628
Value Function Loss: 0.23988

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 11,439.88234
Overall Steps per Second: 9,722.03375

Timestep Collection Time: 4.37312
Timestep Consumption Time: 0.77271
PPO Batch Consumption Time: 0.05023
Total Iteration Time: 5.14584

Cumulative Model Updates: 14,170
Cumulative Timesteps: 236,424,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.98301
Policy Entropy: 1.28548
Value Function Loss: 0.22353

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07157
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.09047

Collected Steps per Second: 11,556.30946
Overall Steps per Second: 9,761.09562

Timestep Collection Time: 4.32664
Timestep Consumption Time: 0.79573
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 5.12238

Cumulative Model Updates: 14,173
Cumulative Timesteps: 236,474,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 236474612...
Checkpoint 236474612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.40079
Policy Entropy: 1.28835
Value Function Loss: 0.21031

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05863
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.07746

Collected Steps per Second: 11,553.39518
Overall Steps per Second: 9,937.18191

Timestep Collection Time: 4.33016
Timestep Consumption Time: 0.70427
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.03443

Cumulative Model Updates: 14,176
Cumulative Timesteps: 236,524,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.49531
Policy Entropy: 1.28874
Value Function Loss: 0.23381

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04088
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.06994

Collected Steps per Second: 11,540.29966
Overall Steps per Second: 9,684.67165

Timestep Collection Time: 4.33490
Timestep Consumption Time: 0.83059
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.16548

Cumulative Model Updates: 14,179
Cumulative Timesteps: 236,574,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 236574666...
Checkpoint 236574666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.81819
Policy Entropy: 1.28929
Value Function Loss: 0.24144

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04981
Policy Update Magnitude: 0.06839
Value Function Update Magnitude: 0.06388

Collected Steps per Second: 10,567.55363
Overall Steps per Second: 8,967.53094

Timestep Collection Time: 4.73392
Timestep Consumption Time: 0.84465
PPO Batch Consumption Time: 0.03814
Total Iteration Time: 5.57857

Cumulative Model Updates: 14,182
Cumulative Timesteps: 236,624,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.74185
Policy Entropy: 1.28711
Value Function Loss: 0.26308

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04752
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.09251

Collected Steps per Second: 11,544.83465
Overall Steps per Second: 9,756.31794

Timestep Collection Time: 4.33233
Timestep Consumption Time: 0.79420
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.12652

Cumulative Model Updates: 14,185
Cumulative Timesteps: 236,674,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 236674708...
Checkpoint 236674708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.75458
Policy Entropy: 1.28390
Value Function Loss: 0.24263

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05480
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.09046

Collected Steps per Second: 11,367.57019
Overall Steps per Second: 9,566.30250

Timestep Collection Time: 4.40006
Timestep Consumption Time: 0.82850
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.22856

Cumulative Model Updates: 14,188
Cumulative Timesteps: 236,724,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.12774
Policy Entropy: 1.28026
Value Function Loss: 0.22975

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06787
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.08601

Collected Steps per Second: 11,501.64060
Overall Steps per Second: 9,855.27283

Timestep Collection Time: 4.34738
Timestep Consumption Time: 0.72625
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.07363

Cumulative Model Updates: 14,191
Cumulative Timesteps: 236,774,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 236774728...
Checkpoint 236774728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.69015
Policy Entropy: 1.28504
Value Function Loss: 0.21368

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04573
Policy Update Magnitude: 0.06808
Value Function Update Magnitude: 0.08662

Collected Steps per Second: 12,644.36465
Overall Steps per Second: 10,548.75308

Timestep Collection Time: 3.95465
Timestep Consumption Time: 0.78563
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.74028

Cumulative Model Updates: 14,194
Cumulative Timesteps: 236,824,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.70608
Policy Entropy: 1.28027
Value Function Loss: 0.20071

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07192
Policy Update Magnitude: 0.06516
Value Function Update Magnitude: 0.08329

Collected Steps per Second: 12,669.81119
Overall Steps per Second: 10,588.20228

Timestep Collection Time: 3.94860
Timestep Consumption Time: 0.77628
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.72488

Cumulative Model Updates: 14,197
Cumulative Timesteps: 236,874,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 236874760...
Checkpoint 236874760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.82478
Policy Entropy: 1.28029
Value Function Loss: 0.20165

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05479
Policy Update Magnitude: 0.06993
Value Function Update Magnitude: 0.07470

Collected Steps per Second: 12,118.83122
Overall Steps per Second: 10,042.10807

Timestep Collection Time: 4.12730
Timestep Consumption Time: 0.85353
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 4.98083

Cumulative Model Updates: 14,200
Cumulative Timesteps: 236,924,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.90035
Policy Entropy: 1.28168
Value Function Loss: 0.20142

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05050
Policy Update Magnitude: 0.07769
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 12,960.20398
Overall Steps per Second: 10,678.76178

Timestep Collection Time: 3.85904
Timestep Consumption Time: 0.82446
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.68350

Cumulative Model Updates: 14,203
Cumulative Timesteps: 236,974,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 236974792...
Checkpoint 236974792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.18906
Policy Entropy: 1.28270
Value Function Loss: 0.21647

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05212
Policy Update Magnitude: 0.08311
Value Function Update Magnitude: 0.07632

Collected Steps per Second: 12,026.66413
Overall Steps per Second: 10,299.04845

Timestep Collection Time: 4.15826
Timestep Consumption Time: 0.69753
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.85579

Cumulative Model Updates: 14,206
Cumulative Timesteps: 237,024,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.43406
Policy Entropy: 1.28180
Value Function Loss: 0.21016

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04927
Policy Update Magnitude: 0.08149
Value Function Update Magnitude: 0.08728

Collected Steps per Second: 11,908.36189
Overall Steps per Second: 9,978.07771

Timestep Collection Time: 4.20075
Timestep Consumption Time: 0.81264
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.01339

Cumulative Model Updates: 14,209
Cumulative Timesteps: 237,074,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 237074826...
Checkpoint 237074826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.63197
Policy Entropy: 1.27987
Value Function Loss: 0.22477

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04768
Policy Update Magnitude: 0.08157
Value Function Update Magnitude: 0.08933

Collected Steps per Second: 11,789.90949
Overall Steps per Second: 9,977.92506

Timestep Collection Time: 4.24295
Timestep Consumption Time: 0.77052
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.01347

Cumulative Model Updates: 14,212
Cumulative Timesteps: 237,124,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.86484
Policy Entropy: 1.28385
Value Function Loss: 0.22526

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04433
Policy Update Magnitude: 0.08298
Value Function Update Magnitude: 0.08650

Collected Steps per Second: 12,021.45676
Overall Steps per Second: 10,163.70708

Timestep Collection Time: 4.16139
Timestep Consumption Time: 0.76063
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 4.92202

Cumulative Model Updates: 14,215
Cumulative Timesteps: 237,174,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 237174876...
Checkpoint 237174876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.29906
Policy Entropy: 1.27628
Value Function Loss: 0.23116

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.05090
Policy Update Magnitude: 0.08804
Value Function Update Magnitude: 0.09143

Collected Steps per Second: 11,080.60511
Overall Steps per Second: 9,488.17715

Timestep Collection Time: 4.51419
Timestep Consumption Time: 0.75763
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.27182

Cumulative Model Updates: 14,218
Cumulative Timesteps: 237,224,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.30393
Policy Entropy: 1.27690
Value Function Loss: 0.22447

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04521
Policy Update Magnitude: 0.09696
Value Function Update Magnitude: 0.08732

Collected Steps per Second: 12,127.37442
Overall Steps per Second: 10,342.86184

Timestep Collection Time: 4.12538
Timestep Consumption Time: 0.71177
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 4.83715

Cumulative Model Updates: 14,221
Cumulative Timesteps: 237,274,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 237274926...
Checkpoint 237274926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.01801
Policy Entropy: 1.27502
Value Function Loss: 0.23004

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04893
Policy Update Magnitude: 0.09499
Value Function Update Magnitude: 0.08066

Collected Steps per Second: 11,777.07427
Overall Steps per Second: 9,802.32674

Timestep Collection Time: 4.24622
Timestep Consumption Time: 0.85543
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 5.10165

Cumulative Model Updates: 14,224
Cumulative Timesteps: 237,324,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.57242
Policy Entropy: 1.27991
Value Function Loss: 0.22788

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03077
Policy Update Magnitude: 0.09539
Value Function Update Magnitude: 0.08901

Collected Steps per Second: 11,597.83241
Overall Steps per Second: 9,832.38969

Timestep Collection Time: 4.31184
Timestep Consumption Time: 0.77421
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.08605

Cumulative Model Updates: 14,227
Cumulative Timesteps: 237,374,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 237374942...
Checkpoint 237374942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.67019
Policy Entropy: 1.27460
Value Function Loss: 0.21728

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05447
Policy Update Magnitude: 0.09889
Value Function Update Magnitude: 0.09768

Collected Steps per Second: 11,816.12203
Overall Steps per Second: 9,918.90248

Timestep Collection Time: 4.23252
Timestep Consumption Time: 0.80957
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.04209

Cumulative Model Updates: 14,230
Cumulative Timesteps: 237,424,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.20851
Policy Entropy: 1.27410
Value Function Loss: 0.20572

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.09088
Value Function Update Magnitude: 0.08541

Collected Steps per Second: 11,798.97533
Overall Steps per Second: 10,067.92944

Timestep Collection Time: 4.23986
Timestep Consumption Time: 0.72899
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 4.96885

Cumulative Model Updates: 14,233
Cumulative Timesteps: 237,474,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 237474980...
Checkpoint 237474980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.17464
Policy Entropy: 1.27515
Value Function Loss: 0.19414

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.06811
Policy Update Magnitude: 0.07971
Value Function Update Magnitude: 0.07806

Collected Steps per Second: 11,129.77401
Overall Steps per Second: 9,698.54557

Timestep Collection Time: 4.49263
Timestep Consumption Time: 0.66298
PPO Batch Consumption Time: 0.03333
Total Iteration Time: 5.15562

Cumulative Model Updates: 14,236
Cumulative Timesteps: 237,524,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.83376
Policy Entropy: 1.27476
Value Function Loss: 0.20430

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05517
Policy Update Magnitude: 0.08257
Value Function Update Magnitude: 0.09326

Collected Steps per Second: 10,723.81690
Overall Steps per Second: 9,212.53105

Timestep Collection Time: 4.66326
Timestep Consumption Time: 0.76499
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 5.42826

Cumulative Model Updates: 14,239
Cumulative Timesteps: 237,574,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 237574990...
Checkpoint 237574990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.21713
Policy Entropy: 1.27711
Value Function Loss: 0.19573

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05681
Policy Update Magnitude: 0.07714
Value Function Update Magnitude: 0.10119

Collected Steps per Second: 11,681.49242
Overall Steps per Second: 9,912.53729

Timestep Collection Time: 4.28182
Timestep Consumption Time: 0.76412
PPO Batch Consumption Time: 0.04392
Total Iteration Time: 5.04593

Cumulative Model Updates: 14,242
Cumulative Timesteps: 237,625,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.42934
Policy Entropy: 1.27599
Value Function Loss: 0.19864

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04696
Policy Update Magnitude: 0.07900
Value Function Update Magnitude: 0.09855

Collected Steps per Second: 11,492.14716
Overall Steps per Second: 9,716.87812

Timestep Collection Time: 4.35323
Timestep Consumption Time: 0.79533
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 5.14857

Cumulative Model Updates: 14,245
Cumulative Timesteps: 237,675,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 237675036...
Checkpoint 237675036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.94617
Policy Entropy: 1.27245
Value Function Loss: 0.18692

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06086
Policy Update Magnitude: 0.08813
Value Function Update Magnitude: 0.09470

Collected Steps per Second: 11,423.35324
Overall Steps per Second: 9,708.16823

Timestep Collection Time: 4.37875
Timestep Consumption Time: 0.77361
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 5.15236

Cumulative Model Updates: 14,248
Cumulative Timesteps: 237,725,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.38265
Policy Entropy: 1.27318
Value Function Loss: 0.18577

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.07930
Value Function Update Magnitude: 0.09823

Collected Steps per Second: 11,434.54175
Overall Steps per Second: 9,923.61231

Timestep Collection Time: 4.37516
Timestep Consumption Time: 0.66614
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.04131

Cumulative Model Updates: 14,251
Cumulative Timesteps: 237,775,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 237775084...
Checkpoint 237775084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.15929
Policy Entropy: 1.27568
Value Function Loss: 0.19720

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06148
Policy Update Magnitude: 0.07765
Value Function Update Magnitude: 0.10607

Collected Steps per Second: 10,819.72098
Overall Steps per Second: 9,216.58816

Timestep Collection Time: 4.62175
Timestep Consumption Time: 0.80391
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 5.42565

Cumulative Model Updates: 14,254
Cumulative Timesteps: 237,825,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.39692
Policy Entropy: 1.27628
Value Function Loss: 0.20206

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06928
Policy Update Magnitude: 0.07466
Value Function Update Magnitude: 0.11059

Collected Steps per Second: 11,356.54639
Overall Steps per Second: 9,708.82302

Timestep Collection Time: 4.40539
Timestep Consumption Time: 0.74766
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 5.15304

Cumulative Model Updates: 14,257
Cumulative Timesteps: 237,875,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 237875120...
Checkpoint 237875120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.57029
Policy Entropy: 1.27627
Value Function Loss: 0.18848

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.06080
Policy Update Magnitude: 0.07586
Value Function Update Magnitude: 0.11446

Collected Steps per Second: 11,663.29426
Overall Steps per Second: 9,856.23007

Timestep Collection Time: 4.28764
Timestep Consumption Time: 0.78611
PPO Batch Consumption Time: 0.03789
Total Iteration Time: 5.07375

Cumulative Model Updates: 14,260
Cumulative Timesteps: 237,925,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.03335
Policy Entropy: 1.27985
Value Function Loss: 0.16874

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04505
Policy Update Magnitude: 0.08077
Value Function Update Magnitude: 0.10285

Collected Steps per Second: 11,558.75960
Overall Steps per Second: 9,790.03951

Timestep Collection Time: 4.32711
Timestep Consumption Time: 0.78176
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.10887

Cumulative Model Updates: 14,263
Cumulative Timesteps: 237,975,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 237975144...
Checkpoint 237975144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.01543
Policy Entropy: 1.28097
Value Function Loss: 0.17755

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05131
Policy Update Magnitude: 0.07745
Value Function Update Magnitude: 0.08184

Collected Steps per Second: 11,864.69108
Overall Steps per Second: 10,188.24931

Timestep Collection Time: 4.21435
Timestep Consumption Time: 0.69346
PPO Batch Consumption Time: 0.03326
Total Iteration Time: 4.90781

Cumulative Model Updates: 14,266
Cumulative Timesteps: 238,025,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.01554
Policy Entropy: 1.27983
Value Function Loss: 0.19949

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05508
Policy Update Magnitude: 0.08455
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 11,926.70229
Overall Steps per Second: 9,946.06048

Timestep Collection Time: 4.19362
Timestep Consumption Time: 0.83511
PPO Batch Consumption Time: 0.04039
Total Iteration Time: 5.02872

Cumulative Model Updates: 14,269
Cumulative Timesteps: 238,075,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 238075162...
Checkpoint 238075162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.63947
Policy Entropy: 1.28408
Value Function Loss: 0.23233

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.08932
Value Function Update Magnitude: 0.06460

Collected Steps per Second: 11,396.18093
Overall Steps per Second: 9,666.80445

Timestep Collection Time: 4.38937
Timestep Consumption Time: 0.78525
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.17462

Cumulative Model Updates: 14,272
Cumulative Timesteps: 238,125,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.97911
Policy Entropy: 1.28677
Value Function Loss: 0.23192

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06116
Policy Update Magnitude: 0.08863
Value Function Update Magnitude: 0.06852

Collected Steps per Second: 12,338.39099
Overall Steps per Second: 10,277.98749

Timestep Collection Time: 4.05418
Timestep Consumption Time: 0.81273
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.86691

Cumulative Model Updates: 14,275
Cumulative Timesteps: 238,175,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 238175206...
Checkpoint 238175206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.05797
Policy Entropy: 1.27960
Value Function Loss: 0.23822

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06533
Policy Update Magnitude: 0.09199
Value Function Update Magnitude: 0.08676

Collected Steps per Second: 11,957.73572
Overall Steps per Second: 9,799.24117

Timestep Collection Time: 4.18190
Timestep Consumption Time: 0.92115
PPO Batch Consumption Time: 0.03819
Total Iteration Time: 5.10305

Cumulative Model Updates: 14,278
Cumulative Timesteps: 238,225,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.69462
Policy Entropy: 1.28676
Value Function Loss: 0.24459

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.08556
Value Function Update Magnitude: 0.09036

Collected Steps per Second: 12,119.59287
Overall Steps per Second: 10,432.07469

Timestep Collection Time: 4.12687
Timestep Consumption Time: 0.66757
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.79444

Cumulative Model Updates: 14,281
Cumulative Timesteps: 238,275,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 238275228...
Checkpoint 238275228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.96133
Policy Entropy: 1.28339
Value Function Loss: 0.22750

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05671
Policy Update Magnitude: 0.08883
Value Function Update Magnitude: 0.10133

Collected Steps per Second: 11,951.56903
Overall Steps per Second: 10,080.92351

Timestep Collection Time: 4.18506
Timestep Consumption Time: 0.77659
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 4.96165

Cumulative Model Updates: 14,284
Cumulative Timesteps: 238,325,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.61196
Policy Entropy: 1.28151
Value Function Loss: 0.22899

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04243
Policy Update Magnitude: 0.09142
Value Function Update Magnitude: 0.10311

Collected Steps per Second: 11,509.66816
Overall Steps per Second: 9,654.69731

Timestep Collection Time: 4.34626
Timestep Consumption Time: 0.83505
PPO Batch Consumption Time: 0.04044
Total Iteration Time: 5.18131

Cumulative Model Updates: 14,287
Cumulative Timesteps: 238,375,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 238375270...
Checkpoint 238375270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.51612
Policy Entropy: 1.28047
Value Function Loss: 0.20503

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04728
Policy Update Magnitude: 0.09297
Value Function Update Magnitude: 0.10199

Collected Steps per Second: 11,645.92132
Overall Steps per Second: 9,854.99595

Timestep Collection Time: 4.29335
Timestep Consumption Time: 0.78022
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.07357

Cumulative Model Updates: 14,290
Cumulative Timesteps: 238,425,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.30222
Policy Entropy: 1.28325
Value Function Loss: 0.21315

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.08481
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 11,755.59796
Overall Steps per Second: 9,796.86918

Timestep Collection Time: 4.25550
Timestep Consumption Time: 0.85082
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 5.10633

Cumulative Model Updates: 14,293
Cumulative Timesteps: 238,475,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 238475296...
Checkpoint 238475296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.83791
Policy Entropy: 1.27653
Value Function Loss: 0.20056

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06707
Policy Update Magnitude: 0.07780
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 11,664.74578
Overall Steps per Second: 10,011.15638

Timestep Collection Time: 4.28813
Timestep Consumption Time: 0.70829
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 4.99643

Cumulative Model Updates: 14,296
Cumulative Timesteps: 238,525,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.58462
Policy Entropy: 1.28563
Value Function Loss: 0.19461

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04198
Policy Update Magnitude: 0.07698
Value Function Update Magnitude: 0.08095

Collected Steps per Second: 11,590.66101
Overall Steps per Second: 9,855.03725

Timestep Collection Time: 4.31572
Timestep Consumption Time: 0.76006
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.07578

Cumulative Model Updates: 14,299
Cumulative Timesteps: 238,575,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 238575338...
Checkpoint 238575338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.66070
Policy Entropy: 1.28626
Value Function Loss: 0.17955

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05841
Policy Update Magnitude: 0.08110
Value Function Update Magnitude: 0.08276

Collected Steps per Second: 11,498.58828
Overall Steps per Second: 9,779.36307

Timestep Collection Time: 4.35097
Timestep Consumption Time: 0.76491
PPO Batch Consumption Time: 0.03984
Total Iteration Time: 5.11588

Cumulative Model Updates: 14,302
Cumulative Timesteps: 238,625,368

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.47638
Policy Entropy: 1.28368
Value Function Loss: 0.19745

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06509
Policy Update Magnitude: 0.08096
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 11,456.95350
Overall Steps per Second: 9,639.99522

Timestep Collection Time: 4.36678
Timestep Consumption Time: 0.82306
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.18984

Cumulative Model Updates: 14,305
Cumulative Timesteps: 238,675,398

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 238675398...
Checkpoint 238675398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.02371
Policy Entropy: 1.28596
Value Function Loss: 0.20760

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.07991
Value Function Update Magnitude: 0.06478

Collected Steps per Second: 11,219.78810
Overall Steps per Second: 9,535.47576

Timestep Collection Time: 4.45784
Timestep Consumption Time: 0.78742
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 5.24525

Cumulative Model Updates: 14,308
Cumulative Timesteps: 238,725,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.21381
Policy Entropy: 1.29000
Value Function Loss: 0.23700

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.05730
Policy Update Magnitude: 0.07608
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 11,643.64703
Overall Steps per Second: 10,051.46563

Timestep Collection Time: 4.29522
Timestep Consumption Time: 0.68038
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 4.97559

Cumulative Model Updates: 14,311
Cumulative Timesteps: 238,775,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 238775426...
Checkpoint 238775426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.36228
Policy Entropy: 1.28733
Value Function Loss: 0.22801

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05728
Policy Update Magnitude: 0.07622
Value Function Update Magnitude: 0.10167

Collected Steps per Second: 11,229.02447
Overall Steps per Second: 9,473.55746

Timestep Collection Time: 4.45542
Timestep Consumption Time: 0.82560
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 5.28102

Cumulative Model Updates: 14,314
Cumulative Timesteps: 238,825,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.19785
Policy Entropy: 1.28261
Value Function Loss: 0.23306

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06543
Policy Update Magnitude: 0.07916
Value Function Update Magnitude: 0.11010

Collected Steps per Second: 11,521.28461
Overall Steps per Second: 9,839.14290

Timestep Collection Time: 4.34066
Timestep Consumption Time: 0.74210
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.08276

Cumulative Model Updates: 14,317
Cumulative Timesteps: 238,875,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 238875466...
Checkpoint 238875466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.10900
Policy Entropy: 1.28168
Value Function Loss: 0.22262

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.06023
Policy Update Magnitude: 0.07622
Value Function Update Magnitude: 0.09267

Collected Steps per Second: 11,608.38714
Overall Steps per Second: 9,826.64578

Timestep Collection Time: 4.30844
Timestep Consumption Time: 0.78119
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.08963

Cumulative Model Updates: 14,320
Cumulative Timesteps: 238,925,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.02172
Policy Entropy: 1.28063
Value Function Loss: 0.25299

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07058
Policy Update Magnitude: 0.07860
Value Function Update Magnitude: 0.08973

Collected Steps per Second: 10,945.75235
Overall Steps per Second: 9,348.28329

Timestep Collection Time: 4.56963
Timestep Consumption Time: 0.78087
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 5.35050

Cumulative Model Updates: 14,323
Cumulative Timesteps: 238,975,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 238975498...
Checkpoint 238975498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.71447
Policy Entropy: 1.28459
Value Function Loss: 0.26852

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06129
Policy Update Magnitude: 0.07458
Value Function Update Magnitude: 0.08650

Collected Steps per Second: 11,610.24101
Overall Steps per Second: 9,937.96374

Timestep Collection Time: 4.30706
Timestep Consumption Time: 0.72476
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.03182

Cumulative Model Updates: 14,326
Cumulative Timesteps: 239,025,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.58139
Policy Entropy: 1.28467
Value Function Loss: 0.25188

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06831
Policy Update Magnitude: 0.07149
Value Function Update Magnitude: 0.08469

Collected Steps per Second: 11,474.50878
Overall Steps per Second: 9,611.64793

Timestep Collection Time: 4.36010
Timestep Consumption Time: 0.84504
PPO Batch Consumption Time: 0.03785
Total Iteration Time: 5.20514

Cumulative Model Updates: 14,329
Cumulative Timesteps: 239,075,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 239075534...
Checkpoint 239075534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.60429
Policy Entropy: 1.28219
Value Function Loss: 0.22004

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05369
Policy Update Magnitude: 0.07541
Value Function Update Magnitude: 0.07305

Collected Steps per Second: 11,347.74839
Overall Steps per Second: 9,531.41745

Timestep Collection Time: 4.40792
Timestep Consumption Time: 0.83998
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.24791

Cumulative Model Updates: 14,332
Cumulative Timesteps: 239,125,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.79672
Policy Entropy: 1.28662
Value Function Loss: 0.18880

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.08242
Value Function Update Magnitude: 0.07411

Collected Steps per Second: 12,243.40210
Overall Steps per Second: 10,255.23874

Timestep Collection Time: 4.08530
Timestep Consumption Time: 0.79201
PPO Batch Consumption Time: 0.03329
Total Iteration Time: 4.87731

Cumulative Model Updates: 14,335
Cumulative Timesteps: 239,175,572

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 239175572...
Checkpoint 239175572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.30331
Policy Entropy: 1.28969
Value Function Loss: 0.19175

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04839
Policy Update Magnitude: 0.07863
Value Function Update Magnitude: 0.06777

Collected Steps per Second: 12,491.20276
Overall Steps per Second: 10,390.22679

Timestep Collection Time: 4.00282
Timestep Consumption Time: 0.80940
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.81221

Cumulative Model Updates: 14,338
Cumulative Timesteps: 239,225,572

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.97654
Policy Entropy: 1.28870
Value Function Loss: 0.20013

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05059
Policy Update Magnitude: 0.07612
Value Function Update Magnitude: 0.06136

Collected Steps per Second: 11,780.74113
Overall Steps per Second: 10,123.50346

Timestep Collection Time: 4.24557
Timestep Consumption Time: 0.69501
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 4.94058

Cumulative Model Updates: 14,341
Cumulative Timesteps: 239,275,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 239275588...
Checkpoint 239275588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.10927
Policy Entropy: 1.29150
Value Function Loss: 0.21821

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07301
Policy Update Magnitude: 0.07601
Value Function Update Magnitude: 0.05481

Collected Steps per Second: 12,364.44814
Overall Steps per Second: 10,235.31863

Timestep Collection Time: 4.04644
Timestep Consumption Time: 0.84173
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 4.88817

Cumulative Model Updates: 14,344
Cumulative Timesteps: 239,325,620

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.00189
Policy Entropy: 1.29039
Value Function Loss: 0.22222

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06119
Policy Update Magnitude: 0.07241
Value Function Update Magnitude: 0.06886

Collected Steps per Second: 12,713.66695
Overall Steps per Second: 10,542.17087

Timestep Collection Time: 3.93325
Timestep Consumption Time: 0.81018
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 4.74343

Cumulative Model Updates: 14,347
Cumulative Timesteps: 239,375,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 239375626...
Checkpoint 239375626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.23400
Policy Entropy: 1.28645
Value Function Loss: 0.21904

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06526
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.07056

Collected Steps per Second: 12,661.29248
Overall Steps per Second: 10,748.84717

Timestep Collection Time: 3.95157
Timestep Consumption Time: 0.70307
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.65464

Cumulative Model Updates: 14,350
Cumulative Timesteps: 239,425,658

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.92536
Policy Entropy: 1.28759
Value Function Loss: 0.20434

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04594
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.06592

Collected Steps per Second: 12,012.10262
Overall Steps per Second: 10,107.91343

Timestep Collection Time: 4.16264
Timestep Consumption Time: 0.78418
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 4.94682

Cumulative Model Updates: 14,353
Cumulative Timesteps: 239,475,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 239475660...
Checkpoint 239475660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.36482
Policy Entropy: 1.28736
Value Function Loss: 0.19386

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04430
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.06002

Collected Steps per Second: 11,795.43058
Overall Steps per Second: 9,910.04902

Timestep Collection Time: 4.23978
Timestep Consumption Time: 0.80662
PPO Batch Consumption Time: 0.03780
Total Iteration Time: 5.04639

Cumulative Model Updates: 14,356
Cumulative Timesteps: 239,525,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.20729
Policy Entropy: 1.28498
Value Function Loss: 0.17290

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04955
Policy Update Magnitude: 0.06938
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 11,666.65711
Overall Steps per Second: 9,840.04169

Timestep Collection Time: 4.28812
Timestep Consumption Time: 0.79601
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.08412

Cumulative Model Updates: 14,359
Cumulative Timesteps: 239,575,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 239575698...
Checkpoint 239575698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.89082
Policy Entropy: 1.29348
Value Function Loss: 0.19024

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06166
Policy Update Magnitude: 0.06503
Value Function Update Magnitude: 0.08158

Collected Steps per Second: 11,826.64236
Overall Steps per Second: 9,941.60144

Timestep Collection Time: 4.22910
Timestep Consumption Time: 0.80188
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.03098

Cumulative Model Updates: 14,362
Cumulative Timesteps: 239,625,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.17913
Policy Entropy: 1.28951
Value Function Loss: 0.19064

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06749
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.07764

Collected Steps per Second: 11,588.20281
Overall Steps per Second: 9,884.82148

Timestep Collection Time: 4.31646
Timestep Consumption Time: 0.74382
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.06028

Cumulative Model Updates: 14,365
Cumulative Timesteps: 239,675,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 239675734...
Checkpoint 239675734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.59546
Policy Entropy: 1.29266
Value Function Loss: 0.20507

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05617
Policy Update Magnitude: 0.06667
Value Function Update Magnitude: 0.06450

Collected Steps per Second: 11,580.58638
Overall Steps per Second: 9,741.85297

Timestep Collection Time: 4.31999
Timestep Consumption Time: 0.81538
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.13537

Cumulative Model Updates: 14,368
Cumulative Timesteps: 239,725,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.07723
Policy Entropy: 1.28806
Value Function Loss: 0.19583

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05189
Policy Update Magnitude: 0.06478
Value Function Update Magnitude: 0.06238

Collected Steps per Second: 11,727.25035
Overall Steps per Second: 10,006.75348

Timestep Collection Time: 4.26426
Timestep Consumption Time: 0.73317
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 4.99742

Cumulative Model Updates: 14,371
Cumulative Timesteps: 239,775,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 239775770...
Checkpoint 239775770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.75791
Policy Entropy: 1.28541
Value Function Loss: 0.18926

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05772
Policy Update Magnitude: 0.06651
Value Function Update Magnitude: 0.06598

Collected Steps per Second: 11,712.61632
Overall Steps per Second: 9,926.12715

Timestep Collection Time: 4.27061
Timestep Consumption Time: 0.76862
PPO Batch Consumption Time: 0.03751
Total Iteration Time: 5.03923

Cumulative Model Updates: 14,374
Cumulative Timesteps: 239,825,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.08532
Policy Entropy: 1.28315
Value Function Loss: 0.19786

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04340
Policy Update Magnitude: 0.06950
Value Function Update Magnitude: 0.08284

Collected Steps per Second: 10,962.35299
Overall Steps per Second: 9,352.05989

Timestep Collection Time: 4.56198
Timestep Consumption Time: 0.78551
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 5.34749

Cumulative Model Updates: 14,377
Cumulative Timesteps: 239,875,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 239875800...
Checkpoint 239875800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.89648
Policy Entropy: 1.28634
Value Function Loss: 0.19528

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03625
Policy Update Magnitude: 0.07571
Value Function Update Magnitude: 0.07869

Collected Steps per Second: 11,590.60545
Overall Steps per Second: 10,001.59330

Timestep Collection Time: 4.31643
Timestep Consumption Time: 0.68578
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.00220

Cumulative Model Updates: 14,380
Cumulative Timesteps: 239,925,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.00910
Policy Entropy: 1.28387
Value Function Loss: 0.19182

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04018
Policy Update Magnitude: 0.07836
Value Function Update Magnitude: 0.08392

Collected Steps per Second: 11,784.98524
Overall Steps per Second: 9,996.20472

Timestep Collection Time: 4.24523
Timestep Consumption Time: 0.75967
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.00490

Cumulative Model Updates: 14,383
Cumulative Timesteps: 239,975,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 239975860...
Checkpoint 239975860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.54861
Policy Entropy: 1.28629
Value Function Loss: 0.18170

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04726
Policy Update Magnitude: 0.07835
Value Function Update Magnitude: 0.09279

Collected Steps per Second: 11,604.63091
Overall Steps per Second: 9,893.87169

Timestep Collection Time: 4.30880
Timestep Consumption Time: 0.74504
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.05384

Cumulative Model Updates: 14,386
Cumulative Timesteps: 240,025,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.27439
Policy Entropy: 1.28716
Value Function Loss: 0.21018

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04205
Policy Update Magnitude: 0.07608
Value Function Update Magnitude: 0.09018

Collected Steps per Second: 11,576.13855
Overall Steps per Second: 9,958.05881

Timestep Collection Time: 4.32078
Timestep Consumption Time: 0.70208
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.02287

Cumulative Model Updates: 14,389
Cumulative Timesteps: 240,075,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 240075880...
Checkpoint 240075880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.18299
Policy Entropy: 1.28796
Value Function Loss: 0.22980

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04315
Policy Update Magnitude: 0.07479
Value Function Update Magnitude: 0.08335

Collected Steps per Second: 11,261.53986
Overall Steps per Second: 9,525.96163

Timestep Collection Time: 4.44220
Timestep Consumption Time: 0.80934
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 5.25154

Cumulative Model Updates: 14,392
Cumulative Timesteps: 240,125,906

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.78490
Policy Entropy: 1.28768
Value Function Loss: 0.22200

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.07093
Value Function Update Magnitude: 0.09450

Collected Steps per Second: 10,821.98078
Overall Steps per Second: 9,296.28720

Timestep Collection Time: 4.62060
Timestep Consumption Time: 0.75833
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.37892

Cumulative Model Updates: 14,395
Cumulative Timesteps: 240,175,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 240175910...
Checkpoint 240175910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.82151
Policy Entropy: 1.28934
Value Function Loss: 0.19493

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04125
Policy Update Magnitude: 0.07065
Value Function Update Magnitude: 0.08461

Collected Steps per Second: 11,478.66204
Overall Steps per Second: 9,670.74575

Timestep Collection Time: 4.35608
Timestep Consumption Time: 0.81436
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.17044

Cumulative Model Updates: 14,398
Cumulative Timesteps: 240,225,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.69304
Policy Entropy: 1.28741
Value Function Loss: 0.21017

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 0.07201
Value Function Update Magnitude: 0.06570

Collected Steps per Second: 11,497.70137
Overall Steps per Second: 9,592.04721

Timestep Collection Time: 4.34939
Timestep Consumption Time: 0.86409
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.21349

Cumulative Model Updates: 14,401
Cumulative Timesteps: 240,275,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 240275920...
Checkpoint 240275920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.03602
Policy Entropy: 1.28672
Value Function Loss: 0.20950

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03133
Policy Update Magnitude: 0.07299
Value Function Update Magnitude: 0.05419

Collected Steps per Second: 11,292.27371
Overall Steps per Second: 9,745.99569

Timestep Collection Time: 4.42869
Timestep Consumption Time: 0.70265
PPO Batch Consumption Time: 0.03953
Total Iteration Time: 5.13134

Cumulative Model Updates: 14,404
Cumulative Timesteps: 240,325,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.02097
Policy Entropy: 1.28974
Value Function Loss: 0.21329

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03470
Policy Update Magnitude: 0.07121
Value Function Update Magnitude: 0.05920

Collected Steps per Second: 11,970.02005
Overall Steps per Second: 10,106.66412

Timestep Collection Time: 4.17861
Timestep Consumption Time: 0.77041
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 4.94901

Cumulative Model Updates: 14,407
Cumulative Timesteps: 240,375,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 240375948...
Checkpoint 240375948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.32445
Policy Entropy: 1.29059
Value Function Loss: 0.20171

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03061
Policy Update Magnitude: 0.07198
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 11,664.22447
Overall Steps per Second: 9,954.28248

Timestep Collection Time: 4.28713
Timestep Consumption Time: 0.73644
PPO Batch Consumption Time: 0.03325
Total Iteration Time: 5.02357

Cumulative Model Updates: 14,410
Cumulative Timesteps: 240,425,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.64826
Policy Entropy: 1.29352
Value Function Loss: 0.20663

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03413
Policy Update Magnitude: 0.07384
Value Function Update Magnitude: 0.05708

Collected Steps per Second: 11,341.38124
Overall Steps per Second: 9,791.11441

Timestep Collection Time: 4.41022
Timestep Consumption Time: 0.69829
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.10851

Cumulative Model Updates: 14,413
Cumulative Timesteps: 240,475,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 240475972...
Checkpoint 240475972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.33992
Policy Entropy: 1.28892
Value Function Loss: 0.22379

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05669
Policy Update Magnitude: 0.07198
Value Function Update Magnitude: 0.06451

Collected Steps per Second: 11,391.58156
Overall Steps per Second: 9,702.36872

Timestep Collection Time: 4.38956
Timestep Consumption Time: 0.76424
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.15379

Cumulative Model Updates: 14,416
Cumulative Timesteps: 240,525,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.23059
Policy Entropy: 1.28732
Value Function Loss: 0.23024

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06079
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.06218

Collected Steps per Second: 11,846.13319
Overall Steps per Second: 9,940.99267

Timestep Collection Time: 4.22197
Timestep Consumption Time: 0.80912
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.03109

Cumulative Model Updates: 14,419
Cumulative Timesteps: 240,575,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 240575990...
Checkpoint 240575990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.96586
Policy Entropy: 1.28159
Value Function Loss: 0.22263

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05577
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.05571

Collected Steps per Second: 12,115.35874
Overall Steps per Second: 10,086.30015

Timestep Collection Time: 4.12732
Timestep Consumption Time: 0.83029
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 4.95762

Cumulative Model Updates: 14,422
Cumulative Timesteps: 240,625,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.85779
Policy Entropy: 1.28742
Value Function Loss: 0.20547

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06843
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.05697

Collected Steps per Second: 11,901.61031
Overall Steps per Second: 9,972.92653

Timestep Collection Time: 4.20195
Timestep Consumption Time: 0.81262
PPO Batch Consumption Time: 0.04553
Total Iteration Time: 5.01458

Cumulative Model Updates: 14,425
Cumulative Timesteps: 240,676,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 240676004...
Checkpoint 240676004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.36817
Policy Entropy: 1.28173
Value Function Loss: 0.19057

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.05606

Collected Steps per Second: 11,981.26874
Overall Steps per Second: 10,207.05576

Timestep Collection Time: 4.17535
Timestep Consumption Time: 0.72577
PPO Batch Consumption Time: 0.03812
Total Iteration Time: 4.90112

Cumulative Model Updates: 14,428
Cumulative Timesteps: 240,726,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.84929
Policy Entropy: 1.29129
Value Function Loss: 0.19206

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.04843

Collected Steps per Second: 11,295.51987
Overall Steps per Second: 9,587.78377

Timestep Collection Time: 4.42724
Timestep Consumption Time: 0.78856
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.21580

Cumulative Model Updates: 14,431
Cumulative Timesteps: 240,776,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 240776038...
Checkpoint 240776038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.38276
Policy Entropy: 1.29295
Value Function Loss: 0.18822

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07199
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.06259

Collected Steps per Second: 11,890.01032
Overall Steps per Second: 10,034.85860

Timestep Collection Time: 4.20689
Timestep Consumption Time: 0.77773
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 4.98462

Cumulative Model Updates: 14,434
Cumulative Timesteps: 240,826,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.57180
Policy Entropy: 1.29158
Value Function Loss: 0.19994

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07082
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.06988

Collected Steps per Second: 11,722.17389
Overall Steps per Second: 10,042.24670

Timestep Collection Time: 4.26713
Timestep Consumption Time: 0.71383
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 4.98096

Cumulative Model Updates: 14,437
Cumulative Timesteps: 240,876,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 240876078...
Checkpoint 240876078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.19995
Policy Entropy: 1.29223
Value Function Loss: 0.19658

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05627
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.06794

Collected Steps per Second: 11,498.29350
Overall Steps per Second: 9,729.88412

Timestep Collection Time: 4.34865
Timestep Consumption Time: 0.79037
PPO Batch Consumption Time: 0.03852
Total Iteration Time: 5.13901

Cumulative Model Updates: 14,440
Cumulative Timesteps: 240,926,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.90003
Policy Entropy: 1.29416
Value Function Loss: 0.20715

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.06147

Collected Steps per Second: 11,809.72446
Overall Steps per Second: 10,041.02168

Timestep Collection Time: 4.23532
Timestep Consumption Time: 0.74604
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 4.98137

Cumulative Model Updates: 14,443
Cumulative Timesteps: 240,976,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 240976098...
Checkpoint 240976098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.19327
Policy Entropy: 1.29225
Value Function Loss: 0.19421

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.05856

Collected Steps per Second: 11,657.93572
Overall Steps per Second: 9,882.82368

Timestep Collection Time: 4.29081
Timestep Consumption Time: 0.77070
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.06151

Cumulative Model Updates: 14,446
Cumulative Timesteps: 241,026,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.65551
Policy Entropy: 1.29436
Value Function Loss: 0.20075

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06567
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.07618

Collected Steps per Second: 10,813.70796
Overall Steps per Second: 9,250.69637

Timestep Collection Time: 4.62487
Timestep Consumption Time: 0.78143
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 5.40630

Cumulative Model Updates: 14,449
Cumulative Timesteps: 241,076,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 241076132...
Checkpoint 241076132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.85369
Policy Entropy: 1.29508
Value Function Loss: 0.19475

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05197
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.08289

Collected Steps per Second: 11,695.91628
Overall Steps per Second: 10,087.05359

Timestep Collection Time: 4.27534
Timestep Consumption Time: 0.68191
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.95725

Cumulative Model Updates: 14,452
Cumulative Timesteps: 241,126,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.57004
Policy Entropy: 1.29180
Value Function Loss: 0.19502

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04781
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.08380

Collected Steps per Second: 11,730.66775
Overall Steps per Second: 9,879.32043

Timestep Collection Time: 4.26370
Timestep Consumption Time: 0.79900
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.06270

Cumulative Model Updates: 14,455
Cumulative Timesteps: 241,176,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 241176152...
Checkpoint 241176152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.75891
Policy Entropy: 1.29006
Value Function Loss: 0.18492

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05605
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.08231

Collected Steps per Second: 11,492.66476
Overall Steps per Second: 9,749.76152

Timestep Collection Time: 4.35130
Timestep Consumption Time: 0.77785
PPO Batch Consumption Time: 0.03342
Total Iteration Time: 5.12915

Cumulative Model Updates: 14,458
Cumulative Timesteps: 241,226,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.34006
Policy Entropy: 1.29299
Value Function Loss: 0.17863

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04995
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.06881

Collected Steps per Second: 11,451.75170
Overall Steps per Second: 9,844.30617

Timestep Collection Time: 4.36667
Timestep Consumption Time: 0.71302
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.07969

Cumulative Model Updates: 14,461
Cumulative Timesteps: 241,276,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 241276166...
Checkpoint 241276166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.85963
Policy Entropy: 1.28903
Value Function Loss: 0.17479

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.08853

Collected Steps per Second: 11,408.96860
Overall Steps per Second: 9,374.09716

Timestep Collection Time: 4.38252
Timestep Consumption Time: 0.95133
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 5.33385

Cumulative Model Updates: 14,464
Cumulative Timesteps: 241,326,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.12900
Policy Entropy: 1.29049
Value Function Loss: 0.19617

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.08891

Collected Steps per Second: 11,374.32998
Overall Steps per Second: 9,763.52175

Timestep Collection Time: 4.39727
Timestep Consumption Time: 0.72547
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.12274

Cumulative Model Updates: 14,467
Cumulative Timesteps: 241,376,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 241376182...
Checkpoint 241376182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.17514
Policy Entropy: 1.28820
Value Function Loss: 0.20151

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04671
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.08655

Collected Steps per Second: 11,652.74774
Overall Steps per Second: 9,817.63517

Timestep Collection Time: 4.29255
Timestep Consumption Time: 0.80236
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.09491

Cumulative Model Updates: 14,470
Cumulative Timesteps: 241,426,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.91174
Policy Entropy: 1.28985
Value Function Loss: 0.21352

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.06951
Value Function Update Magnitude: 0.08017

Collected Steps per Second: 11,664.72538
Overall Steps per Second: 9,943.24834

Timestep Collection Time: 4.28814
Timestep Consumption Time: 0.74241
PPO Batch Consumption Time: 0.03335
Total Iteration Time: 5.03055

Cumulative Model Updates: 14,473
Cumulative Timesteps: 241,476,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 241476222...
Checkpoint 241476222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.18258
Policy Entropy: 1.29107
Value Function Loss: 0.18626

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06087
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.07922

Collected Steps per Second: 11,985.32555
Overall Steps per Second: 10,063.39820

Timestep Collection Time: 4.17177
Timestep Consumption Time: 0.79673
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 4.96850

Cumulative Model Updates: 14,476
Cumulative Timesteps: 241,526,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.87696
Policy Entropy: 1.28740
Value Function Loss: 0.18657

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05368
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.08344

Collected Steps per Second: 12,442.20721
Overall Steps per Second: 10,436.09737

Timestep Collection Time: 4.02083
Timestep Consumption Time: 0.77292
PPO Batch Consumption Time: 0.03912
Total Iteration Time: 4.79375

Cumulative Model Updates: 14,479
Cumulative Timesteps: 241,576,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 241576250...
Checkpoint 241576250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.53839
Policy Entropy: 1.28815
Value Function Loss: 0.18775

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06552
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.07805

Collected Steps per Second: 12,187.81039
Overall Steps per Second: 10,291.01821

Timestep Collection Time: 4.10459
Timestep Consumption Time: 0.75654
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 4.86113

Cumulative Model Updates: 14,482
Cumulative Timesteps: 241,626,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.55257
Policy Entropy: 1.28890
Value Function Loss: 0.19660

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05215
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.07314

Collected Steps per Second: 11,981.34276
Overall Steps per Second: 10,103.54589

Timestep Collection Time: 4.17466
Timestep Consumption Time: 0.77588
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.95054

Cumulative Model Updates: 14,485
Cumulative Timesteps: 241,676,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 241676294...
Checkpoint 241676294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.34376
Policy Entropy: 1.28874
Value Function Loss: 0.19758

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.04063
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 12,688.36512
Overall Steps per Second: 10,513.04461

Timestep Collection Time: 3.94188
Timestep Consumption Time: 0.81564
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 4.75752

Cumulative Model Updates: 14,488
Cumulative Timesteps: 241,726,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.57332
Policy Entropy: 1.28697
Value Function Loss: 0.20257

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03715
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 12,812.03044
Overall Steps per Second: 10,499.01416

Timestep Collection Time: 3.90508
Timestep Consumption Time: 0.86032
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 4.76540

Cumulative Model Updates: 14,491
Cumulative Timesteps: 241,776,342

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 241776342...
Checkpoint 241776342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.00767
Policy Entropy: 1.29311
Value Function Loss: 0.19789

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05135
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.07570

Collected Steps per Second: 12,593.30062
Overall Steps per Second: 10,575.79622

Timestep Collection Time: 3.97148
Timestep Consumption Time: 0.75762
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 4.72910

Cumulative Model Updates: 14,494
Cumulative Timesteps: 241,826,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.34127
Policy Entropy: 1.29296
Value Function Loss: 0.19655

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04578
Policy Update Magnitude: 0.06745
Value Function Update Magnitude: 0.07283

Collected Steps per Second: 11,627.10722
Overall Steps per Second: 9,972.56577

Timestep Collection Time: 4.30219
Timestep Consumption Time: 0.71377
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 5.01596

Cumulative Model Updates: 14,497
Cumulative Timesteps: 241,876,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 241876378...
Checkpoint 241876378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.16880
Policy Entropy: 1.29418
Value Function Loss: 0.19209

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.05661
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.07097

Collected Steps per Second: 11,871.38369
Overall Steps per Second: 9,993.99785

Timestep Collection Time: 4.21450
Timestep Consumption Time: 0.79170
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.00620

Cumulative Model Updates: 14,500
Cumulative Timesteps: 241,926,410

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.41535
Policy Entropy: 1.29480
Value Function Loss: 0.18611

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.05873
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.06710

Collected Steps per Second: 11,277.72905
Overall Steps per Second: 9,588.43769

Timestep Collection Time: 4.43529
Timestep Consumption Time: 0.78141
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.21670

Cumulative Model Updates: 14,503
Cumulative Timesteps: 241,976,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 241976430...
Checkpoint 241976430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.86400
Policy Entropy: 1.29676
Value Function Loss: 0.19045

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05872
Policy Update Magnitude: 0.06005
Value Function Update Magnitude: 0.07384

Collected Steps per Second: 11,841.11738
Overall Steps per Second: 10,003.64402

Timestep Collection Time: 4.22409
Timestep Consumption Time: 0.77588
PPO Batch Consumption Time: 0.03748
Total Iteration Time: 4.99998

Cumulative Model Updates: 14,506
Cumulative Timesteps: 242,026,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.79034
Policy Entropy: 1.29690
Value Function Loss: 0.18590

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05167
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 11,892.72129
Overall Steps per Second: 10,063.64063

Timestep Collection Time: 4.20610
Timestep Consumption Time: 0.76446
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.97057

Cumulative Model Updates: 14,509
Cumulative Timesteps: 242,076,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 242076470...
Checkpoint 242076470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.27085
Policy Entropy: 1.29464
Value Function Loss: 0.19787

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04621
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.08081

Collected Steps per Second: 11,419.21391
Overall Steps per Second: 9,882.94369

Timestep Collection Time: 4.38016
Timestep Consumption Time: 0.68088
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.06104

Cumulative Model Updates: 14,512
Cumulative Timesteps: 242,126,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.94595
Policy Entropy: 1.29564
Value Function Loss: 0.20101

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05197
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.07107

Collected Steps per Second: 11,505.15954
Overall Steps per Second: 9,729.19033

Timestep Collection Time: 4.34744
Timestep Consumption Time: 0.79358
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.14102

Cumulative Model Updates: 14,515
Cumulative Timesteps: 242,176,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 242176506...
Checkpoint 242176506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.95065
Policy Entropy: 1.29558
Value Function Loss: 0.20497

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04020
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.06777

Collected Steps per Second: 11,488.78205
Overall Steps per Second: 9,549.38070

Timestep Collection Time: 4.35329
Timestep Consumption Time: 0.88412
PPO Batch Consumption Time: 0.03983
Total Iteration Time: 5.23741

Cumulative Model Updates: 14,518
Cumulative Timesteps: 242,226,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.12248
Policy Entropy: 1.29428
Value Function Loss: 0.19580

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03817
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.07382

Collected Steps per Second: 11,732.47040
Overall Steps per Second: 9,986.98872

Timestep Collection Time: 4.26304
Timestep Consumption Time: 0.74508
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.00812

Cumulative Model Updates: 14,521
Cumulative Timesteps: 242,276,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 242276536...
Checkpoint 242276536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.87418
Policy Entropy: 1.29517
Value Function Loss: 0.19756

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03072
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.06411

Collected Steps per Second: 11,690.69459
Overall Steps per Second: 9,955.92693

Timestep Collection Time: 4.27793
Timestep Consumption Time: 0.74541
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 5.02334

Cumulative Model Updates: 14,524
Cumulative Timesteps: 242,326,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.51820
Policy Entropy: 1.29113
Value Function Loss: 0.20206

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03371
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.06377

Collected Steps per Second: 11,198.34119
Overall Steps per Second: 9,656.81743

Timestep Collection Time: 4.46566
Timestep Consumption Time: 0.71286
PPO Batch Consumption Time: 0.03854
Total Iteration Time: 5.17852

Cumulative Model Updates: 14,527
Cumulative Timesteps: 242,376,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 242376556...
Checkpoint 242376556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.23929
Policy Entropy: 1.29584
Value Function Loss: 0.21362

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05111
Policy Update Magnitude: 0.06608
Value Function Update Magnitude: 0.05852

Collected Steps per Second: 11,540.68330
Overall Steps per Second: 9,637.74032

Timestep Collection Time: 4.33371
Timestep Consumption Time: 0.85568
PPO Batch Consumption Time: 0.04751
Total Iteration Time: 5.18939

Cumulative Model Updates: 14,530
Cumulative Timesteps: 242,426,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.86093
Policy Entropy: 1.29046
Value Function Loss: 0.19429

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05624
Policy Update Magnitude: 0.06373
Value Function Update Magnitude: 0.06455

Collected Steps per Second: 11,718.27181
Overall Steps per Second: 9,961.47801

Timestep Collection Time: 4.26735
Timestep Consumption Time: 0.75259
PPO Batch Consumption Time: 0.03977
Total Iteration Time: 5.01994

Cumulative Model Updates: 14,533
Cumulative Timesteps: 242,476,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 242476576...
Checkpoint 242476576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.94004
Policy Entropy: 1.28978
Value Function Loss: 0.19135

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04643
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.06411

Collected Steps per Second: 11,322.93570
Overall Steps per Second: 9,564.78599

Timestep Collection Time: 4.41829
Timestep Consumption Time: 0.81215
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 5.23044

Cumulative Model Updates: 14,536
Cumulative Timesteps: 242,526,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.88260
Policy Entropy: 1.28640
Value Function Loss: 0.18344

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06330
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.06386

Collected Steps per Second: 11,784.51912
Overall Steps per Second: 9,935.82744

Timestep Collection Time: 4.24523
Timestep Consumption Time: 0.78988
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 5.03511

Cumulative Model Updates: 14,539
Cumulative Timesteps: 242,576,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 242576632...
Checkpoint 242576632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.89637
Policy Entropy: 1.29086
Value Function Loss: 0.18968

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03665
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.06340

Collected Steps per Second: 11,140.66044
Overall Steps per Second: 9,638.67496

Timestep Collection Time: 4.48914
Timestep Consumption Time: 0.69954
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 5.18868

Cumulative Model Updates: 14,542
Cumulative Timesteps: 242,626,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.18994
Policy Entropy: 1.28764
Value Function Loss: 0.18533

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04842
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.06952

Collected Steps per Second: 11,526.52665
Overall Steps per Second: 9,764.80056

Timestep Collection Time: 4.33799
Timestep Consumption Time: 0.78264
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.12064

Cumulative Model Updates: 14,545
Cumulative Timesteps: 242,676,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 242676646...
Checkpoint 242676646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.91657
Policy Entropy: 1.29074
Value Function Loss: 0.19738

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05014
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.07887

Collected Steps per Second: 11,309.57772
Overall Steps per Second: 9,697.50879

Timestep Collection Time: 4.42121
Timestep Consumption Time: 0.73496
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.15617

Cumulative Model Updates: 14,548
Cumulative Timesteps: 242,726,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.36216
Policy Entropy: 1.29182
Value Function Loss: 0.19588

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06231
Policy Update Magnitude: 0.06500
Value Function Update Magnitude: 0.07188

Collected Steps per Second: 12,069.76924
Overall Steps per Second: 10,147.86962

Timestep Collection Time: 4.14407
Timestep Consumption Time: 0.78484
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 4.92892

Cumulative Model Updates: 14,551
Cumulative Timesteps: 242,776,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 242776666...
Checkpoint 242776666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.06256
Policy Entropy: 1.28845
Value Function Loss: 0.20258

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07655
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 10,425.16883
Overall Steps per Second: 8,905.11424

Timestep Collection Time: 4.79609
Timestep Consumption Time: 0.81867
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.61475

Cumulative Model Updates: 14,554
Cumulative Timesteps: 242,826,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.65436
Policy Entropy: 1.28789
Value Function Loss: 0.20875

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.06133
Value Function Update Magnitude: 0.08422

Collected Steps per Second: 11,619.02424
Overall Steps per Second: 9,862.90141

Timestep Collection Time: 4.30466
Timestep Consumption Time: 0.76646
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 5.07112

Cumulative Model Updates: 14,557
Cumulative Timesteps: 242,876,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 242876682...
Checkpoint 242876682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.81403
Policy Entropy: 1.28815
Value Function Loss: 0.21847

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04699
Policy Update Magnitude: 0.06333
Value Function Update Magnitude: 0.08403

Collected Steps per Second: 11,171.54822
Overall Steps per Second: 9,520.72797

Timestep Collection Time: 4.47709
Timestep Consumption Time: 0.77629
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.25338

Cumulative Model Updates: 14,560
Cumulative Timesteps: 242,926,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.31336
Policy Entropy: 1.29188
Value Function Loss: 0.21020

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04524
Policy Update Magnitude: 0.06676
Value Function Update Magnitude: 0.07989

Collected Steps per Second: 11,962.27257
Overall Steps per Second: 10,120.49606

Timestep Collection Time: 4.18165
Timestep Consumption Time: 0.76100
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 4.94264

Cumulative Model Updates: 14,563
Cumulative Timesteps: 242,976,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 242976720...
Checkpoint 242976720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.16487
Policy Entropy: 1.29032
Value Function Loss: 0.21413

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05717
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.08097

Collected Steps per Second: 12,056.46821
Overall Steps per Second: 10,095.74021

Timestep Collection Time: 4.14931
Timestep Consumption Time: 0.80585
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.95516

Cumulative Model Updates: 14,566
Cumulative Timesteps: 243,026,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.67468
Policy Entropy: 1.29052
Value Function Loss: 0.21005

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04833
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 12,033.13868
Overall Steps per Second: 10,055.07348

Timestep Collection Time: 4.15586
Timestep Consumption Time: 0.81755
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 4.97341

Cumulative Model Updates: 14,569
Cumulative Timesteps: 243,076,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 243076754...
Checkpoint 243076754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.47898
Policy Entropy: 1.28739
Value Function Loss: 0.22731

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04354
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.06185

Collected Steps per Second: 11,059.59599
Overall Steps per Second: 9,569.70906

Timestep Collection Time: 4.52187
Timestep Consumption Time: 0.70400
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 5.22586

Cumulative Model Updates: 14,572
Cumulative Timesteps: 243,126,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.10678
Policy Entropy: 1.29059
Value Function Loss: 0.21163

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05796
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.05802

Collected Steps per Second: 11,953.74322
Overall Steps per Second: 10,068.46617

Timestep Collection Time: 4.18279
Timestep Consumption Time: 0.78321
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.96600

Cumulative Model Updates: 14,575
Cumulative Timesteps: 243,176,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 243176764...
Checkpoint 243176764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.74097
Policy Entropy: 1.29086
Value Function Loss: 0.19218

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.05297
Policy Update Magnitude: 0.06893
Value Function Update Magnitude: 0.06446

Collected Steps per Second: 11,736.17046
Overall Steps per Second: 9,845.70798

Timestep Collection Time: 4.26050
Timestep Consumption Time: 0.81805
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 5.07856

Cumulative Model Updates: 14,578
Cumulative Timesteps: 243,226,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.91352
Policy Entropy: 1.28989
Value Function Loss: 0.19208

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05335
Policy Update Magnitude: 0.06887
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 12,065.94325
Overall Steps per Second: 10,227.75066

Timestep Collection Time: 4.14555
Timestep Consumption Time: 0.74506
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 4.89062

Cumulative Model Updates: 14,581
Cumulative Timesteps: 243,276,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 243276786...
Checkpoint 243276786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.08436
Policy Entropy: 1.29029
Value Function Loss: 0.18553

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05162
Policy Update Magnitude: 0.06885
Value Function Update Magnitude: 0.08397

Collected Steps per Second: 11,575.94090
Overall Steps per Second: 9,889.32873

Timestep Collection Time: 4.32069
Timestep Consumption Time: 0.73689
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.05757

Cumulative Model Updates: 14,584
Cumulative Timesteps: 243,326,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.11669
Policy Entropy: 1.29033
Value Function Loss: 0.19689

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03924
Policy Update Magnitude: 0.07220
Value Function Update Magnitude: 0.07986

Collected Steps per Second: 11,573.12281
Overall Steps per Second: 9,927.86985

Timestep Collection Time: 4.32295
Timestep Consumption Time: 0.71640
PPO Batch Consumption Time: 0.04114
Total Iteration Time: 5.03935

Cumulative Model Updates: 14,587
Cumulative Timesteps: 243,376,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 243376832...
Checkpoint 243376832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.47732
Policy Entropy: 1.28552
Value Function Loss: 0.18446

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06491
Policy Update Magnitude: 0.06955
Value Function Update Magnitude: 0.07864

Collected Steps per Second: 10,902.09175
Overall Steps per Second: 9,349.75730

Timestep Collection Time: 4.58829
Timestep Consumption Time: 0.76179
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.35009

Cumulative Model Updates: 14,590
Cumulative Timesteps: 243,426,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.32738
Policy Entropy: 1.28976
Value Function Loss: 0.18967

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04941
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.07874

Collected Steps per Second: 11,420.04967
Overall Steps per Second: 9,762.28975

Timestep Collection Time: 4.37844
Timestep Consumption Time: 0.74351
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.12195

Cumulative Model Updates: 14,593
Cumulative Timesteps: 243,476,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 243476856...
Checkpoint 243476856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.55691
Policy Entropy: 1.29171
Value Function Loss: 0.19869

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03556
Policy Update Magnitude: 0.06505
Value Function Update Magnitude: 0.07485

Collected Steps per Second: 11,801.57553
Overall Steps per Second: 10,022.34529

Timestep Collection Time: 4.23808
Timestep Consumption Time: 0.75237
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.99045

Cumulative Model Updates: 14,596
Cumulative Timesteps: 243,526,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.50891
Policy Entropy: 1.29041
Value Function Loss: 0.20782

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04617
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.07732

Collected Steps per Second: 11,849.29359
Overall Steps per Second: 10,090.00106

Timestep Collection Time: 4.22000
Timestep Consumption Time: 0.73580
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.95580

Cumulative Model Updates: 14,599
Cumulative Timesteps: 243,576,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 243576876...
Checkpoint 243576876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.26636
Policy Entropy: 1.28973
Value Function Loss: 0.21518

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05377
Policy Update Magnitude: 0.07101
Value Function Update Magnitude: 0.07576

Collected Steps per Second: 11,444.77896
Overall Steps per Second: 9,813.24402

Timestep Collection Time: 4.36968
Timestep Consumption Time: 0.72650
PPO Batch Consumption Time: 0.03795
Total Iteration Time: 5.09617

Cumulative Model Updates: 14,602
Cumulative Timesteps: 243,626,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.28987
Policy Entropy: 1.29265
Value Function Loss: 0.20029

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04371
Policy Update Magnitude: 0.07236
Value Function Update Magnitude: 0.07149

Collected Steps per Second: 11,261.39845
Overall Steps per Second: 9,481.29954

Timestep Collection Time: 4.44083
Timestep Consumption Time: 0.83376
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 5.27459

Cumulative Model Updates: 14,605
Cumulative Timesteps: 243,676,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 243676896...
Checkpoint 243676896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.27524
Policy Entropy: 1.29332
Value Function Loss: 0.17854

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03940
Policy Update Magnitude: 0.07024
Value Function Update Magnitude: 0.07223

Collected Steps per Second: 10,790.24806
Overall Steps per Second: 9,233.41743

Timestep Collection Time: 4.63641
Timestep Consumption Time: 0.78174
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.41815

Cumulative Model Updates: 14,608
Cumulative Timesteps: 243,726,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.07322
Policy Entropy: 1.29150
Value Function Loss: 0.17129

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 0.06832
Value Function Update Magnitude: 0.06723

Collected Steps per Second: 11,990.09102
Overall Steps per Second: 10,049.96560

Timestep Collection Time: 4.17278
Timestep Consumption Time: 0.80555
PPO Batch Consumption Time: 0.03929
Total Iteration Time: 4.97833

Cumulative Model Updates: 14,611
Cumulative Timesteps: 243,776,956

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 243776956...
Checkpoint 243776956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.06986
Policy Entropy: 1.28874
Value Function Loss: 0.17875

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04541
Policy Update Magnitude: 0.06842
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 11,394.07382
Overall Steps per Second: 9,633.02229

Timestep Collection Time: 4.39000
Timestep Consumption Time: 0.80255
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.19256

Cumulative Model Updates: 14,614
Cumulative Timesteps: 243,826,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.46443
Policy Entropy: 1.28816
Value Function Loss: 0.17732

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03943
Policy Update Magnitude: 0.07344
Value Function Update Magnitude: 0.06432

Collected Steps per Second: 11,367.04674
Overall Steps per Second: 9,733.34091

Timestep Collection Time: 4.39868
Timestep Consumption Time: 0.73830
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.13698

Cumulative Model Updates: 14,617
Cumulative Timesteps: 243,876,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 243876976...
Checkpoint 243876976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.21110
Policy Entropy: 1.28876
Value Function Loss: 0.18737

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 0.07057
Value Function Update Magnitude: 0.06663

Collected Steps per Second: 12,472.11224
Overall Steps per Second: 10,404.29212

Timestep Collection Time: 4.01023
Timestep Consumption Time: 0.79702
PPO Batch Consumption Time: 0.03789
Total Iteration Time: 4.80725

Cumulative Model Updates: 14,620
Cumulative Timesteps: 243,926,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.51716
Policy Entropy: 1.29121
Value Function Loss: 0.18015

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02931
Policy Update Magnitude: 0.07095
Value Function Update Magnitude: 0.06190

Collected Steps per Second: 12,552.62286
Overall Steps per Second: 10,393.74749

Timestep Collection Time: 3.98498
Timestep Consumption Time: 0.82772
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 4.81270

Cumulative Model Updates: 14,623
Cumulative Timesteps: 243,977,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 243977014...
Checkpoint 243977014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.13091
Policy Entropy: 1.28774
Value Function Loss: 0.18548

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.04005
Policy Update Magnitude: 0.07027
Value Function Update Magnitude: 0.05233

Collected Steps per Second: 11,808.00323
Overall Steps per Second: 9,843.45800

Timestep Collection Time: 4.23577
Timestep Consumption Time: 0.84537
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.08114

Cumulative Model Updates: 14,626
Cumulative Timesteps: 244,027,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.67002
Policy Entropy: 1.28750
Value Function Loss: 0.17440

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04229
Policy Update Magnitude: 0.06954
Value Function Update Magnitude: 0.05542

Collected Steps per Second: 11,235.52393
Overall Steps per Second: 9,429.05697

Timestep Collection Time: 4.45142
Timestep Consumption Time: 0.85283
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.30424

Cumulative Model Updates: 14,629
Cumulative Timesteps: 244,077,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 244077044...
Checkpoint 244077044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.44863
Policy Entropy: 1.29141
Value Function Loss: 0.17182

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04170
Policy Update Magnitude: 0.07005
Value Function Update Magnitude: 0.05422

Collected Steps per Second: 11,526.22447
Overall Steps per Second: 9,891.40695

Timestep Collection Time: 4.33880
Timestep Consumption Time: 0.71710
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.05590

Cumulative Model Updates: 14,632
Cumulative Timesteps: 244,127,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.39168
Policy Entropy: 1.29431
Value Function Loss: 0.17540

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 0.07257
Value Function Update Magnitude: 0.06008

Collected Steps per Second: 11,468.58929
Overall Steps per Second: 9,672.03315

Timestep Collection Time: 4.36165
Timestep Consumption Time: 0.81017
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 5.17182

Cumulative Model Updates: 14,635
Cumulative Timesteps: 244,177,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 244177076...
Checkpoint 244177076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.45691
Policy Entropy: 1.29119
Value Function Loss: 0.16826

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04032
Policy Update Magnitude: 0.07757
Value Function Update Magnitude: 0.06058

Collected Steps per Second: 10,707.56538
Overall Steps per Second: 9,207.83865

Timestep Collection Time: 4.67053
Timestep Consumption Time: 0.76071
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 5.43124

Cumulative Model Updates: 14,638
Cumulative Timesteps: 244,227,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.52233
Policy Entropy: 1.29283
Value Function Loss: 0.17761

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03815
Policy Update Magnitude: 0.07619
Value Function Update Magnitude: 0.07056

Collected Steps per Second: 11,279.82251
Overall Steps per Second: 9,378.64921

Timestep Collection Time: 4.43358
Timestep Consumption Time: 0.89874
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 5.33232

Cumulative Model Updates: 14,641
Cumulative Timesteps: 244,277,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 244277096...
Checkpoint 244277096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.27827
Policy Entropy: 1.28755
Value Function Loss: 0.18547

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03686
Policy Update Magnitude: 0.07214
Value Function Update Magnitude: 0.08337

Collected Steps per Second: 10,902.50307
Overall Steps per Second: 9,276.08490

Timestep Collection Time: 4.58647
Timestep Consumption Time: 0.80417
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.39064

Cumulative Model Updates: 14,644
Cumulative Timesteps: 244,327,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.30105
Policy Entropy: 1.28914
Value Function Loss: 0.18357

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04213
Policy Update Magnitude: 0.07573
Value Function Update Magnitude: 0.10154

Collected Steps per Second: 11,129.98050
Overall Steps per Second: 9,610.10671

Timestep Collection Time: 4.49417
Timestep Consumption Time: 0.71077
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 5.20494

Cumulative Model Updates: 14,647
Cumulative Timesteps: 244,377,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 244377120...
Checkpoint 244377120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.88022
Policy Entropy: 1.28641
Value Function Loss: 0.17396

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04716
Policy Update Magnitude: 0.07479
Value Function Update Magnitude: 0.09168

Collected Steps per Second: 10,955.47753
Overall Steps per Second: 9,322.66893

Timestep Collection Time: 4.56447
Timestep Consumption Time: 0.79944
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 5.36391

Cumulative Model Updates: 14,650
Cumulative Timesteps: 244,427,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.83947
Policy Entropy: 1.29622
Value Function Loss: 0.16740

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03591
Policy Update Magnitude: 0.07475
Value Function Update Magnitude: 0.08921

Collected Steps per Second: 10,747.38068
Overall Steps per Second: 9,272.12949

Timestep Collection Time: 4.65360
Timestep Consumption Time: 0.74042
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 5.39401

Cumulative Model Updates: 14,653
Cumulative Timesteps: 244,477,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 244477140...
Checkpoint 244477140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.57340
Policy Entropy: 1.28958
Value Function Loss: 0.17061

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04190
Policy Update Magnitude: 0.06871
Value Function Update Magnitude: 0.10401

Collected Steps per Second: 10,550.47560
Overall Steps per Second: 9,070.50844

Timestep Collection Time: 4.74102
Timestep Consumption Time: 0.77356
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.51458

Cumulative Model Updates: 14,656
Cumulative Timesteps: 244,527,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.74696
Policy Entropy: 1.29183
Value Function Loss: 0.18946

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04221
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.11108

Collected Steps per Second: 10,177.40239
Overall Steps per Second: 8,761.55385

Timestep Collection Time: 4.91343
Timestep Consumption Time: 0.79400
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.70744

Cumulative Model Updates: 14,659
Cumulative Timesteps: 244,577,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 244577166...
Checkpoint 244577166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.71747
Policy Entropy: 1.28800
Value Function Loss: 0.19691

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05074
Policy Update Magnitude: 0.07051
Value Function Update Magnitude: 0.09593

Collected Steps per Second: 10,942.44659
Overall Steps per Second: 9,465.28536

Timestep Collection Time: 4.57174
Timestep Consumption Time: 0.71347
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.28521

Cumulative Model Updates: 14,662
Cumulative Timesteps: 244,627,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.20180
Policy Entropy: 1.29111
Value Function Loss: 0.20573

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.06023
Value Function Update Magnitude: 0.08099

Collected Steps per Second: 10,760.88999
Overall Steps per Second: 9,203.83413

Timestep Collection Time: 4.64924
Timestep Consumption Time: 0.78653
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.43578

Cumulative Model Updates: 14,665
Cumulative Timesteps: 244,677,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 244677222...
Checkpoint 244677222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.12958
Policy Entropy: 1.28883
Value Function Loss: 0.19715

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06079
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.08560

Collected Steps per Second: 10,832.03387
Overall Steps per Second: 9,339.25551

Timestep Collection Time: 4.61742
Timestep Consumption Time: 0.73804
PPO Batch Consumption Time: 0.03799
Total Iteration Time: 5.35546

Cumulative Model Updates: 14,668
Cumulative Timesteps: 244,727,238

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.78635
Policy Entropy: 1.28934
Value Function Loss: 0.19347

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04257
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.08239

Collected Steps per Second: 10,705.08990
Overall Steps per Second: 9,291.29104

Timestep Collection Time: 4.67348
Timestep Consumption Time: 0.71113
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.38461

Cumulative Model Updates: 14,671
Cumulative Timesteps: 244,777,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 244777268...
Checkpoint 244777268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.80662
Policy Entropy: 1.28529
Value Function Loss: 0.19629

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.05209
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.07778

Collected Steps per Second: 10,483.60578
Overall Steps per Second: 8,894.36377

Timestep Collection Time: 4.77164
Timestep Consumption Time: 0.85260
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 5.62424

Cumulative Model Updates: 14,674
Cumulative Timesteps: 244,827,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.13898
Policy Entropy: 1.29291
Value Function Loss: 0.20828

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06667
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.06814

Collected Steps per Second: 10,462.94877
Overall Steps per Second: 9,140.84485

Timestep Collection Time: 4.77972
Timestep Consumption Time: 0.69132
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.47105

Cumulative Model Updates: 14,677
Cumulative Timesteps: 244,877,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 244877302...
Checkpoint 244877302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.20912
Policy Entropy: 1.28359
Value Function Loss: 0.21249

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.06581

Collected Steps per Second: 10,808.31266
Overall Steps per Second: 9,236.33712

Timestep Collection Time: 4.62829
Timestep Consumption Time: 0.78771
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.41600

Cumulative Model Updates: 14,680
Cumulative Timesteps: 244,927,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.36663
Policy Entropy: 1.28835
Value Function Loss: 0.22167

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.04067
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.08357

Collected Steps per Second: 10,606.34321
Overall Steps per Second: 9,119.05878

Timestep Collection Time: 4.71586
Timestep Consumption Time: 0.76914
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 5.48500

Cumulative Model Updates: 14,683
Cumulative Timesteps: 244,977,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 244977344...
Checkpoint 244977344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.39344
Policy Entropy: 1.28411
Value Function Loss: 0.21435

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04304
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.08923

Collected Steps per Second: 10,881.77733
Overall Steps per Second: 9,296.58965

Timestep Collection Time: 4.59576
Timestep Consumption Time: 0.78364
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.37939

Cumulative Model Updates: 14,686
Cumulative Timesteps: 245,027,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.35130
Policy Entropy: 1.28372
Value Function Loss: 0.21658

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04447
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.08307

Collected Steps per Second: 11,011.45954
Overall Steps per Second: 9,396.50667

Timestep Collection Time: 4.54181
Timestep Consumption Time: 0.78059
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 5.32240

Cumulative Model Updates: 14,689
Cumulative Timesteps: 245,077,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 245077366...
Checkpoint 245077366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.31522
Policy Entropy: 1.28721
Value Function Loss: 0.20762

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.07054
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 10,534.17023
Overall Steps per Second: 9,205.27476

Timestep Collection Time: 4.74703
Timestep Consumption Time: 0.68529
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.43232

Cumulative Model Updates: 14,692
Cumulative Timesteps: 245,127,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.56381
Policy Entropy: 1.28596
Value Function Loss: 0.19830

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04613
Policy Update Magnitude: 0.07154
Value Function Update Magnitude: 0.07355

Collected Steps per Second: 11,273.86418
Overall Steps per Second: 9,609.80415

Timestep Collection Time: 4.43787
Timestep Consumption Time: 0.76847
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 5.20635

Cumulative Model Updates: 14,695
Cumulative Timesteps: 245,177,404

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 245177404...
Checkpoint 245177404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.33222
Policy Entropy: 1.28405
Value Function Loss: 0.18672

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04555
Policy Update Magnitude: 0.07401
Value Function Update Magnitude: 0.07214

Collected Steps per Second: 11,125.08068
Overall Steps per Second: 9,512.98609

Timestep Collection Time: 4.49525
Timestep Consumption Time: 0.76178
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.25702

Cumulative Model Updates: 14,698
Cumulative Timesteps: 245,227,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.20051
Policy Entropy: 1.28441
Value Function Loss: 0.18966

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04699
Policy Update Magnitude: 0.07251
Value Function Update Magnitude: 0.06950

Collected Steps per Second: 11,534.24538
Overall Steps per Second: 9,768.72894

Timestep Collection Time: 4.33561
Timestep Consumption Time: 0.78358
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 5.11919

Cumulative Model Updates: 14,701
Cumulative Timesteps: 245,277,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 245277422...
Checkpoint 245277422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.70211
Policy Entropy: 1.29024
Value Function Loss: 0.19701

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03863
Policy Update Magnitude: 0.07168
Value Function Update Magnitude: 0.06893

Collected Steps per Second: 10,805.05105
Overall Steps per Second: 9,277.40569

Timestep Collection Time: 4.62913
Timestep Consumption Time: 0.76225
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.39138

Cumulative Model Updates: 14,704
Cumulative Timesteps: 245,327,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.58997
Policy Entropy: 1.29279
Value Function Loss: 0.19750

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03593
Policy Update Magnitude: 0.07439
Value Function Update Magnitude: 0.07325

Collected Steps per Second: 11,044.63119
Overall Steps per Second: 9,490.83337

Timestep Collection Time: 4.52854
Timestep Consumption Time: 0.74139
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.26993

Cumulative Model Updates: 14,707
Cumulative Timesteps: 245,377,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 245377456...
Checkpoint 245377456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.41593
Policy Entropy: 1.28887
Value Function Loss: 0.17521

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04489
Policy Update Magnitude: 0.07379
Value Function Update Magnitude: 0.06762

Collected Steps per Second: 10,380.62844
Overall Steps per Second: 8,913.61571

Timestep Collection Time: 4.81878
Timestep Consumption Time: 0.79308
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 5.61186

Cumulative Model Updates: 14,710
Cumulative Timesteps: 245,427,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.55758
Policy Entropy: 1.28555
Value Function Loss: 0.17583

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04264
Policy Update Magnitude: 0.07013
Value Function Update Magnitude: 0.06359

Collected Steps per Second: 11,017.00848
Overall Steps per Second: 9,441.96500

Timestep Collection Time: 4.54134
Timestep Consumption Time: 0.75756
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.29890

Cumulative Model Updates: 14,713
Cumulative Timesteps: 245,477,510

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 245477510...
Checkpoint 245477510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.01875
Policy Entropy: 1.28754
Value Function Loss: 0.17454

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04377
Policy Update Magnitude: 0.07214
Value Function Update Magnitude: 0.05740

Collected Steps per Second: 11,268.09267
Overall Steps per Second: 9,543.94168

Timestep Collection Time: 4.43962
Timestep Consumption Time: 0.80203
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 5.24165

Cumulative Model Updates: 14,716
Cumulative Timesteps: 245,527,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.51119
Policy Entropy: 1.28826
Value Function Loss: 0.18370

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07391
Policy Update Magnitude: 0.06428
Value Function Update Magnitude: 0.06128

Collected Steps per Second: 10,756.88064
Overall Steps per Second: 9,204.29189

Timestep Collection Time: 4.64837
Timestep Consumption Time: 0.78409
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 5.43247

Cumulative Model Updates: 14,719
Cumulative Timesteps: 245,577,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 245577538...
Checkpoint 245577538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.64578
Policy Entropy: 1.28349
Value Function Loss: 0.19376

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.06631

Collected Steps per Second: 10,821.97160
Overall Steps per Second: 9,384.11403

Timestep Collection Time: 4.62023
Timestep Consumption Time: 0.70792
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.32815

Cumulative Model Updates: 14,722
Cumulative Timesteps: 245,627,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.08776
Policy Entropy: 1.28365
Value Function Loss: 0.20545

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.06491

Collected Steps per Second: 10,397.42375
Overall Steps per Second: 8,936.66357

Timestep Collection Time: 4.80908
Timestep Consumption Time: 0.78608
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.59515

Cumulative Model Updates: 14,725
Cumulative Timesteps: 245,677,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 245677540...
Checkpoint 245677540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.51838
Policy Entropy: 1.28219
Value Function Loss: 0.20562

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.07762

Collected Steps per Second: 10,849.98975
Overall Steps per Second: 9,170.31575

Timestep Collection Time: 4.61070
Timestep Consumption Time: 0.84451
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 5.45521

Cumulative Model Updates: 14,728
Cumulative Timesteps: 245,727,566

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.64348
Policy Entropy: 1.28074
Value Function Loss: 0.19903

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 11,100.92917
Overall Steps per Second: 9,325.29085

Timestep Collection Time: 4.50449
Timestep Consumption Time: 0.85770
PPO Batch Consumption Time: 0.03888
Total Iteration Time: 5.36219

Cumulative Model Updates: 14,731
Cumulative Timesteps: 245,777,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 245777570...
Checkpoint 245777570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.95496
Policy Entropy: 1.28164
Value Function Loss: 0.18988

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.06356

Collected Steps per Second: 10,801.09947
Overall Steps per Second: 9,307.27176

Timestep Collection Time: 4.63120
Timestep Consumption Time: 0.74331
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.37451

Cumulative Model Updates: 14,734
Cumulative Timesteps: 245,827,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.01450
Policy Entropy: 1.27891
Value Function Loss: 0.19327

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.07454

Collected Steps per Second: 10,649.03530
Overall Steps per Second: 9,229.46790

Timestep Collection Time: 4.69545
Timestep Consumption Time: 0.72220
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.41765

Cumulative Model Updates: 14,737
Cumulative Timesteps: 245,877,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 245877594...
Checkpoint 245877594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.09829
Policy Entropy: 1.28097
Value Function Loss: 0.18883

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.06836

Collected Steps per Second: 10,880.76977
Overall Steps per Second: 9,306.78674

Timestep Collection Time: 4.59673
Timestep Consumption Time: 0.77741
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.37414

Cumulative Model Updates: 14,740
Cumulative Timesteps: 245,927,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.15872
Policy Entropy: 1.27974
Value Function Loss: 0.19077

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.07006

Collected Steps per Second: 10,415.88105
Overall Steps per Second: 8,933.85029

Timestep Collection Time: 4.80247
Timestep Consumption Time: 0.79668
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 5.59915

Cumulative Model Updates: 14,743
Cumulative Timesteps: 245,977,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 245977632...
Checkpoint 245977632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.06385
Policy Entropy: 1.28797
Value Function Loss: 0.19007

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.07384

Collected Steps per Second: 11,018.06191
Overall Steps per Second: 9,352.20643

Timestep Collection Time: 4.53818
Timestep Consumption Time: 0.80836
PPO Batch Consumption Time: 0.03912
Total Iteration Time: 5.34655

Cumulative Model Updates: 14,746
Cumulative Timesteps: 246,027,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.42237
Policy Entropy: 1.27631
Value Function Loss: 0.19600

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.06793

Collected Steps per Second: 10,763.18002
Overall Steps per Second: 9,202.45207

Timestep Collection Time: 4.64621
Timestep Consumption Time: 0.78799
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.43420

Cumulative Model Updates: 14,749
Cumulative Timesteps: 246,077,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 246077642...
Checkpoint 246077642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.41448
Policy Entropy: 1.28582
Value Function Loss: 0.19380

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05362
Policy Update Magnitude: 0.06454
Value Function Update Magnitude: 0.07795

Collected Steps per Second: 11,092.57543
Overall Steps per Second: 9,538.97079

Timestep Collection Time: 4.50878
Timestep Consumption Time: 0.73434
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 5.24312

Cumulative Model Updates: 14,752
Cumulative Timesteps: 246,127,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.22939
Policy Entropy: 1.28026
Value Function Loss: 0.18986

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.06576
Value Function Update Magnitude: 0.08415

Collected Steps per Second: 11,059.91639
Overall Steps per Second: 9,323.29950

Timestep Collection Time: 4.52228
Timestep Consumption Time: 0.84235
PPO Batch Consumption Time: 0.03899
Total Iteration Time: 5.36462

Cumulative Model Updates: 14,755
Cumulative Timesteps: 246,177,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 246177672...
Checkpoint 246177672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.45318
Policy Entropy: 1.28460
Value Function Loss: 0.16935

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.07101

Collected Steps per Second: 10,583.61379
Overall Steps per Second: 9,015.84137

Timestep Collection Time: 4.72599
Timestep Consumption Time: 0.82181
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.54779

Cumulative Model Updates: 14,758
Cumulative Timesteps: 246,227,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.65731
Policy Entropy: 1.28509
Value Function Loss: 0.17452

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.05649
Policy Update Magnitude: 0.06679
Value Function Update Magnitude: 0.05995

Collected Steps per Second: 11,118.45668
Overall Steps per Second: 9,309.77133

Timestep Collection Time: 4.49901
Timestep Consumption Time: 0.87406
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 5.37306

Cumulative Model Updates: 14,761
Cumulative Timesteps: 246,277,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 246277712...
Checkpoint 246277712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.27955
Policy Entropy: 1.28170
Value Function Loss: 0.18551

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04182
Policy Update Magnitude: 0.06513
Value Function Update Magnitude: 0.05014

Collected Steps per Second: 10,976.70001
Overall Steps per Second: 9,369.88138

Timestep Collection Time: 4.55601
Timestep Consumption Time: 0.78130
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.33731

Cumulative Model Updates: 14,764
Cumulative Timesteps: 246,327,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.42677
Policy Entropy: 1.27558
Value Function Loss: 0.20032

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.06168
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.04523

Collected Steps per Second: 11,100.28853
Overall Steps per Second: 9,527.77465

Timestep Collection Time: 4.50673
Timestep Consumption Time: 0.74381
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 5.25054

Cumulative Model Updates: 14,767
Cumulative Timesteps: 246,377,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 246377748...
Checkpoint 246377748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.94291
Policy Entropy: 1.28040
Value Function Loss: 0.19925

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03904
Policy Update Magnitude: 0.06784
Value Function Update Magnitude: 0.05559

Collected Steps per Second: 10,843.54427
Overall Steps per Second: 9,260.09816

Timestep Collection Time: 4.61196
Timestep Consumption Time: 0.78863
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.40059

Cumulative Model Updates: 14,770
Cumulative Timesteps: 246,427,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.94986
Policy Entropy: 1.28201
Value Function Loss: 0.19954

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04322
Policy Update Magnitude: 0.06844
Value Function Update Magnitude: 0.04843

Collected Steps per Second: 10,933.58179
Overall Steps per Second: 9,343.59507

Timestep Collection Time: 4.57380
Timestep Consumption Time: 0.77832
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.35212

Cumulative Model Updates: 14,773
Cumulative Timesteps: 246,477,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 246477766...
Checkpoint 246477766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.19917
Policy Entropy: 1.28246
Value Function Loss: 0.19305

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05134
Policy Update Magnitude: 0.06826
Value Function Update Magnitude: 0.04819

Collected Steps per Second: 10,581.33612
Overall Steps per Second: 8,956.18048

Timestep Collection Time: 4.72568
Timestep Consumption Time: 0.85750
PPO Batch Consumption Time: 0.03932
Total Iteration Time: 5.58318

Cumulative Model Updates: 14,776
Cumulative Timesteps: 246,527,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.65932
Policy Entropy: 1.28784
Value Function Loss: 0.18182

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.04847
Policy Update Magnitude: 0.07041
Value Function Update Magnitude: 0.04510

Collected Steps per Second: 11,145.59342
Overall Steps per Second: 9,455.58477

Timestep Collection Time: 4.48662
Timestep Consumption Time: 0.80190
PPO Batch Consumption Time: 0.03919
Total Iteration Time: 5.28851

Cumulative Model Updates: 14,779
Cumulative Timesteps: 246,577,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 246577776...
Checkpoint 246577776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.25240
Policy Entropy: 1.28599
Value Function Loss: 0.17257

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05009
Policy Update Magnitude: 0.06645
Value Function Update Magnitude: 0.05644

Collected Steps per Second: 10,682.52579
Overall Steps per Second: 9,206.08547

Timestep Collection Time: 4.68223
Timestep Consumption Time: 0.75092
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 5.43315

Cumulative Model Updates: 14,782
Cumulative Timesteps: 246,627,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.98064
Policy Entropy: 1.28681
Value Function Loss: 0.16957

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05142
Policy Update Magnitude: 0.06622
Value Function Update Magnitude: 0.06033

Collected Steps per Second: 10,904.01929
Overall Steps per Second: 9,240.15888

Timestep Collection Time: 4.58638
Timestep Consumption Time: 0.82586
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.41224

Cumulative Model Updates: 14,785
Cumulative Timesteps: 246,677,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 246677804...
Checkpoint 246677804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.08202
Policy Entropy: 1.28903
Value Function Loss: 0.17289

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04139
Policy Update Magnitude: 0.06782
Value Function Update Magnitude: 0.07705

Collected Steps per Second: 10,516.23617
Overall Steps per Second: 9,008.86084

Timestep Collection Time: 4.75550
Timestep Consumption Time: 0.79570
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.55120

Cumulative Model Updates: 14,788
Cumulative Timesteps: 246,727,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.72929
Policy Entropy: 1.28618
Value Function Loss: 0.18830

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04075
Policy Update Magnitude: 0.06834
Value Function Update Magnitude: 0.09423

Collected Steps per Second: 10,503.03077
Overall Steps per Second: 8,943.31954

Timestep Collection Time: 4.76091
Timestep Consumption Time: 0.83030
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.59121

Cumulative Model Updates: 14,791
Cumulative Timesteps: 246,777,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 246777818...
Checkpoint 246777818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.40676
Policy Entropy: 1.28623
Value Function Loss: 0.18939

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04791
Policy Update Magnitude: 0.06822
Value Function Update Magnitude: 0.09147

Collected Steps per Second: 10,805.38289
Overall Steps per Second: 9,219.94336

Timestep Collection Time: 4.62991
Timestep Consumption Time: 0.79615
PPO Batch Consumption Time: 0.03844
Total Iteration Time: 5.42606

Cumulative Model Updates: 14,794
Cumulative Timesteps: 246,827,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.78603
Policy Entropy: 1.28485
Value Function Loss: 0.18612

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03100
Policy Update Magnitude: 0.07082
Value Function Update Magnitude: 0.08674

Collected Steps per Second: 10,537.95888
Overall Steps per Second: 9,257.84486

Timestep Collection Time: 4.74589
Timestep Consumption Time: 0.65623
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.40212

Cumulative Model Updates: 14,797
Cumulative Timesteps: 246,877,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 246877858...
Checkpoint 246877858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.55669
Policy Entropy: 1.28602
Value Function Loss: 0.17409

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03571
Policy Update Magnitude: 0.07149
Value Function Update Magnitude: 0.07964

Collected Steps per Second: 10,800.78705
Overall Steps per Second: 9,165.36026

Timestep Collection Time: 4.63170
Timestep Consumption Time: 0.82646
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.45816

Cumulative Model Updates: 14,800
Cumulative Timesteps: 246,927,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.97991
Policy Entropy: 1.28446
Value Function Loss: 0.18633

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04671
Policy Update Magnitude: 0.06934
Value Function Update Magnitude: 0.07313

Collected Steps per Second: 10,279.67547
Overall Steps per Second: 8,845.61864

Timestep Collection Time: 4.86436
Timestep Consumption Time: 0.78861
PPO Batch Consumption Time: 0.03888
Total Iteration Time: 5.65297

Cumulative Model Updates: 14,803
Cumulative Timesteps: 246,977,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 246977888...
Checkpoint 246977888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.04757
Policy Entropy: 1.28576
Value Function Loss: 0.18953

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03406
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.07367

Collected Steps per Second: 10,639.13703
Overall Steps per Second: 9,093.91482

Timestep Collection Time: 4.70076
Timestep Consumption Time: 0.79874
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.49950

Cumulative Model Updates: 14,806
Cumulative Timesteps: 247,027,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.98363
Policy Entropy: 1.28074
Value Function Loss: 0.17627

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05080
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.07808

Collected Steps per Second: 9,991.36167
Overall Steps per Second: 8,564.57764

Timestep Collection Time: 5.00432
Timestep Consumption Time: 0.83368
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 5.83800

Cumulative Model Updates: 14,809
Cumulative Timesteps: 247,077,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 247077900...
Checkpoint 247077900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.26956
Policy Entropy: 1.28020
Value Function Loss: 0.18124

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04814
Policy Update Magnitude: 0.06999
Value Function Update Magnitude: 0.08653

Collected Steps per Second: 10,547.39726
Overall Steps per Second: 9,177.38700

Timestep Collection Time: 4.74145
Timestep Consumption Time: 0.70781
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.44926

Cumulative Model Updates: 14,812
Cumulative Timesteps: 247,127,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.59055
Policy Entropy: 1.28624
Value Function Loss: 0.17845

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.06941
Value Function Update Magnitude: 0.08295

Collected Steps per Second: 10,599.58340
Overall Steps per Second: 9,074.05431

Timestep Collection Time: 4.71754
Timestep Consumption Time: 0.79311
PPO Batch Consumption Time: 0.03858
Total Iteration Time: 5.51066

Cumulative Model Updates: 14,815
Cumulative Timesteps: 247,177,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 247177914...
Checkpoint 247177914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.05566
Policy Entropy: 1.28750
Value Function Loss: 0.18966

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03003
Policy Update Magnitude: 0.07258
Value Function Update Magnitude: 0.07217

Collected Steps per Second: 10,512.39762
Overall Steps per Second: 9,064.67032

Timestep Collection Time: 4.75781
Timestep Consumption Time: 0.75987
PPO Batch Consumption Time: 0.03732
Total Iteration Time: 5.51769

Cumulative Model Updates: 14,818
Cumulative Timesteps: 247,227,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.33055
Policy Entropy: 1.28824
Value Function Loss: 0.17766

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03979
Policy Update Magnitude: 0.06914
Value Function Update Magnitude: 0.07213

Collected Steps per Second: 10,991.32588
Overall Steps per Second: 9,291.40922

Timestep Collection Time: 4.55104
Timestep Consumption Time: 0.83264
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 5.38368

Cumulative Model Updates: 14,821
Cumulative Timesteps: 247,277,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 247277952...
Checkpoint 247277952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.22669
Policy Entropy: 1.28480
Value Function Loss: 0.18395

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05015
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.08764

Collected Steps per Second: 10,382.22764
Overall Steps per Second: 8,921.84775

Timestep Collection Time: 4.81881
Timestep Consumption Time: 0.78877
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.60758

Cumulative Model Updates: 14,824
Cumulative Timesteps: 247,327,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.77231
Policy Entropy: 1.28439
Value Function Loss: 0.19920

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05571
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.08790

Collected Steps per Second: 10,732.34026
Overall Steps per Second: 9,195.94338

Timestep Collection Time: 4.65975
Timestep Consumption Time: 0.77852
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.43827

Cumulative Model Updates: 14,827
Cumulative Timesteps: 247,377,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 247377992...
Checkpoint 247377992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.40511
Policy Entropy: 1.28177
Value Function Loss: 0.20210

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05252
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.08610

Collected Steps per Second: 10,874.81074
Overall Steps per Second: 9,317.28378

Timestep Collection Time: 4.59999
Timestep Consumption Time: 0.76896
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.36895

Cumulative Model Updates: 14,830
Cumulative Timesteps: 247,428,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.65726
Policy Entropy: 1.28127
Value Function Loss: 0.20071

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06762
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 11,060.27347
Overall Steps per Second: 9,423.18381

Timestep Collection Time: 4.52213
Timestep Consumption Time: 0.78563
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.30776

Cumulative Model Updates: 14,833
Cumulative Timesteps: 247,478,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 247478032...
Checkpoint 247478032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.90360
Policy Entropy: 1.28419
Value Function Loss: 0.18797

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05306
Policy Update Magnitude: 0.06526
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 10,921.05379
Overall Steps per Second: 9,442.61920

Timestep Collection Time: 4.57850
Timestep Consumption Time: 0.71686
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.29535

Cumulative Model Updates: 14,836
Cumulative Timesteps: 247,528,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.55242
Policy Entropy: 1.28665
Value Function Loss: 0.18119

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06326
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.06805

Collected Steps per Second: 10,891.88433
Overall Steps per Second: 9,245.25408

Timestep Collection Time: 4.59131
Timestep Consumption Time: 0.81774
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.40905

Cumulative Model Updates: 14,839
Cumulative Timesteps: 247,578,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 247578042...
Checkpoint 247578042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.14819
Policy Entropy: 1.28233
Value Function Loss: 0.20075

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.05752

Collected Steps per Second: 10,431.69526
Overall Steps per Second: 9,122.05743

Timestep Collection Time: 4.79308
Timestep Consumption Time: 0.68813
PPO Batch Consumption Time: 0.03871
Total Iteration Time: 5.48122

Cumulative Model Updates: 14,842
Cumulative Timesteps: 247,628,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.01904
Policy Entropy: 1.28473
Value Function Loss: 0.20265

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04571
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.06111

Collected Steps per Second: 10,931.24872
Overall Steps per Second: 9,294.39491

Timestep Collection Time: 4.57569
Timestep Consumption Time: 0.80583
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.38152

Cumulative Model Updates: 14,845
Cumulative Timesteps: 247,678,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 247678060...
Checkpoint 247678060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.07991
Policy Entropy: 1.28227
Value Function Loss: 0.21541

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05699
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.07112

Collected Steps per Second: 10,983.43182
Overall Steps per Second: 9,358.07880

Timestep Collection Time: 4.55304
Timestep Consumption Time: 0.79079
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.34383

Cumulative Model Updates: 14,848
Cumulative Timesteps: 247,728,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.26357
Policy Entropy: 1.28348
Value Function Loss: 0.19146

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05170
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.07961

Collected Steps per Second: 10,966.42419
Overall Steps per Second: 9,571.26519

Timestep Collection Time: 4.56101
Timestep Consumption Time: 0.66484
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.22585

Cumulative Model Updates: 14,851
Cumulative Timesteps: 247,778,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 247778086...
Checkpoint 247778086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.43492
Policy Entropy: 1.28632
Value Function Loss: 0.18475

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04617
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.08258

Collected Steps per Second: 10,644.82035
Overall Steps per Second: 9,122.41187

Timestep Collection Time: 4.69881
Timestep Consumption Time: 0.78417
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.48298

Cumulative Model Updates: 14,854
Cumulative Timesteps: 247,828,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.29327
Policy Entropy: 1.28254
Value Function Loss: 0.18454

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05484
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 10,285.99728
Overall Steps per Second: 8,990.59643

Timestep Collection Time: 4.86312
Timestep Consumption Time: 0.70070
PPO Batch Consumption Time: 0.03384
Total Iteration Time: 5.56381

Cumulative Model Updates: 14,857
Cumulative Timesteps: 247,878,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 247878126...
Checkpoint 247878126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.25430
Policy Entropy: 1.28416
Value Function Loss: 0.19438

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05585
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.08904

Collected Steps per Second: 10,748.58518
Overall Steps per Second: 9,190.37261

Timestep Collection Time: 4.65252
Timestep Consumption Time: 0.78883
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.44135

Cumulative Model Updates: 14,860
Cumulative Timesteps: 247,928,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.77537
Policy Entropy: 1.27920
Value Function Loss: 0.19713

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.06259
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.07389

Collected Steps per Second: 10,895.95916
Overall Steps per Second: 9,384.82551

Timestep Collection Time: 4.59143
Timestep Consumption Time: 0.73931
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.33073

Cumulative Model Updates: 14,863
Cumulative Timesteps: 247,978,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 247978162...
Checkpoint 247978162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.37642
Policy Entropy: 1.28119
Value Function Loss: 0.19517

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.06438

Collected Steps per Second: 11,035.72628
Overall Steps per Second: 9,422.78765

Timestep Collection Time: 4.53128
Timestep Consumption Time: 0.77564
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.30692

Cumulative Model Updates: 14,866
Cumulative Timesteps: 248,028,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.90281
Policy Entropy: 1.27998
Value Function Loss: 0.19191

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.06257
Policy Update Magnitude: 0.06236
Value Function Update Magnitude: 0.07303

Collected Steps per Second: 10,576.33209
Overall Steps per Second: 9,109.69684

Timestep Collection Time: 4.73018
Timestep Consumption Time: 0.76155
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.49173

Cumulative Model Updates: 14,869
Cumulative Timesteps: 248,078,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 248078196...
Checkpoint 248078196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.48277
Policy Entropy: 1.28185
Value Function Loss: 0.19316

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06758
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.07911

Collected Steps per Second: 10,642.88706
Overall Steps per Second: 9,293.83708

Timestep Collection Time: 4.70023
Timestep Consumption Time: 0.68226
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.38249

Cumulative Model Updates: 14,872
Cumulative Timesteps: 248,128,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.10060
Policy Entropy: 1.27797
Value Function Loss: 0.18719

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.07361

Collected Steps per Second: 10,407.49609
Overall Steps per Second: 8,870.25063

Timestep Collection Time: 4.80500
Timestep Consumption Time: 0.83272
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.63772

Cumulative Model Updates: 14,875
Cumulative Timesteps: 248,178,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 248178228...
Checkpoint 248178228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.77672
Policy Entropy: 1.28405
Value Function Loss: 0.18622

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 10,725.12486
Overall Steps per Second: 9,248.15144

Timestep Collection Time: 4.66270
Timestep Consumption Time: 0.74465
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.40735

Cumulative Model Updates: 14,878
Cumulative Timesteps: 248,228,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.90795
Policy Entropy: 1.28755
Value Function Loss: 0.17984

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.06727

Collected Steps per Second: 10,645.07553
Overall Steps per Second: 9,064.29088

Timestep Collection Time: 4.69738
Timestep Consumption Time: 0.81921
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.51659

Cumulative Model Updates: 14,881
Cumulative Timesteps: 248,278,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 248278240...
Checkpoint 248278240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.88363
Policy Entropy: 1.28491
Value Function Loss: 0.17261

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.05928

Collected Steps per Second: 11,155.78569
Overall Steps per Second: 9,519.20498

Timestep Collection Time: 4.48413
Timestep Consumption Time: 0.77093
PPO Batch Consumption Time: 0.03825
Total Iteration Time: 5.25506

Cumulative Model Updates: 14,884
Cumulative Timesteps: 248,328,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.43784
Policy Entropy: 1.29357
Value Function Loss: 0.17095

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.05847

Collected Steps per Second: 11,439.58099
Overall Steps per Second: 9,756.46268

Timestep Collection Time: 4.37324
Timestep Consumption Time: 0.75444
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 5.12768

Cumulative Model Updates: 14,887
Cumulative Timesteps: 248,378,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 248378292...
Checkpoint 248378292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.48937
Policy Entropy: 1.28764
Value Function Loss: 0.18620

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06840
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.05579

Collected Steps per Second: 11,344.58874
Overall Steps per Second: 9,495.22359

Timestep Collection Time: 4.40827
Timestep Consumption Time: 0.85859
PPO Batch Consumption Time: 0.04163
Total Iteration Time: 5.26686

Cumulative Model Updates: 14,890
Cumulative Timesteps: 248,428,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.64996
Policy Entropy: 1.29108
Value Function Loss: 0.20421

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.06457

Collected Steps per Second: 11,344.03268
Overall Steps per Second: 9,629.85382

Timestep Collection Time: 4.40919
Timestep Consumption Time: 0.78487
PPO Batch Consumption Time: 0.03814
Total Iteration Time: 5.19406

Cumulative Model Updates: 14,893
Cumulative Timesteps: 248,478,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 248478320...
Checkpoint 248478320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.92018
Policy Entropy: 1.28767
Value Function Loss: 0.20899

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.05129
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 11,663.12546
Overall Steps per Second: 9,842.90430

Timestep Collection Time: 4.28907
Timestep Consumption Time: 0.79317
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.08224

Cumulative Model Updates: 14,896
Cumulative Timesteps: 248,528,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.44396
Policy Entropy: 1.29117
Value Function Loss: 0.20908

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05117
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.08108

Collected Steps per Second: 11,352.98947
Overall Steps per Second: 9,632.29196

Timestep Collection Time: 4.40536
Timestep Consumption Time: 0.78697
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 5.19233

Cumulative Model Updates: 14,899
Cumulative Timesteps: 248,578,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 248578358...
Checkpoint 248578358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.11658
Policy Entropy: 1.29021
Value Function Loss: 0.20954

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05207
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.08458

Collected Steps per Second: 11,005.85380
Overall Steps per Second: 9,547.50864

Timestep Collection Time: 4.54467
Timestep Consumption Time: 0.69418
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 5.23885

Cumulative Model Updates: 14,902
Cumulative Timesteps: 248,628,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.28155
Policy Entropy: 1.28887
Value Function Loss: 0.19665

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04149
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 10,676.30841
Overall Steps per Second: 9,116.98790

Timestep Collection Time: 4.68551
Timestep Consumption Time: 0.80139
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 5.48690

Cumulative Model Updates: 14,905
Cumulative Timesteps: 248,678,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 248678400...
Checkpoint 248678400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.08397
Policy Entropy: 1.28449
Value Function Loss: 0.19822

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04318
Policy Update Magnitude: 0.07058
Value Function Update Magnitude: 0.07247

Collected Steps per Second: 10,322.69854
Overall Steps per Second: 8,871.67952

Timestep Collection Time: 4.84621
Timestep Consumption Time: 0.79263
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.63884

Cumulative Model Updates: 14,908
Cumulative Timesteps: 248,728,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.74349
Policy Entropy: 1.28991
Value Function Loss: 0.20258

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05381
Policy Update Magnitude: 0.06866
Value Function Update Magnitude: 0.07099

Collected Steps per Second: 10,929.56940
Overall Steps per Second: 9,306.36133

Timestep Collection Time: 4.57731
Timestep Consumption Time: 0.79837
PPO Batch Consumption Time: 0.03793
Total Iteration Time: 5.37568

Cumulative Model Updates: 14,911
Cumulative Timesteps: 248,778,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 248778454...
Checkpoint 248778454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.75986
Policy Entropy: 1.29299
Value Function Loss: 0.21524

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04643
Policy Update Magnitude: 0.06879
Value Function Update Magnitude: 0.07382

Collected Steps per Second: 10,939.58791
Overall Steps per Second: 9,380.46123

Timestep Collection Time: 4.57238
Timestep Consumption Time: 0.75998
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.33236

Cumulative Model Updates: 14,914
Cumulative Timesteps: 248,828,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.18633
Policy Entropy: 1.29022
Value Function Loss: 0.21908

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 0.06999
Value Function Update Magnitude: 0.07648

Collected Steps per Second: 10,863.81137
Overall Steps per Second: 9,370.56358

Timestep Collection Time: 4.60373
Timestep Consumption Time: 0.73363
PPO Batch Consumption Time: 0.04559
Total Iteration Time: 5.33735

Cumulative Model Updates: 14,917
Cumulative Timesteps: 248,878,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 248878488...
Checkpoint 248878488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.50299
Policy Entropy: 1.29052
Value Function Loss: 0.23566

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04033
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.06815

Collected Steps per Second: 10,620.30484
Overall Steps per Second: 8,971.93166

Timestep Collection Time: 4.70909
Timestep Consumption Time: 0.86518
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 5.57427

Cumulative Model Updates: 14,920
Cumulative Timesteps: 248,928,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.76443
Policy Entropy: 1.29036
Value Function Loss: 0.22576

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04684
Policy Update Magnitude: 0.07491
Value Function Update Magnitude: 0.07068

Collected Steps per Second: 10,909.61790
Overall Steps per Second: 9,172.42304

Timestep Collection Time: 4.58586
Timestep Consumption Time: 0.86853
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.45439

Cumulative Model Updates: 14,923
Cumulative Timesteps: 248,978,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 248978530...
Checkpoint 248978530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.97254
Policy Entropy: 1.29042
Value Function Loss: 0.21590

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04309
Policy Update Magnitude: 0.07108
Value Function Update Magnitude: 0.06448

Collected Steps per Second: 10,641.55204
Overall Steps per Second: 9,030.62163

Timestep Collection Time: 4.70101
Timestep Consumption Time: 0.83859
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 5.53960

Cumulative Model Updates: 14,926
Cumulative Timesteps: 249,028,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.47809
Policy Entropy: 1.28973
Value Function Loss: 0.18894

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05713
Policy Update Magnitude: 0.07319
Value Function Update Magnitude: 0.05969

Collected Steps per Second: 10,639.07292
Overall Steps per Second: 9,119.85005

Timestep Collection Time: 4.70116
Timestep Consumption Time: 0.78314
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.48430

Cumulative Model Updates: 14,929
Cumulative Timesteps: 249,078,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 249078572...
Checkpoint 249078572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.69078
Policy Entropy: 1.29490
Value Function Loss: 0.18792

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03571
Policy Update Magnitude: 0.07373
Value Function Update Magnitude: 0.06649

Collected Steps per Second: 11,053.78707
Overall Steps per Second: 9,558.62636

Timestep Collection Time: 4.52370
Timestep Consumption Time: 0.70760
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.23130

Cumulative Model Updates: 14,932
Cumulative Timesteps: 249,128,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.93108
Policy Entropy: 1.29127
Value Function Loss: 0.17209

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05453
Policy Update Magnitude: 0.07138
Value Function Update Magnitude: 0.06584

Collected Steps per Second: 10,429.54286
Overall Steps per Second: 8,944.00979

Timestep Collection Time: 4.79446
Timestep Consumption Time: 0.79632
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.59078

Cumulative Model Updates: 14,935
Cumulative Timesteps: 249,178,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 249178580...
Checkpoint 249178580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.95049
Policy Entropy: 1.29310
Value Function Loss: 0.16970

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05266
Policy Update Magnitude: 0.06602
Value Function Update Magnitude: 0.07626

Collected Steps per Second: 10,831.68467
Overall Steps per Second: 9,311.58827

Timestep Collection Time: 4.61646
Timestep Consumption Time: 0.75363
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.37008

Cumulative Model Updates: 14,938
Cumulative Timesteps: 249,228,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.68428
Policy Entropy: 1.28939
Value Function Loss: 0.17831

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05028
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.08238

Collected Steps per Second: 10,195.64918
Overall Steps per Second: 8,692.61919

Timestep Collection Time: 4.90464
Timestep Consumption Time: 0.84806
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 5.75270

Cumulative Model Updates: 14,941
Cumulative Timesteps: 249,278,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 249278590...
Checkpoint 249278590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.05453
Policy Entropy: 1.28908
Value Function Loss: 0.19660

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04449
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.07484

Collected Steps per Second: 10,839.26855
Overall Steps per Second: 9,322.49327

Timestep Collection Time: 4.61304
Timestep Consumption Time: 0.75054
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.36359

Cumulative Model Updates: 14,944
Cumulative Timesteps: 249,328,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.58092
Policy Entropy: 1.28986
Value Function Loss: 0.20010

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.06880

Collected Steps per Second: 10,380.68316
Overall Steps per Second: 9,104.57433

Timestep Collection Time: 4.81818
Timestep Consumption Time: 0.67532
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.49350

Cumulative Model Updates: 14,947
Cumulative Timesteps: 249,378,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 249378608...
Checkpoint 249378608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.60200
Policy Entropy: 1.29075
Value Function Loss: 0.19438

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06079
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.07760

Collected Steps per Second: 10,558.15723
Overall Steps per Second: 9,071.13721

Timestep Collection Time: 4.73719
Timestep Consumption Time: 0.77656
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.51375

Cumulative Model Updates: 14,950
Cumulative Timesteps: 249,428,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.16935
Policy Entropy: 1.28800
Value Function Loss: 0.18103

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05290
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.08346

Collected Steps per Second: 10,753.50472
Overall Steps per Second: 9,155.10244

Timestep Collection Time: 4.65244
Timestep Consumption Time: 0.81228
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.46471

Cumulative Model Updates: 14,953
Cumulative Timesteps: 249,478,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 249478654...
Checkpoint 249478654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.83989
Policy Entropy: 1.28620
Value Function Loss: 0.19701

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.09361

Collected Steps per Second: 11,019.51072
Overall Steps per Second: 9,204.38521

Timestep Collection Time: 4.53940
Timestep Consumption Time: 0.89518
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 5.43458

Cumulative Model Updates: 14,956
Cumulative Timesteps: 249,528,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.93544
Policy Entropy: 1.29301
Value Function Loss: 0.19711

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.12127

Collected Steps per Second: 10,631.43562
Overall Steps per Second: 9,148.24295

Timestep Collection Time: 4.70567
Timestep Consumption Time: 0.76292
PPO Batch Consumption Time: 0.03843
Total Iteration Time: 5.46859

Cumulative Model Updates: 14,959
Cumulative Timesteps: 249,578,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 249578704...
Checkpoint 249578704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.14054
Policy Entropy: 1.28903
Value Function Loss: 0.21076

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.11839

Collected Steps per Second: 10,603.93673
Overall Steps per Second: 9,115.62257

Timestep Collection Time: 4.71636
Timestep Consumption Time: 0.77004
PPO Batch Consumption Time: 0.03960
Total Iteration Time: 5.48641

Cumulative Model Updates: 14,962
Cumulative Timesteps: 249,628,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.66478
Policy Entropy: 1.29250
Value Function Loss: 0.20357

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06349
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.11067

Collected Steps per Second: 10,934.01673
Overall Steps per Second: 9,375.65830

Timestep Collection Time: 4.57526
Timestep Consumption Time: 0.76047
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.33573

Cumulative Model Updates: 14,965
Cumulative Timesteps: 249,678,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 249678742...
Checkpoint 249678742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.44391
Policy Entropy: 1.28778
Value Function Loss: 0.21255

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06883
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.11742

Collected Steps per Second: 10,901.80946
Overall Steps per Second: 9,373.46787

Timestep Collection Time: 4.58805
Timestep Consumption Time: 0.74808
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.33613

Cumulative Model Updates: 14,968
Cumulative Timesteps: 249,728,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.04147
Policy Entropy: 1.28849
Value Function Loss: 0.21415

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04786
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.11582

Collected Steps per Second: 11,243.76332
Overall Steps per Second: 9,499.45773

Timestep Collection Time: 4.44904
Timestep Consumption Time: 0.81694
PPO Batch Consumption Time: 0.03781
Total Iteration Time: 5.26598

Cumulative Model Updates: 14,971
Cumulative Timesteps: 249,778,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 249778784...
Checkpoint 249778784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.25928
Policy Entropy: 1.28203
Value Function Loss: 0.21842

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.09635

Collected Steps per Second: 10,228.20321
Overall Steps per Second: 8,834.69391

Timestep Collection Time: 4.88981
Timestep Consumption Time: 0.77128
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.66109

Cumulative Model Updates: 14,974
Cumulative Timesteps: 249,828,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.74063
Policy Entropy: 1.28100
Value Function Loss: 0.22658

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.06018
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.08456

Collected Steps per Second: 10,918.16223
Overall Steps per Second: 9,472.18211

Timestep Collection Time: 4.58227
Timestep Consumption Time: 0.69951
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.28178

Cumulative Model Updates: 14,977
Cumulative Timesteps: 249,878,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 249878828...
Checkpoint 249878828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.37841
Policy Entropy: 1.28040
Value Function Loss: 0.21840

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.07983

Collected Steps per Second: 10,881.68037
Overall Steps per Second: 9,271.29359

Timestep Collection Time: 4.59782
Timestep Consumption Time: 0.79862
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 5.39644

Cumulative Model Updates: 14,980
Cumulative Timesteps: 249,928,860

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.88192
Policy Entropy: 1.28007
Value Function Loss: 0.21243

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.06097
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 10,882.14175
Overall Steps per Second: 9,316.85142

Timestep Collection Time: 4.59560
Timestep Consumption Time: 0.77209
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.36769

Cumulative Model Updates: 14,983
Cumulative Timesteps: 249,978,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 249978870...
Checkpoint 249978870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.49390
Policy Entropy: 1.27918
Value Function Loss: 0.19771

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06899
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.09021

Collected Steps per Second: 10,964.55209
Overall Steps per Second: 9,357.97410

Timestep Collection Time: 4.56015
Timestep Consumption Time: 0.78289
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.34304

Cumulative Model Updates: 14,986
Cumulative Timesteps: 250,028,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.92170
Policy Entropy: 1.28252
Value Function Loss: 0.19976

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05552
Policy Update Magnitude: 0.05982
Value Function Update Magnitude: 0.08344

Collected Steps per Second: 10,173.27115
Overall Steps per Second: 8,617.64020

Timestep Collection Time: 4.91484
Timestep Consumption Time: 0.88721
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.80205

Cumulative Model Updates: 14,989
Cumulative Timesteps: 250,078,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 250078870...
Checkpoint 250078870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.12719
Policy Entropy: 1.28147
Value Function Loss: 0.20679

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05232
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.08934

Collected Steps per Second: 10,649.56105
Overall Steps per Second: 9,277.47250

Timestep Collection Time: 4.69653
Timestep Consumption Time: 0.69459
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.39112

Cumulative Model Updates: 14,992
Cumulative Timesteps: 250,128,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.81291
Policy Entropy: 1.28399
Value Function Loss: 0.20840

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05501
Policy Update Magnitude: 0.06646
Value Function Update Magnitude: 0.09615

Collected Steps per Second: 10,969.03860
Overall Steps per Second: 9,266.47009

Timestep Collection Time: 4.56047
Timestep Consumption Time: 0.83792
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 5.39839

Cumulative Model Updates: 14,995
Cumulative Timesteps: 250,178,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 250178910...
Checkpoint 250178910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.40127
Policy Entropy: 1.28335
Value Function Loss: 0.20502

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06574
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.08779

Collected Steps per Second: 10,752.37084
Overall Steps per Second: 9,250.47056

Timestep Collection Time: 4.65237
Timestep Consumption Time: 0.75536
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 5.40772

Cumulative Model Updates: 14,998
Cumulative Timesteps: 250,228,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.73034
Policy Entropy: 1.28546
Value Function Loss: 0.19480

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04128
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.08356

Collected Steps per Second: 10,512.65721
Overall Steps per Second: 9,021.63955

Timestep Collection Time: 4.75883
Timestep Consumption Time: 0.78650
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.54533

Cumulative Model Updates: 15,001
Cumulative Timesteps: 250,278,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 250278962...
Checkpoint 250278962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.87435
Policy Entropy: 1.28352
Value Function Loss: 0.18147

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03821
Policy Update Magnitude: 0.07041
Value Function Update Magnitude: 0.08546

Collected Steps per Second: 10,613.15957
Overall Steps per Second: 9,083.50415

Timestep Collection Time: 4.71151
Timestep Consumption Time: 0.79341
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.50492

Cumulative Model Updates: 15,004
Cumulative Timesteps: 250,328,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.20669
Policy Entropy: 1.28116
Value Function Loss: 0.17651

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.04009
Policy Update Magnitude: 0.07084
Value Function Update Magnitude: 0.09428

Collected Steps per Second: 10,098.91789
Overall Steps per Second: 8,866.12651

Timestep Collection Time: 4.95103
Timestep Consumption Time: 0.68842
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.63944

Cumulative Model Updates: 15,007
Cumulative Timesteps: 250,378,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 250378966...
Checkpoint 250378966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.55927
Policy Entropy: 1.28464
Value Function Loss: 0.18126

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05269
Policy Update Magnitude: 0.07047
Value Function Update Magnitude: 0.09522

Collected Steps per Second: 10,821.87777
Overall Steps per Second: 9,262.47441

Timestep Collection Time: 4.62267
Timestep Consumption Time: 0.77826
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.40093

Cumulative Model Updates: 15,010
Cumulative Timesteps: 250,428,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.00482
Policy Entropy: 1.27879
Value Function Loss: 0.17494

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05288
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.09396

Collected Steps per Second: 10,536.96595
Overall Steps per Second: 9,039.78076

Timestep Collection Time: 4.74824
Timestep Consumption Time: 0.78641
PPO Batch Consumption Time: 0.04043
Total Iteration Time: 5.53465

Cumulative Model Updates: 15,013
Cumulative Timesteps: 250,479,024

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 250479024...
Checkpoint 250479024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.50444
Policy Entropy: 1.28178
Value Function Loss: 0.18950

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04997
Policy Update Magnitude: 0.07182
Value Function Update Magnitude: 0.09187

Collected Steps per Second: 11,232.98031
Overall Steps per Second: 9,561.98586

Timestep Collection Time: 4.45171
Timestep Consumption Time: 0.77795
PPO Batch Consumption Time: 0.03784
Total Iteration Time: 5.22967

Cumulative Model Updates: 15,016
Cumulative Timesteps: 250,529,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.18879
Policy Entropy: 1.28426
Value Function Loss: 0.18276

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04734
Policy Update Magnitude: 0.07169
Value Function Update Magnitude: 0.08230

Collected Steps per Second: 11,449.81358
Overall Steps per Second: 9,603.01901

Timestep Collection Time: 4.36706
Timestep Consumption Time: 0.83985
PPO Batch Consumption Time: 0.03887
Total Iteration Time: 5.20690

Cumulative Model Updates: 15,019
Cumulative Timesteps: 250,579,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 250579032...
Checkpoint 250579032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.28838
Policy Entropy: 1.28444
Value Function Loss: 0.19295

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04364
Policy Update Magnitude: 0.07145
Value Function Update Magnitude: 0.07685

Collected Steps per Second: 11,375.75196
Overall Steps per Second: 9,659.13155

Timestep Collection Time: 4.39619
Timestep Consumption Time: 0.78129
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 5.17748

Cumulative Model Updates: 15,022
Cumulative Timesteps: 250,629,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.66126
Policy Entropy: 1.28163
Value Function Loss: 0.19176

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04757
Policy Update Magnitude: 0.07345
Value Function Update Magnitude: 0.08037

Collected Steps per Second: 11,396.48406
Overall Steps per Second: 9,624.01283

Timestep Collection Time: 4.38802
Timestep Consumption Time: 0.80815
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.19617

Cumulative Model Updates: 15,025
Cumulative Timesteps: 250,679,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 250679050...
Checkpoint 250679050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.15803
Policy Entropy: 1.28481
Value Function Loss: 0.20590

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05079
Policy Update Magnitude: 0.07449
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 10,535.66348
Overall Steps per Second: 9,038.33846

Timestep Collection Time: 4.74882
Timestep Consumption Time: 0.78671
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 5.53553

Cumulative Model Updates: 15,028
Cumulative Timesteps: 250,729,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.51387
Policy Entropy: 1.28891
Value Function Loss: 0.20222

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04324
Policy Update Magnitude: 0.07199
Value Function Update Magnitude: 0.07211

Collected Steps per Second: 10,748.70071
Overall Steps per Second: 9,165.76510

Timestep Collection Time: 4.65303
Timestep Consumption Time: 0.80358
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 5.45661

Cumulative Model Updates: 15,031
Cumulative Timesteps: 250,779,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 250779096...
Checkpoint 250779096 saved!
