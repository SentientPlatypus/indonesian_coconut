{"PPO Batch Consumption Time":0.03551570574442545,"_step":41099,"Cumulative Timesteps":1000023838,"_wandb":{"runtime":139521},"Overall Steps per Second":10390.827006176378,"x_vel":-6.274587732964115,"Value Function Loss":2.4869624773661294,"y_vel":248.26591665911428,"Mean KL Divergence":0.017151905844608944,"_runtime":139521,"Timesteps Collected":50020,"SB3 Clip Fraction":0.13517999649047852,"z_vel":8.38126073630713,"_timestamp":1.7608595517814496e+09,"Policy Entropy":1.0166916052500408,"Policy Update Magnitude":0.07515363395214081,"Collected Steps per Second":12415.113337925037,"Timestep Consumption Time":0.7849008999983198,"Timestep Collection Time":4.02896039999905,"Policy Reward":839991.3823155109,"Cumulative Model Updates":59955,"Value Function Update Magnitude":0.09312145411968231,"Total Iteration Time":4.81386129999737}